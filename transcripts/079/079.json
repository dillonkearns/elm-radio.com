{"text": " Hello Jeroen. Hello Dillon. You know what goes really well with scaffolding? Workers? Builders. Builders, yes. And I think we're going to be talking about both of those things today. Sounds good to me. I feel like you're trying to make a pun but I don't get it. I feel like I have to at least make some sort of attempt at a bad joke to start things off otherwise people will be disappointed. People will be disappointed either way I'm sure. But you know, I have to do my best. Yeah, I mean the joke that I had in mind was let's try to build a good episode or something. Let's try to scaffold a good episode but we'll just go with yours and we will not edit either of these out. Oh no, these bad puns go straight to tape. No second chances. Yeah. I mean we have removed so many good puns in our episodes. People are going to think we only make bad puns. But we just edit those out. There are no good puns. The worse a pun is the better it is. That's the only way you have a true bad pun. A true good pun is a true bad pun. So scaffolding. So we've talked about code generation. We've talked about OMCODEgen which I think is a really lovely tool for scaffolding. So let's first of all, let's get a definition like what is the difference between code generation and scaffolding? So do you want to take a stab at it? Sure. So I would probably say scaffolding at least for computer science, right? Scaffolding is generating code. So it is code generation but it is meant for things that are temporary or to start something. So you generate code that humans are afterwards going to maintain and change to their needs. Whereas if when we talk about more regular code generation like, oh we need to generate code based off this to do things like boilerplate linking, then that is not meant to be touched by a human. So scaffolding is more for, well, let's use this to start with and then we can change it. Right. So I would say that to me, code generation is a superset of scaffolding. Often when we talk about code generation, as you say, we are, especially in the Elm community, we're often referring to generating code that is not user maintained code. You know, GraphQL, like take the GraphQL schema, generate some decoders and encoders or generate an API or Elm SPA generates the wiring for your SPA application or whatever. So those are forms of code generation. But as you said, it's not meant to be touched by a human after it's generated. Whereas scaffolding, and I really like this sort of term and metaphor, you know, you think about the scaffolding around a building, it's like a temporary structure to help you create something that gets removed once that thing has been created. So you know, you scaffold something, you generate some code that a human can then maintain. But once it's sort of built it up for you, you don't care about what was initially templated out for you. Yeah, the one thing that I would say is bad about this metaphor is that usually you end up with a result that is pretty close to the scaffolding. So for instance, if we try to scaffold a, an Elm project, while we generate a main, we generate a init, update, view function, and that structure is still going to be there. You will change the view function, you will change the update function and the init, which is like still most of the application, but the core parts of the structure will still be there. Whereas we'll scaffolding, well, yeah, pretty much everything's going, is going away. Right. It's almost like, often it's like a pre assembled unit that you're probably not going to change the sort of exterior pieces you're going to fit within it. At least in our use cases, that's pretty common. So I think like, so with Elm Pages v3, I've been really trying to, you know, you've talked about this idea a lot that I think you credit Richard Feldman for, of take responsibility for user experiences. I really like this idea of like, looking at what is the user's workflow and their whole experience in building something with your tool or package. And with Elm Pages v3, I've been thinking about like, what is that end to end experience if you're trying to add a new route, if you're trying to wire in a form, right? And you know, I've been thinking about the form API a lot. We did an episode talking about some of those ideas of all these API design techniques you can use to make that easier phantom builder pattern. I have some opinions about ways to reduce the amount of wiring you have to do and leveraging web standards to not have to do extra work. So the framework can manage these things for you and all these things. For those who haven't listened to those episodes, you only have like six or eight episodes to listen to. Go ahead and come back to this episode afterwards. That's right. Pause now and go listen back. So that's one dimension of taking responsibility for user experiences, making that flow simpler. But then how do you create a new form? How do you create a new route with a form? So I've been really thinking about that. And I think scaffolding is the answer. And like Elm SPA, Ryan did a great job kind of creating some templating helpers that you can customize the sort of these these add commands to add new types of pages in Elm SPA. I've been very inspired by Rails and I've gone back and been watching DHH's sort of early days, 17 years ago, demo of building a blog engine in 15 minutes. And he actually really built it in more like three or four minutes if you watch the timestamps. And then he's like adding comment sections and customizing things after that. So that was kind of a groundbreaking idea at the time, I think, in the server world to be able to just like up and running with a server framework rather than like creating a bajillion config files and installing all these dependencies and setting all these things up. You just like create a database, add some fields and run a scaffolding command and then you have an app. And then you customize the views from there. I thought that was really cool. And I think in some ways we've lost touch with that ethos of making it really easy to get up and running with something, but it's still just as relevant today. So I want to make scaffolding a thing again. And I think in the Elm community in particular, because we have to be so explicit with things, scaffolding is a really great opportunity because we like being explicit in Elm and we don't like magic in Elm. And in fact, there's not that much magic you can actually do in Elm. So scaffolding is sort of the best of both worlds. Like you don't have to handwrite all of this boilerplate, but you can sort of get something up and running. Now we still want to reduce the amount of boilerplate you need in the first place, but it can still help you right then. So clarify what you mean with scaffolding in this instance, because I'm familiar with the concept of scaffolding a new project, for instance. The scaffolding something else is a little bit more foreign to me. I mean, I know what you have in mind, but can you maybe explain it? Yeah, absolutely. So for example, I've been, I actually created a video walking through this, but I'm trying to get it down to 15 minutes like that original Rails demo of creating the same sort of full stack blog engine with database persistence in Elm Pages v3. And so do you try to impersonate DHH? No, I don't. Do the same accent, do the same. It's tempting. It is tempting. It's really funny how when he's doing the demo, he like, he runs a command and then like it works and then he goes, whoops, it worked. He always says whoops whenever something works. It's really funny. So I'm definitely tempted to do that too. So like, for example, like creating a new, you know, the route for creating a new blog post entry that has like the slug and title and body. I've created this sort of helper for running like Elm Pages run, which we talked about Elm Pages scripts, refer back to that episode. So you can run these scripts. I created an API for helping you to sort of scaffold things using Elm Code Gen. So you do Elm Pages run, add route, and then you give it the name of, you know, the new blog post page or whatever. And then you can give it a list of form fields, just like a Rails generator. You can give it the like, you can give it title, colon, string. You can do the same type of thing. You can say, you know, you can give like a checkbox field, you can do colon to give the types to these different form fields. But so you can list out these different fields and it generates a route. It has init and update and view and all of these things, which is like, you know, it's a lot to write out a fresh page. And then it generates the form using the Elm Pages form API. And it wires up the rendering of the form and everything. Now, again, I've gone to great lengths to try to make the wiring very minimal for the Elm Pages form API. But I think that that's like, I think we have to attack it from both sides. We have to make the boilerplate minimal, but then we have to help you build that minimal boilerplate to give you the full productivity experience to take responsibility for user experiences. I wanted to be able to have that DHH. Like I want to do that DHH level of productivity. Like I want people and, you know, Rails was sort of a groundbreaking approach to full stack when it was introduced. Now things are moving in this direction where full stack frameworks are often sort of more tied to the front end. So you can render full stack things, pull in database data, and then hydrate that into your preferred front end framework. But we need to like get back to the roots of Rails productivity to make something that people really love and can be very productive in. Now Rails has a lot of magic. Elm has a lot of boilerplate. And between like meta frameworks that take away some boilerplate and scaffolding commands that help you assemble the minimal amount of explicit Elm code to reduce that boilerplate, I think there's something really compelling there. And I think like in Elm, we like writing decoders if we need a decoder. We don't want to be implicit and magical. So we should use scaffolding commands for why not have a scaffolding command for generating JSON decoders, or this is for generating forms. So whenever you say we need to scaffold something, you run a script through Elm pages or something custom that you built or just run Elm code gen with a predefined code generation script. And then you generate a new file. Is that the idea? You generate a new file that represents a route, a new file that contains a decoder and encoder, stuff like that. So one thing that you could also do is just be a regular person. And if there's already a route, just copy paste it and adapt it. Why not do that instead of scaffolding something from scratch? When should you reach out for scaffolding instead of copy pasting, which could be closer to what you want anyway, or also in a way pretty different, but who knows? It's a great question. I think to me, it's about we have the technology, we have the ability to like automate things. And so, but if we don't create nice interfaces and create the right tools to automate these types of tasks, then we are going to just find it easier to copy paste things and we're going to do that. And, you know, that's fine, but exactly like it's just, if we're copy pasting, that's just a sign that we haven't done a good enough job making it easy to do it in a better way. Right. And so what is that better way? What are those tools for that? So like for the, so like in the ElmPages V3 API, I have a couple of scaffold modules, scaffold.form and scaffold.route. And so this is one of the things that I'm experimenting with. I think that Elm CodeGen is a very nice tool for scaffolding out code, but it's somewhat low level. So it generates helpers for you for, if you want to run list.map, you can do gen.list.map and then you can pass in the corresponding expressions or it doesn't generate all of the high level types for you. A lot of the types end up being Elm.expression because it takes some argument, but that argument could be coming from like a variable you have in scope and it, and it helps you sort of manage what variables you have in scope by if you, if you define a let using Elm CodeGen, then it, it lets you name a variable that you have in scope. So you have an actual variable, but it represents an Elm expression, which is the variable in the code you're going to generate. It's a little bit, hurts your brain a little bit, right? But it does a good job sort of mirroring the code it's going to end up looking like, but it only does that for like at a lower level. But if you have like a higher level API, I think there's an opportunity to create abstractions that mirror those APIs. Like if you have a builder pattern, so like in Elm pages v3, there's, there's a sort of a route builder for defining your route. Is it a server rendered route? Is it a pre-rendered route? Does it have local state? Does it have shared state? Does it have no state? So that's a, that's a builder that you can sort of tack on these options. And if you, you know, if you do with no state, then you need to give it a view function. You need to define a view function. If you do build with local state, you're going to, in addition to the view, need an update and it subscriptions message and model, right? So that is too like Elm code gen isn't going to help you with knowing that you need to define an update function in the one case and only a view function in the other case. And you're going to need to define these types. There's no way for it to know that. So we can help it out. Right? So I, I basically mirrored that API and we'll, we'll link to these modules in the, in the V3 beta docs of Elm pages, but I tried to, to give some high level helpers. Now like one of the keys here, you know, when, when you are doing the builder pattern, you have this sort of builder type that at the end you turn into whatever thing you want, like an Elm code gen expression or whatever. Right? So you need a level of safety that you're not just sort of constantly taking an expression and applying functions to that expression and things like that. Right? Because then you just have like this amorphous expression and you can do a bajillion things to it. And it's not really like clear how to scaffold this code. So this API has like a, like a builder for the, for the scaffolding type for scaffolding a route. So it's sort of like a, for the, for the route scaffolding, it's a builder for the route scaffolding. So you apply these sort of sets of options for generating a server rendered route with local state. So now you're tacking on these options to give all of the function definitions that you need for those options in the builder pattern. So I think essentially like my assertion here is that I think it's a good idea for packages to create higher level APIs that mirror their APIs for scaffolding. So like for Elm review, if you're scaffolding out a new Elm review rule, which there is a feature for already, but yeah, right. And we should talk about that. So now I will say when I'm working on Elm review rules, I do often go to the docs and copy paste an example of a visitor, for example. Those examples are just awesome. So go ahead. Yeah. And I mean, and there is definitely an art to having examples that are copy pastable because things are defined in a way that not only compile, but you know, maybe you take in certain things as parameters so that it's like a nice sort of self-contained example that you can probably copy paste into your own code. So there's definitely an art to that. And you've done a good job of that. Now the question is similar to what we were talking about before with like copy pasting a new route module, can we beat the copy paste experience? Because if we can't, then why waste our time? Because we can already copy paste anything and that's what people are going to do unless we, you know, like that sets the bar, unless we go past that, people are just going to copy paste. Yeah. So there's one reason why every time I work on a new rule, I start from scratch. So I do use the Elm review new dash rule command, which scaffolds a new file and it scaffolds a new test file. And reason why it starts from scratch is because I want to do things in a TDD style. And if I copy paste some code, then I don't have the test for them because the examples are good, but there are no tests for that specific example, which makes a lot of sense. I think if I wanted to copy paste something, then I would also have to copy paste a test, which is usually not very applicable. So therefore I start from scratch anyway. That said, there are multiple variants of Elm review rules. So there's module rules, which are very simple or simpler, and there are projects rules, which are a lot more complex. And I do think that I should probably have a scaffold for each of those because every time I work on a new one and I need to use a particular rule, I need to migrate the module rule to a project rule. And that's a lot of work. So yeah, I should probably scaffold a variance of that for the more complex approach. But again, I would still want to start from scratch because of TDD. Interesting. So like, I'm totally with you on the TDD thing. Surprising. I mean, I just brought up TDD because I know you wouldn't be able to contradict me after that. That's right. That's right. Yeah. So here's the way I would think about this is, and this has been my experience, like copy pasting things from Elm review is I'm not copy pasting for the behavior, I'm copy pasting for the wiring and boilerplate. So it's like, I need to add some sort of import visitor. And it's like, now I'm in my workflow, I'm going to have a failing test that says, whatever, this thing that is a contextual thing from the imports, whatever needs to add an import expression or it need if it doesn't already exist, I have a failing test that shows that, okay, now I have a failing test. Now what do I do? I need to add an import visitor. Now I need to copy paste something because I just like the functions have a certain set of types, it gets wired in in a certain place. I'm just going to go copy paste something. I'm going to go find the with import visitor docs and Elm review, and I'm going to copy paste that. And I think that makes sense. I do that as well, quite a lot, especially for the project rules that I mentioned before. So I really like no op type boilerplate for that reason, because you can do it effectively as like an atomic step that's not changing your behavior. So it fits in really nicely with TDD where effectively it's just like with TDD as much as possible, you want to work in atomic steps. So if you have a green test and you want to refactor something, right? Well, if you have an automated refactoring, it just, everything is fixed. If you have a manual refactoring, that's going to at some stage have things in a broken state, even though conceptually it just belongs as one atomic thing. So automation can get us closer to this atomic set of steps. And I think it's the same for like scaffolding, basic wiring. And I think it's, as you say, for that reason, it's best done as scaffolding out no op type things. Yeah. So, so I do absolutely get the no op operations that you mentioned, but for me, scaffolding is usually always either a new file, if we talk about code generation, or if we talk about code snippets in your editor, for instance, then it's pasting or generating a short piece of code. So the, the code snippet could be used to do what you just said. But if you, if you talk about code generation or generate files with code gen or something like that, then you can't just, I don't see how you integrate it into an existing file already. Or at least I don't have the tools for that. Right. It's a great, it's a great point. And I think this is something worth exploring. I think that, you know, maybe, maybe we need some conventions and tools for these types of things. So for example, like I can imagine Jasper has this Elm pair tool, which we should probably dig into at some point, but we'll link to that in the show notes. But it's kind of built on, on the idea of this workflow, similar to these sort of Elm format workflows, where it automatically fixes things to do what it thinks you expect by changing a colon to an equals to make the syntax, right, things like that. It will, you know, fix your import aliases and things like that based on you just editing the code, right? Yeah. And you could also use GitHub copilot or other GPT AI things in the future, which could do the same thing. Sure, sure. As always, like with some amount of trust and distrust of the tool of the general code. Yeah. Right. And you also mentioned a few times on the podcast, and maybe we'll get there at some point having Elm review be able to pretty much act like a language server. Right. Or have some kind of tool that allows you to write custom actions. Right, right. Exactly. And, and now the thing is, like, we already have some, some simpler versions of that. So it's not like a language server that's nicely integrated into editors to expose intentions under your cursor. But you know, my Elm review HTML to Elm package, you can do debug.todo with some HTML with a sort of magic debug.todo call. And it takes that to convert it and to scaffold out some HTML for you. And it sort of intelligent scaffolding because it's aware of context. And so we can use similar patterns. So you could imagine a similar pattern. You know, and Martin Stewart has, like a similar sort of unpublished tool, but he's worked on this Elm review to do it for me. Tool that sort of helps you scaffold out decoders and things like that based on these magic debug.todo calls. Alex Corbin has an Elm review rule for JSON to Elm. Yes, right. Martin Stewart did some things similar to that and others, but yeah, not published. Yeah, I originally got that idea of that pattern from Martin Stewart and used that idea to for Elm review HTML to Elm. And like, so that's a, like, that's kind of a cool pattern. And you could even imagine having, for example, like, to be honest, I haven't integrated a workflow like this myself, but I think it could be cool. What if we have a bunch of these sort of scaffolding Elm review rules? You could even have like a special review scaffolding folder, right? So a normal Elm review folder by convention is in./.review. Well you could have like a separate review config with your scaffolding ones for scaffolding out decoders, HTML, helping you scaffold out Elm review rule helpers, helping you scaffold out Elm pages forms, you know, the sky's the limit. And then have that running in the background in watch mode in auto fix mode. That could be really cool, right? Yeah, or with a nice integration with the editor, which is currently a little bit lacking, but yeah. Right. And I think that this is actually a very nice progression to, you know, sort of do the 8020 version of it where you don't have to build a fancy thing that gives you options from under the cursor and you just use debug.todo to have valid syntax, but give a special keyword within the string in the debug.todo that Elm review interprets. I mean, you would probably have a code snippet that creates a debug.todo with the right thing, and then you place part of it and then you would have Elm review. That's an amazing idea too. Yeah. So like, I think it would be really cool to have like, let's say like import visitor, you know, what if, and see, here's the thing is like, like Elm review, the actual Elm review package could even ship some of these either scaffolding helpers for like Elm code gen stuff to help with this or an Elm review rule. Now that's meta if Elm review ships Elm review rules to help you generate Elm review rules. You mean instead of having Elm review rules for reviewing Elm review rules, which is, is probably going to happen at some point, to be honest. The snake eating its tail. Yeah. I love it. I love it. We can add steps to it if you want. Who needs copilot? We're going to have Elm review rules to review scaffolding tools for Elm review. Exactly. That generates Elm review rules to, and then this circle is. I did use Elm review HTML to Elm to build Elm review HTML to Elm. The website version. There's like a site that you can paste the code into and I definitely used it to build itself. So that's good. Gotta love a good bootstrapping story, but, um, and, and I mean, I made Elm review and since then I have not made much with it. No, I do use it at work, but yeah, maybe one day I will start custom projects. Probably an Elm review website. Yeah. Yes. One day. And a scaffolding helper. I think it would be great. Like, so I think I like this pattern. I think, I think I'm a fan of this idea that we've just developed here. You heard it here, folks. And then it never happened. Okay. So you see some value and I mean, I, me too, but you see some value in having scaffolding tools to help you with tasks that you do a lot. Small tasks with things like HTML to Elm or bootstrapping tasks, like a new route or a new rule, that kind of thing. How do you identify what you need or when a scaffolding would be a good tool and where it would be worth the investment mostly? Because I mean, copy pasting is still an option or rewriting everything from scratch is still an option. And for the fair short run, there's always going to be faster. So how do you identify those? And we can talk later about how do we know what to generate? Right. I think it's, I think it's kind of similar to Jeroen's hierarchy of constraints where, so like, if you can make impossible states impossible, then you should do that. Don't write an Elm review rule to give guarantees that the compiler, that you can use the compiler to directly give you that. Like yes, Elm review rules are great, but they're there when you need them because the compiler can't give you that. Right. So it should, you should go up, up the pyramid, start with the most robust way of doing it and the first class approach. So similar with sort of scaffolding, if you can eliminate boilerplate by not needing it at all, because you have a more declarative API, you have a clever trick that reduces the amount of boilerplate you need without introducing magic or complexity, then you should absolutely do that. And again, I went to great lengths to try to do that with my form API design. Right. So attack it from both sides. So that's number one. But then once you do notice that, okay, I've reduced the amount of boilerplate I need to set this up, but it's still, I think that there are a couple of things to consider in your workflow when you notice something taking time, but also getting in the way of your thought process because it, it's a context shift, right? So it's not just the amount of time something takes, but it's the amount of context shifting it requires. And because of that, sometimes these sort of workflow automations can be greater than the sum of their parts where having an automated refactoring, maybe it saves you two seconds, but maybe it makes you more likely to do that refactoring. And maybe it allows you to stay focused on the problem you're solving and let refactoring be something that takes no, no brain space. So that's a win, even if it doesn't save you time. So I think those are a couple of things to consider. There's also just sharing with others in the sense that for instance, you might know how to create a new L module and to wire all the updates functions together, the view functions, the subscriptions and all that. And maybe it takes very little amount of time for you to create all those and to wire everything up. But for a beginner, that will take a lot more time. So if it's for you, it's already automatic and you know how you could do, and you know how you could automate that, then that could be worthwhile for a beginner. Right. Or maybe not this example, but yeah. Yeah. You can use it to model best practices. You know, the things that get copy pasted might not end up being the best examples of things to get copy pasted. So you can sort of model the ideal way to write something in sort of scaffolding helpers. That's actually something that I've found that, that's actually something that I'm finding to be a lot more of a problem than I expected is that if you leave bad code around, it gets copy pasted a lot. Exactly. It's always the bad code that gets copy pasted, but that might be some bias. I hope it's a bias. No, it is exactly. And which is something to say about code debts, like fix it now or it will multiply. Exactly. Exactly. Yeah. Sandy Metz talks about this a lot in refactoring. She has some really great books on refactoring in Ruby, but she talks about a lot of just sort of general best practices and refactoring techniques. And she talks about sort of, I can't remember the word she used, but something like replicability or like somehow code wants to be duplicated. So there's a cost to having code that doesn't represent the way you want to do something in your code base. That said, I mean, you can write tools to say, well, this is the way things should be. But if you're starting with a new approach and you're still exploring and like, well, is this the right approach? Maybe we'll try it out and come back to it later. If you don't know what the right approach is yet, then you can't really make tools for it. So, but for things that you do over and over again and always in the same manner, yeah, make tools, make your life easier. Right. Now, just as you want to keep in mind, like what direction you want to guide the code with your scaffolding and your automation tools and how that shapes the code, you also want to make sure that you don't make it too easy to generate things that you don't necessarily want or to duplicate things rather than reusing shared things. This is another consideration. Yeah. Are you thinking of, for instance, when someone creates a module and they add in it, update view and in the end they only need the view? Is that kind of thing? Yeah, that would be one example. Or maybe it's so easy to scaffold out a new decoder that you don't go to see if there's an opportunity to reuse something that already exists somewhere else because it's so easy to just build up the decoder using these automation helpers you have. But yeah, I think, you know, with Elm, we like being explicit. We like to have all of the information of how to do something in code, not defined through magic, not implied through some type somewhere. And so I think scaffolding is like a really good technique to bridge that gap. So like one of the things to think about also is like, what are the inputs to your scaffolding? So like, you know, we talked about using these sort of debug.todo comments that have some sort of something in the debug.todo string that tells it what to do, what to replace that with. That's one pattern. Having sort of an inline thing in the code telling you that you want to do something with that. You can use a CLI to scaffold out new things. You can pull in data from different sources. You can pull in, I mean, I think it would be really cool to have a JSON decoder scaffolding helpers that take a URL or an HTTP request or something and scaffold that for you. So I think it's worth thinking about what are the inputs to and how can we really automate the process to make it really seamless to not have to think about boilerplate in our own code. Yeah. At work we have a few code generation tools or scaffolding tools, for instance, to create routes and then we have a separate code generation script to combine them in an Elm SBA like way. So there's a lot of scaffolding and code generation going around that. One problem is like, usually people don't know that these things, these scaffolding tools exist. So they're in the readme, but no one reads the readme because I mean, it says readme. It doesn't say ignore me. Interesting. That could be fun file to have ignore me.mt. People might actually read that one. I wouldn't read it. I like it. So yeah, we have the problem, but I mean, the tool is there sometimes. It's just not going to be used. That's all. So if you do have like, if you make a package with those scaffolding tools integrated into the package, then I would really recommend like add a nice section in your readme about like, Hey, you should use these things. Then there's the same question I was wondering about a few years ago is like, well, if you have a package, like let's say Elm UI, should you have Elm review rules that come with it? And I would, today I would probably say no, because then you're adding additional dependencies and you should probably have a separate package with the Elm review rules. And I think I'm thinking maybe you should have that too for the scaffolding. I mean, I think the challenge there is keeping them in sync between versions, because if it's in the same package, so like if you have a breaking change, how do you, how do you make sure that the scaffolding tools are being run against the same target version? That's one challenge that you introduce by having them be separate. Yeah. But now, I mean, the problem with dependencies that you now depend on Elm Code Gen, which has maybe other dependencies, and now you risk of having like some major dependency version mismatches, which I always find very scary, at least. Right. So just to elaborate, for people who might not know, in Elm, pulling in dependencies to a package doesn't eagerly pull in those dependencies to your actual code. So it's not like JavaScript that it is going to bloat your bundle size just because you depend on an extra dependency, or that it's going to install it for every single time you npm install your node modules is going to have a duplicate version of that code. And it's going to blow up your file size on your system. There's a single shared place that it caches on your system. So it doesn't really cause problems for that. Elm has live code inclusion, or dead code elimination. So it doesn't really cause issues for that if you don't call a function in your production code that uses the scaffolding thing, it doesn't pull in those dependencies. But if you're upgrading to a new version of some package, and that dependency creates a conflict between that upgrade, that's where it causes headaches. Yeah, it's mostly those Elm Community extra packages that scare me a lot. Which often it's nice to just like inline those because it's not worth making it difficult for people to... Yeah. So again, to clarify, if there's a new major version of, let's say Elm Community list extra, so there's v9, and then an old package or another package depends on v8, then you can't install those two at the same time, because of how Elm works, which makes things simpler. But these kinds of problems do arise. Yeah, we need some sort of like scaffolding tool to inline extra helper functions. No, I mean, it's, it would be nice. It's definitely not ideal to like copy paste these helpers into packages to reduce these dependencies. But if it's like one function from list extra or two functions from list extra, it's not worth having users have that dependency dance if something has a breaking change. I mean, from what I understand, NPM has this ability to install multiple versions of a package, right? Right. But that's also the reason why your node modules are so huge, because it installs plenty of those versions, because you can depend on packages so easily. Right. And it can cause weird unexpected behavior too, right? So it's like, it definitely simplifies like reasoning about your code to be like, this is the version of this dependency that that all of my code uses. Yeah. So yeah, Elm has this little limit limitation, but yeah, we're looking at the node modules. I'm like, yeah, this is pretty good. Actually. It's a pretty sane limitation. Yeah. It's a sane constraint. Elm is good at this. You mentioned inputs for the scaffolding, but you were talking about how do you integrate these scaffoldings? How do you use them? What method? What about the inputs to the scaffolding tool? Like should you, for instance, should you have options to your scaffolding scripts? Let's say we want to make a new module or let's make a new Elm project. Should we have an option to say, well, I want a browser sandbox or a browser elements or a browser application and so on and so on. How custom do you think these should be? Right. I think first of all, it has to beat copy pasting as a user experience. So that's one way to beat copy pasting as a user experience. Now if you make the running the scaffolding tool overly complex, it's not going to beat copy paste, but fair. If you can have a nice CLI. Now Elm pages scripts have the option to do a CLI options parsing that's in pure Elm using my Elm CLI options parser package. So you can use that to add configuration to a scaffolding script. So I think that's like a pretty nice thing to do. If there's like one little flag you want to add to configure one, one change, you should do that. Do you think it's nice for a scaffolding tool to have a few prompt questions or should everything be configurable through the CLI flags? I mean, you could do both. Like if you provide something with the CLI flag that you don't have to ask the question, but they're not necessarily as discoverable or have the same amount of explanation in the prompt. Right. I quite like prompts, but it does make things a bit slower. Right. Yeah. It's definitely a trade off between ease of discovery versus ease of use once you've gotten comfortable with it. So I mean, sometimes tools will sort of have a required flag, but if you don't pass in that flag to the CLI, it will prompt you for it. That can be a nice way to do it. Sort of a best of both worlds approach. It strikes me too that like, so with these magic debug.todo comments that an Elm review rule can find with the special string in there, you could, you know, I think it's good to have conventions for these types of things. So they're discoverable. You could even imagine having like, I don't know, let's say that all of your magic debug.todo comments start with triple exclamation point. So you have three exclamation marks and then maybe the Elm review rule watcher that's running in the background says like, instead of giving a fix, if you just have three exclamation points without anything after it, maybe it says, Hey, here are the ways to fix that. Here are the options you can pass me. So you could have a discoverability experience through that. Right. So like, I think there's a UX opportunity here. It could even be an interesting thing to have like a shared package to crystallize some of these conventions, because I think like conventions are important for user experience because otherwise like people aren't going to go to the readme to look it up. You have to like make it more within reach. We just have to understand that about people that they're probably not going to read the readme, but if we make it easy for them to guide them in the right direction, when they try to do something, they might actually use it instead of copy paste. That's actually something that is, that's actually something that I find it to be a bit of a shame that it's not very discoverable. So for instance, if we're pairing together and I'm running a function or actually you just look at my code, because I've sent you a pull request and you see a function that I've used and you've never seen before, or you go to the documentation and you see, Oh, well, list.partition is a thing. Oh, that could be pretty useful. I will use that next time. But you can see that because it's in the code and it's committed and all that. But all the things that I have done that you have not seen because it's not committed, like all the keyboard shortcuts that I use, all the editor integration that I use, all the scaffolding tools that I use, you don't see them. That's actually like one of the reason why people say, Oh, you should pair together because that's when you learn so many new things. Every time I pair, I learn a new thing with someone. A hundred percent. Or teach someone something new. It goes both ways. Totally. I agree. And workflow, like, I mean, one thing I really learned from a lot of sort of people in these software craftsmanship circles is like, workflow and automation are not just like a vanity sort of cool way to customize your system. It's not like, Whoa, look at this cool theme I have and look at this cool shortcut I have for this and this cool automation. It's like, no, actually, like automating things is a really important part of like building great software. In my view of building great software, like this is a key way to get better at doing that. So I think it's be taken seriously. Yeah. I mean, it would be hard to argue that using notepad is the way to write applications today when the only shortcuts you have is control C and control V. Right. So yeah, you know, all the things that a editor gives you, even a simple one, well, they're useful. They're really useful. Yeah. And again, because it helps you get to those atomic steps of changing things. Now, I'm not going to say that somebody can't create great software without these things. It's just like they're missing out on a superpower. You can also like another superpower is being really good at modeling systems and knowing when to say no to certain features and writing tests first and things that you can do without automating these steps. So I'm not saying that that's the only part of building great software, but I think it's like to me, it's an important piece of the puzzle. It's an important tool in the toolkit. So going back to scaffolding and all those things, what would you write in the scaffolding code? So again, let's take the example of you scaffold a new application with a main and init update view browser data application, whatever. How much comments code would you integrate? So for instance, one thing that I might be wondering is like, well, if I want this code to be for anyone who's new to Elm, then I might add a few comments that says, well, oh, this is main, this is how your application starts and this is how it works. And then you have a comment around init that says, well, this is how we initialize your application and one for model. This is all the data that your application can hold, et cetera, et cetera. So is that something that you think we should do? And also like maybe also steps for, oh, well we have now scaffolded this thing and this is where you should change your code. Like here's where you should add a new kind of message variants or this is where you shouldn't handle this new updates, this new message. How much should you help someone? And I'm guessing it's like, if it's for you, you don't care because you know what you need to do. I mean, you've been able to automate this, right? But I'm guessing if you're in a team and you often have new developers joining your team, then maybe it's worth adding all these comments, but then you probably also want to strip them out. Yeah. I'm a little bit torn. Yeah. So back to this sort of idea that Sandy Metz has that code tends to be duplicated or replicated. I think the term she uses is, is that good code is exemplary, exemplary, exemplary, exemplary, exemplary. We'll see how our transcripts do on that. Maybe it'll just strip it down to one word. We'll see. Yeah, I think it's you, you want, like, if you don't want to have comments in your code explaining this goes here, this is where you add things. I personally would tend to avoid including that in the scaffolding as well. I would, I would want to add that more as like output from running the scaffolding command and it says, great, I added this thing. Here are your next steps. Now what I would want to do. So for example, let's say we're scaffolding out in a new route module for SBA, Elm pages, your custom homegrown SBA helper, whatever. So personally, I tend, I actually tend to find it more useful to like, have an init function defined, even if you don't use it initially. I just find that easier. So then you don't need a comment to say like, comment, if you want to add init and messages, you can change these things. Just, just have, you know, type message equals no op or whatever, you know, but I was, I was thinking of a comment next to the message type, but always including the type, the message type. Right, right, right. Commenting it out is also a possibility. Yeah. Yeah. And, and so like, basically I would tend to, instead of having comments, maybe have a little bit of terminal output to guide people as, as far as that's helpful, maybe even link them to a guide. If somebody's new to a thing, if you're new to our, the way that our route modules work, here's some documentation about it. And now somebody, somebody is not going to be new to a project, read the entire read me and everything about it, but maybe when they're new to a project, they run the scaffolding command and they see output that links them to the relevant thing with like a minimal output. Maybe then they'll click it and read it because it's relevant to them now. So showing people contextually relevant information, I think is a good technique. And also like showing exemplary code that makes it easy to change in the way you want it to evolve. So like if you have a, if you have a message type that is unit type, type message equals unit, it doesn't make it easy to evolve that module in an idiomatic way. So it's better to have custom type there. And it's better to have your update function do a case expression on the message because that's what's idiomatic or whatever the idiomatic pattern is for your code base. So I would say like, try to set up the idioms in a way that's easy to evolve from as a starting point in your scaffolded code. Even if that's like a little verbose sometimes, I, I think it's worth it. And if things are not clear, then it's also potentially API design that needs to come into play. Like you're not going to be able to change the Elm browser API, but if it's your scaffolding in your routes and your route is something that you control, then maybe you can change the names of the fields of the functions to make it very explicit. Like, Hey, this is probably what you need to do in order to do what you want to do. So make good APIs and things will happen automatically. Yeah, totally. Totally. Yeah. So for your Elm review scaffolding, what does, what does it give you? So you've got scaffolding for an Elm review package and you've got scaffolding for an Elm review rule, right? Yep. And what do those give you? So the package creates a whole new package. So it creates an Elm JSON file. It creates a readme that is formatted in a way that looks pretty much like my other packages, which is the way that I recommend things. It comes with the GitHub action scripts. So if you just push this to GitHub, then you will have a CI. And you also always have to create at least one rule. And then for that one rule, it creates a module for the rule and a test module for that rule. And if you run Elm review new rule, then you also get a new rule and a new test file. And every time you add a new rule, it will automatically update the readme to list that rule and it will add it to the exposed modules in your Elm JSON file. And there's also one file that I generate, which is some documentation of how you should manage your project. Like how do you publish this package for the first time and afterwards, because the first time you have to do it manually, the second time we're using your script to automatically publish something every time you change the version in your Elm JSON file. Oh, and also a new package comes with a review configuration. Right. Yes, very meta. And yeah, this is one thing that I quite like about it is there's an Elm review rule that reports comments when they contain some words and it contain, it will flag everything that contains replace me. And I put that replace me in a lot of places. So for instance, every time you create a new rule, that rule will have already some documentation. It will say this rule reports dot dot dot replace me. And it says this rule for instance, will flag some code and it will have a replace me there and it will not flag this code and it will have replaced me. So I'm forcing the author to at least remove that code or that there was documentation better to replace it. So I'm forcing them to think about documentation in a way they don't have to do it now, but they will have to do it in order for this CI to pass. Right. Yeah, I think you've hit on another dimension of scaffolding that I think is really helpful is like, sometimes you don't like sometimes you need to have a placeholder where you say like, you need to do some like replace this thing and you just you can't fill it in for them but you can at least make it very obvious that something needs to be done there. Yeah. I can fill in the rule name because I know it because I'm generating the prompt for it. But the documentation I will not be able to do that. Right. I don't want them to think about it. You can wire in a GPT API call and take the package name and then generate it. Maybe maybe. Next release. Yeah. I've also I used that same pattern of the replace me and I think I used your same setup from your Elm review in it set up there for the Elm package starter, which is a little template repo, which again, that's another another approach to scaffolding is having, you know, a GitHub template repo. I just recently used the Elm package starter and it was really nice. And I used the Elm review rule to tell me all the replace me spots and then went through and filled those out. And it's a nice workflow. Oh, I'm surprised. Past Dillon did did a good job at it. Yeah, I know. I was pleasantly surprised too. And so the now another cool technique you mentioned there was like replacing sections of the read or, you know, modifying the readme when you add a new rule. That's pretty cool. So I think now it's also possible to like modify code. Of course, this becomes much more complicated than like adding a new scaffolded file to like do like an incision, you know, surgery there. But but it's possible. And I think one thing that helps a lot with that is conventions. If you have clear conventions, and you can just sort of follow like, okay, if these exact conventions are followed, and I can check that it's safe to to modify this thing, because I know these exact conventions will have these exact things I can easily check for. Otherwise, I'm going to bail. But if you follow these conventions, then I will allow you to modify it. So that's sort of a cool, like, not like scaffolding within an existing file technique, I think. Yeah. As you say, like, it's incision, so you I need to detect like, well, where's the section where list all the rules, and I'm expecting it to have some kind of shape or try to do some pattern matching. And so far, no one has complained about it. But it works as long as people don't touch it in a weird way. But I don't know if they know it's a feature. Well, actually, a lot of people don't use my package scaffolding tool, because they don't know it takes because they don't know it is. I used it for creating new packages, and I like it. Yeah, yeah. But I think like, the fact that this sort of technique of modifying things easily without too much fancy static analysis and control flow analysis and type inference and stuff, I think the fact that that depends on using some very clear conventions can be a feature not a bug. Because like enforcing certain conventions and giving you these nice automations you can use if you follow these conventions can strengthen the cohesiveness of a code base. In this case, I'm touching the readme, but if I was touching Elm code, then we would have the compiler to help us out. If we don't have that, or if the Elm compiler doesn't help in this case, then yeah, using conventions is a good way around that. Another thing I played around with a little bit in these scaffolding helpers for Elm pages is I noticed, again, like inspired by this DHH demo, I was trying to notice all the things that were slowing me down when I was using the scaffolding. So one thing I noticed was like originally for the add route scaffolding command I had, I noticed that I would go in, I do add route with a few form fields, it generates a route with with a form wired in. And that's great. But then in the Elm pages sort of full stack code, where it's receiving that form submission, and it has the parsed form, I was debug logging it. And what I found when I was trying to make the demo very short, was that I would forget to take out the debug.log sometimes, and then I would do the part of the demo where I ship it to Netlify and show the full stack thing working. And then it would have an error because the build command was failing because it had a debug in it. So that's sort of like not setting it up for success. And again, not being exemplary code that is making it easy to evolve in the shape you want it to evolve in. So I modified it to take this form that it's generating. So you give the CLI these form fields. These form fields have types. The checkbox has a boolean type, a text field has a string type. So it knows sort of the types. It generates a record for the parsed form that you can change the scaffolding to map it into nicer opaque types or whatever you want to do. But it gives you a sort of good baseline of strings and bools and date types for the parsed form. And then I have a scaffolding helper. So you can take that type in addition to using it to just generate the type alias for the parsed form. It can generate a JSON encoder. And so instead of doing debug.log, I took that parsed form type. I know what the type is in the generated code, and I generate a JSON encoder for that. And I send it out through a log, which is not a debug log, but it's an actual back-end task log that you can ship in a production code base. So now, and this is all user configurable. So if your code base evolves and you want to use a different pattern, you don't want to JSON encode it, you don't want to log it, you want to do some specific thing to it, you can follow those patterns and change it because this scaffolding API I built allows you to customize that. But it gives you the building blocks to generate these things. And what I found was when I was trying to basically like speed run this demo, I was more set up for success because actually it was like, oh, actually, I do want to use a JSON encoder. But instead of sending the JSON encoder, and then encoding that to a string, and then logging that, I want to send it through a custom back-end task or whatever. So I was trying to sort of like use these same idioms in a way that would be like meaningful and help me guide me in the direction my production code wants to go. I'm happy with it. I think it's also a nice pattern to like use types and create Elm CodeGen helpers to work with types like creating an Elm CodeGen helper to JSON encode a type. It is something that we can build. So there's some really cool possibilities. Like I think building higher level helpers to help generate things with Elm CodeGen is like a really exciting space. What should we tear this scaffolding down? We should. I did mention it before with GPT and all those AI tools. Maybe this whole conversation will end up being pretty useless. I don't know. We'll see. I mean, we certainly can guide people to do the right thing better than what we can teach such a tool to do, especially if we can't teach it's anything, as far as I know. But I mean, we'll see how those will evolve. It's a fascinating topic. My instincts on this. Now this may be, you know, me becoming an old curmudgeon or something. I don't know. But my instinct is that there's value to explicitness. There are worse things than magic. Yeah, there are worse things than magic. Now I think like having explicit tools for scaffolding code still has value even with AI assist tools. I'm not saying that AI assist tools aren't also helpful, but if you can create high level helpers to help you do a very specific thing in a very exact way, you don't have to think about did this actually give me what I want? Is it idiomatic? You don't have to second guess it. You don't have to double check it. You just use it like a high level thing. There's no context shifting. You think of it as a high level atomic thing. I'm adding a route with a form. Boom. So to me, it still serves a purpose. And then I think that there could be interesting opportunities for an interplay between these sort of scaffolding commands and AI to sort of work together. And I think that's another interesting space to explore. Yeah, absolutely. I for one welcome our new AI overlords. I honestly prefer my Elm Review overlords because I know what they can and what they can't do. And I know that they can't do much about how I live. And that's a good thing. I think that like pure functions and static typing, I imagine a world where that is a superpower for AI assists. I don't think we're at that world yet, but I think that world could come to pass. We'll have to see. Same here. But that might be a topic for another conversation. So Jeroen, until next time. Until next time.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.88, "text": " Hello Jeroen.", "tokens": [2425, 508, 2032, 268, 13], "temperature": 0.0, "avg_logprob": -0.3170585632324219, "compression_ratio": 1.56, "no_speech_prob": 0.12396036833524704}, {"id": 1, "seek": 0, "start": 2.88, "end": 3.88, "text": " Hello Dillon.", "tokens": [2425, 28160, 13], "temperature": 0.0, "avg_logprob": -0.3170585632324219, "compression_ratio": 1.56, "no_speech_prob": 0.12396036833524704}, {"id": 2, "seek": 0, "start": 3.88, "end": 6.72, "text": " You know what goes really well with scaffolding?", "tokens": [509, 458, 437, 1709, 534, 731, 365, 44094, 278, 30], "temperature": 0.0, "avg_logprob": -0.3170585632324219, "compression_ratio": 1.56, "no_speech_prob": 0.12396036833524704}, {"id": 3, "seek": 0, "start": 6.72, "end": 7.72, "text": " Workers?", "tokens": [42375, 30], "temperature": 0.0, "avg_logprob": -0.3170585632324219, "compression_ratio": 1.56, "no_speech_prob": 0.12396036833524704}, {"id": 4, "seek": 0, "start": 7.72, "end": 8.72, "text": " Builders.", "tokens": [11875, 433, 13], "temperature": 0.0, "avg_logprob": -0.3170585632324219, "compression_ratio": 1.56, "no_speech_prob": 0.12396036833524704}, {"id": 5, "seek": 0, "start": 8.72, "end": 9.72, "text": " Builders, yes.", "tokens": [11875, 433, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.3170585632324219, "compression_ratio": 1.56, "no_speech_prob": 0.12396036833524704}, {"id": 6, "seek": 0, "start": 9.72, "end": 14.84, "text": " And I think we're going to be talking about both of those things today.", "tokens": [400, 286, 519, 321, 434, 516, 281, 312, 1417, 466, 1293, 295, 729, 721, 965, 13], "temperature": 0.0, "avg_logprob": -0.3170585632324219, "compression_ratio": 1.56, "no_speech_prob": 0.12396036833524704}, {"id": 7, "seek": 0, "start": 14.84, "end": 15.84, "text": " Sounds good to me.", "tokens": [14576, 665, 281, 385, 13], "temperature": 0.0, "avg_logprob": -0.3170585632324219, "compression_ratio": 1.56, "no_speech_prob": 0.12396036833524704}, {"id": 8, "seek": 0, "start": 15.84, "end": 20.36, "text": " I feel like you're trying to make a pun but I don't get it.", "tokens": [286, 841, 411, 291, 434, 1382, 281, 652, 257, 4468, 457, 286, 500, 380, 483, 309, 13], "temperature": 0.0, "avg_logprob": -0.3170585632324219, "compression_ratio": 1.56, "no_speech_prob": 0.12396036833524704}, {"id": 9, "seek": 0, "start": 20.36, "end": 25.52, "text": " I feel like I have to at least make some sort of attempt at a bad joke to start things off", "tokens": [286, 841, 411, 286, 362, 281, 412, 1935, 652, 512, 1333, 295, 5217, 412, 257, 1578, 7647, 281, 722, 721, 766], "temperature": 0.0, "avg_logprob": -0.3170585632324219, "compression_ratio": 1.56, "no_speech_prob": 0.12396036833524704}, {"id": 10, "seek": 0, "start": 25.52, "end": 27.84, "text": " otherwise people will be disappointed.", "tokens": [5911, 561, 486, 312, 13856, 13], "temperature": 0.0, "avg_logprob": -0.3170585632324219, "compression_ratio": 1.56, "no_speech_prob": 0.12396036833524704}, {"id": 11, "seek": 2784, "start": 27.84, "end": 30.04, "text": " People will be disappointed either way I'm sure.", "tokens": [3432, 486, 312, 13856, 2139, 636, 286, 478, 988, 13], "temperature": 0.0, "avg_logprob": -0.32455658715618546, "compression_ratio": 1.6374501992031874, "no_speech_prob": 2.0142610082984902e-05}, {"id": 12, "seek": 2784, "start": 30.04, "end": 32.32, "text": " But you know, I have to do my best.", "tokens": [583, 291, 458, 11, 286, 362, 281, 360, 452, 1151, 13], "temperature": 0.0, "avg_logprob": -0.32455658715618546, "compression_ratio": 1.6374501992031874, "no_speech_prob": 2.0142610082984902e-05}, {"id": 13, "seek": 2784, "start": 32.32, "end": 38.88, "text": " Yeah, I mean the joke that I had in mind was let's try to build a good episode or something.", "tokens": [865, 11, 286, 914, 264, 7647, 300, 286, 632, 294, 1575, 390, 718, 311, 853, 281, 1322, 257, 665, 3500, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.32455658715618546, "compression_ratio": 1.6374501992031874, "no_speech_prob": 2.0142610082984902e-05}, {"id": 14, "seek": 2784, "start": 38.88, "end": 45.480000000000004, "text": " Let's try to scaffold a good episode but we'll just go with yours and we will not edit either", "tokens": [961, 311, 853, 281, 44094, 257, 665, 3500, 457, 321, 603, 445, 352, 365, 6342, 293, 321, 486, 406, 8129, 2139], "temperature": 0.0, "avg_logprob": -0.32455658715618546, "compression_ratio": 1.6374501992031874, "no_speech_prob": 2.0142610082984902e-05}, {"id": 15, "seek": 2784, "start": 45.480000000000004, "end": 46.480000000000004, "text": " of these out.", "tokens": [295, 613, 484, 13], "temperature": 0.0, "avg_logprob": -0.32455658715618546, "compression_ratio": 1.6374501992031874, "no_speech_prob": 2.0142610082984902e-05}, {"id": 16, "seek": 2784, "start": 46.480000000000004, "end": 49.879999999999995, "text": " Oh no, these bad puns go straight to tape.", "tokens": [876, 572, 11, 613, 1578, 4468, 82, 352, 2997, 281, 7314, 13], "temperature": 0.0, "avg_logprob": -0.32455658715618546, "compression_ratio": 1.6374501992031874, "no_speech_prob": 2.0142610082984902e-05}, {"id": 17, "seek": 2784, "start": 49.879999999999995, "end": 50.879999999999995, "text": " No second chances.", "tokens": [883, 1150, 10486, 13], "temperature": 0.0, "avg_logprob": -0.32455658715618546, "compression_ratio": 1.6374501992031874, "no_speech_prob": 2.0142610082984902e-05}, {"id": 18, "seek": 2784, "start": 50.879999999999995, "end": 51.879999999999995, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.32455658715618546, "compression_ratio": 1.6374501992031874, "no_speech_prob": 2.0142610082984902e-05}, {"id": 19, "seek": 2784, "start": 51.879999999999995, "end": 57.16, "text": " I mean we have removed so many good puns in our episodes.", "tokens": [286, 914, 321, 362, 7261, 370, 867, 665, 4468, 82, 294, 527, 9313, 13], "temperature": 0.0, "avg_logprob": -0.32455658715618546, "compression_ratio": 1.6374501992031874, "no_speech_prob": 2.0142610082984902e-05}, {"id": 20, "seek": 5716, "start": 57.16, "end": 60.839999999999996, "text": " People are going to think we only make bad puns.", "tokens": [3432, 366, 516, 281, 519, 321, 787, 652, 1578, 4468, 82, 13], "temperature": 0.0, "avg_logprob": -0.271655916093706, "compression_ratio": 1.679245283018868, "no_speech_prob": 8.013353181013372e-06}, {"id": 21, "seek": 5716, "start": 60.839999999999996, "end": 62.31999999999999, "text": " But we just edit those out.", "tokens": [583, 321, 445, 8129, 729, 484, 13], "temperature": 0.0, "avg_logprob": -0.271655916093706, "compression_ratio": 1.679245283018868, "no_speech_prob": 8.013353181013372e-06}, {"id": 22, "seek": 5716, "start": 62.31999999999999, "end": 63.599999999999994, "text": " There are no good puns.", "tokens": [821, 366, 572, 665, 4468, 82, 13], "temperature": 0.0, "avg_logprob": -0.271655916093706, "compression_ratio": 1.679245283018868, "no_speech_prob": 8.013353181013372e-06}, {"id": 23, "seek": 5716, "start": 63.599999999999994, "end": 65.47999999999999, "text": " The worse a pun is the better it is.", "tokens": [440, 5324, 257, 4468, 307, 264, 1101, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.271655916093706, "compression_ratio": 1.679245283018868, "no_speech_prob": 8.013353181013372e-06}, {"id": 24, "seek": 5716, "start": 65.47999999999999, "end": 67.08, "text": " That's the only way you have a true bad pun.", "tokens": [663, 311, 264, 787, 636, 291, 362, 257, 2074, 1578, 4468, 13], "temperature": 0.0, "avg_logprob": -0.271655916093706, "compression_ratio": 1.679245283018868, "no_speech_prob": 8.013353181013372e-06}, {"id": 25, "seek": 5716, "start": 67.08, "end": 69.47999999999999, "text": " A true good pun is a true bad pun.", "tokens": [316, 2074, 665, 4468, 307, 257, 2074, 1578, 4468, 13], "temperature": 0.0, "avg_logprob": -0.271655916093706, "compression_ratio": 1.679245283018868, "no_speech_prob": 8.013353181013372e-06}, {"id": 26, "seek": 5716, "start": 69.47999999999999, "end": 71.56, "text": " So scaffolding.", "tokens": [407, 44094, 278, 13], "temperature": 0.0, "avg_logprob": -0.271655916093706, "compression_ratio": 1.679245283018868, "no_speech_prob": 8.013353181013372e-06}, {"id": 27, "seek": 5716, "start": 71.56, "end": 75.52, "text": " So we've talked about code generation.", "tokens": [407, 321, 600, 2825, 466, 3089, 5125, 13], "temperature": 0.0, "avg_logprob": -0.271655916093706, "compression_ratio": 1.679245283018868, "no_speech_prob": 8.013353181013372e-06}, {"id": 28, "seek": 5716, "start": 75.52, "end": 81.56, "text": " We've talked about OMCODEgen which I think is a really lovely tool for scaffolding.", "tokens": [492, 600, 2825, 466, 220, 5251, 12322, 22296, 1766, 597, 286, 519, 307, 257, 534, 7496, 2290, 337, 44094, 278, 13], "temperature": 0.0, "avg_logprob": -0.271655916093706, "compression_ratio": 1.679245283018868, "no_speech_prob": 8.013353181013372e-06}, {"id": 29, "seek": 8156, "start": 81.56, "end": 88.0, "text": " So let's first of all, let's get a definition like what is the difference between code generation", "tokens": [407, 718, 311, 700, 295, 439, 11, 718, 311, 483, 257, 7123, 411, 437, 307, 264, 2649, 1296, 3089, 5125], "temperature": 0.0, "avg_logprob": -0.23372664200632196, "compression_ratio": 1.6919431279620853, "no_speech_prob": 1.4823311857981025e-06}, {"id": 30, "seek": 8156, "start": 88.0, "end": 89.48, "text": " and scaffolding?", "tokens": [293, 44094, 278, 30], "temperature": 0.0, "avg_logprob": -0.23372664200632196, "compression_ratio": 1.6919431279620853, "no_speech_prob": 1.4823311857981025e-06}, {"id": 31, "seek": 8156, "start": 89.48, "end": 92.60000000000001, "text": " So do you want to take a stab at it?", "tokens": [407, 360, 291, 528, 281, 747, 257, 16343, 412, 309, 30], "temperature": 0.0, "avg_logprob": -0.23372664200632196, "compression_ratio": 1.6919431279620853, "no_speech_prob": 1.4823311857981025e-06}, {"id": 32, "seek": 8156, "start": 92.60000000000001, "end": 93.60000000000001, "text": " Sure.", "tokens": [4894, 13], "temperature": 0.0, "avg_logprob": -0.23372664200632196, "compression_ratio": 1.6919431279620853, "no_speech_prob": 1.4823311857981025e-06}, {"id": 33, "seek": 8156, "start": 93.60000000000001, "end": 99.44, "text": " So I would probably say scaffolding at least for computer science, right?", "tokens": [407, 286, 576, 1391, 584, 44094, 278, 412, 1935, 337, 3820, 3497, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.23372664200632196, "compression_ratio": 1.6919431279620853, "no_speech_prob": 1.4823311857981025e-06}, {"id": 34, "seek": 8156, "start": 99.44, "end": 102.44, "text": " Scaffolding is generating code.", "tokens": [47082, 602, 2641, 278, 307, 17746, 3089, 13], "temperature": 0.0, "avg_logprob": -0.23372664200632196, "compression_ratio": 1.6919431279620853, "no_speech_prob": 1.4823311857981025e-06}, {"id": 35, "seek": 8156, "start": 102.44, "end": 108.62, "text": " So it is code generation but it is meant for things that are temporary or to start something.", "tokens": [407, 309, 307, 3089, 5125, 457, 309, 307, 4140, 337, 721, 300, 366, 13413, 420, 281, 722, 746, 13], "temperature": 0.0, "avg_logprob": -0.23372664200632196, "compression_ratio": 1.6919431279620853, "no_speech_prob": 1.4823311857981025e-06}, {"id": 36, "seek": 10862, "start": 108.62, "end": 116.80000000000001, "text": " So you generate code that humans are afterwards going to maintain and change to their needs.", "tokens": [407, 291, 8460, 3089, 300, 6255, 366, 10543, 516, 281, 6909, 293, 1319, 281, 641, 2203, 13], "temperature": 0.0, "avg_logprob": -0.25481568924104325, "compression_ratio": 1.6594827586206897, "no_speech_prob": 5.989238047732215e-07}, {"id": 37, "seek": 10862, "start": 116.80000000000001, "end": 121.36, "text": " Whereas if when we talk about more regular code generation like, oh we need to generate", "tokens": [13813, 498, 562, 321, 751, 466, 544, 3890, 3089, 5125, 411, 11, 1954, 321, 643, 281, 8460], "temperature": 0.0, "avg_logprob": -0.25481568924104325, "compression_ratio": 1.6594827586206897, "no_speech_prob": 5.989238047732215e-07}, {"id": 38, "seek": 10862, "start": 121.36, "end": 128.68, "text": " code based off this to do things like boilerplate linking, then that is not meant to be touched", "tokens": [3089, 2361, 766, 341, 281, 360, 721, 411, 39228, 37008, 25775, 11, 550, 300, 307, 406, 4140, 281, 312, 9828], "temperature": 0.0, "avg_logprob": -0.25481568924104325, "compression_ratio": 1.6594827586206897, "no_speech_prob": 5.989238047732215e-07}, {"id": 39, "seek": 10862, "start": 128.68, "end": 130.6, "text": " by a human.", "tokens": [538, 257, 1952, 13], "temperature": 0.0, "avg_logprob": -0.25481568924104325, "compression_ratio": 1.6594827586206897, "no_speech_prob": 5.989238047732215e-07}, {"id": 40, "seek": 10862, "start": 130.6, "end": 135.4, "text": " So scaffolding is more for, well, let's use this to start with and then we can change", "tokens": [407, 44094, 278, 307, 544, 337, 11, 731, 11, 718, 311, 764, 341, 281, 722, 365, 293, 550, 321, 393, 1319], "temperature": 0.0, "avg_logprob": -0.25481568924104325, "compression_ratio": 1.6594827586206897, "no_speech_prob": 5.989238047732215e-07}, {"id": 41, "seek": 10862, "start": 135.4, "end": 136.4, "text": " it.", "tokens": [309, 13], "temperature": 0.0, "avg_logprob": -0.25481568924104325, "compression_ratio": 1.6594827586206897, "no_speech_prob": 5.989238047732215e-07}, {"id": 42, "seek": 10862, "start": 136.4, "end": 137.4, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.25481568924104325, "compression_ratio": 1.6594827586206897, "no_speech_prob": 5.989238047732215e-07}, {"id": 43, "seek": 13740, "start": 137.4, "end": 142.0, "text": " So I would say that to me, code generation is a superset of scaffolding.", "tokens": [407, 286, 576, 584, 300, 281, 385, 11, 3089, 5125, 307, 257, 37906, 302, 295, 44094, 278, 13], "temperature": 0.0, "avg_logprob": -0.24496135005244501, "compression_ratio": 1.6442687747035574, "no_speech_prob": 8.990883770820801e-07}, {"id": 44, "seek": 13740, "start": 142.0, "end": 147.32, "text": " Often when we talk about code generation, as you say, we are, especially in the Elm", "tokens": [20043, 562, 321, 751, 466, 3089, 5125, 11, 382, 291, 584, 11, 321, 366, 11, 2318, 294, 264, 2699, 76], "temperature": 0.0, "avg_logprob": -0.24496135005244501, "compression_ratio": 1.6442687747035574, "no_speech_prob": 8.990883770820801e-07}, {"id": 45, "seek": 13740, "start": 147.32, "end": 153.24, "text": " community, we're often referring to generating code that is not user maintained code.", "tokens": [1768, 11, 321, 434, 2049, 13761, 281, 17746, 3089, 300, 307, 406, 4195, 17578, 3089, 13], "temperature": 0.0, "avg_logprob": -0.24496135005244501, "compression_ratio": 1.6442687747035574, "no_speech_prob": 8.990883770820801e-07}, {"id": 46, "seek": 13740, "start": 153.24, "end": 159.84, "text": " You know, GraphQL, like take the GraphQL schema, generate some decoders and encoders or generate", "tokens": [509, 458, 11, 21884, 13695, 11, 411, 747, 264, 21884, 13695, 34078, 11, 8460, 512, 979, 378, 433, 293, 2058, 378, 433, 420, 8460], "temperature": 0.0, "avg_logprob": -0.24496135005244501, "compression_ratio": 1.6442687747035574, "no_speech_prob": 8.990883770820801e-07}, {"id": 47, "seek": 13740, "start": 159.84, "end": 166.4, "text": " an API or Elm SPA generates the wiring for your SPA application or whatever.", "tokens": [364, 9362, 420, 2699, 76, 8420, 32, 23815, 264, 27520, 337, 428, 8420, 32, 3861, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.24496135005244501, "compression_ratio": 1.6442687747035574, "no_speech_prob": 8.990883770820801e-07}, {"id": 48, "seek": 16640, "start": 166.4, "end": 169.64000000000001, "text": " So those are forms of code generation.", "tokens": [407, 729, 366, 6422, 295, 3089, 5125, 13], "temperature": 0.0, "avg_logprob": -0.22969049973921343, "compression_ratio": 1.780392156862745, "no_speech_prob": 3.2377242860093247e-06}, {"id": 49, "seek": 16640, "start": 169.64000000000001, "end": 174.08, "text": " But as you said, it's not meant to be touched by a human after it's generated.", "tokens": [583, 382, 291, 848, 11, 309, 311, 406, 4140, 281, 312, 9828, 538, 257, 1952, 934, 309, 311, 10833, 13], "temperature": 0.0, "avg_logprob": -0.22969049973921343, "compression_ratio": 1.780392156862745, "no_speech_prob": 3.2377242860093247e-06}, {"id": 50, "seek": 16640, "start": 174.08, "end": 179.92000000000002, "text": " Whereas scaffolding, and I really like this sort of term and metaphor, you know, you think", "tokens": [13813, 44094, 278, 11, 293, 286, 534, 411, 341, 1333, 295, 1433, 293, 19157, 11, 291, 458, 11, 291, 519], "temperature": 0.0, "avg_logprob": -0.22969049973921343, "compression_ratio": 1.780392156862745, "no_speech_prob": 3.2377242860093247e-06}, {"id": 51, "seek": 16640, "start": 179.92000000000002, "end": 185.68, "text": " about the scaffolding around a building, it's like a temporary structure to help you create", "tokens": [466, 264, 44094, 278, 926, 257, 2390, 11, 309, 311, 411, 257, 13413, 3877, 281, 854, 291, 1884], "temperature": 0.0, "avg_logprob": -0.22969049973921343, "compression_ratio": 1.780392156862745, "no_speech_prob": 3.2377242860093247e-06}, {"id": 52, "seek": 16640, "start": 185.68, "end": 189.16, "text": " something that gets removed once that thing has been created.", "tokens": [746, 300, 2170, 7261, 1564, 300, 551, 575, 668, 2942, 13], "temperature": 0.0, "avg_logprob": -0.22969049973921343, "compression_ratio": 1.780392156862745, "no_speech_prob": 3.2377242860093247e-06}, {"id": 53, "seek": 16640, "start": 189.16, "end": 195.32, "text": " So you know, you scaffold something, you generate some code that a human can then maintain.", "tokens": [407, 291, 458, 11, 291, 44094, 746, 11, 291, 8460, 512, 3089, 300, 257, 1952, 393, 550, 6909, 13], "temperature": 0.0, "avg_logprob": -0.22969049973921343, "compression_ratio": 1.780392156862745, "no_speech_prob": 3.2377242860093247e-06}, {"id": 54, "seek": 19532, "start": 195.32, "end": 201.0, "text": " But once it's sort of built it up for you, you don't care about what was initially templated", "tokens": [583, 1564, 309, 311, 1333, 295, 3094, 309, 493, 337, 291, 11, 291, 500, 380, 1127, 466, 437, 390, 9105, 9100, 770], "temperature": 0.0, "avg_logprob": -0.22988699193586382, "compression_ratio": 1.640926640926641, "no_speech_prob": 1.7603373407837353e-06}, {"id": 55, "seek": 19532, "start": 201.0, "end": 202.0, "text": " out for you.", "tokens": [484, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.22988699193586382, "compression_ratio": 1.640926640926641, "no_speech_prob": 1.7603373407837353e-06}, {"id": 56, "seek": 19532, "start": 202.0, "end": 208.6, "text": " Yeah, the one thing that I would say is bad about this metaphor is that usually you end", "tokens": [865, 11, 264, 472, 551, 300, 286, 576, 584, 307, 1578, 466, 341, 19157, 307, 300, 2673, 291, 917], "temperature": 0.0, "avg_logprob": -0.22988699193586382, "compression_ratio": 1.640926640926641, "no_speech_prob": 1.7603373407837353e-06}, {"id": 57, "seek": 19532, "start": 208.6, "end": 212.28, "text": " up with a result that is pretty close to the scaffolding.", "tokens": [493, 365, 257, 1874, 300, 307, 1238, 1998, 281, 264, 44094, 278, 13], "temperature": 0.0, "avg_logprob": -0.22988699193586382, "compression_ratio": 1.640926640926641, "no_speech_prob": 1.7603373407837353e-06}, {"id": 58, "seek": 19532, "start": 212.28, "end": 217.88, "text": " So for instance, if we try to scaffold a, an Elm project, while we generate a main,", "tokens": [407, 337, 5197, 11, 498, 321, 853, 281, 44094, 257, 11, 364, 2699, 76, 1716, 11, 1339, 321, 8460, 257, 2135, 11], "temperature": 0.0, "avg_logprob": -0.22988699193586382, "compression_ratio": 1.640926640926641, "no_speech_prob": 1.7603373407837353e-06}, {"id": 59, "seek": 19532, "start": 217.88, "end": 224.68, "text": " we generate a init, update, view function, and that structure is still going to be there.", "tokens": [321, 8460, 257, 3157, 11, 5623, 11, 1910, 2445, 11, 293, 300, 3877, 307, 920, 516, 281, 312, 456, 13], "temperature": 0.0, "avg_logprob": -0.22988699193586382, "compression_ratio": 1.640926640926641, "no_speech_prob": 1.7603373407837353e-06}, {"id": 60, "seek": 22468, "start": 224.68, "end": 229.16, "text": " You will change the view function, you will change the update function and the init, which", "tokens": [509, 486, 1319, 264, 1910, 2445, 11, 291, 486, 1319, 264, 5623, 2445, 293, 264, 3157, 11, 597], "temperature": 0.0, "avg_logprob": -0.30124161460182886, "compression_ratio": 1.7429718875502007, "no_speech_prob": 5.507563855644548e-06}, {"id": 61, "seek": 22468, "start": 229.16, "end": 234.72, "text": " is like still most of the application, but the core parts of the structure will still", "tokens": [307, 411, 920, 881, 295, 264, 3861, 11, 457, 264, 4965, 3166, 295, 264, 3877, 486, 920], "temperature": 0.0, "avg_logprob": -0.30124161460182886, "compression_ratio": 1.7429718875502007, "no_speech_prob": 5.507563855644548e-06}, {"id": 62, "seek": 22468, "start": 234.72, "end": 235.72, "text": " be there.", "tokens": [312, 456, 13], "temperature": 0.0, "avg_logprob": -0.30124161460182886, "compression_ratio": 1.7429718875502007, "no_speech_prob": 5.507563855644548e-06}, {"id": 63, "seek": 22468, "start": 235.72, "end": 241.0, "text": " Whereas we'll scaffolding, well, yeah, pretty much everything's going, is going away.", "tokens": [13813, 321, 603, 44094, 278, 11, 731, 11, 1338, 11, 1238, 709, 1203, 311, 516, 11, 307, 516, 1314, 13], "temperature": 0.0, "avg_logprob": -0.30124161460182886, "compression_ratio": 1.7429718875502007, "no_speech_prob": 5.507563855644548e-06}, {"id": 64, "seek": 22468, "start": 241.0, "end": 242.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.30124161460182886, "compression_ratio": 1.7429718875502007, "no_speech_prob": 5.507563855644548e-06}, {"id": 65, "seek": 22468, "start": 242.0, "end": 247.92000000000002, "text": " It's almost like, often it's like a pre assembled unit that you're probably not going to change", "tokens": [467, 311, 1920, 411, 11, 2049, 309, 311, 411, 257, 659, 24204, 4985, 300, 291, 434, 1391, 406, 516, 281, 1319], "temperature": 0.0, "avg_logprob": -0.30124161460182886, "compression_ratio": 1.7429718875502007, "no_speech_prob": 5.507563855644548e-06}, {"id": 66, "seek": 22468, "start": 247.92000000000002, "end": 251.92000000000002, "text": " the sort of exterior pieces you're going to fit within it.", "tokens": [264, 1333, 295, 20677, 3755, 291, 434, 516, 281, 3318, 1951, 309, 13], "temperature": 0.0, "avg_logprob": -0.30124161460182886, "compression_ratio": 1.7429718875502007, "no_speech_prob": 5.507563855644548e-06}, {"id": 67, "seek": 25192, "start": 251.92, "end": 255.39999999999998, "text": " At least in our use cases, that's pretty common.", "tokens": [1711, 1935, 294, 527, 764, 3331, 11, 300, 311, 1238, 2689, 13], "temperature": 0.0, "avg_logprob": -0.24135110689246136, "compression_ratio": 1.5, "no_speech_prob": 3.393068709556246e-06}, {"id": 68, "seek": 25192, "start": 255.39999999999998, "end": 264.0, "text": " So I think like, so with Elm Pages v3, I've been really trying to, you know, you've talked", "tokens": [407, 286, 519, 411, 11, 370, 365, 2699, 76, 430, 1660, 371, 18, 11, 286, 600, 668, 534, 1382, 281, 11, 291, 458, 11, 291, 600, 2825], "temperature": 0.0, "avg_logprob": -0.24135110689246136, "compression_ratio": 1.5, "no_speech_prob": 3.393068709556246e-06}, {"id": 69, "seek": 25192, "start": 264.0, "end": 269.8, "text": " about this idea a lot that I think you credit Richard Feldman for, of take responsibility", "tokens": [466, 341, 1558, 257, 688, 300, 286, 519, 291, 5397, 9809, 42677, 1601, 337, 11, 295, 747, 6357], "temperature": 0.0, "avg_logprob": -0.24135110689246136, "compression_ratio": 1.5, "no_speech_prob": 3.393068709556246e-06}, {"id": 70, "seek": 25192, "start": 269.8, "end": 271.36, "text": " for user experiences.", "tokens": [337, 4195, 5235, 13], "temperature": 0.0, "avg_logprob": -0.24135110689246136, "compression_ratio": 1.5, "no_speech_prob": 3.393068709556246e-06}, {"id": 71, "seek": 25192, "start": 271.36, "end": 277.52, "text": " I really like this idea of like, looking at what is the user's workflow and their whole", "tokens": [286, 534, 411, 341, 1558, 295, 411, 11, 1237, 412, 437, 307, 264, 4195, 311, 20993, 293, 641, 1379], "temperature": 0.0, "avg_logprob": -0.24135110689246136, "compression_ratio": 1.5, "no_speech_prob": 3.393068709556246e-06}, {"id": 72, "seek": 27752, "start": 277.52, "end": 282.24, "text": " experience in building something with your tool or package.", "tokens": [1752, 294, 2390, 746, 365, 428, 2290, 420, 7372, 13], "temperature": 0.0, "avg_logprob": -0.22225262437547957, "compression_ratio": 1.7103174603174602, "no_speech_prob": 2.2959013676882023e-06}, {"id": 73, "seek": 27752, "start": 282.24, "end": 286.76, "text": " And with Elm Pages v3, I've been thinking about like, what is that end to end experience", "tokens": [400, 365, 2699, 76, 430, 1660, 371, 18, 11, 286, 600, 668, 1953, 466, 411, 11, 437, 307, 300, 917, 281, 917, 1752], "temperature": 0.0, "avg_logprob": -0.22225262437547957, "compression_ratio": 1.7103174603174602, "no_speech_prob": 2.2959013676882023e-06}, {"id": 74, "seek": 27752, "start": 286.76, "end": 293.71999999999997, "text": " if you're trying to add a new route, if you're trying to wire in a form, right?", "tokens": [498, 291, 434, 1382, 281, 909, 257, 777, 7955, 11, 498, 291, 434, 1382, 281, 6234, 294, 257, 1254, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.22225262437547957, "compression_ratio": 1.7103174603174602, "no_speech_prob": 2.2959013676882023e-06}, {"id": 75, "seek": 27752, "start": 293.71999999999997, "end": 297.03999999999996, "text": " And you know, I've been thinking about the form API a lot.", "tokens": [400, 291, 458, 11, 286, 600, 668, 1953, 466, 264, 1254, 9362, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.22225262437547957, "compression_ratio": 1.7103174603174602, "no_speech_prob": 2.2959013676882023e-06}, {"id": 76, "seek": 27752, "start": 297.03999999999996, "end": 301.91999999999996, "text": " We did an episode talking about some of those ideas of all these API design techniques you", "tokens": [492, 630, 364, 3500, 1417, 466, 512, 295, 729, 3487, 295, 439, 613, 9362, 1715, 7512, 291], "temperature": 0.0, "avg_logprob": -0.22225262437547957, "compression_ratio": 1.7103174603174602, "no_speech_prob": 2.2959013676882023e-06}, {"id": 77, "seek": 27752, "start": 301.91999999999996, "end": 305.35999999999996, "text": " can use to make that easier phantom builder pattern.", "tokens": [393, 764, 281, 652, 300, 3571, 903, 25796, 27377, 5102, 13], "temperature": 0.0, "avg_logprob": -0.22225262437547957, "compression_ratio": 1.7103174603174602, "no_speech_prob": 2.2959013676882023e-06}, {"id": 78, "seek": 30536, "start": 305.36, "end": 310.64, "text": " I have some opinions about ways to reduce the amount of wiring you have to do and leveraging", "tokens": [286, 362, 512, 11819, 466, 2098, 281, 5407, 264, 2372, 295, 27520, 291, 362, 281, 360, 293, 32666], "temperature": 0.0, "avg_logprob": -0.24332321667280354, "compression_ratio": 1.7439446366782008, "no_speech_prob": 1.2482632882893085e-06}, {"id": 79, "seek": 30536, "start": 310.64, "end": 314.12, "text": " web standards to not have to do extra work.", "tokens": [3670, 7787, 281, 406, 362, 281, 360, 2857, 589, 13], "temperature": 0.0, "avg_logprob": -0.24332321667280354, "compression_ratio": 1.7439446366782008, "no_speech_prob": 1.2482632882893085e-06}, {"id": 80, "seek": 30536, "start": 314.12, "end": 316.64, "text": " So the framework can manage these things for you and all these things.", "tokens": [407, 264, 8388, 393, 3067, 613, 721, 337, 291, 293, 439, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.24332321667280354, "compression_ratio": 1.7439446366782008, "no_speech_prob": 1.2482632882893085e-06}, {"id": 81, "seek": 30536, "start": 316.64, "end": 321.2, "text": " For those who haven't listened to those episodes, you only have like six or eight episodes to", "tokens": [1171, 729, 567, 2378, 380, 13207, 281, 729, 9313, 11, 291, 787, 362, 411, 2309, 420, 3180, 9313, 281], "temperature": 0.0, "avg_logprob": -0.24332321667280354, "compression_ratio": 1.7439446366782008, "no_speech_prob": 1.2482632882893085e-06}, {"id": 82, "seek": 30536, "start": 321.2, "end": 322.2, "text": " listen to.", "tokens": [2140, 281, 13], "temperature": 0.0, "avg_logprob": -0.24332321667280354, "compression_ratio": 1.7439446366782008, "no_speech_prob": 1.2482632882893085e-06}, {"id": 83, "seek": 30536, "start": 322.2, "end": 324.72, "text": " Go ahead and come back to this episode afterwards.", "tokens": [1037, 2286, 293, 808, 646, 281, 341, 3500, 10543, 13], "temperature": 0.0, "avg_logprob": -0.24332321667280354, "compression_ratio": 1.7439446366782008, "no_speech_prob": 1.2482632882893085e-06}, {"id": 84, "seek": 30536, "start": 324.72, "end": 325.72, "text": " That's right.", "tokens": [663, 311, 558, 13], "temperature": 0.0, "avg_logprob": -0.24332321667280354, "compression_ratio": 1.7439446366782008, "no_speech_prob": 1.2482632882893085e-06}, {"id": 85, "seek": 30536, "start": 325.72, "end": 327.96000000000004, "text": " Pause now and go listen back.", "tokens": [31973, 586, 293, 352, 2140, 646, 13], "temperature": 0.0, "avg_logprob": -0.24332321667280354, "compression_ratio": 1.7439446366782008, "no_speech_prob": 1.2482632882893085e-06}, {"id": 86, "seek": 30536, "start": 327.96000000000004, "end": 335.32, "text": " So that's one dimension of taking responsibility for user experiences, making that flow simpler.", "tokens": [407, 300, 311, 472, 10139, 295, 1940, 6357, 337, 4195, 5235, 11, 1455, 300, 3095, 18587, 13], "temperature": 0.0, "avg_logprob": -0.24332321667280354, "compression_ratio": 1.7439446366782008, "no_speech_prob": 1.2482632882893085e-06}, {"id": 87, "seek": 33532, "start": 335.32, "end": 339.15999999999997, "text": " But then how do you create a new form?", "tokens": [583, 550, 577, 360, 291, 1884, 257, 777, 1254, 30], "temperature": 0.0, "avg_logprob": -0.25215008794044963, "compression_ratio": 1.6066350710900474, "no_speech_prob": 3.966914846387226e-06}, {"id": 88, "seek": 33532, "start": 339.15999999999997, "end": 340.88, "text": " How do you create a new route with a form?", "tokens": [1012, 360, 291, 1884, 257, 777, 7955, 365, 257, 1254, 30], "temperature": 0.0, "avg_logprob": -0.25215008794044963, "compression_ratio": 1.6066350710900474, "no_speech_prob": 3.966914846387226e-06}, {"id": 89, "seek": 33532, "start": 340.88, "end": 342.96, "text": " So I've been really thinking about that.", "tokens": [407, 286, 600, 668, 534, 1953, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.25215008794044963, "compression_ratio": 1.6066350710900474, "no_speech_prob": 3.966914846387226e-06}, {"id": 90, "seek": 33532, "start": 342.96, "end": 346.24, "text": " And I think scaffolding is the answer.", "tokens": [400, 286, 519, 44094, 278, 307, 264, 1867, 13], "temperature": 0.0, "avg_logprob": -0.25215008794044963, "compression_ratio": 1.6066350710900474, "no_speech_prob": 3.966914846387226e-06}, {"id": 91, "seek": 33532, "start": 346.24, "end": 352.8, "text": " And like Elm SPA, Ryan did a great job kind of creating some templating helpers that you", "tokens": [400, 411, 2699, 76, 8420, 32, 11, 9116, 630, 257, 869, 1691, 733, 295, 4084, 512, 9100, 990, 854, 433, 300, 291], "temperature": 0.0, "avg_logprob": -0.25215008794044963, "compression_ratio": 1.6066350710900474, "no_speech_prob": 3.966914846387226e-06}, {"id": 92, "seek": 33532, "start": 352.8, "end": 358.76, "text": " can customize the sort of these these add commands to add new types of pages in Elm", "tokens": [393, 19734, 264, 1333, 295, 613, 613, 909, 16901, 281, 909, 777, 3467, 295, 7183, 294, 2699, 76], "temperature": 0.0, "avg_logprob": -0.25215008794044963, "compression_ratio": 1.6066350710900474, "no_speech_prob": 3.966914846387226e-06}, {"id": 93, "seek": 33532, "start": 358.76, "end": 359.76, "text": " SPA.", "tokens": [8420, 32, 13], "temperature": 0.0, "avg_logprob": -0.25215008794044963, "compression_ratio": 1.6066350710900474, "no_speech_prob": 3.966914846387226e-06}, {"id": 94, "seek": 35976, "start": 359.76, "end": 368.15999999999997, "text": " I've been very inspired by Rails and I've gone back and been watching DHH's sort of", "tokens": [286, 600, 668, 588, 7547, 538, 48526, 293, 286, 600, 2780, 646, 293, 668, 1976, 413, 7499, 311, 1333, 295], "temperature": 0.0, "avg_logprob": -0.2740316623594703, "compression_ratio": 1.5022831050228311, "no_speech_prob": 9.721280775920604e-07}, {"id": 95, "seek": 35976, "start": 368.15999999999997, "end": 374.52, "text": " early days, 17 years ago, demo of building a blog engine in 15 minutes.", "tokens": [2440, 1708, 11, 3282, 924, 2057, 11, 10723, 295, 2390, 257, 6968, 2848, 294, 2119, 2077, 13], "temperature": 0.0, "avg_logprob": -0.2740316623594703, "compression_ratio": 1.5022831050228311, "no_speech_prob": 9.721280775920604e-07}, {"id": 96, "seek": 35976, "start": 374.52, "end": 379.82, "text": " And he actually really built it in more like three or four minutes if you watch the timestamps.", "tokens": [400, 415, 767, 534, 3094, 309, 294, 544, 411, 1045, 420, 1451, 2077, 498, 291, 1159, 264, 49108, 23150, 13], "temperature": 0.0, "avg_logprob": -0.2740316623594703, "compression_ratio": 1.5022831050228311, "no_speech_prob": 9.721280775920604e-07}, {"id": 97, "seek": 35976, "start": 379.82, "end": 386.44, "text": " And then he's like adding comment sections and customizing things after that.", "tokens": [400, 550, 415, 311, 411, 5127, 2871, 10863, 293, 2375, 3319, 721, 934, 300, 13], "temperature": 0.0, "avg_logprob": -0.2740316623594703, "compression_ratio": 1.5022831050228311, "no_speech_prob": 9.721280775920604e-07}, {"id": 98, "seek": 38644, "start": 386.44, "end": 392.18, "text": " So that was kind of a groundbreaking idea at the time, I think, in the server world", "tokens": [407, 300, 390, 733, 295, 257, 42491, 1558, 412, 264, 565, 11, 286, 519, 11, 294, 264, 7154, 1002], "temperature": 0.0, "avg_logprob": -0.2266782760620117, "compression_ratio": 1.7045454545454546, "no_speech_prob": 1.1189363249286544e-06}, {"id": 99, "seek": 38644, "start": 392.18, "end": 397.16, "text": " to be able to just like up and running with a server framework rather than like creating", "tokens": [281, 312, 1075, 281, 445, 411, 493, 293, 2614, 365, 257, 7154, 8388, 2831, 813, 411, 4084], "temperature": 0.0, "avg_logprob": -0.2266782760620117, "compression_ratio": 1.7045454545454546, "no_speech_prob": 1.1189363249286544e-06}, {"id": 100, "seek": 38644, "start": 397.16, "end": 402.36, "text": " a bajillion config files and installing all these dependencies and setting all these things", "tokens": [257, 23589, 11836, 6662, 7098, 293, 20762, 439, 613, 36606, 293, 3287, 439, 613, 721], "temperature": 0.0, "avg_logprob": -0.2266782760620117, "compression_ratio": 1.7045454545454546, "no_speech_prob": 1.1189363249286544e-06}, {"id": 101, "seek": 38644, "start": 402.36, "end": 403.36, "text": " up.", "tokens": [493, 13], "temperature": 0.0, "avg_logprob": -0.2266782760620117, "compression_ratio": 1.7045454545454546, "no_speech_prob": 1.1189363249286544e-06}, {"id": 102, "seek": 38644, "start": 403.36, "end": 409.32, "text": " You just like create a database, add some fields and run a scaffolding command and then", "tokens": [509, 445, 411, 1884, 257, 8149, 11, 909, 512, 7909, 293, 1190, 257, 44094, 278, 5622, 293, 550], "temperature": 0.0, "avg_logprob": -0.2266782760620117, "compression_ratio": 1.7045454545454546, "no_speech_prob": 1.1189363249286544e-06}, {"id": 103, "seek": 38644, "start": 409.32, "end": 411.04, "text": " you have an app.", "tokens": [291, 362, 364, 724, 13], "temperature": 0.0, "avg_logprob": -0.2266782760620117, "compression_ratio": 1.7045454545454546, "no_speech_prob": 1.1189363249286544e-06}, {"id": 104, "seek": 38644, "start": 411.04, "end": 413.08, "text": " And then you customize the views from there.", "tokens": [400, 550, 291, 19734, 264, 6809, 490, 456, 13], "temperature": 0.0, "avg_logprob": -0.2266782760620117, "compression_ratio": 1.7045454545454546, "no_speech_prob": 1.1189363249286544e-06}, {"id": 105, "seek": 38644, "start": 413.08, "end": 414.56, "text": " I thought that was really cool.", "tokens": [286, 1194, 300, 390, 534, 1627, 13], "temperature": 0.0, "avg_logprob": -0.2266782760620117, "compression_ratio": 1.7045454545454546, "no_speech_prob": 1.1189363249286544e-06}, {"id": 106, "seek": 41456, "start": 414.56, "end": 420.76, "text": " And I think in some ways we've lost touch with that ethos of making it really easy to", "tokens": [400, 286, 519, 294, 512, 2098, 321, 600, 2731, 2557, 365, 300, 6468, 329, 295, 1455, 309, 534, 1858, 281], "temperature": 0.0, "avg_logprob": -0.21200632826190127, "compression_ratio": 1.6844262295081966, "no_speech_prob": 2.156763002858497e-06}, {"id": 107, "seek": 41456, "start": 420.76, "end": 424.84, "text": " get up and running with something, but it's still just as relevant today.", "tokens": [483, 493, 293, 2614, 365, 746, 11, 457, 309, 311, 920, 445, 382, 7340, 965, 13], "temperature": 0.0, "avg_logprob": -0.21200632826190127, "compression_ratio": 1.6844262295081966, "no_speech_prob": 2.156763002858497e-06}, {"id": 108, "seek": 41456, "start": 424.84, "end": 428.4, "text": " So I want to make scaffolding a thing again.", "tokens": [407, 286, 528, 281, 652, 44094, 278, 257, 551, 797, 13], "temperature": 0.0, "avg_logprob": -0.21200632826190127, "compression_ratio": 1.6844262295081966, "no_speech_prob": 2.156763002858497e-06}, {"id": 109, "seek": 41456, "start": 428.4, "end": 433.88, "text": " And I think in the Elm community in particular, because we have to be so explicit with things,", "tokens": [400, 286, 519, 294, 264, 2699, 76, 1768, 294, 1729, 11, 570, 321, 362, 281, 312, 370, 13691, 365, 721, 11], "temperature": 0.0, "avg_logprob": -0.21200632826190127, "compression_ratio": 1.6844262295081966, "no_speech_prob": 2.156763002858497e-06}, {"id": 110, "seek": 41456, "start": 433.88, "end": 439.24, "text": " scaffolding is a really great opportunity because we like being explicit in Elm and", "tokens": [44094, 278, 307, 257, 534, 869, 2650, 570, 321, 411, 885, 13691, 294, 2699, 76, 293], "temperature": 0.0, "avg_logprob": -0.21200632826190127, "compression_ratio": 1.6844262295081966, "no_speech_prob": 2.156763002858497e-06}, {"id": 111, "seek": 41456, "start": 439.24, "end": 441.04, "text": " we don't like magic in Elm.", "tokens": [321, 500, 380, 411, 5585, 294, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.21200632826190127, "compression_ratio": 1.6844262295081966, "no_speech_prob": 2.156763002858497e-06}, {"id": 112, "seek": 44104, "start": 441.04, "end": 445.52000000000004, "text": " And in fact, there's not that much magic you can actually do in Elm.", "tokens": [400, 294, 1186, 11, 456, 311, 406, 300, 709, 5585, 291, 393, 767, 360, 294, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.20210836839306262, "compression_ratio": 1.7314487632508835, "no_speech_prob": 2.0580096133926418e-06}, {"id": 113, "seek": 44104, "start": 445.52000000000004, "end": 448.36, "text": " So scaffolding is sort of the best of both worlds.", "tokens": [407, 44094, 278, 307, 1333, 295, 264, 1151, 295, 1293, 13401, 13], "temperature": 0.0, "avg_logprob": -0.20210836839306262, "compression_ratio": 1.7314487632508835, "no_speech_prob": 2.0580096133926418e-06}, {"id": 114, "seek": 44104, "start": 448.36, "end": 455.0, "text": " Like you don't have to handwrite all of this boilerplate, but you can sort of get something", "tokens": [1743, 291, 500, 380, 362, 281, 1011, 21561, 439, 295, 341, 39228, 37008, 11, 457, 291, 393, 1333, 295, 483, 746], "temperature": 0.0, "avg_logprob": -0.20210836839306262, "compression_ratio": 1.7314487632508835, "no_speech_prob": 2.0580096133926418e-06}, {"id": 115, "seek": 44104, "start": 455.0, "end": 456.0, "text": " up and running.", "tokens": [493, 293, 2614, 13], "temperature": 0.0, "avg_logprob": -0.20210836839306262, "compression_ratio": 1.7314487632508835, "no_speech_prob": 2.0580096133926418e-06}, {"id": 116, "seek": 44104, "start": 456.0, "end": 460.32000000000005, "text": " Now we still want to reduce the amount of boilerplate you need in the first place, but", "tokens": [823, 321, 920, 528, 281, 5407, 264, 2372, 295, 39228, 37008, 291, 643, 294, 264, 700, 1081, 11, 457], "temperature": 0.0, "avg_logprob": -0.20210836839306262, "compression_ratio": 1.7314487632508835, "no_speech_prob": 2.0580096133926418e-06}, {"id": 117, "seek": 44104, "start": 460.32000000000005, "end": 461.96000000000004, "text": " it can still help you right then.", "tokens": [309, 393, 920, 854, 291, 558, 550, 13], "temperature": 0.0, "avg_logprob": -0.20210836839306262, "compression_ratio": 1.7314487632508835, "no_speech_prob": 2.0580096133926418e-06}, {"id": 118, "seek": 44104, "start": 461.96000000000004, "end": 466.84000000000003, "text": " So clarify what you mean with scaffolding in this instance, because I'm familiar with", "tokens": [407, 17594, 437, 291, 914, 365, 44094, 278, 294, 341, 5197, 11, 570, 286, 478, 4963, 365], "temperature": 0.0, "avg_logprob": -0.20210836839306262, "compression_ratio": 1.7314487632508835, "no_speech_prob": 2.0580096133926418e-06}, {"id": 119, "seek": 44104, "start": 466.84000000000003, "end": 470.52000000000004, "text": " the concept of scaffolding a new project, for instance.", "tokens": [264, 3410, 295, 44094, 278, 257, 777, 1716, 11, 337, 5197, 13], "temperature": 0.0, "avg_logprob": -0.20210836839306262, "compression_ratio": 1.7314487632508835, "no_speech_prob": 2.0580096133926418e-06}, {"id": 120, "seek": 47052, "start": 470.52, "end": 474.56, "text": " The scaffolding something else is a little bit more foreign to me.", "tokens": [440, 44094, 278, 746, 1646, 307, 257, 707, 857, 544, 5329, 281, 385, 13], "temperature": 0.0, "avg_logprob": -0.22057448900662935, "compression_ratio": 1.503787878787879, "no_speech_prob": 6.853952982055489e-06}, {"id": 121, "seek": 47052, "start": 474.56, "end": 478.68, "text": " I mean, I know what you have in mind, but can you maybe explain it?", "tokens": [286, 914, 11, 286, 458, 437, 291, 362, 294, 1575, 11, 457, 393, 291, 1310, 2903, 309, 30], "temperature": 0.0, "avg_logprob": -0.22057448900662935, "compression_ratio": 1.503787878787879, "no_speech_prob": 6.853952982055489e-06}, {"id": 122, "seek": 47052, "start": 478.68, "end": 480.0, "text": " Yeah, absolutely.", "tokens": [865, 11, 3122, 13], "temperature": 0.0, "avg_logprob": -0.22057448900662935, "compression_ratio": 1.503787878787879, "no_speech_prob": 6.853952982055489e-06}, {"id": 123, "seek": 47052, "start": 480.0, "end": 486.15999999999997, "text": " So for example, I've been, I actually created a video walking through this, but I'm trying", "tokens": [407, 337, 1365, 11, 286, 600, 668, 11, 286, 767, 2942, 257, 960, 4494, 807, 341, 11, 457, 286, 478, 1382], "temperature": 0.0, "avg_logprob": -0.22057448900662935, "compression_ratio": 1.503787878787879, "no_speech_prob": 6.853952982055489e-06}, {"id": 124, "seek": 47052, "start": 486.15999999999997, "end": 492.88, "text": " to get it down to 15 minutes like that original Rails demo of creating the same sort of full", "tokens": [281, 483, 309, 760, 281, 2119, 2077, 411, 300, 3380, 48526, 10723, 295, 4084, 264, 912, 1333, 295, 1577], "temperature": 0.0, "avg_logprob": -0.22057448900662935, "compression_ratio": 1.503787878787879, "no_speech_prob": 6.853952982055489e-06}, {"id": 125, "seek": 47052, "start": 492.88, "end": 497.71999999999997, "text": " stack blog engine with database persistence in Elm Pages v3.", "tokens": [8630, 6968, 2848, 365, 8149, 37617, 294, 2699, 76, 430, 1660, 371, 18, 13], "temperature": 0.0, "avg_logprob": -0.22057448900662935, "compression_ratio": 1.503787878787879, "no_speech_prob": 6.853952982055489e-06}, {"id": 126, "seek": 49772, "start": 497.72, "end": 501.84000000000003, "text": " And so do you try to impersonate DHH?", "tokens": [400, 370, 360, 291, 853, 281, 38147, 473, 413, 7499, 30], "temperature": 0.0, "avg_logprob": -0.3282854826554008, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.337884539992956e-07}, {"id": 127, "seek": 49772, "start": 501.84000000000003, "end": 504.04, "text": " No, I don't.", "tokens": [883, 11, 286, 500, 380, 13], "temperature": 0.0, "avg_logprob": -0.3282854826554008, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.337884539992956e-07}, {"id": 128, "seek": 49772, "start": 504.04, "end": 506.56, "text": " Do the same accent, do the same.", "tokens": [1144, 264, 912, 11982, 11, 360, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.3282854826554008, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.337884539992956e-07}, {"id": 129, "seek": 49772, "start": 506.56, "end": 507.56, "text": " It's tempting.", "tokens": [467, 311, 37900, 13], "temperature": 0.0, "avg_logprob": -0.3282854826554008, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.337884539992956e-07}, {"id": 130, "seek": 49772, "start": 507.56, "end": 508.56, "text": " It is tempting.", "tokens": [467, 307, 37900, 13], "temperature": 0.0, "avg_logprob": -0.3282854826554008, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.337884539992956e-07}, {"id": 131, "seek": 49772, "start": 508.56, "end": 514.5600000000001, "text": " It's really funny how when he's doing the demo, he like, he runs a command and then", "tokens": [467, 311, 534, 4074, 577, 562, 415, 311, 884, 264, 10723, 11, 415, 411, 11, 415, 6676, 257, 5622, 293, 550], "temperature": 0.0, "avg_logprob": -0.3282854826554008, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.337884539992956e-07}, {"id": 132, "seek": 49772, "start": 514.5600000000001, "end": 517.72, "text": " like it works and then he goes, whoops, it worked.", "tokens": [411, 309, 1985, 293, 550, 415, 1709, 11, 567, 3370, 11, 309, 2732, 13], "temperature": 0.0, "avg_logprob": -0.3282854826554008, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.337884539992956e-07}, {"id": 133, "seek": 49772, "start": 517.72, "end": 520.8000000000001, "text": " He always says whoops whenever something works.", "tokens": [634, 1009, 1619, 567, 3370, 5699, 746, 1985, 13], "temperature": 0.0, "avg_logprob": -0.3282854826554008, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.337884539992956e-07}, {"id": 134, "seek": 49772, "start": 520.8000000000001, "end": 521.8000000000001, "text": " It's really funny.", "tokens": [467, 311, 534, 4074, 13], "temperature": 0.0, "avg_logprob": -0.3282854826554008, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.337884539992956e-07}, {"id": 135, "seek": 49772, "start": 521.8000000000001, "end": 524.5600000000001, "text": " So I'm definitely tempted to do that too.", "tokens": [407, 286, 478, 2138, 29941, 281, 360, 300, 886, 13], "temperature": 0.0, "avg_logprob": -0.3282854826554008, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.337884539992956e-07}, {"id": 136, "seek": 52456, "start": 524.56, "end": 533.76, "text": " So like, for example, like creating a new, you know, the route for creating a new blog", "tokens": [407, 411, 11, 337, 1365, 11, 411, 4084, 257, 777, 11, 291, 458, 11, 264, 7955, 337, 4084, 257, 777, 6968], "temperature": 0.0, "avg_logprob": -0.2585864123176126, "compression_ratio": 1.5751295336787565, "no_speech_prob": 2.203274505063746e-07}, {"id": 137, "seek": 52456, "start": 533.76, "end": 538.8399999999999, "text": " post entry that has like the slug and title and body.", "tokens": [2183, 8729, 300, 575, 411, 264, 1061, 697, 293, 4876, 293, 1772, 13], "temperature": 0.0, "avg_logprob": -0.2585864123176126, "compression_ratio": 1.5751295336787565, "no_speech_prob": 2.203274505063746e-07}, {"id": 138, "seek": 52456, "start": 538.8399999999999, "end": 544.3199999999999, "text": " I've created this sort of helper for running like Elm Pages run, which we talked about", "tokens": [286, 600, 2942, 341, 1333, 295, 36133, 337, 2614, 411, 2699, 76, 430, 1660, 1190, 11, 597, 321, 2825, 466], "temperature": 0.0, "avg_logprob": -0.2585864123176126, "compression_ratio": 1.5751295336787565, "no_speech_prob": 2.203274505063746e-07}, {"id": 139, "seek": 52456, "start": 544.3199999999999, "end": 548.5999999999999, "text": " Elm Pages scripts, refer back to that episode.", "tokens": [2699, 76, 430, 1660, 23294, 11, 2864, 646, 281, 300, 3500, 13], "temperature": 0.0, "avg_logprob": -0.2585864123176126, "compression_ratio": 1.5751295336787565, "no_speech_prob": 2.203274505063746e-07}, {"id": 140, "seek": 52456, "start": 548.5999999999999, "end": 550.88, "text": " So you can run these scripts.", "tokens": [407, 291, 393, 1190, 613, 23294, 13], "temperature": 0.0, "avg_logprob": -0.2585864123176126, "compression_ratio": 1.5751295336787565, "no_speech_prob": 2.203274505063746e-07}, {"id": 141, "seek": 55088, "start": 550.88, "end": 556.4, "text": " I created an API for helping you to sort of scaffold things using Elm Code Gen.", "tokens": [286, 2942, 364, 9362, 337, 4315, 291, 281, 1333, 295, 44094, 721, 1228, 2699, 76, 15549, 3632, 13], "temperature": 0.0, "avg_logprob": -0.25289343021534105, "compression_ratio": 1.65625, "no_speech_prob": 6.577816975550377e-07}, {"id": 142, "seek": 55088, "start": 556.4, "end": 564.24, "text": " So you do Elm Pages run, add route, and then you give it the name of, you know, the new", "tokens": [407, 291, 360, 2699, 76, 430, 1660, 1190, 11, 909, 7955, 11, 293, 550, 291, 976, 309, 264, 1315, 295, 11, 291, 458, 11, 264, 777], "temperature": 0.0, "avg_logprob": -0.25289343021534105, "compression_ratio": 1.65625, "no_speech_prob": 6.577816975550377e-07}, {"id": 143, "seek": 55088, "start": 564.24, "end": 566.84, "text": " blog post page or whatever.", "tokens": [6968, 2183, 3028, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.25289343021534105, "compression_ratio": 1.65625, "no_speech_prob": 6.577816975550377e-07}, {"id": 144, "seek": 55088, "start": 566.84, "end": 573.0, "text": " And then you can give it a list of form fields, just like a Rails generator.", "tokens": [400, 550, 291, 393, 976, 309, 257, 1329, 295, 1254, 7909, 11, 445, 411, 257, 48526, 19265, 13], "temperature": 0.0, "avg_logprob": -0.25289343021534105, "compression_ratio": 1.65625, "no_speech_prob": 6.577816975550377e-07}, {"id": 145, "seek": 55088, "start": 573.0, "end": 577.76, "text": " You can give it the like, you can give it title, colon, string.", "tokens": [509, 393, 976, 309, 264, 411, 11, 291, 393, 976, 309, 4876, 11, 8255, 11, 6798, 13], "temperature": 0.0, "avg_logprob": -0.25289343021534105, "compression_ratio": 1.65625, "no_speech_prob": 6.577816975550377e-07}, {"id": 146, "seek": 55088, "start": 577.76, "end": 578.92, "text": " You can do the same type of thing.", "tokens": [509, 393, 360, 264, 912, 2010, 295, 551, 13], "temperature": 0.0, "avg_logprob": -0.25289343021534105, "compression_ratio": 1.65625, "no_speech_prob": 6.577816975550377e-07}, {"id": 147, "seek": 57892, "start": 578.92, "end": 583.5999999999999, "text": " You can say, you know, you can give like a checkbox field, you can do colon to give the", "tokens": [509, 393, 584, 11, 291, 458, 11, 291, 393, 976, 411, 257, 1520, 4995, 2519, 11, 291, 393, 360, 8255, 281, 976, 264], "temperature": 0.0, "avg_logprob": -0.23545308473731288, "compression_ratio": 1.7764227642276422, "no_speech_prob": 3.7479679804164334e-07}, {"id": 148, "seek": 57892, "start": 583.5999999999999, "end": 585.24, "text": " types to these different form fields.", "tokens": [3467, 281, 613, 819, 1254, 7909, 13], "temperature": 0.0, "avg_logprob": -0.23545308473731288, "compression_ratio": 1.7764227642276422, "no_speech_prob": 3.7479679804164334e-07}, {"id": 149, "seek": 57892, "start": 585.24, "end": 589.5999999999999, "text": " But so you can list out these different fields and it generates a route.", "tokens": [583, 370, 291, 393, 1329, 484, 613, 819, 7909, 293, 309, 23815, 257, 7955, 13], "temperature": 0.0, "avg_logprob": -0.23545308473731288, "compression_ratio": 1.7764227642276422, "no_speech_prob": 3.7479679804164334e-07}, {"id": 150, "seek": 57892, "start": 589.5999999999999, "end": 595.4399999999999, "text": " It has init and update and view and all of these things, which is like, you know, it's", "tokens": [467, 575, 3157, 293, 5623, 293, 1910, 293, 439, 295, 613, 721, 11, 597, 307, 411, 11, 291, 458, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.23545308473731288, "compression_ratio": 1.7764227642276422, "no_speech_prob": 3.7479679804164334e-07}, {"id": 151, "seek": 57892, "start": 595.4399999999999, "end": 598.7199999999999, "text": " a lot to write out a fresh page.", "tokens": [257, 688, 281, 2464, 484, 257, 4451, 3028, 13], "temperature": 0.0, "avg_logprob": -0.23545308473731288, "compression_ratio": 1.7764227642276422, "no_speech_prob": 3.7479679804164334e-07}, {"id": 152, "seek": 57892, "start": 598.7199999999999, "end": 603.4, "text": " And then it generates the form using the Elm Pages form API.", "tokens": [400, 550, 309, 23815, 264, 1254, 1228, 264, 2699, 76, 430, 1660, 1254, 9362, 13], "temperature": 0.0, "avg_logprob": -0.23545308473731288, "compression_ratio": 1.7764227642276422, "no_speech_prob": 3.7479679804164334e-07}, {"id": 153, "seek": 57892, "start": 603.4, "end": 606.5999999999999, "text": " And it wires up the rendering of the form and everything.", "tokens": [400, 309, 15537, 493, 264, 22407, 295, 264, 1254, 293, 1203, 13], "temperature": 0.0, "avg_logprob": -0.23545308473731288, "compression_ratio": 1.7764227642276422, "no_speech_prob": 3.7479679804164334e-07}, {"id": 154, "seek": 60660, "start": 606.6, "end": 612.24, "text": " Now, again, I've gone to great lengths to try to make the wiring very minimal for the", "tokens": [823, 11, 797, 11, 286, 600, 2780, 281, 869, 26329, 281, 853, 281, 652, 264, 27520, 588, 13206, 337, 264], "temperature": 0.0, "avg_logprob": -0.20258534540895556, "compression_ratio": 1.7490494296577948, "no_speech_prob": 9.72149905464903e-07}, {"id": 155, "seek": 60660, "start": 612.24, "end": 614.0, "text": " Elm Pages form API.", "tokens": [2699, 76, 430, 1660, 1254, 9362, 13], "temperature": 0.0, "avg_logprob": -0.20258534540895556, "compression_ratio": 1.7490494296577948, "no_speech_prob": 9.72149905464903e-07}, {"id": 156, "seek": 60660, "start": 614.0, "end": 618.8000000000001, "text": " But I think that that's like, I think we have to attack it from both sides.", "tokens": [583, 286, 519, 300, 300, 311, 411, 11, 286, 519, 321, 362, 281, 2690, 309, 490, 1293, 4881, 13], "temperature": 0.0, "avg_logprob": -0.20258534540895556, "compression_ratio": 1.7490494296577948, "no_speech_prob": 9.72149905464903e-07}, {"id": 157, "seek": 60660, "start": 618.8000000000001, "end": 623.96, "text": " We have to make the boilerplate minimal, but then we have to help you build that minimal", "tokens": [492, 362, 281, 652, 264, 39228, 37008, 13206, 11, 457, 550, 321, 362, 281, 854, 291, 1322, 300, 13206], "temperature": 0.0, "avg_logprob": -0.20258534540895556, "compression_ratio": 1.7490494296577948, "no_speech_prob": 9.72149905464903e-07}, {"id": 158, "seek": 60660, "start": 623.96, "end": 629.12, "text": " boilerplate to give you the full productivity experience to take responsibility for user", "tokens": [39228, 37008, 281, 976, 291, 264, 1577, 15604, 1752, 281, 747, 6357, 337, 4195], "temperature": 0.0, "avg_logprob": -0.20258534540895556, "compression_ratio": 1.7490494296577948, "no_speech_prob": 9.72149905464903e-07}, {"id": 159, "seek": 60660, "start": 629.12, "end": 630.12, "text": " experiences.", "tokens": [5235, 13], "temperature": 0.0, "avg_logprob": -0.20258534540895556, "compression_ratio": 1.7490494296577948, "no_speech_prob": 9.72149905464903e-07}, {"id": 160, "seek": 60660, "start": 630.12, "end": 632.72, "text": " I wanted to be able to have that DHH.", "tokens": [286, 1415, 281, 312, 1075, 281, 362, 300, 413, 7499, 13], "temperature": 0.0, "avg_logprob": -0.20258534540895556, "compression_ratio": 1.7490494296577948, "no_speech_prob": 9.72149905464903e-07}, {"id": 161, "seek": 60660, "start": 632.72, "end": 636.44, "text": " Like I want to do that DHH level of productivity.", "tokens": [1743, 286, 528, 281, 360, 300, 413, 7499, 1496, 295, 15604, 13], "temperature": 0.0, "avg_logprob": -0.20258534540895556, "compression_ratio": 1.7490494296577948, "no_speech_prob": 9.72149905464903e-07}, {"id": 162, "seek": 63644, "start": 636.44, "end": 644.84, "text": " Like I want people and, you know, Rails was sort of a groundbreaking approach to full", "tokens": [1743, 286, 528, 561, 293, 11, 291, 458, 11, 48526, 390, 1333, 295, 257, 42491, 3109, 281, 1577], "temperature": 0.0, "avg_logprob": -0.2096281837014591, "compression_ratio": 1.644859813084112, "no_speech_prob": 3.966910753661068e-06}, {"id": 163, "seek": 63644, "start": 644.84, "end": 647.48, "text": " stack when it was introduced.", "tokens": [8630, 562, 309, 390, 7268, 13], "temperature": 0.0, "avg_logprob": -0.2096281837014591, "compression_ratio": 1.644859813084112, "no_speech_prob": 3.966910753661068e-06}, {"id": 164, "seek": 63644, "start": 647.48, "end": 652.48, "text": " Now things are moving in this direction where full stack frameworks are often sort of more", "tokens": [823, 721, 366, 2684, 294, 341, 3513, 689, 1577, 8630, 29834, 366, 2049, 1333, 295, 544], "temperature": 0.0, "avg_logprob": -0.2096281837014591, "compression_ratio": 1.644859813084112, "no_speech_prob": 3.966910753661068e-06}, {"id": 165, "seek": 63644, "start": 652.48, "end": 653.48, "text": " tied to the front end.", "tokens": [9601, 281, 264, 1868, 917, 13], "temperature": 0.0, "avg_logprob": -0.2096281837014591, "compression_ratio": 1.644859813084112, "no_speech_prob": 3.966910753661068e-06}, {"id": 166, "seek": 63644, "start": 653.48, "end": 659.9200000000001, "text": " So you can render full stack things, pull in database data, and then hydrate that into", "tokens": [407, 291, 393, 15529, 1577, 8630, 721, 11, 2235, 294, 8149, 1412, 11, 293, 550, 5796, 4404, 300, 666], "temperature": 0.0, "avg_logprob": -0.2096281837014591, "compression_ratio": 1.644859813084112, "no_speech_prob": 3.966910753661068e-06}, {"id": 167, "seek": 63644, "start": 659.9200000000001, "end": 661.9200000000001, "text": " your preferred front end framework.", "tokens": [428, 16494, 1868, 917, 8388, 13], "temperature": 0.0, "avg_logprob": -0.2096281837014591, "compression_ratio": 1.644859813084112, "no_speech_prob": 3.966910753661068e-06}, {"id": 168, "seek": 66192, "start": 661.92, "end": 668.56, "text": " But we need to like get back to the roots of Rails productivity to make something that", "tokens": [583, 321, 643, 281, 411, 483, 646, 281, 264, 10669, 295, 48526, 15604, 281, 652, 746, 300], "temperature": 0.0, "avg_logprob": -0.26427924465125713, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.203530122344091e-07}, {"id": 169, "seek": 66192, "start": 668.56, "end": 671.56, "text": " people really love and can be very productive in.", "tokens": [561, 534, 959, 293, 393, 312, 588, 13304, 294, 13], "temperature": 0.0, "avg_logprob": -0.26427924465125713, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.203530122344091e-07}, {"id": 170, "seek": 66192, "start": 671.56, "end": 674.7199999999999, "text": " Now Rails has a lot of magic.", "tokens": [823, 48526, 575, 257, 688, 295, 5585, 13], "temperature": 0.0, "avg_logprob": -0.26427924465125713, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.203530122344091e-07}, {"id": 171, "seek": 66192, "start": 674.7199999999999, "end": 677.5999999999999, "text": " Elm has a lot of boilerplate.", "tokens": [2699, 76, 575, 257, 688, 295, 39228, 37008, 13], "temperature": 0.0, "avg_logprob": -0.26427924465125713, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.203530122344091e-07}, {"id": 172, "seek": 66192, "start": 677.5999999999999, "end": 684.9599999999999, "text": " And between like meta frameworks that take away some boilerplate and scaffolding commands", "tokens": [400, 1296, 411, 19616, 29834, 300, 747, 1314, 512, 39228, 37008, 293, 44094, 278, 16901], "temperature": 0.0, "avg_logprob": -0.26427924465125713, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.203530122344091e-07}, {"id": 173, "seek": 68496, "start": 684.96, "end": 692.76, "text": " that help you assemble the minimal amount of explicit Elm code to reduce that boilerplate,", "tokens": [300, 854, 291, 22364, 264, 13206, 2372, 295, 13691, 2699, 76, 3089, 281, 5407, 300, 39228, 37008, 11], "temperature": 0.0, "avg_logprob": -0.21792091720405665, "compression_ratio": 1.599078341013825, "no_speech_prob": 3.412558271520538e-07}, {"id": 174, "seek": 68496, "start": 692.76, "end": 694.76, "text": " I think there's something really compelling there.", "tokens": [286, 519, 456, 311, 746, 534, 20050, 456, 13], "temperature": 0.0, "avg_logprob": -0.21792091720405665, "compression_ratio": 1.599078341013825, "no_speech_prob": 3.412558271520538e-07}, {"id": 175, "seek": 68496, "start": 694.76, "end": 701.1800000000001, "text": " And I think like in Elm, we like writing decoders if we need a decoder.", "tokens": [400, 286, 519, 411, 294, 2699, 76, 11, 321, 411, 3579, 979, 378, 433, 498, 321, 643, 257, 979, 19866, 13], "temperature": 0.0, "avg_logprob": -0.21792091720405665, "compression_ratio": 1.599078341013825, "no_speech_prob": 3.412558271520538e-07}, {"id": 176, "seek": 68496, "start": 701.1800000000001, "end": 704.5600000000001, "text": " We don't want to be implicit and magical.", "tokens": [492, 500, 380, 528, 281, 312, 26947, 293, 12066, 13], "temperature": 0.0, "avg_logprob": -0.21792091720405665, "compression_ratio": 1.599078341013825, "no_speech_prob": 3.412558271520538e-07}, {"id": 177, "seek": 68496, "start": 704.5600000000001, "end": 709.84, "text": " So we should use scaffolding commands for why not have a scaffolding command for generating", "tokens": [407, 321, 820, 764, 44094, 278, 16901, 337, 983, 406, 362, 257, 44094, 278, 5622, 337, 17746], "temperature": 0.0, "avg_logprob": -0.21792091720405665, "compression_ratio": 1.599078341013825, "no_speech_prob": 3.412558271520538e-07}, {"id": 178, "seek": 70984, "start": 709.84, "end": 716.9200000000001, "text": " JSON decoders, or this is for generating forms.", "tokens": [31828, 979, 378, 433, 11, 420, 341, 307, 337, 17746, 6422, 13], "temperature": 0.0, "avg_logprob": -0.31709814071655273, "compression_ratio": 1.53475935828877, "no_speech_prob": 6.375511247824761e-07}, {"id": 179, "seek": 70984, "start": 716.9200000000001, "end": 723.4, "text": " So whenever you say we need to scaffold something, you run a script through Elm pages or something", "tokens": [407, 5699, 291, 584, 321, 643, 281, 44094, 746, 11, 291, 1190, 257, 5755, 807, 2699, 76, 7183, 420, 746], "temperature": 0.0, "avg_logprob": -0.31709814071655273, "compression_ratio": 1.53475935828877, "no_speech_prob": 6.375511247824761e-07}, {"id": 180, "seek": 70984, "start": 723.4, "end": 732.4, "text": " custom that you built or just run Elm code gen with a predefined code generation script.", "tokens": [2375, 300, 291, 3094, 420, 445, 1190, 2699, 76, 3089, 1049, 365, 257, 659, 37716, 3089, 5125, 5755, 13], "temperature": 0.0, "avg_logprob": -0.31709814071655273, "compression_ratio": 1.53475935828877, "no_speech_prob": 6.375511247824761e-07}, {"id": 181, "seek": 70984, "start": 732.4, "end": 734.5600000000001, "text": " And then you generate a new file.", "tokens": [400, 550, 291, 8460, 257, 777, 3991, 13], "temperature": 0.0, "avg_logprob": -0.31709814071655273, "compression_ratio": 1.53475935828877, "no_speech_prob": 6.375511247824761e-07}, {"id": 182, "seek": 70984, "start": 734.5600000000001, "end": 735.5600000000001, "text": " Is that the idea?", "tokens": [1119, 300, 264, 1558, 30], "temperature": 0.0, "avg_logprob": -0.31709814071655273, "compression_ratio": 1.53475935828877, "no_speech_prob": 6.375511247824761e-07}, {"id": 183, "seek": 73556, "start": 735.56, "end": 741.9599999999999, "text": " You generate a new file that represents a route, a new file that contains a decoder", "tokens": [509, 8460, 257, 777, 3991, 300, 8855, 257, 7955, 11, 257, 777, 3991, 300, 8306, 257, 979, 19866], "temperature": 0.0, "avg_logprob": -0.27635473086510176, "compression_ratio": 1.5612244897959184, "no_speech_prob": 9.874445368041052e-07}, {"id": 184, "seek": 73556, "start": 741.9599999999999, "end": 746.16, "text": " and encoder, stuff like that.", "tokens": [293, 2058, 19866, 11, 1507, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.27635473086510176, "compression_ratio": 1.5612244897959184, "no_speech_prob": 9.874445368041052e-07}, {"id": 185, "seek": 73556, "start": 746.16, "end": 751.7199999999999, "text": " So one thing that you could also do is just be a regular person.", "tokens": [407, 472, 551, 300, 291, 727, 611, 360, 307, 445, 312, 257, 3890, 954, 13], "temperature": 0.0, "avg_logprob": -0.27635473086510176, "compression_ratio": 1.5612244897959184, "no_speech_prob": 9.874445368041052e-07}, {"id": 186, "seek": 73556, "start": 751.7199999999999, "end": 757.3599999999999, "text": " And if there's already a route, just copy paste it and adapt it.", "tokens": [400, 498, 456, 311, 1217, 257, 7955, 11, 445, 5055, 9163, 309, 293, 6231, 309, 13], "temperature": 0.0, "avg_logprob": -0.27635473086510176, "compression_ratio": 1.5612244897959184, "no_speech_prob": 9.874445368041052e-07}, {"id": 187, "seek": 73556, "start": 757.3599999999999, "end": 762.38, "text": " Why not do that instead of scaffolding something from scratch?", "tokens": [1545, 406, 360, 300, 2602, 295, 44094, 278, 746, 490, 8459, 30], "temperature": 0.0, "avg_logprob": -0.27635473086510176, "compression_ratio": 1.5612244897959184, "no_speech_prob": 9.874445368041052e-07}, {"id": 188, "seek": 76238, "start": 762.38, "end": 767.08, "text": " When should you reach out for scaffolding instead of copy pasting, which could be closer", "tokens": [1133, 820, 291, 2524, 484, 337, 44094, 278, 2602, 295, 5055, 1791, 278, 11, 597, 727, 312, 4966], "temperature": 0.0, "avg_logprob": -0.2394452546772204, "compression_ratio": 1.5940170940170941, "no_speech_prob": 1.1910990451724501e-06}, {"id": 189, "seek": 76238, "start": 767.08, "end": 773.88, "text": " to what you want anyway, or also in a way pretty different, but who knows?", "tokens": [281, 437, 291, 528, 4033, 11, 420, 611, 294, 257, 636, 1238, 819, 11, 457, 567, 3255, 30], "temperature": 0.0, "avg_logprob": -0.2394452546772204, "compression_ratio": 1.5940170940170941, "no_speech_prob": 1.1910990451724501e-06}, {"id": 190, "seek": 76238, "start": 773.88, "end": 774.88, "text": " It's a great question.", "tokens": [467, 311, 257, 869, 1168, 13], "temperature": 0.0, "avg_logprob": -0.2394452546772204, "compression_ratio": 1.5940170940170941, "no_speech_prob": 1.1910990451724501e-06}, {"id": 191, "seek": 76238, "start": 774.88, "end": 782.24, "text": " I think to me, it's about we have the technology, we have the ability to like automate things.", "tokens": [286, 519, 281, 385, 11, 309, 311, 466, 321, 362, 264, 2899, 11, 321, 362, 264, 3485, 281, 411, 31605, 721, 13], "temperature": 0.0, "avg_logprob": -0.2394452546772204, "compression_ratio": 1.5940170940170941, "no_speech_prob": 1.1910990451724501e-06}, {"id": 192, "seek": 76238, "start": 782.24, "end": 789.56, "text": " And so, but if we don't create nice interfaces and create the right tools to automate these", "tokens": [400, 370, 11, 457, 498, 321, 500, 380, 1884, 1481, 28416, 293, 1884, 264, 558, 3873, 281, 31605, 613], "temperature": 0.0, "avg_logprob": -0.2394452546772204, "compression_ratio": 1.5940170940170941, "no_speech_prob": 1.1910990451724501e-06}, {"id": 193, "seek": 78956, "start": 789.56, "end": 794.0, "text": " types of tasks, then we are going to just find it easier to copy paste things and we're", "tokens": [3467, 295, 9608, 11, 550, 321, 366, 516, 281, 445, 915, 309, 3571, 281, 5055, 9163, 721, 293, 321, 434], "temperature": 0.0, "avg_logprob": -0.22589406427347436, "compression_ratio": 1.6572769953051643, "no_speech_prob": 4.3818053541144764e-07}, {"id": 194, "seek": 78956, "start": 794.0, "end": 795.0, "text": " going to do that.", "tokens": [516, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.22589406427347436, "compression_ratio": 1.6572769953051643, "no_speech_prob": 4.3818053541144764e-07}, {"id": 195, "seek": 78956, "start": 795.0, "end": 800.8399999999999, "text": " And, you know, that's fine, but exactly like it's just, if we're copy pasting, that's just", "tokens": [400, 11, 291, 458, 11, 300, 311, 2489, 11, 457, 2293, 411, 309, 311, 445, 11, 498, 321, 434, 5055, 1791, 278, 11, 300, 311, 445], "temperature": 0.0, "avg_logprob": -0.22589406427347436, "compression_ratio": 1.6572769953051643, "no_speech_prob": 4.3818053541144764e-07}, {"id": 196, "seek": 78956, "start": 800.8399999999999, "end": 807.04, "text": " a sign that we haven't done a good enough job making it easy to do it in a better way.", "tokens": [257, 1465, 300, 321, 2378, 380, 1096, 257, 665, 1547, 1691, 1455, 309, 1858, 281, 360, 309, 294, 257, 1101, 636, 13], "temperature": 0.0, "avg_logprob": -0.22589406427347436, "compression_ratio": 1.6572769953051643, "no_speech_prob": 4.3818053541144764e-07}, {"id": 197, "seek": 78956, "start": 807.04, "end": 808.04, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.22589406427347436, "compression_ratio": 1.6572769953051643, "no_speech_prob": 4.3818053541144764e-07}, {"id": 198, "seek": 78956, "start": 808.04, "end": 809.4399999999999, "text": " And so what is that better way?", "tokens": [400, 370, 437, 307, 300, 1101, 636, 30], "temperature": 0.0, "avg_logprob": -0.22589406427347436, "compression_ratio": 1.6572769953051643, "no_speech_prob": 4.3818053541144764e-07}, {"id": 199, "seek": 78956, "start": 809.4399999999999, "end": 811.1199999999999, "text": " What are those tools for that?", "tokens": [708, 366, 729, 3873, 337, 300, 30], "temperature": 0.0, "avg_logprob": -0.22589406427347436, "compression_ratio": 1.6572769953051643, "no_speech_prob": 4.3818053541144764e-07}, {"id": 200, "seek": 81112, "start": 811.12, "end": 820.76, "text": " So like for the, so like in the ElmPages V3 API, I have a couple of scaffold modules,", "tokens": [407, 411, 337, 264, 11, 370, 411, 294, 264, 2699, 76, 47, 1660, 691, 18, 9362, 11, 286, 362, 257, 1916, 295, 44094, 16679, 11], "temperature": 0.0, "avg_logprob": -0.24241727643308386, "compression_ratio": 1.5654008438818565, "no_speech_prob": 3.520844700233283e-07}, {"id": 201, "seek": 81112, "start": 820.76, "end": 823.08, "text": " scaffold.form and scaffold.route.", "tokens": [44094, 13, 837, 293, 44094, 13, 81, 14040, 13], "temperature": 0.0, "avg_logprob": -0.24241727643308386, "compression_ratio": 1.5654008438818565, "no_speech_prob": 3.520844700233283e-07}, {"id": 202, "seek": 81112, "start": 823.08, "end": 826.84, "text": " And so this is one of the things that I'm experimenting with.", "tokens": [400, 370, 341, 307, 472, 295, 264, 721, 300, 286, 478, 29070, 365, 13], "temperature": 0.0, "avg_logprob": -0.24241727643308386, "compression_ratio": 1.5654008438818565, "no_speech_prob": 3.520844700233283e-07}, {"id": 203, "seek": 81112, "start": 826.84, "end": 833.34, "text": " I think that Elm CodeGen is a very nice tool for scaffolding out code, but it's somewhat", "tokens": [286, 519, 300, 2699, 76, 15549, 26647, 307, 257, 588, 1481, 2290, 337, 44094, 278, 484, 3089, 11, 457, 309, 311, 8344], "temperature": 0.0, "avg_logprob": -0.24241727643308386, "compression_ratio": 1.5654008438818565, "no_speech_prob": 3.520844700233283e-07}, {"id": 204, "seek": 81112, "start": 833.34, "end": 834.34, "text": " low level.", "tokens": [2295, 1496, 13], "temperature": 0.0, "avg_logprob": -0.24241727643308386, "compression_ratio": 1.5654008438818565, "no_speech_prob": 3.520844700233283e-07}, {"id": 205, "seek": 81112, "start": 834.34, "end": 840.36, "text": " So it generates helpers for you for, if you want to run list.map, you can do gen.list.map", "tokens": [407, 309, 23815, 854, 433, 337, 291, 337, 11, 498, 291, 528, 281, 1190, 1329, 13, 24223, 11, 291, 393, 360, 1049, 13, 8264, 13, 24223], "temperature": 0.0, "avg_logprob": -0.24241727643308386, "compression_ratio": 1.5654008438818565, "no_speech_prob": 3.520844700233283e-07}, {"id": 206, "seek": 84036, "start": 840.36, "end": 846.76, "text": " and then you can pass in the corresponding expressions or it doesn't generate all of", "tokens": [293, 550, 291, 393, 1320, 294, 264, 11760, 15277, 420, 309, 1177, 380, 8460, 439, 295], "temperature": 0.0, "avg_logprob": -0.2351892452047329, "compression_ratio": 1.706140350877193, "no_speech_prob": 1.7880454379337607e-06}, {"id": 207, "seek": 84036, "start": 846.76, "end": 848.0, "text": " the high level types for you.", "tokens": [264, 1090, 1496, 3467, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.2351892452047329, "compression_ratio": 1.706140350877193, "no_speech_prob": 1.7880454379337607e-06}, {"id": 208, "seek": 84036, "start": 848.0, "end": 854.6800000000001, "text": " A lot of the types end up being Elm.expression because it takes some argument, but that argument", "tokens": [316, 688, 295, 264, 3467, 917, 493, 885, 2699, 76, 13, 15952, 2775, 570, 309, 2516, 512, 6770, 11, 457, 300, 6770], "temperature": 0.0, "avg_logprob": -0.2351892452047329, "compression_ratio": 1.706140350877193, "no_speech_prob": 1.7880454379337607e-06}, {"id": 209, "seek": 84036, "start": 854.6800000000001, "end": 859.48, "text": " could be coming from like a variable you have in scope and it, and it helps you sort of", "tokens": [727, 312, 1348, 490, 411, 257, 7006, 291, 362, 294, 11923, 293, 309, 11, 293, 309, 3665, 291, 1333, 295], "temperature": 0.0, "avg_logprob": -0.2351892452047329, "compression_ratio": 1.706140350877193, "no_speech_prob": 1.7880454379337607e-06}, {"id": 210, "seek": 84036, "start": 859.48, "end": 867.88, "text": " manage what variables you have in scope by if you, if you define a let using Elm CodeGen,", "tokens": [3067, 437, 9102, 291, 362, 294, 11923, 538, 498, 291, 11, 498, 291, 6964, 257, 718, 1228, 2699, 76, 15549, 26647, 11], "temperature": 0.0, "avg_logprob": -0.2351892452047329, "compression_ratio": 1.706140350877193, "no_speech_prob": 1.7880454379337607e-06}, {"id": 211, "seek": 86788, "start": 867.88, "end": 872.2, "text": " then it, it lets you name a variable that you have in scope.", "tokens": [550, 309, 11, 309, 6653, 291, 1315, 257, 7006, 300, 291, 362, 294, 11923, 13], "temperature": 0.0, "avg_logprob": -0.2081246113213967, "compression_ratio": 1.7463235294117647, "no_speech_prob": 6.276670205807022e-07}, {"id": 212, "seek": 86788, "start": 872.2, "end": 876.8, "text": " So you have an actual variable, but it represents an Elm expression, which is the variable in", "tokens": [407, 291, 362, 364, 3539, 7006, 11, 457, 309, 8855, 364, 2699, 76, 6114, 11, 597, 307, 264, 7006, 294], "temperature": 0.0, "avg_logprob": -0.2081246113213967, "compression_ratio": 1.7463235294117647, "no_speech_prob": 6.276670205807022e-07}, {"id": 213, "seek": 86788, "start": 876.8, "end": 878.24, "text": " the code you're going to generate.", "tokens": [264, 3089, 291, 434, 516, 281, 8460, 13], "temperature": 0.0, "avg_logprob": -0.2081246113213967, "compression_ratio": 1.7463235294117647, "no_speech_prob": 6.276670205807022e-07}, {"id": 214, "seek": 86788, "start": 878.24, "end": 880.72, "text": " It's a little bit, hurts your brain a little bit, right?", "tokens": [467, 311, 257, 707, 857, 11, 11051, 428, 3567, 257, 707, 857, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2081246113213967, "compression_ratio": 1.7463235294117647, "no_speech_prob": 6.276670205807022e-07}, {"id": 215, "seek": 86788, "start": 880.72, "end": 887.72, "text": " But it does a good job sort of mirroring the code it's going to end up looking like, but", "tokens": [583, 309, 775, 257, 665, 1691, 1333, 295, 8013, 278, 264, 3089, 309, 311, 516, 281, 917, 493, 1237, 411, 11, 457], "temperature": 0.0, "avg_logprob": -0.2081246113213967, "compression_ratio": 1.7463235294117647, "no_speech_prob": 6.276670205807022e-07}, {"id": 216, "seek": 86788, "start": 887.72, "end": 891.68, "text": " it only does that for like at a lower level.", "tokens": [309, 787, 775, 300, 337, 411, 412, 257, 3126, 1496, 13], "temperature": 0.0, "avg_logprob": -0.2081246113213967, "compression_ratio": 1.7463235294117647, "no_speech_prob": 6.276670205807022e-07}, {"id": 217, "seek": 86788, "start": 891.68, "end": 897.78, "text": " But if you have like a higher level API, I think there's an opportunity to create abstractions", "tokens": [583, 498, 291, 362, 411, 257, 2946, 1496, 9362, 11, 286, 519, 456, 311, 364, 2650, 281, 1884, 12649, 626], "temperature": 0.0, "avg_logprob": -0.2081246113213967, "compression_ratio": 1.7463235294117647, "no_speech_prob": 6.276670205807022e-07}, {"id": 218, "seek": 89778, "start": 897.78, "end": 899.4399999999999, "text": " that mirror those APIs.", "tokens": [300, 8013, 729, 21445, 13], "temperature": 0.0, "avg_logprob": -0.2191941755531478, "compression_ratio": 1.8672199170124482, "no_speech_prob": 3.7479847492249974e-07}, {"id": 219, "seek": 89778, "start": 899.4399999999999, "end": 905.04, "text": " Like if you have a builder pattern, so like in Elm pages v3, there's, there's a sort of", "tokens": [1743, 498, 291, 362, 257, 27377, 5102, 11, 370, 411, 294, 2699, 76, 7183, 371, 18, 11, 456, 311, 11, 456, 311, 257, 1333, 295], "temperature": 0.0, "avg_logprob": -0.2191941755531478, "compression_ratio": 1.8672199170124482, "no_speech_prob": 3.7479847492249974e-07}, {"id": 220, "seek": 89778, "start": 905.04, "end": 908.56, "text": " a route builder for defining your route.", "tokens": [257, 7955, 27377, 337, 17827, 428, 7955, 13], "temperature": 0.0, "avg_logprob": -0.2191941755531478, "compression_ratio": 1.8672199170124482, "no_speech_prob": 3.7479847492249974e-07}, {"id": 221, "seek": 89778, "start": 908.56, "end": 910.1999999999999, "text": " Is it a server rendered route?", "tokens": [1119, 309, 257, 7154, 28748, 7955, 30], "temperature": 0.0, "avg_logprob": -0.2191941755531478, "compression_ratio": 1.8672199170124482, "no_speech_prob": 3.7479847492249974e-07}, {"id": 222, "seek": 89778, "start": 910.1999999999999, "end": 912.3199999999999, "text": " Is it a pre-rendered route?", "tokens": [1119, 309, 257, 659, 12, 4542, 4073, 7955, 30], "temperature": 0.0, "avg_logprob": -0.2191941755531478, "compression_ratio": 1.8672199170124482, "no_speech_prob": 3.7479847492249974e-07}, {"id": 223, "seek": 89778, "start": 912.3199999999999, "end": 913.48, "text": " Does it have local state?", "tokens": [4402, 309, 362, 2654, 1785, 30], "temperature": 0.0, "avg_logprob": -0.2191941755531478, "compression_ratio": 1.8672199170124482, "no_speech_prob": 3.7479847492249974e-07}, {"id": 224, "seek": 89778, "start": 913.48, "end": 914.52, "text": " Does it have shared state?", "tokens": [4402, 309, 362, 5507, 1785, 30], "temperature": 0.0, "avg_logprob": -0.2191941755531478, "compression_ratio": 1.8672199170124482, "no_speech_prob": 3.7479847492249974e-07}, {"id": 225, "seek": 89778, "start": 914.52, "end": 916.0, "text": " Does it have no state?", "tokens": [4402, 309, 362, 572, 1785, 30], "temperature": 0.0, "avg_logprob": -0.2191941755531478, "compression_ratio": 1.8672199170124482, "no_speech_prob": 3.7479847492249974e-07}, {"id": 226, "seek": 89778, "start": 916.0, "end": 920.4599999999999, "text": " So that's a, that's a builder that you can sort of tack on these options.", "tokens": [407, 300, 311, 257, 11, 300, 311, 257, 27377, 300, 291, 393, 1333, 295, 9426, 322, 613, 3956, 13], "temperature": 0.0, "avg_logprob": -0.2191941755531478, "compression_ratio": 1.8672199170124482, "no_speech_prob": 3.7479847492249974e-07}, {"id": 227, "seek": 89778, "start": 920.4599999999999, "end": 927.4399999999999, "text": " And if you, you know, if you do with no state, then you need to give it a view function.", "tokens": [400, 498, 291, 11, 291, 458, 11, 498, 291, 360, 365, 572, 1785, 11, 550, 291, 643, 281, 976, 309, 257, 1910, 2445, 13], "temperature": 0.0, "avg_logprob": -0.2191941755531478, "compression_ratio": 1.8672199170124482, "no_speech_prob": 3.7479847492249974e-07}, {"id": 228, "seek": 92744, "start": 927.44, "end": 929.4000000000001, "text": " You need to define a view function.", "tokens": [509, 643, 281, 6964, 257, 1910, 2445, 13], "temperature": 0.0, "avg_logprob": -0.24864017963409424, "compression_ratio": 1.84, "no_speech_prob": 3.412560829474387e-07}, {"id": 229, "seek": 92744, "start": 929.4000000000001, "end": 934.7600000000001, "text": " If you do build with local state, you're going to, in addition to the view, need an update", "tokens": [759, 291, 360, 1322, 365, 2654, 1785, 11, 291, 434, 516, 281, 11, 294, 4500, 281, 264, 1910, 11, 643, 364, 5623], "temperature": 0.0, "avg_logprob": -0.24864017963409424, "compression_ratio": 1.84, "no_speech_prob": 3.412560829474387e-07}, {"id": 230, "seek": 92744, "start": 934.7600000000001, "end": 938.08, "text": " and it subscriptions message and model, right?", "tokens": [293, 309, 44951, 3636, 293, 2316, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.24864017963409424, "compression_ratio": 1.84, "no_speech_prob": 3.412560829474387e-07}, {"id": 231, "seek": 92744, "start": 938.08, "end": 945.36, "text": " So that is too like Elm code gen isn't going to help you with knowing that you need to", "tokens": [407, 300, 307, 886, 411, 2699, 76, 3089, 1049, 1943, 380, 516, 281, 854, 291, 365, 5276, 300, 291, 643, 281], "temperature": 0.0, "avg_logprob": -0.24864017963409424, "compression_ratio": 1.84, "no_speech_prob": 3.412560829474387e-07}, {"id": 232, "seek": 92744, "start": 945.36, "end": 951.2800000000001, "text": " define an update function in the one case and only a view function in the other case.", "tokens": [6964, 364, 5623, 2445, 294, 264, 472, 1389, 293, 787, 257, 1910, 2445, 294, 264, 661, 1389, 13], "temperature": 0.0, "avg_logprob": -0.24864017963409424, "compression_ratio": 1.84, "no_speech_prob": 3.412560829474387e-07}, {"id": 233, "seek": 92744, "start": 951.2800000000001, "end": 953.6800000000001, "text": " And you're going to need to define these types.", "tokens": [400, 291, 434, 516, 281, 643, 281, 6964, 613, 3467, 13], "temperature": 0.0, "avg_logprob": -0.24864017963409424, "compression_ratio": 1.84, "no_speech_prob": 3.412560829474387e-07}, {"id": 234, "seek": 92744, "start": 953.6800000000001, "end": 955.4200000000001, "text": " There's no way for it to know that.", "tokens": [821, 311, 572, 636, 337, 309, 281, 458, 300, 13], "temperature": 0.0, "avg_logprob": -0.24864017963409424, "compression_ratio": 1.84, "no_speech_prob": 3.412560829474387e-07}, {"id": 235, "seek": 92744, "start": 955.4200000000001, "end": 956.4200000000001, "text": " So we can help it out.", "tokens": [407, 321, 393, 854, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.24864017963409424, "compression_ratio": 1.84, "no_speech_prob": 3.412560829474387e-07}, {"id": 236, "seek": 92744, "start": 956.4200000000001, "end": 957.4200000000001, "text": " Right?", "tokens": [1779, 30], "temperature": 0.0, "avg_logprob": -0.24864017963409424, "compression_ratio": 1.84, "no_speech_prob": 3.412560829474387e-07}, {"id": 237, "seek": 95742, "start": 957.42, "end": 964.16, "text": " So I, I basically mirrored that API and we'll, we'll link to these modules in the, in the", "tokens": [407, 286, 11, 286, 1936, 3149, 340, 986, 300, 9362, 293, 321, 603, 11, 321, 603, 2113, 281, 613, 16679, 294, 264, 11, 294, 264], "temperature": 0.0, "avg_logprob": -0.2672825028411055, "compression_ratio": 1.5634920634920635, "no_speech_prob": 3.412457090234966e-07}, {"id": 238, "seek": 95742, "start": 964.16, "end": 970.28, "text": " V3 beta docs of Elm pages, but I tried to, to give some high level helpers.", "tokens": [691, 18, 9861, 45623, 295, 2699, 76, 7183, 11, 457, 286, 3031, 281, 11, 281, 976, 512, 1090, 1496, 854, 433, 13], "temperature": 0.0, "avg_logprob": -0.2672825028411055, "compression_ratio": 1.5634920634920635, "no_speech_prob": 3.412457090234966e-07}, {"id": 239, "seek": 95742, "start": 970.28, "end": 976.36, "text": " Now like one of the keys here, you know, when, when you are doing the builder pattern, you", "tokens": [823, 411, 472, 295, 264, 9317, 510, 11, 291, 458, 11, 562, 11, 562, 291, 366, 884, 264, 27377, 5102, 11, 291], "temperature": 0.0, "avg_logprob": -0.2672825028411055, "compression_ratio": 1.5634920634920635, "no_speech_prob": 3.412457090234966e-07}, {"id": 240, "seek": 95742, "start": 976.36, "end": 983.12, "text": " have this sort of builder type that at the end you turn into whatever thing you want,", "tokens": [362, 341, 1333, 295, 27377, 2010, 300, 412, 264, 917, 291, 1261, 666, 2035, 551, 291, 528, 11], "temperature": 0.0, "avg_logprob": -0.2672825028411055, "compression_ratio": 1.5634920634920635, "no_speech_prob": 3.412457090234966e-07}, {"id": 241, "seek": 95742, "start": 983.12, "end": 985.4, "text": " like an Elm code gen expression or whatever.", "tokens": [411, 364, 2699, 76, 3089, 1049, 6114, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.2672825028411055, "compression_ratio": 1.5634920634920635, "no_speech_prob": 3.412457090234966e-07}, {"id": 242, "seek": 95742, "start": 985.4, "end": 986.4, "text": " Right?", "tokens": [1779, 30], "temperature": 0.0, "avg_logprob": -0.2672825028411055, "compression_ratio": 1.5634920634920635, "no_speech_prob": 3.412457090234966e-07}, {"id": 243, "seek": 98640, "start": 986.4, "end": 992.16, "text": " So you need a level of safety that you're not just sort of constantly taking an expression", "tokens": [407, 291, 643, 257, 1496, 295, 4514, 300, 291, 434, 406, 445, 1333, 295, 6460, 1940, 364, 6114], "temperature": 0.0, "avg_logprob": -0.18161865516945166, "compression_ratio": 1.7478991596638656, "no_speech_prob": 4.6643603468510264e-07}, {"id": 244, "seek": 98640, "start": 992.16, "end": 996.9599999999999, "text": " and applying functions to that expression and things like that.", "tokens": [293, 9275, 6828, 281, 300, 6114, 293, 721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.18161865516945166, "compression_ratio": 1.7478991596638656, "no_speech_prob": 4.6643603468510264e-07}, {"id": 245, "seek": 98640, "start": 996.9599999999999, "end": 997.9599999999999, "text": " Right?", "tokens": [1779, 30], "temperature": 0.0, "avg_logprob": -0.18161865516945166, "compression_ratio": 1.7478991596638656, "no_speech_prob": 4.6643603468510264e-07}, {"id": 246, "seek": 98640, "start": 997.9599999999999, "end": 1003.3199999999999, "text": " Because then you just have like this amorphous expression and you can do a bajillion things", "tokens": [1436, 550, 291, 445, 362, 411, 341, 15543, 950, 563, 6114, 293, 291, 393, 360, 257, 23589, 11836, 721], "temperature": 0.0, "avg_logprob": -0.18161865516945166, "compression_ratio": 1.7478991596638656, "no_speech_prob": 4.6643603468510264e-07}, {"id": 247, "seek": 98640, "start": 1003.3199999999999, "end": 1004.3199999999999, "text": " to it.", "tokens": [281, 309, 13], "temperature": 0.0, "avg_logprob": -0.18161865516945166, "compression_ratio": 1.7478991596638656, "no_speech_prob": 4.6643603468510264e-07}, {"id": 248, "seek": 98640, "start": 1004.3199999999999, "end": 1008.28, "text": " And it's not really like clear how to scaffold this code.", "tokens": [400, 309, 311, 406, 534, 411, 1850, 577, 281, 44094, 341, 3089, 13], "temperature": 0.0, "avg_logprob": -0.18161865516945166, "compression_ratio": 1.7478991596638656, "no_speech_prob": 4.6643603468510264e-07}, {"id": 249, "seek": 98640, "start": 1008.28, "end": 1015.3199999999999, "text": " So this API has like a, like a builder for the, for the scaffolding type for scaffolding", "tokens": [407, 341, 9362, 575, 411, 257, 11, 411, 257, 27377, 337, 264, 11, 337, 264, 44094, 278, 2010, 337, 44094, 278], "temperature": 0.0, "avg_logprob": -0.18161865516945166, "compression_ratio": 1.7478991596638656, "no_speech_prob": 4.6643603468510264e-07}, {"id": 250, "seek": 98640, "start": 1015.3199999999999, "end": 1016.3199999999999, "text": " a route.", "tokens": [257, 7955, 13], "temperature": 0.0, "avg_logprob": -0.18161865516945166, "compression_ratio": 1.7478991596638656, "no_speech_prob": 4.6643603468510264e-07}, {"id": 251, "seek": 101632, "start": 1016.32, "end": 1020.6800000000001, "text": " So it's sort of like a, for the, for the route scaffolding, it's a builder for the route", "tokens": [407, 309, 311, 1333, 295, 411, 257, 11, 337, 264, 11, 337, 264, 7955, 44094, 278, 11, 309, 311, 257, 27377, 337, 264, 7955], "temperature": 0.0, "avg_logprob": -0.20157833757071658, "compression_ratio": 1.826086956521739, "no_speech_prob": 4.5921098035250907e-07}, {"id": 252, "seek": 101632, "start": 1020.6800000000001, "end": 1022.0400000000001, "text": " scaffolding.", "tokens": [44094, 278, 13], "temperature": 0.0, "avg_logprob": -0.20157833757071658, "compression_ratio": 1.826086956521739, "no_speech_prob": 4.5921098035250907e-07}, {"id": 253, "seek": 101632, "start": 1022.0400000000001, "end": 1030.3400000000001, "text": " So you apply these sort of sets of options for generating a server rendered route with", "tokens": [407, 291, 3079, 613, 1333, 295, 6352, 295, 3956, 337, 17746, 257, 7154, 28748, 7955, 365], "temperature": 0.0, "avg_logprob": -0.20157833757071658, "compression_ratio": 1.826086956521739, "no_speech_prob": 4.5921098035250907e-07}, {"id": 254, "seek": 101632, "start": 1030.3400000000001, "end": 1031.76, "text": " local state.", "tokens": [2654, 1785, 13], "temperature": 0.0, "avg_logprob": -0.20157833757071658, "compression_ratio": 1.826086956521739, "no_speech_prob": 4.5921098035250907e-07}, {"id": 255, "seek": 101632, "start": 1031.76, "end": 1036.56, "text": " So now you're tacking on these options to give all of the function definitions that", "tokens": [407, 586, 291, 434, 9426, 278, 322, 613, 3956, 281, 976, 439, 295, 264, 2445, 21988, 300], "temperature": 0.0, "avg_logprob": -0.20157833757071658, "compression_ratio": 1.826086956521739, "no_speech_prob": 4.5921098035250907e-07}, {"id": 256, "seek": 101632, "start": 1036.56, "end": 1040.68, "text": " you need for those options in the builder pattern.", "tokens": [291, 643, 337, 729, 3956, 294, 264, 27377, 5102, 13], "temperature": 0.0, "avg_logprob": -0.20157833757071658, "compression_ratio": 1.826086956521739, "no_speech_prob": 4.5921098035250907e-07}, {"id": 257, "seek": 104068, "start": 1040.68, "end": 1048.92, "text": " So I think essentially like my assertion here is that I think it's a good idea for packages", "tokens": [407, 286, 519, 4476, 411, 452, 19810, 313, 510, 307, 300, 286, 519, 309, 311, 257, 665, 1558, 337, 17401], "temperature": 0.0, "avg_logprob": -0.20961207221536077, "compression_ratio": 1.5588235294117647, "no_speech_prob": 4.3138763317074336e-07}, {"id": 258, "seek": 104068, "start": 1048.92, "end": 1055.8, "text": " to create higher level APIs that mirror their APIs for scaffolding.", "tokens": [281, 1884, 2946, 1496, 21445, 300, 8013, 641, 21445, 337, 44094, 278, 13], "temperature": 0.0, "avg_logprob": -0.20961207221536077, "compression_ratio": 1.5588235294117647, "no_speech_prob": 4.3138763317074336e-07}, {"id": 259, "seek": 104068, "start": 1055.8, "end": 1063.52, "text": " So like for Elm review, if you're scaffolding out a new Elm review rule, which there is", "tokens": [407, 411, 337, 2699, 76, 3131, 11, 498, 291, 434, 44094, 278, 484, 257, 777, 2699, 76, 3131, 4978, 11, 597, 456, 307], "temperature": 0.0, "avg_logprob": -0.20961207221536077, "compression_ratio": 1.5588235294117647, "no_speech_prob": 4.3138763317074336e-07}, {"id": 260, "seek": 104068, "start": 1063.52, "end": 1067.5600000000002, "text": " a feature for already, but yeah, right.", "tokens": [257, 4111, 337, 1217, 11, 457, 1338, 11, 558, 13], "temperature": 0.0, "avg_logprob": -0.20961207221536077, "compression_ratio": 1.5588235294117647, "no_speech_prob": 4.3138763317074336e-07}, {"id": 261, "seek": 104068, "start": 1067.5600000000002, "end": 1068.6000000000001, "text": " And we should talk about that.", "tokens": [400, 321, 820, 751, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.20961207221536077, "compression_ratio": 1.5588235294117647, "no_speech_prob": 4.3138763317074336e-07}, {"id": 262, "seek": 106860, "start": 1068.6, "end": 1075.32, "text": " So now I will say when I'm working on Elm review rules, I do often go to the docs and", "tokens": [407, 586, 286, 486, 584, 562, 286, 478, 1364, 322, 2699, 76, 3131, 4474, 11, 286, 360, 2049, 352, 281, 264, 45623, 293], "temperature": 0.0, "avg_logprob": -0.21459329007851957, "compression_ratio": 1.5541125541125542, "no_speech_prob": 9.570690053806175e-07}, {"id": 263, "seek": 106860, "start": 1075.32, "end": 1079.98, "text": " copy paste an example of a visitor, for example.", "tokens": [5055, 9163, 364, 1365, 295, 257, 28222, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.21459329007851957, "compression_ratio": 1.5541125541125542, "no_speech_prob": 9.570690053806175e-07}, {"id": 264, "seek": 106860, "start": 1079.98, "end": 1081.7199999999998, "text": " Those examples are just awesome.", "tokens": [3950, 5110, 366, 445, 3476, 13], "temperature": 0.0, "avg_logprob": -0.21459329007851957, "compression_ratio": 1.5541125541125542, "no_speech_prob": 9.570690053806175e-07}, {"id": 265, "seek": 106860, "start": 1081.7199999999998, "end": 1083.28, "text": " So go ahead.", "tokens": [407, 352, 2286, 13], "temperature": 0.0, "avg_logprob": -0.21459329007851957, "compression_ratio": 1.5541125541125542, "no_speech_prob": 9.570690053806175e-07}, {"id": 266, "seek": 106860, "start": 1083.28, "end": 1084.28, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.21459329007851957, "compression_ratio": 1.5541125541125542, "no_speech_prob": 9.570690053806175e-07}, {"id": 267, "seek": 106860, "start": 1084.28, "end": 1089.3799999999999, "text": " And I mean, and there is definitely an art to having examples that are copy pastable", "tokens": [400, 286, 914, 11, 293, 456, 307, 2138, 364, 1523, 281, 1419, 5110, 300, 366, 5055, 1791, 712], "temperature": 0.0, "avg_logprob": -0.21459329007851957, "compression_ratio": 1.5541125541125542, "no_speech_prob": 9.570690053806175e-07}, {"id": 268, "seek": 106860, "start": 1089.3799999999999, "end": 1096.84, "text": " because things are defined in a way that not only compile, but you know, maybe you take", "tokens": [570, 721, 366, 7642, 294, 257, 636, 300, 406, 787, 31413, 11, 457, 291, 458, 11, 1310, 291, 747], "temperature": 0.0, "avg_logprob": -0.21459329007851957, "compression_ratio": 1.5541125541125542, "no_speech_prob": 9.570690053806175e-07}, {"id": 269, "seek": 109684, "start": 1096.84, "end": 1102.8, "text": " in certain things as parameters so that it's like a nice sort of self-contained example", "tokens": [294, 1629, 721, 382, 9834, 370, 300, 309, 311, 411, 257, 1481, 1333, 295, 2698, 12, 9000, 3563, 1365], "temperature": 0.0, "avg_logprob": -0.22953851646352036, "compression_ratio": 1.6023622047244095, "no_speech_prob": 2.260293513245415e-06}, {"id": 270, "seek": 109684, "start": 1102.8, "end": 1106.6, "text": " that you can probably copy paste into your own code.", "tokens": [300, 291, 393, 1391, 5055, 9163, 666, 428, 1065, 3089, 13], "temperature": 0.0, "avg_logprob": -0.22953851646352036, "compression_ratio": 1.6023622047244095, "no_speech_prob": 2.260293513245415e-06}, {"id": 271, "seek": 109684, "start": 1106.6, "end": 1108.0, "text": " So there's definitely an art to that.", "tokens": [407, 456, 311, 2138, 364, 1523, 281, 300, 13], "temperature": 0.0, "avg_logprob": -0.22953851646352036, "compression_ratio": 1.6023622047244095, "no_speech_prob": 2.260293513245415e-06}, {"id": 272, "seek": 109684, "start": 1108.0, "end": 1109.6799999999998, "text": " And you've done a good job of that.", "tokens": [400, 291, 600, 1096, 257, 665, 1691, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.22953851646352036, "compression_ratio": 1.6023622047244095, "no_speech_prob": 2.260293513245415e-06}, {"id": 273, "seek": 109684, "start": 1109.6799999999998, "end": 1114.3999999999999, "text": " Now the question is similar to what we were talking about before with like copy pasting", "tokens": [823, 264, 1168, 307, 2531, 281, 437, 321, 645, 1417, 466, 949, 365, 411, 5055, 1791, 278], "temperature": 0.0, "avg_logprob": -0.22953851646352036, "compression_ratio": 1.6023622047244095, "no_speech_prob": 2.260293513245415e-06}, {"id": 274, "seek": 109684, "start": 1114.3999999999999, "end": 1119.56, "text": " a new route module, can we beat the copy paste experience?", "tokens": [257, 777, 7955, 10088, 11, 393, 321, 4224, 264, 5055, 9163, 1752, 30], "temperature": 0.0, "avg_logprob": -0.22953851646352036, "compression_ratio": 1.6023622047244095, "no_speech_prob": 2.260293513245415e-06}, {"id": 275, "seek": 109684, "start": 1119.56, "end": 1122.12, "text": " Because if we can't, then why waste our time?", "tokens": [1436, 498, 321, 393, 380, 11, 550, 983, 5964, 527, 565, 30], "temperature": 0.0, "avg_logprob": -0.22953851646352036, "compression_ratio": 1.6023622047244095, "no_speech_prob": 2.260293513245415e-06}, {"id": 276, "seek": 112212, "start": 1122.12, "end": 1127.08, "text": " Because we can already copy paste anything and that's what people are going to do unless", "tokens": [1436, 321, 393, 1217, 5055, 9163, 1340, 293, 300, 311, 437, 561, 366, 516, 281, 360, 5969], "temperature": 0.0, "avg_logprob": -0.24729504408659758, "compression_ratio": 1.6812227074235808, "no_speech_prob": 8.05940715054021e-07}, {"id": 277, "seek": 112212, "start": 1127.08, "end": 1132.04, "text": " we, you know, like that sets the bar, unless we go past that, people are just going to", "tokens": [321, 11, 291, 458, 11, 411, 300, 6352, 264, 2159, 11, 5969, 321, 352, 1791, 300, 11, 561, 366, 445, 516, 281], "temperature": 0.0, "avg_logprob": -0.24729504408659758, "compression_ratio": 1.6812227074235808, "no_speech_prob": 8.05940715054021e-07}, {"id": 278, "seek": 112212, "start": 1132.04, "end": 1133.04, "text": " copy paste.", "tokens": [5055, 9163, 13], "temperature": 0.0, "avg_logprob": -0.24729504408659758, "compression_ratio": 1.6812227074235808, "no_speech_prob": 8.05940715054021e-07}, {"id": 279, "seek": 112212, "start": 1133.04, "end": 1134.04, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.24729504408659758, "compression_ratio": 1.6812227074235808, "no_speech_prob": 8.05940715054021e-07}, {"id": 280, "seek": 112212, "start": 1134.04, "end": 1137.76, "text": " So there's one reason why every time I work on a new rule, I start from scratch.", "tokens": [407, 456, 311, 472, 1778, 983, 633, 565, 286, 589, 322, 257, 777, 4978, 11, 286, 722, 490, 8459, 13], "temperature": 0.0, "avg_logprob": -0.24729504408659758, "compression_ratio": 1.6812227074235808, "no_speech_prob": 8.05940715054021e-07}, {"id": 281, "seek": 112212, "start": 1137.76, "end": 1145.2399999999998, "text": " So I do use the Elm review new dash rule command, which scaffolds a new file and it scaffolds", "tokens": [407, 286, 360, 764, 264, 2699, 76, 3131, 777, 8240, 4978, 5622, 11, 597, 40889, 31518, 257, 777, 3991, 293, 309, 40889, 31518], "temperature": 0.0, "avg_logprob": -0.24729504408659758, "compression_ratio": 1.6812227074235808, "no_speech_prob": 8.05940715054021e-07}, {"id": 282, "seek": 112212, "start": 1145.2399999999998, "end": 1146.52, "text": " a new test file.", "tokens": [257, 777, 1500, 3991, 13], "temperature": 0.0, "avg_logprob": -0.24729504408659758, "compression_ratio": 1.6812227074235808, "no_speech_prob": 8.05940715054021e-07}, {"id": 283, "seek": 114652, "start": 1146.52, "end": 1152.68, "text": " And reason why it starts from scratch is because I want to do things in a TDD style.", "tokens": [400, 1778, 983, 309, 3719, 490, 8459, 307, 570, 286, 528, 281, 360, 721, 294, 257, 314, 20818, 3758, 13], "temperature": 0.0, "avg_logprob": -0.24038217717950994, "compression_ratio": 1.7479674796747968, "no_speech_prob": 1.933317207658547e-06}, {"id": 284, "seek": 114652, "start": 1152.68, "end": 1158.44, "text": " And if I copy paste some code, then I don't have the test for them because the examples", "tokens": [400, 498, 286, 5055, 9163, 512, 3089, 11, 550, 286, 500, 380, 362, 264, 1500, 337, 552, 570, 264, 5110], "temperature": 0.0, "avg_logprob": -0.24038217717950994, "compression_ratio": 1.7479674796747968, "no_speech_prob": 1.933317207658547e-06}, {"id": 285, "seek": 114652, "start": 1158.44, "end": 1164.52, "text": " are good, but there are no tests for that specific example, which makes a lot of sense.", "tokens": [366, 665, 11, 457, 456, 366, 572, 6921, 337, 300, 2685, 1365, 11, 597, 1669, 257, 688, 295, 2020, 13], "temperature": 0.0, "avg_logprob": -0.24038217717950994, "compression_ratio": 1.7479674796747968, "no_speech_prob": 1.933317207658547e-06}, {"id": 286, "seek": 114652, "start": 1164.52, "end": 1169.96, "text": " I think if I wanted to copy paste something, then I would also have to copy paste a test,", "tokens": [286, 519, 498, 286, 1415, 281, 5055, 9163, 746, 11, 550, 286, 576, 611, 362, 281, 5055, 9163, 257, 1500, 11], "temperature": 0.0, "avg_logprob": -0.24038217717950994, "compression_ratio": 1.7479674796747968, "no_speech_prob": 1.933317207658547e-06}, {"id": 287, "seek": 114652, "start": 1169.96, "end": 1173.28, "text": " which is usually not very applicable.", "tokens": [597, 307, 2673, 406, 588, 21142, 13], "temperature": 0.0, "avg_logprob": -0.24038217717950994, "compression_ratio": 1.7479674796747968, "no_speech_prob": 1.933317207658547e-06}, {"id": 288, "seek": 114652, "start": 1173.28, "end": 1175.6, "text": " So therefore I start from scratch anyway.", "tokens": [407, 4412, 286, 722, 490, 8459, 4033, 13], "temperature": 0.0, "avg_logprob": -0.24038217717950994, "compression_ratio": 1.7479674796747968, "no_speech_prob": 1.933317207658547e-06}, {"id": 289, "seek": 117560, "start": 1175.6, "end": 1179.4599999999998, "text": " That said, there are multiple variants of Elm review rules.", "tokens": [663, 848, 11, 456, 366, 3866, 21669, 295, 2699, 76, 3131, 4474, 13], "temperature": 0.0, "avg_logprob": -0.24976670300519024, "compression_ratio": 1.7307692307692308, "no_speech_prob": 5.989173814668902e-07}, {"id": 290, "seek": 117560, "start": 1179.4599999999998, "end": 1184.76, "text": " So there's module rules, which are very simple or simpler, and there are projects rules,", "tokens": [407, 456, 311, 10088, 4474, 11, 597, 366, 588, 2199, 420, 18587, 11, 293, 456, 366, 4455, 4474, 11], "temperature": 0.0, "avg_logprob": -0.24976670300519024, "compression_ratio": 1.7307692307692308, "no_speech_prob": 5.989173814668902e-07}, {"id": 291, "seek": 117560, "start": 1184.76, "end": 1186.6599999999999, "text": " which are a lot more complex.", "tokens": [597, 366, 257, 688, 544, 3997, 13], "temperature": 0.0, "avg_logprob": -0.24976670300519024, "compression_ratio": 1.7307692307692308, "no_speech_prob": 5.989173814668902e-07}, {"id": 292, "seek": 117560, "start": 1186.6599999999999, "end": 1192.52, "text": " And I do think that I should probably have a scaffold for each of those because every", "tokens": [400, 286, 360, 519, 300, 286, 820, 1391, 362, 257, 44094, 337, 1184, 295, 729, 570, 633], "temperature": 0.0, "avg_logprob": -0.24976670300519024, "compression_ratio": 1.7307692307692308, "no_speech_prob": 5.989173814668902e-07}, {"id": 293, "seek": 117560, "start": 1192.52, "end": 1198.9599999999998, "text": " time I work on a new one and I need to use a particular rule, I need to migrate the module", "tokens": [565, 286, 589, 322, 257, 777, 472, 293, 286, 643, 281, 764, 257, 1729, 4978, 11, 286, 643, 281, 31821, 264, 10088], "temperature": 0.0, "avg_logprob": -0.24976670300519024, "compression_ratio": 1.7307692307692308, "no_speech_prob": 5.989173814668902e-07}, {"id": 294, "seek": 117560, "start": 1198.9599999999998, "end": 1200.28, "text": " rule to a project rule.", "tokens": [4978, 281, 257, 1716, 4978, 13], "temperature": 0.0, "avg_logprob": -0.24976670300519024, "compression_ratio": 1.7307692307692308, "no_speech_prob": 5.989173814668902e-07}, {"id": 295, "seek": 117560, "start": 1200.28, "end": 1202.84, "text": " And that's a lot of work.", "tokens": [400, 300, 311, 257, 688, 295, 589, 13], "temperature": 0.0, "avg_logprob": -0.24976670300519024, "compression_ratio": 1.7307692307692308, "no_speech_prob": 5.989173814668902e-07}, {"id": 296, "seek": 120284, "start": 1202.84, "end": 1209.0, "text": " So yeah, I should probably scaffold a variance of that for the more complex approach.", "tokens": [407, 1338, 11, 286, 820, 1391, 44094, 257, 21977, 295, 300, 337, 264, 544, 3997, 3109, 13], "temperature": 0.0, "avg_logprob": -0.27400421427789134, "compression_ratio": 1.5570175438596492, "no_speech_prob": 6.681354420834396e-07}, {"id": 297, "seek": 120284, "start": 1209.0, "end": 1212.8, "text": " But again, I would still want to start from scratch because of TDD.", "tokens": [583, 797, 11, 286, 576, 920, 528, 281, 722, 490, 8459, 570, 295, 314, 20818, 13], "temperature": 0.0, "avg_logprob": -0.27400421427789134, "compression_ratio": 1.5570175438596492, "no_speech_prob": 6.681354420834396e-07}, {"id": 298, "seek": 120284, "start": 1212.8, "end": 1213.8, "text": " Interesting.", "tokens": [14711, 13], "temperature": 0.0, "avg_logprob": -0.27400421427789134, "compression_ratio": 1.5570175438596492, "no_speech_prob": 6.681354420834396e-07}, {"id": 299, "seek": 120284, "start": 1213.8, "end": 1217.08, "text": " So like, I'm totally with you on the TDD thing.", "tokens": [407, 411, 11, 286, 478, 3879, 365, 291, 322, 264, 314, 20818, 551, 13], "temperature": 0.0, "avg_logprob": -0.27400421427789134, "compression_ratio": 1.5570175438596492, "no_speech_prob": 6.681354420834396e-07}, {"id": 300, "seek": 120284, "start": 1217.08, "end": 1218.08, "text": " Surprising.", "tokens": [6732, 26203, 13], "temperature": 0.0, "avg_logprob": -0.27400421427789134, "compression_ratio": 1.5570175438596492, "no_speech_prob": 6.681354420834396e-07}, {"id": 301, "seek": 120284, "start": 1218.08, "end": 1224.8799999999999, "text": " I mean, I just brought up TDD because I know you wouldn't be able to contradict me after", "tokens": [286, 914, 11, 286, 445, 3038, 493, 314, 20818, 570, 286, 458, 291, 2759, 380, 312, 1075, 281, 28900, 385, 934], "temperature": 0.0, "avg_logprob": -0.27400421427789134, "compression_ratio": 1.5570175438596492, "no_speech_prob": 6.681354420834396e-07}, {"id": 302, "seek": 120284, "start": 1224.8799999999999, "end": 1225.8799999999999, "text": " that.", "tokens": [300, 13], "temperature": 0.0, "avg_logprob": -0.27400421427789134, "compression_ratio": 1.5570175438596492, "no_speech_prob": 6.681354420834396e-07}, {"id": 303, "seek": 120284, "start": 1225.8799999999999, "end": 1226.8799999999999, "text": " That's right.", "tokens": [663, 311, 558, 13], "temperature": 0.0, "avg_logprob": -0.27400421427789134, "compression_ratio": 1.5570175438596492, "no_speech_prob": 6.681354420834396e-07}, {"id": 304, "seek": 120284, "start": 1226.8799999999999, "end": 1227.8799999999999, "text": " That's right.", "tokens": [663, 311, 558, 13], "temperature": 0.0, "avg_logprob": -0.27400421427789134, "compression_ratio": 1.5570175438596492, "no_speech_prob": 6.681354420834396e-07}, {"id": 305, "seek": 120284, "start": 1227.8799999999999, "end": 1228.8799999999999, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.27400421427789134, "compression_ratio": 1.5570175438596492, "no_speech_prob": 6.681354420834396e-07}, {"id": 306, "seek": 122888, "start": 1228.88, "end": 1234.8000000000002, "text": " So here's the way I would think about this is, and this has been my experience, like", "tokens": [407, 510, 311, 264, 636, 286, 576, 519, 466, 341, 307, 11, 293, 341, 575, 668, 452, 1752, 11, 411], "temperature": 0.0, "avg_logprob": -0.2594487273577348, "compression_ratio": 1.6559633027522935, "no_speech_prob": 4.029389401694061e-06}, {"id": 307, "seek": 122888, "start": 1234.8000000000002, "end": 1239.72, "text": " copy pasting things from Elm review is I'm not copy pasting for the behavior, I'm copy", "tokens": [5055, 1791, 278, 721, 490, 2699, 76, 3131, 307, 286, 478, 406, 5055, 1791, 278, 337, 264, 5223, 11, 286, 478, 5055], "temperature": 0.0, "avg_logprob": -0.2594487273577348, "compression_ratio": 1.6559633027522935, "no_speech_prob": 4.029389401694061e-06}, {"id": 308, "seek": 122888, "start": 1239.72, "end": 1242.5600000000002, "text": " pasting for the wiring and boilerplate.", "tokens": [1791, 278, 337, 264, 27520, 293, 39228, 37008, 13], "temperature": 0.0, "avg_logprob": -0.2594487273577348, "compression_ratio": 1.6559633027522935, "no_speech_prob": 4.029389401694061e-06}, {"id": 309, "seek": 122888, "start": 1242.5600000000002, "end": 1246.88, "text": " So it's like, I need to add some sort of import visitor.", "tokens": [407, 309, 311, 411, 11, 286, 643, 281, 909, 512, 1333, 295, 974, 28222, 13], "temperature": 0.0, "avg_logprob": -0.2594487273577348, "compression_ratio": 1.6559633027522935, "no_speech_prob": 4.029389401694061e-06}, {"id": 310, "seek": 122888, "start": 1246.88, "end": 1253.7, "text": " And it's like, now I'm in my workflow, I'm going to have a failing test that says, whatever,", "tokens": [400, 309, 311, 411, 11, 586, 286, 478, 294, 452, 20993, 11, 286, 478, 516, 281, 362, 257, 18223, 1500, 300, 1619, 11, 2035, 11], "temperature": 0.0, "avg_logprob": -0.2594487273577348, "compression_ratio": 1.6559633027522935, "no_speech_prob": 4.029389401694061e-06}, {"id": 311, "seek": 125370, "start": 1253.7, "end": 1262.24, "text": " this thing that is a contextual thing from the imports, whatever needs to add an import", "tokens": [341, 551, 300, 307, 257, 35526, 551, 490, 264, 41596, 11, 2035, 2203, 281, 909, 364, 974], "temperature": 0.0, "avg_logprob": -0.2577864492041433, "compression_ratio": 1.8368200836820083, "no_speech_prob": 1.1015920335921692e-06}, {"id": 312, "seek": 125370, "start": 1262.24, "end": 1267.72, "text": " expression or it need if it doesn't already exist, I have a failing test that shows that,", "tokens": [6114, 420, 309, 643, 498, 309, 1177, 380, 1217, 2514, 11, 286, 362, 257, 18223, 1500, 300, 3110, 300, 11], "temperature": 0.0, "avg_logprob": -0.2577864492041433, "compression_ratio": 1.8368200836820083, "no_speech_prob": 1.1015920335921692e-06}, {"id": 313, "seek": 125370, "start": 1267.72, "end": 1269.68, "text": " okay, now I have a failing test.", "tokens": [1392, 11, 586, 286, 362, 257, 18223, 1500, 13], "temperature": 0.0, "avg_logprob": -0.2577864492041433, "compression_ratio": 1.8368200836820083, "no_speech_prob": 1.1015920335921692e-06}, {"id": 314, "seek": 125370, "start": 1269.68, "end": 1270.68, "text": " Now what do I do?", "tokens": [823, 437, 360, 286, 360, 30], "temperature": 0.0, "avg_logprob": -0.2577864492041433, "compression_ratio": 1.8368200836820083, "no_speech_prob": 1.1015920335921692e-06}, {"id": 315, "seek": 125370, "start": 1270.68, "end": 1273.24, "text": " I need to add an import visitor.", "tokens": [286, 643, 281, 909, 364, 974, 28222, 13], "temperature": 0.0, "avg_logprob": -0.2577864492041433, "compression_ratio": 1.8368200836820083, "no_speech_prob": 1.1015920335921692e-06}, {"id": 316, "seek": 125370, "start": 1273.24, "end": 1278.4, "text": " Now I need to copy paste something because I just like the functions have a certain set", "tokens": [823, 286, 643, 281, 5055, 9163, 746, 570, 286, 445, 411, 264, 6828, 362, 257, 1629, 992], "temperature": 0.0, "avg_logprob": -0.2577864492041433, "compression_ratio": 1.8368200836820083, "no_speech_prob": 1.1015920335921692e-06}, {"id": 317, "seek": 125370, "start": 1278.4, "end": 1281.44, "text": " of types, it gets wired in in a certain place.", "tokens": [295, 3467, 11, 309, 2170, 27415, 294, 294, 257, 1629, 1081, 13], "temperature": 0.0, "avg_logprob": -0.2577864492041433, "compression_ratio": 1.8368200836820083, "no_speech_prob": 1.1015920335921692e-06}, {"id": 318, "seek": 125370, "start": 1281.44, "end": 1283.0, "text": " I'm just going to go copy paste something.", "tokens": [286, 478, 445, 516, 281, 352, 5055, 9163, 746, 13], "temperature": 0.0, "avg_logprob": -0.2577864492041433, "compression_ratio": 1.8368200836820083, "no_speech_prob": 1.1015920335921692e-06}, {"id": 319, "seek": 128300, "start": 1283.0, "end": 1290.36, "text": " I'm going to go find the with import visitor docs and Elm review, and I'm going to copy", "tokens": [286, 478, 516, 281, 352, 915, 264, 365, 974, 28222, 45623, 293, 2699, 76, 3131, 11, 293, 286, 478, 516, 281, 5055], "temperature": 0.0, "avg_logprob": -0.22450079377164545, "compression_ratio": 1.5726495726495726, "no_speech_prob": 4.181160022653785e-07}, {"id": 320, "seek": 128300, "start": 1290.36, "end": 1291.36, "text": " paste that.", "tokens": [9163, 300, 13], "temperature": 0.0, "avg_logprob": -0.22450079377164545, "compression_ratio": 1.5726495726495726, "no_speech_prob": 4.181160022653785e-07}, {"id": 321, "seek": 128300, "start": 1291.36, "end": 1292.36, "text": " And I think that makes sense.", "tokens": [400, 286, 519, 300, 1669, 2020, 13], "temperature": 0.0, "avg_logprob": -0.22450079377164545, "compression_ratio": 1.5726495726495726, "no_speech_prob": 4.181160022653785e-07}, {"id": 322, "seek": 128300, "start": 1292.36, "end": 1300.08, "text": " I do that as well, quite a lot, especially for the project rules that I mentioned before.", "tokens": [286, 360, 300, 382, 731, 11, 1596, 257, 688, 11, 2318, 337, 264, 1716, 4474, 300, 286, 2835, 949, 13], "temperature": 0.0, "avg_logprob": -0.22450079377164545, "compression_ratio": 1.5726495726495726, "no_speech_prob": 4.181160022653785e-07}, {"id": 323, "seek": 128300, "start": 1300.08, "end": 1306.74, "text": " So I really like no op type boilerplate for that reason, because you can do it effectively", "tokens": [407, 286, 534, 411, 572, 999, 2010, 39228, 37008, 337, 300, 1778, 11, 570, 291, 393, 360, 309, 8659], "temperature": 0.0, "avg_logprob": -0.22450079377164545, "compression_ratio": 1.5726495726495726, "no_speech_prob": 4.181160022653785e-07}, {"id": 324, "seek": 128300, "start": 1306.74, "end": 1310.54, "text": " as like an atomic step that's not changing your behavior.", "tokens": [382, 411, 364, 22275, 1823, 300, 311, 406, 4473, 428, 5223, 13], "temperature": 0.0, "avg_logprob": -0.22450079377164545, "compression_ratio": 1.5726495726495726, "no_speech_prob": 4.181160022653785e-07}, {"id": 325, "seek": 131054, "start": 1310.54, "end": 1316.68, "text": " So it fits in really nicely with TDD where effectively it's just like with TDD as much", "tokens": [407, 309, 9001, 294, 534, 9594, 365, 314, 20818, 689, 8659, 309, 311, 445, 411, 365, 314, 20818, 382, 709], "temperature": 0.0, "avg_logprob": -0.2376031025801555, "compression_ratio": 1.7031963470319635, "no_speech_prob": 2.3823426431590633e-07}, {"id": 326, "seek": 131054, "start": 1316.68, "end": 1319.84, "text": " as possible, you want to work in atomic steps.", "tokens": [382, 1944, 11, 291, 528, 281, 589, 294, 22275, 4439, 13], "temperature": 0.0, "avg_logprob": -0.2376031025801555, "compression_ratio": 1.7031963470319635, "no_speech_prob": 2.3823426431590633e-07}, {"id": 327, "seek": 131054, "start": 1319.84, "end": 1325.1599999999999, "text": " So if you have a green test and you want to refactor something, right?", "tokens": [407, 498, 291, 362, 257, 3092, 1500, 293, 291, 528, 281, 1895, 15104, 746, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2376031025801555, "compression_ratio": 1.7031963470319635, "no_speech_prob": 2.3823426431590633e-07}, {"id": 328, "seek": 131054, "start": 1325.1599999999999, "end": 1329.56, "text": " Well, if you have an automated refactoring, it just, everything is fixed.", "tokens": [1042, 11, 498, 291, 362, 364, 18473, 1895, 578, 3662, 11, 309, 445, 11, 1203, 307, 6806, 13], "temperature": 0.0, "avg_logprob": -0.2376031025801555, "compression_ratio": 1.7031963470319635, "no_speech_prob": 2.3823426431590633e-07}, {"id": 329, "seek": 131054, "start": 1329.56, "end": 1336.8, "text": " If you have a manual refactoring, that's going to at some stage have things in a broken state,", "tokens": [759, 291, 362, 257, 9688, 1895, 578, 3662, 11, 300, 311, 516, 281, 412, 512, 3233, 362, 721, 294, 257, 5463, 1785, 11], "temperature": 0.0, "avg_logprob": -0.2376031025801555, "compression_ratio": 1.7031963470319635, "no_speech_prob": 2.3823426431590633e-07}, {"id": 330, "seek": 133680, "start": 1336.8, "end": 1340.82, "text": " even though conceptually it just belongs as one atomic thing.", "tokens": [754, 1673, 3410, 671, 309, 445, 12953, 382, 472, 22275, 551, 13], "temperature": 0.0, "avg_logprob": -0.20061546901486954, "compression_ratio": 1.6828193832599119, "no_speech_prob": 3.747973948975414e-07}, {"id": 331, "seek": 133680, "start": 1340.82, "end": 1345.22, "text": " So automation can get us closer to this atomic set of steps.", "tokens": [407, 17769, 393, 483, 505, 4966, 281, 341, 22275, 992, 295, 4439, 13], "temperature": 0.0, "avg_logprob": -0.20061546901486954, "compression_ratio": 1.6828193832599119, "no_speech_prob": 3.747973948975414e-07}, {"id": 332, "seek": 133680, "start": 1345.22, "end": 1349.04, "text": " And I think it's the same for like scaffolding, basic wiring.", "tokens": [400, 286, 519, 309, 311, 264, 912, 337, 411, 44094, 278, 11, 3875, 27520, 13], "temperature": 0.0, "avg_logprob": -0.20061546901486954, "compression_ratio": 1.6828193832599119, "no_speech_prob": 3.747973948975414e-07}, {"id": 333, "seek": 133680, "start": 1349.04, "end": 1353.8799999999999, "text": " And I think it's, as you say, for that reason, it's best done as scaffolding out no op type", "tokens": [400, 286, 519, 309, 311, 11, 382, 291, 584, 11, 337, 300, 1778, 11, 309, 311, 1151, 1096, 382, 44094, 278, 484, 572, 999, 2010], "temperature": 0.0, "avg_logprob": -0.20061546901486954, "compression_ratio": 1.6828193832599119, "no_speech_prob": 3.747973948975414e-07}, {"id": 334, "seek": 133680, "start": 1353.8799999999999, "end": 1354.8799999999999, "text": " things.", "tokens": [721, 13], "temperature": 0.0, "avg_logprob": -0.20061546901486954, "compression_ratio": 1.6828193832599119, "no_speech_prob": 3.747973948975414e-07}, {"id": 335, "seek": 133680, "start": 1354.8799999999999, "end": 1355.8799999999999, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.20061546901486954, "compression_ratio": 1.6828193832599119, "no_speech_prob": 3.747973948975414e-07}, {"id": 336, "seek": 133680, "start": 1355.8799999999999, "end": 1362.12, "text": " So, so I do absolutely get the no op operations that you mentioned, but for me, scaffolding", "tokens": [407, 11, 370, 286, 360, 3122, 483, 264, 572, 999, 7705, 300, 291, 2835, 11, 457, 337, 385, 11, 44094, 278], "temperature": 0.0, "avg_logprob": -0.20061546901486954, "compression_ratio": 1.6828193832599119, "no_speech_prob": 3.747973948975414e-07}, {"id": 337, "seek": 136212, "start": 1362.12, "end": 1367.4199999999998, "text": " is usually always either a new file, if we talk about code generation, or if we talk", "tokens": [307, 2673, 1009, 2139, 257, 777, 3991, 11, 498, 321, 751, 466, 3089, 5125, 11, 420, 498, 321, 751], "temperature": 0.0, "avg_logprob": -0.2561287350124783, "compression_ratio": 1.796875, "no_speech_prob": 1.9033622038477915e-06}, {"id": 338, "seek": 136212, "start": 1367.4199999999998, "end": 1376.04, "text": " about code snippets in your editor, for instance, then it's pasting or generating a short piece", "tokens": [466, 3089, 35623, 1385, 294, 428, 9839, 11, 337, 5197, 11, 550, 309, 311, 1791, 278, 420, 17746, 257, 2099, 2522], "temperature": 0.0, "avg_logprob": -0.2561287350124783, "compression_ratio": 1.796875, "no_speech_prob": 1.9033622038477915e-06}, {"id": 339, "seek": 136212, "start": 1376.04, "end": 1377.04, "text": " of code.", "tokens": [295, 3089, 13], "temperature": 0.0, "avg_logprob": -0.2561287350124783, "compression_ratio": 1.796875, "no_speech_prob": 1.9033622038477915e-06}, {"id": 340, "seek": 136212, "start": 1377.04, "end": 1380.86, "text": " So the, the code snippet could be used to do what you just said.", "tokens": [407, 264, 11, 264, 3089, 35623, 302, 727, 312, 1143, 281, 360, 437, 291, 445, 848, 13], "temperature": 0.0, "avg_logprob": -0.2561287350124783, "compression_ratio": 1.796875, "no_speech_prob": 1.9033622038477915e-06}, {"id": 341, "seek": 136212, "start": 1380.86, "end": 1386.4599999999998, "text": " But if you, if you talk about code generation or generate files with code gen or something", "tokens": [583, 498, 291, 11, 498, 291, 751, 466, 3089, 5125, 420, 8460, 7098, 365, 3089, 1049, 420, 746], "temperature": 0.0, "avg_logprob": -0.2561287350124783, "compression_ratio": 1.796875, "no_speech_prob": 1.9033622038477915e-06}, {"id": 342, "seek": 138646, "start": 1386.46, "end": 1392.46, "text": " like that, then you can't just, I don't see how you integrate it into an existing file", "tokens": [411, 300, 11, 550, 291, 393, 380, 445, 11, 286, 500, 380, 536, 577, 291, 13365, 309, 666, 364, 6741, 3991], "temperature": 0.0, "avg_logprob": -0.25417798360188804, "compression_ratio": 1.6328125, "no_speech_prob": 8.059265610427246e-07}, {"id": 343, "seek": 138646, "start": 1392.46, "end": 1393.46, "text": " already.", "tokens": [1217, 13], "temperature": 0.0, "avg_logprob": -0.25417798360188804, "compression_ratio": 1.6328125, "no_speech_prob": 8.059265610427246e-07}, {"id": 344, "seek": 138646, "start": 1393.46, "end": 1395.1000000000001, "text": " Or at least I don't have the tools for that.", "tokens": [1610, 412, 1935, 286, 500, 380, 362, 264, 3873, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.25417798360188804, "compression_ratio": 1.6328125, "no_speech_prob": 8.059265610427246e-07}, {"id": 345, "seek": 138646, "start": 1395.1000000000001, "end": 1396.1000000000001, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.25417798360188804, "compression_ratio": 1.6328125, "no_speech_prob": 8.059265610427246e-07}, {"id": 346, "seek": 138646, "start": 1396.1000000000001, "end": 1397.42, "text": " It's a great, it's a great point.", "tokens": [467, 311, 257, 869, 11, 309, 311, 257, 869, 935, 13], "temperature": 0.0, "avg_logprob": -0.25417798360188804, "compression_ratio": 1.6328125, "no_speech_prob": 8.059265610427246e-07}, {"id": 347, "seek": 138646, "start": 1397.42, "end": 1400.8400000000001, "text": " And I think this is something worth exploring.", "tokens": [400, 286, 519, 341, 307, 746, 3163, 12736, 13], "temperature": 0.0, "avg_logprob": -0.25417798360188804, "compression_ratio": 1.6328125, "no_speech_prob": 8.059265610427246e-07}, {"id": 348, "seek": 138646, "start": 1400.8400000000001, "end": 1407.38, "text": " I think that, you know, maybe, maybe we need some conventions and tools for these types", "tokens": [286, 519, 300, 11, 291, 458, 11, 1310, 11, 1310, 321, 643, 512, 33520, 293, 3873, 337, 613, 3467], "temperature": 0.0, "avg_logprob": -0.25417798360188804, "compression_ratio": 1.6328125, "no_speech_prob": 8.059265610427246e-07}, {"id": 349, "seek": 138646, "start": 1407.38, "end": 1408.38, "text": " of things.", "tokens": [295, 721, 13], "temperature": 0.0, "avg_logprob": -0.25417798360188804, "compression_ratio": 1.6328125, "no_speech_prob": 8.059265610427246e-07}, {"id": 350, "seek": 138646, "start": 1408.38, "end": 1416.22, "text": " So for example, like I can imagine Jasper has this Elm pair tool, which we should probably", "tokens": [407, 337, 1365, 11, 411, 286, 393, 3811, 34023, 610, 575, 341, 2699, 76, 6119, 2290, 11, 597, 321, 820, 1391], "temperature": 0.0, "avg_logprob": -0.25417798360188804, "compression_ratio": 1.6328125, "no_speech_prob": 8.059265610427246e-07}, {"id": 351, "seek": 141622, "start": 1416.22, "end": 1420.02, "text": " dig into at some point, but we'll link to that in the show notes.", "tokens": [2528, 666, 412, 512, 935, 11, 457, 321, 603, 2113, 281, 300, 294, 264, 855, 5570, 13], "temperature": 0.0, "avg_logprob": -0.2459613965905231, "compression_ratio": 1.6398467432950192, "no_speech_prob": 5.9550770856731106e-06}, {"id": 352, "seek": 141622, "start": 1420.02, "end": 1426.58, "text": " But it's kind of built on, on the idea of this workflow, similar to these sort of Elm", "tokens": [583, 309, 311, 733, 295, 3094, 322, 11, 322, 264, 1558, 295, 341, 20993, 11, 2531, 281, 613, 1333, 295, 2699, 76], "temperature": 0.0, "avg_logprob": -0.2459613965905231, "compression_ratio": 1.6398467432950192, "no_speech_prob": 5.9550770856731106e-06}, {"id": 353, "seek": 141622, "start": 1426.58, "end": 1433.2, "text": " format workflows, where it automatically fixes things to do what it thinks you expect by", "tokens": [7877, 43461, 11, 689, 309, 6772, 32539, 721, 281, 360, 437, 309, 7309, 291, 2066, 538], "temperature": 0.0, "avg_logprob": -0.2459613965905231, "compression_ratio": 1.6398467432950192, "no_speech_prob": 5.9550770856731106e-06}, {"id": 354, "seek": 141622, "start": 1433.2, "end": 1437.58, "text": " changing a colon to an equals to make the syntax, right, things like that.", "tokens": [4473, 257, 8255, 281, 364, 6915, 281, 652, 264, 28431, 11, 558, 11, 721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.2459613965905231, "compression_ratio": 1.6398467432950192, "no_speech_prob": 5.9550770856731106e-06}, {"id": 355, "seek": 141622, "start": 1437.58, "end": 1442.6200000000001, "text": " It will, you know, fix your import aliases and things like that based on you just editing", "tokens": [467, 486, 11, 291, 458, 11, 3191, 428, 974, 10198, 1957, 293, 721, 411, 300, 2361, 322, 291, 445, 10000], "temperature": 0.0, "avg_logprob": -0.2459613965905231, "compression_ratio": 1.6398467432950192, "no_speech_prob": 5.9550770856731106e-06}, {"id": 356, "seek": 141622, "start": 1442.6200000000001, "end": 1443.6200000000001, "text": " the code, right?", "tokens": [264, 3089, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2459613965905231, "compression_ratio": 1.6398467432950192, "no_speech_prob": 5.9550770856731106e-06}, {"id": 357, "seek": 141622, "start": 1443.6200000000001, "end": 1444.6200000000001, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2459613965905231, "compression_ratio": 1.6398467432950192, "no_speech_prob": 5.9550770856731106e-06}, {"id": 358, "seek": 144462, "start": 1444.62, "end": 1451.86, "text": " And you could also use GitHub copilot or other GPT AI things in the future, which could do", "tokens": [400, 291, 727, 611, 764, 23331, 2971, 31516, 420, 661, 26039, 51, 7318, 721, 294, 264, 2027, 11, 597, 727, 360], "temperature": 0.0, "avg_logprob": -0.3472354542125355, "compression_ratio": 1.5564516129032258, "no_speech_prob": 3.8069831020948186e-07}, {"id": 359, "seek": 144462, "start": 1451.86, "end": 1452.86, "text": " the same thing.", "tokens": [264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.3472354542125355, "compression_ratio": 1.5564516129032258, "no_speech_prob": 3.8069831020948186e-07}, {"id": 360, "seek": 144462, "start": 1452.86, "end": 1453.9799999999998, "text": " Sure, sure.", "tokens": [4894, 11, 988, 13], "temperature": 0.0, "avg_logprob": -0.3472354542125355, "compression_ratio": 1.5564516129032258, "no_speech_prob": 3.8069831020948186e-07}, {"id": 361, "seek": 144462, "start": 1453.9799999999998, "end": 1460.34, "text": " As always, like with some amount of trust and distrust of the tool of the general code.", "tokens": [1018, 1009, 11, 411, 365, 512, 2372, 295, 3361, 293, 1483, 22326, 295, 264, 2290, 295, 264, 2674, 3089, 13], "temperature": 0.0, "avg_logprob": -0.3472354542125355, "compression_ratio": 1.5564516129032258, "no_speech_prob": 3.8069831020948186e-07}, {"id": 362, "seek": 144462, "start": 1460.34, "end": 1461.34, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.3472354542125355, "compression_ratio": 1.5564516129032258, "no_speech_prob": 3.8069831020948186e-07}, {"id": 363, "seek": 144462, "start": 1461.34, "end": 1462.34, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.3472354542125355, "compression_ratio": 1.5564516129032258, "no_speech_prob": 3.8069831020948186e-07}, {"id": 364, "seek": 144462, "start": 1462.34, "end": 1465.9799999999998, "text": " And you also mentioned a few times on the podcast, and maybe we'll get there at some", "tokens": [400, 291, 611, 2835, 257, 1326, 1413, 322, 264, 7367, 11, 293, 1310, 321, 603, 483, 456, 412, 512], "temperature": 0.0, "avg_logprob": -0.3472354542125355, "compression_ratio": 1.5564516129032258, "no_speech_prob": 3.8069831020948186e-07}, {"id": 365, "seek": 144462, "start": 1465.9799999999998, "end": 1472.5, "text": " point having Elm review be able to pretty much act like a language server.", "tokens": [935, 1419, 2699, 76, 3131, 312, 1075, 281, 1238, 709, 605, 411, 257, 2856, 7154, 13], "temperature": 0.0, "avg_logprob": -0.3472354542125355, "compression_ratio": 1.5564516129032258, "no_speech_prob": 3.8069831020948186e-07}, {"id": 366, "seek": 144462, "start": 1472.5, "end": 1473.5, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.3472354542125355, "compression_ratio": 1.5564516129032258, "no_speech_prob": 3.8069831020948186e-07}, {"id": 367, "seek": 147350, "start": 1473.5, "end": 1477.78, "text": " Or have some kind of tool that allows you to write custom actions.", "tokens": [1610, 362, 512, 733, 295, 2290, 300, 4045, 291, 281, 2464, 2375, 5909, 13], "temperature": 0.0, "avg_logprob": -0.3085256626731471, "compression_ratio": 1.476923076923077, "no_speech_prob": 6.68147094984306e-07}, {"id": 368, "seek": 147350, "start": 1477.78, "end": 1479.78, "text": " Right, right.", "tokens": [1779, 11, 558, 13], "temperature": 0.0, "avg_logprob": -0.3085256626731471, "compression_ratio": 1.476923076923077, "no_speech_prob": 6.68147094984306e-07}, {"id": 369, "seek": 147350, "start": 1479.78, "end": 1480.78, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.3085256626731471, "compression_ratio": 1.476923076923077, "no_speech_prob": 6.68147094984306e-07}, {"id": 370, "seek": 147350, "start": 1480.78, "end": 1487.1, "text": " And, and now the thing is, like, we already have some, some simpler versions of that.", "tokens": [400, 11, 293, 586, 264, 551, 307, 11, 411, 11, 321, 1217, 362, 512, 11, 512, 18587, 9606, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.3085256626731471, "compression_ratio": 1.476923076923077, "no_speech_prob": 6.68147094984306e-07}, {"id": 371, "seek": 147350, "start": 1487.1, "end": 1494.22, "text": " So it's not like a language server that's nicely integrated into editors to expose intentions", "tokens": [407, 309, 311, 406, 411, 257, 2856, 7154, 300, 311, 9594, 10919, 666, 31446, 281, 19219, 19354], "temperature": 0.0, "avg_logprob": -0.3085256626731471, "compression_ratio": 1.476923076923077, "no_speech_prob": 6.68147094984306e-07}, {"id": 372, "seek": 147350, "start": 1494.22, "end": 1496.02, "text": " under your cursor.", "tokens": [833, 428, 28169, 13], "temperature": 0.0, "avg_logprob": -0.3085256626731471, "compression_ratio": 1.476923076923077, "no_speech_prob": 6.68147094984306e-07}, {"id": 373, "seek": 149602, "start": 1496.02, "end": 1503.66, "text": " But you know, my Elm review HTML to Elm package, you can do debug.todo with some HTML with", "tokens": [583, 291, 458, 11, 452, 2699, 76, 3131, 17995, 281, 2699, 76, 7372, 11, 291, 393, 360, 24083, 13, 83, 17423, 365, 512, 17995, 365], "temperature": 0.0, "avg_logprob": -0.2487595608359889, "compression_ratio": 1.6346153846153846, "no_speech_prob": 2.19076036955812e-06}, {"id": 374, "seek": 149602, "start": 1503.66, "end": 1507.98, "text": " a sort of magic debug.todo call.", "tokens": [257, 1333, 295, 5585, 24083, 13, 83, 17423, 818, 13], "temperature": 0.0, "avg_logprob": -0.2487595608359889, "compression_ratio": 1.6346153846153846, "no_speech_prob": 2.19076036955812e-06}, {"id": 375, "seek": 149602, "start": 1507.98, "end": 1513.82, "text": " And it takes that to convert it and to scaffold out some HTML for you.", "tokens": [400, 309, 2516, 300, 281, 7620, 309, 293, 281, 44094, 484, 512, 17995, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.2487595608359889, "compression_ratio": 1.6346153846153846, "no_speech_prob": 2.19076036955812e-06}, {"id": 376, "seek": 149602, "start": 1513.82, "end": 1517.98, "text": " And it sort of intelligent scaffolding because it's aware of context.", "tokens": [400, 309, 1333, 295, 13232, 44094, 278, 570, 309, 311, 3650, 295, 4319, 13], "temperature": 0.0, "avg_logprob": -0.2487595608359889, "compression_ratio": 1.6346153846153846, "no_speech_prob": 2.19076036955812e-06}, {"id": 377, "seek": 149602, "start": 1517.98, "end": 1519.82, "text": " And so we can use similar patterns.", "tokens": [400, 370, 321, 393, 764, 2531, 8294, 13], "temperature": 0.0, "avg_logprob": -0.2487595608359889, "compression_ratio": 1.6346153846153846, "no_speech_prob": 2.19076036955812e-06}, {"id": 378, "seek": 149602, "start": 1519.82, "end": 1522.3799999999999, "text": " So you could imagine a similar pattern.", "tokens": [407, 291, 727, 3811, 257, 2531, 5102, 13], "temperature": 0.0, "avg_logprob": -0.2487595608359889, "compression_ratio": 1.6346153846153846, "no_speech_prob": 2.19076036955812e-06}, {"id": 379, "seek": 152238, "start": 1522.38, "end": 1529.18, "text": " You know, and Martin Stewart has, like a similar sort of unpublished tool, but he's worked", "tokens": [509, 458, 11, 293, 9184, 25951, 575, 11, 411, 257, 2531, 1333, 295, 20994, 836, 4173, 2290, 11, 457, 415, 311, 2732], "temperature": 0.0, "avg_logprob": -0.3152344043438251, "compression_ratio": 1.4563106796116505, "no_speech_prob": 8.851482107274933e-07}, {"id": 380, "seek": 152238, "start": 1529.18, "end": 1534.5, "text": " on this Elm review to do it for me.", "tokens": [322, 341, 2699, 76, 3131, 281, 360, 309, 337, 385, 13], "temperature": 0.0, "avg_logprob": -0.3152344043438251, "compression_ratio": 1.4563106796116505, "no_speech_prob": 8.851482107274933e-07}, {"id": 381, "seek": 152238, "start": 1534.5, "end": 1539.3400000000001, "text": " Tool that sort of helps you scaffold out decoders and things like that based on these magic", "tokens": [15934, 300, 1333, 295, 3665, 291, 44094, 484, 979, 378, 433, 293, 721, 411, 300, 2361, 322, 613, 5585], "temperature": 0.0, "avg_logprob": -0.3152344043438251, "compression_ratio": 1.4563106796116505, "no_speech_prob": 8.851482107274933e-07}, {"id": 382, "seek": 152238, "start": 1539.3400000000001, "end": 1541.14, "text": " debug.todo calls.", "tokens": [24083, 13, 83, 17423, 5498, 13], "temperature": 0.0, "avg_logprob": -0.3152344043438251, "compression_ratio": 1.4563106796116505, "no_speech_prob": 8.851482107274933e-07}, {"id": 383, "seek": 152238, "start": 1541.14, "end": 1546.3400000000001, "text": " Alex Corbin has an Elm review rule for JSON to Elm.", "tokens": [5202, 3925, 13496, 575, 364, 2699, 76, 3131, 4978, 337, 31828, 281, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.3152344043438251, "compression_ratio": 1.4563106796116505, "no_speech_prob": 8.851482107274933e-07}, {"id": 384, "seek": 152238, "start": 1546.3400000000001, "end": 1548.3400000000001, "text": " Yes, right.", "tokens": [1079, 11, 558, 13], "temperature": 0.0, "avg_logprob": -0.3152344043438251, "compression_ratio": 1.4563106796116505, "no_speech_prob": 8.851482107274933e-07}, {"id": 385, "seek": 154834, "start": 1548.34, "end": 1553.9399999999998, "text": " Martin Stewart did some things similar to that and others, but yeah, not published.", "tokens": [9184, 25951, 630, 512, 721, 2531, 281, 300, 293, 2357, 11, 457, 1338, 11, 406, 6572, 13], "temperature": 0.0, "avg_logprob": -0.24600270011208275, "compression_ratio": 1.64, "no_speech_prob": 7.4096205935347825e-06}, {"id": 386, "seek": 154834, "start": 1553.9399999999998, "end": 1560.54, "text": " Yeah, I originally got that idea of that pattern from Martin Stewart and used that idea to", "tokens": [865, 11, 286, 7993, 658, 300, 1558, 295, 300, 5102, 490, 9184, 25951, 293, 1143, 300, 1558, 281], "temperature": 0.0, "avg_logprob": -0.24600270011208275, "compression_ratio": 1.64, "no_speech_prob": 7.4096205935347825e-06}, {"id": 387, "seek": 154834, "start": 1560.54, "end": 1561.86, "text": " for Elm review HTML to Elm.", "tokens": [337, 2699, 76, 3131, 17995, 281, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.24600270011208275, "compression_ratio": 1.64, "no_speech_prob": 7.4096205935347825e-06}, {"id": 388, "seek": 154834, "start": 1561.86, "end": 1567.3, "text": " And like, so that's a, like, that's kind of a cool pattern.", "tokens": [400, 411, 11, 370, 300, 311, 257, 11, 411, 11, 300, 311, 733, 295, 257, 1627, 5102, 13], "temperature": 0.0, "avg_logprob": -0.24600270011208275, "compression_ratio": 1.64, "no_speech_prob": 7.4096205935347825e-06}, {"id": 389, "seek": 154834, "start": 1567.3, "end": 1572.52, "text": " And you could even imagine having, for example, like, to be honest, I haven't integrated a", "tokens": [400, 291, 727, 754, 3811, 1419, 11, 337, 1365, 11, 411, 11, 281, 312, 3245, 11, 286, 2378, 380, 10919, 257], "temperature": 0.0, "avg_logprob": -0.24600270011208275, "compression_ratio": 1.64, "no_speech_prob": 7.4096205935347825e-06}, {"id": 390, "seek": 154834, "start": 1572.52, "end": 1576.58, "text": " workflow like this myself, but I think it could be cool.", "tokens": [20993, 411, 341, 2059, 11, 457, 286, 519, 309, 727, 312, 1627, 13], "temperature": 0.0, "avg_logprob": -0.24600270011208275, "compression_ratio": 1.64, "no_speech_prob": 7.4096205935347825e-06}, {"id": 391, "seek": 157658, "start": 1576.58, "end": 1580.54, "text": " What if we have a bunch of these sort of scaffolding Elm review rules?", "tokens": [708, 498, 321, 362, 257, 3840, 295, 613, 1333, 295, 44094, 278, 2699, 76, 3131, 4474, 30], "temperature": 0.0, "avg_logprob": -0.26096487536872787, "compression_ratio": 1.8502415458937198, "no_speech_prob": 1.0030046269093873e-06}, {"id": 392, "seek": 157658, "start": 1580.54, "end": 1584.6999999999998, "text": " You could even have like a special review scaffolding folder, right?", "tokens": [509, 727, 754, 362, 411, 257, 2121, 3131, 44094, 278, 10820, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.26096487536872787, "compression_ratio": 1.8502415458937198, "no_speech_prob": 1.0030046269093873e-06}, {"id": 393, "seek": 157658, "start": 1584.6999999999998, "end": 1590.86, "text": " So a normal Elm review folder by convention is in./.review.", "tokens": [407, 257, 2710, 2699, 76, 3131, 10820, 538, 10286, 307, 294, 2411, 48550, 265, 1759, 13], "temperature": 0.0, "avg_logprob": -0.26096487536872787, "compression_ratio": 1.8502415458937198, "no_speech_prob": 1.0030046269093873e-06}, {"id": 394, "seek": 157658, "start": 1590.86, "end": 1597.54, "text": " Well you could have like a separate review config with your scaffolding ones for scaffolding", "tokens": [1042, 291, 727, 362, 411, 257, 4994, 3131, 6662, 365, 428, 44094, 278, 2306, 337, 44094, 278], "temperature": 0.0, "avg_logprob": -0.26096487536872787, "compression_ratio": 1.8502415458937198, "no_speech_prob": 1.0030046269093873e-06}, {"id": 395, "seek": 157658, "start": 1597.54, "end": 1604.74, "text": " out decoders, HTML, helping you scaffold out Elm review rule helpers, helping you scaffold", "tokens": [484, 979, 378, 433, 11, 17995, 11, 4315, 291, 44094, 484, 2699, 76, 3131, 4978, 854, 433, 11, 4315, 291, 44094], "temperature": 0.0, "avg_logprob": -0.26096487536872787, "compression_ratio": 1.8502415458937198, "no_speech_prob": 1.0030046269093873e-06}, {"id": 396, "seek": 160474, "start": 1604.74, "end": 1610.18, "text": " out Elm pages forms, you know, the sky's the limit.", "tokens": [484, 2699, 76, 7183, 6422, 11, 291, 458, 11, 264, 5443, 311, 264, 4948, 13], "temperature": 0.0, "avg_logprob": -0.28540834105841006, "compression_ratio": 1.5274261603375527, "no_speech_prob": 1.154454253082804e-06}, {"id": 397, "seek": 160474, "start": 1610.18, "end": 1615.74, "text": " And then have that running in the background in watch mode in auto fix mode.", "tokens": [400, 550, 362, 300, 2614, 294, 264, 3678, 294, 1159, 4391, 294, 8399, 3191, 4391, 13], "temperature": 0.0, "avg_logprob": -0.28540834105841006, "compression_ratio": 1.5274261603375527, "no_speech_prob": 1.154454253082804e-06}, {"id": 398, "seek": 160474, "start": 1615.74, "end": 1617.94, "text": " That could be really cool, right?", "tokens": [663, 727, 312, 534, 1627, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.28540834105841006, "compression_ratio": 1.5274261603375527, "no_speech_prob": 1.154454253082804e-06}, {"id": 399, "seek": 160474, "start": 1617.94, "end": 1623.66, "text": " Yeah, or with a nice integration with the editor, which is currently a little bit lacking,", "tokens": [865, 11, 420, 365, 257, 1481, 10980, 365, 264, 9839, 11, 597, 307, 4362, 257, 707, 857, 20889, 11], "temperature": 0.0, "avg_logprob": -0.28540834105841006, "compression_ratio": 1.5274261603375527, "no_speech_prob": 1.154454253082804e-06}, {"id": 400, "seek": 160474, "start": 1623.66, "end": 1624.66, "text": " but yeah.", "tokens": [457, 1338, 13], "temperature": 0.0, "avg_logprob": -0.28540834105841006, "compression_ratio": 1.5274261603375527, "no_speech_prob": 1.154454253082804e-06}, {"id": 401, "seek": 160474, "start": 1624.66, "end": 1625.66, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.28540834105841006, "compression_ratio": 1.5274261603375527, "no_speech_prob": 1.154454253082804e-06}, {"id": 402, "seek": 160474, "start": 1625.66, "end": 1632.18, "text": " And I think that this is actually a very nice progression to, you know, sort of do the 8020", "tokens": [400, 286, 519, 300, 341, 307, 767, 257, 588, 1481, 18733, 281, 11, 291, 458, 11, 1333, 295, 360, 264, 4688, 2009], "temperature": 0.0, "avg_logprob": -0.28540834105841006, "compression_ratio": 1.5274261603375527, "no_speech_prob": 1.154454253082804e-06}, {"id": 403, "seek": 163218, "start": 1632.18, "end": 1638.6200000000001, "text": " version of it where you don't have to build a fancy thing that gives you options from", "tokens": [3037, 295, 309, 689, 291, 500, 380, 362, 281, 1322, 257, 10247, 551, 300, 2709, 291, 3956, 490], "temperature": 0.0, "avg_logprob": -0.2301862890070135, "compression_ratio": 1.6172248803827751, "no_speech_prob": 1.7603209698791034e-06}, {"id": 404, "seek": 163218, "start": 1638.6200000000001, "end": 1645.66, "text": " under the cursor and you just use debug.todo to have valid syntax, but give a special keyword", "tokens": [833, 264, 28169, 293, 291, 445, 764, 24083, 13, 83, 17423, 281, 362, 7363, 28431, 11, 457, 976, 257, 2121, 20428], "temperature": 0.0, "avg_logprob": -0.2301862890070135, "compression_ratio": 1.6172248803827751, "no_speech_prob": 1.7603209698791034e-06}, {"id": 405, "seek": 163218, "start": 1645.66, "end": 1651.5800000000002, "text": " within the string in the debug.todo that Elm review interprets.", "tokens": [1951, 264, 6798, 294, 264, 24083, 13, 83, 17423, 300, 2699, 76, 3131, 17489, 1373, 13], "temperature": 0.0, "avg_logprob": -0.2301862890070135, "compression_ratio": 1.6172248803827751, "no_speech_prob": 1.7603209698791034e-06}, {"id": 406, "seek": 163218, "start": 1651.5800000000002, "end": 1657.1000000000001, "text": " I mean, you would probably have a code snippet that creates a debug.todo with the right thing,", "tokens": [286, 914, 11, 291, 576, 1391, 362, 257, 3089, 35623, 302, 300, 7829, 257, 24083, 13, 83, 17423, 365, 264, 558, 551, 11], "temperature": 0.0, "avg_logprob": -0.2301862890070135, "compression_ratio": 1.6172248803827751, "no_speech_prob": 1.7603209698791034e-06}, {"id": 407, "seek": 165710, "start": 1657.1, "end": 1662.62, "text": " and then you place part of it and then you would have Elm review.", "tokens": [293, 550, 291, 1081, 644, 295, 309, 293, 550, 291, 576, 362, 2699, 76, 3131, 13], "temperature": 0.0, "avg_logprob": -0.27620971808999273, "compression_ratio": 1.7095435684647302, "no_speech_prob": 3.2887062388908817e-06}, {"id": 408, "seek": 165710, "start": 1662.62, "end": 1664.02, "text": " That's an amazing idea too.", "tokens": [663, 311, 364, 2243, 1558, 886, 13], "temperature": 0.0, "avg_logprob": -0.27620971808999273, "compression_ratio": 1.7095435684647302, "no_speech_prob": 3.2887062388908817e-06}, {"id": 409, "seek": 165710, "start": 1664.02, "end": 1665.02, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.27620971808999273, "compression_ratio": 1.7095435684647302, "no_speech_prob": 3.2887062388908817e-06}, {"id": 410, "seek": 165710, "start": 1665.02, "end": 1670.02, "text": " So like, I think it would be really cool to have like, let's say like import visitor,", "tokens": [407, 411, 11, 286, 519, 309, 576, 312, 534, 1627, 281, 362, 411, 11, 718, 311, 584, 411, 974, 28222, 11], "temperature": 0.0, "avg_logprob": -0.27620971808999273, "compression_ratio": 1.7095435684647302, "no_speech_prob": 3.2887062388908817e-06}, {"id": 411, "seek": 165710, "start": 1670.02, "end": 1675.9399999999998, "text": " you know, what if, and see, here's the thing is like, like Elm review, the actual Elm review", "tokens": [291, 458, 11, 437, 498, 11, 293, 536, 11, 510, 311, 264, 551, 307, 411, 11, 411, 2699, 76, 3131, 11, 264, 3539, 2699, 76, 3131], "temperature": 0.0, "avg_logprob": -0.27620971808999273, "compression_ratio": 1.7095435684647302, "no_speech_prob": 3.2887062388908817e-06}, {"id": 412, "seek": 165710, "start": 1675.9399999999998, "end": 1682.3799999999999, "text": " package could even ship some of these either scaffolding helpers for like Elm code gen", "tokens": [7372, 727, 754, 5374, 512, 295, 613, 2139, 44094, 278, 854, 433, 337, 411, 2699, 76, 3089, 1049], "temperature": 0.0, "avg_logprob": -0.27620971808999273, "compression_ratio": 1.7095435684647302, "no_speech_prob": 3.2887062388908817e-06}, {"id": 413, "seek": 165710, "start": 1682.3799999999999, "end": 1685.06, "text": " stuff to help with this or an Elm review rule.", "tokens": [1507, 281, 854, 365, 341, 420, 364, 2699, 76, 3131, 4978, 13], "temperature": 0.0, "avg_logprob": -0.27620971808999273, "compression_ratio": 1.7095435684647302, "no_speech_prob": 3.2887062388908817e-06}, {"id": 414, "seek": 168506, "start": 1685.06, "end": 1692.74, "text": " Now that's meta if Elm review ships Elm review rules to help you generate Elm review rules.", "tokens": [823, 300, 311, 19616, 498, 2699, 76, 3131, 11434, 2699, 76, 3131, 4474, 281, 854, 291, 8460, 2699, 76, 3131, 4474, 13], "temperature": 0.0, "avg_logprob": -0.3294532049269903, "compression_ratio": 1.7114427860696517, "no_speech_prob": 3.5208907434025605e-07}, {"id": 415, "seek": 168506, "start": 1692.74, "end": 1699.1799999999998, "text": " You mean instead of having Elm review rules for reviewing Elm review rules, which is,", "tokens": [509, 914, 2602, 295, 1419, 2699, 76, 3131, 4474, 337, 19576, 2699, 76, 3131, 4474, 11, 597, 307, 11], "temperature": 0.0, "avg_logprob": -0.3294532049269903, "compression_ratio": 1.7114427860696517, "no_speech_prob": 3.5208907434025605e-07}, {"id": 416, "seek": 168506, "start": 1699.1799999999998, "end": 1702.58, "text": " is probably going to happen at some point, to be honest.", "tokens": [307, 1391, 516, 281, 1051, 412, 512, 935, 11, 281, 312, 3245, 13], "temperature": 0.0, "avg_logprob": -0.3294532049269903, "compression_ratio": 1.7114427860696517, "no_speech_prob": 3.5208907434025605e-07}, {"id": 417, "seek": 168506, "start": 1702.58, "end": 1703.82, "text": " The snake eating its tail.", "tokens": [440, 12650, 3936, 1080, 6838, 13], "temperature": 0.0, "avg_logprob": -0.3294532049269903, "compression_ratio": 1.7114427860696517, "no_speech_prob": 3.5208907434025605e-07}, {"id": 418, "seek": 168506, "start": 1703.82, "end": 1704.82, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.3294532049269903, "compression_ratio": 1.7114427860696517, "no_speech_prob": 3.5208907434025605e-07}, {"id": 419, "seek": 168506, "start": 1704.82, "end": 1705.82, "text": " I love it.", "tokens": [286, 959, 309, 13], "temperature": 0.0, "avg_logprob": -0.3294532049269903, "compression_ratio": 1.7114427860696517, "no_speech_prob": 3.5208907434025605e-07}, {"id": 420, "seek": 168506, "start": 1705.82, "end": 1706.82, "text": " I love it.", "tokens": [286, 959, 309, 13], "temperature": 0.0, "avg_logprob": -0.3294532049269903, "compression_ratio": 1.7114427860696517, "no_speech_prob": 3.5208907434025605e-07}, {"id": 421, "seek": 168506, "start": 1706.82, "end": 1710.3, "text": " We can add steps to it if you want.", "tokens": [492, 393, 909, 4439, 281, 309, 498, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.3294532049269903, "compression_ratio": 1.7114427860696517, "no_speech_prob": 3.5208907434025605e-07}, {"id": 422, "seek": 168506, "start": 1710.3, "end": 1711.3, "text": " Who needs copilot?", "tokens": [2102, 2203, 2971, 31516, 30], "temperature": 0.0, "avg_logprob": -0.3294532049269903, "compression_ratio": 1.7114427860696517, "no_speech_prob": 3.5208907434025605e-07}, {"id": 423, "seek": 171130, "start": 1711.3, "end": 1717.8999999999999, "text": " We're going to have Elm review rules to review scaffolding tools for Elm review.", "tokens": [492, 434, 516, 281, 362, 2699, 76, 3131, 4474, 281, 3131, 44094, 278, 3873, 337, 2699, 76, 3131, 13], "temperature": 0.0, "avg_logprob": -0.2759228308223984, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.4060825580818346e-06}, {"id": 424, "seek": 171130, "start": 1717.8999999999999, "end": 1718.8999999999999, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.2759228308223984, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.4060825580818346e-06}, {"id": 425, "seek": 171130, "start": 1718.8999999999999, "end": 1724.7, "text": " That generates Elm review rules to, and then this circle is.", "tokens": [663, 23815, 2699, 76, 3131, 4474, 281, 11, 293, 550, 341, 6329, 307, 13], "temperature": 0.0, "avg_logprob": -0.2759228308223984, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.4060825580818346e-06}, {"id": 426, "seek": 171130, "start": 1724.7, "end": 1730.82, "text": " I did use Elm review HTML to Elm to build Elm review HTML to Elm.", "tokens": [286, 630, 764, 2699, 76, 3131, 17995, 281, 2699, 76, 281, 1322, 2699, 76, 3131, 17995, 281, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.2759228308223984, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.4060825580818346e-06}, {"id": 427, "seek": 171130, "start": 1730.82, "end": 1732.3, "text": " The website version.", "tokens": [440, 3144, 3037, 13], "temperature": 0.0, "avg_logprob": -0.2759228308223984, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.4060825580818346e-06}, {"id": 428, "seek": 171130, "start": 1732.3, "end": 1736.86, "text": " There's like a site that you can paste the code into and I definitely used it to build", "tokens": [821, 311, 411, 257, 3621, 300, 291, 393, 9163, 264, 3089, 666, 293, 286, 2138, 1143, 309, 281, 1322], "temperature": 0.0, "avg_logprob": -0.2759228308223984, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.4060825580818346e-06}, {"id": 429, "seek": 171130, "start": 1736.86, "end": 1737.86, "text": " itself.", "tokens": [2564, 13], "temperature": 0.0, "avg_logprob": -0.2759228308223984, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.4060825580818346e-06}, {"id": 430, "seek": 171130, "start": 1737.86, "end": 1738.86, "text": " So that's good.", "tokens": [407, 300, 311, 665, 13], "temperature": 0.0, "avg_logprob": -0.2759228308223984, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.4060825580818346e-06}, {"id": 431, "seek": 173886, "start": 1738.86, "end": 1744.34, "text": " Gotta love a good bootstrapping story, but, um, and, and I mean, I made Elm review and", "tokens": [21527, 959, 257, 665, 11450, 19639, 3759, 1657, 11, 457, 11, 1105, 11, 293, 11, 293, 286, 914, 11, 286, 1027, 2699, 76, 3131, 293], "temperature": 0.0, "avg_logprob": -0.3097213081691576, "compression_ratio": 1.5108225108225108, "no_speech_prob": 2.918915811278566e-07}, {"id": 432, "seek": 173886, "start": 1744.34, "end": 1748.9799999999998, "text": " since then I have not made much with it.", "tokens": [1670, 550, 286, 362, 406, 1027, 709, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.3097213081691576, "compression_ratio": 1.5108225108225108, "no_speech_prob": 2.918915811278566e-07}, {"id": 433, "seek": 173886, "start": 1748.9799999999998, "end": 1757.9799999999998, "text": " No, I do use it at work, but yeah, maybe one day I will start custom projects.", "tokens": [883, 11, 286, 360, 764, 309, 412, 589, 11, 457, 1338, 11, 1310, 472, 786, 286, 486, 722, 2375, 4455, 13], "temperature": 0.0, "avg_logprob": -0.3097213081691576, "compression_ratio": 1.5108225108225108, "no_speech_prob": 2.918915811278566e-07}, {"id": 434, "seek": 173886, "start": 1757.9799999999998, "end": 1759.3799999999999, "text": " Probably an Elm review website.", "tokens": [9210, 364, 2699, 76, 3131, 3144, 13], "temperature": 0.0, "avg_logprob": -0.3097213081691576, "compression_ratio": 1.5108225108225108, "no_speech_prob": 2.918915811278566e-07}, {"id": 435, "seek": 173886, "start": 1759.3799999999999, "end": 1760.3799999999999, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.3097213081691576, "compression_ratio": 1.5108225108225108, "no_speech_prob": 2.918915811278566e-07}, {"id": 436, "seek": 173886, "start": 1760.3799999999999, "end": 1761.3799999999999, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.3097213081691576, "compression_ratio": 1.5108225108225108, "no_speech_prob": 2.918915811278566e-07}, {"id": 437, "seek": 173886, "start": 1761.3799999999999, "end": 1762.3799999999999, "text": " One day.", "tokens": [1485, 786, 13], "temperature": 0.0, "avg_logprob": -0.3097213081691576, "compression_ratio": 1.5108225108225108, "no_speech_prob": 2.918915811278566e-07}, {"id": 438, "seek": 173886, "start": 1762.3799999999999, "end": 1763.3799999999999, "text": " And a scaffolding helper.", "tokens": [400, 257, 44094, 278, 36133, 13], "temperature": 0.0, "avg_logprob": -0.3097213081691576, "compression_ratio": 1.5108225108225108, "no_speech_prob": 2.918915811278566e-07}, {"id": 439, "seek": 173886, "start": 1763.3799999999999, "end": 1764.3799999999999, "text": " I think it would be great.", "tokens": [286, 519, 309, 576, 312, 869, 13], "temperature": 0.0, "avg_logprob": -0.3097213081691576, "compression_ratio": 1.5108225108225108, "no_speech_prob": 2.918915811278566e-07}, {"id": 440, "seek": 173886, "start": 1764.3799999999999, "end": 1767.1399999999999, "text": " Like, so I think I like this pattern.", "tokens": [1743, 11, 370, 286, 519, 286, 411, 341, 5102, 13], "temperature": 0.0, "avg_logprob": -0.3097213081691576, "compression_ratio": 1.5108225108225108, "no_speech_prob": 2.918915811278566e-07}, {"id": 441, "seek": 176714, "start": 1767.14, "end": 1772.0200000000002, "text": " I think, I think I'm a fan of this idea that we've just developed here.", "tokens": [286, 519, 11, 286, 519, 286, 478, 257, 3429, 295, 341, 1558, 300, 321, 600, 445, 4743, 510, 13], "temperature": 0.0, "avg_logprob": -0.267201765528265, "compression_ratio": 1.5614035087719298, "no_speech_prob": 7.224268188110727e-07}, {"id": 442, "seek": 176714, "start": 1772.0200000000002, "end": 1775.26, "text": " You heard it here, folks.", "tokens": [509, 2198, 309, 510, 11, 4024, 13], "temperature": 0.0, "avg_logprob": -0.267201765528265, "compression_ratio": 1.5614035087719298, "no_speech_prob": 7.224268188110727e-07}, {"id": 443, "seek": 176714, "start": 1775.26, "end": 1778.1000000000001, "text": " And then it never happened.", "tokens": [400, 550, 309, 1128, 2011, 13], "temperature": 0.0, "avg_logprob": -0.267201765528265, "compression_ratio": 1.5614035087719298, "no_speech_prob": 7.224268188110727e-07}, {"id": 444, "seek": 176714, "start": 1778.1000000000001, "end": 1779.9, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.267201765528265, "compression_ratio": 1.5614035087719298, "no_speech_prob": 7.224268188110727e-07}, {"id": 445, "seek": 176714, "start": 1779.9, "end": 1785.22, "text": " So you see some value and I mean, I, me too, but you see some value in having scaffolding", "tokens": [407, 291, 536, 512, 2158, 293, 286, 914, 11, 286, 11, 385, 886, 11, 457, 291, 536, 512, 2158, 294, 1419, 44094, 278], "temperature": 0.0, "avg_logprob": -0.267201765528265, "compression_ratio": 1.5614035087719298, "no_speech_prob": 7.224268188110727e-07}, {"id": 446, "seek": 176714, "start": 1785.22, "end": 1789.1000000000001, "text": " tools to help you with tasks that you do a lot.", "tokens": [3873, 281, 854, 291, 365, 9608, 300, 291, 360, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.267201765528265, "compression_ratio": 1.5614035087719298, "no_speech_prob": 7.224268188110727e-07}, {"id": 447, "seek": 176714, "start": 1789.1000000000001, "end": 1796.7, "text": " Small tasks with things like HTML to Elm or bootstrapping tasks, like a new route or a", "tokens": [15287, 9608, 365, 721, 411, 17995, 281, 2699, 76, 420, 11450, 19639, 3759, 9608, 11, 411, 257, 777, 7955, 420, 257], "temperature": 0.0, "avg_logprob": -0.267201765528265, "compression_ratio": 1.5614035087719298, "no_speech_prob": 7.224268188110727e-07}, {"id": 448, "seek": 179670, "start": 1796.7, "end": 1799.5, "text": " new rule, that kind of thing.", "tokens": [777, 4978, 11, 300, 733, 295, 551, 13], "temperature": 0.0, "avg_logprob": -0.25739344546669407, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.6280212093988666e-06}, {"id": 449, "seek": 179670, "start": 1799.5, "end": 1806.6200000000001, "text": " How do you identify what you need or when a scaffolding would be a good tool and where", "tokens": [1012, 360, 291, 5876, 437, 291, 643, 420, 562, 257, 44094, 278, 576, 312, 257, 665, 2290, 293, 689], "temperature": 0.0, "avg_logprob": -0.25739344546669407, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.6280212093988666e-06}, {"id": 450, "seek": 179670, "start": 1806.6200000000001, "end": 1810.38, "text": " it would be worth the investment mostly?", "tokens": [309, 576, 312, 3163, 264, 6078, 5240, 30], "temperature": 0.0, "avg_logprob": -0.25739344546669407, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.6280212093988666e-06}, {"id": 451, "seek": 179670, "start": 1810.38, "end": 1814.82, "text": " Because I mean, copy pasting is still an option or rewriting everything from scratch is still", "tokens": [1436, 286, 914, 11, 5055, 1791, 278, 307, 920, 364, 3614, 420, 319, 19868, 1203, 490, 8459, 307, 920], "temperature": 0.0, "avg_logprob": -0.25739344546669407, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.6280212093988666e-06}, {"id": 452, "seek": 179670, "start": 1814.82, "end": 1816.22, "text": " an option.", "tokens": [364, 3614, 13], "temperature": 0.0, "avg_logprob": -0.25739344546669407, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.6280212093988666e-06}, {"id": 453, "seek": 179670, "start": 1816.22, "end": 1820.64, "text": " And for the fair short run, there's always going to be faster.", "tokens": [400, 337, 264, 3143, 2099, 1190, 11, 456, 311, 1009, 516, 281, 312, 4663, 13], "temperature": 0.0, "avg_logprob": -0.25739344546669407, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.6280212093988666e-06}, {"id": 454, "seek": 179670, "start": 1820.64, "end": 1823.3400000000001, "text": " So how do you identify those?", "tokens": [407, 577, 360, 291, 5876, 729, 30], "temperature": 0.0, "avg_logprob": -0.25739344546669407, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.6280212093988666e-06}, {"id": 455, "seek": 182334, "start": 1823.34, "end": 1827.4599999999998, "text": " And we can talk later about how do we know what to generate?", "tokens": [400, 321, 393, 751, 1780, 466, 577, 360, 321, 458, 437, 281, 8460, 30], "temperature": 0.0, "avg_logprob": -0.2598905762036641, "compression_ratio": 1.6, "no_speech_prob": 6.475891609625251e-07}, {"id": 456, "seek": 182334, "start": 1827.4599999999998, "end": 1828.4599999999998, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.2598905762036641, "compression_ratio": 1.6, "no_speech_prob": 6.475891609625251e-07}, {"id": 457, "seek": 182334, "start": 1828.4599999999998, "end": 1835.82, "text": " I think it's, I think it's kind of similar to Jeroen's hierarchy of constraints where,", "tokens": [286, 519, 309, 311, 11, 286, 519, 309, 311, 733, 295, 2531, 281, 508, 2032, 268, 311, 22333, 295, 18491, 689, 11], "temperature": 0.0, "avg_logprob": -0.2598905762036641, "compression_ratio": 1.6, "no_speech_prob": 6.475891609625251e-07}, {"id": 458, "seek": 182334, "start": 1835.82, "end": 1841.9399999999998, "text": " so like, if you can make impossible states impossible, then you should do that.", "tokens": [370, 411, 11, 498, 291, 393, 652, 6243, 4368, 6243, 11, 550, 291, 820, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.2598905762036641, "compression_ratio": 1.6, "no_speech_prob": 6.475891609625251e-07}, {"id": 459, "seek": 182334, "start": 1841.9399999999998, "end": 1846.58, "text": " Don't write an Elm review rule to give guarantees that the compiler, that you can use the compiler", "tokens": [1468, 380, 2464, 364, 2699, 76, 3131, 4978, 281, 976, 32567, 300, 264, 31958, 11, 300, 291, 393, 764, 264, 31958], "temperature": 0.0, "avg_logprob": -0.2598905762036641, "compression_ratio": 1.6, "no_speech_prob": 6.475891609625251e-07}, {"id": 460, "seek": 182334, "start": 1846.58, "end": 1848.1799999999998, "text": " to directly give you that.", "tokens": [281, 3838, 976, 291, 300, 13], "temperature": 0.0, "avg_logprob": -0.2598905762036641, "compression_ratio": 1.6, "no_speech_prob": 6.475891609625251e-07}, {"id": 461, "seek": 184818, "start": 1848.18, "end": 1853.26, "text": " Like yes, Elm review rules are great, but they're there when you need them because the", "tokens": [1743, 2086, 11, 2699, 76, 3131, 4474, 366, 869, 11, 457, 436, 434, 456, 562, 291, 643, 552, 570, 264], "temperature": 0.0, "avg_logprob": -0.24264732103669243, "compression_ratio": 1.5660377358490567, "no_speech_prob": 1.7330164610029897e-06}, {"id": 462, "seek": 184818, "start": 1853.26, "end": 1855.22, "text": " compiler can't give you that.", "tokens": [31958, 393, 380, 976, 291, 300, 13], "temperature": 0.0, "avg_logprob": -0.24264732103669243, "compression_ratio": 1.5660377358490567, "no_speech_prob": 1.7330164610029897e-06}, {"id": 463, "seek": 184818, "start": 1855.22, "end": 1856.22, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.24264732103669243, "compression_ratio": 1.5660377358490567, "no_speech_prob": 1.7330164610029897e-06}, {"id": 464, "seek": 184818, "start": 1856.22, "end": 1863.1000000000001, "text": " So it should, you should go up, up the pyramid, start with the most robust way of doing it", "tokens": [407, 309, 820, 11, 291, 820, 352, 493, 11, 493, 264, 25950, 11, 722, 365, 264, 881, 13956, 636, 295, 884, 309], "temperature": 0.0, "avg_logprob": -0.24264732103669243, "compression_ratio": 1.5660377358490567, "no_speech_prob": 1.7330164610029897e-06}, {"id": 465, "seek": 184818, "start": 1863.1000000000001, "end": 1865.9, "text": " and the first class approach.", "tokens": [293, 264, 700, 1508, 3109, 13], "temperature": 0.0, "avg_logprob": -0.24264732103669243, "compression_ratio": 1.5660377358490567, "no_speech_prob": 1.7330164610029897e-06}, {"id": 466, "seek": 184818, "start": 1865.9, "end": 1872.46, "text": " So similar with sort of scaffolding, if you can eliminate boilerplate by not needing it", "tokens": [407, 2531, 365, 1333, 295, 44094, 278, 11, 498, 291, 393, 13819, 39228, 37008, 538, 406, 18006, 309], "temperature": 0.0, "avg_logprob": -0.24264732103669243, "compression_ratio": 1.5660377358490567, "no_speech_prob": 1.7330164610029897e-06}, {"id": 467, "seek": 187246, "start": 1872.46, "end": 1879.14, "text": " at all, because you have a more declarative API, you have a clever trick that reduces", "tokens": [412, 439, 11, 570, 291, 362, 257, 544, 16694, 1166, 9362, 11, 291, 362, 257, 13494, 4282, 300, 18081], "temperature": 0.0, "avg_logprob": -0.21021994522639684, "compression_ratio": 1.6653543307086613, "no_speech_prob": 1.4367141147886286e-06}, {"id": 468, "seek": 187246, "start": 1879.14, "end": 1882.9, "text": " the amount of boilerplate you need without introducing magic or complexity, then you", "tokens": [264, 2372, 295, 39228, 37008, 291, 643, 1553, 15424, 5585, 420, 14024, 11, 550, 291], "temperature": 0.0, "avg_logprob": -0.21021994522639684, "compression_ratio": 1.6653543307086613, "no_speech_prob": 1.4367141147886286e-06}, {"id": 469, "seek": 187246, "start": 1882.9, "end": 1884.3400000000001, "text": " should absolutely do that.", "tokens": [820, 3122, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.21021994522639684, "compression_ratio": 1.6653543307086613, "no_speech_prob": 1.4367141147886286e-06}, {"id": 470, "seek": 187246, "start": 1884.3400000000001, "end": 1889.14, "text": " And again, I went to great lengths to try to do that with my form API design.", "tokens": [400, 797, 11, 286, 1437, 281, 869, 26329, 281, 853, 281, 360, 300, 365, 452, 1254, 9362, 1715, 13], "temperature": 0.0, "avg_logprob": -0.21021994522639684, "compression_ratio": 1.6653543307086613, "no_speech_prob": 1.4367141147886286e-06}, {"id": 471, "seek": 187246, "start": 1889.14, "end": 1890.14, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.21021994522639684, "compression_ratio": 1.6653543307086613, "no_speech_prob": 1.4367141147886286e-06}, {"id": 472, "seek": 187246, "start": 1890.14, "end": 1891.42, "text": " So attack it from both sides.", "tokens": [407, 2690, 309, 490, 1293, 4881, 13], "temperature": 0.0, "avg_logprob": -0.21021994522639684, "compression_ratio": 1.6653543307086613, "no_speech_prob": 1.4367141147886286e-06}, {"id": 473, "seek": 187246, "start": 1891.42, "end": 1892.54, "text": " So that's number one.", "tokens": [407, 300, 311, 1230, 472, 13], "temperature": 0.0, "avg_logprob": -0.21021994522639684, "compression_ratio": 1.6653543307086613, "no_speech_prob": 1.4367141147886286e-06}, {"id": 474, "seek": 187246, "start": 1892.54, "end": 1899.02, "text": " But then once you do notice that, okay, I've reduced the amount of boilerplate I need to", "tokens": [583, 550, 1564, 291, 360, 3449, 300, 11, 1392, 11, 286, 600, 9212, 264, 2372, 295, 39228, 37008, 286, 643, 281], "temperature": 0.0, "avg_logprob": -0.21021994522639684, "compression_ratio": 1.6653543307086613, "no_speech_prob": 1.4367141147886286e-06}, {"id": 475, "seek": 189902, "start": 1899.02, "end": 1903.82, "text": " set this up, but it's still, I think that there are a couple of things to consider in", "tokens": [992, 341, 493, 11, 457, 309, 311, 920, 11, 286, 519, 300, 456, 366, 257, 1916, 295, 721, 281, 1949, 294], "temperature": 0.0, "avg_logprob": -0.21081669513995832, "compression_ratio": 1.8, "no_speech_prob": 4.313874910621962e-07}, {"id": 476, "seek": 189902, "start": 1903.82, "end": 1912.5, "text": " your workflow when you notice something taking time, but also getting in the way of your", "tokens": [428, 20993, 562, 291, 3449, 746, 1940, 565, 11, 457, 611, 1242, 294, 264, 636, 295, 428], "temperature": 0.0, "avg_logprob": -0.21081669513995832, "compression_ratio": 1.8, "no_speech_prob": 4.313874910621962e-07}, {"id": 477, "seek": 189902, "start": 1912.5, "end": 1916.02, "text": " thought process because it, it's a context shift, right?", "tokens": [1194, 1399, 570, 309, 11, 309, 311, 257, 4319, 5513, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.21081669513995832, "compression_ratio": 1.8, "no_speech_prob": 4.313874910621962e-07}, {"id": 478, "seek": 189902, "start": 1916.02, "end": 1919.94, "text": " So it's not just the amount of time something takes, but it's the amount of context shifting", "tokens": [407, 309, 311, 406, 445, 264, 2372, 295, 565, 746, 2516, 11, 457, 309, 311, 264, 2372, 295, 4319, 17573], "temperature": 0.0, "avg_logprob": -0.21081669513995832, "compression_ratio": 1.8, "no_speech_prob": 4.313874910621962e-07}, {"id": 479, "seek": 189902, "start": 1919.94, "end": 1921.7, "text": " it requires.", "tokens": [309, 7029, 13], "temperature": 0.0, "avg_logprob": -0.21081669513995832, "compression_ratio": 1.8, "no_speech_prob": 4.313874910621962e-07}, {"id": 480, "seek": 189902, "start": 1921.7, "end": 1925.62, "text": " And because of that, sometimes these sort of workflow automations can be greater than", "tokens": [400, 570, 295, 300, 11, 2171, 613, 1333, 295, 20993, 3553, 763, 393, 312, 5044, 813], "temperature": 0.0, "avg_logprob": -0.21081669513995832, "compression_ratio": 1.8, "no_speech_prob": 4.313874910621962e-07}, {"id": 481, "seek": 192562, "start": 1925.62, "end": 1932.6999999999998, "text": " the sum of their parts where having an automated refactoring, maybe it saves you two seconds,", "tokens": [264, 2408, 295, 641, 3166, 689, 1419, 364, 18473, 1895, 578, 3662, 11, 1310, 309, 19155, 291, 732, 3949, 11], "temperature": 0.0, "avg_logprob": -0.18437844056349534, "compression_ratio": 1.703056768558952, "no_speech_prob": 5.626355914500891e-07}, {"id": 482, "seek": 192562, "start": 1932.6999999999998, "end": 1936.3799999999999, "text": " but maybe it makes you more likely to do that refactoring.", "tokens": [457, 1310, 309, 1669, 291, 544, 3700, 281, 360, 300, 1895, 578, 3662, 13], "temperature": 0.0, "avg_logprob": -0.18437844056349534, "compression_ratio": 1.703056768558952, "no_speech_prob": 5.626355914500891e-07}, {"id": 483, "seek": 192562, "start": 1936.3799999999999, "end": 1942.7399999999998, "text": " And maybe it allows you to stay focused on the problem you're solving and let refactoring", "tokens": [400, 1310, 309, 4045, 291, 281, 1754, 5178, 322, 264, 1154, 291, 434, 12606, 293, 718, 1895, 578, 3662], "temperature": 0.0, "avg_logprob": -0.18437844056349534, "compression_ratio": 1.703056768558952, "no_speech_prob": 5.626355914500891e-07}, {"id": 484, "seek": 192562, "start": 1942.7399999999998, "end": 1945.9799999999998, "text": " be something that takes no, no brain space.", "tokens": [312, 746, 300, 2516, 572, 11, 572, 3567, 1901, 13], "temperature": 0.0, "avg_logprob": -0.18437844056349534, "compression_ratio": 1.703056768558952, "no_speech_prob": 5.626355914500891e-07}, {"id": 485, "seek": 192562, "start": 1945.9799999999998, "end": 1948.78, "text": " So that's a win, even if it doesn't save you time.", "tokens": [407, 300, 311, 257, 1942, 11, 754, 498, 309, 1177, 380, 3155, 291, 565, 13], "temperature": 0.0, "avg_logprob": -0.18437844056349534, "compression_ratio": 1.703056768558952, "no_speech_prob": 5.626355914500891e-07}, {"id": 486, "seek": 192562, "start": 1948.78, "end": 1952.1399999999999, "text": " So I think those are a couple of things to consider.", "tokens": [407, 286, 519, 729, 366, 257, 1916, 295, 721, 281, 1949, 13], "temperature": 0.0, "avg_logprob": -0.18437844056349534, "compression_ratio": 1.703056768558952, "no_speech_prob": 5.626355914500891e-07}, {"id": 487, "seek": 195214, "start": 1952.14, "end": 1958.42, "text": " There's also just sharing with others in the sense that for instance, you might know how", "tokens": [821, 311, 611, 445, 5414, 365, 2357, 294, 264, 2020, 300, 337, 5197, 11, 291, 1062, 458, 577], "temperature": 0.0, "avg_logprob": -0.2664565201644059, "compression_ratio": 1.6561085972850678, "no_speech_prob": 1.2679029168793932e-06}, {"id": 488, "seek": 195214, "start": 1958.42, "end": 1965.6200000000001, "text": " to create a new L module and to wire all the updates functions together, the view functions,", "tokens": [281, 1884, 257, 777, 441, 10088, 293, 281, 6234, 439, 264, 9205, 6828, 1214, 11, 264, 1910, 6828, 11], "temperature": 0.0, "avg_logprob": -0.2664565201644059, "compression_ratio": 1.6561085972850678, "no_speech_prob": 1.2679029168793932e-06}, {"id": 489, "seek": 195214, "start": 1965.6200000000001, "end": 1967.0200000000002, "text": " the subscriptions and all that.", "tokens": [264, 44951, 293, 439, 300, 13], "temperature": 0.0, "avg_logprob": -0.2664565201644059, "compression_ratio": 1.6561085972850678, "no_speech_prob": 1.2679029168793932e-06}, {"id": 490, "seek": 195214, "start": 1967.0200000000002, "end": 1971.98, "text": " And maybe it takes very little amount of time for you to create all those and to wire everything", "tokens": [400, 1310, 309, 2516, 588, 707, 2372, 295, 565, 337, 291, 281, 1884, 439, 729, 293, 281, 6234, 1203], "temperature": 0.0, "avg_logprob": -0.2664565201644059, "compression_ratio": 1.6561085972850678, "no_speech_prob": 1.2679029168793932e-06}, {"id": 491, "seek": 195214, "start": 1971.98, "end": 1972.98, "text": " up.", "tokens": [493, 13], "temperature": 0.0, "avg_logprob": -0.2664565201644059, "compression_ratio": 1.6561085972850678, "no_speech_prob": 1.2679029168793932e-06}, {"id": 492, "seek": 195214, "start": 1972.98, "end": 1976.3000000000002, "text": " But for a beginner, that will take a lot more time.", "tokens": [583, 337, 257, 22080, 11, 300, 486, 747, 257, 688, 544, 565, 13], "temperature": 0.0, "avg_logprob": -0.2664565201644059, "compression_ratio": 1.6561085972850678, "no_speech_prob": 1.2679029168793932e-06}, {"id": 493, "seek": 197630, "start": 1976.3, "end": 1983.02, "text": " So if it's for you, it's already automatic and you know how you could do, and you know", "tokens": [407, 498, 309, 311, 337, 291, 11, 309, 311, 1217, 12509, 293, 291, 458, 577, 291, 727, 360, 11, 293, 291, 458], "temperature": 0.0, "avg_logprob": -0.2718757888645802, "compression_ratio": 1.775609756097561, "no_speech_prob": 9.87449084277614e-07}, {"id": 494, "seek": 197630, "start": 1983.02, "end": 1987.54, "text": " how you could automate that, then that could be worthwhile for a beginner.", "tokens": [577, 291, 727, 31605, 300, 11, 550, 300, 727, 312, 28159, 337, 257, 22080, 13], "temperature": 0.0, "avg_logprob": -0.2718757888645802, "compression_ratio": 1.775609756097561, "no_speech_prob": 9.87449084277614e-07}, {"id": 495, "seek": 197630, "start": 1987.54, "end": 1988.54, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.2718757888645802, "compression_ratio": 1.775609756097561, "no_speech_prob": 9.87449084277614e-07}, {"id": 496, "seek": 197630, "start": 1988.54, "end": 1990.3, "text": " Or maybe not this example, but yeah.", "tokens": [1610, 1310, 406, 341, 1365, 11, 457, 1338, 13], "temperature": 0.0, "avg_logprob": -0.2718757888645802, "compression_ratio": 1.775609756097561, "no_speech_prob": 9.87449084277614e-07}, {"id": 497, "seek": 197630, "start": 1990.3, "end": 1991.3, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2718757888645802, "compression_ratio": 1.775609756097561, "no_speech_prob": 9.87449084277614e-07}, {"id": 498, "seek": 197630, "start": 1991.3, "end": 1994.34, "text": " You can use it to model best practices.", "tokens": [509, 393, 764, 309, 281, 2316, 1151, 7525, 13], "temperature": 0.0, "avg_logprob": -0.2718757888645802, "compression_ratio": 1.775609756097561, "no_speech_prob": 9.87449084277614e-07}, {"id": 499, "seek": 197630, "start": 1994.34, "end": 1999.18, "text": " You know, the things that get copy pasted might not end up being the best examples of", "tokens": [509, 458, 11, 264, 721, 300, 483, 5055, 1791, 292, 1062, 406, 917, 493, 885, 264, 1151, 5110, 295], "temperature": 0.0, "avg_logprob": -0.2718757888645802, "compression_ratio": 1.775609756097561, "no_speech_prob": 9.87449084277614e-07}, {"id": 500, "seek": 197630, "start": 1999.18, "end": 2000.82, "text": " things to get copy pasted.", "tokens": [721, 281, 483, 5055, 1791, 292, 13], "temperature": 0.0, "avg_logprob": -0.2718757888645802, "compression_ratio": 1.775609756097561, "no_speech_prob": 9.87449084277614e-07}, {"id": 501, "seek": 200082, "start": 2000.82, "end": 2009.1, "text": " So you can sort of model the ideal way to write something in sort of scaffolding helpers.", "tokens": [407, 291, 393, 1333, 295, 2316, 264, 7157, 636, 281, 2464, 746, 294, 1333, 295, 44094, 278, 854, 433, 13], "temperature": 0.0, "avg_logprob": -0.27131669828207183, "compression_ratio": 1.7453703703703705, "no_speech_prob": 4.2469275740586454e-07}, {"id": 502, "seek": 200082, "start": 2009.1, "end": 2014.3, "text": " That's actually something that I've found that, that's actually something that I'm finding", "tokens": [663, 311, 767, 746, 300, 286, 600, 1352, 300, 11, 300, 311, 767, 746, 300, 286, 478, 5006], "temperature": 0.0, "avg_logprob": -0.27131669828207183, "compression_ratio": 1.7453703703703705, "no_speech_prob": 4.2469275740586454e-07}, {"id": 503, "seek": 200082, "start": 2014.3, "end": 2020.54, "text": " to be a lot more of a problem than I expected is that if you leave bad code around, it gets", "tokens": [281, 312, 257, 688, 544, 295, 257, 1154, 813, 286, 5176, 307, 300, 498, 291, 1856, 1578, 3089, 926, 11, 309, 2170], "temperature": 0.0, "avg_logprob": -0.27131669828207183, "compression_ratio": 1.7453703703703705, "no_speech_prob": 4.2469275740586454e-07}, {"id": 504, "seek": 200082, "start": 2020.54, "end": 2022.22, "text": " copy pasted a lot.", "tokens": [5055, 1791, 292, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.27131669828207183, "compression_ratio": 1.7453703703703705, "no_speech_prob": 4.2469275740586454e-07}, {"id": 505, "seek": 200082, "start": 2022.22, "end": 2023.22, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.27131669828207183, "compression_ratio": 1.7453703703703705, "no_speech_prob": 4.2469275740586454e-07}, {"id": 506, "seek": 200082, "start": 2023.22, "end": 2029.6599999999999, "text": " It's always the bad code that gets copy pasted, but that might be some bias.", "tokens": [467, 311, 1009, 264, 1578, 3089, 300, 2170, 5055, 1791, 292, 11, 457, 300, 1062, 312, 512, 12577, 13], "temperature": 0.0, "avg_logprob": -0.27131669828207183, "compression_ratio": 1.7453703703703705, "no_speech_prob": 4.2469275740586454e-07}, {"id": 507, "seek": 202966, "start": 2029.66, "end": 2030.94, "text": " I hope it's a bias.", "tokens": [286, 1454, 309, 311, 257, 12577, 13], "temperature": 0.0, "avg_logprob": -0.27735139791247915, "compression_ratio": 1.5944700460829493, "no_speech_prob": 4.812497991224518e-07}, {"id": 508, "seek": 202966, "start": 2030.94, "end": 2033.7, "text": " No, it is exactly.", "tokens": [883, 11, 309, 307, 2293, 13], "temperature": 0.0, "avg_logprob": -0.27735139791247915, "compression_ratio": 1.5944700460829493, "no_speech_prob": 4.812497991224518e-07}, {"id": 509, "seek": 202966, "start": 2033.7, "end": 2040.26, "text": " And which is something to say about code debts, like fix it now or it will multiply.", "tokens": [400, 597, 307, 746, 281, 584, 466, 3089, 32528, 11, 411, 3191, 309, 586, 420, 309, 486, 12972, 13], "temperature": 0.0, "avg_logprob": -0.27735139791247915, "compression_ratio": 1.5944700460829493, "no_speech_prob": 4.812497991224518e-07}, {"id": 510, "seek": 202966, "start": 2040.26, "end": 2041.26, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.27735139791247915, "compression_ratio": 1.5944700460829493, "no_speech_prob": 4.812497991224518e-07}, {"id": 511, "seek": 202966, "start": 2041.26, "end": 2042.26, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.27735139791247915, "compression_ratio": 1.5944700460829493, "no_speech_prob": 4.812497991224518e-07}, {"id": 512, "seek": 202966, "start": 2042.26, "end": 2043.26, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.27735139791247915, "compression_ratio": 1.5944700460829493, "no_speech_prob": 4.812497991224518e-07}, {"id": 513, "seek": 202966, "start": 2043.26, "end": 2046.02, "text": " Sandy Metz talks about this a lot in refactoring.", "tokens": [27390, 6377, 89, 6686, 466, 341, 257, 688, 294, 1895, 578, 3662, 13], "temperature": 0.0, "avg_logprob": -0.27735139791247915, "compression_ratio": 1.5944700460829493, "no_speech_prob": 4.812497991224518e-07}, {"id": 514, "seek": 202966, "start": 2046.02, "end": 2051.1, "text": " She has some really great books on refactoring in Ruby, but she talks about a lot of just", "tokens": [1240, 575, 512, 534, 869, 3642, 322, 1895, 578, 3662, 294, 19907, 11, 457, 750, 6686, 466, 257, 688, 295, 445], "temperature": 0.0, "avg_logprob": -0.27735139791247915, "compression_ratio": 1.5944700460829493, "no_speech_prob": 4.812497991224518e-07}, {"id": 515, "seek": 202966, "start": 2051.1, "end": 2054.7000000000003, "text": " sort of general best practices and refactoring techniques.", "tokens": [1333, 295, 2674, 1151, 7525, 293, 1895, 578, 3662, 7512, 13], "temperature": 0.0, "avg_logprob": -0.27735139791247915, "compression_ratio": 1.5944700460829493, "no_speech_prob": 4.812497991224518e-07}, {"id": 516, "seek": 205470, "start": 2054.7, "end": 2061.3399999999997, "text": " And she talks about sort of, I can't remember the word she used, but something like replicability", "tokens": [400, 750, 6686, 466, 1333, 295, 11, 286, 393, 380, 1604, 264, 1349, 750, 1143, 11, 457, 746, 411, 3248, 299, 2310], "temperature": 0.0, "avg_logprob": -0.23245094133460004, "compression_ratio": 1.6280193236714975, "no_speech_prob": 9.422246876056306e-07}, {"id": 517, "seek": 205470, "start": 2061.3399999999997, "end": 2066.14, "text": " or like somehow code wants to be duplicated.", "tokens": [420, 411, 6063, 3089, 2738, 281, 312, 1581, 564, 3587, 13], "temperature": 0.0, "avg_logprob": -0.23245094133460004, "compression_ratio": 1.6280193236714975, "no_speech_prob": 9.422246876056306e-07}, {"id": 518, "seek": 205470, "start": 2066.14, "end": 2073.7799999999997, "text": " So there's a cost to having code that doesn't represent the way you want to do something", "tokens": [407, 456, 311, 257, 2063, 281, 1419, 3089, 300, 1177, 380, 2906, 264, 636, 291, 528, 281, 360, 746], "temperature": 0.0, "avg_logprob": -0.23245094133460004, "compression_ratio": 1.6280193236714975, "no_speech_prob": 9.422246876056306e-07}, {"id": 519, "seek": 205470, "start": 2073.7799999999997, "end": 2074.7799999999997, "text": " in your code base.", "tokens": [294, 428, 3089, 3096, 13], "temperature": 0.0, "avg_logprob": -0.23245094133460004, "compression_ratio": 1.6280193236714975, "no_speech_prob": 9.422246876056306e-07}, {"id": 520, "seek": 205470, "start": 2074.7799999999997, "end": 2081.7799999999997, "text": " That said, I mean, you can write tools to say, well, this is the way things should be.", "tokens": [663, 848, 11, 286, 914, 11, 291, 393, 2464, 3873, 281, 584, 11, 731, 11, 341, 307, 264, 636, 721, 820, 312, 13], "temperature": 0.0, "avg_logprob": -0.23245094133460004, "compression_ratio": 1.6280193236714975, "no_speech_prob": 9.422246876056306e-07}, {"id": 521, "seek": 208178, "start": 2081.78, "end": 2087.3, "text": " But if you're starting with a new approach and you're still exploring and like, well,", "tokens": [583, 498, 291, 434, 2891, 365, 257, 777, 3109, 293, 291, 434, 920, 12736, 293, 411, 11, 731, 11], "temperature": 0.0, "avg_logprob": -0.2605803253453806, "compression_ratio": 1.6695652173913043, "no_speech_prob": 7.002097959230014e-07}, {"id": 522, "seek": 208178, "start": 2087.3, "end": 2088.7000000000003, "text": " is this the right approach?", "tokens": [307, 341, 264, 558, 3109, 30], "temperature": 0.0, "avg_logprob": -0.2605803253453806, "compression_ratio": 1.6695652173913043, "no_speech_prob": 7.002097959230014e-07}, {"id": 523, "seek": 208178, "start": 2088.7000000000003, "end": 2092.94, "text": " Maybe we'll try it out and come back to it later.", "tokens": [2704, 321, 603, 853, 309, 484, 293, 808, 646, 281, 309, 1780, 13], "temperature": 0.0, "avg_logprob": -0.2605803253453806, "compression_ratio": 1.6695652173913043, "no_speech_prob": 7.002097959230014e-07}, {"id": 524, "seek": 208178, "start": 2092.94, "end": 2098.3, "text": " If you don't know what the right approach is yet, then you can't really make tools for", "tokens": [759, 291, 500, 380, 458, 437, 264, 558, 3109, 307, 1939, 11, 550, 291, 393, 380, 534, 652, 3873, 337], "temperature": 0.0, "avg_logprob": -0.2605803253453806, "compression_ratio": 1.6695652173913043, "no_speech_prob": 7.002097959230014e-07}, {"id": 525, "seek": 208178, "start": 2098.3, "end": 2099.3, "text": " it.", "tokens": [309, 13], "temperature": 0.0, "avg_logprob": -0.2605803253453806, "compression_ratio": 1.6695652173913043, "no_speech_prob": 7.002097959230014e-07}, {"id": 526, "seek": 208178, "start": 2099.3, "end": 2106.1800000000003, "text": " So, but for things that you do over and over again and always in the same manner, yeah,", "tokens": [407, 11, 457, 337, 721, 300, 291, 360, 670, 293, 670, 797, 293, 1009, 294, 264, 912, 9060, 11, 1338, 11], "temperature": 0.0, "avg_logprob": -0.2605803253453806, "compression_ratio": 1.6695652173913043, "no_speech_prob": 7.002097959230014e-07}, {"id": 527, "seek": 208178, "start": 2106.1800000000003, "end": 2109.1800000000003, "text": " make tools, make your life easier.", "tokens": [652, 3873, 11, 652, 428, 993, 3571, 13], "temperature": 0.0, "avg_logprob": -0.2605803253453806, "compression_ratio": 1.6695652173913043, "no_speech_prob": 7.002097959230014e-07}, {"id": 528, "seek": 208178, "start": 2109.1800000000003, "end": 2110.1800000000003, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.2605803253453806, "compression_ratio": 1.6695652173913043, "no_speech_prob": 7.002097959230014e-07}, {"id": 529, "seek": 211018, "start": 2110.18, "end": 2118.22, "text": " Now, just as you want to keep in mind, like what direction you want to guide the code", "tokens": [823, 11, 445, 382, 291, 528, 281, 1066, 294, 1575, 11, 411, 437, 3513, 291, 528, 281, 5934, 264, 3089], "temperature": 0.0, "avg_logprob": -0.24112703535291885, "compression_ratio": 1.7777777777777777, "no_speech_prob": 9.422385005564138e-07}, {"id": 530, "seek": 211018, "start": 2118.22, "end": 2123.14, "text": " with your scaffolding and your automation tools and how that shapes the code, you also", "tokens": [365, 428, 44094, 278, 293, 428, 17769, 3873, 293, 577, 300, 10854, 264, 3089, 11, 291, 611], "temperature": 0.0, "avg_logprob": -0.24112703535291885, "compression_ratio": 1.7777777777777777, "no_speech_prob": 9.422385005564138e-07}, {"id": 531, "seek": 211018, "start": 2123.14, "end": 2130.7, "text": " want to make sure that you don't make it too easy to generate things that you don't necessarily", "tokens": [528, 281, 652, 988, 300, 291, 500, 380, 652, 309, 886, 1858, 281, 8460, 721, 300, 291, 500, 380, 4725], "temperature": 0.0, "avg_logprob": -0.24112703535291885, "compression_ratio": 1.7777777777777777, "no_speech_prob": 9.422385005564138e-07}, {"id": 532, "seek": 211018, "start": 2130.7, "end": 2135.96, "text": " want or to duplicate things rather than reusing shared things.", "tokens": [528, 420, 281, 23976, 721, 2831, 813, 319, 7981, 5507, 721, 13], "temperature": 0.0, "avg_logprob": -0.24112703535291885, "compression_ratio": 1.7777777777777777, "no_speech_prob": 9.422385005564138e-07}, {"id": 533, "seek": 211018, "start": 2135.96, "end": 2137.22, "text": " This is another consideration.", "tokens": [639, 307, 1071, 12381, 13], "temperature": 0.0, "avg_logprob": -0.24112703535291885, "compression_ratio": 1.7777777777777777, "no_speech_prob": 9.422385005564138e-07}, {"id": 534, "seek": 211018, "start": 2137.22, "end": 2138.22, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.24112703535291885, "compression_ratio": 1.7777777777777777, "no_speech_prob": 9.422385005564138e-07}, {"id": 535, "seek": 213822, "start": 2138.22, "end": 2142.58, "text": " Are you thinking of, for instance, when someone creates a module and they add in it, update", "tokens": [2014, 291, 1953, 295, 11, 337, 5197, 11, 562, 1580, 7829, 257, 10088, 293, 436, 909, 294, 309, 11, 5623], "temperature": 0.0, "avg_logprob": -0.3046078263667592, "compression_ratio": 1.6923076923076923, "no_speech_prob": 7.002120128163369e-07}, {"id": 536, "seek": 213822, "start": 2142.58, "end": 2145.1, "text": " view and in the end they only need the view?", "tokens": [1910, 293, 294, 264, 917, 436, 787, 643, 264, 1910, 30], "temperature": 0.0, "avg_logprob": -0.3046078263667592, "compression_ratio": 1.6923076923076923, "no_speech_prob": 7.002120128163369e-07}, {"id": 537, "seek": 213822, "start": 2145.1, "end": 2146.8199999999997, "text": " Is that kind of thing?", "tokens": [1119, 300, 733, 295, 551, 30], "temperature": 0.0, "avg_logprob": -0.3046078263667592, "compression_ratio": 1.6923076923076923, "no_speech_prob": 7.002120128163369e-07}, {"id": 538, "seek": 213822, "start": 2146.8199999999997, "end": 2148.62, "text": " Yeah, that would be one example.", "tokens": [865, 11, 300, 576, 312, 472, 1365, 13], "temperature": 0.0, "avg_logprob": -0.3046078263667592, "compression_ratio": 1.6923076923076923, "no_speech_prob": 7.002120128163369e-07}, {"id": 539, "seek": 213822, "start": 2148.62, "end": 2156.1, "text": " Or maybe it's so easy to scaffold out a new decoder that you don't go to see if there's", "tokens": [1610, 1310, 309, 311, 370, 1858, 281, 44094, 484, 257, 777, 979, 19866, 300, 291, 500, 380, 352, 281, 536, 498, 456, 311], "temperature": 0.0, "avg_logprob": -0.3046078263667592, "compression_ratio": 1.6923076923076923, "no_speech_prob": 7.002120128163369e-07}, {"id": 540, "seek": 213822, "start": 2156.1, "end": 2161.66, "text": " an opportunity to reuse something that already exists somewhere else because it's so easy", "tokens": [364, 2650, 281, 26225, 746, 300, 1217, 8198, 4079, 1646, 570, 309, 311, 370, 1858], "temperature": 0.0, "avg_logprob": -0.3046078263667592, "compression_ratio": 1.6923076923076923, "no_speech_prob": 7.002120128163369e-07}, {"id": 541, "seek": 213822, "start": 2161.66, "end": 2165.7799999999997, "text": " to just build up the decoder using these automation helpers you have.", "tokens": [281, 445, 1322, 493, 264, 979, 19866, 1228, 613, 17769, 854, 433, 291, 362, 13], "temperature": 0.0, "avg_logprob": -0.3046078263667592, "compression_ratio": 1.6923076923076923, "no_speech_prob": 7.002120128163369e-07}, {"id": 542, "seek": 216578, "start": 2165.78, "end": 2170.7200000000003, "text": " But yeah, I think, you know, with Elm, we like being explicit.", "tokens": [583, 1338, 11, 286, 519, 11, 291, 458, 11, 365, 2699, 76, 11, 321, 411, 885, 13691, 13], "temperature": 0.0, "avg_logprob": -0.22257150079786164, "compression_ratio": 1.6563876651982379, "no_speech_prob": 7.453637635990162e-07}, {"id": 543, "seek": 216578, "start": 2170.7200000000003, "end": 2177.82, "text": " We like to have all of the information of how to do something in code, not defined through", "tokens": [492, 411, 281, 362, 439, 295, 264, 1589, 295, 577, 281, 360, 746, 294, 3089, 11, 406, 7642, 807], "temperature": 0.0, "avg_logprob": -0.22257150079786164, "compression_ratio": 1.6563876651982379, "no_speech_prob": 7.453637635990162e-07}, {"id": 544, "seek": 216578, "start": 2177.82, "end": 2181.6200000000003, "text": " magic, not implied through some type somewhere.", "tokens": [5585, 11, 406, 32614, 807, 512, 2010, 4079, 13], "temperature": 0.0, "avg_logprob": -0.22257150079786164, "compression_ratio": 1.6563876651982379, "no_speech_prob": 7.453637635990162e-07}, {"id": 545, "seek": 216578, "start": 2181.6200000000003, "end": 2187.5400000000004, "text": " And so I think scaffolding is like a really good technique to bridge that gap.", "tokens": [400, 370, 286, 519, 44094, 278, 307, 411, 257, 534, 665, 6532, 281, 7283, 300, 7417, 13], "temperature": 0.0, "avg_logprob": -0.22257150079786164, "compression_ratio": 1.6563876651982379, "no_speech_prob": 7.453637635990162e-07}, {"id": 546, "seek": 216578, "start": 2187.5400000000004, "end": 2192.0400000000004, "text": " So like one of the things to think about also is like, what are the inputs to your scaffolding?", "tokens": [407, 411, 472, 295, 264, 721, 281, 519, 466, 611, 307, 411, 11, 437, 366, 264, 15743, 281, 428, 44094, 278, 30], "temperature": 0.0, "avg_logprob": -0.22257150079786164, "compression_ratio": 1.6563876651982379, "no_speech_prob": 7.453637635990162e-07}, {"id": 547, "seek": 219204, "start": 2192.04, "end": 2198.86, "text": " So like, you know, we talked about using these sort of debug.todo comments that have some", "tokens": [407, 411, 11, 291, 458, 11, 321, 2825, 466, 1228, 613, 1333, 295, 24083, 13, 83, 17423, 3053, 300, 362, 512], "temperature": 0.0, "avg_logprob": -0.20619464407161792, "compression_ratio": 1.7009803921568627, "no_speech_prob": 9.132405125455989e-07}, {"id": 548, "seek": 219204, "start": 2198.86, "end": 2205.3, "text": " sort of something in the debug.todo string that tells it what to do, what to replace", "tokens": [1333, 295, 746, 294, 264, 24083, 13, 83, 17423, 6798, 300, 5112, 309, 437, 281, 360, 11, 437, 281, 7406], "temperature": 0.0, "avg_logprob": -0.20619464407161792, "compression_ratio": 1.7009803921568627, "no_speech_prob": 9.132405125455989e-07}, {"id": 549, "seek": 219204, "start": 2205.3, "end": 2206.3, "text": " that with.", "tokens": [300, 365, 13], "temperature": 0.0, "avg_logprob": -0.20619464407161792, "compression_ratio": 1.7009803921568627, "no_speech_prob": 9.132405125455989e-07}, {"id": 550, "seek": 219204, "start": 2206.3, "end": 2207.9, "text": " That's one pattern.", "tokens": [663, 311, 472, 5102, 13], "temperature": 0.0, "avg_logprob": -0.20619464407161792, "compression_ratio": 1.7009803921568627, "no_speech_prob": 9.132405125455989e-07}, {"id": 551, "seek": 219204, "start": 2207.9, "end": 2213.62, "text": " Having sort of an inline thing in the code telling you that you want to do something", "tokens": [10222, 1333, 295, 364, 294, 1889, 551, 294, 264, 3089, 3585, 291, 300, 291, 528, 281, 360, 746], "temperature": 0.0, "avg_logprob": -0.20619464407161792, "compression_ratio": 1.7009803921568627, "no_speech_prob": 9.132405125455989e-07}, {"id": 552, "seek": 219204, "start": 2213.62, "end": 2214.62, "text": " with that.", "tokens": [365, 300, 13], "temperature": 0.0, "avg_logprob": -0.20619464407161792, "compression_ratio": 1.7009803921568627, "no_speech_prob": 9.132405125455989e-07}, {"id": 553, "seek": 219204, "start": 2214.62, "end": 2218.62, "text": " You can use a CLI to scaffold out new things.", "tokens": [509, 393, 764, 257, 12855, 40, 281, 44094, 484, 777, 721, 13], "temperature": 0.0, "avg_logprob": -0.20619464407161792, "compression_ratio": 1.7009803921568627, "no_speech_prob": 9.132405125455989e-07}, {"id": 554, "seek": 221862, "start": 2218.62, "end": 2222.7, "text": " You can pull in data from different sources.", "tokens": [509, 393, 2235, 294, 1412, 490, 819, 7139, 13], "temperature": 0.0, "avg_logprob": -0.24897746650540098, "compression_ratio": 1.6596638655462186, "no_speech_prob": 3.237729970351211e-06}, {"id": 555, "seek": 221862, "start": 2222.7, "end": 2230.2, "text": " You can pull in, I mean, I think it would be really cool to have a JSON decoder scaffolding", "tokens": [509, 393, 2235, 294, 11, 286, 914, 11, 286, 519, 309, 576, 312, 534, 1627, 281, 362, 257, 31828, 979, 19866, 44094, 278], "temperature": 0.0, "avg_logprob": -0.24897746650540098, "compression_ratio": 1.6596638655462186, "no_speech_prob": 3.237729970351211e-06}, {"id": 556, "seek": 221862, "start": 2230.2, "end": 2237.14, "text": " helpers that take a URL or an HTTP request or something and scaffold that for you.", "tokens": [854, 433, 300, 747, 257, 12905, 420, 364, 33283, 5308, 420, 746, 293, 44094, 300, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.24897746650540098, "compression_ratio": 1.6596638655462186, "no_speech_prob": 3.237729970351211e-06}, {"id": 557, "seek": 221862, "start": 2237.14, "end": 2243.8399999999997, "text": " So I think it's worth thinking about what are the inputs to and how can we really automate", "tokens": [407, 286, 519, 309, 311, 3163, 1953, 466, 437, 366, 264, 15743, 281, 293, 577, 393, 321, 534, 31605], "temperature": 0.0, "avg_logprob": -0.24897746650540098, "compression_ratio": 1.6596638655462186, "no_speech_prob": 3.237729970351211e-06}, {"id": 558, "seek": 221862, "start": 2243.8399999999997, "end": 2248.2999999999997, "text": " the process to make it really seamless to not have to think about boilerplate in our", "tokens": [264, 1399, 281, 652, 309, 534, 28677, 281, 406, 362, 281, 519, 466, 39228, 37008, 294, 527], "temperature": 0.0, "avg_logprob": -0.24897746650540098, "compression_ratio": 1.6596638655462186, "no_speech_prob": 3.237729970351211e-06}, {"id": 559, "seek": 224830, "start": 2248.3, "end": 2249.3, "text": " own code.", "tokens": [1065, 3089, 13], "temperature": 0.0, "avg_logprob": -0.2965177576592628, "compression_ratio": 1.7211538461538463, "no_speech_prob": 5.422079084382858e-06}, {"id": 560, "seek": 224830, "start": 2249.3, "end": 2250.3, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2965177576592628, "compression_ratio": 1.7211538461538463, "no_speech_prob": 5.422079084382858e-06}, {"id": 561, "seek": 224830, "start": 2250.3, "end": 2257.6600000000003, "text": " At work we have a few code generation tools or scaffolding tools, for instance, to create", "tokens": [1711, 589, 321, 362, 257, 1326, 3089, 5125, 3873, 420, 44094, 278, 3873, 11, 337, 5197, 11, 281, 1884], "temperature": 0.0, "avg_logprob": -0.2965177576592628, "compression_ratio": 1.7211538461538463, "no_speech_prob": 5.422079084382858e-06}, {"id": 562, "seek": 224830, "start": 2257.6600000000003, "end": 2265.1800000000003, "text": " routes and then we have a separate code generation script to combine them in an Elm SBA like", "tokens": [18242, 293, 550, 321, 362, 257, 4994, 3089, 5125, 5755, 281, 10432, 552, 294, 364, 2699, 76, 318, 9295, 411], "temperature": 0.0, "avg_logprob": -0.2965177576592628, "compression_ratio": 1.7211538461538463, "no_speech_prob": 5.422079084382858e-06}, {"id": 563, "seek": 224830, "start": 2265.1800000000003, "end": 2266.2200000000003, "text": " way.", "tokens": [636, 13], "temperature": 0.0, "avg_logprob": -0.2965177576592628, "compression_ratio": 1.7211538461538463, "no_speech_prob": 5.422079084382858e-06}, {"id": 564, "seek": 224830, "start": 2266.2200000000003, "end": 2272.48, "text": " So there's a lot of scaffolding and code generation going around that.", "tokens": [407, 456, 311, 257, 688, 295, 44094, 278, 293, 3089, 5125, 516, 926, 300, 13], "temperature": 0.0, "avg_logprob": -0.2965177576592628, "compression_ratio": 1.7211538461538463, "no_speech_prob": 5.422079084382858e-06}, {"id": 565, "seek": 224830, "start": 2272.48, "end": 2277.7400000000002, "text": " One problem is like, usually people don't know that these things, these scaffolding", "tokens": [1485, 1154, 307, 411, 11, 2673, 561, 500, 380, 458, 300, 613, 721, 11, 613, 44094, 278], "temperature": 0.0, "avg_logprob": -0.2965177576592628, "compression_ratio": 1.7211538461538463, "no_speech_prob": 5.422079084382858e-06}, {"id": 566, "seek": 227774, "start": 2277.74, "end": 2278.8199999999997, "text": " tools exist.", "tokens": [3873, 2514, 13], "temperature": 0.0, "avg_logprob": -0.4262050147195464, "compression_ratio": 1.621212121212121, "no_speech_prob": 2.4579776436439715e-07}, {"id": 567, "seek": 227774, "start": 2278.8199999999997, "end": 2284.2999999999997, "text": " So they're in the readme, but no one reads the readme because I mean, it says readme.", "tokens": [407, 436, 434, 294, 264, 1401, 1398, 11, 457, 572, 472, 15700, 264, 1401, 1398, 570, 286, 914, 11, 309, 1619, 1401, 1398, 13], "temperature": 0.0, "avg_logprob": -0.4262050147195464, "compression_ratio": 1.621212121212121, "no_speech_prob": 2.4579776436439715e-07}, {"id": 568, "seek": 227774, "start": 2284.2999999999997, "end": 2286.4199999999996, "text": " It doesn't say ignore me.", "tokens": [467, 1177, 380, 584, 11200, 385, 13], "temperature": 0.0, "avg_logprob": -0.4262050147195464, "compression_ratio": 1.621212121212121, "no_speech_prob": 2.4579776436439715e-07}, {"id": 569, "seek": 227774, "start": 2286.4199999999996, "end": 2287.4199999999996, "text": " Interesting.", "tokens": [14711, 13], "temperature": 0.0, "avg_logprob": -0.4262050147195464, "compression_ratio": 1.621212121212121, "no_speech_prob": 2.4579776436439715e-07}, {"id": 570, "seek": 227774, "start": 2287.4199999999996, "end": 2292.9399999999996, "text": " That could be fun file to have ignore me.mt.", "tokens": [663, 727, 312, 1019, 3991, 281, 362, 11200, 385, 13, 42744, 13], "temperature": 0.0, "avg_logprob": -0.4262050147195464, "compression_ratio": 1.621212121212121, "no_speech_prob": 2.4579776436439715e-07}, {"id": 571, "seek": 227774, "start": 2292.9399999999996, "end": 2294.3799999999997, "text": " People might actually read that one.", "tokens": [3432, 1062, 767, 1401, 300, 472, 13], "temperature": 0.0, "avg_logprob": -0.4262050147195464, "compression_ratio": 1.621212121212121, "no_speech_prob": 2.4579776436439715e-07}, {"id": 572, "seek": 227774, "start": 2294.3799999999997, "end": 2295.8599999999997, "text": " I wouldn't read it.", "tokens": [286, 2759, 380, 1401, 309, 13], "temperature": 0.0, "avg_logprob": -0.4262050147195464, "compression_ratio": 1.621212121212121, "no_speech_prob": 2.4579776436439715e-07}, {"id": 573, "seek": 227774, "start": 2295.8599999999997, "end": 2298.22, "text": " I like it.", "tokens": [286, 411, 309, 13], "temperature": 0.0, "avg_logprob": -0.4262050147195464, "compression_ratio": 1.621212121212121, "no_speech_prob": 2.4579776436439715e-07}, {"id": 574, "seek": 227774, "start": 2298.22, "end": 2306.9399999999996, "text": " So yeah, we have the problem, but I mean, the tool is there sometimes.", "tokens": [407, 1338, 11, 321, 362, 264, 1154, 11, 457, 286, 914, 11, 264, 2290, 307, 456, 2171, 13], "temperature": 0.0, "avg_logprob": -0.4262050147195464, "compression_ratio": 1.621212121212121, "no_speech_prob": 2.4579776436439715e-07}, {"id": 575, "seek": 230694, "start": 2306.94, "end": 2308.26, "text": " It's just not going to be used.", "tokens": [467, 311, 445, 406, 516, 281, 312, 1143, 13], "temperature": 0.0, "avg_logprob": -0.2898607805740735, "compression_ratio": 1.7011494252873562, "no_speech_prob": 2.7264316031505587e-06}, {"id": 576, "seek": 230694, "start": 2308.26, "end": 2309.26, "text": " That's all.", "tokens": [663, 311, 439, 13], "temperature": 0.0, "avg_logprob": -0.2898607805740735, "compression_ratio": 1.7011494252873562, "no_speech_prob": 2.7264316031505587e-06}, {"id": 577, "seek": 230694, "start": 2309.26, "end": 2316.02, "text": " So if you do have like, if you make a package with those scaffolding tools integrated into", "tokens": [407, 498, 291, 360, 362, 411, 11, 498, 291, 652, 257, 7372, 365, 729, 44094, 278, 3873, 10919, 666], "temperature": 0.0, "avg_logprob": -0.2898607805740735, "compression_ratio": 1.7011494252873562, "no_speech_prob": 2.7264316031505587e-06}, {"id": 578, "seek": 230694, "start": 2316.02, "end": 2320.58, "text": " the package, then I would really recommend like add a nice section in your readme about", "tokens": [264, 7372, 11, 550, 286, 576, 534, 2748, 411, 909, 257, 1481, 3541, 294, 428, 1401, 1398, 466], "temperature": 0.0, "avg_logprob": -0.2898607805740735, "compression_ratio": 1.7011494252873562, "no_speech_prob": 2.7264316031505587e-06}, {"id": 579, "seek": 230694, "start": 2320.58, "end": 2323.1, "text": " like, Hey, you should use these things.", "tokens": [411, 11, 1911, 11, 291, 820, 764, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.2898607805740735, "compression_ratio": 1.7011494252873562, "no_speech_prob": 2.7264316031505587e-06}, {"id": 580, "seek": 230694, "start": 2323.1, "end": 2327.06, "text": " Then there's the same question I was wondering about a few years ago is like, well, if you", "tokens": [1396, 456, 311, 264, 912, 1168, 286, 390, 6359, 466, 257, 1326, 924, 2057, 307, 411, 11, 731, 11, 498, 291], "temperature": 0.0, "avg_logprob": -0.2898607805740735, "compression_ratio": 1.7011494252873562, "no_speech_prob": 2.7264316031505587e-06}, {"id": 581, "seek": 230694, "start": 2327.06, "end": 2334.46, "text": " have a package, like let's say Elm UI, should you have Elm review rules that come with it?", "tokens": [362, 257, 7372, 11, 411, 718, 311, 584, 2699, 76, 15682, 11, 820, 291, 362, 2699, 76, 3131, 4474, 300, 808, 365, 309, 30], "temperature": 0.0, "avg_logprob": -0.2898607805740735, "compression_ratio": 1.7011494252873562, "no_speech_prob": 2.7264316031505587e-06}, {"id": 582, "seek": 233446, "start": 2334.46, "end": 2341.02, "text": " And I would, today I would probably say no, because then you're adding additional dependencies", "tokens": [400, 286, 576, 11, 965, 286, 576, 1391, 584, 572, 11, 570, 550, 291, 434, 5127, 4497, 36606], "temperature": 0.0, "avg_logprob": -0.23521580742400827, "compression_ratio": 1.7336065573770492, "no_speech_prob": 3.059014090922574e-07}, {"id": 583, "seek": 233446, "start": 2341.02, "end": 2345.42, "text": " and you should probably have a separate package with the Elm review rules.", "tokens": [293, 291, 820, 1391, 362, 257, 4994, 7372, 365, 264, 2699, 76, 3131, 4474, 13], "temperature": 0.0, "avg_logprob": -0.23521580742400827, "compression_ratio": 1.7336065573770492, "no_speech_prob": 3.059014090922574e-07}, {"id": 584, "seek": 233446, "start": 2345.42, "end": 2349.42, "text": " And I think I'm thinking maybe you should have that too for the scaffolding.", "tokens": [400, 286, 519, 286, 478, 1953, 1310, 291, 820, 362, 300, 886, 337, 264, 44094, 278, 13], "temperature": 0.0, "avg_logprob": -0.23521580742400827, "compression_ratio": 1.7336065573770492, "no_speech_prob": 3.059014090922574e-07}, {"id": 585, "seek": 233446, "start": 2349.42, "end": 2356.1, "text": " I mean, I think the challenge there is keeping them in sync between versions, because if", "tokens": [286, 914, 11, 286, 519, 264, 3430, 456, 307, 5145, 552, 294, 20271, 1296, 9606, 11, 570, 498], "temperature": 0.0, "avg_logprob": -0.23521580742400827, "compression_ratio": 1.7336065573770492, "no_speech_prob": 3.059014090922574e-07}, {"id": 586, "seek": 233446, "start": 2356.1, "end": 2361.86, "text": " it's in the same package, so like if you have a breaking change, how do you, how do you", "tokens": [309, 311, 294, 264, 912, 7372, 11, 370, 411, 498, 291, 362, 257, 7697, 1319, 11, 577, 360, 291, 11, 577, 360, 291], "temperature": 0.0, "avg_logprob": -0.23521580742400827, "compression_ratio": 1.7336065573770492, "no_speech_prob": 3.059014090922574e-07}, {"id": 587, "seek": 236186, "start": 2361.86, "end": 2367.58, "text": " make sure that the scaffolding tools are being run against the same target version?", "tokens": [652, 988, 300, 264, 44094, 278, 3873, 366, 885, 1190, 1970, 264, 912, 3779, 3037, 30], "temperature": 0.0, "avg_logprob": -0.33437875906626385, "compression_ratio": 1.6239669421487604, "no_speech_prob": 7.338158525271865e-07}, {"id": 588, "seek": 236186, "start": 2367.58, "end": 2371.46, "text": " That's one challenge that you introduce by having them be separate.", "tokens": [663, 311, 472, 3430, 300, 291, 5366, 538, 1419, 552, 312, 4994, 13], "temperature": 0.0, "avg_logprob": -0.33437875906626385, "compression_ratio": 1.6239669421487604, "no_speech_prob": 7.338158525271865e-07}, {"id": 589, "seek": 236186, "start": 2371.46, "end": 2372.46, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.33437875906626385, "compression_ratio": 1.6239669421487604, "no_speech_prob": 7.338158525271865e-07}, {"id": 590, "seek": 236186, "start": 2372.46, "end": 2377.2200000000003, "text": " But now, I mean, the problem with dependencies that you now depend on Elm Code Gen, which", "tokens": [583, 586, 11, 286, 914, 11, 264, 1154, 365, 36606, 300, 291, 586, 5672, 322, 2699, 76, 15549, 3632, 11, 597], "temperature": 0.0, "avg_logprob": -0.33437875906626385, "compression_ratio": 1.6239669421487604, "no_speech_prob": 7.338158525271865e-07}, {"id": 591, "seek": 236186, "start": 2377.2200000000003, "end": 2385.46, "text": " has maybe other dependencies, and now you risk of having like some major dependency", "tokens": [575, 1310, 661, 36606, 11, 293, 586, 291, 3148, 295, 1419, 411, 512, 2563, 33621], "temperature": 0.0, "avg_logprob": -0.33437875906626385, "compression_ratio": 1.6239669421487604, "no_speech_prob": 7.338158525271865e-07}, {"id": 592, "seek": 236186, "start": 2385.46, "end": 2390.94, "text": " version mismatches, which I always find very scary, at least.", "tokens": [3037, 23220, 852, 279, 11, 597, 286, 1009, 915, 588, 6958, 11, 412, 1935, 13], "temperature": 0.0, "avg_logprob": -0.33437875906626385, "compression_ratio": 1.6239669421487604, "no_speech_prob": 7.338158525271865e-07}, {"id": 593, "seek": 239094, "start": 2390.94, "end": 2391.94, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.24756665499705188, "compression_ratio": 1.708, "no_speech_prob": 1.9946735392295523e-06}, {"id": 594, "seek": 239094, "start": 2391.94, "end": 2399.9, "text": " So just to elaborate, for people who might not know, in Elm, pulling in dependencies", "tokens": [407, 445, 281, 20945, 11, 337, 561, 567, 1062, 406, 458, 11, 294, 2699, 76, 11, 8407, 294, 36606], "temperature": 0.0, "avg_logprob": -0.24756665499705188, "compression_ratio": 1.708, "no_speech_prob": 1.9946735392295523e-06}, {"id": 595, "seek": 239094, "start": 2399.9, "end": 2405.2200000000003, "text": " to a package doesn't eagerly pull in those dependencies to your actual code.", "tokens": [281, 257, 7372, 1177, 380, 18259, 356, 2235, 294, 729, 36606, 281, 428, 3539, 3089, 13], "temperature": 0.0, "avg_logprob": -0.24756665499705188, "compression_ratio": 1.708, "no_speech_prob": 1.9946735392295523e-06}, {"id": 596, "seek": 239094, "start": 2405.2200000000003, "end": 2410.86, "text": " So it's not like JavaScript that it is going to bloat your bundle size just because you", "tokens": [407, 309, 311, 406, 411, 15778, 300, 309, 307, 516, 281, 1749, 267, 428, 24438, 2744, 445, 570, 291], "temperature": 0.0, "avg_logprob": -0.24756665499705188, "compression_ratio": 1.708, "no_speech_prob": 1.9946735392295523e-06}, {"id": 597, "seek": 239094, "start": 2410.86, "end": 2416.46, "text": " depend on an extra dependency, or that it's going to install it for every single time", "tokens": [5672, 322, 364, 2857, 33621, 11, 420, 300, 309, 311, 516, 281, 3625, 309, 337, 633, 2167, 565], "temperature": 0.0, "avg_logprob": -0.24756665499705188, "compression_ratio": 1.708, "no_speech_prob": 1.9946735392295523e-06}, {"id": 598, "seek": 239094, "start": 2416.46, "end": 2420.58, "text": " you npm install your node modules is going to have a duplicate version of that code.", "tokens": [291, 297, 14395, 3625, 428, 9984, 16679, 307, 516, 281, 362, 257, 23976, 3037, 295, 300, 3089, 13], "temperature": 0.0, "avg_logprob": -0.24756665499705188, "compression_ratio": 1.708, "no_speech_prob": 1.9946735392295523e-06}, {"id": 599, "seek": 242058, "start": 2420.58, "end": 2423.98, "text": " And it's going to blow up your file size on your system.", "tokens": [400, 309, 311, 516, 281, 6327, 493, 428, 3991, 2744, 322, 428, 1185, 13], "temperature": 0.0, "avg_logprob": -0.209841825194278, "compression_ratio": 1.7811320754716982, "no_speech_prob": 2.2125499526737258e-05}, {"id": 600, "seek": 242058, "start": 2423.98, "end": 2427.22, "text": " There's a single shared place that it caches on your system.", "tokens": [821, 311, 257, 2167, 5507, 1081, 300, 309, 269, 13272, 322, 428, 1185, 13], "temperature": 0.0, "avg_logprob": -0.209841825194278, "compression_ratio": 1.7811320754716982, "no_speech_prob": 2.2125499526737258e-05}, {"id": 601, "seek": 242058, "start": 2427.22, "end": 2430.42, "text": " So it doesn't really cause problems for that.", "tokens": [407, 309, 1177, 380, 534, 3082, 2740, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.209841825194278, "compression_ratio": 1.7811320754716982, "no_speech_prob": 2.2125499526737258e-05}, {"id": 602, "seek": 242058, "start": 2430.42, "end": 2434.02, "text": " Elm has live code inclusion, or dead code elimination.", "tokens": [2699, 76, 575, 1621, 3089, 15874, 11, 420, 3116, 3089, 29224, 13], "temperature": 0.0, "avg_logprob": -0.209841825194278, "compression_ratio": 1.7811320754716982, "no_speech_prob": 2.2125499526737258e-05}, {"id": 603, "seek": 242058, "start": 2434.02, "end": 2438.62, "text": " So it doesn't really cause issues for that if you don't call a function in your production", "tokens": [407, 309, 1177, 380, 534, 3082, 2663, 337, 300, 498, 291, 500, 380, 818, 257, 2445, 294, 428, 4265], "temperature": 0.0, "avg_logprob": -0.209841825194278, "compression_ratio": 1.7811320754716982, "no_speech_prob": 2.2125499526737258e-05}, {"id": 604, "seek": 242058, "start": 2438.62, "end": 2442.2999999999997, "text": " code that uses the scaffolding thing, it doesn't pull in those dependencies.", "tokens": [3089, 300, 4960, 264, 44094, 278, 551, 11, 309, 1177, 380, 2235, 294, 729, 36606, 13], "temperature": 0.0, "avg_logprob": -0.209841825194278, "compression_ratio": 1.7811320754716982, "no_speech_prob": 2.2125499526737258e-05}, {"id": 605, "seek": 242058, "start": 2442.2999999999997, "end": 2448.66, "text": " But if you're upgrading to a new version of some package, and that dependency creates", "tokens": [583, 498, 291, 434, 36249, 281, 257, 777, 3037, 295, 512, 7372, 11, 293, 300, 33621, 7829], "temperature": 0.0, "avg_logprob": -0.209841825194278, "compression_ratio": 1.7811320754716982, "no_speech_prob": 2.2125499526737258e-05}, {"id": 606, "seek": 244866, "start": 2448.66, "end": 2452.94, "text": " a conflict between that upgrade, that's where it causes headaches.", "tokens": [257, 6596, 1296, 300, 11484, 11, 300, 311, 689, 309, 7700, 35046, 13], "temperature": 0.0, "avg_logprob": -0.3241096619636782, "compression_ratio": 1.5422222222222222, "no_speech_prob": 1.1189374617970316e-06}, {"id": 607, "seek": 244866, "start": 2452.94, "end": 2459.22, "text": " Yeah, it's mostly those Elm Community extra packages that scare me a lot.", "tokens": [865, 11, 309, 311, 5240, 729, 2699, 76, 10421, 2857, 17401, 300, 17185, 385, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.3241096619636782, "compression_ratio": 1.5422222222222222, "no_speech_prob": 1.1189374617970316e-06}, {"id": 608, "seek": 244866, "start": 2459.22, "end": 2464.74, "text": " Which often it's nice to just like inline those because it's not worth making it difficult", "tokens": [3013, 2049, 309, 311, 1481, 281, 445, 411, 294, 1889, 729, 570, 309, 311, 406, 3163, 1455, 309, 2252], "temperature": 0.0, "avg_logprob": -0.3241096619636782, "compression_ratio": 1.5422222222222222, "no_speech_prob": 1.1189374617970316e-06}, {"id": 609, "seek": 244866, "start": 2464.74, "end": 2465.98, "text": " for people to...", "tokens": [337, 561, 281, 485], "temperature": 0.0, "avg_logprob": -0.3241096619636782, "compression_ratio": 1.5422222222222222, "no_speech_prob": 1.1189374617970316e-06}, {"id": 610, "seek": 244866, "start": 2465.98, "end": 2466.98, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.3241096619636782, "compression_ratio": 1.5422222222222222, "no_speech_prob": 1.1189374617970316e-06}, {"id": 611, "seek": 244866, "start": 2466.98, "end": 2475.14, "text": " So again, to clarify, if there's a new major version of, let's say Elm Community list extra,", "tokens": [407, 797, 11, 281, 17594, 11, 498, 456, 311, 257, 777, 2563, 3037, 295, 11, 718, 311, 584, 2699, 76, 10421, 1329, 2857, 11], "temperature": 0.0, "avg_logprob": -0.3241096619636782, "compression_ratio": 1.5422222222222222, "no_speech_prob": 1.1189374617970316e-06}, {"id": 612, "seek": 247514, "start": 2475.14, "end": 2480.7, "text": " so there's v9, and then an old package or another package depends on v8, then you can't", "tokens": [370, 456, 311, 371, 24, 11, 293, 550, 364, 1331, 7372, 420, 1071, 7372, 5946, 322, 371, 23, 11, 550, 291, 393, 380], "temperature": 0.0, "avg_logprob": -0.26622157401226937, "compression_ratio": 1.4778761061946903, "no_speech_prob": 7.934459063108079e-07}, {"id": 613, "seek": 247514, "start": 2480.7, "end": 2486.7799999999997, "text": " install those two at the same time, because of how Elm works, which makes things simpler.", "tokens": [3625, 729, 732, 412, 264, 912, 565, 11, 570, 295, 577, 2699, 76, 1985, 11, 597, 1669, 721, 18587, 13], "temperature": 0.0, "avg_logprob": -0.26622157401226937, "compression_ratio": 1.4778761061946903, "no_speech_prob": 7.934459063108079e-07}, {"id": 614, "seek": 247514, "start": 2486.7799999999997, "end": 2490.02, "text": " But these kinds of problems do arise.", "tokens": [583, 613, 3685, 295, 2740, 360, 20288, 13], "temperature": 0.0, "avg_logprob": -0.26622157401226937, "compression_ratio": 1.4778761061946903, "no_speech_prob": 7.934459063108079e-07}, {"id": 615, "seek": 247514, "start": 2490.02, "end": 2497.42, "text": " Yeah, we need some sort of like scaffolding tool to inline extra helper functions.", "tokens": [865, 11, 321, 643, 512, 1333, 295, 411, 44094, 278, 2290, 281, 294, 1889, 2857, 36133, 6828, 13], "temperature": 0.0, "avg_logprob": -0.26622157401226937, "compression_ratio": 1.4778761061946903, "no_speech_prob": 7.934459063108079e-07}, {"id": 616, "seek": 247514, "start": 2497.42, "end": 2501.9, "text": " No, I mean, it's, it would be nice.", "tokens": [883, 11, 286, 914, 11, 309, 311, 11, 309, 576, 312, 1481, 13], "temperature": 0.0, "avg_logprob": -0.26622157401226937, "compression_ratio": 1.4778761061946903, "no_speech_prob": 7.934459063108079e-07}, {"id": 617, "seek": 250190, "start": 2501.9, "end": 2507.06, "text": " It's definitely not ideal to like copy paste these helpers into packages to reduce these", "tokens": [467, 311, 2138, 406, 7157, 281, 411, 5055, 9163, 613, 854, 433, 666, 17401, 281, 5407, 613], "temperature": 0.0, "avg_logprob": -0.28222753646525933, "compression_ratio": 1.6092436974789917, "no_speech_prob": 4.181175938811066e-07}, {"id": 618, "seek": 250190, "start": 2507.06, "end": 2508.06, "text": " dependencies.", "tokens": [36606, 13], "temperature": 0.0, "avg_logprob": -0.28222753646525933, "compression_ratio": 1.6092436974789917, "no_speech_prob": 4.181175938811066e-07}, {"id": 619, "seek": 250190, "start": 2508.06, "end": 2512.34, "text": " But if it's like one function from list extra or two functions from list extra, it's not", "tokens": [583, 498, 309, 311, 411, 472, 2445, 490, 1329, 2857, 420, 732, 6828, 490, 1329, 2857, 11, 309, 311, 406], "temperature": 0.0, "avg_logprob": -0.28222753646525933, "compression_ratio": 1.6092436974789917, "no_speech_prob": 4.181175938811066e-07}, {"id": 620, "seek": 250190, "start": 2512.34, "end": 2518.46, "text": " worth having users have that dependency dance if something has a breaking change.", "tokens": [3163, 1419, 5022, 362, 300, 33621, 4489, 498, 746, 575, 257, 7697, 1319, 13], "temperature": 0.0, "avg_logprob": -0.28222753646525933, "compression_ratio": 1.6092436974789917, "no_speech_prob": 4.181175938811066e-07}, {"id": 621, "seek": 250190, "start": 2518.46, "end": 2526.9, "text": " I mean, from what I understand, NPM has this ability to install multiple versions of a", "tokens": [286, 914, 11, 490, 437, 286, 1223, 11, 426, 18819, 575, 341, 3485, 281, 3625, 3866, 9606, 295, 257], "temperature": 0.0, "avg_logprob": -0.28222753646525933, "compression_ratio": 1.6092436974789917, "no_speech_prob": 4.181175938811066e-07}, {"id": 622, "seek": 250190, "start": 2526.9, "end": 2527.9, "text": " package, right?", "tokens": [7372, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.28222753646525933, "compression_ratio": 1.6092436974789917, "no_speech_prob": 4.181175938811066e-07}, {"id": 623, "seek": 250190, "start": 2527.9, "end": 2528.9, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.28222753646525933, "compression_ratio": 1.6092436974789917, "no_speech_prob": 4.181175938811066e-07}, {"id": 624, "seek": 252890, "start": 2528.9, "end": 2536.2200000000003, "text": " But that's also the reason why your node modules are so huge, because it installs plenty of", "tokens": [583, 300, 311, 611, 264, 1778, 983, 428, 9984, 16679, 366, 370, 2603, 11, 570, 309, 3625, 82, 7140, 295], "temperature": 0.0, "avg_logprob": -0.27871296803156537, "compression_ratio": 1.5940170940170941, "no_speech_prob": 2.6577137646199844e-07}, {"id": 625, "seek": 252890, "start": 2536.2200000000003, "end": 2541.94, "text": " those versions, because you can depend on packages so easily.", "tokens": [729, 9606, 11, 570, 291, 393, 5672, 322, 17401, 370, 3612, 13], "temperature": 0.0, "avg_logprob": -0.27871296803156537, "compression_ratio": 1.5940170940170941, "no_speech_prob": 2.6577137646199844e-07}, {"id": 626, "seek": 252890, "start": 2541.94, "end": 2542.94, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.27871296803156537, "compression_ratio": 1.5940170940170941, "no_speech_prob": 2.6577137646199844e-07}, {"id": 627, "seek": 252890, "start": 2542.94, "end": 2545.3, "text": " And it can cause weird unexpected behavior too, right?", "tokens": [400, 309, 393, 3082, 3657, 13106, 5223, 886, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.27871296803156537, "compression_ratio": 1.5940170940170941, "no_speech_prob": 2.6577137646199844e-07}, {"id": 628, "seek": 252890, "start": 2545.3, "end": 2550.94, "text": " So it's like, it definitely simplifies like reasoning about your code to be like, this", "tokens": [407, 309, 311, 411, 11, 309, 2138, 6883, 11221, 411, 21577, 466, 428, 3089, 281, 312, 411, 11, 341], "temperature": 0.0, "avg_logprob": -0.27871296803156537, "compression_ratio": 1.5940170940170941, "no_speech_prob": 2.6577137646199844e-07}, {"id": 629, "seek": 252890, "start": 2550.94, "end": 2555.26, "text": " is the version of this dependency that that all of my code uses.", "tokens": [307, 264, 3037, 295, 341, 33621, 300, 300, 439, 295, 452, 3089, 4960, 13], "temperature": 0.0, "avg_logprob": -0.27871296803156537, "compression_ratio": 1.5940170940170941, "no_speech_prob": 2.6577137646199844e-07}, {"id": 630, "seek": 252890, "start": 2555.26, "end": 2556.78, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.27871296803156537, "compression_ratio": 1.5940170940170941, "no_speech_prob": 2.6577137646199844e-07}, {"id": 631, "seek": 255678, "start": 2556.78, "end": 2563.34, "text": " So yeah, Elm has this little limit limitation, but yeah, we're looking at the node modules.", "tokens": [407, 1338, 11, 2699, 76, 575, 341, 707, 4948, 27432, 11, 457, 1338, 11, 321, 434, 1237, 412, 264, 9984, 16679, 13], "temperature": 0.0, "avg_logprob": -0.31430618162077617, "compression_ratio": 1.7639484978540771, "no_speech_prob": 5.626354777632514e-07}, {"id": 632, "seek": 255678, "start": 2563.34, "end": 2564.94, "text": " I'm like, yeah, this is pretty good.", "tokens": [286, 478, 411, 11, 1338, 11, 341, 307, 1238, 665, 13], "temperature": 0.0, "avg_logprob": -0.31430618162077617, "compression_ratio": 1.7639484978540771, "no_speech_prob": 5.626354777632514e-07}, {"id": 633, "seek": 255678, "start": 2564.94, "end": 2565.94, "text": " Actually.", "tokens": [5135, 13], "temperature": 0.0, "avg_logprob": -0.31430618162077617, "compression_ratio": 1.7639484978540771, "no_speech_prob": 5.626354777632514e-07}, {"id": 634, "seek": 255678, "start": 2565.94, "end": 2566.94, "text": " It's a pretty sane limitation.", "tokens": [467, 311, 257, 1238, 45610, 27432, 13], "temperature": 0.0, "avg_logprob": -0.31430618162077617, "compression_ratio": 1.7639484978540771, "no_speech_prob": 5.626354777632514e-07}, {"id": 635, "seek": 255678, "start": 2566.94, "end": 2567.94, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.31430618162077617, "compression_ratio": 1.7639484978540771, "no_speech_prob": 5.626354777632514e-07}, {"id": 636, "seek": 255678, "start": 2567.94, "end": 2568.94, "text": " It's a sane constraint.", "tokens": [467, 311, 257, 45610, 25534, 13], "temperature": 0.0, "avg_logprob": -0.31430618162077617, "compression_ratio": 1.7639484978540771, "no_speech_prob": 5.626354777632514e-07}, {"id": 637, "seek": 255678, "start": 2568.94, "end": 2570.82, "text": " Elm is good at this.", "tokens": [2699, 76, 307, 665, 412, 341, 13], "temperature": 0.0, "avg_logprob": -0.31430618162077617, "compression_ratio": 1.7639484978540771, "no_speech_prob": 5.626354777632514e-07}, {"id": 638, "seek": 255678, "start": 2570.82, "end": 2576.42, "text": " You mentioned inputs for the scaffolding, but you were talking about how do you integrate", "tokens": [509, 2835, 15743, 337, 264, 44094, 278, 11, 457, 291, 645, 1417, 466, 577, 360, 291, 13365], "temperature": 0.0, "avg_logprob": -0.31430618162077617, "compression_ratio": 1.7639484978540771, "no_speech_prob": 5.626354777632514e-07}, {"id": 639, "seek": 255678, "start": 2576.42, "end": 2577.42, "text": " these scaffoldings?", "tokens": [613, 44094, 1109, 30], "temperature": 0.0, "avg_logprob": -0.31430618162077617, "compression_ratio": 1.7639484978540771, "no_speech_prob": 5.626354777632514e-07}, {"id": 640, "seek": 255678, "start": 2577.42, "end": 2578.94, "text": " How do you use them?", "tokens": [1012, 360, 291, 764, 552, 30], "temperature": 0.0, "avg_logprob": -0.31430618162077617, "compression_ratio": 1.7639484978540771, "no_speech_prob": 5.626354777632514e-07}, {"id": 641, "seek": 255678, "start": 2578.94, "end": 2580.1000000000004, "text": " What method?", "tokens": [708, 3170, 30], "temperature": 0.0, "avg_logprob": -0.31430618162077617, "compression_ratio": 1.7639484978540771, "no_speech_prob": 5.626354777632514e-07}, {"id": 642, "seek": 255678, "start": 2580.1000000000004, "end": 2583.5, "text": " What about the inputs to the scaffolding tool?", "tokens": [708, 466, 264, 15743, 281, 264, 44094, 278, 2290, 30], "temperature": 0.0, "avg_logprob": -0.31430618162077617, "compression_ratio": 1.7639484978540771, "no_speech_prob": 5.626354777632514e-07}, {"id": 643, "seek": 258350, "start": 2583.5, "end": 2591.62, "text": " Like should you, for instance, should you have options to your scaffolding scripts?", "tokens": [1743, 820, 291, 11, 337, 5197, 11, 820, 291, 362, 3956, 281, 428, 44094, 278, 23294, 30], "temperature": 0.0, "avg_logprob": -0.2419770282247792, "compression_ratio": 1.6341463414634145, "no_speech_prob": 5.368677875594585e-07}, {"id": 644, "seek": 258350, "start": 2591.62, "end": 2597.78, "text": " Let's say we want to make a new module or let's make a new Elm project.", "tokens": [961, 311, 584, 321, 528, 281, 652, 257, 777, 10088, 420, 718, 311, 652, 257, 777, 2699, 76, 1716, 13], "temperature": 0.0, "avg_logprob": -0.2419770282247792, "compression_ratio": 1.6341463414634145, "no_speech_prob": 5.368677875594585e-07}, {"id": 645, "seek": 258350, "start": 2597.78, "end": 2604.42, "text": " Should we have an option to say, well, I want a browser sandbox or a browser elements or", "tokens": [6454, 321, 362, 364, 3614, 281, 584, 11, 731, 11, 286, 528, 257, 11185, 42115, 420, 257, 11185, 4959, 420], "temperature": 0.0, "avg_logprob": -0.2419770282247792, "compression_ratio": 1.6341463414634145, "no_speech_prob": 5.368677875594585e-07}, {"id": 646, "seek": 258350, "start": 2604.42, "end": 2607.06, "text": " a browser application and so on and so on.", "tokens": [257, 11185, 3861, 293, 370, 322, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.2419770282247792, "compression_ratio": 1.6341463414634145, "no_speech_prob": 5.368677875594585e-07}, {"id": 647, "seek": 258350, "start": 2607.06, "end": 2609.86, "text": " How custom do you think these should be?", "tokens": [1012, 2375, 360, 291, 519, 613, 820, 312, 30], "temperature": 0.0, "avg_logprob": -0.2419770282247792, "compression_ratio": 1.6341463414634145, "no_speech_prob": 5.368677875594585e-07}, {"id": 648, "seek": 258350, "start": 2609.86, "end": 2610.86, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.2419770282247792, "compression_ratio": 1.6341463414634145, "no_speech_prob": 5.368677875594585e-07}, {"id": 649, "seek": 261086, "start": 2610.86, "end": 2617.1800000000003, "text": " I think first of all, it has to beat copy pasting as a user experience.", "tokens": [286, 519, 700, 295, 439, 11, 309, 575, 281, 4224, 5055, 1791, 278, 382, 257, 4195, 1752, 13], "temperature": 0.0, "avg_logprob": -0.2661960491767296, "compression_ratio": 1.7355769230769231, "no_speech_prob": 3.927838179151877e-07}, {"id": 650, "seek": 261086, "start": 2617.1800000000003, "end": 2620.86, "text": " So that's one way to beat copy pasting as a user experience.", "tokens": [407, 300, 311, 472, 636, 281, 4224, 5055, 1791, 278, 382, 257, 4195, 1752, 13], "temperature": 0.0, "avg_logprob": -0.2661960491767296, "compression_ratio": 1.7355769230769231, "no_speech_prob": 3.927838179151877e-07}, {"id": 651, "seek": 261086, "start": 2620.86, "end": 2626.7400000000002, "text": " Now if you make the running the scaffolding tool overly complex, it's not going to beat", "tokens": [823, 498, 291, 652, 264, 2614, 264, 44094, 278, 2290, 24324, 3997, 11, 309, 311, 406, 516, 281, 4224], "temperature": 0.0, "avg_logprob": -0.2661960491767296, "compression_ratio": 1.7355769230769231, "no_speech_prob": 3.927838179151877e-07}, {"id": 652, "seek": 261086, "start": 2626.7400000000002, "end": 2628.86, "text": " copy paste, but fair.", "tokens": [5055, 9163, 11, 457, 3143, 13], "temperature": 0.0, "avg_logprob": -0.2661960491767296, "compression_ratio": 1.7355769230769231, "no_speech_prob": 3.927838179151877e-07}, {"id": 653, "seek": 261086, "start": 2628.86, "end": 2630.82, "text": " If you can have a nice CLI.", "tokens": [759, 291, 393, 362, 257, 1481, 12855, 40, 13], "temperature": 0.0, "avg_logprob": -0.2661960491767296, "compression_ratio": 1.7355769230769231, "no_speech_prob": 3.927838179151877e-07}, {"id": 654, "seek": 261086, "start": 2630.82, "end": 2638.56, "text": " Now Elm pages scripts have the option to do a CLI options parsing that's in pure Elm using", "tokens": [823, 2699, 76, 7183, 23294, 362, 264, 3614, 281, 360, 257, 12855, 40, 3956, 21156, 278, 300, 311, 294, 6075, 2699, 76, 1228], "temperature": 0.0, "avg_logprob": -0.2661960491767296, "compression_ratio": 1.7355769230769231, "no_speech_prob": 3.927838179151877e-07}, {"id": 655, "seek": 263856, "start": 2638.56, "end": 2641.9, "text": " my Elm CLI options parser package.", "tokens": [452, 2699, 76, 12855, 40, 3956, 21156, 260, 7372, 13], "temperature": 0.0, "avg_logprob": -0.2083510854969854, "compression_ratio": 1.7095435684647302, "no_speech_prob": 3.8069990182520996e-07}, {"id": 656, "seek": 263856, "start": 2641.9, "end": 2647.1, "text": " So you can use that to add configuration to a scaffolding script.", "tokens": [407, 291, 393, 764, 300, 281, 909, 11694, 281, 257, 44094, 278, 5755, 13], "temperature": 0.0, "avg_logprob": -0.2083510854969854, "compression_ratio": 1.7095435684647302, "no_speech_prob": 3.8069990182520996e-07}, {"id": 657, "seek": 263856, "start": 2647.1, "end": 2649.7, "text": " So I think that's like a pretty nice thing to do.", "tokens": [407, 286, 519, 300, 311, 411, 257, 1238, 1481, 551, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.2083510854969854, "compression_ratio": 1.7095435684647302, "no_speech_prob": 3.8069990182520996e-07}, {"id": 658, "seek": 263856, "start": 2649.7, "end": 2654.18, "text": " If there's like one little flag you want to add to configure one, one change, you should", "tokens": [759, 456, 311, 411, 472, 707, 7166, 291, 528, 281, 909, 281, 22162, 472, 11, 472, 1319, 11, 291, 820], "temperature": 0.0, "avg_logprob": -0.2083510854969854, "compression_ratio": 1.7095435684647302, "no_speech_prob": 3.8069990182520996e-07}, {"id": 659, "seek": 263856, "start": 2654.18, "end": 2655.18, "text": " do that.", "tokens": [360, 300, 13], "temperature": 0.0, "avg_logprob": -0.2083510854969854, "compression_ratio": 1.7095435684647302, "no_speech_prob": 3.8069990182520996e-07}, {"id": 660, "seek": 263856, "start": 2655.18, "end": 2661.42, "text": " Do you think it's nice for a scaffolding tool to have a few prompt questions or should everything", "tokens": [1144, 291, 519, 309, 311, 1481, 337, 257, 44094, 278, 2290, 281, 362, 257, 1326, 12391, 1651, 420, 820, 1203], "temperature": 0.0, "avg_logprob": -0.2083510854969854, "compression_ratio": 1.7095435684647302, "no_speech_prob": 3.8069990182520996e-07}, {"id": 661, "seek": 263856, "start": 2661.42, "end": 2664.98, "text": " be configurable through the CLI flags?", "tokens": [312, 22192, 712, 807, 264, 12855, 40, 23265, 30], "temperature": 0.0, "avg_logprob": -0.2083510854969854, "compression_ratio": 1.7095435684647302, "no_speech_prob": 3.8069990182520996e-07}, {"id": 662, "seek": 263856, "start": 2664.98, "end": 2666.7799999999997, "text": " I mean, you could do both.", "tokens": [286, 914, 11, 291, 727, 360, 1293, 13], "temperature": 0.0, "avg_logprob": -0.2083510854969854, "compression_ratio": 1.7095435684647302, "no_speech_prob": 3.8069990182520996e-07}, {"id": 663, "seek": 266678, "start": 2666.78, "end": 2671.94, "text": " Like if you provide something with the CLI flag that you don't have to ask the question,", "tokens": [1743, 498, 291, 2893, 746, 365, 264, 12855, 40, 7166, 300, 291, 500, 380, 362, 281, 1029, 264, 1168, 11], "temperature": 0.0, "avg_logprob": -0.2327695412210899, "compression_ratio": 1.59915611814346, "no_speech_prob": 2.457984464854235e-07}, {"id": 664, "seek": 266678, "start": 2671.94, "end": 2678.6600000000003, "text": " but they're not necessarily as discoverable or have the same amount of explanation in", "tokens": [457, 436, 434, 406, 4725, 382, 4411, 712, 420, 362, 264, 912, 2372, 295, 10835, 294], "temperature": 0.0, "avg_logprob": -0.2327695412210899, "compression_ratio": 1.59915611814346, "no_speech_prob": 2.457984464854235e-07}, {"id": 665, "seek": 266678, "start": 2678.6600000000003, "end": 2679.6600000000003, "text": " the prompt.", "tokens": [264, 12391, 13], "temperature": 0.0, "avg_logprob": -0.2327695412210899, "compression_ratio": 1.59915611814346, "no_speech_prob": 2.457984464854235e-07}, {"id": 666, "seek": 266678, "start": 2679.6600000000003, "end": 2680.6600000000003, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.2327695412210899, "compression_ratio": 1.59915611814346, "no_speech_prob": 2.457984464854235e-07}, {"id": 667, "seek": 266678, "start": 2680.6600000000003, "end": 2683.7400000000002, "text": " I quite like prompts, but it does make things a bit slower.", "tokens": [286, 1596, 411, 41095, 11, 457, 309, 775, 652, 721, 257, 857, 14009, 13], "temperature": 0.0, "avg_logprob": -0.2327695412210899, "compression_ratio": 1.59915611814346, "no_speech_prob": 2.457984464854235e-07}, {"id": 668, "seek": 266678, "start": 2683.7400000000002, "end": 2684.7400000000002, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.2327695412210899, "compression_ratio": 1.59915611814346, "no_speech_prob": 2.457984464854235e-07}, {"id": 669, "seek": 266678, "start": 2684.7400000000002, "end": 2685.7400000000002, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2327695412210899, "compression_ratio": 1.59915611814346, "no_speech_prob": 2.457984464854235e-07}, {"id": 670, "seek": 266678, "start": 2685.7400000000002, "end": 2690.98, "text": " It's definitely a trade off between ease of discovery versus ease of use once you've gotten", "tokens": [467, 311, 2138, 257, 4923, 766, 1296, 12708, 295, 12114, 5717, 12708, 295, 764, 1564, 291, 600, 5768], "temperature": 0.0, "avg_logprob": -0.2327695412210899, "compression_ratio": 1.59915611814346, "no_speech_prob": 2.457984464854235e-07}, {"id": 671, "seek": 266678, "start": 2690.98, "end": 2692.02, "text": " comfortable with it.", "tokens": [4619, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.2327695412210899, "compression_ratio": 1.59915611814346, "no_speech_prob": 2.457984464854235e-07}, {"id": 672, "seek": 269202, "start": 2692.02, "end": 2700.62, "text": " So I mean, sometimes tools will sort of have a required flag, but if you don't pass in", "tokens": [407, 286, 914, 11, 2171, 3873, 486, 1333, 295, 362, 257, 4739, 7166, 11, 457, 498, 291, 500, 380, 1320, 294], "temperature": 0.0, "avg_logprob": -0.22669769836975648, "compression_ratio": 1.5755102040816327, "no_speech_prob": 1.101586349250283e-06}, {"id": 673, "seek": 269202, "start": 2700.62, "end": 2703.7, "text": " that flag to the CLI, it will prompt you for it.", "tokens": [300, 7166, 281, 264, 12855, 40, 11, 309, 486, 12391, 291, 337, 309, 13], "temperature": 0.0, "avg_logprob": -0.22669769836975648, "compression_ratio": 1.5755102040816327, "no_speech_prob": 1.101586349250283e-06}, {"id": 674, "seek": 269202, "start": 2703.7, "end": 2705.06, "text": " That can be a nice way to do it.", "tokens": [663, 393, 312, 257, 1481, 636, 281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.22669769836975648, "compression_ratio": 1.5755102040816327, "no_speech_prob": 1.101586349250283e-06}, {"id": 675, "seek": 269202, "start": 2705.06, "end": 2707.34, "text": " Sort of a best of both worlds approach.", "tokens": [26149, 295, 257, 1151, 295, 1293, 13401, 3109, 13], "temperature": 0.0, "avg_logprob": -0.22669769836975648, "compression_ratio": 1.5755102040816327, "no_speech_prob": 1.101586349250283e-06}, {"id": 676, "seek": 269202, "start": 2707.34, "end": 2713.9, "text": " It strikes me too that like, so with these magic debug.todo comments that an Elm review", "tokens": [467, 16750, 385, 886, 300, 411, 11, 370, 365, 613, 5585, 24083, 13, 83, 17423, 3053, 300, 364, 2699, 76, 3131], "temperature": 0.0, "avg_logprob": -0.22669769836975648, "compression_ratio": 1.5755102040816327, "no_speech_prob": 1.101586349250283e-06}, {"id": 677, "seek": 269202, "start": 2713.9, "end": 2721.22, "text": " rule can find with the special string in there, you could, you know, I think it's good to", "tokens": [4978, 393, 915, 365, 264, 2121, 6798, 294, 456, 11, 291, 727, 11, 291, 458, 11, 286, 519, 309, 311, 665, 281], "temperature": 0.0, "avg_logprob": -0.22669769836975648, "compression_ratio": 1.5755102040816327, "no_speech_prob": 1.101586349250283e-06}, {"id": 678, "seek": 272122, "start": 2721.22, "end": 2723.22, "text": " have conventions for these types of things.", "tokens": [362, 33520, 337, 613, 3467, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.21800707807444564, "compression_ratio": 1.6359832635983265, "no_speech_prob": 1.7061732933143503e-06}, {"id": 679, "seek": 272122, "start": 2723.22, "end": 2724.5, "text": " So they're discoverable.", "tokens": [407, 436, 434, 4411, 712, 13], "temperature": 0.0, "avg_logprob": -0.21800707807444564, "compression_ratio": 1.6359832635983265, "no_speech_prob": 1.7061732933143503e-06}, {"id": 680, "seek": 272122, "start": 2724.5, "end": 2731.1, "text": " You could even imagine having like, I don't know, let's say that all of your magic debug.todo", "tokens": [509, 727, 754, 3811, 1419, 411, 11, 286, 500, 380, 458, 11, 718, 311, 584, 300, 439, 295, 428, 5585, 24083, 13, 83, 17423], "temperature": 0.0, "avg_logprob": -0.21800707807444564, "compression_ratio": 1.6359832635983265, "no_speech_prob": 1.7061732933143503e-06}, {"id": 681, "seek": 272122, "start": 2731.1, "end": 2734.18, "text": " comments start with triple exclamation point.", "tokens": [3053, 722, 365, 15508, 1624, 43233, 935, 13], "temperature": 0.0, "avg_logprob": -0.21800707807444564, "compression_ratio": 1.6359832635983265, "no_speech_prob": 1.7061732933143503e-06}, {"id": 682, "seek": 272122, "start": 2734.18, "end": 2742.7, "text": " So you have three exclamation marks and then maybe the Elm review rule watcher that's running", "tokens": [407, 291, 362, 1045, 1624, 43233, 10640, 293, 550, 1310, 264, 2699, 76, 3131, 4978, 1159, 260, 300, 311, 2614], "temperature": 0.0, "avg_logprob": -0.21800707807444564, "compression_ratio": 1.6359832635983265, "no_speech_prob": 1.7061732933143503e-06}, {"id": 683, "seek": 272122, "start": 2742.7, "end": 2748.3799999999997, "text": " in the background says like, instead of giving a fix, if you just have three exclamation", "tokens": [294, 264, 3678, 1619, 411, 11, 2602, 295, 2902, 257, 3191, 11, 498, 291, 445, 362, 1045, 1624, 43233], "temperature": 0.0, "avg_logprob": -0.21800707807444564, "compression_ratio": 1.6359832635983265, "no_speech_prob": 1.7061732933143503e-06}, {"id": 684, "seek": 274838, "start": 2748.38, "end": 2754.7400000000002, "text": " points without anything after it, maybe it says, Hey, here are the ways to fix that.", "tokens": [2793, 1553, 1340, 934, 309, 11, 1310, 309, 1619, 11, 1911, 11, 510, 366, 264, 2098, 281, 3191, 300, 13], "temperature": 0.0, "avg_logprob": -0.24639503554542466, "compression_ratio": 1.653386454183267, "no_speech_prob": 1.2289133337617386e-06}, {"id": 685, "seek": 274838, "start": 2754.7400000000002, "end": 2757.2200000000003, "text": " Here are the options you can pass me.", "tokens": [1692, 366, 264, 3956, 291, 393, 1320, 385, 13], "temperature": 0.0, "avg_logprob": -0.24639503554542466, "compression_ratio": 1.653386454183267, "no_speech_prob": 1.2289133337617386e-06}, {"id": 686, "seek": 274838, "start": 2757.2200000000003, "end": 2761.5, "text": " So you could have a discoverability experience through that.", "tokens": [407, 291, 727, 362, 257, 4411, 2310, 1752, 807, 300, 13], "temperature": 0.0, "avg_logprob": -0.24639503554542466, "compression_ratio": 1.653386454183267, "no_speech_prob": 1.2289133337617386e-06}, {"id": 687, "seek": 274838, "start": 2761.5, "end": 2762.9, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.24639503554542466, "compression_ratio": 1.653386454183267, "no_speech_prob": 1.2289133337617386e-06}, {"id": 688, "seek": 274838, "start": 2762.9, "end": 2766.38, "text": " So like, I think there's a UX opportunity here.", "tokens": [407, 411, 11, 286, 519, 456, 311, 257, 40176, 2650, 510, 13], "temperature": 0.0, "avg_logprob": -0.24639503554542466, "compression_ratio": 1.653386454183267, "no_speech_prob": 1.2289133337617386e-06}, {"id": 689, "seek": 274838, "start": 2766.38, "end": 2772.1400000000003, "text": " It could even be an interesting thing to have like a shared package to crystallize some", "tokens": [467, 727, 754, 312, 364, 1880, 551, 281, 362, 411, 257, 5507, 7372, 281, 31924, 1125, 512], "temperature": 0.0, "avg_logprob": -0.24639503554542466, "compression_ratio": 1.653386454183267, "no_speech_prob": 1.2289133337617386e-06}, {"id": 690, "seek": 274838, "start": 2772.1400000000003, "end": 2776.82, "text": " of these conventions, because I think like conventions are important for user experience", "tokens": [295, 613, 33520, 11, 570, 286, 519, 411, 33520, 366, 1021, 337, 4195, 1752], "temperature": 0.0, "avg_logprob": -0.24639503554542466, "compression_ratio": 1.653386454183267, "no_speech_prob": 1.2289133337617386e-06}, {"id": 691, "seek": 277682, "start": 2776.82, "end": 2781.2200000000003, "text": " because otherwise like people aren't going to go to the readme to look it up.", "tokens": [570, 5911, 411, 561, 3212, 380, 516, 281, 352, 281, 264, 1401, 1398, 281, 574, 309, 493, 13], "temperature": 0.0, "avg_logprob": -0.2140586432509535, "compression_ratio": 1.8284671532846715, "no_speech_prob": 1.0030082648881944e-06}, {"id": 692, "seek": 277682, "start": 2781.2200000000003, "end": 2784.3, "text": " You have to like make it more within reach.", "tokens": [509, 362, 281, 411, 652, 309, 544, 1951, 2524, 13], "temperature": 0.0, "avg_logprob": -0.2140586432509535, "compression_ratio": 1.8284671532846715, "no_speech_prob": 1.0030082648881944e-06}, {"id": 693, "seek": 277682, "start": 2784.3, "end": 2788.42, "text": " We just have to understand that about people that they're probably not going to read the", "tokens": [492, 445, 362, 281, 1223, 300, 466, 561, 300, 436, 434, 1391, 406, 516, 281, 1401, 264], "temperature": 0.0, "avg_logprob": -0.2140586432509535, "compression_ratio": 1.8284671532846715, "no_speech_prob": 1.0030082648881944e-06}, {"id": 694, "seek": 277682, "start": 2788.42, "end": 2793.1000000000004, "text": " readme, but if we make it easy for them to guide them in the right direction, when they", "tokens": [1401, 1398, 11, 457, 498, 321, 652, 309, 1858, 337, 552, 281, 5934, 552, 294, 264, 558, 3513, 11, 562, 436], "temperature": 0.0, "avg_logprob": -0.2140586432509535, "compression_ratio": 1.8284671532846715, "no_speech_prob": 1.0030082648881944e-06}, {"id": 695, "seek": 277682, "start": 2793.1000000000004, "end": 2797.02, "text": " try to do something, they might actually use it instead of copy paste.", "tokens": [853, 281, 360, 746, 11, 436, 1062, 767, 764, 309, 2602, 295, 5055, 9163, 13], "temperature": 0.0, "avg_logprob": -0.2140586432509535, "compression_ratio": 1.8284671532846715, "no_speech_prob": 1.0030082648881944e-06}, {"id": 696, "seek": 277682, "start": 2797.02, "end": 2800.3, "text": " That's actually something that is, that's actually something that I find it to be a", "tokens": [663, 311, 767, 746, 300, 307, 11, 300, 311, 767, 746, 300, 286, 915, 309, 281, 312, 257], "temperature": 0.0, "avg_logprob": -0.2140586432509535, "compression_ratio": 1.8284671532846715, "no_speech_prob": 1.0030082648881944e-06}, {"id": 697, "seek": 277682, "start": 2800.3, "end": 2803.7400000000002, "text": " bit of a shame that it's not very discoverable.", "tokens": [857, 295, 257, 10069, 300, 309, 311, 406, 588, 4411, 712, 13], "temperature": 0.0, "avg_logprob": -0.2140586432509535, "compression_ratio": 1.8284671532846715, "no_speech_prob": 1.0030082648881944e-06}, {"id": 698, "seek": 280374, "start": 2803.74, "end": 2808.8999999999996, "text": " So for instance, if we're pairing together and I'm running a function or actually you", "tokens": [407, 337, 5197, 11, 498, 321, 434, 32735, 1214, 293, 286, 478, 2614, 257, 2445, 420, 767, 291], "temperature": 0.0, "avg_logprob": -0.24669294357299804, "compression_ratio": 1.7075098814229248, "no_speech_prob": 9.57074121288315e-07}, {"id": 699, "seek": 280374, "start": 2808.8999999999996, "end": 2814.66, "text": " just look at my code, because I've sent you a pull request and you see a function that", "tokens": [445, 574, 412, 452, 3089, 11, 570, 286, 600, 2279, 291, 257, 2235, 5308, 293, 291, 536, 257, 2445, 300], "temperature": 0.0, "avg_logprob": -0.24669294357299804, "compression_ratio": 1.7075098814229248, "no_speech_prob": 9.57074121288315e-07}, {"id": 700, "seek": 280374, "start": 2814.66, "end": 2819.62, "text": " I've used and you've never seen before, or you go to the documentation and you see, Oh,", "tokens": [286, 600, 1143, 293, 291, 600, 1128, 1612, 949, 11, 420, 291, 352, 281, 264, 14333, 293, 291, 536, 11, 876, 11], "temperature": 0.0, "avg_logprob": -0.24669294357299804, "compression_ratio": 1.7075098814229248, "no_speech_prob": 9.57074121288315e-07}, {"id": 701, "seek": 280374, "start": 2819.62, "end": 2821.7799999999997, "text": " well, list.partition is a thing.", "tokens": [731, 11, 1329, 13, 6971, 849, 307, 257, 551, 13], "temperature": 0.0, "avg_logprob": -0.24669294357299804, "compression_ratio": 1.7075098814229248, "no_speech_prob": 9.57074121288315e-07}, {"id": 702, "seek": 280374, "start": 2821.7799999999997, "end": 2823.62, "text": " Oh, that could be pretty useful.", "tokens": [876, 11, 300, 727, 312, 1238, 4420, 13], "temperature": 0.0, "avg_logprob": -0.24669294357299804, "compression_ratio": 1.7075098814229248, "no_speech_prob": 9.57074121288315e-07}, {"id": 703, "seek": 280374, "start": 2823.62, "end": 2825.24, "text": " I will use that next time.", "tokens": [286, 486, 764, 300, 958, 565, 13], "temperature": 0.0, "avg_logprob": -0.24669294357299804, "compression_ratio": 1.7075098814229248, "no_speech_prob": 9.57074121288315e-07}, {"id": 704, "seek": 280374, "start": 2825.24, "end": 2829.3399999999997, "text": " But you can see that because it's in the code and it's committed and all that.", "tokens": [583, 291, 393, 536, 300, 570, 309, 311, 294, 264, 3089, 293, 309, 311, 7784, 293, 439, 300, 13], "temperature": 0.0, "avg_logprob": -0.24669294357299804, "compression_ratio": 1.7075098814229248, "no_speech_prob": 9.57074121288315e-07}, {"id": 705, "seek": 282934, "start": 2829.34, "end": 2834.54, "text": " But all the things that I have done that you have not seen because it's not committed,", "tokens": [583, 439, 264, 721, 300, 286, 362, 1096, 300, 291, 362, 406, 1612, 570, 309, 311, 406, 7784, 11], "temperature": 0.0, "avg_logprob": -0.30339660066546814, "compression_ratio": 1.7927272727272727, "no_speech_prob": 8.186310651581152e-07}, {"id": 706, "seek": 282934, "start": 2834.54, "end": 2838.82, "text": " like all the keyboard shortcuts that I use, all the editor integration that I use, all", "tokens": [411, 439, 264, 10186, 34620, 300, 286, 764, 11, 439, 264, 9839, 10980, 300, 286, 764, 11, 439], "temperature": 0.0, "avg_logprob": -0.30339660066546814, "compression_ratio": 1.7927272727272727, "no_speech_prob": 8.186310651581152e-07}, {"id": 707, "seek": 282934, "start": 2838.82, "end": 2843.02, "text": " the scaffolding tools that I use, you don't see them.", "tokens": [264, 44094, 278, 3873, 300, 286, 764, 11, 291, 500, 380, 536, 552, 13], "temperature": 0.0, "avg_logprob": -0.30339660066546814, "compression_ratio": 1.7927272727272727, "no_speech_prob": 8.186310651581152e-07}, {"id": 708, "seek": 282934, "start": 2843.02, "end": 2847.48, "text": " That's actually like one of the reason why people say, Oh, you should pair together because", "tokens": [663, 311, 767, 411, 472, 295, 264, 1778, 983, 561, 584, 11, 876, 11, 291, 820, 6119, 1214, 570], "temperature": 0.0, "avg_logprob": -0.30339660066546814, "compression_ratio": 1.7927272727272727, "no_speech_prob": 8.186310651581152e-07}, {"id": 709, "seek": 282934, "start": 2847.48, "end": 2850.86, "text": " that's when you learn so many new things.", "tokens": [300, 311, 562, 291, 1466, 370, 867, 777, 721, 13], "temperature": 0.0, "avg_logprob": -0.30339660066546814, "compression_ratio": 1.7927272727272727, "no_speech_prob": 8.186310651581152e-07}, {"id": 710, "seek": 282934, "start": 2850.86, "end": 2853.38, "text": " Every time I pair, I learn a new thing with someone.", "tokens": [2048, 565, 286, 6119, 11, 286, 1466, 257, 777, 551, 365, 1580, 13], "temperature": 0.0, "avg_logprob": -0.30339660066546814, "compression_ratio": 1.7927272727272727, "no_speech_prob": 8.186310651581152e-07}, {"id": 711, "seek": 282934, "start": 2853.38, "end": 2854.38, "text": " A hundred percent.", "tokens": [316, 3262, 3043, 13], "temperature": 0.0, "avg_logprob": -0.30339660066546814, "compression_ratio": 1.7927272727272727, "no_speech_prob": 8.186310651581152e-07}, {"id": 712, "seek": 282934, "start": 2854.38, "end": 2856.46, "text": " Or teach someone something new.", "tokens": [1610, 2924, 1580, 746, 777, 13], "temperature": 0.0, "avg_logprob": -0.30339660066546814, "compression_ratio": 1.7927272727272727, "no_speech_prob": 8.186310651581152e-07}, {"id": 713, "seek": 282934, "start": 2856.46, "end": 2857.46, "text": " It goes both ways.", "tokens": [467, 1709, 1293, 2098, 13], "temperature": 0.0, "avg_logprob": -0.30339660066546814, "compression_ratio": 1.7927272727272727, "no_speech_prob": 8.186310651581152e-07}, {"id": 714, "seek": 282934, "start": 2857.46, "end": 2858.46, "text": " Totally.", "tokens": [22837, 13], "temperature": 0.0, "avg_logprob": -0.30339660066546814, "compression_ratio": 1.7927272727272727, "no_speech_prob": 8.186310651581152e-07}, {"id": 715, "seek": 285846, "start": 2858.46, "end": 2859.46, "text": " I agree.", "tokens": [286, 3986, 13], "temperature": 0.0, "avg_logprob": -0.27671164654670877, "compression_ratio": 1.6901408450704225, "no_speech_prob": 1.7603160813450813e-06}, {"id": 716, "seek": 285846, "start": 2859.46, "end": 2867.18, "text": " And workflow, like, I mean, one thing I really learned from a lot of sort of people in these", "tokens": [400, 20993, 11, 411, 11, 286, 914, 11, 472, 551, 286, 534, 3264, 490, 257, 688, 295, 1333, 295, 561, 294, 613], "temperature": 0.0, "avg_logprob": -0.27671164654670877, "compression_ratio": 1.6901408450704225, "no_speech_prob": 1.7603160813450813e-06}, {"id": 717, "seek": 285846, "start": 2867.18, "end": 2876.9, "text": " software craftsmanship circles is like, workflow and automation are not just like a vanity", "tokens": [4722, 8448, 10817, 27140, 13040, 307, 411, 11, 20993, 293, 17769, 366, 406, 445, 411, 257, 44622], "temperature": 0.0, "avg_logprob": -0.27671164654670877, "compression_ratio": 1.6901408450704225, "no_speech_prob": 1.7603160813450813e-06}, {"id": 718, "seek": 285846, "start": 2876.9, "end": 2881.0, "text": " sort of cool way to customize your system.", "tokens": [1333, 295, 1627, 636, 281, 19734, 428, 1185, 13], "temperature": 0.0, "avg_logprob": -0.27671164654670877, "compression_ratio": 1.6901408450704225, "no_speech_prob": 1.7603160813450813e-06}, {"id": 719, "seek": 285846, "start": 2881.0, "end": 2885.94, "text": " It's not like, Whoa, look at this cool theme I have and look at this cool shortcut I have", "tokens": [467, 311, 406, 411, 11, 7521, 11, 574, 412, 341, 1627, 6314, 286, 362, 293, 574, 412, 341, 1627, 24822, 286, 362], "temperature": 0.0, "avg_logprob": -0.27671164654670877, "compression_ratio": 1.6901408450704225, "no_speech_prob": 1.7603160813450813e-06}, {"id": 720, "seek": 285846, "start": 2885.94, "end": 2887.66, "text": " for this and this cool automation.", "tokens": [337, 341, 293, 341, 1627, 17769, 13], "temperature": 0.0, "avg_logprob": -0.27671164654670877, "compression_ratio": 1.6901408450704225, "no_speech_prob": 1.7603160813450813e-06}, {"id": 721, "seek": 288766, "start": 2887.66, "end": 2894.42, "text": " It's like, no, actually, like automating things is a really important part of like building", "tokens": [467, 311, 411, 11, 572, 11, 767, 11, 411, 3553, 990, 721, 307, 257, 534, 1021, 644, 295, 411, 2390], "temperature": 0.0, "avg_logprob": -0.26975421905517577, "compression_ratio": 1.6274509803921569, "no_speech_prob": 1.2482661304602516e-06}, {"id": 722, "seek": 288766, "start": 2894.42, "end": 2895.42, "text": " great software.", "tokens": [869, 4722, 13], "temperature": 0.0, "avg_logprob": -0.26975421905517577, "compression_ratio": 1.6274509803921569, "no_speech_prob": 1.2482661304602516e-06}, {"id": 723, "seek": 288766, "start": 2895.42, "end": 2902.54, "text": " In my view of building great software, like this is a key way to get better at doing that.", "tokens": [682, 452, 1910, 295, 2390, 869, 4722, 11, 411, 341, 307, 257, 2141, 636, 281, 483, 1101, 412, 884, 300, 13], "temperature": 0.0, "avg_logprob": -0.26975421905517577, "compression_ratio": 1.6274509803921569, "no_speech_prob": 1.2482661304602516e-06}, {"id": 724, "seek": 288766, "start": 2902.54, "end": 2904.46, "text": " So I think it's be taken seriously.", "tokens": [407, 286, 519, 309, 311, 312, 2726, 6638, 13], "temperature": 0.0, "avg_logprob": -0.26975421905517577, "compression_ratio": 1.6274509803921569, "no_speech_prob": 1.2482661304602516e-06}, {"id": 725, "seek": 288766, "start": 2904.46, "end": 2905.46, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.26975421905517577, "compression_ratio": 1.6274509803921569, "no_speech_prob": 1.2482661304602516e-06}, {"id": 726, "seek": 288766, "start": 2905.46, "end": 2914.14, "text": " I mean, it would be hard to argue that using notepad is the way to write applications today", "tokens": [286, 914, 11, 309, 576, 312, 1152, 281, 9695, 300, 1228, 406, 595, 345, 307, 264, 636, 281, 2464, 5821, 965], "temperature": 0.0, "avg_logprob": -0.26975421905517577, "compression_ratio": 1.6274509803921569, "no_speech_prob": 1.2482661304602516e-06}, {"id": 727, "seek": 291414, "start": 2914.14, "end": 2917.7799999999997, "text": " when the only shortcuts you have is control C and control V.", "tokens": [562, 264, 787, 34620, 291, 362, 307, 1969, 383, 293, 1969, 691, 13], "temperature": 0.0, "avg_logprob": -0.29166266399881113, "compression_ratio": 1.606177606177606, "no_speech_prob": 2.873672997338872e-07}, {"id": 728, "seek": 291414, "start": 2917.7799999999997, "end": 2918.7799999999997, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.29166266399881113, "compression_ratio": 1.606177606177606, "no_speech_prob": 2.873672997338872e-07}, {"id": 729, "seek": 291414, "start": 2918.7799999999997, "end": 2923.66, "text": " So yeah, you know, all the things that a editor gives you, even a simple one, well, they're", "tokens": [407, 1338, 11, 291, 458, 11, 439, 264, 721, 300, 257, 9839, 2709, 291, 11, 754, 257, 2199, 472, 11, 731, 11, 436, 434], "temperature": 0.0, "avg_logprob": -0.29166266399881113, "compression_ratio": 1.606177606177606, "no_speech_prob": 2.873672997338872e-07}, {"id": 730, "seek": 291414, "start": 2923.66, "end": 2924.66, "text": " useful.", "tokens": [4420, 13], "temperature": 0.0, "avg_logprob": -0.29166266399881113, "compression_ratio": 1.606177606177606, "no_speech_prob": 2.873672997338872e-07}, {"id": 731, "seek": 291414, "start": 2924.66, "end": 2925.66, "text": " They're really useful.", "tokens": [814, 434, 534, 4420, 13], "temperature": 0.0, "avg_logprob": -0.29166266399881113, "compression_ratio": 1.606177606177606, "no_speech_prob": 2.873672997338872e-07}, {"id": 732, "seek": 291414, "start": 2925.66, "end": 2926.66, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.29166266399881113, "compression_ratio": 1.606177606177606, "no_speech_prob": 2.873672997338872e-07}, {"id": 733, "seek": 291414, "start": 2926.66, "end": 2931.14, "text": " And again, because it helps you get to those atomic steps of changing things.", "tokens": [400, 797, 11, 570, 309, 3665, 291, 483, 281, 729, 22275, 4439, 295, 4473, 721, 13], "temperature": 0.0, "avg_logprob": -0.29166266399881113, "compression_ratio": 1.606177606177606, "no_speech_prob": 2.873672997338872e-07}, {"id": 734, "seek": 291414, "start": 2931.14, "end": 2936.74, "text": " Now, I'm not going to say that somebody can't create great software without these things.", "tokens": [823, 11, 286, 478, 406, 516, 281, 584, 300, 2618, 393, 380, 1884, 869, 4722, 1553, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.29166266399881113, "compression_ratio": 1.606177606177606, "no_speech_prob": 2.873672997338872e-07}, {"id": 735, "seek": 291414, "start": 2936.74, "end": 2941.54, "text": " It's just like they're missing out on a superpower.", "tokens": [467, 311, 445, 411, 436, 434, 5361, 484, 322, 257, 45765, 13], "temperature": 0.0, "avg_logprob": -0.29166266399881113, "compression_ratio": 1.606177606177606, "no_speech_prob": 2.873672997338872e-07}, {"id": 736, "seek": 294154, "start": 2941.54, "end": 2950.2599999999998, "text": " You can also like another superpower is being really good at modeling systems and knowing", "tokens": [509, 393, 611, 411, 1071, 45765, 307, 885, 534, 665, 412, 15983, 3652, 293, 5276], "temperature": 0.0, "avg_logprob": -0.23236487539190995, "compression_ratio": 1.6566523605150214, "no_speech_prob": 2.812996399370604e-06}, {"id": 737, "seek": 294154, "start": 2950.2599999999998, "end": 2956.66, "text": " when to say no to certain features and writing tests first and things that you can do without", "tokens": [562, 281, 584, 572, 281, 1629, 4122, 293, 3579, 6921, 700, 293, 721, 300, 291, 393, 360, 1553], "temperature": 0.0, "avg_logprob": -0.23236487539190995, "compression_ratio": 1.6566523605150214, "no_speech_prob": 2.812996399370604e-06}, {"id": 738, "seek": 294154, "start": 2956.66, "end": 2957.74, "text": " automating these steps.", "tokens": [3553, 990, 613, 4439, 13], "temperature": 0.0, "avg_logprob": -0.23236487539190995, "compression_ratio": 1.6566523605150214, "no_speech_prob": 2.812996399370604e-06}, {"id": 739, "seek": 294154, "start": 2957.74, "end": 2964.42, "text": " So I'm not saying that that's the only part of building great software, but I think it's", "tokens": [407, 286, 478, 406, 1566, 300, 300, 311, 264, 787, 644, 295, 2390, 869, 4722, 11, 457, 286, 519, 309, 311], "temperature": 0.0, "avg_logprob": -0.23236487539190995, "compression_ratio": 1.6566523605150214, "no_speech_prob": 2.812996399370604e-06}, {"id": 740, "seek": 294154, "start": 2964.42, "end": 2966.9, "text": " like to me, it's an important piece of the puzzle.", "tokens": [411, 281, 385, 11, 309, 311, 364, 1021, 2522, 295, 264, 12805, 13], "temperature": 0.0, "avg_logprob": -0.23236487539190995, "compression_ratio": 1.6566523605150214, "no_speech_prob": 2.812996399370604e-06}, {"id": 741, "seek": 294154, "start": 2966.9, "end": 2968.6, "text": " It's an important tool in the toolkit.", "tokens": [467, 311, 364, 1021, 2290, 294, 264, 40167, 13], "temperature": 0.0, "avg_logprob": -0.23236487539190995, "compression_ratio": 1.6566523605150214, "no_speech_prob": 2.812996399370604e-06}, {"id": 742, "seek": 296860, "start": 2968.6, "end": 2974.7799999999997, "text": " So going back to scaffolding and all those things, what would you write in the scaffolding", "tokens": [407, 516, 646, 281, 44094, 278, 293, 439, 729, 721, 11, 437, 576, 291, 2464, 294, 264, 44094, 278], "temperature": 0.0, "avg_logprob": -0.2579905750987294, "compression_ratio": 1.6470588235294117, "no_speech_prob": 3.2058142096502706e-07}, {"id": 743, "seek": 296860, "start": 2974.7799999999997, "end": 2975.7799999999997, "text": " code?", "tokens": [3089, 30], "temperature": 0.0, "avg_logprob": -0.2579905750987294, "compression_ratio": 1.6470588235294117, "no_speech_prob": 3.2058142096502706e-07}, {"id": 744, "seek": 296860, "start": 2975.7799999999997, "end": 2983.62, "text": " So again, let's take the example of you scaffold a new application with a main and init update", "tokens": [407, 797, 11, 718, 311, 747, 264, 1365, 295, 291, 44094, 257, 777, 3861, 365, 257, 2135, 293, 3157, 5623], "temperature": 0.0, "avg_logprob": -0.2579905750987294, "compression_ratio": 1.6470588235294117, "no_speech_prob": 3.2058142096502706e-07}, {"id": 745, "seek": 296860, "start": 2983.62, "end": 2987.3399999999997, "text": " view browser data application, whatever.", "tokens": [1910, 11185, 1412, 3861, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.2579905750987294, "compression_ratio": 1.6470588235294117, "no_speech_prob": 3.2058142096502706e-07}, {"id": 746, "seek": 296860, "start": 2987.3399999999997, "end": 2991.18, "text": " How much comments code would you integrate?", "tokens": [1012, 709, 3053, 3089, 576, 291, 13365, 30], "temperature": 0.0, "avg_logprob": -0.2579905750987294, "compression_ratio": 1.6470588235294117, "no_speech_prob": 3.2058142096502706e-07}, {"id": 747, "seek": 296860, "start": 2991.18, "end": 2996.94, "text": " So for instance, one thing that I might be wondering is like, well, if I want this code", "tokens": [407, 337, 5197, 11, 472, 551, 300, 286, 1062, 312, 6359, 307, 411, 11, 731, 11, 498, 286, 528, 341, 3089], "temperature": 0.0, "avg_logprob": -0.2579905750987294, "compression_ratio": 1.6470588235294117, "no_speech_prob": 3.2058142096502706e-07}, {"id": 748, "seek": 299694, "start": 2996.94, "end": 3003.5, "text": " to be for anyone who's new to Elm, then I might add a few comments that says, well,", "tokens": [281, 312, 337, 2878, 567, 311, 777, 281, 2699, 76, 11, 550, 286, 1062, 909, 257, 1326, 3053, 300, 1619, 11, 731, 11], "temperature": 0.0, "avg_logprob": -0.2692549792203036, "compression_ratio": 1.8333333333333333, "no_speech_prob": 1.4823516494288924e-06}, {"id": 749, "seek": 299694, "start": 3003.5, "end": 3007.82, "text": " oh, this is main, this is how your application starts and this is how it works.", "tokens": [1954, 11, 341, 307, 2135, 11, 341, 307, 577, 428, 3861, 3719, 293, 341, 307, 577, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.2692549792203036, "compression_ratio": 1.8333333333333333, "no_speech_prob": 1.4823516494288924e-06}, {"id": 750, "seek": 299694, "start": 3007.82, "end": 3012.06, "text": " And then you have a comment around init that says, well, this is how we initialize your", "tokens": [400, 550, 291, 362, 257, 2871, 926, 3157, 300, 1619, 11, 731, 11, 341, 307, 577, 321, 5883, 1125, 428], "temperature": 0.0, "avg_logprob": -0.2692549792203036, "compression_ratio": 1.8333333333333333, "no_speech_prob": 1.4823516494288924e-06}, {"id": 751, "seek": 299694, "start": 3012.06, "end": 3014.34, "text": " application and one for model.", "tokens": [3861, 293, 472, 337, 2316, 13], "temperature": 0.0, "avg_logprob": -0.2692549792203036, "compression_ratio": 1.8333333333333333, "no_speech_prob": 1.4823516494288924e-06}, {"id": 752, "seek": 299694, "start": 3014.34, "end": 3019.64, "text": " This is all the data that your application can hold, et cetera, et cetera.", "tokens": [639, 307, 439, 264, 1412, 300, 428, 3861, 393, 1797, 11, 1030, 11458, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.2692549792203036, "compression_ratio": 1.8333333333333333, "no_speech_prob": 1.4823516494288924e-06}, {"id": 753, "seek": 299694, "start": 3019.64, "end": 3023.62, "text": " So is that something that you think we should do?", "tokens": [407, 307, 300, 746, 300, 291, 519, 321, 820, 360, 30], "temperature": 0.0, "avg_logprob": -0.2692549792203036, "compression_ratio": 1.8333333333333333, "no_speech_prob": 1.4823516494288924e-06}, {"id": 754, "seek": 302362, "start": 3023.62, "end": 3028.66, "text": " And also like maybe also steps for, oh, well we have now scaffolded this thing and this", "tokens": [400, 611, 411, 1310, 611, 4439, 337, 11, 1954, 11, 731, 321, 362, 586, 44094, 292, 341, 551, 293, 341], "temperature": 0.0, "avg_logprob": -0.22777160269315125, "compression_ratio": 1.7519685039370079, "no_speech_prob": 6.577851650035882e-07}, {"id": 755, "seek": 302362, "start": 3028.66, "end": 3030.8199999999997, "text": " is where you should change your code.", "tokens": [307, 689, 291, 820, 1319, 428, 3089, 13], "temperature": 0.0, "avg_logprob": -0.22777160269315125, "compression_ratio": 1.7519685039370079, "no_speech_prob": 6.577851650035882e-07}, {"id": 756, "seek": 302362, "start": 3030.8199999999997, "end": 3036.38, "text": " Like here's where you should add a new kind of message variants or this is where you shouldn't", "tokens": [1743, 510, 311, 689, 291, 820, 909, 257, 777, 733, 295, 3636, 21669, 420, 341, 307, 689, 291, 4659, 380], "temperature": 0.0, "avg_logprob": -0.22777160269315125, "compression_ratio": 1.7519685039370079, "no_speech_prob": 6.577851650035882e-07}, {"id": 757, "seek": 302362, "start": 3036.38, "end": 3040.44, "text": " handle this new updates, this new message.", "tokens": [4813, 341, 777, 9205, 11, 341, 777, 3636, 13], "temperature": 0.0, "avg_logprob": -0.22777160269315125, "compression_ratio": 1.7519685039370079, "no_speech_prob": 6.577851650035882e-07}, {"id": 758, "seek": 302362, "start": 3040.44, "end": 3043.3199999999997, "text": " How much should you help someone?", "tokens": [1012, 709, 820, 291, 854, 1580, 30], "temperature": 0.0, "avg_logprob": -0.22777160269315125, "compression_ratio": 1.7519685039370079, "no_speech_prob": 6.577851650035882e-07}, {"id": 759, "seek": 302362, "start": 3043.3199999999997, "end": 3047.18, "text": " And I'm guessing it's like, if it's for you, you don't care because you know what you need", "tokens": [400, 286, 478, 17939, 309, 311, 411, 11, 498, 309, 311, 337, 291, 11, 291, 500, 380, 1127, 570, 291, 458, 437, 291, 643], "temperature": 0.0, "avg_logprob": -0.22777160269315125, "compression_ratio": 1.7519685039370079, "no_speech_prob": 6.577851650035882e-07}, {"id": 760, "seek": 302362, "start": 3047.18, "end": 3048.18, "text": " to do.", "tokens": [281, 360, 13], "temperature": 0.0, "avg_logprob": -0.22777160269315125, "compression_ratio": 1.7519685039370079, "no_speech_prob": 6.577851650035882e-07}, {"id": 761, "seek": 302362, "start": 3048.18, "end": 3050.2799999999997, "text": " I mean, you've been able to automate this, right?", "tokens": [286, 914, 11, 291, 600, 668, 1075, 281, 31605, 341, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.22777160269315125, "compression_ratio": 1.7519685039370079, "no_speech_prob": 6.577851650035882e-07}, {"id": 762, "seek": 305028, "start": 3050.28, "end": 3055.7400000000002, "text": " But I'm guessing if you're in a team and you often have new developers joining your team,", "tokens": [583, 286, 478, 17939, 498, 291, 434, 294, 257, 1469, 293, 291, 2049, 362, 777, 8849, 5549, 428, 1469, 11], "temperature": 0.0, "avg_logprob": -0.2629328905525854, "compression_ratio": 1.6910569105691058, "no_speech_prob": 3.412533544633334e-07}, {"id": 763, "seek": 305028, "start": 3055.7400000000002, "end": 3060.0600000000004, "text": " then maybe it's worth adding all these comments, but then you probably also want to strip them", "tokens": [550, 1310, 309, 311, 3163, 5127, 439, 613, 3053, 11, 457, 550, 291, 1391, 611, 528, 281, 12828, 552], "temperature": 0.0, "avg_logprob": -0.2629328905525854, "compression_ratio": 1.6910569105691058, "no_speech_prob": 3.412533544633334e-07}, {"id": 764, "seek": 305028, "start": 3060.0600000000004, "end": 3061.0600000000004, "text": " out.", "tokens": [484, 13], "temperature": 0.0, "avg_logprob": -0.2629328905525854, "compression_ratio": 1.6910569105691058, "no_speech_prob": 3.412533544633334e-07}, {"id": 765, "seek": 305028, "start": 3061.0600000000004, "end": 3062.0600000000004, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2629328905525854, "compression_ratio": 1.6910569105691058, "no_speech_prob": 3.412533544633334e-07}, {"id": 766, "seek": 305028, "start": 3062.0600000000004, "end": 3063.0600000000004, "text": " I'm a little bit torn.", "tokens": [286, 478, 257, 707, 857, 10885, 13], "temperature": 0.0, "avg_logprob": -0.2629328905525854, "compression_ratio": 1.6910569105691058, "no_speech_prob": 3.412533544633334e-07}, {"id": 767, "seek": 305028, "start": 3063.0600000000004, "end": 3064.0600000000004, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2629328905525854, "compression_ratio": 1.6910569105691058, "no_speech_prob": 3.412533544633334e-07}, {"id": 768, "seek": 305028, "start": 3064.0600000000004, "end": 3071.38, "text": " So back to this sort of idea that Sandy Metz has that code tends to be duplicated or replicated.", "tokens": [407, 646, 281, 341, 1333, 295, 1558, 300, 27390, 376, 10074, 575, 300, 3089, 12258, 281, 312, 1581, 564, 3587, 420, 46365, 13], "temperature": 0.0, "avg_logprob": -0.2629328905525854, "compression_ratio": 1.6910569105691058, "no_speech_prob": 3.412533544633334e-07}, {"id": 769, "seek": 305028, "start": 3071.38, "end": 3080.26, "text": " I think the term she uses is, is that good code is exemplary, exemplary, exemplary, exemplary,", "tokens": [286, 519, 264, 1433, 750, 4960, 307, 11, 307, 300, 665, 3089, 307, 24112, 822, 11, 24112, 822, 11, 24112, 822, 11, 24112, 822, 11], "temperature": 0.0, "avg_logprob": -0.2629328905525854, "compression_ratio": 1.6910569105691058, "no_speech_prob": 3.412533544633334e-07}, {"id": 770, "seek": 308026, "start": 3080.26, "end": 3081.26, "text": " exemplary.", "tokens": [24112, 822, 13], "temperature": 0.0, "avg_logprob": -0.28961517413457233, "compression_ratio": 1.539906103286385, "no_speech_prob": 8.579024779464817e-07}, {"id": 771, "seek": 308026, "start": 3081.26, "end": 3085.5400000000004, "text": " We'll see how our transcripts do on that.", "tokens": [492, 603, 536, 577, 527, 24444, 82, 360, 322, 300, 13], "temperature": 0.0, "avg_logprob": -0.28961517413457233, "compression_ratio": 1.539906103286385, "no_speech_prob": 8.579024779464817e-07}, {"id": 772, "seek": 308026, "start": 3085.5400000000004, "end": 3088.7000000000003, "text": " Maybe it'll just strip it down to one word.", "tokens": [2704, 309, 603, 445, 12828, 309, 760, 281, 472, 1349, 13], "temperature": 0.0, "avg_logprob": -0.28961517413457233, "compression_ratio": 1.539906103286385, "no_speech_prob": 8.579024779464817e-07}, {"id": 773, "seek": 308026, "start": 3088.7000000000003, "end": 3089.7000000000003, "text": " We'll see.", "tokens": [492, 603, 536, 13], "temperature": 0.0, "avg_logprob": -0.28961517413457233, "compression_ratio": 1.539906103286385, "no_speech_prob": 8.579024779464817e-07}, {"id": 774, "seek": 308026, "start": 3089.7000000000003, "end": 3096.5400000000004, "text": " Yeah, I think it's you, you want, like, if you don't want to have comments in your code", "tokens": [865, 11, 286, 519, 309, 311, 291, 11, 291, 528, 11, 411, 11, 498, 291, 500, 380, 528, 281, 362, 3053, 294, 428, 3089], "temperature": 0.0, "avg_logprob": -0.28961517413457233, "compression_ratio": 1.539906103286385, "no_speech_prob": 8.579024779464817e-07}, {"id": 775, "seek": 308026, "start": 3096.5400000000004, "end": 3100.98, "text": " explaining this goes here, this is where you add things.", "tokens": [13468, 341, 1709, 510, 11, 341, 307, 689, 291, 909, 721, 13], "temperature": 0.0, "avg_logprob": -0.28961517413457233, "compression_ratio": 1.539906103286385, "no_speech_prob": 8.579024779464817e-07}, {"id": 776, "seek": 308026, "start": 3100.98, "end": 3106.26, "text": " I personally would tend to avoid including that in the scaffolding as well.", "tokens": [286, 5665, 576, 3928, 281, 5042, 3009, 300, 294, 264, 44094, 278, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.28961517413457233, "compression_ratio": 1.539906103286385, "no_speech_prob": 8.579024779464817e-07}, {"id": 777, "seek": 310626, "start": 3106.26, "end": 3111.7000000000003, "text": " I would, I would want to add that more as like output from running the scaffolding command", "tokens": [286, 576, 11, 286, 576, 528, 281, 909, 300, 544, 382, 411, 5598, 490, 2614, 264, 44094, 278, 5622], "temperature": 0.0, "avg_logprob": -0.2725851817797589, "compression_ratio": 1.541062801932367, "no_speech_prob": 1.4367365110956598e-06}, {"id": 778, "seek": 310626, "start": 3111.7000000000003, "end": 3114.38, "text": " and it says, great, I added this thing.", "tokens": [293, 309, 1619, 11, 869, 11, 286, 3869, 341, 551, 13], "temperature": 0.0, "avg_logprob": -0.2725851817797589, "compression_ratio": 1.541062801932367, "no_speech_prob": 1.4367365110956598e-06}, {"id": 779, "seek": 310626, "start": 3114.38, "end": 3116.26, "text": " Here are your next steps.", "tokens": [1692, 366, 428, 958, 4439, 13], "temperature": 0.0, "avg_logprob": -0.2725851817797589, "compression_ratio": 1.541062801932367, "no_speech_prob": 1.4367365110956598e-06}, {"id": 780, "seek": 310626, "start": 3116.26, "end": 3117.82, "text": " Now what I would want to do.", "tokens": [823, 437, 286, 576, 528, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.2725851817797589, "compression_ratio": 1.541062801932367, "no_speech_prob": 1.4367365110956598e-06}, {"id": 781, "seek": 310626, "start": 3117.82, "end": 3124.26, "text": " So for example, let's say we're scaffolding out in a new route module for SBA, Elm pages,", "tokens": [407, 337, 1365, 11, 718, 311, 584, 321, 434, 44094, 278, 484, 294, 257, 777, 7955, 10088, 337, 318, 9295, 11, 2699, 76, 7183, 11], "temperature": 0.0, "avg_logprob": -0.2725851817797589, "compression_ratio": 1.541062801932367, "no_speech_prob": 1.4367365110956598e-06}, {"id": 782, "seek": 310626, "start": 3124.26, "end": 3127.7000000000003, "text": " your custom homegrown SBA helper, whatever.", "tokens": [428, 2375, 1280, 38413, 318, 9295, 36133, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.2725851817797589, "compression_ratio": 1.541062801932367, "no_speech_prob": 1.4367365110956598e-06}, {"id": 783, "seek": 312770, "start": 3127.7, "end": 3136.2599999999998, "text": " So personally, I tend, I actually tend to find it more useful to like, have an init", "tokens": [407, 5665, 11, 286, 3928, 11, 286, 767, 3928, 281, 915, 309, 544, 4420, 281, 411, 11, 362, 364, 3157], "temperature": 0.0, "avg_logprob": -0.2708454132080078, "compression_ratio": 1.6228571428571428, "no_speech_prob": 6.577851081601693e-07}, {"id": 784, "seek": 312770, "start": 3136.2599999999998, "end": 3140.2999999999997, "text": " function defined, even if you don't use it initially.", "tokens": [2445, 7642, 11, 754, 498, 291, 500, 380, 764, 309, 9105, 13], "temperature": 0.0, "avg_logprob": -0.2708454132080078, "compression_ratio": 1.6228571428571428, "no_speech_prob": 6.577851081601693e-07}, {"id": 785, "seek": 312770, "start": 3140.2999999999997, "end": 3141.66, "text": " I just find that easier.", "tokens": [286, 445, 915, 300, 3571, 13], "temperature": 0.0, "avg_logprob": -0.2708454132080078, "compression_ratio": 1.6228571428571428, "no_speech_prob": 6.577851081601693e-07}, {"id": 786, "seek": 312770, "start": 3141.66, "end": 3148.18, "text": " So then you don't need a comment to say like, comment, if you want to add init and messages,", "tokens": [407, 550, 291, 500, 380, 643, 257, 2871, 281, 584, 411, 11, 2871, 11, 498, 291, 528, 281, 909, 3157, 293, 7897, 11], "temperature": 0.0, "avg_logprob": -0.2708454132080078, "compression_ratio": 1.6228571428571428, "no_speech_prob": 6.577851081601693e-07}, {"id": 787, "seek": 312770, "start": 3148.18, "end": 3149.98, "text": " you can change these things.", "tokens": [291, 393, 1319, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.2708454132080078, "compression_ratio": 1.6228571428571428, "no_speech_prob": 6.577851081601693e-07}, {"id": 788, "seek": 314998, "start": 3149.98, "end": 3159.02, "text": " Just, just have, you know, type message equals no op or whatever, you know, but I was, I", "tokens": [1449, 11, 445, 362, 11, 291, 458, 11, 2010, 3636, 6915, 572, 999, 420, 2035, 11, 291, 458, 11, 457, 286, 390, 11, 286], "temperature": 0.0, "avg_logprob": -0.27880444572967233, "compression_ratio": 1.6872037914691944, "no_speech_prob": 3.256276954743953e-07}, {"id": 789, "seek": 314998, "start": 3159.02, "end": 3165.26, "text": " was thinking of a comment next to the message type, but always including the type, the message", "tokens": [390, 1953, 295, 257, 2871, 958, 281, 264, 3636, 2010, 11, 457, 1009, 3009, 264, 2010, 11, 264, 3636], "temperature": 0.0, "avg_logprob": -0.27880444572967233, "compression_ratio": 1.6872037914691944, "no_speech_prob": 3.256276954743953e-07}, {"id": 790, "seek": 314998, "start": 3165.26, "end": 3166.26, "text": " type.", "tokens": [2010, 13], "temperature": 0.0, "avg_logprob": -0.27880444572967233, "compression_ratio": 1.6872037914691944, "no_speech_prob": 3.256276954743953e-07}, {"id": 791, "seek": 314998, "start": 3166.26, "end": 3167.26, "text": " Right, right, right.", "tokens": [1779, 11, 558, 11, 558, 13], "temperature": 0.0, "avg_logprob": -0.27880444572967233, "compression_ratio": 1.6872037914691944, "no_speech_prob": 3.256276954743953e-07}, {"id": 792, "seek": 314998, "start": 3167.26, "end": 3169.82, "text": " Commenting it out is also a possibility.", "tokens": [16328, 278, 309, 484, 307, 611, 257, 7959, 13], "temperature": 0.0, "avg_logprob": -0.27880444572967233, "compression_ratio": 1.6872037914691944, "no_speech_prob": 3.256276954743953e-07}, {"id": 793, "seek": 314998, "start": 3169.82, "end": 3170.82, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.27880444572967233, "compression_ratio": 1.6872037914691944, "no_speech_prob": 3.256276954743953e-07}, {"id": 794, "seek": 314998, "start": 3170.82, "end": 3171.82, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.27880444572967233, "compression_ratio": 1.6872037914691944, "no_speech_prob": 3.256276954743953e-07}, {"id": 795, "seek": 314998, "start": 3171.82, "end": 3179.18, "text": " And, and so like, basically I would tend to, instead of having comments, maybe have a little", "tokens": [400, 11, 293, 370, 411, 11, 1936, 286, 576, 3928, 281, 11, 2602, 295, 1419, 3053, 11, 1310, 362, 257, 707], "temperature": 0.0, "avg_logprob": -0.27880444572967233, "compression_ratio": 1.6872037914691944, "no_speech_prob": 3.256276954743953e-07}, {"id": 796, "seek": 317918, "start": 3179.18, "end": 3184.3399999999997, "text": " bit of terminal output to guide people as, as far as that's helpful, maybe even link", "tokens": [857, 295, 14709, 5598, 281, 5934, 561, 382, 11, 382, 1400, 382, 300, 311, 4961, 11, 1310, 754, 2113], "temperature": 0.0, "avg_logprob": -0.2183241844177246, "compression_ratio": 1.7234042553191489, "no_speech_prob": 2.2958959107199917e-06}, {"id": 797, "seek": 317918, "start": 3184.3399999999997, "end": 3185.3399999999997, "text": " them to a guide.", "tokens": [552, 281, 257, 5934, 13], "temperature": 0.0, "avg_logprob": -0.2183241844177246, "compression_ratio": 1.7234042553191489, "no_speech_prob": 2.2958959107199917e-06}, {"id": 798, "seek": 317918, "start": 3185.3399999999997, "end": 3190.54, "text": " If somebody's new to a thing, if you're new to our, the way that our route modules work,", "tokens": [759, 2618, 311, 777, 281, 257, 551, 11, 498, 291, 434, 777, 281, 527, 11, 264, 636, 300, 527, 7955, 16679, 589, 11], "temperature": 0.0, "avg_logprob": -0.2183241844177246, "compression_ratio": 1.7234042553191489, "no_speech_prob": 2.2958959107199917e-06}, {"id": 799, "seek": 317918, "start": 3190.54, "end": 3192.94, "text": " here's some documentation about it.", "tokens": [510, 311, 512, 14333, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.2183241844177246, "compression_ratio": 1.7234042553191489, "no_speech_prob": 2.2958959107199917e-06}, {"id": 800, "seek": 317918, "start": 3192.94, "end": 3198.2999999999997, "text": " And now somebody, somebody is not going to be new to a project, read the entire read", "tokens": [400, 586, 2618, 11, 2618, 307, 406, 516, 281, 312, 777, 281, 257, 1716, 11, 1401, 264, 2302, 1401], "temperature": 0.0, "avg_logprob": -0.2183241844177246, "compression_ratio": 1.7234042553191489, "no_speech_prob": 2.2958959107199917e-06}, {"id": 801, "seek": 317918, "start": 3198.2999999999997, "end": 3203.7999999999997, "text": " me and everything about it, but maybe when they're new to a project, they run the scaffolding", "tokens": [385, 293, 1203, 466, 309, 11, 457, 1310, 562, 436, 434, 777, 281, 257, 1716, 11, 436, 1190, 264, 44094, 278], "temperature": 0.0, "avg_logprob": -0.2183241844177246, "compression_ratio": 1.7234042553191489, "no_speech_prob": 2.2958959107199917e-06}, {"id": 802, "seek": 320380, "start": 3203.8, "end": 3209.1800000000003, "text": " command and they see output that links them to the relevant thing with like a minimal", "tokens": [5622, 293, 436, 536, 5598, 300, 6123, 552, 281, 264, 7340, 551, 365, 411, 257, 13206], "temperature": 0.0, "avg_logprob": -0.1925909409829236, "compression_ratio": 1.7215686274509805, "no_speech_prob": 1.1365557384124259e-06}, {"id": 803, "seek": 320380, "start": 3209.1800000000003, "end": 3210.1800000000003, "text": " output.", "tokens": [5598, 13], "temperature": 0.0, "avg_logprob": -0.1925909409829236, "compression_ratio": 1.7215686274509805, "no_speech_prob": 1.1365557384124259e-06}, {"id": 804, "seek": 320380, "start": 3210.1800000000003, "end": 3212.54, "text": " Maybe then they'll click it and read it because it's relevant to them now.", "tokens": [2704, 550, 436, 603, 2052, 309, 293, 1401, 309, 570, 309, 311, 7340, 281, 552, 586, 13], "temperature": 0.0, "avg_logprob": -0.1925909409829236, "compression_ratio": 1.7215686274509805, "no_speech_prob": 1.1365557384124259e-06}, {"id": 805, "seek": 320380, "start": 3212.54, "end": 3216.5800000000004, "text": " So showing people contextually relevant information, I think is a good technique.", "tokens": [407, 4099, 561, 4319, 671, 7340, 1589, 11, 286, 519, 307, 257, 665, 6532, 13], "temperature": 0.0, "avg_logprob": -0.1925909409829236, "compression_ratio": 1.7215686274509805, "no_speech_prob": 1.1365557384124259e-06}, {"id": 806, "seek": 320380, "start": 3216.5800000000004, "end": 3223.1000000000004, "text": " And also like showing exemplary code that makes it easy to change in the way you want", "tokens": [400, 611, 411, 4099, 24112, 822, 3089, 300, 1669, 309, 1858, 281, 1319, 294, 264, 636, 291, 528], "temperature": 0.0, "avg_logprob": -0.1925909409829236, "compression_ratio": 1.7215686274509805, "no_speech_prob": 1.1365557384124259e-06}, {"id": 807, "seek": 320380, "start": 3223.1000000000004, "end": 3224.54, "text": " it to evolve.", "tokens": [309, 281, 16693, 13], "temperature": 0.0, "avg_logprob": -0.1925909409829236, "compression_ratio": 1.7215686274509805, "no_speech_prob": 1.1365557384124259e-06}, {"id": 808, "seek": 320380, "start": 3224.54, "end": 3231.3, "text": " So like if you have a, if you have a message type that is unit type, type message equals", "tokens": [407, 411, 498, 291, 362, 257, 11, 498, 291, 362, 257, 3636, 2010, 300, 307, 4985, 2010, 11, 2010, 3636, 6915], "temperature": 0.0, "avg_logprob": -0.1925909409829236, "compression_ratio": 1.7215686274509805, "no_speech_prob": 1.1365557384124259e-06}, {"id": 809, "seek": 323130, "start": 3231.3, "end": 3235.6200000000003, "text": " unit, it doesn't make it easy to evolve that module in an idiomatic way.", "tokens": [4985, 11, 309, 1177, 380, 652, 309, 1858, 281, 16693, 300, 10088, 294, 364, 18014, 13143, 636, 13], "temperature": 0.0, "avg_logprob": -0.18666005316581435, "compression_ratio": 1.7636363636363637, "no_speech_prob": 4.7378722456414835e-07}, {"id": 810, "seek": 323130, "start": 3235.6200000000003, "end": 3238.6000000000004, "text": " So it's better to have custom type there.", "tokens": [407, 309, 311, 1101, 281, 362, 2375, 2010, 456, 13], "temperature": 0.0, "avg_logprob": -0.18666005316581435, "compression_ratio": 1.7636363636363637, "no_speech_prob": 4.7378722456414835e-07}, {"id": 811, "seek": 323130, "start": 3238.6000000000004, "end": 3243.9, "text": " And it's better to have your update function do a case expression on the message because", "tokens": [400, 309, 311, 1101, 281, 362, 428, 5623, 2445, 360, 257, 1389, 6114, 322, 264, 3636, 570], "temperature": 0.0, "avg_logprob": -0.18666005316581435, "compression_ratio": 1.7636363636363637, "no_speech_prob": 4.7378722456414835e-07}, {"id": 812, "seek": 323130, "start": 3243.9, "end": 3247.5800000000004, "text": " that's what's idiomatic or whatever the idiomatic pattern is for your code base.", "tokens": [300, 311, 437, 311, 18014, 13143, 420, 2035, 264, 18014, 13143, 5102, 307, 337, 428, 3089, 3096, 13], "temperature": 0.0, "avg_logprob": -0.18666005316581435, "compression_ratio": 1.7636363636363637, "no_speech_prob": 4.7378722456414835e-07}, {"id": 813, "seek": 323130, "start": 3247.5800000000004, "end": 3253.8, "text": " So I would say like, try to set up the idioms in a way that's easy to evolve from as a starting", "tokens": [407, 286, 576, 584, 411, 11, 853, 281, 992, 493, 264, 18014, 4785, 294, 257, 636, 300, 311, 1858, 281, 16693, 490, 382, 257, 2891], "temperature": 0.0, "avg_logprob": -0.18666005316581435, "compression_ratio": 1.7636363636363637, "no_speech_prob": 4.7378722456414835e-07}, {"id": 814, "seek": 323130, "start": 3253.8, "end": 3255.78, "text": " point in your scaffolded code.", "tokens": [935, 294, 428, 44094, 292, 3089, 13], "temperature": 0.0, "avg_logprob": -0.18666005316581435, "compression_ratio": 1.7636363636363637, "no_speech_prob": 4.7378722456414835e-07}, {"id": 815, "seek": 323130, "start": 3255.78, "end": 3260.0600000000004, "text": " Even if that's like a little verbose sometimes, I, I think it's worth it.", "tokens": [2754, 498, 300, 311, 411, 257, 707, 9595, 541, 2171, 11, 286, 11, 286, 519, 309, 311, 3163, 309, 13], "temperature": 0.0, "avg_logprob": -0.18666005316581435, "compression_ratio": 1.7636363636363637, "no_speech_prob": 4.7378722456414835e-07}, {"id": 816, "seek": 326006, "start": 3260.06, "end": 3265.74, "text": " And if things are not clear, then it's also potentially API design that needs to come", "tokens": [400, 498, 721, 366, 406, 1850, 11, 550, 309, 311, 611, 7263, 9362, 1715, 300, 2203, 281, 808], "temperature": 0.0, "avg_logprob": -0.2665190037673082, "compression_ratio": 1.7311827956989247, "no_speech_prob": 2.5612532681407174e-06}, {"id": 817, "seek": 326006, "start": 3265.74, "end": 3266.74, "text": " into play.", "tokens": [666, 862, 13], "temperature": 0.0, "avg_logprob": -0.2665190037673082, "compression_ratio": 1.7311827956989247, "no_speech_prob": 2.5612532681407174e-06}, {"id": 818, "seek": 326006, "start": 3266.74, "end": 3271.94, "text": " Like you're not going to be able to change the Elm browser API, but if it's your scaffolding", "tokens": [1743, 291, 434, 406, 516, 281, 312, 1075, 281, 1319, 264, 2699, 76, 11185, 9362, 11, 457, 498, 309, 311, 428, 44094, 278], "temperature": 0.0, "avg_logprob": -0.2665190037673082, "compression_ratio": 1.7311827956989247, "no_speech_prob": 2.5612532681407174e-06}, {"id": 819, "seek": 326006, "start": 3271.94, "end": 3276.98, "text": " in your routes and your route is something that you control, then maybe you can change", "tokens": [294, 428, 18242, 293, 428, 7955, 307, 746, 300, 291, 1969, 11, 550, 1310, 291, 393, 1319], "temperature": 0.0, "avg_logprob": -0.2665190037673082, "compression_ratio": 1.7311827956989247, "no_speech_prob": 2.5612532681407174e-06}, {"id": 820, "seek": 326006, "start": 3276.98, "end": 3280.42, "text": " the names of the fields of the functions to make it very explicit.", "tokens": [264, 5288, 295, 264, 7909, 295, 264, 6828, 281, 652, 309, 588, 13691, 13], "temperature": 0.0, "avg_logprob": -0.2665190037673082, "compression_ratio": 1.7311827956989247, "no_speech_prob": 2.5612532681407174e-06}, {"id": 821, "seek": 326006, "start": 3280.42, "end": 3284.66, "text": " Like, Hey, this is probably what you need to do in order to do what you want to do.", "tokens": [1743, 11, 1911, 11, 341, 307, 1391, 437, 291, 643, 281, 360, 294, 1668, 281, 360, 437, 291, 528, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.2665190037673082, "compression_ratio": 1.7311827956989247, "no_speech_prob": 2.5612532681407174e-06}, {"id": 822, "seek": 326006, "start": 3284.66, "end": 3288.66, "text": " So make good APIs and things will happen automatically.", "tokens": [407, 652, 665, 21445, 293, 721, 486, 1051, 6772, 13], "temperature": 0.0, "avg_logprob": -0.2665190037673082, "compression_ratio": 1.7311827956989247, "no_speech_prob": 2.5612532681407174e-06}, {"id": 823, "seek": 328866, "start": 3288.66, "end": 3290.7, "text": " Yeah, totally.", "tokens": [865, 11, 3879, 13], "temperature": 0.0, "avg_logprob": -0.2803466086294137, "compression_ratio": 1.8596491228070176, "no_speech_prob": 2.135506065314985e-07}, {"id": 824, "seek": 328866, "start": 3290.7, "end": 3291.7, "text": " Totally.", "tokens": [22837, 13], "temperature": 0.0, "avg_logprob": -0.2803466086294137, "compression_ratio": 1.8596491228070176, "no_speech_prob": 2.135506065314985e-07}, {"id": 825, "seek": 328866, "start": 3291.7, "end": 3292.7, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2803466086294137, "compression_ratio": 1.8596491228070176, "no_speech_prob": 2.135506065314985e-07}, {"id": 826, "seek": 328866, "start": 3292.7, "end": 3298.8999999999996, "text": " So for your Elm review scaffolding, what does, what does it give you?", "tokens": [407, 337, 428, 2699, 76, 3131, 44094, 278, 11, 437, 775, 11, 437, 775, 309, 976, 291, 30], "temperature": 0.0, "avg_logprob": -0.2803466086294137, "compression_ratio": 1.8596491228070176, "no_speech_prob": 2.135506065314985e-07}, {"id": 827, "seek": 328866, "start": 3298.8999999999996, "end": 3304.62, "text": " So you've got scaffolding for an Elm review package and you've got scaffolding for an", "tokens": [407, 291, 600, 658, 44094, 278, 337, 364, 2699, 76, 3131, 7372, 293, 291, 600, 658, 44094, 278, 337, 364], "temperature": 0.0, "avg_logprob": -0.2803466086294137, "compression_ratio": 1.8596491228070176, "no_speech_prob": 2.135506065314985e-07}, {"id": 828, "seek": 328866, "start": 3304.62, "end": 3306.54, "text": " Elm review rule, right?", "tokens": [2699, 76, 3131, 4978, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2803466086294137, "compression_ratio": 1.8596491228070176, "no_speech_prob": 2.135506065314985e-07}, {"id": 829, "seek": 328866, "start": 3306.54, "end": 3307.54, "text": " Yep.", "tokens": [7010, 13], "temperature": 0.0, "avg_logprob": -0.2803466086294137, "compression_ratio": 1.8596491228070176, "no_speech_prob": 2.135506065314985e-07}, {"id": 830, "seek": 328866, "start": 3307.54, "end": 3308.8199999999997, "text": " And what do those give you?", "tokens": [400, 437, 360, 729, 976, 291, 30], "temperature": 0.0, "avg_logprob": -0.2803466086294137, "compression_ratio": 1.8596491228070176, "no_speech_prob": 2.135506065314985e-07}, {"id": 831, "seek": 328866, "start": 3308.8199999999997, "end": 3311.5, "text": " So the package creates a whole new package.", "tokens": [407, 264, 7372, 7829, 257, 1379, 777, 7372, 13], "temperature": 0.0, "avg_logprob": -0.2803466086294137, "compression_ratio": 1.8596491228070176, "no_speech_prob": 2.135506065314985e-07}, {"id": 832, "seek": 328866, "start": 3311.5, "end": 3314.3799999999997, "text": " So it creates an Elm JSON file.", "tokens": [407, 309, 7829, 364, 2699, 76, 31828, 3991, 13], "temperature": 0.0, "avg_logprob": -0.2803466086294137, "compression_ratio": 1.8596491228070176, "no_speech_prob": 2.135506065314985e-07}, {"id": 833, "seek": 331438, "start": 3314.38, "end": 3322.54, "text": " It creates a readme that is formatted in a way that looks pretty much like my other packages,", "tokens": [467, 7829, 257, 1401, 1398, 300, 307, 1254, 32509, 294, 257, 636, 300, 1542, 1238, 709, 411, 452, 661, 17401, 11], "temperature": 0.0, "avg_logprob": -0.2748081917856254, "compression_ratio": 1.7264573991031391, "no_speech_prob": 4.737855761050014e-07}, {"id": 834, "seek": 331438, "start": 3322.54, "end": 3326.2200000000003, "text": " which is the way that I recommend things.", "tokens": [597, 307, 264, 636, 300, 286, 2748, 721, 13], "temperature": 0.0, "avg_logprob": -0.2748081917856254, "compression_ratio": 1.7264573991031391, "no_speech_prob": 4.737855761050014e-07}, {"id": 835, "seek": 331438, "start": 3326.2200000000003, "end": 3328.82, "text": " It comes with the GitHub action scripts.", "tokens": [467, 1487, 365, 264, 23331, 3069, 23294, 13], "temperature": 0.0, "avg_logprob": -0.2748081917856254, "compression_ratio": 1.7264573991031391, "no_speech_prob": 4.737855761050014e-07}, {"id": 836, "seek": 331438, "start": 3328.82, "end": 3335.02, "text": " So if you just push this to GitHub, then you will have a CI.", "tokens": [407, 498, 291, 445, 2944, 341, 281, 23331, 11, 550, 291, 486, 362, 257, 37777, 13], "temperature": 0.0, "avg_logprob": -0.2748081917856254, "compression_ratio": 1.7264573991031391, "no_speech_prob": 4.737855761050014e-07}, {"id": 837, "seek": 331438, "start": 3335.02, "end": 3337.9, "text": " And you also always have to create at least one rule.", "tokens": [400, 291, 611, 1009, 362, 281, 1884, 412, 1935, 472, 4978, 13], "temperature": 0.0, "avg_logprob": -0.2748081917856254, "compression_ratio": 1.7264573991031391, "no_speech_prob": 4.737855761050014e-07}, {"id": 838, "seek": 331438, "start": 3337.9, "end": 3343.94, "text": " And then for that one rule, it creates a module for the rule and a test module for that rule.", "tokens": [400, 550, 337, 300, 472, 4978, 11, 309, 7829, 257, 10088, 337, 264, 4978, 293, 257, 1500, 10088, 337, 300, 4978, 13], "temperature": 0.0, "avg_logprob": -0.2748081917856254, "compression_ratio": 1.7264573991031391, "no_speech_prob": 4.737855761050014e-07}, {"id": 839, "seek": 334394, "start": 3343.94, "end": 3349.82, "text": " And if you run Elm review new rule, then you also get a new rule and a new test file.", "tokens": [400, 498, 291, 1190, 2699, 76, 3131, 777, 4978, 11, 550, 291, 611, 483, 257, 777, 4978, 293, 257, 777, 1500, 3991, 13], "temperature": 0.0, "avg_logprob": -0.2441635542018439, "compression_ratio": 1.6418604651162791, "no_speech_prob": 2.4439493699901504e-06}, {"id": 840, "seek": 334394, "start": 3349.82, "end": 3356.82, "text": " And every time you add a new rule, it will automatically update the readme to list that", "tokens": [400, 633, 565, 291, 909, 257, 777, 4978, 11, 309, 486, 6772, 5623, 264, 1401, 1398, 281, 1329, 300], "temperature": 0.0, "avg_logprob": -0.2441635542018439, "compression_ratio": 1.6418604651162791, "no_speech_prob": 2.4439493699901504e-06}, {"id": 841, "seek": 334394, "start": 3356.82, "end": 3361.02, "text": " rule and it will add it to the exposed modules in your Elm JSON file.", "tokens": [4978, 293, 309, 486, 909, 309, 281, 264, 9495, 16679, 294, 428, 2699, 76, 31828, 3991, 13], "temperature": 0.0, "avg_logprob": -0.2441635542018439, "compression_ratio": 1.6418604651162791, "no_speech_prob": 2.4439493699901504e-06}, {"id": 842, "seek": 334394, "start": 3361.02, "end": 3368.02, "text": " And there's also one file that I generate, which is some documentation of how you should", "tokens": [400, 456, 311, 611, 472, 3991, 300, 286, 8460, 11, 597, 307, 512, 14333, 295, 577, 291, 820], "temperature": 0.0, "avg_logprob": -0.2441635542018439, "compression_ratio": 1.6418604651162791, "no_speech_prob": 2.4439493699901504e-06}, {"id": 843, "seek": 334394, "start": 3368.02, "end": 3369.06, "text": " manage your project.", "tokens": [3067, 428, 1716, 13], "temperature": 0.0, "avg_logprob": -0.2441635542018439, "compression_ratio": 1.6418604651162791, "no_speech_prob": 2.4439493699901504e-06}, {"id": 844, "seek": 336906, "start": 3369.06, "end": 3375.2599999999998, "text": " Like how do you publish this package for the first time and afterwards, because the first", "tokens": [1743, 577, 360, 291, 11374, 341, 7372, 337, 264, 700, 565, 293, 10543, 11, 570, 264, 700], "temperature": 0.0, "avg_logprob": -0.3487011818658738, "compression_ratio": 1.5694444444444444, "no_speech_prob": 8.013307706278283e-06}, {"id": 845, "seek": 336906, "start": 3375.2599999999998, "end": 3380.06, "text": " time you have to do it manually, the second time we're using your script to automatically", "tokens": [565, 291, 362, 281, 360, 309, 16945, 11, 264, 1150, 565, 321, 434, 1228, 428, 5755, 281, 6772], "temperature": 0.0, "avg_logprob": -0.3487011818658738, "compression_ratio": 1.5694444444444444, "no_speech_prob": 8.013307706278283e-06}, {"id": 846, "seek": 336906, "start": 3380.06, "end": 3385.98, "text": " publish something every time you change the version in your Elm JSON file.", "tokens": [11374, 746, 633, 565, 291, 1319, 264, 3037, 294, 428, 2699, 76, 31828, 3991, 13], "temperature": 0.0, "avg_logprob": -0.3487011818658738, "compression_ratio": 1.5694444444444444, "no_speech_prob": 8.013307706278283e-06}, {"id": 847, "seek": 336906, "start": 3385.98, "end": 3391.02, "text": " Oh, and also a new package comes with a review configuration.", "tokens": [876, 11, 293, 611, 257, 777, 7372, 1487, 365, 257, 3131, 11694, 13], "temperature": 0.0, "avg_logprob": -0.3487011818658738, "compression_ratio": 1.5694444444444444, "no_speech_prob": 8.013307706278283e-06}, {"id": 848, "seek": 336906, "start": 3391.02, "end": 3392.02, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.3487011818658738, "compression_ratio": 1.5694444444444444, "no_speech_prob": 8.013307706278283e-06}, {"id": 849, "seek": 336906, "start": 3392.02, "end": 3393.9, "text": " Yes, very meta.", "tokens": [1079, 11, 588, 19616, 13], "temperature": 0.0, "avg_logprob": -0.3487011818658738, "compression_ratio": 1.5694444444444444, "no_speech_prob": 8.013307706278283e-06}, {"id": 850, "seek": 339390, "start": 3393.9, "end": 3398.98, "text": " And yeah, this is one thing that I quite like about it is there's an Elm review rule that", "tokens": [400, 1338, 11, 341, 307, 472, 551, 300, 286, 1596, 411, 466, 309, 307, 456, 311, 364, 2699, 76, 3131, 4978, 300], "temperature": 0.0, "avg_logprob": -0.28549976348876954, "compression_ratio": 1.7467248908296944, "no_speech_prob": 1.4144444548946922e-06}, {"id": 851, "seek": 339390, "start": 3398.98, "end": 3404.82, "text": " reports comments when they contain some words and it contain, it will flag everything that", "tokens": [7122, 3053, 562, 436, 5304, 512, 2283, 293, 309, 5304, 11, 309, 486, 7166, 1203, 300], "temperature": 0.0, "avg_logprob": -0.28549976348876954, "compression_ratio": 1.7467248908296944, "no_speech_prob": 1.4144444548946922e-06}, {"id": 852, "seek": 339390, "start": 3404.82, "end": 3406.7400000000002, "text": " contains replace me.", "tokens": [8306, 7406, 385, 13], "temperature": 0.0, "avg_logprob": -0.28549976348876954, "compression_ratio": 1.7467248908296944, "no_speech_prob": 1.4144444548946922e-06}, {"id": 853, "seek": 339390, "start": 3406.7400000000002, "end": 3409.78, "text": " And I put that replace me in a lot of places.", "tokens": [400, 286, 829, 300, 7406, 385, 294, 257, 688, 295, 3190, 13], "temperature": 0.0, "avg_logprob": -0.28549976348876954, "compression_ratio": 1.7467248908296944, "no_speech_prob": 1.4144444548946922e-06}, {"id": 854, "seek": 339390, "start": 3409.78, "end": 3415.54, "text": " So for instance, every time you create a new rule, that rule will have already some documentation.", "tokens": [407, 337, 5197, 11, 633, 565, 291, 1884, 257, 777, 4978, 11, 300, 4978, 486, 362, 1217, 512, 14333, 13], "temperature": 0.0, "avg_logprob": -0.28549976348876954, "compression_ratio": 1.7467248908296944, "no_speech_prob": 1.4144444548946922e-06}, {"id": 855, "seek": 339390, "start": 3415.54, "end": 3420.3, "text": " It will say this rule reports dot dot dot replace me.", "tokens": [467, 486, 584, 341, 4978, 7122, 5893, 5893, 5893, 7406, 385, 13], "temperature": 0.0, "avg_logprob": -0.28549976348876954, "compression_ratio": 1.7467248908296944, "no_speech_prob": 1.4144444548946922e-06}, {"id": 856, "seek": 342030, "start": 3420.3, "end": 3426.2200000000003, "text": " And it says this rule for instance, will flag some code and it will have a replace me there", "tokens": [400, 309, 1619, 341, 4978, 337, 5197, 11, 486, 7166, 512, 3089, 293, 309, 486, 362, 257, 7406, 385, 456], "temperature": 0.0, "avg_logprob": -0.2542227003309462, "compression_ratio": 1.8578947368421053, "no_speech_prob": 7.811320870132477e-07}, {"id": 857, "seek": 342030, "start": 3426.2200000000003, "end": 3430.6600000000003, "text": " and it will not flag this code and it will have replaced me.", "tokens": [293, 309, 486, 406, 7166, 341, 3089, 293, 309, 486, 362, 10772, 385, 13], "temperature": 0.0, "avg_logprob": -0.2542227003309462, "compression_ratio": 1.8578947368421053, "no_speech_prob": 7.811320870132477e-07}, {"id": 858, "seek": 342030, "start": 3430.6600000000003, "end": 3438.94, "text": " So I'm forcing the author to at least remove that code or that there was documentation", "tokens": [407, 286, 478, 19030, 264, 3793, 281, 412, 1935, 4159, 300, 3089, 420, 300, 456, 390, 14333], "temperature": 0.0, "avg_logprob": -0.2542227003309462, "compression_ratio": 1.8578947368421053, "no_speech_prob": 7.811320870132477e-07}, {"id": 859, "seek": 342030, "start": 3438.94, "end": 3441.2200000000003, "text": " better to replace it.", "tokens": [1101, 281, 7406, 309, 13], "temperature": 0.0, "avg_logprob": -0.2542227003309462, "compression_ratio": 1.8578947368421053, "no_speech_prob": 7.811320870132477e-07}, {"id": 860, "seek": 342030, "start": 3441.2200000000003, "end": 3446.6600000000003, "text": " So I'm forcing them to think about documentation in a way they don't have to do it now, but", "tokens": [407, 286, 478, 19030, 552, 281, 519, 466, 14333, 294, 257, 636, 436, 500, 380, 362, 281, 360, 309, 586, 11, 457], "temperature": 0.0, "avg_logprob": -0.2542227003309462, "compression_ratio": 1.8578947368421053, "no_speech_prob": 7.811320870132477e-07}, {"id": 861, "seek": 344666, "start": 3446.66, "end": 3450.42, "text": " they will have to do it in order for this CI to pass.", "tokens": [436, 486, 362, 281, 360, 309, 294, 1668, 337, 341, 37777, 281, 1320, 13], "temperature": 0.0, "avg_logprob": -0.2862135225588137, "compression_ratio": 1.7396694214876034, "no_speech_prob": 2.4060743726295186e-06}, {"id": 862, "seek": 344666, "start": 3450.42, "end": 3451.42, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.2862135225588137, "compression_ratio": 1.7396694214876034, "no_speech_prob": 2.4060743726295186e-06}, {"id": 863, "seek": 344666, "start": 3451.42, "end": 3458.02, "text": " Yeah, I think you've hit on another dimension of scaffolding that I think is really helpful", "tokens": [865, 11, 286, 519, 291, 600, 2045, 322, 1071, 10139, 295, 44094, 278, 300, 286, 519, 307, 534, 4961], "temperature": 0.0, "avg_logprob": -0.2862135225588137, "compression_ratio": 1.7396694214876034, "no_speech_prob": 2.4060743726295186e-06}, {"id": 864, "seek": 344666, "start": 3458.02, "end": 3463.2599999999998, "text": " is like, sometimes you don't like sometimes you need to have a placeholder where you say", "tokens": [307, 411, 11, 2171, 291, 500, 380, 411, 2171, 291, 643, 281, 362, 257, 1081, 20480, 689, 291, 584], "temperature": 0.0, "avg_logprob": -0.2862135225588137, "compression_ratio": 1.7396694214876034, "no_speech_prob": 2.4060743726295186e-06}, {"id": 865, "seek": 344666, "start": 3463.2599999999998, "end": 3469.2599999999998, "text": " like, you need to do some like replace this thing and you just you can't fill it in for", "tokens": [411, 11, 291, 643, 281, 360, 512, 411, 7406, 341, 551, 293, 291, 445, 291, 393, 380, 2836, 309, 294, 337], "temperature": 0.0, "avg_logprob": -0.2862135225588137, "compression_ratio": 1.7396694214876034, "no_speech_prob": 2.4060743726295186e-06}, {"id": 866, "seek": 344666, "start": 3469.2599999999998, "end": 3474.18, "text": " them but you can at least make it very obvious that something needs to be done there.", "tokens": [552, 457, 291, 393, 412, 1935, 652, 309, 588, 6322, 300, 746, 2203, 281, 312, 1096, 456, 13], "temperature": 0.0, "avg_logprob": -0.2862135225588137, "compression_ratio": 1.7396694214876034, "no_speech_prob": 2.4060743726295186e-06}, {"id": 867, "seek": 344666, "start": 3474.18, "end": 3475.18, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2862135225588137, "compression_ratio": 1.7396694214876034, "no_speech_prob": 2.4060743726295186e-06}, {"id": 868, "seek": 347518, "start": 3475.18, "end": 3482.1, "text": " I can fill in the rule name because I know it because I'm generating the prompt for it.", "tokens": [286, 393, 2836, 294, 264, 4978, 1315, 570, 286, 458, 309, 570, 286, 478, 17746, 264, 12391, 337, 309, 13], "temperature": 0.0, "avg_logprob": -0.4013604582025764, "compression_ratio": 1.5336787564766838, "no_speech_prob": 5.203544901632995e-07}, {"id": 869, "seek": 347518, "start": 3482.1, "end": 3484.22, "text": " But the documentation I will not be able to do that.", "tokens": [583, 264, 14333, 286, 486, 406, 312, 1075, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.4013604582025764, "compression_ratio": 1.5336787564766838, "no_speech_prob": 5.203544901632995e-07}, {"id": 870, "seek": 347518, "start": 3484.22, "end": 3485.22, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.4013604582025764, "compression_ratio": 1.5336787564766838, "no_speech_prob": 5.203544901632995e-07}, {"id": 871, "seek": 347518, "start": 3485.22, "end": 3487.7799999999997, "text": " I don't want them to think about it.", "tokens": [286, 500, 380, 528, 552, 281, 519, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.4013604582025764, "compression_ratio": 1.5336787564766838, "no_speech_prob": 5.203544901632995e-07}, {"id": 872, "seek": 347518, "start": 3487.7799999999997, "end": 3495.54, "text": " You can wire in a GPT API call and take the package name and then generate it.", "tokens": [509, 393, 6234, 294, 257, 26039, 51, 9362, 818, 293, 747, 264, 7372, 1315, 293, 550, 8460, 309, 13], "temperature": 0.0, "avg_logprob": -0.4013604582025764, "compression_ratio": 1.5336787564766838, "no_speech_prob": 5.203544901632995e-07}, {"id": 873, "seek": 347518, "start": 3495.54, "end": 3496.54, "text": " Maybe maybe.", "tokens": [2704, 1310, 13], "temperature": 0.0, "avg_logprob": -0.4013604582025764, "compression_ratio": 1.5336787564766838, "no_speech_prob": 5.203544901632995e-07}, {"id": 874, "seek": 347518, "start": 3496.54, "end": 3497.54, "text": " Next release.", "tokens": [3087, 4374, 13], "temperature": 0.0, "avg_logprob": -0.4013604582025764, "compression_ratio": 1.5336787564766838, "no_speech_prob": 5.203544901632995e-07}, {"id": 875, "seek": 347518, "start": 3497.54, "end": 3498.54, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.4013604582025764, "compression_ratio": 1.5336787564766838, "no_speech_prob": 5.203544901632995e-07}, {"id": 876, "seek": 349854, "start": 3498.54, "end": 3507.14, "text": " I've also I used that same pattern of the replace me and I think I used your same setup", "tokens": [286, 600, 611, 286, 1143, 300, 912, 5102, 295, 264, 7406, 385, 293, 286, 519, 286, 1143, 428, 912, 8657], "temperature": 0.0, "avg_logprob": -0.24931967130271337, "compression_ratio": 1.6883720930232557, "no_speech_prob": 4.4253661144466605e-06}, {"id": 877, "seek": 349854, "start": 3507.14, "end": 3514.06, "text": " from your Elm review in it set up there for the Elm package starter, which is a little", "tokens": [490, 428, 2699, 76, 3131, 294, 309, 992, 493, 456, 337, 264, 2699, 76, 7372, 22465, 11, 597, 307, 257, 707], "temperature": 0.0, "avg_logprob": -0.24931967130271337, "compression_ratio": 1.6883720930232557, "no_speech_prob": 4.4253661144466605e-06}, {"id": 878, "seek": 349854, "start": 3514.06, "end": 3519.74, "text": " template repo, which again, that's another another approach to scaffolding is having,", "tokens": [12379, 49040, 11, 597, 797, 11, 300, 311, 1071, 1071, 3109, 281, 44094, 278, 307, 1419, 11], "temperature": 0.0, "avg_logprob": -0.24931967130271337, "compression_ratio": 1.6883720930232557, "no_speech_prob": 4.4253661144466605e-06}, {"id": 879, "seek": 349854, "start": 3519.74, "end": 3522.22, "text": " you know, a GitHub template repo.", "tokens": [291, 458, 11, 257, 23331, 12379, 49040, 13], "temperature": 0.0, "avg_logprob": -0.24931967130271337, "compression_ratio": 1.6883720930232557, "no_speech_prob": 4.4253661144466605e-06}, {"id": 880, "seek": 349854, "start": 3522.22, "end": 3527.06, "text": " I just recently used the Elm package starter and it was really nice.", "tokens": [286, 445, 3938, 1143, 264, 2699, 76, 7372, 22465, 293, 309, 390, 534, 1481, 13], "temperature": 0.0, "avg_logprob": -0.24931967130271337, "compression_ratio": 1.6883720930232557, "no_speech_prob": 4.4253661144466605e-06}, {"id": 881, "seek": 352706, "start": 3527.06, "end": 3532.42, "text": " And I used the Elm review rule to tell me all the replace me spots and then went through", "tokens": [400, 286, 1143, 264, 2699, 76, 3131, 4978, 281, 980, 385, 439, 264, 7406, 385, 10681, 293, 550, 1437, 807], "temperature": 0.0, "avg_logprob": -0.32509417238488664, "compression_ratio": 1.616326530612245, "no_speech_prob": 3.8449111343652476e-06}, {"id": 882, "seek": 352706, "start": 3532.42, "end": 3533.42, "text": " and filled those out.", "tokens": [293, 6412, 729, 484, 13], "temperature": 0.0, "avg_logprob": -0.32509417238488664, "compression_ratio": 1.616326530612245, "no_speech_prob": 3.8449111343652476e-06}, {"id": 883, "seek": 352706, "start": 3533.42, "end": 3535.1, "text": " And it's a nice workflow.", "tokens": [400, 309, 311, 257, 1481, 20993, 13], "temperature": 0.0, "avg_logprob": -0.32509417238488664, "compression_ratio": 1.616326530612245, "no_speech_prob": 3.8449111343652476e-06}, {"id": 884, "seek": 352706, "start": 3535.1, "end": 3536.98, "text": " Oh, I'm surprised.", "tokens": [876, 11, 286, 478, 6100, 13], "temperature": 0.0, "avg_logprob": -0.32509417238488664, "compression_ratio": 1.616326530612245, "no_speech_prob": 3.8449111343652476e-06}, {"id": 885, "seek": 352706, "start": 3536.98, "end": 3539.2999999999997, "text": " Past Dillon did did a good job at it.", "tokens": [18408, 28160, 630, 630, 257, 665, 1691, 412, 309, 13], "temperature": 0.0, "avg_logprob": -0.32509417238488664, "compression_ratio": 1.616326530612245, "no_speech_prob": 3.8449111343652476e-06}, {"id": 886, "seek": 352706, "start": 3539.2999999999997, "end": 3540.2999999999997, "text": " Yeah, I know.", "tokens": [865, 11, 286, 458, 13], "temperature": 0.0, "avg_logprob": -0.32509417238488664, "compression_ratio": 1.616326530612245, "no_speech_prob": 3.8449111343652476e-06}, {"id": 887, "seek": 352706, "start": 3540.2999999999997, "end": 3545.9, "text": " I was pleasantly surprised too.", "tokens": [286, 390, 35122, 3627, 6100, 886, 13], "temperature": 0.0, "avg_logprob": -0.32509417238488664, "compression_ratio": 1.616326530612245, "no_speech_prob": 3.8449111343652476e-06}, {"id": 888, "seek": 352706, "start": 3545.9, "end": 3551.54, "text": " And so the now another cool technique you mentioned there was like replacing sections", "tokens": [400, 370, 264, 586, 1071, 1627, 6532, 291, 2835, 456, 390, 411, 19139, 10863], "temperature": 0.0, "avg_logprob": -0.32509417238488664, "compression_ratio": 1.616326530612245, "no_speech_prob": 3.8449111343652476e-06}, {"id": 889, "seek": 352706, "start": 3551.54, "end": 3556.34, "text": " of the read or, you know, modifying the readme when you add a new rule.", "tokens": [295, 264, 1401, 420, 11, 291, 458, 11, 42626, 264, 1401, 1398, 562, 291, 909, 257, 777, 4978, 13], "temperature": 0.0, "avg_logprob": -0.32509417238488664, "compression_ratio": 1.616326530612245, "no_speech_prob": 3.8449111343652476e-06}, {"id": 890, "seek": 355634, "start": 3556.34, "end": 3557.34, "text": " That's pretty cool.", "tokens": [663, 311, 1238, 1627, 13], "temperature": 0.0, "avg_logprob": -0.2063934069413405, "compression_ratio": 1.5959183673469388, "no_speech_prob": 3.187521770087187e-06}, {"id": 891, "seek": 355634, "start": 3557.34, "end": 3562.26, "text": " So I think now it's also possible to like modify code.", "tokens": [407, 286, 519, 586, 309, 311, 611, 1944, 281, 411, 16927, 3089, 13], "temperature": 0.0, "avg_logprob": -0.2063934069413405, "compression_ratio": 1.5959183673469388, "no_speech_prob": 3.187521770087187e-06}, {"id": 892, "seek": 355634, "start": 3562.26, "end": 3567.2200000000003, "text": " Of course, this becomes much more complicated than like adding a new scaffolded file to", "tokens": [2720, 1164, 11, 341, 3643, 709, 544, 6179, 813, 411, 5127, 257, 777, 44094, 292, 3991, 281], "temperature": 0.0, "avg_logprob": -0.2063934069413405, "compression_ratio": 1.5959183673469388, "no_speech_prob": 3.187521770087187e-06}, {"id": 893, "seek": 355634, "start": 3567.2200000000003, "end": 3572.78, "text": " like do like an incision, you know, surgery there.", "tokens": [411, 360, 411, 364, 834, 1991, 11, 291, 458, 11, 7930, 456, 13], "temperature": 0.0, "avg_logprob": -0.2063934069413405, "compression_ratio": 1.5959183673469388, "no_speech_prob": 3.187521770087187e-06}, {"id": 894, "seek": 355634, "start": 3572.78, "end": 3575.1800000000003, "text": " But but it's possible.", "tokens": [583, 457, 309, 311, 1944, 13], "temperature": 0.0, "avg_logprob": -0.2063934069413405, "compression_ratio": 1.5959183673469388, "no_speech_prob": 3.187521770087187e-06}, {"id": 895, "seek": 355634, "start": 3575.1800000000003, "end": 3578.04, "text": " And I think one thing that helps a lot with that is conventions.", "tokens": [400, 286, 519, 472, 551, 300, 3665, 257, 688, 365, 300, 307, 33520, 13], "temperature": 0.0, "avg_logprob": -0.2063934069413405, "compression_ratio": 1.5959183673469388, "no_speech_prob": 3.187521770087187e-06}, {"id": 896, "seek": 355634, "start": 3578.04, "end": 3584.82, "text": " If you have clear conventions, and you can just sort of follow like, okay, if these exact", "tokens": [759, 291, 362, 1850, 33520, 11, 293, 291, 393, 445, 1333, 295, 1524, 411, 11, 1392, 11, 498, 613, 1900], "temperature": 0.0, "avg_logprob": -0.2063934069413405, "compression_ratio": 1.5959183673469388, "no_speech_prob": 3.187521770087187e-06}, {"id": 897, "seek": 358482, "start": 3584.82, "end": 3591.2200000000003, "text": " conventions are followed, and I can check that it's safe to to modify this thing, because", "tokens": [33520, 366, 6263, 11, 293, 286, 393, 1520, 300, 309, 311, 3273, 281, 281, 16927, 341, 551, 11, 570], "temperature": 0.0, "avg_logprob": -0.22136139383121411, "compression_ratio": 1.676991150442478, "no_speech_prob": 7.224427918117726e-07}, {"id": 898, "seek": 358482, "start": 3591.2200000000003, "end": 3596.02, "text": " I know these exact conventions will have these exact things I can easily check for.", "tokens": [286, 458, 613, 1900, 33520, 486, 362, 613, 1900, 721, 286, 393, 3612, 1520, 337, 13], "temperature": 0.0, "avg_logprob": -0.22136139383121411, "compression_ratio": 1.676991150442478, "no_speech_prob": 7.224427918117726e-07}, {"id": 899, "seek": 358482, "start": 3596.02, "end": 3597.7000000000003, "text": " Otherwise, I'm going to bail.", "tokens": [10328, 11, 286, 478, 516, 281, 19313, 13], "temperature": 0.0, "avg_logprob": -0.22136139383121411, "compression_ratio": 1.676991150442478, "no_speech_prob": 7.224427918117726e-07}, {"id": 900, "seek": 358482, "start": 3597.7000000000003, "end": 3601.7000000000003, "text": " But if you follow these conventions, then I will allow you to modify it.", "tokens": [583, 498, 291, 1524, 613, 33520, 11, 550, 286, 486, 2089, 291, 281, 16927, 309, 13], "temperature": 0.0, "avg_logprob": -0.22136139383121411, "compression_ratio": 1.676991150442478, "no_speech_prob": 7.224427918117726e-07}, {"id": 901, "seek": 358482, "start": 3601.7000000000003, "end": 3609.02, "text": " So that's sort of a cool, like, not like scaffolding within an existing file technique, I think.", "tokens": [407, 300, 311, 1333, 295, 257, 1627, 11, 411, 11, 406, 411, 44094, 278, 1951, 364, 6741, 3991, 6532, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.22136139383121411, "compression_ratio": 1.676991150442478, "no_speech_prob": 7.224427918117726e-07}, {"id": 902, "seek": 358482, "start": 3609.02, "end": 3610.02, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.22136139383121411, "compression_ratio": 1.676991150442478, "no_speech_prob": 7.224427918117726e-07}, {"id": 903, "seek": 361002, "start": 3610.02, "end": 3615.42, "text": " As you say, like, it's incision, so you I need to detect like, well, where's the section", "tokens": [1018, 291, 584, 11, 411, 11, 309, 311, 834, 1991, 11, 370, 291, 286, 643, 281, 5531, 411, 11, 731, 11, 689, 311, 264, 3541], "temperature": 0.0, "avg_logprob": -0.2631070797259991, "compression_ratio": 1.5981735159817352, "no_speech_prob": 8.446180004284543e-07}, {"id": 904, "seek": 361002, "start": 3615.42, "end": 3621.06, "text": " where list all the rules, and I'm expecting it to have some kind of shape or try to do", "tokens": [689, 1329, 439, 264, 4474, 11, 293, 286, 478, 9650, 309, 281, 362, 512, 733, 295, 3909, 420, 853, 281, 360], "temperature": 0.0, "avg_logprob": -0.2631070797259991, "compression_ratio": 1.5981735159817352, "no_speech_prob": 8.446180004284543e-07}, {"id": 905, "seek": 361002, "start": 3621.06, "end": 3622.98, "text": " some pattern matching.", "tokens": [512, 5102, 14324, 13], "temperature": 0.0, "avg_logprob": -0.2631070797259991, "compression_ratio": 1.5981735159817352, "no_speech_prob": 8.446180004284543e-07}, {"id": 906, "seek": 361002, "start": 3622.98, "end": 3626.98, "text": " And so far, no one has complained about it.", "tokens": [400, 370, 1400, 11, 572, 472, 575, 33951, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.2631070797259991, "compression_ratio": 1.5981735159817352, "no_speech_prob": 8.446180004284543e-07}, {"id": 907, "seek": 361002, "start": 3626.98, "end": 3630.74, "text": " But it works as long as people don't touch it in a weird way.", "tokens": [583, 309, 1985, 382, 938, 382, 561, 500, 380, 2557, 309, 294, 257, 3657, 636, 13], "temperature": 0.0, "avg_logprob": -0.2631070797259991, "compression_ratio": 1.5981735159817352, "no_speech_prob": 8.446180004284543e-07}, {"id": 908, "seek": 361002, "start": 3630.74, "end": 3633.14, "text": " But I don't know if they know it's a feature.", "tokens": [583, 286, 500, 380, 458, 498, 436, 458, 309, 311, 257, 4111, 13], "temperature": 0.0, "avg_logprob": -0.2631070797259991, "compression_ratio": 1.5981735159817352, "no_speech_prob": 8.446180004284543e-07}, {"id": 909, "seek": 363314, "start": 3633.14, "end": 3640.18, "text": " Well, actually, a lot of people don't use my package scaffolding tool, because they", "tokens": [1042, 11, 767, 11, 257, 688, 295, 561, 500, 380, 764, 452, 7372, 44094, 278, 2290, 11, 570, 436], "temperature": 0.0, "avg_logprob": -0.36689858558850413, "compression_ratio": 1.5737704918032787, "no_speech_prob": 9.721483138491749e-07}, {"id": 910, "seek": 363314, "start": 3640.18, "end": 3643.8599999999997, "text": " don't know it takes because they don't know it is.", "tokens": [500, 380, 458, 309, 2516, 570, 436, 500, 380, 458, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.36689858558850413, "compression_ratio": 1.5737704918032787, "no_speech_prob": 9.721483138491749e-07}, {"id": 911, "seek": 363314, "start": 3643.8599999999997, "end": 3648.46, "text": " I used it for creating new packages, and I like it.", "tokens": [286, 1143, 309, 337, 4084, 777, 17401, 11, 293, 286, 411, 309, 13], "temperature": 0.0, "avg_logprob": -0.36689858558850413, "compression_ratio": 1.5737704918032787, "no_speech_prob": 9.721483138491749e-07}, {"id": 912, "seek": 363314, "start": 3648.46, "end": 3651.1, "text": " Yeah, yeah.", "tokens": [865, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.36689858558850413, "compression_ratio": 1.5737704918032787, "no_speech_prob": 9.721483138491749e-07}, {"id": 913, "seek": 363314, "start": 3651.1, "end": 3658.9, "text": " But I think like, the fact that this sort of technique of modifying things easily without", "tokens": [583, 286, 519, 411, 11, 264, 1186, 300, 341, 1333, 295, 6532, 295, 42626, 721, 3612, 1553], "temperature": 0.0, "avg_logprob": -0.36689858558850413, "compression_ratio": 1.5737704918032787, "no_speech_prob": 9.721483138491749e-07}, {"id": 914, "seek": 365890, "start": 3658.9, "end": 3665.54, "text": " too much fancy static analysis and control flow analysis and type inference and stuff,", "tokens": [886, 709, 10247, 13437, 5215, 293, 1969, 3095, 5215, 293, 2010, 38253, 293, 1507, 11], "temperature": 0.0, "avg_logprob": -0.26661741733551025, "compression_ratio": 1.7259615384615385, "no_speech_prob": 7.5279576776665635e-06}, {"id": 915, "seek": 365890, "start": 3665.54, "end": 3672.38, "text": " I think the fact that that depends on using some very clear conventions can be a feature", "tokens": [286, 519, 264, 1186, 300, 300, 5946, 322, 1228, 512, 588, 1850, 33520, 393, 312, 257, 4111], "temperature": 0.0, "avg_logprob": -0.26661741733551025, "compression_ratio": 1.7259615384615385, "no_speech_prob": 7.5279576776665635e-06}, {"id": 916, "seek": 365890, "start": 3672.38, "end": 3673.94, "text": " not a bug.", "tokens": [406, 257, 7426, 13], "temperature": 0.0, "avg_logprob": -0.26661741733551025, "compression_ratio": 1.7259615384615385, "no_speech_prob": 7.5279576776665635e-06}, {"id": 917, "seek": 365890, "start": 3673.94, "end": 3679.62, "text": " Because like enforcing certain conventions and giving you these nice automations you", "tokens": [1436, 411, 25495, 2175, 1629, 33520, 293, 2902, 291, 613, 1481, 3553, 763, 291], "temperature": 0.0, "avg_logprob": -0.26661741733551025, "compression_ratio": 1.7259615384615385, "no_speech_prob": 7.5279576776665635e-06}, {"id": 918, "seek": 365890, "start": 3679.62, "end": 3686.14, "text": " can use if you follow these conventions can strengthen the cohesiveness of a code base.", "tokens": [393, 764, 498, 291, 1524, 613, 33520, 393, 17045, 264, 598, 8076, 8477, 295, 257, 3089, 3096, 13], "temperature": 0.0, "avg_logprob": -0.26661741733551025, "compression_ratio": 1.7259615384615385, "no_speech_prob": 7.5279576776665635e-06}, {"id": 919, "seek": 368614, "start": 3686.14, "end": 3689.3799999999997, "text": " In this case, I'm touching the readme, but if I was touching Elm code, then we would", "tokens": [682, 341, 1389, 11, 286, 478, 11175, 264, 1401, 1398, 11, 457, 498, 286, 390, 11175, 2699, 76, 3089, 11, 550, 321, 576], "temperature": 0.0, "avg_logprob": -0.22905487125202761, "compression_ratio": 1.7091633466135459, "no_speech_prob": 1.2482612419262296e-06}, {"id": 920, "seek": 368614, "start": 3689.3799999999997, "end": 3691.8199999999997, "text": " have the compiler to help us out.", "tokens": [362, 264, 31958, 281, 854, 505, 484, 13], "temperature": 0.0, "avg_logprob": -0.22905487125202761, "compression_ratio": 1.7091633466135459, "no_speech_prob": 1.2482612419262296e-06}, {"id": 921, "seek": 368614, "start": 3691.8199999999997, "end": 3697.58, "text": " If we don't have that, or if the Elm compiler doesn't help in this case, then yeah, using", "tokens": [759, 321, 500, 380, 362, 300, 11, 420, 498, 264, 2699, 76, 31958, 1177, 380, 854, 294, 341, 1389, 11, 550, 1338, 11, 1228], "temperature": 0.0, "avg_logprob": -0.22905487125202761, "compression_ratio": 1.7091633466135459, "no_speech_prob": 1.2482612419262296e-06}, {"id": 922, "seek": 368614, "start": 3697.58, "end": 3701.24, "text": " conventions is a good way around that.", "tokens": [33520, 307, 257, 665, 636, 926, 300, 13], "temperature": 0.0, "avg_logprob": -0.22905487125202761, "compression_ratio": 1.7091633466135459, "no_speech_prob": 1.2482612419262296e-06}, {"id": 923, "seek": 368614, "start": 3701.24, "end": 3705.66, "text": " Another thing I played around with a little bit in these scaffolding helpers for Elm pages", "tokens": [3996, 551, 286, 3737, 926, 365, 257, 707, 857, 294, 613, 44094, 278, 854, 433, 337, 2699, 76, 7183], "temperature": 0.0, "avg_logprob": -0.22905487125202761, "compression_ratio": 1.7091633466135459, "no_speech_prob": 1.2482612419262296e-06}, {"id": 924, "seek": 368614, "start": 3705.66, "end": 3714.2599999999998, "text": " is I noticed, again, like inspired by this DHH demo, I was trying to notice all the things", "tokens": [307, 286, 5694, 11, 797, 11, 411, 7547, 538, 341, 413, 7499, 10723, 11, 286, 390, 1382, 281, 3449, 439, 264, 721], "temperature": 0.0, "avg_logprob": -0.22905487125202761, "compression_ratio": 1.7091633466135459, "no_speech_prob": 1.2482612419262296e-06}, {"id": 925, "seek": 371426, "start": 3714.26, "end": 3717.98, "text": " that were slowing me down when I was using the scaffolding.", "tokens": [300, 645, 26958, 385, 760, 562, 286, 390, 1228, 264, 44094, 278, 13], "temperature": 0.0, "avg_logprob": -0.2607619094848633, "compression_ratio": 1.6711111111111112, "no_speech_prob": 7.338182967941975e-07}, {"id": 926, "seek": 371426, "start": 3717.98, "end": 3723.6200000000003, "text": " So one thing I noticed was like originally for the add route scaffolding command I had,", "tokens": [407, 472, 551, 286, 5694, 390, 411, 7993, 337, 264, 909, 7955, 44094, 278, 5622, 286, 632, 11], "temperature": 0.0, "avg_logprob": -0.2607619094848633, "compression_ratio": 1.6711111111111112, "no_speech_prob": 7.338182967941975e-07}, {"id": 927, "seek": 371426, "start": 3723.6200000000003, "end": 3729.38, "text": " I noticed that I would go in, I do add route with a few form fields, it generates a route", "tokens": [286, 5694, 300, 286, 576, 352, 294, 11, 286, 360, 909, 7955, 365, 257, 1326, 1254, 7909, 11, 309, 23815, 257, 7955], "temperature": 0.0, "avg_logprob": -0.2607619094848633, "compression_ratio": 1.6711111111111112, "no_speech_prob": 7.338182967941975e-07}, {"id": 928, "seek": 371426, "start": 3729.38, "end": 3731.7000000000003, "text": " with with a form wired in.", "tokens": [365, 365, 257, 1254, 27415, 294, 13], "temperature": 0.0, "avg_logprob": -0.2607619094848633, "compression_ratio": 1.6711111111111112, "no_speech_prob": 7.338182967941975e-07}, {"id": 929, "seek": 371426, "start": 3731.7000000000003, "end": 3732.98, "text": " And that's great.", "tokens": [400, 300, 311, 869, 13], "temperature": 0.0, "avg_logprob": -0.2607619094848633, "compression_ratio": 1.6711111111111112, "no_speech_prob": 7.338182967941975e-07}, {"id": 930, "seek": 371426, "start": 3732.98, "end": 3741.42, "text": " But then in the Elm pages sort of full stack code, where it's receiving that form submission,", "tokens": [583, 550, 294, 264, 2699, 76, 7183, 1333, 295, 1577, 8630, 3089, 11, 689, 309, 311, 10040, 300, 1254, 23689, 11], "temperature": 0.0, "avg_logprob": -0.2607619094848633, "compression_ratio": 1.6711111111111112, "no_speech_prob": 7.338182967941975e-07}, {"id": 931, "seek": 374142, "start": 3741.42, "end": 3746.34, "text": " and it has the parsed form, I was debug logging it.", "tokens": [293, 309, 575, 264, 21156, 292, 1254, 11, 286, 390, 24083, 27991, 309, 13], "temperature": 0.0, "avg_logprob": -0.18419403589072347, "compression_ratio": 1.7692307692307692, "no_speech_prob": 1.6536835119040916e-06}, {"id": 932, "seek": 374142, "start": 3746.34, "end": 3752.1800000000003, "text": " And what I found when I was trying to make the demo very short, was that I would forget", "tokens": [400, 437, 286, 1352, 562, 286, 390, 1382, 281, 652, 264, 10723, 588, 2099, 11, 390, 300, 286, 576, 2870], "temperature": 0.0, "avg_logprob": -0.18419403589072347, "compression_ratio": 1.7692307692307692, "no_speech_prob": 1.6536835119040916e-06}, {"id": 933, "seek": 374142, "start": 3752.1800000000003, "end": 3758.02, "text": " to take out the debug.log sometimes, and then I would do the part of the demo where I ship", "tokens": [281, 747, 484, 264, 24083, 13, 4987, 2171, 11, 293, 550, 286, 576, 360, 264, 644, 295, 264, 10723, 689, 286, 5374], "temperature": 0.0, "avg_logprob": -0.18419403589072347, "compression_ratio": 1.7692307692307692, "no_speech_prob": 1.6536835119040916e-06}, {"id": 934, "seek": 374142, "start": 3758.02, "end": 3761.58, "text": " it to Netlify and show the full stack thing working.", "tokens": [309, 281, 6188, 75, 2505, 293, 855, 264, 1577, 8630, 551, 1364, 13], "temperature": 0.0, "avg_logprob": -0.18419403589072347, "compression_ratio": 1.7692307692307692, "no_speech_prob": 1.6536835119040916e-06}, {"id": 935, "seek": 374142, "start": 3761.58, "end": 3765.06, "text": " And then it would have an error because the build command was failing because it had a", "tokens": [400, 550, 309, 576, 362, 364, 6713, 570, 264, 1322, 5622, 390, 18223, 570, 309, 632, 257], "temperature": 0.0, "avg_logprob": -0.18419403589072347, "compression_ratio": 1.7692307692307692, "no_speech_prob": 1.6536835119040916e-06}, {"id": 936, "seek": 374142, "start": 3765.06, "end": 3766.06, "text": " debug in it.", "tokens": [24083, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.18419403589072347, "compression_ratio": 1.7692307692307692, "no_speech_prob": 1.6536835119040916e-06}, {"id": 937, "seek": 374142, "start": 3766.06, "end": 3769.58, "text": " So that's sort of like not setting it up for success.", "tokens": [407, 300, 311, 1333, 295, 411, 406, 3287, 309, 493, 337, 2245, 13], "temperature": 0.0, "avg_logprob": -0.18419403589072347, "compression_ratio": 1.7692307692307692, "no_speech_prob": 1.6536835119040916e-06}, {"id": 938, "seek": 376958, "start": 3769.58, "end": 3775.74, "text": " And again, not being exemplary code that is making it easy to evolve in the shape you", "tokens": [400, 797, 11, 406, 885, 24112, 822, 3089, 300, 307, 1455, 309, 1858, 281, 16693, 294, 264, 3909, 291], "temperature": 0.0, "avg_logprob": -0.24700327714284262, "compression_ratio": 1.6616161616161615, "no_speech_prob": 4.6644231588288676e-07}, {"id": 939, "seek": 376958, "start": 3775.74, "end": 3777.14, "text": " want it to evolve in.", "tokens": [528, 309, 281, 16693, 294, 13], "temperature": 0.0, "avg_logprob": -0.24700327714284262, "compression_ratio": 1.6616161616161615, "no_speech_prob": 4.6644231588288676e-07}, {"id": 940, "seek": 376958, "start": 3777.14, "end": 3781.5, "text": " So I modified it to take this form that it's generating.", "tokens": [407, 286, 15873, 309, 281, 747, 341, 1254, 300, 309, 311, 17746, 13], "temperature": 0.0, "avg_logprob": -0.24700327714284262, "compression_ratio": 1.6616161616161615, "no_speech_prob": 4.6644231588288676e-07}, {"id": 941, "seek": 376958, "start": 3781.5, "end": 3785.2599999999998, "text": " So you give the CLI these form fields.", "tokens": [407, 291, 976, 264, 12855, 40, 613, 1254, 7909, 13], "temperature": 0.0, "avg_logprob": -0.24700327714284262, "compression_ratio": 1.6616161616161615, "no_speech_prob": 4.6644231588288676e-07}, {"id": 942, "seek": 376958, "start": 3785.2599999999998, "end": 3787.06, "text": " These form fields have types.", "tokens": [1981, 1254, 7909, 362, 3467, 13], "temperature": 0.0, "avg_logprob": -0.24700327714284262, "compression_ratio": 1.6616161616161615, "no_speech_prob": 4.6644231588288676e-07}, {"id": 943, "seek": 376958, "start": 3787.06, "end": 3791.38, "text": " The checkbox has a boolean type, a text field has a string type.", "tokens": [440, 1520, 4995, 575, 257, 748, 4812, 282, 2010, 11, 257, 2487, 2519, 575, 257, 6798, 2010, 13], "temperature": 0.0, "avg_logprob": -0.24700327714284262, "compression_ratio": 1.6616161616161615, "no_speech_prob": 4.6644231588288676e-07}, {"id": 944, "seek": 376958, "start": 3791.38, "end": 3793.38, "text": " So it knows sort of the types.", "tokens": [407, 309, 3255, 1333, 295, 264, 3467, 13], "temperature": 0.0, "avg_logprob": -0.24700327714284262, "compression_ratio": 1.6616161616161615, "no_speech_prob": 4.6644231588288676e-07}, {"id": 945, "seek": 379338, "start": 3793.38, "end": 3800.6400000000003, "text": " It generates a record for the parsed form that you can change the scaffolding to map", "tokens": [467, 23815, 257, 2136, 337, 264, 21156, 292, 1254, 300, 291, 393, 1319, 264, 44094, 278, 281, 4471], "temperature": 0.0, "avg_logprob": -0.2284322182337443, "compression_ratio": 1.7464114832535884, "no_speech_prob": 6.179319598231814e-07}, {"id": 946, "seek": 379338, "start": 3800.6400000000003, "end": 3804.06, "text": " it into nicer opaque types or whatever you want to do.", "tokens": [309, 666, 22842, 42687, 3467, 420, 2035, 291, 528, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.2284322182337443, "compression_ratio": 1.7464114832535884, "no_speech_prob": 6.179319598231814e-07}, {"id": 947, "seek": 379338, "start": 3804.06, "end": 3810.98, "text": " But it gives you a sort of good baseline of strings and bools and date types for the parsed", "tokens": [583, 309, 2709, 291, 257, 1333, 295, 665, 20518, 295, 13985, 293, 748, 19385, 293, 4002, 3467, 337, 264, 21156, 292], "temperature": 0.0, "avg_logprob": -0.2284322182337443, "compression_ratio": 1.7464114832535884, "no_speech_prob": 6.179319598231814e-07}, {"id": 948, "seek": 379338, "start": 3810.98, "end": 3812.2400000000002, "text": " form.", "tokens": [1254, 13], "temperature": 0.0, "avg_logprob": -0.2284322182337443, "compression_ratio": 1.7464114832535884, "no_speech_prob": 6.179319598231814e-07}, {"id": 949, "seek": 379338, "start": 3812.2400000000002, "end": 3815.1600000000003, "text": " And then I have a scaffolding helper.", "tokens": [400, 550, 286, 362, 257, 44094, 278, 36133, 13], "temperature": 0.0, "avg_logprob": -0.2284322182337443, "compression_ratio": 1.7464114832535884, "no_speech_prob": 6.179319598231814e-07}, {"id": 950, "seek": 379338, "start": 3815.1600000000003, "end": 3822.62, "text": " So you can take that type in addition to using it to just generate the type alias for the", "tokens": [407, 291, 393, 747, 300, 2010, 294, 4500, 281, 1228, 309, 281, 445, 8460, 264, 2010, 419, 4609, 337, 264], "temperature": 0.0, "avg_logprob": -0.2284322182337443, "compression_ratio": 1.7464114832535884, "no_speech_prob": 6.179319598231814e-07}, {"id": 951, "seek": 382262, "start": 3822.62, "end": 3824.2999999999997, "text": " parsed form.", "tokens": [21156, 292, 1254, 13], "temperature": 0.0, "avg_logprob": -0.20257978439331054, "compression_ratio": 1.6439024390243901, "no_speech_prob": 3.0894623250787845e-06}, {"id": 952, "seek": 382262, "start": 3824.2999999999997, "end": 3827.58, "text": " It can generate a JSON encoder.", "tokens": [467, 393, 8460, 257, 31828, 2058, 19866, 13], "temperature": 0.0, "avg_logprob": -0.20257978439331054, "compression_ratio": 1.6439024390243901, "no_speech_prob": 3.0894623250787845e-06}, {"id": 953, "seek": 382262, "start": 3827.58, "end": 3833.02, "text": " And so instead of doing debug.log, I took that parsed form type.", "tokens": [400, 370, 2602, 295, 884, 24083, 13, 4987, 11, 286, 1890, 300, 21156, 292, 1254, 2010, 13], "temperature": 0.0, "avg_logprob": -0.20257978439331054, "compression_ratio": 1.6439024390243901, "no_speech_prob": 3.0894623250787845e-06}, {"id": 954, "seek": 382262, "start": 3833.02, "end": 3840.54, "text": " I know what the type is in the generated code, and I generate a JSON encoder for that.", "tokens": [286, 458, 437, 264, 2010, 307, 294, 264, 10833, 3089, 11, 293, 286, 8460, 257, 31828, 2058, 19866, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.20257978439331054, "compression_ratio": 1.6439024390243901, "no_speech_prob": 3.0894623250787845e-06}, {"id": 955, "seek": 382262, "start": 3840.54, "end": 3846.18, "text": " And I send it out through a log, which is not a debug log, but it's an actual back-end", "tokens": [400, 286, 2845, 309, 484, 807, 257, 3565, 11, 597, 307, 406, 257, 24083, 3565, 11, 457, 309, 311, 364, 3539, 646, 12, 521], "temperature": 0.0, "avg_logprob": -0.20257978439331054, "compression_ratio": 1.6439024390243901, "no_speech_prob": 3.0894623250787845e-06}, {"id": 956, "seek": 382262, "start": 3846.18, "end": 3850.14, "text": " task log that you can ship in a production code base.", "tokens": [5633, 3565, 300, 291, 393, 5374, 294, 257, 4265, 3089, 3096, 13], "temperature": 0.0, "avg_logprob": -0.20257978439331054, "compression_ratio": 1.6439024390243901, "no_speech_prob": 3.0894623250787845e-06}, {"id": 957, "seek": 385014, "start": 3850.14, "end": 3852.68, "text": " So now, and this is all user configurable.", "tokens": [407, 586, 11, 293, 341, 307, 439, 4195, 22192, 712, 13], "temperature": 0.0, "avg_logprob": -0.20950981828032947, "compression_ratio": 1.754646840148699, "no_speech_prob": 1.933354724314995e-06}, {"id": 958, "seek": 385014, "start": 3852.68, "end": 3857.8599999999997, "text": " So if your code base evolves and you want to use a different pattern, you don't want", "tokens": [407, 498, 428, 3089, 3096, 43737, 293, 291, 528, 281, 764, 257, 819, 5102, 11, 291, 500, 380, 528], "temperature": 0.0, "avg_logprob": -0.20950981828032947, "compression_ratio": 1.754646840148699, "no_speech_prob": 1.933354724314995e-06}, {"id": 959, "seek": 385014, "start": 3857.8599999999997, "end": 3861.98, "text": " to JSON encode it, you don't want to log it, you want to do some specific thing to it,", "tokens": [281, 31828, 2058, 1429, 309, 11, 291, 500, 380, 528, 281, 3565, 309, 11, 291, 528, 281, 360, 512, 2685, 551, 281, 309, 11], "temperature": 0.0, "avg_logprob": -0.20950981828032947, "compression_ratio": 1.754646840148699, "no_speech_prob": 1.933354724314995e-06}, {"id": 960, "seek": 385014, "start": 3861.98, "end": 3866.98, "text": " you can follow those patterns and change it because this scaffolding API I built allows", "tokens": [291, 393, 1524, 729, 8294, 293, 1319, 309, 570, 341, 44094, 278, 9362, 286, 3094, 4045], "temperature": 0.0, "avg_logprob": -0.20950981828032947, "compression_ratio": 1.754646840148699, "no_speech_prob": 1.933354724314995e-06}, {"id": 961, "seek": 385014, "start": 3866.98, "end": 3868.2999999999997, "text": " you to customize that.", "tokens": [291, 281, 19734, 300, 13], "temperature": 0.0, "avg_logprob": -0.20950981828032947, "compression_ratio": 1.754646840148699, "no_speech_prob": 1.933354724314995e-06}, {"id": 962, "seek": 385014, "start": 3868.2999999999997, "end": 3871.1, "text": " But it gives you the building blocks to generate these things.", "tokens": [583, 309, 2709, 291, 264, 2390, 8474, 281, 8460, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.20950981828032947, "compression_ratio": 1.754646840148699, "no_speech_prob": 1.933354724314995e-06}, {"id": 963, "seek": 385014, "start": 3871.1, "end": 3878.22, "text": " And what I found was when I was trying to basically like speed run this demo, I was", "tokens": [400, 437, 286, 1352, 390, 562, 286, 390, 1382, 281, 1936, 411, 3073, 1190, 341, 10723, 11, 286, 390], "temperature": 0.0, "avg_logprob": -0.20950981828032947, "compression_ratio": 1.754646840148699, "no_speech_prob": 1.933354724314995e-06}, {"id": 964, "seek": 387822, "start": 3878.22, "end": 3882.1, "text": " more set up for success because actually it was like, oh, actually, I do want to use a", "tokens": [544, 992, 493, 337, 2245, 570, 767, 309, 390, 411, 11, 1954, 11, 767, 11, 286, 360, 528, 281, 764, 257], "temperature": 0.0, "avg_logprob": -0.23902177810668945, "compression_ratio": 1.7011494252873562, "no_speech_prob": 4.289306161808781e-06}, {"id": 965, "seek": 387822, "start": 3882.1, "end": 3883.1, "text": " JSON encoder.", "tokens": [31828, 2058, 19866, 13], "temperature": 0.0, "avg_logprob": -0.23902177810668945, "compression_ratio": 1.7011494252873562, "no_speech_prob": 4.289306161808781e-06}, {"id": 966, "seek": 387822, "start": 3883.1, "end": 3888.8999999999996, "text": " But instead of sending the JSON encoder, and then encoding that to a string, and then logging", "tokens": [583, 2602, 295, 7750, 264, 31828, 2058, 19866, 11, 293, 550, 43430, 300, 281, 257, 6798, 11, 293, 550, 27991], "temperature": 0.0, "avg_logprob": -0.23902177810668945, "compression_ratio": 1.7011494252873562, "no_speech_prob": 4.289306161808781e-06}, {"id": 967, "seek": 387822, "start": 3888.8999999999996, "end": 3892.8999999999996, "text": " that, I want to send it through a custom back-end task or whatever.", "tokens": [300, 11, 286, 528, 281, 2845, 309, 807, 257, 2375, 646, 12, 521, 5633, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.23902177810668945, "compression_ratio": 1.7011494252873562, "no_speech_prob": 4.289306161808781e-06}, {"id": 968, "seek": 387822, "start": 3892.8999999999996, "end": 3902.22, "text": " So I was trying to sort of like use these same idioms in a way that would be like meaningful", "tokens": [407, 286, 390, 1382, 281, 1333, 295, 411, 764, 613, 912, 18014, 4785, 294, 257, 636, 300, 576, 312, 411, 10995], "temperature": 0.0, "avg_logprob": -0.23902177810668945, "compression_ratio": 1.7011494252873562, "no_speech_prob": 4.289306161808781e-06}, {"id": 969, "seek": 387822, "start": 3902.22, "end": 3905.58, "text": " and help me guide me in the direction my production code wants to go.", "tokens": [293, 854, 385, 5934, 385, 294, 264, 3513, 452, 4265, 3089, 2738, 281, 352, 13], "temperature": 0.0, "avg_logprob": -0.23902177810668945, "compression_ratio": 1.7011494252873562, "no_speech_prob": 4.289306161808781e-06}, {"id": 970, "seek": 387822, "start": 3905.58, "end": 3906.58, "text": " I'm happy with it.", "tokens": [286, 478, 2055, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.23902177810668945, "compression_ratio": 1.7011494252873562, "no_speech_prob": 4.289306161808781e-06}, {"id": 971, "seek": 390658, "start": 3906.58, "end": 3912.38, "text": " I think it's also a nice pattern to like use types and create Elm CodeGen helpers to work", "tokens": [286, 519, 309, 311, 611, 257, 1481, 5102, 281, 411, 764, 3467, 293, 1884, 2699, 76, 15549, 26647, 854, 433, 281, 589], "temperature": 0.0, "avg_logprob": -0.2799499231740969, "compression_ratio": 1.707112970711297, "no_speech_prob": 6.240789844014216e-06}, {"id": 972, "seek": 390658, "start": 3912.38, "end": 3917.7799999999997, "text": " with types like creating an Elm CodeGen helper to JSON encode a type.", "tokens": [365, 3467, 411, 4084, 364, 2699, 76, 15549, 26647, 36133, 281, 31828, 2058, 1429, 257, 2010, 13], "temperature": 0.0, "avg_logprob": -0.2799499231740969, "compression_ratio": 1.707112970711297, "no_speech_prob": 6.240789844014216e-06}, {"id": 973, "seek": 390658, "start": 3917.7799999999997, "end": 3920.5, "text": " It is something that we can build.", "tokens": [467, 307, 746, 300, 321, 393, 1322, 13], "temperature": 0.0, "avg_logprob": -0.2799499231740969, "compression_ratio": 1.707112970711297, "no_speech_prob": 6.240789844014216e-06}, {"id": 974, "seek": 390658, "start": 3920.5, "end": 3922.7, "text": " So there's some really cool possibilities.", "tokens": [407, 456, 311, 512, 534, 1627, 12178, 13], "temperature": 0.0, "avg_logprob": -0.2799499231740969, "compression_ratio": 1.707112970711297, "no_speech_prob": 6.240789844014216e-06}, {"id": 975, "seek": 390658, "start": 3922.7, "end": 3927.98, "text": " Like I think building higher level helpers to help generate things with Elm CodeGen is", "tokens": [1743, 286, 519, 2390, 2946, 1496, 854, 433, 281, 854, 8460, 721, 365, 2699, 76, 15549, 26647, 307], "temperature": 0.0, "avg_logprob": -0.2799499231740969, "compression_ratio": 1.707112970711297, "no_speech_prob": 6.240789844014216e-06}, {"id": 976, "seek": 390658, "start": 3927.98, "end": 3930.46, "text": " like a really exciting space.", "tokens": [411, 257, 534, 4670, 1901, 13], "temperature": 0.0, "avg_logprob": -0.2799499231740969, "compression_ratio": 1.707112970711297, "no_speech_prob": 6.240789844014216e-06}, {"id": 977, "seek": 390658, "start": 3930.46, "end": 3932.68, "text": " What should we tear this scaffolding down?", "tokens": [708, 820, 321, 12556, 341, 44094, 278, 760, 30], "temperature": 0.0, "avg_logprob": -0.2799499231740969, "compression_ratio": 1.707112970711297, "no_speech_prob": 6.240789844014216e-06}, {"id": 978, "seek": 390658, "start": 3932.68, "end": 3933.68, "text": " We should.", "tokens": [492, 820, 13], "temperature": 0.0, "avg_logprob": -0.2799499231740969, "compression_ratio": 1.707112970711297, "no_speech_prob": 6.240789844014216e-06}, {"id": 979, "seek": 393368, "start": 3933.68, "end": 3940.94, "text": " I did mention it before with GPT and all those AI tools.", "tokens": [286, 630, 2152, 309, 949, 365, 26039, 51, 293, 439, 729, 7318, 3873, 13], "temperature": 0.0, "avg_logprob": -0.2342722817753138, "compression_ratio": 1.4976303317535544, "no_speech_prob": 1.5779455679876264e-06}, {"id": 980, "seek": 393368, "start": 3940.94, "end": 3946.54, "text": " Maybe this whole conversation will end up being pretty useless.", "tokens": [2704, 341, 1379, 3761, 486, 917, 493, 885, 1238, 14115, 13], "temperature": 0.0, "avg_logprob": -0.2342722817753138, "compression_ratio": 1.4976303317535544, "no_speech_prob": 1.5779455679876264e-06}, {"id": 981, "seek": 393368, "start": 3946.54, "end": 3947.54, "text": " I don't know.", "tokens": [286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.2342722817753138, "compression_ratio": 1.4976303317535544, "no_speech_prob": 1.5779455679876264e-06}, {"id": 982, "seek": 393368, "start": 3947.54, "end": 3948.54, "text": " We'll see.", "tokens": [492, 603, 536, 13], "temperature": 0.0, "avg_logprob": -0.2342722817753138, "compression_ratio": 1.4976303317535544, "no_speech_prob": 1.5779455679876264e-06}, {"id": 983, "seek": 393368, "start": 3948.54, "end": 3955.7999999999997, "text": " I mean, we certainly can guide people to do the right thing better than what we can teach", "tokens": [286, 914, 11, 321, 3297, 393, 5934, 561, 281, 360, 264, 558, 551, 1101, 813, 437, 321, 393, 2924], "temperature": 0.0, "avg_logprob": -0.2342722817753138, "compression_ratio": 1.4976303317535544, "no_speech_prob": 1.5779455679876264e-06}, {"id": 984, "seek": 393368, "start": 3955.7999999999997, "end": 3961.74, "text": " such a tool to do, especially if we can't teach it's anything, as far as I know.", "tokens": [1270, 257, 2290, 281, 360, 11, 2318, 498, 321, 393, 380, 2924, 309, 311, 1340, 11, 382, 1400, 382, 286, 458, 13], "temperature": 0.0, "avg_logprob": -0.2342722817753138, "compression_ratio": 1.4976303317535544, "no_speech_prob": 1.5779455679876264e-06}, {"id": 985, "seek": 396174, "start": 3961.74, "end": 3965.58, "text": " But I mean, we'll see how those will evolve.", "tokens": [583, 286, 914, 11, 321, 603, 536, 577, 729, 486, 16693, 13], "temperature": 0.0, "avg_logprob": -0.2880202169003694, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.4144540045890608e-06}, {"id": 986, "seek": 396174, "start": 3965.58, "end": 3967.3599999999997, "text": " It's a fascinating topic.", "tokens": [467, 311, 257, 10343, 4829, 13], "temperature": 0.0, "avg_logprob": -0.2880202169003694, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.4144540045890608e-06}, {"id": 987, "seek": 396174, "start": 3967.3599999999997, "end": 3969.3799999999997, "text": " My instincts on this.", "tokens": [1222, 38997, 322, 341, 13], "temperature": 0.0, "avg_logprob": -0.2880202169003694, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.4144540045890608e-06}, {"id": 988, "seek": 396174, "start": 3969.3799999999997, "end": 3973.8199999999997, "text": " Now this may be, you know, me becoming an old curmudgeon or something.", "tokens": [823, 341, 815, 312, 11, 291, 458, 11, 385, 5617, 364, 1331, 1262, 31916, 11641, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.2880202169003694, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.4144540045890608e-06}, {"id": 989, "seek": 396174, "start": 3973.8199999999997, "end": 3974.8199999999997, "text": " I don't know.", "tokens": [286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.2880202169003694, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.4144540045890608e-06}, {"id": 990, "seek": 396174, "start": 3974.8199999999997, "end": 3979.3399999999997, "text": " But my instinct is that there's value to explicitness.", "tokens": [583, 452, 16556, 307, 300, 456, 311, 2158, 281, 28021, 6394, 13], "temperature": 0.0, "avg_logprob": -0.2880202169003694, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.4144540045890608e-06}, {"id": 991, "seek": 396174, "start": 3979.3399999999997, "end": 3981.3399999999997, "text": " There are worse things than magic.", "tokens": [821, 366, 5324, 721, 813, 5585, 13], "temperature": 0.0, "avg_logprob": -0.2880202169003694, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.4144540045890608e-06}, {"id": 992, "seek": 396174, "start": 3981.3399999999997, "end": 3984.9799999999996, "text": " Yeah, there are worse things than magic.", "tokens": [865, 11, 456, 366, 5324, 721, 813, 5585, 13], "temperature": 0.0, "avg_logprob": -0.2880202169003694, "compression_ratio": 1.5714285714285714, "no_speech_prob": 1.4144540045890608e-06}, {"id": 993, "seek": 398498, "start": 3984.98, "end": 3991.86, "text": " Now I think like having explicit tools for scaffolding code still has value even with", "tokens": [823, 286, 519, 411, 1419, 13691, 3873, 337, 44094, 278, 3089, 920, 575, 2158, 754, 365], "temperature": 0.0, "avg_logprob": -0.20835516357421874, "compression_ratio": 1.7432950191570882, "no_speech_prob": 1.760274585649313e-06}, {"id": 994, "seek": 398498, "start": 3991.86, "end": 3993.9, "text": " AI assist tools.", "tokens": [7318, 4255, 3873, 13], "temperature": 0.0, "avg_logprob": -0.20835516357421874, "compression_ratio": 1.7432950191570882, "no_speech_prob": 1.760274585649313e-06}, {"id": 995, "seek": 398498, "start": 3993.9, "end": 3999.82, "text": " I'm not saying that AI assist tools aren't also helpful, but if you can create high level", "tokens": [286, 478, 406, 1566, 300, 7318, 4255, 3873, 3212, 380, 611, 4961, 11, 457, 498, 291, 393, 1884, 1090, 1496], "temperature": 0.0, "avg_logprob": -0.20835516357421874, "compression_ratio": 1.7432950191570882, "no_speech_prob": 1.760274585649313e-06}, {"id": 996, "seek": 398498, "start": 3999.82, "end": 4006.06, "text": " helpers to help you do a very specific thing in a very exact way, you don't have to think", "tokens": [854, 433, 281, 854, 291, 360, 257, 588, 2685, 551, 294, 257, 588, 1900, 636, 11, 291, 500, 380, 362, 281, 519], "temperature": 0.0, "avg_logprob": -0.20835516357421874, "compression_ratio": 1.7432950191570882, "no_speech_prob": 1.760274585649313e-06}, {"id": 997, "seek": 398498, "start": 4006.06, "end": 4008.94, "text": " about did this actually give me what I want?", "tokens": [466, 630, 341, 767, 976, 385, 437, 286, 528, 30], "temperature": 0.0, "avg_logprob": -0.20835516357421874, "compression_ratio": 1.7432950191570882, "no_speech_prob": 1.760274585649313e-06}, {"id": 998, "seek": 398498, "start": 4008.94, "end": 4010.02, "text": " Is it idiomatic?", "tokens": [1119, 309, 18014, 13143, 30], "temperature": 0.0, "avg_logprob": -0.20835516357421874, "compression_ratio": 1.7432950191570882, "no_speech_prob": 1.760274585649313e-06}, {"id": 999, "seek": 398498, "start": 4010.02, "end": 4011.1, "text": " You don't have to second guess it.", "tokens": [509, 500, 380, 362, 281, 1150, 2041, 309, 13], "temperature": 0.0, "avg_logprob": -0.20835516357421874, "compression_ratio": 1.7432950191570882, "no_speech_prob": 1.760274585649313e-06}, {"id": 1000, "seek": 398498, "start": 4011.1, "end": 4012.1, "text": " You don't have to double check it.", "tokens": [509, 500, 380, 362, 281, 3834, 1520, 309, 13], "temperature": 0.0, "avg_logprob": -0.20835516357421874, "compression_ratio": 1.7432950191570882, "no_speech_prob": 1.760274585649313e-06}, {"id": 1001, "seek": 398498, "start": 4012.1, "end": 4014.34, "text": " You just use it like a high level thing.", "tokens": [509, 445, 764, 309, 411, 257, 1090, 1496, 551, 13], "temperature": 0.0, "avg_logprob": -0.20835516357421874, "compression_ratio": 1.7432950191570882, "no_speech_prob": 1.760274585649313e-06}, {"id": 1002, "seek": 401434, "start": 4014.34, "end": 4015.6000000000004, "text": " There's no context shifting.", "tokens": [821, 311, 572, 4319, 17573, 13], "temperature": 0.0, "avg_logprob": -0.28768656546609445, "compression_ratio": 1.6091954022988506, "no_speech_prob": 3.611931788327638e-06}, {"id": 1003, "seek": 401434, "start": 4015.6000000000004, "end": 4017.7400000000002, "text": " You think of it as a high level atomic thing.", "tokens": [509, 519, 295, 309, 382, 257, 1090, 1496, 22275, 551, 13], "temperature": 0.0, "avg_logprob": -0.28768656546609445, "compression_ratio": 1.6091954022988506, "no_speech_prob": 3.611931788327638e-06}, {"id": 1004, "seek": 401434, "start": 4017.7400000000002, "end": 4019.6600000000003, "text": " I'm adding a route with a form.", "tokens": [286, 478, 5127, 257, 7955, 365, 257, 1254, 13], "temperature": 0.0, "avg_logprob": -0.28768656546609445, "compression_ratio": 1.6091954022988506, "no_speech_prob": 3.611931788327638e-06}, {"id": 1005, "seek": 401434, "start": 4019.6600000000003, "end": 4020.6600000000003, "text": " Boom.", "tokens": [15523, 13], "temperature": 0.0, "avg_logprob": -0.28768656546609445, "compression_ratio": 1.6091954022988506, "no_speech_prob": 3.611931788327638e-06}, {"id": 1006, "seek": 401434, "start": 4020.6600000000003, "end": 4023.1000000000004, "text": " So to me, it still serves a purpose.", "tokens": [407, 281, 385, 11, 309, 920, 13451, 257, 4334, 13], "temperature": 0.0, "avg_logprob": -0.28768656546609445, "compression_ratio": 1.6091954022988506, "no_speech_prob": 3.611931788327638e-06}, {"id": 1007, "seek": 401434, "start": 4023.1000000000004, "end": 4027.92, "text": " And then I think that there could be interesting opportunities for an interplay between these", "tokens": [400, 550, 286, 519, 300, 456, 727, 312, 1880, 4786, 337, 364, 728, 2858, 1296, 613], "temperature": 0.0, "avg_logprob": -0.28768656546609445, "compression_ratio": 1.6091954022988506, "no_speech_prob": 3.611931788327638e-06}, {"id": 1008, "seek": 401434, "start": 4027.92, "end": 4032.1400000000003, "text": " sort of scaffolding commands and AI to sort of work together.", "tokens": [1333, 295, 44094, 278, 16901, 293, 7318, 281, 1333, 295, 589, 1214, 13], "temperature": 0.0, "avg_logprob": -0.28768656546609445, "compression_ratio": 1.6091954022988506, "no_speech_prob": 3.611931788327638e-06}, {"id": 1009, "seek": 401434, "start": 4032.1400000000003, "end": 4034.86, "text": " And I think that's another interesting space to explore.", "tokens": [400, 286, 519, 300, 311, 1071, 1880, 1901, 281, 6839, 13], "temperature": 0.0, "avg_logprob": -0.28768656546609445, "compression_ratio": 1.6091954022988506, "no_speech_prob": 3.611931788327638e-06}, {"id": 1010, "seek": 401434, "start": 4034.86, "end": 4036.6600000000003, "text": " Yeah, absolutely.", "tokens": [865, 11, 3122, 13], "temperature": 0.0, "avg_logprob": -0.28768656546609445, "compression_ratio": 1.6091954022988506, "no_speech_prob": 3.611931788327638e-06}, {"id": 1011, "seek": 401434, "start": 4036.6600000000003, "end": 4040.26, "text": " I for one welcome our new AI overlords.", "tokens": [286, 337, 472, 2928, 527, 777, 7318, 15986, 5703, 13], "temperature": 0.0, "avg_logprob": -0.28768656546609445, "compression_ratio": 1.6091954022988506, "no_speech_prob": 3.611931788327638e-06}, {"id": 1012, "seek": 404026, "start": 4040.26, "end": 4048.5, "text": " I honestly prefer my Elm Review overlords because I know what they can and what they", "tokens": [286, 6095, 4382, 452, 2699, 76, 19954, 15986, 5703, 570, 286, 458, 437, 436, 393, 293, 437, 436], "temperature": 0.0, "avg_logprob": -0.30507256984710696, "compression_ratio": 1.548913043478261, "no_speech_prob": 3.9896843873066246e-07}, {"id": 1013, "seek": 404026, "start": 4048.5, "end": 4050.5800000000004, "text": " can't do.", "tokens": [393, 380, 360, 13], "temperature": 0.0, "avg_logprob": -0.30507256984710696, "compression_ratio": 1.548913043478261, "no_speech_prob": 3.9896843873066246e-07}, {"id": 1014, "seek": 404026, "start": 4050.5800000000004, "end": 4056.0600000000004, "text": " And I know that they can't do much about how I live.", "tokens": [400, 286, 458, 300, 436, 393, 380, 360, 709, 466, 577, 286, 1621, 13], "temperature": 0.0, "avg_logprob": -0.30507256984710696, "compression_ratio": 1.548913043478261, "no_speech_prob": 3.9896843873066246e-07}, {"id": 1015, "seek": 404026, "start": 4056.0600000000004, "end": 4059.7000000000003, "text": " And that's a good thing.", "tokens": [400, 300, 311, 257, 665, 551, 13], "temperature": 0.0, "avg_logprob": -0.30507256984710696, "compression_ratio": 1.548913043478261, "no_speech_prob": 3.9896843873066246e-07}, {"id": 1016, "seek": 404026, "start": 4059.7000000000003, "end": 4065.42, "text": " I think that like pure functions and static typing, I imagine a world where that is a", "tokens": [286, 519, 300, 411, 6075, 6828, 293, 13437, 18444, 11, 286, 3811, 257, 1002, 689, 300, 307, 257], "temperature": 0.0, "avg_logprob": -0.30507256984710696, "compression_ratio": 1.548913043478261, "no_speech_prob": 3.9896843873066246e-07}, {"id": 1017, "seek": 404026, "start": 4065.42, "end": 4068.1800000000003, "text": " superpower for AI assists.", "tokens": [45765, 337, 7318, 49416, 13], "temperature": 0.0, "avg_logprob": -0.30507256984710696, "compression_ratio": 1.548913043478261, "no_speech_prob": 3.9896843873066246e-07}, {"id": 1018, "seek": 406818, "start": 4068.18, "end": 4073.98, "text": " I don't think we're at that world yet, but I think that world could come to pass.", "tokens": [286, 500, 380, 519, 321, 434, 412, 300, 1002, 1939, 11, 457, 286, 519, 300, 1002, 727, 808, 281, 1320, 13], "temperature": 0.0, "avg_logprob": -0.2549507834694602, "compression_ratio": 1.4545454545454546, "no_speech_prob": 9.664187018643133e-06}, {"id": 1019, "seek": 406818, "start": 4073.98, "end": 4074.98, "text": " We'll have to see.", "tokens": [492, 603, 362, 281, 536, 13], "temperature": 0.0, "avg_logprob": -0.2549507834694602, "compression_ratio": 1.4545454545454546, "no_speech_prob": 9.664187018643133e-06}, {"id": 1020, "seek": 406818, "start": 4074.98, "end": 4075.98, "text": " Same here.", "tokens": [10635, 510, 13], "temperature": 0.0, "avg_logprob": -0.2549507834694602, "compression_ratio": 1.4545454545454546, "no_speech_prob": 9.664187018643133e-06}, {"id": 1021, "seek": 406818, "start": 4075.98, "end": 4078.8999999999996, "text": " But that might be a topic for another conversation.", "tokens": [583, 300, 1062, 312, 257, 4829, 337, 1071, 3761, 13], "temperature": 0.0, "avg_logprob": -0.2549507834694602, "compression_ratio": 1.4545454545454546, "no_speech_prob": 9.664187018643133e-06}, {"id": 1022, "seek": 406818, "start": 4078.8999999999996, "end": 4082.1, "text": " So Jeroen, until next time.", "tokens": [407, 508, 2032, 268, 11, 1826, 958, 565, 13], "temperature": 0.0, "avg_logprob": -0.2549507834694602, "compression_ratio": 1.4545454545454546, "no_speech_prob": 9.664187018643133e-06}, {"id": 1023, "seek": 408210, "start": 4082.1, "end": 4102.54, "text": " Until next time.", "tokens": [50364, 9088, 958, 565, 13, 51386], "temperature": 0.0, "avg_logprob": -0.5625003065381732, "compression_ratio": 0.6666666666666666, "no_speech_prob": 1.5904175597825088e-05}], "language": "en"}