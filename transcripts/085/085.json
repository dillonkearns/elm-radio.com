{"text": " Hello Jeroen. Hello Dillon. Well today I think it might be time to pull back the curtain a bit and expose some of our opaque types for our listeners. Oh no! No, we want to keep those things hidden! But they need to know how we got here. They need to know our supervillain backstories Jeroen and why we care so much about Elm. Alright, should we not say like supervillains that stay opaque? That's our superpower! Yeah, but like if you discover the villain, then he's not a villain anymore. He's just a troubled person with problems that he's trying to solve. Then we'll just be Batman. Okay, you be Batman and I'll be Robin. You could be Superman. We'll just reveal your kryptonite. Alright, that's fair. So I think it's fair to say Jeroen, we do care a lot about Elm. That might even be an understatement. Slight understatement. Yeah, probably. I think we've both invested a lot into Elm and really I feel a sense of wanting to invest in this community because I think at the core of it there's something I really believe in and I want to like fulfill this vision of this thing that I think is really important. So I thought it'd be cool to like get at that. What is that thing that's so important to us and like how did we get here? What made us care about this so much? Yeah, absolutely. So Dillon, why do you care? Well... What is your origin story? My origin, so I, my first job out of college was doing Ruby on Rails development and throughout college I was, you know, we learned, my first college class was in Python. Really? And that was quite a nice experience learning in Python. It felt very high level and it was great for being introduced to some like basic computing ideas. Then we started doing Java and C and C++ for the rest of my college courses. And you know, I have mixed feelings about Java. It's quite powerful, but, and the editor tooling is incredible. But when I discovered Ruby for this first programming job and Ruby on Rails, I did start to fall in love with the approach of like doing things in a way that felt like it did away with the formalities a little bit. And it said, let's model domain concepts. Let's come up with APIs that are DSLs, domain specific languages. Let's really think about the domain. Let's think about the domain terms. Let's speak in domain terms, not in lingo that's talking about an abstract factory instance. And you know, like Java does start to feel like you're bending over backwards to do things that aren't related to your domain. So I liked that about Ruby. I felt like, okay, I'm really spending a lot of time thinking about my domain. So that resonated. Then working with Ruby on Rails. Now I liked, I think I liked Ruby more than I liked Ruby on Rails. I know there's a lot to love about Ruby on Rails, but I found it extremely confusing to navigate because of all of the magic and all of the implicitness and the mocking, the mocking, Jeroen. Don't get him started on mocking. Have you worked with like code bases that do a lot of mocking in their test suites? I think so. Yeah. It's been a while, but yeah, I think so. Well, I know so, Jeroen. I know that I've done it because I remember it because I really did not like it. Like, I don't know. I still feel the blood on my hands. I think, I don't know, maybe that is a part of my, maybe that's my radioactive spider that bit me or something. I don't know, but I really don't like mocking in tests because it just feels like there's something so horribly wrong. If this is what we're doing, then we need to throw everything away and rethink it. Wait a second. You've been bitten by mocking, right? So now you gain the ability to mock mocking. Exactly. And now we just make fun of it all the time. That's right. Yes, I do. Superpower. Absolutely. Mock man. I would like to, I'd like to make a mockery out of mocking and gosh, because it just feels like you're, you don't, you don't know anymore what you're testing, you know, because any, you can't trust anything that you're looking at. So that was, that was my experience with Ruby on Rails. I'm looking at some code and I'm like, okay, what, what things are happening to get here? Like what global variables are there? What, what code is mixed into this module? So like, this is like a class that I'm defining, but does something monkey patch it later? Or is there a module that gets mixed into it later that changes the behavior or override something? Is it calling some methods that depend on implicit context and depend on some, some state that it's changing? Does it pass in an argument somewhere and that gets mutated somewhere? And that's like a very real thing that happened when I was debugging things and trying to figure out what went wrong. And so like, and then you go to fix it. And I, and I loved like writing tests to wrap my head around what was working. And when I was writing unit tests, I'm like, oh yes, this, like, this makes sense. I can like understand what this is doing. And then you start doing controller level tests, integration tests, and everything is mocked and you're like, wait a minute now, like now there's all this magic in the code itself. And now I've added this, like, I don't know what I'm actually testing. I don't know what's real and what's fake in the test. So I was very disillusioned by that, but I didn't, I didn't know it at the time. I didn't know I was disillusioned at the time because that I'm like, well, I guess like this is programming. This is like, this is what you do. And I didn't know there were alternatives to that. This is my life now for the next 40 years or however long. Exactly. So I had had a little bit of a seed planted because when I was doing Ruby on Rails, I discovered the enumerable mixin, which is something you can use on data structures that are enumerable like arrays to, to filter them and map them and inject fold L sort of thing. Wait, was inject fold L? I can't even, I honestly can't even remember now. Sounds like a weird name for fold, but I think it might've been. And then there was compact. Compact was very cool. Compact is something I do all the time now in Elm, a filter map identity. Oh yeah. Removing all the nils in the case of Ruby from a, from a list. But but I fell in love with working in that way and I started to really, you know, instead of using the shovel operator to imperatively add things into an array as you iterate over it, it's a way to push things into a list. That's another thing about Ruby and Ruby on Rails. There's more than one way to do it. You know, my mind is a little bit stuck on the shovel operator. I'm trying to imagine what it would look like. It's a double carrot. I think it's two less than signs. Okay. Oh, so function composition in Elm, they call that shovel? They call it shovel because you're shoveling things into an array, I guess. Okay. So it's more about the use and what it looks like. Okay. I guess. I think so. But these are things that you, you need to know. And so much time was spent in code reviews, just talking about, you know, nitpicks of like, oh, you know, I really don't like the shovel operator. I prefer to do it this way. I prefer to do it, you know, with a list dot map, or I prefer to do it with a for loop, or I prefer to do it within each loop because those are all things you can do. I prefer to use unless. I prefer to use if. It's like, geez, let's just like have one way to do things that works nicely, you know, but. Let's configure this linter to make all those choices for us. Oh, right. Which linter should we use? Yeah, I prefer this linter. This was in the days before like auto formatters were in vogue also. So you know, that was a whole nother thing. But yeah, it felt like there was so much churn just figuring out how to express something. And at the same time, like, like, I wanted to just think about how do I model these domain concepts? And how do I understand what the heck is actually happening here? Like, how do I get a test around it to understand exactly what inputs lead to what outputs and what scenarios are interesting? How do I model the domain, interestingly, and how do I avoid like magic stuff? And so like enumerable started to feel like, OK, I like this way, but I felt a little bit out of place because I didn't feel like everybody was on the same page as me with like, some people could kind of get behind it, but it wasn't a widely held opinion that that was a cleaner way to do things. So I guess the thing after my Ruby on Rails days was I got into coaching, agile and technical coaching and that influenced me a lot in terms of the power of small steps, the power of being very deliberate. And I was coaching teams, I was coaching a team using AngularJS. And there were so many, so many challenges working with that code base, you know, making it testable and, you know, bugs would pop up and Angular just, you know, this is Angular 1, AngularJS. And it was, again, there were a lot of ways you could do things. There were a lot of foot guns. There was, you know, you could mutate the DOM. You're definitely not supposed to. There are like big warning signs that say, warning, don't use this, but it's here. And you find some random stack overflow post and you don't know what's broken. There's some subtle, like leaky abstraction that you need to fix and you don't know what's going wrong to fix it. And so a stack overflow post tells you to mutate the DOM and you do it. And not to mention, it just felt like very difficult to, to even just like, you know, I want to have this Angular dependency that I can use in this context. How do I even get it in there? And how do I know that it's working correctly? You know, it like automatically injects values based on the variable name. And you're like, is this even working? And if it breaks, how do I know? And at the same time, like I'm coaching this team on these technical practices and we're helping them do legacy code refactoring, do continuous delivery, getting push button deploys and doing trunk based development on it, all of these things. And it had real results. Like we were, we were shipping faster and more confidently, but there was so much work to get there. And I realized like the language choice plays a big role in your ability to do these practices. And when I discovered Elm, it was a breath of fresh air because suddenly all these things I was trying to coach, like let's avoid having our tests blow up on the first of the month because it depends on the specific date they're run. Let's make them deterministic. Like these are practices I was coaching teams on that, like I saw results in the code bases becoming more robust and teams spending less time churning on these fires and more time focusing on the domain and shipping things faster. But with Elm, I'm like, wow, like dependency injection is just the only way to do things because you can't depend on impure things. And testing is very straightforward and you have this fast feedback loop from the compiler telling you exactly what went wrong. Even back then, because I think you used Elm in 18? That was in the 18 days. Okay. Yeah. When the compiler was still slow, right? Well, when I say fast feedback, I mean, everything was kind of slow back then. So I wasn't really like noticing a speed difference between other things. Also, this wasn't like a, you know, several hundred thousand line code base. But when I say fast feedback loop, I mean, just more like compared to scratching your head at why isn't this Angular thing working and it not telling you and you literally spending a whole day trying to figure it out. And you're like, oh, of course it was here, some dumb little thing, but it doesn't tell you. So it really felt like a breath of fresh air. And it really felt like it addressed these things in my experience with Ruby that didn't sit right with me where mocking it's like, well, you can't mock. But more importantly, like you express the code in a way where you wouldn't need to mock because it's not coupled to all of these side effects and external systems. You inject that in. So you just test the behavior. You write something that isn't coupled to that. Right. So all of these like very subtle decoupling things that I was trying really hard to like coach teams on and teach them how to practice. It's like, well, in Elm, you don't really need to teach that. It's just like, I mean, in Elm, you just need to tell people, write tests. But if they write tests, then they're going to write them in that way and they're going to write their code in that way. So I think that's I think that's kind of my story. That's why I really believe in Elm because all these things like that, I felt like I didn't belong. I wasn't in the right place because I just wanted one way to do things. And also, I just like wanted these practices to be natural. It just made sense to me. Yeah, I totally see where you're coming from. The mock spider, radioactive mocks. Mock man. Well, Jeroen, what is your super villain backstory? Are you a super villain or are you a superhero? Who knows? The listeners can decide. Yeah. Please say I'm a good guy. Yeah, so where I come from is more from working as a developer. So my career started with CoffeeScript and JavaScript and then more and more JavaScript until I did some Elm. And I was pretty much always getting a little bit frustrated with all the problems that we were hitting, crashes that were happening that felt preventable. I started looking into ways that we can improve things by using the newest framework out there. I remember being very excited about AngularJS when I was still interning. I was excited by React when it was released, which is at a company where we're using AngularJS. And later on, I became excited by Elm for the same reason as well. I started playing with functional programming using Lodash, a specific version of Lodash, which is called Lodash-FP, which is all those, not standard, but all those extra functions like we have in basics extra and text extra that are done in FP style. So nothing is mutated. You always get a copy of things and the order of arguments is data last instead of data first. So that was quite different from regular Lodash, but I really enjoyed using that. That made things feel more easier to understand. And the Lodash, the FP stuff is using like curried JS style. So you were already into partial application and down that rabbit hole at that point. Yeah, in a way, yeah. So maybe I didn't use it all that much, I feel, in retrospect, but it did make my learning of Elm much easier. I didn't have as much trouble with learning Elm as plenty of others have done, probably because of that. Yeah, yeah, I think so. It's just like, well, it's the same things as Lodash, except you have less surprises. And yeah, and it worked well. So that felt very nice. And at the same time, I was playing with ESLint, writing a lot of ESLint rules. I wrote like 75 over the course of a year, because there were just so many problems that you could have in our code base and in JavaScript. So I wrote plenty for packages that were published, a few under my name, a few under other people's names, and a few that were custom to our code base at work. And I mean, 75 rules are a lot of rules. I don't think I've written that many for Elm Review in the four years that I've been working on it, or however long that was. So yeah, at some point, I discovered Elm. And I'm like, well, just first to play with Elm, I needed to try it out. And Elm is a front-end language to do web applications, but I had no real experience with making front-end applications. What I did have experience with, however, was writing Linter rules. So I decided, well, you know what, let's try to make a Linter, even a basic one. And I really liked the experience, mostly because of custom types, like just the fact that you can pattern match on AST nodes, and you know exactly what they contain and all the AST nodes that you can encounter. That felt like a breath of fresh air, because when I was running ESLint rules, oftentimes I didn't know which AST nodes I would hit, which one I would encounter. And then there were some properties that I thought would always be there that turned out to be optional. And when I relied on them not being optional, that crashed the whole ESLint application. And that didn't feel nice. So when I was playing with writing a Linter in Elm, I was like, well, the experience is much nicer. And I say that even while writing the Linter from scratch. So that was a lot more work. Right. And that was your first Elm project, right? That was my first Elm project. And at some point that became ElmReview. And that was at the beginning of 2017. So that's been a long time. Yeah, wow. Yeah, so then I didn't use Elm for a few years. Started doing it professionally at a company, and I really enjoyed it. There was one thing that was lacking. There's like, oh, well, there's plenty of problems in my code base that we can just fix by telling people, hey, look at the code you wrote. This is not how we should do things. And I'm like, well, if only we had a Linter that could write custom Linter rules. Well, you know the rest of the story. So yeah, my experience with Elm was like, there's a lot less things that you need to check with static analysis, because the compiler is already doing that, and the design of the language is already doing that. I actually made a blog post on Elmcraft, or an article on Elmcraft, describing all the rules for ESLint, the core rules that don't make sense in Elm, like that you don't need, or which ones do you still need? And like 86% or something like that were not needed, and therefore they're not in ElmReview either. And that's just like a staggering number. So yeah, these are the kinds of things that I really enjoyed with Elm. And over the course of my Elm career, or mostly working as a tooling developer, I've just come to appreciate how much potential Elm has. And it's a bit of a weird potential that you have, because you can say, oh well, JavaScript has plenty of potential, you can do plenty of amazing things, and that's true. Rust has plenty of potential, etc. All those languages have them. But Elm's case is a bit particular, because for instance, for JavaScript, you're like, oh, JavaScript is amazing, and once we have async await, or whatever new feature that was decided by a committee, it's going to be much more awesome, things are going to be much easier, and you're going to be able to create very cool products with it or very cool tooling. And the Elm way, the way that Elm has potential is not that way. It's not like, oh, we're waiting on features that a committee has decided or that Evan has decided. It's more like, well, we see a lot of innovation because people push what they can do with Elm. And I'm just always amazed by what people do. And it's usually just relying on the design of the language, which is like pure functions everywhere, immutable values everywhere. And just from those tiny facts, you can do so much. Like ElmReview, great tool, but it's great because it has a language that is very analyzable. And if a value doesn't appear anywhere, then you can just remove it. Easy as that. Lambdara, for instance, has like, well, we're just writing Elm code. And because Elm code is just plain data, we can just send them over the wire from the front end to the back end and back end to the front end, maybe with some additional limitations. But you can basically just write Elm and you have now an amazing experience writing front end and back end languages with hosting and backups and all that. And it's only because we're pushing on the things that Elm gives us, not because we're expecting new features to arrive to the language. And that's something that I haven't found anywhere else. So that's one of the reasons why I really care about Elm, is I just see so much potential and it's not even like because I see it, like I can think of it. It's like I know that people will make more things because they just keep happening. Yeah, right. That resonates with me a lot too. Like because, yeah, as you say, it's not just like what got you in the door, but then what makes you see the long term vision that you want to be a part of? And I think we both are really invested in that. And it is, like you say, because I mean, you know, Elm Tailwind modules and Lambdaera and you know, Elm UI and all these like innovative approaches. I mean, Elm format, it just like it feels like there's also an ethos in the community of being willing to think things up from first principles. That's really cool. But thinking things up from first principles while also being very pragmatic and user focused. And I think that's pretty remarkable. Yeah, Elm's design has a lot of things going for it, where we're able to mix a very simple language with very strong guarantees to get a lot of things out of it. So we have a simple language that is easy to teach. Like people always tell you, oh, there's a learning curve because it's different. But in practice, Elm is still a very simple language, especially for a functional one. It's teachable, it's analyzable for Elm review, for people reviewing the code. It's pretty fast. It's super maintainable because of pure functional features and immutable. And all of that, it goes well together. And you add to that, like all the things that you can get out of that. And it's just the result is just amazing, in my opinion. That's why I stay here, because I see some potential. I don't know what people will come up with. I'm very excited to see things. I see other languages, like for instance, Rust is an amazing choice for plenty of projects at the moment. And it's trying to improve the status quo compared to other languages or frameworks that are in the same space. So mostly about memory and performance, it's trying to be really good at that. And other languages do the same thing, like F sharp is an improvement over C sharp because of improvements. It's a different approach. And you've got other languages like Rescript or Reason, I still don't remember the name, Grain, Glean, they all try to improve the status quo, improve things compared to JavaScript, compared to other languages. But they never go as deep as Elm goes. Like it's always like, well, F sharp is, if you're a functional, it's a functional language, we're not going to go deep into purity. Glean is like, well, we're going to be pretty much just like Elm, but we have FFI with Erlang things. And you lose some of the guarantees that Elm has, or the Elm approach has. And I'm like, well, it's a shame because you lose so much by doing that. Yes. The difference between a, I mean, a 99% guarantee isn't a guarantee, right? And it just, it feels different. You know, not to say that it's not a valid approach with benefits to say, I want to make the set of trade-offs where I can do FFI with these other languages, or, you know, I want to just write in JavaScript, or I want to use Rescript and be able to directly call JavaScript and wrap things with their FFI wrappers. That's great. Like, that's a totally valid set of trade-offs. It's just a very different set of things that fall out of that compared to Elm. And I think you and I really find it a compelling vision when you say, let's make that drastic choice. And, you know, as you're saying, like, I think the thing about Elm, it's not, it's not about what Elm adds. It's about what Elm has removed. And it's removed these things that you, that give you guarantees. So now you can say, well, this is all I have. I have custom types and pure functions and immutable values. And that's, if that's all there is, then I can make so many assumptions and I can have so many guarantees and I can build such interesting tools to use that. I don't even know if I was like a tooling person before I got into Elm. Like I feel like Elm really changed that about me where it, I mean, in my coaching days, I really saw the power of good tools. And I realized that if you're really good at editor tools, it's not, it's not a fun toy. It is like a very powerful tool that transforms you as a developer. I think like, I think if you're able to navigate around refactoring tools and work, I find that so powerful, like working with guaranteed refactorings, which like if you're working with Java or Kotlin, it's like really powerful what you can do just working with like refactoring operations that you can trust. But the potential there in Elm is even greater because there are way fewer sharp edges that you can encounter. Well, as you say, Elm has removed a lot of features and in a way it has removed pretty much all the foot guns. It also has removed a lot of escape hatches because in some of the escape hatches, you have a gun. We are in, in the basement of America. I don't know. Plenty of guns everywhere. And as you say, like there are trade-offs to doing things in one language or another and making one tool in JavaScript is, might be much easier than writing in Elm or a similar language with those same limitations. But you don't get the same things in return. So in Elm, like I'm almost amazed that I forgot to say that, but like there are no errors. There are no crashes. Like, yeah, that's kind of the main things. So for instance, if you write things in Lambda or in Elm pages, your code will not crash. It will not have any errors. You could probably have a framework like Lambda or Elm pages for JavaScript or other languages like that, but you're not going to be able to prevent it from crashing. Or maybe it's possible, but you're going to have to do so much work on making that work. So you're going to have to add additional limitations to your language. So for instance, say like, well, you can use, it's just JavaScript, but don't use eval, don't use subclassing, don't use, I don't know, whatever feature doesn't work in this imaginary situation. Or you're going to just do a lot more analysis work. Like oh, please add all these ESLint plugins to make sure you're not falling into one of these traps or using these foot guns or all these things that you need to worry about. Like in Elm, it's just much simpler. That's the default approach. And then tooling authors, package authors in Elm have just this ethos of trying to make things type safe, which just improves the situation for Elm even more. Sometimes at the cost of a little bit more verbose API or things that are not as nice to use because you need to handle all possible cases. But in practice, like the result is really, really good. And you're just going to have a hard time having the same results in another language. At least when Elm is a good fit for your project, like not saying Elm is always a good fit. Like we're, but. Yeah, and obviously there is a trade off with convenience, you know, just being able to grab an off the shelf NPM package or, you know, React hook or component library, whatever it may be. You know, there's a trade off. And this is a choice that we all make when we're using Elm. And I mean, in a way, like I feel like you and I really want to do everything we can to make the ecosystem as compelling as we can to narrow the gap of those trade offs. Because like inherently, yes, there is a certain like there's people want convenience and Elm takes away convenience in a fundamental way that gives you something back that's very valuable. It gives you back the ability to reason about your code in a totally different way and the ability to have guarantees and trust your code in a very different way. But it takes away convenience and that's just a fundamental truth about the core trade offs that Elm makes. And some people are just not going to like that. Some people are not going to want to be constrained in that way. They're going to say, hey, you know what? Like I'm an adult. I want to be able to have a global variable if that's how I want to solve my problem. I want to be able to bypass the compiler checks and just use a type and not have to write a decoder for it and things like that. And that's a reasonable preference, but it's just a very different world. And but, you know, I mean, I think that working with Tailwind in Elm is super compelling. And like that's, you know, as we fill out the ecosystem with more of these things, we get closer to that vision, which it's not going to be. I don't think it's ever going to be as big as JavaScript. Right. It's just I think inherently like you take away people's convenience and fewer people will be attracted to that world. Yeah. But. But in some cases, like people are going to adopt it and they'll be fine with it. Like all the functional tools that we have in Elm, like map and filter and reduce and whatever. Well, we can see those in popping up in all other languages, anonymous functions as well. Right. So people are getting used to some of the features. And I would kind of say like Elm's some of Elm's features are like seatbelts. People hated them when they had to start using them. I'm guessing I was still too young back then. Yeah. Oh, yeah. But now everyone has them. And I don't think a lot of people will just say, well, this is for nothing. Like this is useless. People know it's going to be helpful. Some people will still decide to take them off or not to put them on. And well, it's going to be very scary for them. Should anything happen, you lose some guarantees. Yeah. And yeah, sometimes the tradeoffs are very much in favor of one design or compared to another seatbelts. It's not a lot of a lot of constraints, but it adds a lot of guarantee about like helping you survive a crash. So it's definitely worth the effort and not worth encountering the risk. And I'd say in Elm, like there's just so many things that handling all cases, handling that something is null or nothing, it's worth it. It's not always practical, but yeah, it's a very compelling story. I mean, it is interesting. Like I think TypeScript has shown that like, I think that 99% guarantees are in a lot of people's minds. Fine. Right. And, and that's okay. But a lot of people calling JSON dot parse and it returning in any type, it's like, yeah, that's fine. You know, or maybe they're like, well, I'll use Zod or IOTS and do a decoder style thing. And be really careful about not introducing any types, but some people are like a lot of people see TypeScript more as a developer tool and a productivity tool and an auto-completion tool rather than something that prevents crashes in their system and something, I mean, you know, prevent some, but it doesn't prevent all and people, people aren't expecting it to and they're okay with that. But yeah, when we can have an ecosystem built around this, it just opens up these interesting possibilities, which we haven't really even scratched the surface of with editor tooling, refactoring tools. You know, I mean, Elm Review has like filled a lot of this gap, but Elm Review still has so much more that it could do, I'm sure. Right. So like, we're really just scratching the surface of what we can do with this. Not to mention that, you know, as you talked about, like the thoughtfulness of the API design that we see is really humbling. And I mean, I love being a part of this community for that reason. Like it's just like people really put a lot of care into the domain and they really think through like they put so much care into that user's experience. Like what is it going to be like using this package and what things could go wrong and what things can I make so the user doesn't have to ever think about going wrong because I can prevent it entirely. And what things can I model that can go wrong because I can't avoid it, but I can make it explicit and nice to work with and make those choices. So and as we talked about in our documentation episode, the Elm package docs are a big part of that. And I mean, navigating documentation back when I was doing Ruby on Rails development and JavaScript development, you know, sometimes tough, like finding what you were looking for and like, what, what can I, what can I call? Because there's meta programming and things are, you know, except different types of values, you know, except an object or null or undefined and have different behavior based on what you pass in. So it's very, very pleasant to work with Elm APIs and very easy to navigate. And it's just so, yeah, like I think, and in general, like I think I really at my core believe in this idea of working with pure functions as, as the basis of what we're writing and building out all of these things around them. Again, like the mocks, right? Like if you're a mock man, it's just like, it solves that problem by inverting things. If you can't do non-deterministic things, if you can't mutate state and perform side effects and do non-deterministic outputs from, from within your code, you can only do it from outside of your code. You can only pass it in from outside of your code as a dependency. You've inverted that as a language feature, which is amazing. And I can't understate the value of that to me, having that as not a guideline and a principle and a best practice, but as a part of the language is very powerful. And so I just deeply believe in that. I also believe in that not just for my beliefs about like best practices for coding you know, taking small steps and making things testable and all these sorts of things, but also for frameworks. Like I believe that it's a very good way to target things as a framework author to, to just neatly define like, here's the interface for this thing. And I, as the framework, I'm going to be the interface between you and the outside world, but I'm going to clearly define the contract. Choose your contract of what you can ask me to do, and I'll go do the dirty stuff in the outside world that performs side effects and does impure things. So building Elm pages, that's been something I've really started to believe more deeply as well is that Elm is actually a very powerful tool for, as a target for framework authors. And I, well, actually the day that we're recording this is the day after I released Elm Pages V3. And I hope that there will be more big framework releases like this to come in the Elm ecosystem, because I think it's a very promising part of the Elm language. And I hope it's for the maintainer because it's been a lot of work. It has. Yeah. Very true. Yeah, I think we could do with maybe a suite of tools to empower framework authors. I'm not sure if that would be at the compiler level or a set of meta tools, but whatever it is, yeah, we could definitely empower. And in general, I think, I mean, I think that's what I most wish for the Elm ecosystem is that we could empower authors of tools to do more, like having more access to type information and things like that. Like if we have that, I feel like so many powerful tools would come out of that. Yeah. See, you're not even asking for new features in the language. Right, exactly. You just want the things that we have to be even easier to access to make even better tools or better frameworks or better packages. Yes, exactly. Because there's so much rich information that the compiler has. And when you pair that together with the guarantees that the language gives you, the tooling possibilities are endless. But if we had an easier way to make use of those and didn't have to reinvent the wheel every time as tooling authors, I think it would enable a lot of innovation. And that's like, I think that's really what Elm needs to blossom. Like you said, it's not, it's not so much new, like there aren't that many language features that Elm really needs, maybe a handful of small improvements, but nothing, nothing massive. There's like, that's not the main thing it needs. I do feel like we're both on the, of the opinion, like what Elm is missing is more tools. At least that was what we said. And I'm sure that if we, if other people talked about the same topic in Elm, like more regular users of Elm, just people who write Elm to do their day job, then they would have a very different reply to this or different opinion of this. At least I don't think they would focus on tooling as much. Yeah. In practice, I think most people, they want better tools and for people in the JavaScript world, for instance, that often comes, that often comes from new language features or new framework or new build tools or whatever. So yeah, also tooling, but also sometimes new language features. Yeah. I mean, we, we would definitely benefit a lot from a larger ecosystem. You know, I mean, it would be great to, if you want to use a particular, you know, view, view library, it would be great if there were some no brainer choices for doing material UI or Ant design or whatever it is in Elm. That would definitely be a huge boon for, for the Elm community, I think. Another reason why I care about Elm is just, I find it fun. It's like just working on, no, not even working on Elm things. It's like working with Elm. I'm for instance, super happy that I've built Elm review in Elm, at least mostly in Elm. The Elm parts are the more, the most fun ones and just the, yeah, the, the sheer simplicity of refactoring and adding new features and making sure you don't have to, not having to think about all the edge cases because the compiler will remind you about those. It's just feels so nice. It's just very enjoyable, very relaxing compared to when I work on Elm review, but on the CLI part, which is in parts written in JavaScript. Now with a slightly bit TypeScript or JavaScript with JS doc and it's not a fun. Yeah, I feel the same way. And I definitely make the sacrifice of writing JavaScript and TypeScript to build these meta frameworks to make it nicer to work in the Elm ecosystem. But then once I can move away from that and just say, okay, I built all this infrastructure. Now let me sit down and write an Elm pages script, you know, or let me write a route module in my Elm pages app. Like yeah, I feel so happy just having that explicitness and the Elm compiler to help me. And again, like not having to wonder, does this throw an exception? Does, does this change some state somewhere, you know, or should this use the shovel operator or a map or a for loop or an each loop, you know, or it just see like, it really does feel like there's, there's almost one way to express a lot of Elm code. Of course it's not literally one way, but it, it, it feels like you write Elm and it, you don't have to think about all these details. You think about what is the problem I'm solving and, and you can refactor your code. It's fun to refactor your code. It's not scary. And like, well, here we go. Probably going to break a bunch of stuff. And if you, if you write tests with Elm, it's even easier to, to refactor your Elm code. And it's very easy to write tests in Elm. It's so nice to write tests in Elm. And the kinds of tools that we see, like Martin Stewart wrote Lambdaera program tests, which I'm absolutely amazed by just emulating. So similar to Elm program tests, where you have something that, that emulates a browser, letting you click on something in an Elm view and navigate around an Elm application and make assertions about what the view shows. Lambdaera program test builds upon that, but it lets you simulate multiple connected clients interacting with an actual Lambdaera backend and actually executing that backend code. And it's not mocking it. It's running the same code that's going to run in your backend in production and the same code that's going to run on your frontend in production. And you can trust it. And there is the browser emulation piece, but that's a pretty thin layer, you know, clicking on things and triggering on click events. So besides that, you know, that it's going to behave the exact same way, but it's as fast as a unit test because it's not spinning up a headless browser. And in the case of Lambdaera program tests, it's emulating multiple connected clients to like a real time backend framework. And you can actually view it stepping through it. It's just unreal. And the, and this was something that Martin Stewart was like hacking on something. He's like, Oh yeah, it'd be nice if I could like write a test for multiple connected clients to make sure I've got these race conditions ironed out. And it'd be nice if I could visualize the state of it. And he just kind of hacks it together and he's like, Oh yeah, it actually works out perfectly and it's really easy and elegant. And that's how it is. Like I feel like that's something inherent in Elm that things don't end up, you pull on the thread and it gets messier and messier and you, and it works really nicely until you start pulling on that thread and then it falls apart. In Elm I feel like you start pulling on that thread and it, it comes together even more cleanly because it's, there's an elegance and a simplicity to Elm itself. Yeah. It requires some work to, to, to remove all the hairy parts, but yeah, absolutely. It requires a lot of work, but you're like, the potential is there to build amazing tools that like don't have these caveats and these messy edges. If you're willing to put in that work as a tooling author. Yeah. I'm thinking of Cypress for instance, where Cypress is a testing framework where you can emulate your browser and it actually runs a browser and it's super powerful, but everywhere in its docs it says things like, don't do this or don't do things this way. And whenever you go to another test, then we just start from scratch. It's like kind of the same experience that you just said, like you, you pull on a thread and the result is nice, but at some point if things get hairy and in the case of Cypress, because it's JavaScript, it's playing with a browser, which is complicated in practice. Well, they don't put out something nice. They just say, okay, well not start from here. You should not do this. You should not do that. And the result is not as nice and you don't get the same results. Like it's slower, well for good reasons potentially, but it can crash. It can crash in weird ways. I might be a little bit biased, but you get what I mean. Yeah. I mean, you know, I think that's what we get for the price of Elm, the price of writing pure functions, which is a limitation that we take on. And that's what we get from that, right? So really interesting things emerge from that. But that's why tooling is so important in Elm, because we paid that price. So give us our money's worth by giving us amazing tools and dedicating your life to building really cool tools, tooling authors. So that's why we do it. I will dedicate my life to make these awesome tools that rely on the purity and functional and blah, blah, blah. Okay. So that's not my villain story. That's my priesthood story or something. Maybe it's a curse. I don't know what it is, but here we are. You talked earlier about people who do TypeScript and they're happy with the new guarantees that they gain from TypeScript compared to JavaScript. And I mean, it was a lot of work to convince those people to use TypeScript for good reason, because it has a lot of complexity still and a lot of build steps and all that. And some people got convinced and some people are now very, very happy with it. And TypeScript is now pretty much the standard, even compared to JavaScript, at least in the circles that I... Sometimes you just don't know how bad you have it, right? Like the people who did JavaScript and not TypeScript, they didn't know how good it was to have types. We often say that they've been bitten by Java and they're pretty lousy type system. And that might be true. But yeah, if you go to Reason or to Elm or to F Sharp, the types are really nice. And I would say from TypeScript compared to Elm, you now have a type checker, which works well. It doesn't use the same technology or the same idea behind it. So the TypeScript one is not as reliable. Like something that is still missing is side effect tracking. And I don't think the TypeScript people know how bad they have it, that they have to handle all those side effects. Yeah, right. Every time I go to the Netherlands, I'm just always amazed by something that is very simple and that is traffic lights. Have you ever been to the Netherlands? No, I'd like to go. Okay, well, the road infrastructure is very nice because you've got bikes everywhere. You get a separated bike lane and a separate pedestrian lane on top of the normal roads. And the traffic lights are just amazing. Like for instance, if you're in a car and you go to a crossroad, so we've got traffic lights everywhere stopping people. And if you're the only one who's driving through that. So for instance, if you're driving in the middle of the night, then the traffic light will be red. And once you arrive at this traffic light, it will go green and you can just go now because the traffic light knows there's no one around. And every time I go there, I'm like, ah, this is so amazing. And then I go back to France and I get to a traffic light that is red and I look everywhere and there's no one in sight. No pedestrian, no bike lanes. Oh, well, there are no bike lanes and no other cars. I'm like, why am I waiting? And just being able to have a green light right away would improve traffic for sure because people don't stop for nothing. You don't have a large lane of cars just waiting for this red light. And the people, at least in France, I don't think they know how bad they have it because they haven't seen, they haven't been to the Netherlands. When they have, they go there for bad reasons like French tourists. Right, right. And yeah, I think for typescript, it's the same. Like if you go to Elm, you won't have the same type system. It will be a much nicer one. Limiting, potentially, but much nicer. Side effects, not an issue, but you don't know how bad you have it when you have that. So trade-offs everywhere, but sometimes the results are very, very nice. And I think it would be nice for people to try out those things. And by the way, go to the Netherlands. It's a nice place. Yes, I definitely will. Yeah. But don't take the plane too much. Yeah. Yeah. Yeah. I mean, it's definitely, you kind of buy into a way of working and thinking. And I find it really interesting. My time as a coach, doing my coaching work really influenced me on this as well, of how much somebody's mental model of something can influence the way they interpret what's going on. So for example, like a lot of my coaching work, I was trying to get teams not being blocked by things, not being blocked by needing things from other teams, but being empowered to work on things on their own and being able to ship things all within one team and being able to deploy something with the push of a button. But if you're perceiving things as being more efficient by another team working on something, then you're going to interpret the pain points around that in a different light. Whereas if you perceive the pain of fitting pieces together, where two different teams built something and now you go to integrate those two pieces and they don't work, or these two systems don't understand each other, or they have a very heavy handed contract with each other because it's not people operating within the same context, or you're going to ship something and you have five months of work that you're going to spend one month testing. You're going to perceive that very differently if you have a mental model that says, well, let's be efficient with our testing. We have to manually test this, so let's be efficient by batching everything up. We don't want to ship something today and then have to go test the whole app. That would be inefficient. Well, if that's your mental model of things, then it is going to look inefficient. But if you have a different mental model, then you look at it as the more we batch things up, the more that can break at once. And the more we've lost context from the thing that we've worked on to know what we're looking for. And the less we've automated testing things and the less confident we can be about our deploy process and the less we automate our deploy. So looking at it through different lenses totally transforms the way that you see it. I think it's the same with looking at the tradeoffs of Elm versus TypeScript. If you're looking at it as the value of guarantees versus the inconvenience of having to pass through side effects explicitly, not being able to trigger them from anywhere, the hindrance that that causes you, you're going to perceive it very differently. And I think some people just have a different mental model and a different preference fundamentally. And I think that's fine. But for those who, I mean, my bottom line is if you make a set of tradeoffs, then cash in the good things from those tradeoffs. You've paid the cost of making the sacrifices of the cons of that tradeoff. So get all the pros from that tradeoff that you can. And right. But you need to know which tradeoffs you made. If you only know JavaScript, what are the tradeoffs of JavaScript compared to other things? Like where does it shine? Absolutely. Absolutely. Yes. And I mean, I think, I mean, I've heard a lot of people say that try Elm out, you'll learn something even if you end up not using it in your production stack. So I definitely think it's a good learning experience for people to try it out regardless of whether they end up using it. It's interesting because when you say, tell people how to write good code, it's usually like stay simple, write good names and just use simple functions. Right. That in practice, that's what it boils down to. Like keep codes very simple. Kiss. Keep it stupid, simple, silly, simple, silly. Okay. Is that stupid? Usually people say keep it simple, stupid. I was just being silly. Well, I mean, it's maybe a less offensive one. Yeah. Not the one that I had heard at least. I mean, in practice, like if you want to go towards better and simple code, you go to words code that it looks like Elm and Elm just makes that the default. Yes. Also like the only thing you can do. So we might feel like a limitation, but in practice, like, yeah, it's just good code because that's what good code tends to words. Yeah. I mean, I definitely am convinced personally, my, like all of the things that I've learned about what makes a code base maintainable are very aligned with Elm and happen very naturally with Elm. Making code traceable, you know, decoupling things, inversion of control, all these types of practices. It's very natural with Elm. Also like it's hard to imagine with how core parse don't validate and these types of principles make impossible states impossible are to how I think about writing good code and fixing bugs and keeping them fixed. I don't think I could go back. I don't know, I don't know how I would write code without tools in my tool belt that make it really easy to do that. And when I, when I'm writing TypeScript personally, I honestly don't do that much of things like parse don't validate and make impossible states impossible. It's just cumbersome and I don't really get the full guarantee. So it feels like, why am I bending over backwards to make discriminated unions that like, I can't really trust. It feels like it's going against the grain of how the whole ecosystem is working that I'm using. Yeah. On top of that, it's also like, there's this distraction or there's this temptation, this little devil telling you like, Oh, Hey, this could be much simpler if you just mutate this argument. Right. Like, and potentially for good reason, because also like can be more performance. Sure. But there's always this temptation to write code in a, not a nice way. That is, I just find distracting and sometimes I get tempted in practice to do that. And that's how my code turns out. And that will, or the might create problems, but you don't have that in Elm. And that feels just nice. Like it's not an option. Stop thinking about it. Just write the good code from the start. And if it's not great, then you can refactor it because refactoring is safe. Great. It feels good. Little angels everywhere. Yeah. Yeah. And it just, it really does feel like Elm takes it a step further, you know, like something like Haskell or pure script. Like I've never felt that drawn to, to some of these other languages, because again, there's just like Elm really makes this hard choice of like not having escape patches and having pure functions and exhaustive case checks and all these things that are, it's just like airtight at the core. Like all of its core decisions are made around being airtight and then having pragmatic APIs that are focused, like making, you know, which maybe somebody who's really big into Haskell would say, well, yeah, but you're missing out on the power of a lot of things that type systems can provide to you. And you're missing out on some of the ease that you have from things like type classes and stuff. And there, there are definitely trade-offs there. There are definitely valuable things that come from that. But Elm, it goes all in on saying no escape patches. It's an airtight system that you can completely trace and understand pure functions all the way, and let's be pragmatic and talk about things in more domain terms than category theory terms or things like that. And to me, that just really resonates like that, that that's my love language, just like speaking in domain language and simple, understandable, traceable code that you know exactly what it does and its pure functions. Like it just works for me at the core. And Elm does that in a way that I think is very unique. And I think I definitely am keen to see what Richard Feldman's project Rock does. I think that like he is kind of bringing a similar ethos to a different context and more, you know, more of a sort of the types of things you would do with Rust back end, more performance focused projects. But I think he's bringing a similar ethos there that I'm very keen to see what he does with. I think that will pull up my heartstrings as well. Yeah, I'm looking forward to playing with it more as well. And I really hope they don't make any choices that go counter to what we like about Elm, the large parts. From everything I've seen so far, it has. Yeah. But yeah, I agree. Yeah, we kind of mentioned like it's about pushing Elm to its limits. But as a tooling author, it's also just simply intellectually fun to see how far you can push it. For instance, I had a lot of fun making pull requests to Elm Optimize Level 2. Yeah, to make things even faster, but relying on the fact that it's Elm codes that I'm optimizing. Right, right. Yes. You can do isomorphic things with Elm code because if it can give you the same result and it's pure, so it's so easy to swap it out for something else that does the same thing, then you can do whatever dirty tricks you want. Yeah, yeah, exactly. Yeah, also like Tail Recursion module concept I worked on that I made blog posts about, because it's still Elm, but now the compiler can change the resulting source code, the resulting JavaScript in a way that is more optimized. And that would unlock some ways of running Elm code that are currently like not stack safe or something. That would be amazing. Is that a feature for the language or is it just like optimization? That's a good question. Stack safety is a feature. Yeah, it's borderline. It's still Elm, but... I mean, put it this way, if Elm didn't have tail call optimization, then certain use cases wouldn't be possible. And being able to make a guarantee about that is definitely compelling. So yeah, I think in conclusion, like Elm is just such a nice bundle of features that are put together in a very nice and polished way. The fact that it doesn't crash, the fact that its language is super simple and teachable, compared to Haskell for instance, the fact that the resulting code is good code and maintainable code and that you can have tools around it that are just so powerful that just make so much good use of all the guarantees that the language gives you and the compiler gives you. And I'm sure I'm forgetting more things, but it's just such a dense, small, little language that is with so much good in it. It's just super enjoyable. And a community of inspiring people who believe in that stuff too, which is really cool, you know, and who pull up their sleeves and try to build cool things with it. Yeah, I really like the ethos of the community, like everyone trying to make good stuff. Yeah, and just the quality of the average Elm package is pretty impressive. Yeah, so that's why we care about Elm. Well, this was a fun trip down memory lane. And perhaps you're a superhero trying to build cool static analysis and I'm a super villain trying to destroy all mocking in the universe. Mock man! I'm one step closer. Well Jeroen, until next time. Until next time.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.0, "text": " Hello Jeroen.", "tokens": [2425, 508, 2032, 268, 13], "temperature": 0.0, "avg_logprob": -0.3734787449692235, "compression_ratio": 1.5, "no_speech_prob": 0.07576096057891846}, {"id": 1, "seek": 0, "start": 2.0, "end": 3.0, "text": " Hello Dillon.", "tokens": [2425, 28160, 13], "temperature": 0.0, "avg_logprob": -0.3734787449692235, "compression_ratio": 1.5, "no_speech_prob": 0.07576096057891846}, {"id": 2, "seek": 0, "start": 3.0, "end": 8.16, "text": " Well today I think it might be time to pull back the curtain a bit and expose some of", "tokens": [1042, 965, 286, 519, 309, 1062, 312, 565, 281, 2235, 646, 264, 26789, 257, 857, 293, 19219, 512, 295], "temperature": 0.0, "avg_logprob": -0.3734787449692235, "compression_ratio": 1.5, "no_speech_prob": 0.07576096057891846}, {"id": 3, "seek": 0, "start": 8.16, "end": 10.6, "text": " our opaque types for our listeners.", "tokens": [527, 42687, 3467, 337, 527, 23274, 13], "temperature": 0.0, "avg_logprob": -0.3734787449692235, "compression_ratio": 1.5, "no_speech_prob": 0.07576096057891846}, {"id": 4, "seek": 0, "start": 10.6, "end": 11.6, "text": " Oh no!", "tokens": [876, 572, 0], "temperature": 0.0, "avg_logprob": -0.3734787449692235, "compression_ratio": 1.5, "no_speech_prob": 0.07576096057891846}, {"id": 5, "seek": 0, "start": 11.6, "end": 16.240000000000002, "text": " No, we want to keep those things hidden!", "tokens": [883, 11, 321, 528, 281, 1066, 729, 721, 7633, 0], "temperature": 0.0, "avg_logprob": -0.3734787449692235, "compression_ratio": 1.5, "no_speech_prob": 0.07576096057891846}, {"id": 6, "seek": 0, "start": 16.240000000000002, "end": 17.72, "text": " But they need to know how we got here.", "tokens": [583, 436, 643, 281, 458, 577, 321, 658, 510, 13], "temperature": 0.0, "avg_logprob": -0.3734787449692235, "compression_ratio": 1.5, "no_speech_prob": 0.07576096057891846}, {"id": 7, "seek": 0, "start": 17.72, "end": 23.88, "text": " They need to know our supervillain backstories Jeroen and why we care so much about Elm.", "tokens": [814, 643, 281, 458, 527, 37971, 373, 491, 646, 372, 2083, 508, 2032, 268, 293, 983, 321, 1127, 370, 709, 466, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.3734787449692235, "compression_ratio": 1.5, "no_speech_prob": 0.07576096057891846}, {"id": 8, "seek": 2388, "start": 23.88, "end": 30.919999999999998, "text": " Alright, should we not say like supervillains that stay opaque?", "tokens": [2798, 11, 820, 321, 406, 584, 411, 37971, 373, 2315, 300, 1754, 42687, 30], "temperature": 0.0, "avg_logprob": -0.3357709930056617, "compression_ratio": 1.4974874371859297, "no_speech_prob": 0.00021979145822115242}, {"id": 9, "seek": 2388, "start": 30.919999999999998, "end": 31.92, "text": " That's our superpower!", "tokens": [663, 311, 527, 45765, 0], "temperature": 0.0, "avg_logprob": -0.3357709930056617, "compression_ratio": 1.4974874371859297, "no_speech_prob": 0.00021979145822115242}, {"id": 10, "seek": 2388, "start": 31.92, "end": 38.12, "text": " Yeah, but like if you discover the villain, then he's not a villain anymore.", "tokens": [865, 11, 457, 411, 498, 291, 4411, 264, 17906, 11, 550, 415, 311, 406, 257, 17906, 3602, 13], "temperature": 0.0, "avg_logprob": -0.3357709930056617, "compression_ratio": 1.4974874371859297, "no_speech_prob": 0.00021979145822115242}, {"id": 11, "seek": 2388, "start": 38.12, "end": 43.8, "text": " He's just a troubled person with problems that he's trying to solve.", "tokens": [634, 311, 445, 257, 29402, 954, 365, 2740, 300, 415, 311, 1382, 281, 5039, 13], "temperature": 0.0, "avg_logprob": -0.3357709930056617, "compression_ratio": 1.4974874371859297, "no_speech_prob": 0.00021979145822115242}, {"id": 12, "seek": 2388, "start": 43.8, "end": 45.36, "text": " Then we'll just be Batman.", "tokens": [1396, 321, 603, 445, 312, 15432, 13], "temperature": 0.0, "avg_logprob": -0.3357709930056617, "compression_ratio": 1.4974874371859297, "no_speech_prob": 0.00021979145822115242}, {"id": 13, "seek": 2388, "start": 45.36, "end": 53.239999999999995, "text": " Okay, you be Batman and I'll be Robin.", "tokens": [1033, 11, 291, 312, 15432, 293, 286, 603, 312, 16533, 13], "temperature": 0.0, "avg_logprob": -0.3357709930056617, "compression_ratio": 1.4974874371859297, "no_speech_prob": 0.00021979145822115242}, {"id": 14, "seek": 5324, "start": 53.24, "end": 54.24, "text": " You could be Superman.", "tokens": [509, 727, 312, 22455, 13], "temperature": 0.0, "avg_logprob": -0.27927057670824457, "compression_ratio": 1.5048543689320388, "no_speech_prob": 1.2410173440002836e-05}, {"id": 15, "seek": 5324, "start": 54.24, "end": 56.24, "text": " We'll just reveal your kryptonite.", "tokens": [492, 603, 445, 10658, 428, 34847, 21987, 642, 13], "temperature": 0.0, "avg_logprob": -0.27927057670824457, "compression_ratio": 1.5048543689320388, "no_speech_prob": 1.2410173440002836e-05}, {"id": 16, "seek": 5324, "start": 56.24, "end": 58.160000000000004, "text": " Alright, that's fair.", "tokens": [2798, 11, 300, 311, 3143, 13], "temperature": 0.0, "avg_logprob": -0.27927057670824457, "compression_ratio": 1.5048543689320388, "no_speech_prob": 1.2410173440002836e-05}, {"id": 17, "seek": 5324, "start": 58.160000000000004, "end": 63.56, "text": " So I think it's fair to say Jeroen, we do care a lot about Elm.", "tokens": [407, 286, 519, 309, 311, 3143, 281, 584, 508, 2032, 268, 11, 321, 360, 1127, 257, 688, 466, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.27927057670824457, "compression_ratio": 1.5048543689320388, "no_speech_prob": 1.2410173440002836e-05}, {"id": 18, "seek": 5324, "start": 63.56, "end": 65.76, "text": " That might even be an understatement.", "tokens": [663, 1062, 754, 312, 364, 833, 19435, 1712, 13], "temperature": 0.0, "avg_logprob": -0.27927057670824457, "compression_ratio": 1.5048543689320388, "no_speech_prob": 1.2410173440002836e-05}, {"id": 19, "seek": 5324, "start": 65.76, "end": 66.76, "text": " Slight understatement.", "tokens": [318, 2764, 833, 19435, 1712, 13], "temperature": 0.0, "avg_logprob": -0.27927057670824457, "compression_ratio": 1.5048543689320388, "no_speech_prob": 1.2410173440002836e-05}, {"id": 20, "seek": 5324, "start": 66.76, "end": 70.24000000000001, "text": " Yeah, probably.", "tokens": [865, 11, 1391, 13], "temperature": 0.0, "avg_logprob": -0.27927057670824457, "compression_ratio": 1.5048543689320388, "no_speech_prob": 1.2410173440002836e-05}, {"id": 21, "seek": 5324, "start": 70.24000000000001, "end": 79.52000000000001, "text": " I think we've both invested a lot into Elm and really I feel a sense of wanting to invest", "tokens": [286, 519, 321, 600, 1293, 13104, 257, 688, 666, 2699, 76, 293, 534, 286, 841, 257, 2020, 295, 7935, 281, 1963], "temperature": 0.0, "avg_logprob": -0.27927057670824457, "compression_ratio": 1.5048543689320388, "no_speech_prob": 1.2410173440002836e-05}, {"id": 22, "seek": 7952, "start": 79.52, "end": 84.84, "text": " in this community because I think at the core of it there's something I really believe in", "tokens": [294, 341, 1768, 570, 286, 519, 412, 264, 4965, 295, 309, 456, 311, 746, 286, 534, 1697, 294], "temperature": 0.0, "avg_logprob": -0.25802449522347287, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.362428429274587e-05}, {"id": 23, "seek": 7952, "start": 84.84, "end": 91.24, "text": " and I want to like fulfill this vision of this thing that I think is really important.", "tokens": [293, 286, 528, 281, 411, 13875, 341, 5201, 295, 341, 551, 300, 286, 519, 307, 534, 1021, 13], "temperature": 0.0, "avg_logprob": -0.25802449522347287, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.362428429274587e-05}, {"id": 24, "seek": 7952, "start": 91.24, "end": 93.75999999999999, "text": " So I thought it'd be cool to like get at that.", "tokens": [407, 286, 1194, 309, 1116, 312, 1627, 281, 411, 483, 412, 300, 13], "temperature": 0.0, "avg_logprob": -0.25802449522347287, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.362428429274587e-05}, {"id": 25, "seek": 7952, "start": 93.75999999999999, "end": 98.32, "text": " What is that thing that's so important to us and like how did we get here?", "tokens": [708, 307, 300, 551, 300, 311, 370, 1021, 281, 505, 293, 411, 577, 630, 321, 483, 510, 30], "temperature": 0.0, "avg_logprob": -0.25802449522347287, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.362428429274587e-05}, {"id": 26, "seek": 7952, "start": 98.32, "end": 100.24, "text": " What made us care about this so much?", "tokens": [708, 1027, 505, 1127, 466, 341, 370, 709, 30], "temperature": 0.0, "avg_logprob": -0.25802449522347287, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.362428429274587e-05}, {"id": 27, "seek": 7952, "start": 100.24, "end": 101.52, "text": " Yeah, absolutely.", "tokens": [865, 11, 3122, 13], "temperature": 0.0, "avg_logprob": -0.25802449522347287, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.362428429274587e-05}, {"id": 28, "seek": 7952, "start": 101.52, "end": 103.8, "text": " So Dillon, why do you care?", "tokens": [407, 28160, 11, 983, 360, 291, 1127, 30], "temperature": 0.0, "avg_logprob": -0.25802449522347287, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.362428429274587e-05}, {"id": 29, "seek": 7952, "start": 103.8, "end": 104.96, "text": " Well...", "tokens": [1042, 485], "temperature": 0.0, "avg_logprob": -0.25802449522347287, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.362428429274587e-05}, {"id": 30, "seek": 7952, "start": 104.96, "end": 107.03999999999999, "text": " What is your origin story?", "tokens": [708, 307, 428, 4957, 1657, 30], "temperature": 0.0, "avg_logprob": -0.25802449522347287, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.362428429274587e-05}, {"id": 31, "seek": 10704, "start": 107.04, "end": 114.0, "text": " My origin, so I, my first job out of college was doing Ruby on Rails development and throughout", "tokens": [1222, 4957, 11, 370, 286, 11, 452, 700, 1691, 484, 295, 3859, 390, 884, 19907, 322, 48526, 3250, 293, 3710], "temperature": 0.0, "avg_logprob": -0.2892053240821475, "compression_ratio": 1.5633802816901408, "no_speech_prob": 8.446012884633092e-07}, {"id": 32, "seek": 10704, "start": 114.0, "end": 120.4, "text": " college I was, you know, we learned, my first college class was in Python.", "tokens": [3859, 286, 390, 11, 291, 458, 11, 321, 3264, 11, 452, 700, 3859, 1508, 390, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.2892053240821475, "compression_ratio": 1.5633802816901408, "no_speech_prob": 8.446012884633092e-07}, {"id": 33, "seek": 10704, "start": 120.4, "end": 121.48, "text": " Really?", "tokens": [4083, 30], "temperature": 0.0, "avg_logprob": -0.2892053240821475, "compression_ratio": 1.5633802816901408, "no_speech_prob": 8.446012884633092e-07}, {"id": 34, "seek": 10704, "start": 121.48, "end": 125.04, "text": " And that was quite a nice experience learning in Python.", "tokens": [400, 300, 390, 1596, 257, 1481, 1752, 2539, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.2892053240821475, "compression_ratio": 1.5633802816901408, "no_speech_prob": 8.446012884633092e-07}, {"id": 35, "seek": 10704, "start": 125.04, "end": 130.56, "text": " It felt very high level and it was great for being introduced to some like basic computing", "tokens": [467, 2762, 588, 1090, 1496, 293, 309, 390, 869, 337, 885, 7268, 281, 512, 411, 3875, 15866], "temperature": 0.0, "avg_logprob": -0.2892053240821475, "compression_ratio": 1.5633802816901408, "no_speech_prob": 8.446012884633092e-07}, {"id": 36, "seek": 10704, "start": 130.56, "end": 132.16, "text": " ideas.", "tokens": [3487, 13], "temperature": 0.0, "avg_logprob": -0.2892053240821475, "compression_ratio": 1.5633802816901408, "no_speech_prob": 8.446012884633092e-07}, {"id": 37, "seek": 13216, "start": 132.16, "end": 138.32, "text": " Then we started doing Java and C and C++ for the rest of my college courses.", "tokens": [1396, 321, 1409, 884, 10745, 293, 383, 293, 383, 25472, 337, 264, 1472, 295, 452, 3859, 7712, 13], "temperature": 0.0, "avg_logprob": -0.24249184649923575, "compression_ratio": 1.5381355932203389, "no_speech_prob": 1.873838868959865e-06}, {"id": 38, "seek": 13216, "start": 138.32, "end": 141.8, "text": " And you know, I have mixed feelings about Java.", "tokens": [400, 291, 458, 11, 286, 362, 7467, 6640, 466, 10745, 13], "temperature": 0.0, "avg_logprob": -0.24249184649923575, "compression_ratio": 1.5381355932203389, "no_speech_prob": 1.873838868959865e-06}, {"id": 39, "seek": 13216, "start": 141.8, "end": 148.24, "text": " It's quite powerful, but, and the editor tooling is incredible.", "tokens": [467, 311, 1596, 4005, 11, 457, 11, 293, 264, 9839, 46593, 307, 4651, 13], "temperature": 0.0, "avg_logprob": -0.24249184649923575, "compression_ratio": 1.5381355932203389, "no_speech_prob": 1.873838868959865e-06}, {"id": 40, "seek": 13216, "start": 148.24, "end": 155.16, "text": " But when I discovered Ruby for this first programming job and Ruby on Rails, I did start", "tokens": [583, 562, 286, 6941, 19907, 337, 341, 700, 9410, 1691, 293, 19907, 322, 48526, 11, 286, 630, 722], "temperature": 0.0, "avg_logprob": -0.24249184649923575, "compression_ratio": 1.5381355932203389, "no_speech_prob": 1.873838868959865e-06}, {"id": 41, "seek": 13216, "start": 155.16, "end": 161.76, "text": " to fall in love with the approach of like doing things in a way that felt like it did", "tokens": [281, 2100, 294, 959, 365, 264, 3109, 295, 411, 884, 721, 294, 257, 636, 300, 2762, 411, 309, 630], "temperature": 0.0, "avg_logprob": -0.24249184649923575, "compression_ratio": 1.5381355932203389, "no_speech_prob": 1.873838868959865e-06}, {"id": 42, "seek": 16176, "start": 161.76, "end": 163.76, "text": " away with the formalities a little bit.", "tokens": [1314, 365, 264, 9860, 1088, 257, 707, 857, 13], "temperature": 0.0, "avg_logprob": -0.20729950239073555, "compression_ratio": 1.6833333333333333, "no_speech_prob": 1.0844614735106006e-06}, {"id": 43, "seek": 16176, "start": 163.76, "end": 166.67999999999998, "text": " And it said, let's model domain concepts.", "tokens": [400, 309, 848, 11, 718, 311, 2316, 9274, 10392, 13], "temperature": 0.0, "avg_logprob": -0.20729950239073555, "compression_ratio": 1.6833333333333333, "no_speech_prob": 1.0844614735106006e-06}, {"id": 44, "seek": 16176, "start": 166.67999999999998, "end": 171.48, "text": " Let's come up with APIs that are DSLs, domain specific languages.", "tokens": [961, 311, 808, 493, 365, 21445, 300, 366, 15816, 43, 82, 11, 9274, 2685, 8650, 13], "temperature": 0.0, "avg_logprob": -0.20729950239073555, "compression_ratio": 1.6833333333333333, "no_speech_prob": 1.0844614735106006e-06}, {"id": 45, "seek": 16176, "start": 171.48, "end": 173.66, "text": " Let's really think about the domain.", "tokens": [961, 311, 534, 519, 466, 264, 9274, 13], "temperature": 0.0, "avg_logprob": -0.20729950239073555, "compression_ratio": 1.6833333333333333, "no_speech_prob": 1.0844614735106006e-06}, {"id": 46, "seek": 16176, "start": 173.66, "end": 175.28, "text": " Let's think about the domain terms.", "tokens": [961, 311, 519, 466, 264, 9274, 2115, 13], "temperature": 0.0, "avg_logprob": -0.20729950239073555, "compression_ratio": 1.6833333333333333, "no_speech_prob": 1.0844614735106006e-06}, {"id": 47, "seek": 16176, "start": 175.28, "end": 182.64, "text": " Let's speak in domain terms, not in lingo that's talking about an abstract factory instance.", "tokens": [961, 311, 1710, 294, 9274, 2115, 11, 406, 294, 287, 18459, 300, 311, 1417, 466, 364, 12649, 9265, 5197, 13], "temperature": 0.0, "avg_logprob": -0.20729950239073555, "compression_ratio": 1.6833333333333333, "no_speech_prob": 1.0844614735106006e-06}, {"id": 48, "seek": 16176, "start": 182.64, "end": 191.45999999999998, "text": " And you know, like Java does start to feel like you're bending over backwards to do things", "tokens": [400, 291, 458, 11, 411, 10745, 775, 722, 281, 841, 411, 291, 434, 22487, 670, 12204, 281, 360, 721], "temperature": 0.0, "avg_logprob": -0.20729950239073555, "compression_ratio": 1.6833333333333333, "no_speech_prob": 1.0844614735106006e-06}, {"id": 49, "seek": 19146, "start": 191.46, "end": 193.6, "text": " that aren't related to your domain.", "tokens": [300, 3212, 380, 4077, 281, 428, 9274, 13], "temperature": 0.0, "avg_logprob": -0.21547629469532079, "compression_ratio": 1.7901234567901234, "no_speech_prob": 4.860152330365963e-06}, {"id": 50, "seek": 19146, "start": 193.6, "end": 194.68, "text": " So I liked that about Ruby.", "tokens": [407, 286, 4501, 300, 466, 19907, 13], "temperature": 0.0, "avg_logprob": -0.21547629469532079, "compression_ratio": 1.7901234567901234, "no_speech_prob": 4.860152330365963e-06}, {"id": 51, "seek": 19146, "start": 194.68, "end": 199.48000000000002, "text": " I felt like, okay, I'm really spending a lot of time thinking about my domain.", "tokens": [286, 2762, 411, 11, 1392, 11, 286, 478, 534, 6434, 257, 688, 295, 565, 1953, 466, 452, 9274, 13], "temperature": 0.0, "avg_logprob": -0.21547629469532079, "compression_ratio": 1.7901234567901234, "no_speech_prob": 4.860152330365963e-06}, {"id": 52, "seek": 19146, "start": 199.48000000000002, "end": 201.12, "text": " So that resonated.", "tokens": [407, 300, 47957, 13], "temperature": 0.0, "avg_logprob": -0.21547629469532079, "compression_ratio": 1.7901234567901234, "no_speech_prob": 4.860152330365963e-06}, {"id": 53, "seek": 19146, "start": 201.12, "end": 203.60000000000002, "text": " Then working with Ruby on Rails.", "tokens": [1396, 1364, 365, 19907, 322, 48526, 13], "temperature": 0.0, "avg_logprob": -0.21547629469532079, "compression_ratio": 1.7901234567901234, "no_speech_prob": 4.860152330365963e-06}, {"id": 54, "seek": 19146, "start": 203.60000000000002, "end": 207.88, "text": " Now I liked, I think I liked Ruby more than I liked Ruby on Rails.", "tokens": [823, 286, 4501, 11, 286, 519, 286, 4501, 19907, 544, 813, 286, 4501, 19907, 322, 48526, 13], "temperature": 0.0, "avg_logprob": -0.21547629469532079, "compression_ratio": 1.7901234567901234, "no_speech_prob": 4.860152330365963e-06}, {"id": 55, "seek": 19146, "start": 207.88, "end": 212.64000000000001, "text": " I know there's a lot to love about Ruby on Rails, but I found it extremely confusing", "tokens": [286, 458, 456, 311, 257, 688, 281, 959, 466, 19907, 322, 48526, 11, 457, 286, 1352, 309, 4664, 13181], "temperature": 0.0, "avg_logprob": -0.21547629469532079, "compression_ratio": 1.7901234567901234, "no_speech_prob": 4.860152330365963e-06}, {"id": 56, "seek": 19146, "start": 212.64000000000001, "end": 218.28, "text": " to navigate because of all of the magic and all of the implicitness and the mocking, the", "tokens": [281, 12350, 570, 295, 439, 295, 264, 5585, 293, 439, 295, 264, 10629, 6394, 293, 264, 49792, 11, 264], "temperature": 0.0, "avg_logprob": -0.21547629469532079, "compression_ratio": 1.7901234567901234, "no_speech_prob": 4.860152330365963e-06}, {"id": 57, "seek": 21828, "start": 218.28, "end": 221.92, "text": " mocking, Jeroen.", "tokens": [49792, 11, 508, 2032, 268, 13], "temperature": 0.0, "avg_logprob": -0.26323215901350777, "compression_ratio": 1.6136363636363635, "no_speech_prob": 4.936671302857576e-06}, {"id": 58, "seek": 21828, "start": 221.92, "end": 225.04, "text": " Don't get him started on mocking.", "tokens": [1468, 380, 483, 796, 1409, 322, 49792, 13], "temperature": 0.0, "avg_logprob": -0.26323215901350777, "compression_ratio": 1.6136363636363635, "no_speech_prob": 4.936671302857576e-06}, {"id": 59, "seek": 21828, "start": 225.04, "end": 231.56, "text": " Have you worked with like code bases that do a lot of mocking in their test suites?", "tokens": [3560, 291, 2732, 365, 411, 3089, 17949, 300, 360, 257, 688, 295, 49792, 294, 641, 1500, 459, 3324, 30], "temperature": 0.0, "avg_logprob": -0.26323215901350777, "compression_ratio": 1.6136363636363635, "no_speech_prob": 4.936671302857576e-06}, {"id": 60, "seek": 21828, "start": 231.56, "end": 232.56, "text": " I think so.", "tokens": [286, 519, 370, 13], "temperature": 0.0, "avg_logprob": -0.26323215901350777, "compression_ratio": 1.6136363636363635, "no_speech_prob": 4.936671302857576e-06}, {"id": 61, "seek": 21828, "start": 232.56, "end": 233.56, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.26323215901350777, "compression_ratio": 1.6136363636363635, "no_speech_prob": 4.936671302857576e-06}, {"id": 62, "seek": 21828, "start": 233.56, "end": 235.28, "text": " It's been a while, but yeah, I think so.", "tokens": [467, 311, 668, 257, 1339, 11, 457, 1338, 11, 286, 519, 370, 13], "temperature": 0.0, "avg_logprob": -0.26323215901350777, "compression_ratio": 1.6136363636363635, "no_speech_prob": 4.936671302857576e-06}, {"id": 63, "seek": 21828, "start": 235.28, "end": 236.92000000000002, "text": " Well, I know so, Jeroen.", "tokens": [1042, 11, 286, 458, 370, 11, 508, 2032, 268, 13], "temperature": 0.0, "avg_logprob": -0.26323215901350777, "compression_ratio": 1.6136363636363635, "no_speech_prob": 4.936671302857576e-06}, {"id": 64, "seek": 21828, "start": 236.92000000000002, "end": 241.84, "text": " I know that I've done it because I remember it because I really did not like it.", "tokens": [286, 458, 300, 286, 600, 1096, 309, 570, 286, 1604, 309, 570, 286, 534, 630, 406, 411, 309, 13], "temperature": 0.0, "avg_logprob": -0.26323215901350777, "compression_ratio": 1.6136363636363635, "no_speech_prob": 4.936671302857576e-06}, {"id": 65, "seek": 21828, "start": 241.84, "end": 242.84, "text": " Like, I don't know.", "tokens": [1743, 11, 286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.26323215901350777, "compression_ratio": 1.6136363636363635, "no_speech_prob": 4.936671302857576e-06}, {"id": 66, "seek": 21828, "start": 242.84, "end": 246.92000000000002, "text": " I still feel the blood on my hands.", "tokens": [286, 920, 841, 264, 3390, 322, 452, 2377, 13], "temperature": 0.0, "avg_logprob": -0.26323215901350777, "compression_ratio": 1.6136363636363635, "no_speech_prob": 4.936671302857576e-06}, {"id": 67, "seek": 24692, "start": 246.92, "end": 255.0, "text": " I think, I don't know, maybe that is a part of my, maybe that's my radioactive spider", "tokens": [286, 519, 11, 286, 500, 380, 458, 11, 1310, 300, 307, 257, 644, 295, 452, 11, 1310, 300, 311, 452, 35844, 17614], "temperature": 0.0, "avg_logprob": -0.21529279970655255, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.8158175407734234e-06}, {"id": 68, "seek": 24692, "start": 255.0, "end": 256.15999999999997, "text": " that bit me or something.", "tokens": [300, 857, 385, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.21529279970655255, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.8158175407734234e-06}, {"id": 69, "seek": 24692, "start": 256.15999999999997, "end": 263.68, "text": " I don't know, but I really don't like mocking in tests because it just feels like there's", "tokens": [286, 500, 380, 458, 11, 457, 286, 534, 500, 380, 411, 49792, 294, 6921, 570, 309, 445, 3417, 411, 456, 311], "temperature": 0.0, "avg_logprob": -0.21529279970655255, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.8158175407734234e-06}, {"id": 70, "seek": 24692, "start": 263.68, "end": 265.74, "text": " something so horribly wrong.", "tokens": [746, 370, 45028, 2085, 13], "temperature": 0.0, "avg_logprob": -0.21529279970655255, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.8158175407734234e-06}, {"id": 71, "seek": 24692, "start": 265.74, "end": 270.12, "text": " If this is what we're doing, then we need to throw everything away and rethink it.", "tokens": [759, 341, 307, 437, 321, 434, 884, 11, 550, 321, 643, 281, 3507, 1203, 1314, 293, 34595, 309, 13], "temperature": 0.0, "avg_logprob": -0.21529279970655255, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.8158175407734234e-06}, {"id": 72, "seek": 24692, "start": 270.12, "end": 271.24, "text": " Wait a second.", "tokens": [3802, 257, 1150, 13], "temperature": 0.0, "avg_logprob": -0.21529279970655255, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.8158175407734234e-06}, {"id": 73, "seek": 24692, "start": 271.24, "end": 274.71999999999997, "text": " You've been bitten by mocking, right?", "tokens": [509, 600, 668, 34608, 538, 49792, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.21529279970655255, "compression_ratio": 1.6266666666666667, "no_speech_prob": 1.8158175407734234e-06}, {"id": 74, "seek": 27472, "start": 274.72, "end": 277.56, "text": " So now you gain the ability to mock mocking.", "tokens": [407, 586, 291, 6052, 264, 3485, 281, 17362, 49792, 13], "temperature": 0.0, "avg_logprob": -0.28927141481691654, "compression_ratio": 1.5841121495327102, "no_speech_prob": 1.1910686907867785e-06}, {"id": 75, "seek": 27472, "start": 277.56, "end": 278.56, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.28927141481691654, "compression_ratio": 1.5841121495327102, "no_speech_prob": 1.1910686907867785e-06}, {"id": 76, "seek": 27472, "start": 278.56, "end": 281.24, "text": " And now we just make fun of it all the time.", "tokens": [400, 586, 321, 445, 652, 1019, 295, 309, 439, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.28927141481691654, "compression_ratio": 1.5841121495327102, "no_speech_prob": 1.1910686907867785e-06}, {"id": 77, "seek": 27472, "start": 281.24, "end": 282.24, "text": " That's right.", "tokens": [663, 311, 558, 13], "temperature": 0.0, "avg_logprob": -0.28927141481691654, "compression_ratio": 1.5841121495327102, "no_speech_prob": 1.1910686907867785e-06}, {"id": 78, "seek": 27472, "start": 282.24, "end": 283.24, "text": " Yes, I do.", "tokens": [1079, 11, 286, 360, 13], "temperature": 0.0, "avg_logprob": -0.28927141481691654, "compression_ratio": 1.5841121495327102, "no_speech_prob": 1.1910686907867785e-06}, {"id": 79, "seek": 27472, "start": 283.24, "end": 284.24, "text": " Superpower.", "tokens": [4548, 9513, 13], "temperature": 0.0, "avg_logprob": -0.28927141481691654, "compression_ratio": 1.5841121495327102, "no_speech_prob": 1.1910686907867785e-06}, {"id": 80, "seek": 27472, "start": 284.24, "end": 285.24, "text": " Absolutely.", "tokens": [7021, 13], "temperature": 0.0, "avg_logprob": -0.28927141481691654, "compression_ratio": 1.5841121495327102, "no_speech_prob": 1.1910686907867785e-06}, {"id": 81, "seek": 27472, "start": 285.24, "end": 286.24, "text": " Mock man.", "tokens": [376, 1560, 587, 13], "temperature": 0.0, "avg_logprob": -0.28927141481691654, "compression_ratio": 1.5841121495327102, "no_speech_prob": 1.1910686907867785e-06}, {"id": 82, "seek": 27472, "start": 286.24, "end": 295.32000000000005, "text": " I would like to, I'd like to make a mockery out of mocking and gosh, because it just feels", "tokens": [286, 576, 411, 281, 11, 286, 1116, 411, 281, 652, 257, 17362, 2109, 484, 295, 49792, 293, 6502, 11, 570, 309, 445, 3417], "temperature": 0.0, "avg_logprob": -0.28927141481691654, "compression_ratio": 1.5841121495327102, "no_speech_prob": 1.1910686907867785e-06}, {"id": 83, "seek": 27472, "start": 295.32000000000005, "end": 302.0, "text": " like you're, you don't, you don't know anymore what you're testing, you know, because any,", "tokens": [411, 291, 434, 11, 291, 500, 380, 11, 291, 500, 380, 458, 3602, 437, 291, 434, 4997, 11, 291, 458, 11, 570, 604, 11], "temperature": 0.0, "avg_logprob": -0.28927141481691654, "compression_ratio": 1.5841121495327102, "no_speech_prob": 1.1910686907867785e-06}, {"id": 84, "seek": 30200, "start": 302.0, "end": 305.2, "text": " you can't trust anything that you're looking at.", "tokens": [291, 393, 380, 3361, 1340, 300, 291, 434, 1237, 412, 13], "temperature": 0.0, "avg_logprob": -0.19312739763103548, "compression_ratio": 1.7651515151515151, "no_speech_prob": 8.851549750943377e-07}, {"id": 85, "seek": 30200, "start": 305.2, "end": 308.32, "text": " So that was, that was my experience with Ruby on Rails.", "tokens": [407, 300, 390, 11, 300, 390, 452, 1752, 365, 19907, 322, 48526, 13], "temperature": 0.0, "avg_logprob": -0.19312739763103548, "compression_ratio": 1.7651515151515151, "no_speech_prob": 8.851549750943377e-07}, {"id": 86, "seek": 30200, "start": 308.32, "end": 314.48, "text": " I'm looking at some code and I'm like, okay, what, what things are happening to get here?", "tokens": [286, 478, 1237, 412, 512, 3089, 293, 286, 478, 411, 11, 1392, 11, 437, 11, 437, 721, 366, 2737, 281, 483, 510, 30], "temperature": 0.0, "avg_logprob": -0.19312739763103548, "compression_ratio": 1.7651515151515151, "no_speech_prob": 8.851549750943377e-07}, {"id": 87, "seek": 30200, "start": 314.48, "end": 318.36, "text": " Like what global variables are there?", "tokens": [1743, 437, 4338, 9102, 366, 456, 30], "temperature": 0.0, "avg_logprob": -0.19312739763103548, "compression_ratio": 1.7651515151515151, "no_speech_prob": 8.851549750943377e-07}, {"id": 88, "seek": 30200, "start": 318.36, "end": 321.28, "text": " What, what code is mixed into this module?", "tokens": [708, 11, 437, 3089, 307, 7467, 666, 341, 10088, 30], "temperature": 0.0, "avg_logprob": -0.19312739763103548, "compression_ratio": 1.7651515151515151, "no_speech_prob": 8.851549750943377e-07}, {"id": 89, "seek": 30200, "start": 321.28, "end": 326.2, "text": " So like, this is like a class that I'm defining, but does something monkey patch it later?", "tokens": [407, 411, 11, 341, 307, 411, 257, 1508, 300, 286, 478, 17827, 11, 457, 775, 746, 17847, 9972, 309, 1780, 30], "temperature": 0.0, "avg_logprob": -0.19312739763103548, "compression_ratio": 1.7651515151515151, "no_speech_prob": 8.851549750943377e-07}, {"id": 90, "seek": 30200, "start": 326.2, "end": 330.44, "text": " Or is there a module that gets mixed into it later that changes the behavior or override", "tokens": [1610, 307, 456, 257, 10088, 300, 2170, 7467, 666, 309, 1780, 300, 2962, 264, 5223, 420, 42321], "temperature": 0.0, "avg_logprob": -0.19312739763103548, "compression_ratio": 1.7651515151515151, "no_speech_prob": 8.851549750943377e-07}, {"id": 91, "seek": 30200, "start": 330.44, "end": 331.44, "text": " something?", "tokens": [746, 30], "temperature": 0.0, "avg_logprob": -0.19312739763103548, "compression_ratio": 1.7651515151515151, "no_speech_prob": 8.851549750943377e-07}, {"id": 92, "seek": 33144, "start": 331.44, "end": 339.08, "text": " Is it calling some methods that depend on implicit context and depend on some, some", "tokens": [1119, 309, 5141, 512, 7150, 300, 5672, 322, 26947, 4319, 293, 5672, 322, 512, 11, 512], "temperature": 0.0, "avg_logprob": -0.23797470668576798, "compression_ratio": 1.7231404958677685, "no_speech_prob": 1.6027919400585233e-06}, {"id": 93, "seek": 33144, "start": 339.08, "end": 341.08, "text": " state that it's changing?", "tokens": [1785, 300, 309, 311, 4473, 30], "temperature": 0.0, "avg_logprob": -0.23797470668576798, "compression_ratio": 1.7231404958677685, "no_speech_prob": 1.6027919400585233e-06}, {"id": 94, "seek": 33144, "start": 341.08, "end": 345.04, "text": " Does it pass in an argument somewhere and that gets mutated somewhere?", "tokens": [4402, 309, 1320, 294, 364, 6770, 4079, 293, 300, 2170, 5839, 770, 4079, 30], "temperature": 0.0, "avg_logprob": -0.23797470668576798, "compression_ratio": 1.7231404958677685, "no_speech_prob": 1.6027919400585233e-06}, {"id": 95, "seek": 33144, "start": 345.04, "end": 351.52, "text": " And that's like a very real thing that happened when I was debugging things and trying to", "tokens": [400, 300, 311, 411, 257, 588, 957, 551, 300, 2011, 562, 286, 390, 45592, 721, 293, 1382, 281], "temperature": 0.0, "avg_logprob": -0.23797470668576798, "compression_ratio": 1.7231404958677685, "no_speech_prob": 1.6027919400585233e-06}, {"id": 96, "seek": 33144, "start": 351.52, "end": 353.04, "text": " figure out what went wrong.", "tokens": [2573, 484, 437, 1437, 2085, 13], "temperature": 0.0, "avg_logprob": -0.23797470668576798, "compression_ratio": 1.7231404958677685, "no_speech_prob": 1.6027919400585233e-06}, {"id": 97, "seek": 33144, "start": 353.04, "end": 356.24, "text": " And so like, and then you go to fix it.", "tokens": [400, 370, 411, 11, 293, 550, 291, 352, 281, 3191, 309, 13], "temperature": 0.0, "avg_logprob": -0.23797470668576798, "compression_ratio": 1.7231404958677685, "no_speech_prob": 1.6027919400585233e-06}, {"id": 98, "seek": 33144, "start": 356.24, "end": 361.04, "text": " And I, and I loved like writing tests to wrap my head around what was working.", "tokens": [400, 286, 11, 293, 286, 4333, 411, 3579, 6921, 281, 7019, 452, 1378, 926, 437, 390, 1364, 13], "temperature": 0.0, "avg_logprob": -0.23797470668576798, "compression_ratio": 1.7231404958677685, "no_speech_prob": 1.6027919400585233e-06}, {"id": 99, "seek": 36104, "start": 361.04, "end": 365.08000000000004, "text": " And when I was writing unit tests, I'm like, oh yes, this, like, this makes sense.", "tokens": [400, 562, 286, 390, 3579, 4985, 6921, 11, 286, 478, 411, 11, 1954, 2086, 11, 341, 11, 411, 11, 341, 1669, 2020, 13], "temperature": 0.0, "avg_logprob": -0.20863377081381307, "compression_ratio": 1.8581818181818182, "no_speech_prob": 4.710832854470937e-06}, {"id": 100, "seek": 36104, "start": 365.08000000000004, "end": 367.72, "text": " I can like understand what this is doing.", "tokens": [286, 393, 411, 1223, 437, 341, 307, 884, 13], "temperature": 0.0, "avg_logprob": -0.20863377081381307, "compression_ratio": 1.8581818181818182, "no_speech_prob": 4.710832854470937e-06}, {"id": 101, "seek": 36104, "start": 367.72, "end": 373.32000000000005, "text": " And then you start doing controller level tests, integration tests, and everything is", "tokens": [400, 550, 291, 722, 884, 10561, 1496, 6921, 11, 10980, 6921, 11, 293, 1203, 307], "temperature": 0.0, "avg_logprob": -0.20863377081381307, "compression_ratio": 1.8581818181818182, "no_speech_prob": 4.710832854470937e-06}, {"id": 102, "seek": 36104, "start": 373.32000000000005, "end": 377.48, "text": " mocked and you're like, wait a minute now, like now there's all this magic in the code", "tokens": [17362, 292, 293, 291, 434, 411, 11, 1699, 257, 3456, 586, 11, 411, 586, 456, 311, 439, 341, 5585, 294, 264, 3089], "temperature": 0.0, "avg_logprob": -0.20863377081381307, "compression_ratio": 1.8581818181818182, "no_speech_prob": 4.710832854470937e-06}, {"id": 103, "seek": 36104, "start": 377.48, "end": 378.56, "text": " itself.", "tokens": [2564, 13], "temperature": 0.0, "avg_logprob": -0.20863377081381307, "compression_ratio": 1.8581818181818182, "no_speech_prob": 4.710832854470937e-06}, {"id": 104, "seek": 36104, "start": 378.56, "end": 381.76, "text": " And now I've added this, like, I don't know what I'm actually testing.", "tokens": [400, 586, 286, 600, 3869, 341, 11, 411, 11, 286, 500, 380, 458, 437, 286, 478, 767, 4997, 13], "temperature": 0.0, "avg_logprob": -0.20863377081381307, "compression_ratio": 1.8581818181818182, "no_speech_prob": 4.710832854470937e-06}, {"id": 105, "seek": 36104, "start": 381.76, "end": 385.36, "text": " I don't know what's real and what's fake in the test.", "tokens": [286, 500, 380, 458, 437, 311, 957, 293, 437, 311, 7592, 294, 264, 1500, 13], "temperature": 0.0, "avg_logprob": -0.20863377081381307, "compression_ratio": 1.8581818181818182, "no_speech_prob": 4.710832854470937e-06}, {"id": 106, "seek": 36104, "start": 385.36, "end": 390.36, "text": " So I was very disillusioned by that, but I didn't, I didn't know it at the time.", "tokens": [407, 286, 390, 588, 717, 373, 5704, 292, 538, 300, 11, 457, 286, 994, 380, 11, 286, 994, 380, 458, 309, 412, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.20863377081381307, "compression_ratio": 1.8581818181818182, "no_speech_prob": 4.710832854470937e-06}, {"id": 107, "seek": 39036, "start": 390.36, "end": 396.28000000000003, "text": " I didn't know I was disillusioned at the time because that I'm like, well, I guess like", "tokens": [286, 994, 380, 458, 286, 390, 717, 373, 5704, 292, 412, 264, 565, 570, 300, 286, 478, 411, 11, 731, 11, 286, 2041, 411], "temperature": 0.0, "avg_logprob": -0.21010984158983417, "compression_ratio": 1.5605381165919283, "no_speech_prob": 1.7880417999549536e-06}, {"id": 108, "seek": 39036, "start": 396.28000000000003, "end": 398.2, "text": " this is programming.", "tokens": [341, 307, 9410, 13], "temperature": 0.0, "avg_logprob": -0.21010984158983417, "compression_ratio": 1.5605381165919283, "no_speech_prob": 1.7880417999549536e-06}, {"id": 109, "seek": 39036, "start": 398.2, "end": 400.24, "text": " This is like, this is what you do.", "tokens": [639, 307, 411, 11, 341, 307, 437, 291, 360, 13], "temperature": 0.0, "avg_logprob": -0.21010984158983417, "compression_ratio": 1.5605381165919283, "no_speech_prob": 1.7880417999549536e-06}, {"id": 110, "seek": 39036, "start": 400.24, "end": 402.68, "text": " And I didn't know there were alternatives to that.", "tokens": [400, 286, 994, 380, 458, 456, 645, 20478, 281, 300, 13], "temperature": 0.0, "avg_logprob": -0.21010984158983417, "compression_ratio": 1.5605381165919283, "no_speech_prob": 1.7880417999549536e-06}, {"id": 111, "seek": 39036, "start": 402.68, "end": 407.04, "text": " This is my life now for the next 40 years or however long.", "tokens": [639, 307, 452, 993, 586, 337, 264, 958, 3356, 924, 420, 4461, 938, 13], "temperature": 0.0, "avg_logprob": -0.21010984158983417, "compression_ratio": 1.5605381165919283, "no_speech_prob": 1.7880417999549536e-06}, {"id": 112, "seek": 39036, "start": 407.04, "end": 408.04, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.21010984158983417, "compression_ratio": 1.5605381165919283, "no_speech_prob": 1.7880417999549536e-06}, {"id": 113, "seek": 39036, "start": 408.04, "end": 414.0, "text": " So I had had a little bit of a seed planted because when I was doing Ruby on Rails, I", "tokens": [407, 286, 632, 632, 257, 707, 857, 295, 257, 8871, 17395, 570, 562, 286, 390, 884, 19907, 322, 48526, 11, 286], "temperature": 0.0, "avg_logprob": -0.21010984158983417, "compression_ratio": 1.5605381165919283, "no_speech_prob": 1.7880417999549536e-06}, {"id": 114, "seek": 41400, "start": 414.0, "end": 420.52, "text": " discovered the enumerable mixin, which is something you can use on data structures that", "tokens": [6941, 264, 465, 15583, 712, 2890, 259, 11, 597, 307, 746, 291, 393, 764, 322, 1412, 9227, 300], "temperature": 0.0, "avg_logprob": -0.31509692852313703, "compression_ratio": 1.5879828326180256, "no_speech_prob": 8.186321451830736e-07}, {"id": 115, "seek": 41400, "start": 420.52, "end": 430.68, "text": " are enumerable like arrays to, to filter them and map them and inject fold L sort of thing.", "tokens": [366, 465, 15583, 712, 411, 41011, 281, 11, 281, 6608, 552, 293, 4471, 552, 293, 10711, 4860, 441, 1333, 295, 551, 13], "temperature": 0.0, "avg_logprob": -0.31509692852313703, "compression_ratio": 1.5879828326180256, "no_speech_prob": 8.186321451830736e-07}, {"id": 116, "seek": 41400, "start": 430.68, "end": 432.84, "text": " Wait, was inject fold L?", "tokens": [3802, 11, 390, 10711, 4860, 441, 30], "temperature": 0.0, "avg_logprob": -0.31509692852313703, "compression_ratio": 1.5879828326180256, "no_speech_prob": 8.186321451830736e-07}, {"id": 117, "seek": 41400, "start": 432.84, "end": 435.96, "text": " I can't even, I honestly can't even remember now.", "tokens": [286, 393, 380, 754, 11, 286, 6095, 393, 380, 754, 1604, 586, 13], "temperature": 0.0, "avg_logprob": -0.31509692852313703, "compression_ratio": 1.5879828326180256, "no_speech_prob": 8.186321451830736e-07}, {"id": 118, "seek": 41400, "start": 435.96, "end": 440.6, "text": " Sounds like a weird name for fold, but I think it might've been.", "tokens": [14576, 411, 257, 3657, 1315, 337, 4860, 11, 457, 286, 519, 309, 1062, 600, 668, 13], "temperature": 0.0, "avg_logprob": -0.31509692852313703, "compression_ratio": 1.5879828326180256, "no_speech_prob": 8.186321451830736e-07}, {"id": 119, "seek": 41400, "start": 440.6, "end": 441.96, "text": " And then there was compact.", "tokens": [400, 550, 456, 390, 14679, 13], "temperature": 0.0, "avg_logprob": -0.31509692852313703, "compression_ratio": 1.5879828326180256, "no_speech_prob": 8.186321451830736e-07}, {"id": 120, "seek": 41400, "start": 441.96, "end": 443.48, "text": " Compact was very cool.", "tokens": [6620, 578, 390, 588, 1627, 13], "temperature": 0.0, "avg_logprob": -0.31509692852313703, "compression_ratio": 1.5879828326180256, "no_speech_prob": 8.186321451830736e-07}, {"id": 121, "seek": 44348, "start": 443.48, "end": 447.84000000000003, "text": " Compact is something I do all the time now in Elm, a filter map identity.", "tokens": [6620, 578, 307, 746, 286, 360, 439, 264, 565, 586, 294, 2699, 76, 11, 257, 6608, 4471, 6575, 13], "temperature": 0.0, "avg_logprob": -0.27333396335817733, "compression_ratio": 1.5836909871244635, "no_speech_prob": 2.2252565941016655e-06}, {"id": 122, "seek": 44348, "start": 447.84000000000003, "end": 449.32, "text": " Oh yeah.", "tokens": [876, 1338, 13], "temperature": 0.0, "avg_logprob": -0.27333396335817733, "compression_ratio": 1.5836909871244635, "no_speech_prob": 2.2252565941016655e-06}, {"id": 123, "seek": 44348, "start": 449.32, "end": 453.32, "text": " Removing all the nils in the case of Ruby from a, from a list.", "tokens": [46445, 798, 439, 264, 297, 388, 82, 294, 264, 1389, 295, 19907, 490, 257, 11, 490, 257, 1329, 13], "temperature": 0.0, "avg_logprob": -0.27333396335817733, "compression_ratio": 1.5836909871244635, "no_speech_prob": 2.2252565941016655e-06}, {"id": 124, "seek": 44348, "start": 453.32, "end": 459.68, "text": " But but I fell in love with working in that way and I started to really, you know, instead", "tokens": [583, 457, 286, 5696, 294, 959, 365, 1364, 294, 300, 636, 293, 286, 1409, 281, 534, 11, 291, 458, 11, 2602], "temperature": 0.0, "avg_logprob": -0.27333396335817733, "compression_ratio": 1.5836909871244635, "no_speech_prob": 2.2252565941016655e-06}, {"id": 125, "seek": 44348, "start": 459.68, "end": 468.20000000000005, "text": " of using the shovel operator to imperatively add things into an array as you iterate over", "tokens": [295, 1228, 264, 29789, 12973, 281, 10100, 19020, 909, 721, 666, 364, 10225, 382, 291, 44497, 670], "temperature": 0.0, "avg_logprob": -0.27333396335817733, "compression_ratio": 1.5836909871244635, "no_speech_prob": 2.2252565941016655e-06}, {"id": 126, "seek": 44348, "start": 468.20000000000005, "end": 471.44, "text": " it, it's a way to push things into a list.", "tokens": [309, 11, 309, 311, 257, 636, 281, 2944, 721, 666, 257, 1329, 13], "temperature": 0.0, "avg_logprob": -0.27333396335817733, "compression_ratio": 1.5836909871244635, "no_speech_prob": 2.2252565941016655e-06}, {"id": 127, "seek": 47144, "start": 471.44, "end": 473.8, "text": " That's another thing about Ruby and Ruby on Rails.", "tokens": [663, 311, 1071, 551, 466, 19907, 293, 19907, 322, 48526, 13], "temperature": 0.0, "avg_logprob": -0.30159351375553156, "compression_ratio": 1.6823104693140793, "no_speech_prob": 3.205819041340874e-07}, {"id": 128, "seek": 47144, "start": 473.8, "end": 475.32, "text": " There's more than one way to do it.", "tokens": [821, 311, 544, 813, 472, 636, 281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.30159351375553156, "compression_ratio": 1.6823104693140793, "no_speech_prob": 3.205819041340874e-07}, {"id": 129, "seek": 47144, "start": 475.32, "end": 478.6, "text": " You know, my mind is a little bit stuck on the shovel operator.", "tokens": [509, 458, 11, 452, 1575, 307, 257, 707, 857, 5541, 322, 264, 29789, 12973, 13], "temperature": 0.0, "avg_logprob": -0.30159351375553156, "compression_ratio": 1.6823104693140793, "no_speech_prob": 3.205819041340874e-07}, {"id": 130, "seek": 47144, "start": 478.6, "end": 482.52, "text": " I'm trying to imagine what it would look like.", "tokens": [286, 478, 1382, 281, 3811, 437, 309, 576, 574, 411, 13], "temperature": 0.0, "avg_logprob": -0.30159351375553156, "compression_ratio": 1.6823104693140793, "no_speech_prob": 3.205819041340874e-07}, {"id": 131, "seek": 47144, "start": 482.52, "end": 485.24, "text": " It's a double carrot.", "tokens": [467, 311, 257, 3834, 22767, 13], "temperature": 0.0, "avg_logprob": -0.30159351375553156, "compression_ratio": 1.6823104693140793, "no_speech_prob": 3.205819041340874e-07}, {"id": 132, "seek": 47144, "start": 485.24, "end": 487.64, "text": " I think it's two less than signs.", "tokens": [286, 519, 309, 311, 732, 1570, 813, 7880, 13], "temperature": 0.0, "avg_logprob": -0.30159351375553156, "compression_ratio": 1.6823104693140793, "no_speech_prob": 3.205819041340874e-07}, {"id": 133, "seek": 47144, "start": 487.64, "end": 488.64, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.30159351375553156, "compression_ratio": 1.6823104693140793, "no_speech_prob": 3.205819041340874e-07}, {"id": 134, "seek": 47144, "start": 488.64, "end": 493.24, "text": " Oh, so function composition in Elm, they call that shovel?", "tokens": [876, 11, 370, 2445, 12686, 294, 2699, 76, 11, 436, 818, 300, 29789, 30], "temperature": 0.0, "avg_logprob": -0.30159351375553156, "compression_ratio": 1.6823104693140793, "no_speech_prob": 3.205819041340874e-07}, {"id": 135, "seek": 47144, "start": 493.24, "end": 496.68, "text": " They call it shovel because you're shoveling things into an array, I guess.", "tokens": [814, 818, 309, 29789, 570, 291, 434, 29789, 278, 721, 666, 364, 10225, 11, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.30159351375553156, "compression_ratio": 1.6823104693140793, "no_speech_prob": 3.205819041340874e-07}, {"id": 136, "seek": 47144, "start": 496.68, "end": 497.68, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.30159351375553156, "compression_ratio": 1.6823104693140793, "no_speech_prob": 3.205819041340874e-07}, {"id": 137, "seek": 47144, "start": 497.68, "end": 499.08, "text": " So it's more about the use and what it looks like.", "tokens": [407, 309, 311, 544, 466, 264, 764, 293, 437, 309, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.30159351375553156, "compression_ratio": 1.6823104693140793, "no_speech_prob": 3.205819041340874e-07}, {"id": 138, "seek": 47144, "start": 499.08, "end": 500.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.30159351375553156, "compression_ratio": 1.6823104693140793, "no_speech_prob": 3.205819041340874e-07}, {"id": 139, "seek": 47144, "start": 500.08, "end": 501.08, "text": " I guess.", "tokens": [286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.30159351375553156, "compression_ratio": 1.6823104693140793, "no_speech_prob": 3.205819041340874e-07}, {"id": 140, "seek": 50108, "start": 501.08, "end": 502.08, "text": " I think so.", "tokens": [286, 519, 370, 13], "temperature": 0.0, "avg_logprob": -0.23659445769595402, "compression_ratio": 1.9307359307359306, "no_speech_prob": 2.8572769679158228e-06}, {"id": 141, "seek": 50108, "start": 502.08, "end": 504.44, "text": " But these are things that you, you need to know.", "tokens": [583, 613, 366, 721, 300, 291, 11, 291, 643, 281, 458, 13], "temperature": 0.0, "avg_logprob": -0.23659445769595402, "compression_ratio": 1.9307359307359306, "no_speech_prob": 2.8572769679158228e-06}, {"id": 142, "seek": 50108, "start": 504.44, "end": 510.32, "text": " And so much time was spent in code reviews, just talking about, you know, nitpicks of", "tokens": [400, 370, 709, 565, 390, 4418, 294, 3089, 10229, 11, 445, 1417, 466, 11, 291, 458, 11, 10900, 79, 7663, 295], "temperature": 0.0, "avg_logprob": -0.23659445769595402, "compression_ratio": 1.9307359307359306, "no_speech_prob": 2.8572769679158228e-06}, {"id": 143, "seek": 50108, "start": 510.32, "end": 513.72, "text": " like, oh, you know, I really don't like the shovel operator.", "tokens": [411, 11, 1954, 11, 291, 458, 11, 286, 534, 500, 380, 411, 264, 29789, 12973, 13], "temperature": 0.0, "avg_logprob": -0.23659445769595402, "compression_ratio": 1.9307359307359306, "no_speech_prob": 2.8572769679158228e-06}, {"id": 144, "seek": 50108, "start": 513.72, "end": 515.64, "text": " I prefer to do it this way.", "tokens": [286, 4382, 281, 360, 309, 341, 636, 13], "temperature": 0.0, "avg_logprob": -0.23659445769595402, "compression_ratio": 1.9307359307359306, "no_speech_prob": 2.8572769679158228e-06}, {"id": 145, "seek": 50108, "start": 515.64, "end": 521.88, "text": " I prefer to do it, you know, with a list dot map, or I prefer to do it with a for loop,", "tokens": [286, 4382, 281, 360, 309, 11, 291, 458, 11, 365, 257, 1329, 5893, 4471, 11, 420, 286, 4382, 281, 360, 309, 365, 257, 337, 6367, 11], "temperature": 0.0, "avg_logprob": -0.23659445769595402, "compression_ratio": 1.9307359307359306, "no_speech_prob": 2.8572769679158228e-06}, {"id": 146, "seek": 50108, "start": 521.88, "end": 526.36, "text": " or I prefer to do it within each loop because those are all things you can do.", "tokens": [420, 286, 4382, 281, 360, 309, 1951, 1184, 6367, 570, 729, 366, 439, 721, 291, 393, 360, 13], "temperature": 0.0, "avg_logprob": -0.23659445769595402, "compression_ratio": 1.9307359307359306, "no_speech_prob": 2.8572769679158228e-06}, {"id": 147, "seek": 50108, "start": 526.36, "end": 528.6, "text": " I prefer to use unless.", "tokens": [286, 4382, 281, 764, 5969, 13], "temperature": 0.0, "avg_logprob": -0.23659445769595402, "compression_ratio": 1.9307359307359306, "no_speech_prob": 2.8572769679158228e-06}, {"id": 148, "seek": 50108, "start": 528.6, "end": 530.56, "text": " I prefer to use if.", "tokens": [286, 4382, 281, 764, 498, 13], "temperature": 0.0, "avg_logprob": -0.23659445769595402, "compression_ratio": 1.9307359307359306, "no_speech_prob": 2.8572769679158228e-06}, {"id": 149, "seek": 53056, "start": 530.56, "end": 536.16, "text": " It's like, geez, let's just like have one way to do things that works nicely, you know,", "tokens": [467, 311, 411, 11, 46108, 11, 718, 311, 445, 411, 362, 472, 636, 281, 360, 721, 300, 1985, 9594, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.29909588740422177, "compression_ratio": 1.5251141552511416, "no_speech_prob": 2.994380338350311e-06}, {"id": 150, "seek": 53056, "start": 536.16, "end": 537.16, "text": " but.", "tokens": [457, 13], "temperature": 0.0, "avg_logprob": -0.29909588740422177, "compression_ratio": 1.5251141552511416, "no_speech_prob": 2.994380338350311e-06}, {"id": 151, "seek": 53056, "start": 537.16, "end": 541.5999999999999, "text": " Let's configure this linter to make all those choices for us.", "tokens": [961, 311, 22162, 341, 287, 5106, 281, 652, 439, 729, 7994, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.29909588740422177, "compression_ratio": 1.5251141552511416, "no_speech_prob": 2.994380338350311e-06}, {"id": 152, "seek": 53056, "start": 541.5999999999999, "end": 542.5999999999999, "text": " Oh, right.", "tokens": [876, 11, 558, 13], "temperature": 0.0, "avg_logprob": -0.29909588740422177, "compression_ratio": 1.5251141552511416, "no_speech_prob": 2.994380338350311e-06}, {"id": 153, "seek": 53056, "start": 542.5999999999999, "end": 544.52, "text": " Which linter should we use?", "tokens": [3013, 287, 5106, 820, 321, 764, 30], "temperature": 0.0, "avg_logprob": -0.29909588740422177, "compression_ratio": 1.5251141552511416, "no_speech_prob": 2.994380338350311e-06}, {"id": 154, "seek": 53056, "start": 544.52, "end": 548.4799999999999, "text": " Yeah, I prefer this linter.", "tokens": [865, 11, 286, 4382, 341, 287, 5106, 13], "temperature": 0.0, "avg_logprob": -0.29909588740422177, "compression_ratio": 1.5251141552511416, "no_speech_prob": 2.994380338350311e-06}, {"id": 155, "seek": 53056, "start": 548.4799999999999, "end": 553.52, "text": " This was in the days before like auto formatters were in vogue also.", "tokens": [639, 390, 294, 264, 1708, 949, 411, 8399, 1254, 37690, 645, 294, 371, 7213, 611, 13], "temperature": 0.0, "avg_logprob": -0.29909588740422177, "compression_ratio": 1.5251141552511416, "no_speech_prob": 2.994380338350311e-06}, {"id": 156, "seek": 53056, "start": 553.52, "end": 556.3599999999999, "text": " So you know, that was a whole nother thing.", "tokens": [407, 291, 458, 11, 300, 390, 257, 1379, 406, 511, 551, 13], "temperature": 0.0, "avg_logprob": -0.29909588740422177, "compression_ratio": 1.5251141552511416, "no_speech_prob": 2.994380338350311e-06}, {"id": 157, "seek": 55636, "start": 556.36, "end": 565.5600000000001, "text": " But yeah, it felt like there was so much churn just figuring out how to express something.", "tokens": [583, 1338, 11, 309, 2762, 411, 456, 390, 370, 709, 417, 925, 445, 15213, 484, 577, 281, 5109, 746, 13], "temperature": 0.0, "avg_logprob": -0.23086355129877725, "compression_ratio": 1.6916299559471366, "no_speech_prob": 5.2553082241502125e-06}, {"id": 158, "seek": 55636, "start": 565.5600000000001, "end": 570.36, "text": " And at the same time, like, like, I wanted to just think about how do I model these domain", "tokens": [400, 412, 264, 912, 565, 11, 411, 11, 411, 11, 286, 1415, 281, 445, 519, 466, 577, 360, 286, 2316, 613, 9274], "temperature": 0.0, "avg_logprob": -0.23086355129877725, "compression_ratio": 1.6916299559471366, "no_speech_prob": 5.2553082241502125e-06}, {"id": 159, "seek": 55636, "start": 570.36, "end": 571.64, "text": " concepts?", "tokens": [10392, 30], "temperature": 0.0, "avg_logprob": -0.23086355129877725, "compression_ratio": 1.6916299559471366, "no_speech_prob": 5.2553082241502125e-06}, {"id": 160, "seek": 55636, "start": 571.64, "end": 575.36, "text": " And how do I understand what the heck is actually happening here?", "tokens": [400, 577, 360, 286, 1223, 437, 264, 12872, 307, 767, 2737, 510, 30], "temperature": 0.0, "avg_logprob": -0.23086355129877725, "compression_ratio": 1.6916299559471366, "no_speech_prob": 5.2553082241502125e-06}, {"id": 161, "seek": 55636, "start": 575.36, "end": 581.36, "text": " Like, how do I get a test around it to understand exactly what inputs lead to what outputs and", "tokens": [1743, 11, 577, 360, 286, 483, 257, 1500, 926, 309, 281, 1223, 2293, 437, 15743, 1477, 281, 437, 23930, 293], "temperature": 0.0, "avg_logprob": -0.23086355129877725, "compression_ratio": 1.6916299559471366, "no_speech_prob": 5.2553082241502125e-06}, {"id": 162, "seek": 55636, "start": 581.36, "end": 583.4, "text": " what scenarios are interesting?", "tokens": [437, 15077, 366, 1880, 30], "temperature": 0.0, "avg_logprob": -0.23086355129877725, "compression_ratio": 1.6916299559471366, "no_speech_prob": 5.2553082241502125e-06}, {"id": 163, "seek": 58340, "start": 583.4, "end": 589.36, "text": " How do I model the domain, interestingly, and how do I avoid like magic stuff?", "tokens": [1012, 360, 286, 2316, 264, 9274, 11, 25873, 11, 293, 577, 360, 286, 5042, 411, 5585, 1507, 30], "temperature": 0.0, "avg_logprob": -0.21161606288192295, "compression_ratio": 1.5957446808510638, "no_speech_prob": 5.203524438002205e-07}, {"id": 164, "seek": 58340, "start": 589.36, "end": 595.72, "text": " And so like enumerable started to feel like, OK, I like this way, but I felt a little bit", "tokens": [400, 370, 411, 465, 15583, 712, 1409, 281, 841, 411, 11, 2264, 11, 286, 411, 341, 636, 11, 457, 286, 2762, 257, 707, 857], "temperature": 0.0, "avg_logprob": -0.21161606288192295, "compression_ratio": 1.5957446808510638, "no_speech_prob": 5.203524438002205e-07}, {"id": 165, "seek": 58340, "start": 595.72, "end": 600.88, "text": " out of place because I didn't feel like everybody was on the same page as me with like, some", "tokens": [484, 295, 1081, 570, 286, 994, 380, 841, 411, 2201, 390, 322, 264, 912, 3028, 382, 385, 365, 411, 11, 512], "temperature": 0.0, "avg_logprob": -0.21161606288192295, "compression_ratio": 1.5957446808510638, "no_speech_prob": 5.203524438002205e-07}, {"id": 166, "seek": 58340, "start": 600.88, "end": 607.1999999999999, "text": " people could kind of get behind it, but it wasn't a widely held opinion that that was", "tokens": [561, 727, 733, 295, 483, 2261, 309, 11, 457, 309, 2067, 380, 257, 13371, 5167, 4800, 300, 300, 390], "temperature": 0.0, "avg_logprob": -0.21161606288192295, "compression_ratio": 1.5957446808510638, "no_speech_prob": 5.203524438002205e-07}, {"id": 167, "seek": 58340, "start": 607.1999999999999, "end": 609.1999999999999, "text": " a cleaner way to do things.", "tokens": [257, 16532, 636, 281, 360, 721, 13], "temperature": 0.0, "avg_logprob": -0.21161606288192295, "compression_ratio": 1.5957446808510638, "no_speech_prob": 5.203524438002205e-07}, {"id": 168, "seek": 60920, "start": 609.2, "end": 617.84, "text": " So I guess the thing after my Ruby on Rails days was I got into coaching, agile and technical", "tokens": [407, 286, 2041, 264, 551, 934, 452, 19907, 322, 48526, 1708, 390, 286, 658, 666, 15818, 11, 30072, 293, 6191], "temperature": 0.0, "avg_logprob": -0.25681300693088105, "compression_ratio": 1.669767441860465, "no_speech_prob": 1.392538933941978e-06}, {"id": 169, "seek": 60920, "start": 617.84, "end": 624.2800000000001, "text": " coaching and that influenced me a lot in terms of the power of small steps, the power of", "tokens": [15818, 293, 300, 15269, 385, 257, 688, 294, 2115, 295, 264, 1347, 295, 1359, 4439, 11, 264, 1347, 295], "temperature": 0.0, "avg_logprob": -0.25681300693088105, "compression_ratio": 1.669767441860465, "no_speech_prob": 1.392538933941978e-06}, {"id": 170, "seek": 60920, "start": 624.2800000000001, "end": 626.9200000000001, "text": " being very deliberate.", "tokens": [885, 588, 30515, 13], "temperature": 0.0, "avg_logprob": -0.25681300693088105, "compression_ratio": 1.669767441860465, "no_speech_prob": 1.392538933941978e-06}, {"id": 171, "seek": 60920, "start": 626.9200000000001, "end": 631.48, "text": " And I was coaching teams, I was coaching a team using AngularJS.", "tokens": [400, 286, 390, 15818, 5491, 11, 286, 390, 15818, 257, 1469, 1228, 34107, 41, 50, 13], "temperature": 0.0, "avg_logprob": -0.25681300693088105, "compression_ratio": 1.669767441860465, "no_speech_prob": 1.392538933941978e-06}, {"id": 172, "seek": 60920, "start": 631.48, "end": 637.2800000000001, "text": " And there were so many, so many challenges working with that code base, you know, making", "tokens": [400, 456, 645, 370, 867, 11, 370, 867, 4759, 1364, 365, 300, 3089, 3096, 11, 291, 458, 11, 1455], "temperature": 0.0, "avg_logprob": -0.25681300693088105, "compression_ratio": 1.669767441860465, "no_speech_prob": 1.392538933941978e-06}, {"id": 173, "seek": 63728, "start": 637.28, "end": 644.28, "text": " it testable and, you know, bugs would pop up and Angular just, you know, this is Angular", "tokens": [309, 1500, 712, 293, 11, 291, 458, 11, 15120, 576, 1665, 493, 293, 34107, 445, 11, 291, 458, 11, 341, 307, 34107], "temperature": 0.0, "avg_logprob": -0.24449284293434836, "compression_ratio": 1.6883720930232557, "no_speech_prob": 1.8738489870884223e-06}, {"id": 174, "seek": 63728, "start": 644.28, "end": 645.36, "text": " 1, AngularJS.", "tokens": [502, 11, 34107, 41, 50, 13], "temperature": 0.0, "avg_logprob": -0.24449284293434836, "compression_ratio": 1.6883720930232557, "no_speech_prob": 1.8738489870884223e-06}, {"id": 175, "seek": 63728, "start": 645.36, "end": 649.0799999999999, "text": " And it was, again, there were a lot of ways you could do things.", "tokens": [400, 309, 390, 11, 797, 11, 456, 645, 257, 688, 295, 2098, 291, 727, 360, 721, 13], "temperature": 0.0, "avg_logprob": -0.24449284293434836, "compression_ratio": 1.6883720930232557, "no_speech_prob": 1.8738489870884223e-06}, {"id": 176, "seek": 63728, "start": 649.0799999999999, "end": 650.64, "text": " There were a lot of foot guns.", "tokens": [821, 645, 257, 688, 295, 2671, 10153, 13], "temperature": 0.0, "avg_logprob": -0.24449284293434836, "compression_ratio": 1.6883720930232557, "no_speech_prob": 1.8738489870884223e-06}, {"id": 177, "seek": 63728, "start": 650.64, "end": 655.12, "text": " There was, you know, you could mutate the DOM.", "tokens": [821, 390, 11, 291, 458, 11, 291, 727, 5839, 473, 264, 35727, 13], "temperature": 0.0, "avg_logprob": -0.24449284293434836, "compression_ratio": 1.6883720930232557, "no_speech_prob": 1.8738489870884223e-06}, {"id": 178, "seek": 63728, "start": 655.12, "end": 656.76, "text": " You're definitely not supposed to.", "tokens": [509, 434, 2138, 406, 3442, 281, 13], "temperature": 0.0, "avg_logprob": -0.24449284293434836, "compression_ratio": 1.6883720930232557, "no_speech_prob": 1.8738489870884223e-06}, {"id": 179, "seek": 63728, "start": 656.76, "end": 662.1999999999999, "text": " There are like big warning signs that say, warning, don't use this, but it's here.", "tokens": [821, 366, 411, 955, 9164, 7880, 300, 584, 11, 9164, 11, 500, 380, 764, 341, 11, 457, 309, 311, 510, 13], "temperature": 0.0, "avg_logprob": -0.24449284293434836, "compression_ratio": 1.6883720930232557, "no_speech_prob": 1.8738489870884223e-06}, {"id": 180, "seek": 66220, "start": 662.2, "end": 667.72, "text": " And you find some random stack overflow post and you don't know what's broken.", "tokens": [400, 291, 915, 512, 4974, 8630, 37772, 2183, 293, 291, 500, 380, 458, 437, 311, 5463, 13], "temperature": 0.0, "avg_logprob": -0.20675962347733348, "compression_ratio": 1.7326732673267327, "no_speech_prob": 3.6118638035986805e-06}, {"id": 181, "seek": 66220, "start": 667.72, "end": 673.84, "text": " There's some subtle, like leaky abstraction that you need to fix and you don't know what's", "tokens": [821, 311, 512, 13743, 11, 411, 476, 15681, 37765, 300, 291, 643, 281, 3191, 293, 291, 500, 380, 458, 437, 311], "temperature": 0.0, "avg_logprob": -0.20675962347733348, "compression_ratio": 1.7326732673267327, "no_speech_prob": 3.6118638035986805e-06}, {"id": 182, "seek": 66220, "start": 673.84, "end": 675.48, "text": " going wrong to fix it.", "tokens": [516, 2085, 281, 3191, 309, 13], "temperature": 0.0, "avg_logprob": -0.20675962347733348, "compression_ratio": 1.7326732673267327, "no_speech_prob": 3.6118638035986805e-06}, {"id": 183, "seek": 66220, "start": 675.48, "end": 680.2, "text": " And so a stack overflow post tells you to mutate the DOM and you do it.", "tokens": [400, 370, 257, 8630, 37772, 2183, 5112, 291, 281, 5839, 473, 264, 35727, 293, 291, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.20675962347733348, "compression_ratio": 1.7326732673267327, "no_speech_prob": 3.6118638035986805e-06}, {"id": 184, "seek": 66220, "start": 680.2, "end": 686.6800000000001, "text": " And not to mention, it just felt like very difficult to, to even just like, you know,", "tokens": [400, 406, 281, 2152, 11, 309, 445, 2762, 411, 588, 2252, 281, 11, 281, 754, 445, 411, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.20675962347733348, "compression_ratio": 1.7326732673267327, "no_speech_prob": 3.6118638035986805e-06}, {"id": 185, "seek": 68668, "start": 686.68, "end": 693.76, "text": " I want to have this Angular dependency that I can use in this context.", "tokens": [286, 528, 281, 362, 341, 34107, 33621, 300, 286, 393, 764, 294, 341, 4319, 13], "temperature": 0.0, "avg_logprob": -0.18402533758254278, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.443916400807211e-06}, {"id": 186, "seek": 68668, "start": 693.76, "end": 694.92, "text": " How do I even get it in there?", "tokens": [1012, 360, 286, 754, 483, 309, 294, 456, 30], "temperature": 0.0, "avg_logprob": -0.18402533758254278, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.443916400807211e-06}, {"id": 187, "seek": 68668, "start": 694.92, "end": 697.4, "text": " And how do I know that it's working correctly?", "tokens": [400, 577, 360, 286, 458, 300, 309, 311, 1364, 8944, 30], "temperature": 0.0, "avg_logprob": -0.18402533758254278, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.443916400807211e-06}, {"id": 188, "seek": 68668, "start": 697.4, "end": 702.64, "text": " You know, it like automatically injects values based on the variable name.", "tokens": [509, 458, 11, 309, 411, 6772, 10711, 82, 4190, 2361, 322, 264, 7006, 1315, 13], "temperature": 0.0, "avg_logprob": -0.18402533758254278, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.443916400807211e-06}, {"id": 189, "seek": 68668, "start": 702.64, "end": 704.64, "text": " And you're like, is this even working?", "tokens": [400, 291, 434, 411, 11, 307, 341, 754, 1364, 30], "temperature": 0.0, "avg_logprob": -0.18402533758254278, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.443916400807211e-06}, {"id": 190, "seek": 68668, "start": 704.64, "end": 707.0, "text": " And if it breaks, how do I know?", "tokens": [400, 498, 309, 9857, 11, 577, 360, 286, 458, 30], "temperature": 0.0, "avg_logprob": -0.18402533758254278, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.443916400807211e-06}, {"id": 191, "seek": 68668, "start": 707.0, "end": 711.68, "text": " And at the same time, like I'm coaching this team on these technical practices and we're", "tokens": [400, 412, 264, 912, 565, 11, 411, 286, 478, 15818, 341, 1469, 322, 613, 6191, 7525, 293, 321, 434], "temperature": 0.0, "avg_logprob": -0.18402533758254278, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.443916400807211e-06}, {"id": 192, "seek": 71168, "start": 711.68, "end": 718.3599999999999, "text": " helping them do legacy code refactoring, do continuous delivery, getting push button deploys", "tokens": [4315, 552, 360, 11711, 3089, 1895, 578, 3662, 11, 360, 10957, 8982, 11, 1242, 2944, 2960, 368, 49522], "temperature": 0.0, "avg_logprob": -0.23502009847889777, "compression_ratio": 1.5932203389830508, "no_speech_prob": 2.6840887130674673e-06}, {"id": 193, "seek": 71168, "start": 718.3599999999999, "end": 721.52, "text": " and doing trunk based development on it, all of these things.", "tokens": [293, 884, 19849, 2361, 3250, 322, 309, 11, 439, 295, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.23502009847889777, "compression_ratio": 1.5932203389830508, "no_speech_prob": 2.6840887130674673e-06}, {"id": 194, "seek": 71168, "start": 721.52, "end": 724.3599999999999, "text": " And it had real results.", "tokens": [400, 309, 632, 957, 3542, 13], "temperature": 0.0, "avg_logprob": -0.23502009847889777, "compression_ratio": 1.5932203389830508, "no_speech_prob": 2.6840887130674673e-06}, {"id": 195, "seek": 71168, "start": 724.3599999999999, "end": 730.1999999999999, "text": " Like we were, we were shipping faster and more confidently, but there was so much work", "tokens": [1743, 321, 645, 11, 321, 645, 14122, 4663, 293, 544, 41956, 11, 457, 456, 390, 370, 709, 589], "temperature": 0.0, "avg_logprob": -0.23502009847889777, "compression_ratio": 1.5932203389830508, "no_speech_prob": 2.6840887130674673e-06}, {"id": 196, "seek": 71168, "start": 730.1999999999999, "end": 731.56, "text": " to get there.", "tokens": [281, 483, 456, 13], "temperature": 0.0, "avg_logprob": -0.23502009847889777, "compression_ratio": 1.5932203389830508, "no_speech_prob": 2.6840887130674673e-06}, {"id": 197, "seek": 71168, "start": 731.56, "end": 738.04, "text": " And I realized like the language choice plays a big role in your ability to do these practices.", "tokens": [400, 286, 5334, 411, 264, 2856, 3922, 5749, 257, 955, 3090, 294, 428, 3485, 281, 360, 613, 7525, 13], "temperature": 0.0, "avg_logprob": -0.23502009847889777, "compression_ratio": 1.5932203389830508, "no_speech_prob": 2.6840887130674673e-06}, {"id": 198, "seek": 73804, "start": 738.04, "end": 742.28, "text": " And when I discovered Elm, it was a breath of fresh air because suddenly all these things", "tokens": [400, 562, 286, 6941, 2699, 76, 11, 309, 390, 257, 6045, 295, 4451, 1988, 570, 5800, 439, 613, 721], "temperature": 0.0, "avg_logprob": -0.2274277719219079, "compression_ratio": 1.6108597285067874, "no_speech_prob": 1.3081652241453412e-06}, {"id": 199, "seek": 73804, "start": 742.28, "end": 748.28, "text": " I was trying to coach, like let's avoid having our tests blow up on the first of the month", "tokens": [286, 390, 1382, 281, 6560, 11, 411, 718, 311, 5042, 1419, 527, 6921, 6327, 493, 322, 264, 700, 295, 264, 1618], "temperature": 0.0, "avg_logprob": -0.2274277719219079, "compression_ratio": 1.6108597285067874, "no_speech_prob": 1.3081652241453412e-06}, {"id": 200, "seek": 73804, "start": 748.28, "end": 752.4, "text": " because it depends on the specific date they're run.", "tokens": [570, 309, 5946, 322, 264, 2685, 4002, 436, 434, 1190, 13], "temperature": 0.0, "avg_logprob": -0.2274277719219079, "compression_ratio": 1.6108597285067874, "no_speech_prob": 1.3081652241453412e-06}, {"id": 201, "seek": 73804, "start": 752.4, "end": 754.64, "text": " Let's make them deterministic.", "tokens": [961, 311, 652, 552, 15957, 3142, 13], "temperature": 0.0, "avg_logprob": -0.2274277719219079, "compression_ratio": 1.6108597285067874, "no_speech_prob": 1.3081652241453412e-06}, {"id": 202, "seek": 73804, "start": 754.64, "end": 761.24, "text": " Like these are practices I was coaching teams on that, like I saw results in the code bases", "tokens": [1743, 613, 366, 7525, 286, 390, 15818, 5491, 322, 300, 11, 411, 286, 1866, 3542, 294, 264, 3089, 17949], "temperature": 0.0, "avg_logprob": -0.2274277719219079, "compression_ratio": 1.6108597285067874, "no_speech_prob": 1.3081652241453412e-06}, {"id": 203, "seek": 76124, "start": 761.24, "end": 768.96, "text": " becoming more robust and teams spending less time churning on these fires and more time", "tokens": [5617, 544, 13956, 293, 5491, 6434, 1570, 565, 417, 10656, 322, 613, 15044, 293, 544, 565], "temperature": 0.0, "avg_logprob": -0.21676266577935988, "compression_ratio": 1.611336032388664, "no_speech_prob": 3.6118874504609266e-06}, {"id": 204, "seek": 76124, "start": 768.96, "end": 771.96, "text": " focusing on the domain and shipping things faster.", "tokens": [8416, 322, 264, 9274, 293, 14122, 721, 4663, 13], "temperature": 0.0, "avg_logprob": -0.21676266577935988, "compression_ratio": 1.611336032388664, "no_speech_prob": 3.6118874504609266e-06}, {"id": 205, "seek": 76124, "start": 771.96, "end": 777.0, "text": " But with Elm, I'm like, wow, like dependency injection is just the only way to do things", "tokens": [583, 365, 2699, 76, 11, 286, 478, 411, 11, 6076, 11, 411, 33621, 22873, 307, 445, 264, 787, 636, 281, 360, 721], "temperature": 0.0, "avg_logprob": -0.21676266577935988, "compression_ratio": 1.611336032388664, "no_speech_prob": 3.6118874504609266e-06}, {"id": 206, "seek": 76124, "start": 777.0, "end": 780.3, "text": " because you can't depend on impure things.", "tokens": [570, 291, 393, 380, 5672, 322, 704, 540, 721, 13], "temperature": 0.0, "avg_logprob": -0.21676266577935988, "compression_ratio": 1.611336032388664, "no_speech_prob": 3.6118874504609266e-06}, {"id": 207, "seek": 76124, "start": 780.3, "end": 786.36, "text": " And testing is very straightforward and you have this fast feedback loop from the compiler", "tokens": [400, 4997, 307, 588, 15325, 293, 291, 362, 341, 2370, 5824, 6367, 490, 264, 31958], "temperature": 0.0, "avg_logprob": -0.21676266577935988, "compression_ratio": 1.611336032388664, "no_speech_prob": 3.6118874504609266e-06}, {"id": 208, "seek": 76124, "start": 786.36, "end": 789.44, "text": " telling you exactly what went wrong.", "tokens": [3585, 291, 2293, 437, 1437, 2085, 13], "temperature": 0.0, "avg_logprob": -0.21676266577935988, "compression_ratio": 1.611336032388664, "no_speech_prob": 3.6118874504609266e-06}, {"id": 209, "seek": 78944, "start": 789.44, "end": 793.8000000000001, "text": " Even back then, because I think you used Elm in 18?", "tokens": [2754, 646, 550, 11, 570, 286, 519, 291, 1143, 2699, 76, 294, 2443, 30], "temperature": 0.0, "avg_logprob": -0.28428572367846483, "compression_ratio": 1.6360294117647058, "no_speech_prob": 1.1189162023583776e-06}, {"id": 210, "seek": 78944, "start": 793.8000000000001, "end": 796.32, "text": " That was in the 18 days.", "tokens": [663, 390, 294, 264, 2443, 1708, 13], "temperature": 0.0, "avg_logprob": -0.28428572367846483, "compression_ratio": 1.6360294117647058, "no_speech_prob": 1.1189162023583776e-06}, {"id": 211, "seek": 78944, "start": 796.32, "end": 797.32, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.28428572367846483, "compression_ratio": 1.6360294117647058, "no_speech_prob": 1.1189162023583776e-06}, {"id": 212, "seek": 78944, "start": 797.32, "end": 798.32, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.28428572367846483, "compression_ratio": 1.6360294117647058, "no_speech_prob": 1.1189162023583776e-06}, {"id": 213, "seek": 78944, "start": 798.32, "end": 799.32, "text": " When the compiler was still slow, right?", "tokens": [1133, 264, 31958, 390, 920, 2964, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.28428572367846483, "compression_ratio": 1.6360294117647058, "no_speech_prob": 1.1189162023583776e-06}, {"id": 214, "seek": 78944, "start": 799.32, "end": 804.08, "text": " Well, when I say fast feedback, I mean, everything was kind of slow back then.", "tokens": [1042, 11, 562, 286, 584, 2370, 5824, 11, 286, 914, 11, 1203, 390, 733, 295, 2964, 646, 550, 13], "temperature": 0.0, "avg_logprob": -0.28428572367846483, "compression_ratio": 1.6360294117647058, "no_speech_prob": 1.1189162023583776e-06}, {"id": 215, "seek": 78944, "start": 804.08, "end": 808.4000000000001, "text": " So I wasn't really like noticing a speed difference between other things.", "tokens": [407, 286, 2067, 380, 534, 411, 21814, 257, 3073, 2649, 1296, 661, 721, 13], "temperature": 0.0, "avg_logprob": -0.28428572367846483, "compression_ratio": 1.6360294117647058, "no_speech_prob": 1.1189162023583776e-06}, {"id": 216, "seek": 78944, "start": 808.4000000000001, "end": 814.2, "text": " Also, this wasn't like a, you know, several hundred thousand line code base.", "tokens": [2743, 11, 341, 2067, 380, 411, 257, 11, 291, 458, 11, 2940, 3262, 4714, 1622, 3089, 3096, 13], "temperature": 0.0, "avg_logprob": -0.28428572367846483, "compression_ratio": 1.6360294117647058, "no_speech_prob": 1.1189162023583776e-06}, {"id": 217, "seek": 78944, "start": 814.2, "end": 819.1400000000001, "text": " But when I say fast feedback loop, I mean, just more like compared to scratching your", "tokens": [583, 562, 286, 584, 2370, 5824, 6367, 11, 286, 914, 11, 445, 544, 411, 5347, 281, 29699, 428], "temperature": 0.0, "avg_logprob": -0.28428572367846483, "compression_ratio": 1.6360294117647058, "no_speech_prob": 1.1189162023583776e-06}, {"id": 218, "seek": 81914, "start": 819.14, "end": 823.52, "text": " head at why isn't this Angular thing working and it not telling you and you literally spending", "tokens": [1378, 412, 983, 1943, 380, 341, 34107, 551, 1364, 293, 309, 406, 3585, 291, 293, 291, 3736, 6434], "temperature": 0.0, "avg_logprob": -0.24171344790838462, "compression_ratio": 1.7306122448979593, "no_speech_prob": 7.888998879934661e-06}, {"id": 219, "seek": 81914, "start": 823.52, "end": 825.04, "text": " a whole day trying to figure it out.", "tokens": [257, 1379, 786, 1382, 281, 2573, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.24171344790838462, "compression_ratio": 1.7306122448979593, "no_speech_prob": 7.888998879934661e-06}, {"id": 220, "seek": 81914, "start": 825.04, "end": 829.92, "text": " And you're like, oh, of course it was here, some dumb little thing, but it doesn't tell", "tokens": [400, 291, 434, 411, 11, 1954, 11, 295, 1164, 309, 390, 510, 11, 512, 10316, 707, 551, 11, 457, 309, 1177, 380, 980], "temperature": 0.0, "avg_logprob": -0.24171344790838462, "compression_ratio": 1.7306122448979593, "no_speech_prob": 7.888998879934661e-06}, {"id": 221, "seek": 81914, "start": 829.92, "end": 830.92, "text": " you.", "tokens": [291, 13], "temperature": 0.0, "avg_logprob": -0.24171344790838462, "compression_ratio": 1.7306122448979593, "no_speech_prob": 7.888998879934661e-06}, {"id": 222, "seek": 81914, "start": 830.92, "end": 833.4399999999999, "text": " So it really felt like a breath of fresh air.", "tokens": [407, 309, 534, 2762, 411, 257, 6045, 295, 4451, 1988, 13], "temperature": 0.0, "avg_logprob": -0.24171344790838462, "compression_ratio": 1.7306122448979593, "no_speech_prob": 7.888998879934661e-06}, {"id": 223, "seek": 81914, "start": 833.4399999999999, "end": 840.52, "text": " And it really felt like it addressed these things in my experience with Ruby that didn't", "tokens": [400, 309, 534, 2762, 411, 309, 13847, 613, 721, 294, 452, 1752, 365, 19907, 300, 994, 380], "temperature": 0.0, "avg_logprob": -0.24171344790838462, "compression_ratio": 1.7306122448979593, "no_speech_prob": 7.888998879934661e-06}, {"id": 224, "seek": 81914, "start": 840.52, "end": 845.36, "text": " sit right with me where mocking it's like, well, you can't mock.", "tokens": [1394, 558, 365, 385, 689, 49792, 309, 311, 411, 11, 731, 11, 291, 393, 380, 17362, 13], "temperature": 0.0, "avg_logprob": -0.24171344790838462, "compression_ratio": 1.7306122448979593, "no_speech_prob": 7.888998879934661e-06}, {"id": 225, "seek": 84536, "start": 845.36, "end": 851.24, "text": " But more importantly, like you express the code in a way where you wouldn't need to mock", "tokens": [583, 544, 8906, 11, 411, 291, 5109, 264, 3089, 294, 257, 636, 689, 291, 2759, 380, 643, 281, 17362], "temperature": 0.0, "avg_logprob": -0.27558303106398807, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.601568439786206e-06}, {"id": 226, "seek": 84536, "start": 851.24, "end": 858.08, "text": " because it's not coupled to all of these side effects and external systems.", "tokens": [570, 309, 311, 406, 29482, 281, 439, 295, 613, 1252, 5065, 293, 8320, 3652, 13], "temperature": 0.0, "avg_logprob": -0.27558303106398807, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.601568439786206e-06}, {"id": 227, "seek": 84536, "start": 858.08, "end": 859.22, "text": " You inject that in.", "tokens": [509, 10711, 300, 294, 13], "temperature": 0.0, "avg_logprob": -0.27558303106398807, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.601568439786206e-06}, {"id": 228, "seek": 84536, "start": 859.22, "end": 861.52, "text": " So you just test the behavior.", "tokens": [407, 291, 445, 1500, 264, 5223, 13], "temperature": 0.0, "avg_logprob": -0.27558303106398807, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.601568439786206e-06}, {"id": 229, "seek": 84536, "start": 861.52, "end": 864.44, "text": " You write something that isn't coupled to that.", "tokens": [509, 2464, 746, 300, 1943, 380, 29482, 281, 300, 13], "temperature": 0.0, "avg_logprob": -0.27558303106398807, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.601568439786206e-06}, {"id": 230, "seek": 84536, "start": 864.44, "end": 865.44, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.27558303106398807, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.601568439786206e-06}, {"id": 231, "seek": 84536, "start": 865.44, "end": 870.12, "text": " So all of these like very subtle decoupling things that I was trying really hard to like", "tokens": [407, 439, 295, 613, 411, 588, 13743, 979, 263, 11970, 721, 300, 286, 390, 1382, 534, 1152, 281, 411], "temperature": 0.0, "avg_logprob": -0.27558303106398807, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.601568439786206e-06}, {"id": 232, "seek": 84536, "start": 870.12, "end": 872.44, "text": " coach teams on and teach them how to practice.", "tokens": [6560, 5491, 322, 293, 2924, 552, 577, 281, 3124, 13], "temperature": 0.0, "avg_logprob": -0.27558303106398807, "compression_ratio": 1.6571428571428573, "no_speech_prob": 2.601568439786206e-06}, {"id": 233, "seek": 87244, "start": 872.44, "end": 875.96, "text": " It's like, well, in Elm, you don't really need to teach that.", "tokens": [467, 311, 411, 11, 731, 11, 294, 2699, 76, 11, 291, 500, 380, 534, 643, 281, 2924, 300, 13], "temperature": 0.0, "avg_logprob": -0.21262386483205875, "compression_ratio": 1.9047619047619047, "no_speech_prob": 4.4249854909139685e-06}, {"id": 234, "seek": 87244, "start": 875.96, "end": 881.24, "text": " It's just like, I mean, in Elm, you just need to tell people, write tests.", "tokens": [467, 311, 445, 411, 11, 286, 914, 11, 294, 2699, 76, 11, 291, 445, 643, 281, 980, 561, 11, 2464, 6921, 13], "temperature": 0.0, "avg_logprob": -0.21262386483205875, "compression_ratio": 1.9047619047619047, "no_speech_prob": 4.4249854909139685e-06}, {"id": 235, "seek": 87244, "start": 881.24, "end": 884.8000000000001, "text": " But if they write tests, then they're going to write them in that way and they're going", "tokens": [583, 498, 436, 2464, 6921, 11, 550, 436, 434, 516, 281, 2464, 552, 294, 300, 636, 293, 436, 434, 516], "temperature": 0.0, "avg_logprob": -0.21262386483205875, "compression_ratio": 1.9047619047619047, "no_speech_prob": 4.4249854909139685e-06}, {"id": 236, "seek": 87244, "start": 884.8000000000001, "end": 886.32, "text": " to write their code in that way.", "tokens": [281, 2464, 641, 3089, 294, 300, 636, 13], "temperature": 0.0, "avg_logprob": -0.21262386483205875, "compression_ratio": 1.9047619047619047, "no_speech_prob": 4.4249854909139685e-06}, {"id": 237, "seek": 87244, "start": 886.32, "end": 890.8800000000001, "text": " So I think that's I think that's kind of my story.", "tokens": [407, 286, 519, 300, 311, 286, 519, 300, 311, 733, 295, 452, 1657, 13], "temperature": 0.0, "avg_logprob": -0.21262386483205875, "compression_ratio": 1.9047619047619047, "no_speech_prob": 4.4249854909139685e-06}, {"id": 238, "seek": 87244, "start": 890.8800000000001, "end": 896.12, "text": " That's why I really believe in Elm because all these things like that, I felt like I", "tokens": [663, 311, 983, 286, 534, 1697, 294, 2699, 76, 570, 439, 613, 721, 411, 300, 11, 286, 2762, 411, 286], "temperature": 0.0, "avg_logprob": -0.21262386483205875, "compression_ratio": 1.9047619047619047, "no_speech_prob": 4.4249854909139685e-06}, {"id": 239, "seek": 87244, "start": 896.12, "end": 897.12, "text": " didn't belong.", "tokens": [994, 380, 5784, 13], "temperature": 0.0, "avg_logprob": -0.21262386483205875, "compression_ratio": 1.9047619047619047, "no_speech_prob": 4.4249854909139685e-06}, {"id": 240, "seek": 87244, "start": 897.12, "end": 901.1800000000001, "text": " I wasn't in the right place because I just wanted one way to do things.", "tokens": [286, 2067, 380, 294, 264, 558, 1081, 570, 286, 445, 1415, 472, 636, 281, 360, 721, 13], "temperature": 0.0, "avg_logprob": -0.21262386483205875, "compression_ratio": 1.9047619047619047, "no_speech_prob": 4.4249854909139685e-06}, {"id": 241, "seek": 90118, "start": 901.18, "end": 905.0, "text": " And also, I just like wanted these practices to be natural.", "tokens": [400, 611, 11, 286, 445, 411, 1415, 613, 7525, 281, 312, 3303, 13], "temperature": 0.0, "avg_logprob": -0.3432434152025695, "compression_ratio": 1.52863436123348, "no_speech_prob": 1.6536663451915956e-06}, {"id": 242, "seek": 90118, "start": 905.0, "end": 907.0799999999999, "text": " It just made sense to me.", "tokens": [467, 445, 1027, 2020, 281, 385, 13], "temperature": 0.0, "avg_logprob": -0.3432434152025695, "compression_ratio": 1.52863436123348, "no_speech_prob": 1.6536663451915956e-06}, {"id": 243, "seek": 90118, "start": 907.0799999999999, "end": 909.28, "text": " Yeah, I totally see where you're coming from.", "tokens": [865, 11, 286, 3879, 536, 689, 291, 434, 1348, 490, 13], "temperature": 0.0, "avg_logprob": -0.3432434152025695, "compression_ratio": 1.52863436123348, "no_speech_prob": 1.6536663451915956e-06}, {"id": 244, "seek": 90118, "start": 909.28, "end": 912.92, "text": " The mock spider, radioactive mocks.", "tokens": [440, 17362, 17614, 11, 35844, 705, 2761, 13], "temperature": 0.0, "avg_logprob": -0.3432434152025695, "compression_ratio": 1.52863436123348, "no_speech_prob": 1.6536663451915956e-06}, {"id": 245, "seek": 90118, "start": 912.92, "end": 913.92, "text": " Mock man.", "tokens": [376, 1560, 587, 13], "temperature": 0.0, "avg_logprob": -0.3432434152025695, "compression_ratio": 1.52863436123348, "no_speech_prob": 1.6536663451915956e-06}, {"id": 246, "seek": 90118, "start": 913.92, "end": 918.7199999999999, "text": " Well, Jeroen, what is your super villain backstory?", "tokens": [1042, 11, 508, 2032, 268, 11, 437, 307, 428, 1687, 17906, 36899, 30], "temperature": 0.0, "avg_logprob": -0.3432434152025695, "compression_ratio": 1.52863436123348, "no_speech_prob": 1.6536663451915956e-06}, {"id": 247, "seek": 90118, "start": 918.7199999999999, "end": 921.12, "text": " Are you a super villain or are you a superhero?", "tokens": [2014, 291, 257, 1687, 17906, 420, 366, 291, 257, 19428, 30], "temperature": 0.0, "avg_logprob": -0.3432434152025695, "compression_ratio": 1.52863436123348, "no_speech_prob": 1.6536663451915956e-06}, {"id": 248, "seek": 90118, "start": 921.12, "end": 923.9599999999999, "text": " Who knows?", "tokens": [2102, 3255, 30], "temperature": 0.0, "avg_logprob": -0.3432434152025695, "compression_ratio": 1.52863436123348, "no_speech_prob": 1.6536663451915956e-06}, {"id": 249, "seek": 90118, "start": 923.9599999999999, "end": 925.3599999999999, "text": " The listeners can decide.", "tokens": [440, 23274, 393, 4536, 13], "temperature": 0.0, "avg_logprob": -0.3432434152025695, "compression_ratio": 1.52863436123348, "no_speech_prob": 1.6536663451915956e-06}, {"id": 250, "seek": 90118, "start": 925.3599999999999, "end": 926.3599999999999, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.3432434152025695, "compression_ratio": 1.52863436123348, "no_speech_prob": 1.6536663451915956e-06}, {"id": 251, "seek": 90118, "start": 926.3599999999999, "end": 929.76, "text": " Please say I'm a good guy.", "tokens": [2555, 584, 286, 478, 257, 665, 2146, 13], "temperature": 0.0, "avg_logprob": -0.3432434152025695, "compression_ratio": 1.52863436123348, "no_speech_prob": 1.6536663451915956e-06}, {"id": 252, "seek": 92976, "start": 929.76, "end": 936.12, "text": " Yeah, so where I come from is more from working as a developer.", "tokens": [865, 11, 370, 689, 286, 808, 490, 307, 544, 490, 1364, 382, 257, 10754, 13], "temperature": 0.0, "avg_logprob": -0.2565875909267328, "compression_ratio": 1.5893719806763285, "no_speech_prob": 3.2884220217965776e-06}, {"id": 253, "seek": 92976, "start": 936.12, "end": 941.68, "text": " So my career started with CoffeeScript and JavaScript and then more and more JavaScript", "tokens": [407, 452, 3988, 1409, 365, 25481, 14237, 293, 15778, 293, 550, 544, 293, 544, 15778], "temperature": 0.0, "avg_logprob": -0.2565875909267328, "compression_ratio": 1.5893719806763285, "no_speech_prob": 3.2884220217965776e-06}, {"id": 254, "seek": 92976, "start": 941.68, "end": 943.52, "text": " until I did some Elm.", "tokens": [1826, 286, 630, 512, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.2565875909267328, "compression_ratio": 1.5893719806763285, "no_speech_prob": 3.2884220217965776e-06}, {"id": 255, "seek": 92976, "start": 943.52, "end": 947.3199999999999, "text": " And I was pretty much always getting a little bit frustrated with all the problems that", "tokens": [400, 286, 390, 1238, 709, 1009, 1242, 257, 707, 857, 15751, 365, 439, 264, 2740, 300], "temperature": 0.0, "avg_logprob": -0.2565875909267328, "compression_ratio": 1.5893719806763285, "no_speech_prob": 3.2884220217965776e-06}, {"id": 256, "seek": 92976, "start": 947.3199999999999, "end": 952.28, "text": " we were hitting, crashes that were happening that felt preventable.", "tokens": [321, 645, 8850, 11, 28642, 300, 645, 2737, 300, 2762, 4871, 712, 13], "temperature": 0.0, "avg_logprob": -0.2565875909267328, "compression_ratio": 1.5893719806763285, "no_speech_prob": 3.2884220217965776e-06}, {"id": 257, "seek": 95228, "start": 952.28, "end": 961.4, "text": " I started looking into ways that we can improve things by using the newest framework out there.", "tokens": [286, 1409, 1237, 666, 2098, 300, 321, 393, 3470, 721, 538, 1228, 264, 17569, 8388, 484, 456, 13], "temperature": 0.0, "avg_logprob": -0.21838190442039854, "compression_ratio": 1.5586854460093897, "no_speech_prob": 2.768759713944746e-06}, {"id": 258, "seek": 95228, "start": 961.4, "end": 968.0, "text": " I remember being very excited about AngularJS when I was still interning.", "tokens": [286, 1604, 885, 588, 2919, 466, 34107, 41, 50, 562, 286, 390, 920, 728, 773, 13], "temperature": 0.0, "avg_logprob": -0.21838190442039854, "compression_ratio": 1.5586854460093897, "no_speech_prob": 2.768759713944746e-06}, {"id": 259, "seek": 95228, "start": 968.0, "end": 976.68, "text": " I was excited by React when it was released, which is at a company where we're using AngularJS.", "tokens": [286, 390, 2919, 538, 30644, 562, 309, 390, 4736, 11, 597, 307, 412, 257, 2237, 689, 321, 434, 1228, 34107, 41, 50, 13], "temperature": 0.0, "avg_logprob": -0.21838190442039854, "compression_ratio": 1.5586854460093897, "no_speech_prob": 2.768759713944746e-06}, {"id": 260, "seek": 95228, "start": 976.68, "end": 980.24, "text": " And later on, I became excited by Elm for the same reason as well.", "tokens": [400, 1780, 322, 11, 286, 3062, 2919, 538, 2699, 76, 337, 264, 912, 1778, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.21838190442039854, "compression_ratio": 1.5586854460093897, "no_speech_prob": 2.768759713944746e-06}, {"id": 261, "seek": 98024, "start": 980.24, "end": 986.6800000000001, "text": " I started playing with functional programming using Lodash, a specific version of Lodash,", "tokens": [286, 1409, 2433, 365, 11745, 9410, 1228, 441, 378, 1299, 11, 257, 2685, 3037, 295, 441, 378, 1299, 11], "temperature": 0.0, "avg_logprob": -0.32964659390384204, "compression_ratio": 1.5480225988700564, "no_speech_prob": 4.494106178754009e-06}, {"id": 262, "seek": 98024, "start": 986.6800000000001, "end": 996.92, "text": " which is called Lodash-FP, which is all those, not standard, but all those extra functions", "tokens": [597, 307, 1219, 441, 378, 1299, 12, 45882, 11, 597, 307, 439, 729, 11, 406, 3832, 11, 457, 439, 729, 2857, 6828], "temperature": 0.0, "avg_logprob": -0.32964659390384204, "compression_ratio": 1.5480225988700564, "no_speech_prob": 4.494106178754009e-06}, {"id": 263, "seek": 98024, "start": 996.92, "end": 1002.5, "text": " like we have in basics extra and text extra that are done in FP style.", "tokens": [411, 321, 362, 294, 14688, 2857, 293, 2487, 2857, 300, 366, 1096, 294, 36655, 3758, 13], "temperature": 0.0, "avg_logprob": -0.32964659390384204, "compression_ratio": 1.5480225988700564, "no_speech_prob": 4.494106178754009e-06}, {"id": 264, "seek": 98024, "start": 1002.5, "end": 1004.32, "text": " So nothing is mutated.", "tokens": [407, 1825, 307, 5839, 770, 13], "temperature": 0.0, "avg_logprob": -0.32964659390384204, "compression_ratio": 1.5480225988700564, "no_speech_prob": 4.494106178754009e-06}, {"id": 265, "seek": 100432, "start": 1004.32, "end": 1011.72, "text": " You always get a copy of things and the order of arguments is data last instead of data", "tokens": [509, 1009, 483, 257, 5055, 295, 721, 293, 264, 1668, 295, 12869, 307, 1412, 1036, 2602, 295, 1412], "temperature": 0.0, "avg_logprob": -0.3130924151493953, "compression_ratio": 1.5511811023622046, "no_speech_prob": 3.2884854590520263e-06}, {"id": 266, "seek": 100432, "start": 1011.72, "end": 1012.72, "text": " first.", "tokens": [700, 13], "temperature": 0.0, "avg_logprob": -0.3130924151493953, "compression_ratio": 1.5511811023622046, "no_speech_prob": 3.2884854590520263e-06}, {"id": 267, "seek": 100432, "start": 1012.72, "end": 1016.6800000000001, "text": " So that was quite different from regular Lodash, but I really enjoyed using that.", "tokens": [407, 300, 390, 1596, 819, 490, 3890, 441, 378, 1299, 11, 457, 286, 534, 4626, 1228, 300, 13], "temperature": 0.0, "avg_logprob": -0.3130924151493953, "compression_ratio": 1.5511811023622046, "no_speech_prob": 3.2884854590520263e-06}, {"id": 268, "seek": 100432, "start": 1016.6800000000001, "end": 1020.2, "text": " That made things feel more easier to understand.", "tokens": [663, 1027, 721, 841, 544, 3571, 281, 1223, 13], "temperature": 0.0, "avg_logprob": -0.3130924151493953, "compression_ratio": 1.5511811023622046, "no_speech_prob": 3.2884854590520263e-06}, {"id": 269, "seek": 100432, "start": 1020.2, "end": 1027.64, "text": " And the Lodash, the FP stuff is using like curried JS style.", "tokens": [400, 264, 441, 378, 1299, 11, 264, 36655, 1507, 307, 1228, 411, 1262, 2428, 33063, 3758, 13], "temperature": 0.0, "avg_logprob": -0.3130924151493953, "compression_ratio": 1.5511811023622046, "no_speech_prob": 3.2884854590520263e-06}, {"id": 270, "seek": 100432, "start": 1027.64, "end": 1031.72, "text": " So you were already into partial application and down that rabbit hole at that point.", "tokens": [407, 291, 645, 1217, 666, 14641, 3861, 293, 760, 300, 19509, 5458, 412, 300, 935, 13], "temperature": 0.0, "avg_logprob": -0.3130924151493953, "compression_ratio": 1.5511811023622046, "no_speech_prob": 3.2884854590520263e-06}, {"id": 271, "seek": 100432, "start": 1031.72, "end": 1034.3, "text": " Yeah, in a way, yeah.", "tokens": [865, 11, 294, 257, 636, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.3130924151493953, "compression_ratio": 1.5511811023622046, "no_speech_prob": 3.2884854590520263e-06}, {"id": 272, "seek": 103430, "start": 1034.3, "end": 1041.48, "text": " So maybe I didn't use it all that much, I feel, in retrospect, but it did make my learning", "tokens": [407, 1310, 286, 994, 380, 764, 309, 439, 300, 709, 11, 286, 841, 11, 294, 34997, 11, 457, 309, 630, 652, 452, 2539], "temperature": 0.0, "avg_logprob": -0.262378394085428, "compression_ratio": 1.5726141078838174, "no_speech_prob": 8.800082468951587e-06}, {"id": 273, "seek": 103430, "start": 1041.48, "end": 1043.1599999999999, "text": " of Elm much easier.", "tokens": [295, 2699, 76, 709, 3571, 13], "temperature": 0.0, "avg_logprob": -0.262378394085428, "compression_ratio": 1.5726141078838174, "no_speech_prob": 8.800082468951587e-06}, {"id": 274, "seek": 103430, "start": 1043.1599999999999, "end": 1049.8999999999999, "text": " I didn't have as much trouble with learning Elm as plenty of others have done, probably", "tokens": [286, 994, 380, 362, 382, 709, 5253, 365, 2539, 2699, 76, 382, 7140, 295, 2357, 362, 1096, 11, 1391], "temperature": 0.0, "avg_logprob": -0.262378394085428, "compression_ratio": 1.5726141078838174, "no_speech_prob": 8.800082468951587e-06}, {"id": 275, "seek": 103430, "start": 1049.8999999999999, "end": 1050.8999999999999, "text": " because of that.", "tokens": [570, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.262378394085428, "compression_ratio": 1.5726141078838174, "no_speech_prob": 8.800082468951587e-06}, {"id": 276, "seek": 103430, "start": 1050.8999999999999, "end": 1052.8799999999999, "text": " Yeah, yeah, I think so.", "tokens": [865, 11, 1338, 11, 286, 519, 370, 13], "temperature": 0.0, "avg_logprob": -0.262378394085428, "compression_ratio": 1.5726141078838174, "no_speech_prob": 8.800082468951587e-06}, {"id": 277, "seek": 103430, "start": 1052.8799999999999, "end": 1057.6399999999999, "text": " It's just like, well, it's the same things as Lodash, except you have less surprises.", "tokens": [467, 311, 445, 411, 11, 731, 11, 309, 311, 264, 912, 721, 382, 441, 378, 1299, 11, 3993, 291, 362, 1570, 22655, 13], "temperature": 0.0, "avg_logprob": -0.262378394085428, "compression_ratio": 1.5726141078838174, "no_speech_prob": 8.800082468951587e-06}, {"id": 278, "seek": 103430, "start": 1057.6399999999999, "end": 1059.5, "text": " And yeah, and it worked well.", "tokens": [400, 1338, 11, 293, 309, 2732, 731, 13], "temperature": 0.0, "avg_logprob": -0.262378394085428, "compression_ratio": 1.5726141078838174, "no_speech_prob": 8.800082468951587e-06}, {"id": 279, "seek": 103430, "start": 1059.5, "end": 1062.1599999999999, "text": " So that felt very nice.", "tokens": [407, 300, 2762, 588, 1481, 13], "temperature": 0.0, "avg_logprob": -0.262378394085428, "compression_ratio": 1.5726141078838174, "no_speech_prob": 8.800082468951587e-06}, {"id": 280, "seek": 106216, "start": 1062.16, "end": 1066.72, "text": " And at the same time, I was playing with ESLint, writing a lot of ESLint rules.", "tokens": [400, 412, 264, 912, 565, 11, 286, 390, 2433, 365, 12564, 43, 686, 11, 3579, 257, 688, 295, 12564, 43, 686, 4474, 13], "temperature": 0.0, "avg_logprob": -0.24856901168823242, "compression_ratio": 1.6600790513833992, "no_speech_prob": 3.23754238706897e-06}, {"id": 281, "seek": 106216, "start": 1066.72, "end": 1072.8000000000002, "text": " I wrote like 75 over the course of a year, because there were just so many problems that", "tokens": [286, 4114, 411, 9562, 670, 264, 1164, 295, 257, 1064, 11, 570, 456, 645, 445, 370, 867, 2740, 300], "temperature": 0.0, "avg_logprob": -0.24856901168823242, "compression_ratio": 1.6600790513833992, "no_speech_prob": 3.23754238706897e-06}, {"id": 282, "seek": 106216, "start": 1072.8000000000002, "end": 1075.8000000000002, "text": " you could have in our code base and in JavaScript.", "tokens": [291, 727, 362, 294, 527, 3089, 3096, 293, 294, 15778, 13], "temperature": 0.0, "avg_logprob": -0.24856901168823242, "compression_ratio": 1.6600790513833992, "no_speech_prob": 3.23754238706897e-06}, {"id": 283, "seek": 106216, "start": 1075.8000000000002, "end": 1082.28, "text": " So I wrote plenty for packages that were published, a few under my name, a few under other people's", "tokens": [407, 286, 4114, 7140, 337, 17401, 300, 645, 6572, 11, 257, 1326, 833, 452, 1315, 11, 257, 1326, 833, 661, 561, 311], "temperature": 0.0, "avg_logprob": -0.24856901168823242, "compression_ratio": 1.6600790513833992, "no_speech_prob": 3.23754238706897e-06}, {"id": 284, "seek": 106216, "start": 1082.28, "end": 1088.0800000000002, "text": " names, and a few that were custom to our code base at work.", "tokens": [5288, 11, 293, 257, 1326, 300, 645, 2375, 281, 527, 3089, 3096, 412, 589, 13], "temperature": 0.0, "avg_logprob": -0.24856901168823242, "compression_ratio": 1.6600790513833992, "no_speech_prob": 3.23754238706897e-06}, {"id": 285, "seek": 106216, "start": 1088.0800000000002, "end": 1091.4, "text": " And I mean, 75 rules are a lot of rules.", "tokens": [400, 286, 914, 11, 9562, 4474, 366, 257, 688, 295, 4474, 13], "temperature": 0.0, "avg_logprob": -0.24856901168823242, "compression_ratio": 1.6600790513833992, "no_speech_prob": 3.23754238706897e-06}, {"id": 286, "seek": 109140, "start": 1091.4, "end": 1097.0, "text": " I don't think I've written that many for Elm Review in the four years that I've been working", "tokens": [286, 500, 380, 519, 286, 600, 3720, 300, 867, 337, 2699, 76, 19954, 294, 264, 1451, 924, 300, 286, 600, 668, 1364], "temperature": 0.0, "avg_logprob": -0.24983963876400353, "compression_ratio": 1.5764192139737991, "no_speech_prob": 1.0783030120364856e-05}, {"id": 287, "seek": 109140, "start": 1097.0, "end": 1099.5600000000002, "text": " on it, or however long that was.", "tokens": [322, 309, 11, 420, 4461, 938, 300, 390, 13], "temperature": 0.0, "avg_logprob": -0.24983963876400353, "compression_ratio": 1.5764192139737991, "no_speech_prob": 1.0783030120364856e-05}, {"id": 288, "seek": 109140, "start": 1099.5600000000002, "end": 1102.8400000000001, "text": " So yeah, at some point, I discovered Elm.", "tokens": [407, 1338, 11, 412, 512, 935, 11, 286, 6941, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.24983963876400353, "compression_ratio": 1.5764192139737991, "no_speech_prob": 1.0783030120364856e-05}, {"id": 289, "seek": 109140, "start": 1102.8400000000001, "end": 1109.72, "text": " And I'm like, well, just first to play with Elm, I needed to try it out.", "tokens": [400, 286, 478, 411, 11, 731, 11, 445, 700, 281, 862, 365, 2699, 76, 11, 286, 2978, 281, 853, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.24983963876400353, "compression_ratio": 1.5764192139737991, "no_speech_prob": 1.0783030120364856e-05}, {"id": 290, "seek": 109140, "start": 1109.72, "end": 1116.16, "text": " And Elm is a front-end language to do web applications, but I had no real experience", "tokens": [400, 2699, 76, 307, 257, 1868, 12, 521, 2856, 281, 360, 3670, 5821, 11, 457, 286, 632, 572, 957, 1752], "temperature": 0.0, "avg_logprob": -0.24983963876400353, "compression_ratio": 1.5764192139737991, "no_speech_prob": 1.0783030120364856e-05}, {"id": 291, "seek": 109140, "start": 1116.16, "end": 1119.0800000000002, "text": " with making front-end applications.", "tokens": [365, 1455, 1868, 12, 521, 5821, 13], "temperature": 0.0, "avg_logprob": -0.24983963876400353, "compression_ratio": 1.5764192139737991, "no_speech_prob": 1.0783030120364856e-05}, {"id": 292, "seek": 111908, "start": 1119.08, "end": 1122.8799999999999, "text": " What I did have experience with, however, was writing Linter rules.", "tokens": [708, 286, 630, 362, 1752, 365, 11, 4461, 11, 390, 3579, 441, 5106, 4474, 13], "temperature": 0.0, "avg_logprob": -0.2426319122314453, "compression_ratio": 1.6, "no_speech_prob": 3.3405165140720783e-06}, {"id": 293, "seek": 111908, "start": 1122.8799999999999, "end": 1128.36, "text": " So I decided, well, you know what, let's try to make a Linter, even a basic one.", "tokens": [407, 286, 3047, 11, 731, 11, 291, 458, 437, 11, 718, 311, 853, 281, 652, 257, 441, 5106, 11, 754, 257, 3875, 472, 13], "temperature": 0.0, "avg_logprob": -0.2426319122314453, "compression_ratio": 1.6, "no_speech_prob": 3.3405165140720783e-06}, {"id": 294, "seek": 111908, "start": 1128.36, "end": 1133.84, "text": " And I really liked the experience, mostly because of custom types, like just the fact", "tokens": [400, 286, 534, 4501, 264, 1752, 11, 5240, 570, 295, 2375, 3467, 11, 411, 445, 264, 1186], "temperature": 0.0, "avg_logprob": -0.2426319122314453, "compression_ratio": 1.6, "no_speech_prob": 3.3405165140720783e-06}, {"id": 295, "seek": 111908, "start": 1133.84, "end": 1140.56, "text": " that you can pattern match on AST nodes, and you know exactly what they contain and all", "tokens": [300, 291, 393, 5102, 2995, 322, 316, 6840, 13891, 11, 293, 291, 458, 2293, 437, 436, 5304, 293, 439], "temperature": 0.0, "avg_logprob": -0.2426319122314453, "compression_ratio": 1.6, "no_speech_prob": 3.3405165140720783e-06}, {"id": 296, "seek": 111908, "start": 1140.56, "end": 1144.28, "text": " the AST nodes that you can encounter.", "tokens": [264, 316, 6840, 13891, 300, 291, 393, 8593, 13], "temperature": 0.0, "avg_logprob": -0.2426319122314453, "compression_ratio": 1.6, "no_speech_prob": 3.3405165140720783e-06}, {"id": 297, "seek": 114428, "start": 1144.28, "end": 1149.16, "text": " That felt like a breath of fresh air, because when I was running ESLint rules, oftentimes", "tokens": [663, 2762, 411, 257, 6045, 295, 4451, 1988, 11, 570, 562, 286, 390, 2614, 12564, 43, 686, 4474, 11, 18349], "temperature": 0.0, "avg_logprob": -0.2063729227805624, "compression_ratio": 1.6536796536796536, "no_speech_prob": 3.1381061944557587e-06}, {"id": 298, "seek": 114428, "start": 1149.16, "end": 1154.36, "text": " I didn't know which AST nodes I would hit, which one I would encounter.", "tokens": [286, 994, 380, 458, 597, 316, 6840, 13891, 286, 576, 2045, 11, 597, 472, 286, 576, 8593, 13], "temperature": 0.0, "avg_logprob": -0.2063729227805624, "compression_ratio": 1.6536796536796536, "no_speech_prob": 3.1381061944557587e-06}, {"id": 299, "seek": 114428, "start": 1154.36, "end": 1160.56, "text": " And then there were some properties that I thought would always be there that turned", "tokens": [400, 550, 456, 645, 512, 7221, 300, 286, 1194, 576, 1009, 312, 456, 300, 3574], "temperature": 0.0, "avg_logprob": -0.2063729227805624, "compression_ratio": 1.6536796536796536, "no_speech_prob": 3.1381061944557587e-06}, {"id": 300, "seek": 114428, "start": 1160.56, "end": 1162.36, "text": " out to be optional.", "tokens": [484, 281, 312, 17312, 13], "temperature": 0.0, "avg_logprob": -0.2063729227805624, "compression_ratio": 1.6536796536796536, "no_speech_prob": 3.1381061944557587e-06}, {"id": 301, "seek": 114428, "start": 1162.36, "end": 1168.0, "text": " And when I relied on them not being optional, that crashed the whole ESLint application.", "tokens": [400, 562, 286, 35463, 322, 552, 406, 885, 17312, 11, 300, 24190, 264, 1379, 12564, 43, 686, 3861, 13], "temperature": 0.0, "avg_logprob": -0.2063729227805624, "compression_ratio": 1.6536796536796536, "no_speech_prob": 3.1381061944557587e-06}, {"id": 302, "seek": 114428, "start": 1168.0, "end": 1169.96, "text": " And that didn't feel nice.", "tokens": [400, 300, 994, 380, 841, 1481, 13], "temperature": 0.0, "avg_logprob": -0.2063729227805624, "compression_ratio": 1.6536796536796536, "no_speech_prob": 3.1381061944557587e-06}, {"id": 303, "seek": 116996, "start": 1169.96, "end": 1175.04, "text": " So when I was playing with writing a Linter in Elm, I was like, well, the experience is", "tokens": [407, 562, 286, 390, 2433, 365, 3579, 257, 441, 5106, 294, 2699, 76, 11, 286, 390, 411, 11, 731, 11, 264, 1752, 307], "temperature": 0.0, "avg_logprob": -0.31445460165700606, "compression_ratio": 1.6652360515021458, "no_speech_prob": 1.5779301065776963e-06}, {"id": 304, "seek": 116996, "start": 1175.04, "end": 1176.04, "text": " much nicer.", "tokens": [709, 22842, 13], "temperature": 0.0, "avg_logprob": -0.31445460165700606, "compression_ratio": 1.6652360515021458, "no_speech_prob": 1.5779301065776963e-06}, {"id": 305, "seek": 116996, "start": 1176.04, "end": 1181.48, "text": " And I say that even while writing the Linter from scratch.", "tokens": [400, 286, 584, 300, 754, 1339, 3579, 264, 441, 5106, 490, 8459, 13], "temperature": 0.0, "avg_logprob": -0.31445460165700606, "compression_ratio": 1.6652360515021458, "no_speech_prob": 1.5779301065776963e-06}, {"id": 306, "seek": 116996, "start": 1181.48, "end": 1183.16, "text": " So that was a lot more work.", "tokens": [407, 300, 390, 257, 688, 544, 589, 13], "temperature": 0.0, "avg_logprob": -0.31445460165700606, "compression_ratio": 1.6652360515021458, "no_speech_prob": 1.5779301065776963e-06}, {"id": 307, "seek": 116996, "start": 1183.16, "end": 1184.16, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.31445460165700606, "compression_ratio": 1.6652360515021458, "no_speech_prob": 1.5779301065776963e-06}, {"id": 308, "seek": 116996, "start": 1184.16, "end": 1186.0, "text": " And that was your first Elm project, right?", "tokens": [400, 300, 390, 428, 700, 2699, 76, 1716, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.31445460165700606, "compression_ratio": 1.6652360515021458, "no_speech_prob": 1.5779301065776963e-06}, {"id": 309, "seek": 116996, "start": 1186.0, "end": 1187.16, "text": " That was my first Elm project.", "tokens": [663, 390, 452, 700, 2699, 76, 1716, 13], "temperature": 0.0, "avg_logprob": -0.31445460165700606, "compression_ratio": 1.6652360515021458, "no_speech_prob": 1.5779301065776963e-06}, {"id": 310, "seek": 116996, "start": 1187.16, "end": 1190.6000000000001, "text": " And at some point that became ElmReview.", "tokens": [400, 412, 512, 935, 300, 3062, 2699, 76, 8524, 1759, 13], "temperature": 0.0, "avg_logprob": -0.31445460165700606, "compression_ratio": 1.6652360515021458, "no_speech_prob": 1.5779301065776963e-06}, {"id": 311, "seek": 116996, "start": 1190.6000000000001, "end": 1194.8400000000001, "text": " And that was at the beginning of 2017.", "tokens": [400, 300, 390, 412, 264, 2863, 295, 6591, 13], "temperature": 0.0, "avg_logprob": -0.31445460165700606, "compression_ratio": 1.6652360515021458, "no_speech_prob": 1.5779301065776963e-06}, {"id": 312, "seek": 116996, "start": 1194.8400000000001, "end": 1196.96, "text": " So that's been a long time.", "tokens": [407, 300, 311, 668, 257, 938, 565, 13], "temperature": 0.0, "avg_logprob": -0.31445460165700606, "compression_ratio": 1.6652360515021458, "no_speech_prob": 1.5779301065776963e-06}, {"id": 313, "seek": 116996, "start": 1196.96, "end": 1198.72, "text": " Yeah, wow.", "tokens": [865, 11, 6076, 13], "temperature": 0.0, "avg_logprob": -0.31445460165700606, "compression_ratio": 1.6652360515021458, "no_speech_prob": 1.5779301065776963e-06}, {"id": 314, "seek": 119872, "start": 1198.72, "end": 1203.84, "text": " Yeah, so then I didn't use Elm for a few years.", "tokens": [865, 11, 370, 550, 286, 994, 380, 764, 2699, 76, 337, 257, 1326, 924, 13], "temperature": 0.0, "avg_logprob": -0.30637607137665496, "compression_ratio": 1.6236559139784945, "no_speech_prob": 1.2678145822064835e-06}, {"id": 315, "seek": 119872, "start": 1203.84, "end": 1208.92, "text": " Started doing it professionally at a company, and I really enjoyed it.", "tokens": [39715, 884, 309, 27941, 412, 257, 2237, 11, 293, 286, 534, 4626, 309, 13], "temperature": 0.0, "avg_logprob": -0.30637607137665496, "compression_ratio": 1.6236559139784945, "no_speech_prob": 1.2678145822064835e-06}, {"id": 316, "seek": 119872, "start": 1208.92, "end": 1210.48, "text": " There was one thing that was lacking.", "tokens": [821, 390, 472, 551, 300, 390, 20889, 13], "temperature": 0.0, "avg_logprob": -0.30637607137665496, "compression_ratio": 1.6236559139784945, "no_speech_prob": 1.2678145822064835e-06}, {"id": 317, "seek": 119872, "start": 1210.48, "end": 1214.16, "text": " There's like, oh, well, there's plenty of problems in my code base that we can just", "tokens": [821, 311, 411, 11, 1954, 11, 731, 11, 456, 311, 7140, 295, 2740, 294, 452, 3089, 3096, 300, 321, 393, 445], "temperature": 0.0, "avg_logprob": -0.30637607137665496, "compression_ratio": 1.6236559139784945, "no_speech_prob": 1.2678145822064835e-06}, {"id": 318, "seek": 119872, "start": 1214.16, "end": 1217.72, "text": " fix by telling people, hey, look at the code you wrote.", "tokens": [3191, 538, 3585, 561, 11, 4177, 11, 574, 412, 264, 3089, 291, 4114, 13], "temperature": 0.0, "avg_logprob": -0.30637607137665496, "compression_ratio": 1.6236559139784945, "no_speech_prob": 1.2678145822064835e-06}, {"id": 319, "seek": 119872, "start": 1217.72, "end": 1218.96, "text": " This is not how we should do things.", "tokens": [639, 307, 406, 577, 321, 820, 360, 721, 13], "temperature": 0.0, "avg_logprob": -0.30637607137665496, "compression_ratio": 1.6236559139784945, "no_speech_prob": 1.2678145822064835e-06}, {"id": 320, "seek": 119872, "start": 1218.96, "end": 1224.72, "text": " And I'm like, well, if only we had a Linter that could write custom Linter rules.", "tokens": [400, 286, 478, 411, 11, 731, 11, 498, 787, 321, 632, 257, 441, 5106, 300, 727, 2464, 2375, 441, 5106, 4474, 13], "temperature": 0.0, "avg_logprob": -0.30637607137665496, "compression_ratio": 1.6236559139784945, "no_speech_prob": 1.2678145822064835e-06}, {"id": 321, "seek": 119872, "start": 1224.72, "end": 1227.8, "text": " Well, you know the rest of the story.", "tokens": [1042, 11, 291, 458, 264, 1472, 295, 264, 1657, 13], "temperature": 0.0, "avg_logprob": -0.30637607137665496, "compression_ratio": 1.6236559139784945, "no_speech_prob": 1.2678145822064835e-06}, {"id": 322, "seek": 122780, "start": 1227.8, "end": 1232.48, "text": " So yeah, my experience with Elm was like, there's a lot less things that you need to", "tokens": [407, 1338, 11, 452, 1752, 365, 2699, 76, 390, 411, 11, 456, 311, 257, 688, 1570, 721, 300, 291, 643, 281], "temperature": 0.0, "avg_logprob": -0.24094954708166288, "compression_ratio": 1.689516129032258, "no_speech_prob": 4.860023636865662e-06}, {"id": 323, "seek": 122780, "start": 1232.48, "end": 1237.08, "text": " check with static analysis, because the compiler is already doing that, and the design of the", "tokens": [1520, 365, 13437, 5215, 11, 570, 264, 31958, 307, 1217, 884, 300, 11, 293, 264, 1715, 295, 264], "temperature": 0.0, "avg_logprob": -0.24094954708166288, "compression_ratio": 1.689516129032258, "no_speech_prob": 4.860023636865662e-06}, {"id": 324, "seek": 122780, "start": 1237.08, "end": 1238.6399999999999, "text": " language is already doing that.", "tokens": [2856, 307, 1217, 884, 300, 13], "temperature": 0.0, "avg_logprob": -0.24094954708166288, "compression_ratio": 1.689516129032258, "no_speech_prob": 4.860023636865662e-06}, {"id": 325, "seek": 122780, "start": 1238.6399999999999, "end": 1245.52, "text": " I actually made a blog post on Elmcraft, or an article on Elmcraft, describing all the", "tokens": [286, 767, 1027, 257, 6968, 2183, 322, 2699, 76, 5611, 11, 420, 364, 7222, 322, 2699, 76, 5611, 11, 16141, 439, 264], "temperature": 0.0, "avg_logprob": -0.24094954708166288, "compression_ratio": 1.689516129032258, "no_speech_prob": 4.860023636865662e-06}, {"id": 326, "seek": 122780, "start": 1245.52, "end": 1253.76, "text": " rules for ESLint, the core rules that don't make sense in Elm, like that you don't need,", "tokens": [4474, 337, 12564, 43, 686, 11, 264, 4965, 4474, 300, 500, 380, 652, 2020, 294, 2699, 76, 11, 411, 300, 291, 500, 380, 643, 11], "temperature": 0.0, "avg_logprob": -0.24094954708166288, "compression_ratio": 1.689516129032258, "no_speech_prob": 4.860023636865662e-06}, {"id": 327, "seek": 122780, "start": 1253.76, "end": 1257.1599999999999, "text": " or which ones do you still need?", "tokens": [420, 597, 2306, 360, 291, 920, 643, 30], "temperature": 0.0, "avg_logprob": -0.24094954708166288, "compression_ratio": 1.689516129032258, "no_speech_prob": 4.860023636865662e-06}, {"id": 328, "seek": 125716, "start": 1257.16, "end": 1264.64, "text": " And like 86% or something like that were not needed, and therefore they're not in ElmReview", "tokens": [400, 411, 26687, 4, 420, 746, 411, 300, 645, 406, 2978, 11, 293, 4412, 436, 434, 406, 294, 2699, 76, 8524, 1759], "temperature": 0.0, "avg_logprob": -0.26566200256347655, "compression_ratio": 1.551111111111111, "no_speech_prob": 2.8572530936799012e-06}, {"id": 329, "seek": 125716, "start": 1264.64, "end": 1265.64, "text": " either.", "tokens": [2139, 13], "temperature": 0.0, "avg_logprob": -0.26566200256347655, "compression_ratio": 1.551111111111111, "no_speech_prob": 2.8572530936799012e-06}, {"id": 330, "seek": 125716, "start": 1265.64, "end": 1268.3200000000002, "text": " And that's just like a staggering number.", "tokens": [400, 300, 311, 445, 411, 257, 42974, 1230, 13], "temperature": 0.0, "avg_logprob": -0.26566200256347655, "compression_ratio": 1.551111111111111, "no_speech_prob": 2.8572530936799012e-06}, {"id": 331, "seek": 125716, "start": 1268.3200000000002, "end": 1272.2, "text": " So yeah, these are the kinds of things that I really enjoyed with Elm.", "tokens": [407, 1338, 11, 613, 366, 264, 3685, 295, 721, 300, 286, 534, 4626, 365, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.26566200256347655, "compression_ratio": 1.551111111111111, "no_speech_prob": 2.8572530936799012e-06}, {"id": 332, "seek": 125716, "start": 1272.2, "end": 1280.24, "text": " And over the course of my Elm career, or mostly working as a tooling developer, I've just", "tokens": [400, 670, 264, 1164, 295, 452, 2699, 76, 3988, 11, 420, 5240, 1364, 382, 257, 46593, 10754, 11, 286, 600, 445], "temperature": 0.0, "avg_logprob": -0.26566200256347655, "compression_ratio": 1.551111111111111, "no_speech_prob": 2.8572530936799012e-06}, {"id": 333, "seek": 125716, "start": 1280.24, "end": 1283.96, "text": " come to appreciate how much potential Elm has.", "tokens": [808, 281, 4449, 577, 709, 3995, 2699, 76, 575, 13], "temperature": 0.0, "avg_logprob": -0.26566200256347655, "compression_ratio": 1.551111111111111, "no_speech_prob": 2.8572530936799012e-06}, {"id": 334, "seek": 128396, "start": 1283.96, "end": 1289.48, "text": " And it's a bit of a weird potential that you have, because you can say, oh well, JavaScript", "tokens": [400, 309, 311, 257, 857, 295, 257, 3657, 3995, 300, 291, 362, 11, 570, 291, 393, 584, 11, 1954, 731, 11, 15778], "temperature": 0.0, "avg_logprob": -0.2612765806692618, "compression_ratio": 1.7629310344827587, "no_speech_prob": 5.5074629017326515e-06}, {"id": 335, "seek": 128396, "start": 1289.48, "end": 1293.48, "text": " has plenty of potential, you can do plenty of amazing things, and that's true.", "tokens": [575, 7140, 295, 3995, 11, 291, 393, 360, 7140, 295, 2243, 721, 11, 293, 300, 311, 2074, 13], "temperature": 0.0, "avg_logprob": -0.2612765806692618, "compression_ratio": 1.7629310344827587, "no_speech_prob": 5.5074629017326515e-06}, {"id": 336, "seek": 128396, "start": 1293.48, "end": 1296.88, "text": " Rust has plenty of potential, etc.", "tokens": [34952, 575, 7140, 295, 3995, 11, 5183, 13], "temperature": 0.0, "avg_logprob": -0.2612765806692618, "compression_ratio": 1.7629310344827587, "no_speech_prob": 5.5074629017326515e-06}, {"id": 337, "seek": 128396, "start": 1296.88, "end": 1298.8, "text": " All those languages have them.", "tokens": [1057, 729, 8650, 362, 552, 13], "temperature": 0.0, "avg_logprob": -0.2612765806692618, "compression_ratio": 1.7629310344827587, "no_speech_prob": 5.5074629017326515e-06}, {"id": 338, "seek": 128396, "start": 1298.8, "end": 1304.48, "text": " But Elm's case is a bit particular, because for instance, for JavaScript, you're like,", "tokens": [583, 2699, 76, 311, 1389, 307, 257, 857, 1729, 11, 570, 337, 5197, 11, 337, 15778, 11, 291, 434, 411, 11], "temperature": 0.0, "avg_logprob": -0.2612765806692618, "compression_ratio": 1.7629310344827587, "no_speech_prob": 5.5074629017326515e-06}, {"id": 339, "seek": 128396, "start": 1304.48, "end": 1311.24, "text": " oh, JavaScript is amazing, and once we have async await, or whatever new feature that", "tokens": [1954, 11, 15778, 307, 2243, 11, 293, 1564, 321, 362, 382, 34015, 19670, 11, 420, 2035, 777, 4111, 300], "temperature": 0.0, "avg_logprob": -0.2612765806692618, "compression_ratio": 1.7629310344827587, "no_speech_prob": 5.5074629017326515e-06}, {"id": 340, "seek": 131124, "start": 1311.24, "end": 1315.52, "text": " was decided by a committee, it's going to be much more awesome, things are going to", "tokens": [390, 3047, 538, 257, 7482, 11, 309, 311, 516, 281, 312, 709, 544, 3476, 11, 721, 366, 516, 281], "temperature": 0.0, "avg_logprob": -0.21865145365397134, "compression_ratio": 1.7894736842105263, "no_speech_prob": 4.222708412271459e-06}, {"id": 341, "seek": 131124, "start": 1315.52, "end": 1320.96, "text": " be much easier, and you're going to be able to create very cool products with it or very", "tokens": [312, 709, 3571, 11, 293, 291, 434, 516, 281, 312, 1075, 281, 1884, 588, 1627, 3383, 365, 309, 420, 588], "temperature": 0.0, "avg_logprob": -0.21865145365397134, "compression_ratio": 1.7894736842105263, "no_speech_prob": 4.222708412271459e-06}, {"id": 342, "seek": 131124, "start": 1320.96, "end": 1322.92, "text": " cool tooling.", "tokens": [1627, 46593, 13], "temperature": 0.0, "avg_logprob": -0.21865145365397134, "compression_ratio": 1.7894736842105263, "no_speech_prob": 4.222708412271459e-06}, {"id": 343, "seek": 131124, "start": 1322.92, "end": 1327.92, "text": " And the Elm way, the way that Elm has potential is not that way.", "tokens": [400, 264, 2699, 76, 636, 11, 264, 636, 300, 2699, 76, 575, 3995, 307, 406, 300, 636, 13], "temperature": 0.0, "avg_logprob": -0.21865145365397134, "compression_ratio": 1.7894736842105263, "no_speech_prob": 4.222708412271459e-06}, {"id": 344, "seek": 131124, "start": 1327.92, "end": 1332.8, "text": " It's not like, oh, we're waiting on features that a committee has decided or that Evan", "tokens": [467, 311, 406, 411, 11, 1954, 11, 321, 434, 3806, 322, 4122, 300, 257, 7482, 575, 3047, 420, 300, 22613], "temperature": 0.0, "avg_logprob": -0.21865145365397134, "compression_ratio": 1.7894736842105263, "no_speech_prob": 4.222708412271459e-06}, {"id": 345, "seek": 131124, "start": 1332.8, "end": 1334.04, "text": " has decided.", "tokens": [575, 3047, 13], "temperature": 0.0, "avg_logprob": -0.21865145365397134, "compression_ratio": 1.7894736842105263, "no_speech_prob": 4.222708412271459e-06}, {"id": 346, "seek": 131124, "start": 1334.04, "end": 1340.8, "text": " It's more like, well, we see a lot of innovation because people push what they can do with", "tokens": [467, 311, 544, 411, 11, 731, 11, 321, 536, 257, 688, 295, 8504, 570, 561, 2944, 437, 436, 393, 360, 365], "temperature": 0.0, "avg_logprob": -0.21865145365397134, "compression_ratio": 1.7894736842105263, "no_speech_prob": 4.222708412271459e-06}, {"id": 347, "seek": 134080, "start": 1340.8, "end": 1341.8, "text": " Elm.", "tokens": [2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.22449074210701409, "compression_ratio": 1.5069124423963134, "no_speech_prob": 9.81819994194666e-06}, {"id": 348, "seek": 134080, "start": 1341.8, "end": 1345.96, "text": " And I'm just always amazed by what people do.", "tokens": [400, 286, 478, 445, 1009, 20507, 538, 437, 561, 360, 13], "temperature": 0.0, "avg_logprob": -0.22449074210701409, "compression_ratio": 1.5069124423963134, "no_speech_prob": 9.81819994194666e-06}, {"id": 349, "seek": 134080, "start": 1345.96, "end": 1352.12, "text": " And it's usually just relying on the design of the language, which is like pure functions", "tokens": [400, 309, 311, 2673, 445, 24140, 322, 264, 1715, 295, 264, 2856, 11, 597, 307, 411, 6075, 6828], "temperature": 0.0, "avg_logprob": -0.22449074210701409, "compression_ratio": 1.5069124423963134, "no_speech_prob": 9.81819994194666e-06}, {"id": 350, "seek": 134080, "start": 1352.12, "end": 1354.6, "text": " everywhere, immutable values everywhere.", "tokens": [5315, 11, 3397, 32148, 4190, 5315, 13], "temperature": 0.0, "avg_logprob": -0.22449074210701409, "compression_ratio": 1.5069124423963134, "no_speech_prob": 9.81819994194666e-06}, {"id": 351, "seek": 134080, "start": 1354.6, "end": 1358.56, "text": " And just from those tiny facts, you can do so much.", "tokens": [400, 445, 490, 729, 5870, 9130, 11, 291, 393, 360, 370, 709, 13], "temperature": 0.0, "avg_logprob": -0.22449074210701409, "compression_ratio": 1.5069124423963134, "no_speech_prob": 9.81819994194666e-06}, {"id": 352, "seek": 134080, "start": 1358.56, "end": 1366.96, "text": " Like ElmReview, great tool, but it's great because it has a language that is very analyzable.", "tokens": [1743, 2699, 76, 8524, 1759, 11, 869, 2290, 11, 457, 309, 311, 869, 570, 309, 575, 257, 2856, 300, 307, 588, 6459, 89, 712, 13], "temperature": 0.0, "avg_logprob": -0.22449074210701409, "compression_ratio": 1.5069124423963134, "no_speech_prob": 9.81819994194666e-06}, {"id": 353, "seek": 136696, "start": 1366.96, "end": 1373.16, "text": " And if a value doesn't appear anywhere, then you can just remove it.", "tokens": [400, 498, 257, 2158, 1177, 380, 4204, 4992, 11, 550, 291, 393, 445, 4159, 309, 13], "temperature": 0.0, "avg_logprob": -0.25991913580125375, "compression_ratio": 1.6213592233009708, "no_speech_prob": 1.0348493333367514e-06}, {"id": 354, "seek": 136696, "start": 1373.16, "end": 1374.16, "text": " Easy as that.", "tokens": [16002, 382, 300, 13], "temperature": 0.0, "avg_logprob": -0.25991913580125375, "compression_ratio": 1.6213592233009708, "no_speech_prob": 1.0348493333367514e-06}, {"id": 355, "seek": 136696, "start": 1374.16, "end": 1380.44, "text": " Lambdara, for instance, has like, well, we're just writing Elm code.", "tokens": [45691, 424, 11, 337, 5197, 11, 575, 411, 11, 731, 11, 321, 434, 445, 3579, 2699, 76, 3089, 13], "temperature": 0.0, "avg_logprob": -0.25991913580125375, "compression_ratio": 1.6213592233009708, "no_speech_prob": 1.0348493333367514e-06}, {"id": 356, "seek": 136696, "start": 1380.44, "end": 1387.96, "text": " And because Elm code is just plain data, we can just send them over the wire from the", "tokens": [400, 570, 2699, 76, 3089, 307, 445, 11121, 1412, 11, 321, 393, 445, 2845, 552, 670, 264, 6234, 490, 264], "temperature": 0.0, "avg_logprob": -0.25991913580125375, "compression_ratio": 1.6213592233009708, "no_speech_prob": 1.0348493333367514e-06}, {"id": 357, "seek": 136696, "start": 1387.96, "end": 1392.92, "text": " front end to the back end and back end to the front end, maybe with some additional", "tokens": [1868, 917, 281, 264, 646, 917, 293, 646, 917, 281, 264, 1868, 917, 11, 1310, 365, 512, 4497], "temperature": 0.0, "avg_logprob": -0.25991913580125375, "compression_ratio": 1.6213592233009708, "no_speech_prob": 1.0348493333367514e-06}, {"id": 358, "seek": 136696, "start": 1392.92, "end": 1393.92, "text": " limitations.", "tokens": [15705, 13], "temperature": 0.0, "avg_logprob": -0.25991913580125375, "compression_ratio": 1.6213592233009708, "no_speech_prob": 1.0348493333367514e-06}, {"id": 359, "seek": 139392, "start": 1393.92, "end": 1401.16, "text": " But you can basically just write Elm and you have now an amazing experience writing front", "tokens": [583, 291, 393, 1936, 445, 2464, 2699, 76, 293, 291, 362, 586, 364, 2243, 1752, 3579, 1868], "temperature": 0.0, "avg_logprob": -0.2134128146701389, "compression_ratio": 1.7081712062256809, "no_speech_prob": 3.785218268603785e-06}, {"id": 360, "seek": 139392, "start": 1401.16, "end": 1407.16, "text": " end and back end languages with hosting and backups and all that.", "tokens": [917, 293, 646, 917, 8650, 365, 16058, 293, 50160, 293, 439, 300, 13], "temperature": 0.0, "avg_logprob": -0.2134128146701389, "compression_ratio": 1.7081712062256809, "no_speech_prob": 3.785218268603785e-06}, {"id": 361, "seek": 139392, "start": 1407.16, "end": 1412.96, "text": " And it's only because we're pushing on the things that Elm gives us, not because we're", "tokens": [400, 309, 311, 787, 570, 321, 434, 7380, 322, 264, 721, 300, 2699, 76, 2709, 505, 11, 406, 570, 321, 434], "temperature": 0.0, "avg_logprob": -0.2134128146701389, "compression_ratio": 1.7081712062256809, "no_speech_prob": 3.785218268603785e-06}, {"id": 362, "seek": 139392, "start": 1412.96, "end": 1416.2, "text": " expecting new features to arrive to the language.", "tokens": [9650, 777, 4122, 281, 8881, 281, 264, 2856, 13], "temperature": 0.0, "avg_logprob": -0.2134128146701389, "compression_ratio": 1.7081712062256809, "no_speech_prob": 3.785218268603785e-06}, {"id": 363, "seek": 139392, "start": 1416.2, "end": 1419.66, "text": " And that's something that I haven't found anywhere else.", "tokens": [400, 300, 311, 746, 300, 286, 2378, 380, 1352, 4992, 1646, 13], "temperature": 0.0, "avg_logprob": -0.2134128146701389, "compression_ratio": 1.7081712062256809, "no_speech_prob": 3.785218268603785e-06}, {"id": 364, "seek": 139392, "start": 1419.66, "end": 1423.72, "text": " So that's one of the reasons why I really care about Elm, is I just see so much potential", "tokens": [407, 300, 311, 472, 295, 264, 4112, 983, 286, 534, 1127, 466, 2699, 76, 11, 307, 286, 445, 536, 370, 709, 3995], "temperature": 0.0, "avg_logprob": -0.2134128146701389, "compression_ratio": 1.7081712062256809, "no_speech_prob": 3.785218268603785e-06}, {"id": 365, "seek": 142372, "start": 1423.72, "end": 1428.88, "text": " and it's not even like because I see it, like I can think of it.", "tokens": [293, 309, 311, 406, 754, 411, 570, 286, 536, 309, 11, 411, 286, 393, 519, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.29634071576713333, "compression_ratio": 1.6342592592592593, "no_speech_prob": 3.966896656493191e-06}, {"id": 366, "seek": 142372, "start": 1428.88, "end": 1434.96, "text": " It's like I know that people will make more things because they just keep happening.", "tokens": [467, 311, 411, 286, 458, 300, 561, 486, 652, 544, 721, 570, 436, 445, 1066, 2737, 13], "temperature": 0.0, "avg_logprob": -0.29634071576713333, "compression_ratio": 1.6342592592592593, "no_speech_prob": 3.966896656493191e-06}, {"id": 367, "seek": 142372, "start": 1434.96, "end": 1436.56, "text": " Yeah, right.", "tokens": [865, 11, 558, 13], "temperature": 0.0, "avg_logprob": -0.29634071576713333, "compression_ratio": 1.6342592592592593, "no_speech_prob": 3.966896656493191e-06}, {"id": 368, "seek": 142372, "start": 1436.56, "end": 1438.4, "text": " That resonates with me a lot too.", "tokens": [663, 41051, 365, 385, 257, 688, 886, 13], "temperature": 0.0, "avg_logprob": -0.29634071576713333, "compression_ratio": 1.6342592592592593, "no_speech_prob": 3.966896656493191e-06}, {"id": 369, "seek": 142372, "start": 1438.4, "end": 1446.68, "text": " Like because, yeah, as you say, it's not just like what got you in the door, but then what", "tokens": [1743, 570, 11, 1338, 11, 382, 291, 584, 11, 309, 311, 406, 445, 411, 437, 658, 291, 294, 264, 2853, 11, 457, 550, 437], "temperature": 0.0, "avg_logprob": -0.29634071576713333, "compression_ratio": 1.6342592592592593, "no_speech_prob": 3.966896656493191e-06}, {"id": 370, "seek": 142372, "start": 1446.68, "end": 1450.84, "text": " makes you see the long term vision that you want to be a part of?", "tokens": [1669, 291, 536, 264, 938, 1433, 5201, 300, 291, 528, 281, 312, 257, 644, 295, 30], "temperature": 0.0, "avg_logprob": -0.29634071576713333, "compression_ratio": 1.6342592592592593, "no_speech_prob": 3.966896656493191e-06}, {"id": 371, "seek": 145084, "start": 1450.84, "end": 1454.52, "text": " And I think we both are really invested in that.", "tokens": [400, 286, 519, 321, 1293, 366, 534, 13104, 294, 300, 13], "temperature": 0.0, "avg_logprob": -0.28767683029174806, "compression_ratio": 1.567099567099567, "no_speech_prob": 1.061510465660831e-05}, {"id": 372, "seek": 145084, "start": 1454.52, "end": 1462.8, "text": " And it is, like you say, because I mean, you know, Elm Tailwind modules and Lambdaera and", "tokens": [400, 309, 307, 11, 411, 291, 584, 11, 570, 286, 914, 11, 291, 458, 11, 2699, 76, 46074, 12199, 16679, 293, 45691, 1663, 293], "temperature": 0.0, "avg_logprob": -0.28767683029174806, "compression_ratio": 1.567099567099567, "no_speech_prob": 1.061510465660831e-05}, {"id": 373, "seek": 145084, "start": 1462.8, "end": 1467.36, "text": " you know, Elm UI and all these like innovative approaches.", "tokens": [291, 458, 11, 2699, 76, 15682, 293, 439, 613, 411, 12999, 11587, 13], "temperature": 0.0, "avg_logprob": -0.28767683029174806, "compression_ratio": 1.567099567099567, "no_speech_prob": 1.061510465660831e-05}, {"id": 374, "seek": 145084, "start": 1467.36, "end": 1472.4399999999998, "text": " I mean, Elm format, it just like it feels like there's also an ethos in the community", "tokens": [286, 914, 11, 2699, 76, 7877, 11, 309, 445, 411, 309, 3417, 411, 456, 311, 611, 364, 6468, 329, 294, 264, 1768], "temperature": 0.0, "avg_logprob": -0.28767683029174806, "compression_ratio": 1.567099567099567, "no_speech_prob": 1.061510465660831e-05}, {"id": 375, "seek": 145084, "start": 1472.4399999999998, "end": 1476.56, "text": " of being willing to think things up from first principles.", "tokens": [295, 885, 4950, 281, 519, 721, 493, 490, 700, 9156, 13], "temperature": 0.0, "avg_logprob": -0.28767683029174806, "compression_ratio": 1.567099567099567, "no_speech_prob": 1.061510465660831e-05}, {"id": 376, "seek": 145084, "start": 1476.56, "end": 1478.1599999999999, "text": " That's really cool.", "tokens": [663, 311, 534, 1627, 13], "temperature": 0.0, "avg_logprob": -0.28767683029174806, "compression_ratio": 1.567099567099567, "no_speech_prob": 1.061510465660831e-05}, {"id": 377, "seek": 147816, "start": 1478.16, "end": 1484.4, "text": " But thinking things up from first principles while also being very pragmatic and user focused.", "tokens": [583, 1953, 721, 493, 490, 700, 9156, 1339, 611, 885, 588, 46904, 293, 4195, 5178, 13], "temperature": 0.0, "avg_logprob": -0.20892186031163296, "compression_ratio": 1.6398467432950192, "no_speech_prob": 1.3006303561269306e-05}, {"id": 378, "seek": 147816, "start": 1484.4, "end": 1485.88, "text": " And I think that's pretty remarkable.", "tokens": [400, 286, 519, 300, 311, 1238, 12802, 13], "temperature": 0.0, "avg_logprob": -0.20892186031163296, "compression_ratio": 1.6398467432950192, "no_speech_prob": 1.3006303561269306e-05}, {"id": 379, "seek": 147816, "start": 1485.88, "end": 1493.4, "text": " Yeah, Elm's design has a lot of things going for it, where we're able to mix a very simple", "tokens": [865, 11, 2699, 76, 311, 1715, 575, 257, 688, 295, 721, 516, 337, 309, 11, 689, 321, 434, 1075, 281, 2890, 257, 588, 2199], "temperature": 0.0, "avg_logprob": -0.20892186031163296, "compression_ratio": 1.6398467432950192, "no_speech_prob": 1.3006303561269306e-05}, {"id": 380, "seek": 147816, "start": 1493.4, "end": 1498.5600000000002, "text": " language with very strong guarantees to get a lot of things out of it.", "tokens": [2856, 365, 588, 2068, 32567, 281, 483, 257, 688, 295, 721, 484, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.20892186031163296, "compression_ratio": 1.6398467432950192, "no_speech_prob": 1.3006303561269306e-05}, {"id": 381, "seek": 147816, "start": 1498.5600000000002, "end": 1502.0800000000002, "text": " So we have a simple language that is easy to teach.", "tokens": [407, 321, 362, 257, 2199, 2856, 300, 307, 1858, 281, 2924, 13], "temperature": 0.0, "avg_logprob": -0.20892186031163296, "compression_ratio": 1.6398467432950192, "no_speech_prob": 1.3006303561269306e-05}, {"id": 382, "seek": 147816, "start": 1502.0800000000002, "end": 1506.3400000000001, "text": " Like people always tell you, oh, there's a learning curve because it's different.", "tokens": [1743, 561, 1009, 980, 291, 11, 1954, 11, 456, 311, 257, 2539, 7605, 570, 309, 311, 819, 13], "temperature": 0.0, "avg_logprob": -0.20892186031163296, "compression_ratio": 1.6398467432950192, "no_speech_prob": 1.3006303561269306e-05}, {"id": 383, "seek": 150634, "start": 1506.34, "end": 1512.58, "text": " But in practice, Elm is still a very simple language, especially for a functional one.", "tokens": [583, 294, 3124, 11, 2699, 76, 307, 920, 257, 588, 2199, 2856, 11, 2318, 337, 257, 11745, 472, 13], "temperature": 0.0, "avg_logprob": -0.23257084381886017, "compression_ratio": 1.6904761904761905, "no_speech_prob": 2.3319723823078675e-06}, {"id": 384, "seek": 150634, "start": 1512.58, "end": 1518.1799999999998, "text": " It's teachable, it's analyzable for Elm review, for people reviewing the code.", "tokens": [467, 311, 2924, 712, 11, 309, 311, 6459, 89, 712, 337, 2699, 76, 3131, 11, 337, 561, 19576, 264, 3089, 13], "temperature": 0.0, "avg_logprob": -0.23257084381886017, "compression_ratio": 1.6904761904761905, "no_speech_prob": 2.3319723823078675e-06}, {"id": 385, "seek": 150634, "start": 1518.1799999999998, "end": 1519.3999999999999, "text": " It's pretty fast.", "tokens": [467, 311, 1238, 2370, 13], "temperature": 0.0, "avg_logprob": -0.23257084381886017, "compression_ratio": 1.6904761904761905, "no_speech_prob": 2.3319723823078675e-06}, {"id": 386, "seek": 150634, "start": 1519.3999999999999, "end": 1525.04, "text": " It's super maintainable because of pure functional features and immutable.", "tokens": [467, 311, 1687, 6909, 712, 570, 295, 6075, 11745, 4122, 293, 3397, 32148, 13], "temperature": 0.0, "avg_logprob": -0.23257084381886017, "compression_ratio": 1.6904761904761905, "no_speech_prob": 2.3319723823078675e-06}, {"id": 387, "seek": 150634, "start": 1525.04, "end": 1527.4399999999998, "text": " And all of that, it goes well together.", "tokens": [400, 439, 295, 300, 11, 309, 1709, 731, 1214, 13], "temperature": 0.0, "avg_logprob": -0.23257084381886017, "compression_ratio": 1.6904761904761905, "no_speech_prob": 2.3319723823078675e-06}, {"id": 388, "seek": 150634, "start": 1527.4399999999998, "end": 1531.6799999999998, "text": " And you add to that, like all the things that you can get out of that.", "tokens": [400, 291, 909, 281, 300, 11, 411, 439, 264, 721, 300, 291, 393, 483, 484, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.23257084381886017, "compression_ratio": 1.6904761904761905, "no_speech_prob": 2.3319723823078675e-06}, {"id": 389, "seek": 150634, "start": 1531.6799999999998, "end": 1535.1599999999999, "text": " And it's just the result is just amazing, in my opinion.", "tokens": [400, 309, 311, 445, 264, 1874, 307, 445, 2243, 11, 294, 452, 4800, 13], "temperature": 0.0, "avg_logprob": -0.23257084381886017, "compression_ratio": 1.6904761904761905, "no_speech_prob": 2.3319723823078675e-06}, {"id": 390, "seek": 153516, "start": 1535.16, "end": 1538.48, "text": " That's why I stay here, because I see some potential.", "tokens": [663, 311, 983, 286, 1754, 510, 11, 570, 286, 536, 512, 3995, 13], "temperature": 0.0, "avg_logprob": -0.2265890138643282, "compression_ratio": 1.6511627906976745, "no_speech_prob": 1.8918277419288643e-05}, {"id": 391, "seek": 153516, "start": 1538.48, "end": 1540.6000000000001, "text": " I don't know what people will come up with.", "tokens": [286, 500, 380, 458, 437, 561, 486, 808, 493, 365, 13], "temperature": 0.0, "avg_logprob": -0.2265890138643282, "compression_ratio": 1.6511627906976745, "no_speech_prob": 1.8918277419288643e-05}, {"id": 392, "seek": 153516, "start": 1540.6000000000001, "end": 1542.16, "text": " I'm very excited to see things.", "tokens": [286, 478, 588, 2919, 281, 536, 721, 13], "temperature": 0.0, "avg_logprob": -0.2265890138643282, "compression_ratio": 1.6511627906976745, "no_speech_prob": 1.8918277419288643e-05}, {"id": 393, "seek": 153516, "start": 1542.16, "end": 1548.52, "text": " I see other languages, like for instance, Rust is an amazing choice for plenty of projects", "tokens": [286, 536, 661, 8650, 11, 411, 337, 5197, 11, 34952, 307, 364, 2243, 3922, 337, 7140, 295, 4455], "temperature": 0.0, "avg_logprob": -0.2265890138643282, "compression_ratio": 1.6511627906976745, "no_speech_prob": 1.8918277419288643e-05}, {"id": 394, "seek": 153516, "start": 1548.52, "end": 1549.96, "text": " at the moment.", "tokens": [412, 264, 1623, 13], "temperature": 0.0, "avg_logprob": -0.2265890138643282, "compression_ratio": 1.6511627906976745, "no_speech_prob": 1.8918277419288643e-05}, {"id": 395, "seek": 153516, "start": 1549.96, "end": 1556.8400000000001, "text": " And it's trying to improve the status quo compared to other languages or frameworks", "tokens": [400, 309, 311, 1382, 281, 3470, 264, 6558, 28425, 5347, 281, 661, 8650, 420, 29834], "temperature": 0.0, "avg_logprob": -0.2265890138643282, "compression_ratio": 1.6511627906976745, "no_speech_prob": 1.8918277419288643e-05}, {"id": 396, "seek": 153516, "start": 1556.8400000000001, "end": 1558.68, "text": " that are in the same space.", "tokens": [300, 366, 294, 264, 912, 1901, 13], "temperature": 0.0, "avg_logprob": -0.2265890138643282, "compression_ratio": 1.6511627906976745, "no_speech_prob": 1.8918277419288643e-05}, {"id": 397, "seek": 153516, "start": 1558.68, "end": 1564.96, "text": " So mostly about memory and performance, it's trying to be really good at that.", "tokens": [407, 5240, 466, 4675, 293, 3389, 11, 309, 311, 1382, 281, 312, 534, 665, 412, 300, 13], "temperature": 0.0, "avg_logprob": -0.2265890138643282, "compression_ratio": 1.6511627906976745, "no_speech_prob": 1.8918277419288643e-05}, {"id": 398, "seek": 156496, "start": 1564.96, "end": 1570.16, "text": " And other languages do the same thing, like F sharp is an improvement over C sharp because", "tokens": [400, 661, 8650, 360, 264, 912, 551, 11, 411, 479, 8199, 307, 364, 10444, 670, 383, 8199, 570], "temperature": 0.0, "avg_logprob": -0.3487803268432617, "compression_ratio": 1.6991150442477876, "no_speech_prob": 2.429615233268123e-05}, {"id": 399, "seek": 156496, "start": 1570.16, "end": 1572.24, "text": " of improvements.", "tokens": [295, 13797, 13], "temperature": 0.0, "avg_logprob": -0.3487803268432617, "compression_ratio": 1.6991150442477876, "no_speech_prob": 2.429615233268123e-05}, {"id": 400, "seek": 156496, "start": 1572.24, "end": 1573.76, "text": " It's a different approach.", "tokens": [467, 311, 257, 819, 3109, 13], "temperature": 0.0, "avg_logprob": -0.3487803268432617, "compression_ratio": 1.6991150442477876, "no_speech_prob": 2.429615233268123e-05}, {"id": 401, "seek": 156496, "start": 1573.76, "end": 1581.1200000000001, "text": " And you've got other languages like Rescript or Reason, I still don't remember the name,", "tokens": [400, 291, 600, 658, 661, 8650, 411, 5015, 5944, 420, 39693, 11, 286, 920, 500, 380, 1604, 264, 1315, 11], "temperature": 0.0, "avg_logprob": -0.3487803268432617, "compression_ratio": 1.6991150442477876, "no_speech_prob": 2.429615233268123e-05}, {"id": 402, "seek": 156496, "start": 1581.1200000000001, "end": 1587.64, "text": " Grain, Glean, they all try to improve the status quo, improve things compared to JavaScript,", "tokens": [460, 7146, 11, 460, 28499, 11, 436, 439, 853, 281, 3470, 264, 6558, 28425, 11, 3470, 721, 5347, 281, 15778, 11], "temperature": 0.0, "avg_logprob": -0.3487803268432617, "compression_ratio": 1.6991150442477876, "no_speech_prob": 2.429615233268123e-05}, {"id": 403, "seek": 156496, "start": 1587.64, "end": 1589.44, "text": " compared to other languages.", "tokens": [5347, 281, 661, 8650, 13], "temperature": 0.0, "avg_logprob": -0.3487803268432617, "compression_ratio": 1.6991150442477876, "no_speech_prob": 2.429615233268123e-05}, {"id": 404, "seek": 156496, "start": 1589.44, "end": 1593.52, "text": " But they never go as deep as Elm goes.", "tokens": [583, 436, 1128, 352, 382, 2452, 382, 2699, 76, 1709, 13], "temperature": 0.0, "avg_logprob": -0.3487803268432617, "compression_ratio": 1.6991150442477876, "no_speech_prob": 2.429615233268123e-05}, {"id": 405, "seek": 159352, "start": 1593.52, "end": 1601.68, "text": " Like it's always like, well, F sharp is, if you're a functional, it's a functional language,", "tokens": [1743, 309, 311, 1009, 411, 11, 731, 11, 479, 8199, 307, 11, 498, 291, 434, 257, 11745, 11, 309, 311, 257, 11745, 2856, 11], "temperature": 0.0, "avg_logprob": -0.30631377849173036, "compression_ratio": 1.5685279187817258, "no_speech_prob": 2.726358388827066e-06}, {"id": 406, "seek": 159352, "start": 1601.68, "end": 1605.52, "text": " we're not going to go deep into purity.", "tokens": [321, 434, 406, 516, 281, 352, 2452, 666, 34382, 13], "temperature": 0.0, "avg_logprob": -0.30631377849173036, "compression_ratio": 1.5685279187817258, "no_speech_prob": 2.726358388827066e-06}, {"id": 407, "seek": 159352, "start": 1605.52, "end": 1613.72, "text": " Glean is like, well, we're going to be pretty much just like Elm, but we have FFI with Erlang", "tokens": [460, 28499, 307, 411, 11, 731, 11, 321, 434, 516, 281, 312, 1238, 709, 445, 411, 2699, 76, 11, 457, 321, 362, 479, 38568, 365, 3300, 25241], "temperature": 0.0, "avg_logprob": -0.30631377849173036, "compression_ratio": 1.5685279187817258, "no_speech_prob": 2.726358388827066e-06}, {"id": 408, "seek": 159352, "start": 1613.72, "end": 1615.16, "text": " things.", "tokens": [721, 13], "temperature": 0.0, "avg_logprob": -0.30631377849173036, "compression_ratio": 1.5685279187817258, "no_speech_prob": 2.726358388827066e-06}, {"id": 409, "seek": 159352, "start": 1615.16, "end": 1621.68, "text": " And you lose some of the guarantees that Elm has, or the Elm approach has.", "tokens": [400, 291, 3624, 512, 295, 264, 32567, 300, 2699, 76, 575, 11, 420, 264, 2699, 76, 3109, 575, 13], "temperature": 0.0, "avg_logprob": -0.30631377849173036, "compression_ratio": 1.5685279187817258, "no_speech_prob": 2.726358388827066e-06}, {"id": 410, "seek": 162168, "start": 1621.68, "end": 1628.44, "text": " And I'm like, well, it's a shame because you lose so much by doing that.", "tokens": [400, 286, 478, 411, 11, 731, 11, 309, 311, 257, 10069, 570, 291, 3624, 370, 709, 538, 884, 300, 13], "temperature": 0.0, "avg_logprob": -0.2602631212717079, "compression_ratio": 1.4473684210526316, "no_speech_prob": 2.60150386566238e-06}, {"id": 411, "seek": 162168, "start": 1628.44, "end": 1629.44, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.2602631212717079, "compression_ratio": 1.4473684210526316, "no_speech_prob": 2.60150386566238e-06}, {"id": 412, "seek": 162168, "start": 1629.44, "end": 1634.3600000000001, "text": " The difference between a, I mean, a 99% guarantee isn't a guarantee, right?", "tokens": [440, 2649, 1296, 257, 11, 286, 914, 11, 257, 11803, 4, 10815, 1943, 380, 257, 10815, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2602631212717079, "compression_ratio": 1.4473684210526316, "no_speech_prob": 2.60150386566238e-06}, {"id": 413, "seek": 162168, "start": 1634.3600000000001, "end": 1638.3600000000001, "text": " And it just, it feels different.", "tokens": [400, 309, 445, 11, 309, 3417, 819, 13], "temperature": 0.0, "avg_logprob": -0.2602631212717079, "compression_ratio": 1.4473684210526316, "no_speech_prob": 2.60150386566238e-06}, {"id": 414, "seek": 162168, "start": 1638.3600000000001, "end": 1644.5600000000002, "text": " You know, not to say that it's not a valid approach with benefits to say, I want to make", "tokens": [509, 458, 11, 406, 281, 584, 300, 309, 311, 406, 257, 7363, 3109, 365, 5311, 281, 584, 11, 286, 528, 281, 652], "temperature": 0.0, "avg_logprob": -0.2602631212717079, "compression_ratio": 1.4473684210526316, "no_speech_prob": 2.60150386566238e-06}, {"id": 415, "seek": 164456, "start": 1644.56, "end": 1652.9199999999998, "text": " the set of trade-offs where I can do FFI with these other languages, or, you know, I want", "tokens": [264, 992, 295, 4923, 12, 19231, 689, 286, 393, 360, 479, 38568, 365, 613, 661, 8650, 11, 420, 11, 291, 458, 11, 286, 528], "temperature": 0.0, "avg_logprob": -0.19421735176673302, "compression_ratio": 1.6238938053097345, "no_speech_prob": 1.1910901775991078e-06}, {"id": 416, "seek": 164456, "start": 1652.9199999999998, "end": 1659.0, "text": " to just write in JavaScript, or I want to use Rescript and be able to directly call", "tokens": [281, 445, 2464, 294, 15778, 11, 420, 286, 528, 281, 764, 5015, 5944, 293, 312, 1075, 281, 3838, 818], "temperature": 0.0, "avg_logprob": -0.19421735176673302, "compression_ratio": 1.6238938053097345, "no_speech_prob": 1.1910901775991078e-06}, {"id": 417, "seek": 164456, "start": 1659.0, "end": 1662.96, "text": " JavaScript and wrap things with their FFI wrappers.", "tokens": [15778, 293, 7019, 721, 365, 641, 479, 38568, 7843, 15226, 13], "temperature": 0.0, "avg_logprob": -0.19421735176673302, "compression_ratio": 1.6238938053097345, "no_speech_prob": 1.1910901775991078e-06}, {"id": 418, "seek": 164456, "start": 1662.96, "end": 1663.96, "text": " That's great.", "tokens": [663, 311, 869, 13], "temperature": 0.0, "avg_logprob": -0.19421735176673302, "compression_ratio": 1.6238938053097345, "no_speech_prob": 1.1910901775991078e-06}, {"id": 419, "seek": 164456, "start": 1663.96, "end": 1667.44, "text": " Like, that's a totally valid set of trade-offs.", "tokens": [1743, 11, 300, 311, 257, 3879, 7363, 992, 295, 4923, 12, 19231, 13], "temperature": 0.0, "avg_logprob": -0.19421735176673302, "compression_ratio": 1.6238938053097345, "no_speech_prob": 1.1910901775991078e-06}, {"id": 420, "seek": 164456, "start": 1667.44, "end": 1673.6, "text": " It's just a very different set of things that fall out of that compared to Elm.", "tokens": [467, 311, 445, 257, 588, 819, 992, 295, 721, 300, 2100, 484, 295, 300, 5347, 281, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.19421735176673302, "compression_ratio": 1.6238938053097345, "no_speech_prob": 1.1910901775991078e-06}, {"id": 421, "seek": 167360, "start": 1673.6, "end": 1679.84, "text": " And I think you and I really find it a compelling vision when you say, let's make that drastic", "tokens": [400, 286, 519, 291, 293, 286, 534, 915, 309, 257, 20050, 5201, 562, 291, 584, 11, 718, 311, 652, 300, 36821], "temperature": 0.0, "avg_logprob": -0.1938360021748674, "compression_ratio": 1.6745283018867925, "no_speech_prob": 1.1659208212222438e-05}, {"id": 422, "seek": 167360, "start": 1679.84, "end": 1680.84, "text": " choice.", "tokens": [3922, 13], "temperature": 0.0, "avg_logprob": -0.1938360021748674, "compression_ratio": 1.6745283018867925, "no_speech_prob": 1.1659208212222438e-05}, {"id": 423, "seek": 167360, "start": 1680.84, "end": 1686.32, "text": " And, you know, as you're saying, like, I think the thing about Elm, it's not, it's not about", "tokens": [400, 11, 291, 458, 11, 382, 291, 434, 1566, 11, 411, 11, 286, 519, 264, 551, 466, 2699, 76, 11, 309, 311, 406, 11, 309, 311, 406, 466], "temperature": 0.0, "avg_logprob": -0.1938360021748674, "compression_ratio": 1.6745283018867925, "no_speech_prob": 1.1659208212222438e-05}, {"id": 424, "seek": 167360, "start": 1686.32, "end": 1687.32, "text": " what Elm adds.", "tokens": [437, 2699, 76, 10860, 13], "temperature": 0.0, "avg_logprob": -0.1938360021748674, "compression_ratio": 1.6745283018867925, "no_speech_prob": 1.1659208212222438e-05}, {"id": 425, "seek": 167360, "start": 1687.32, "end": 1689.84, "text": " It's about what Elm has removed.", "tokens": [467, 311, 466, 437, 2699, 76, 575, 7261, 13], "temperature": 0.0, "avg_logprob": -0.1938360021748674, "compression_ratio": 1.6745283018867925, "no_speech_prob": 1.1659208212222438e-05}, {"id": 426, "seek": 167360, "start": 1689.84, "end": 1695.12, "text": " And it's removed these things that you, that give you guarantees.", "tokens": [400, 309, 311, 7261, 613, 721, 300, 291, 11, 300, 976, 291, 32567, 13], "temperature": 0.0, "avg_logprob": -0.1938360021748674, "compression_ratio": 1.6745283018867925, "no_speech_prob": 1.1659208212222438e-05}, {"id": 427, "seek": 167360, "start": 1695.12, "end": 1697.4399999999998, "text": " So now you can say, well, this is all I have.", "tokens": [407, 586, 291, 393, 584, 11, 731, 11, 341, 307, 439, 286, 362, 13], "temperature": 0.0, "avg_logprob": -0.1938360021748674, "compression_ratio": 1.6745283018867925, "no_speech_prob": 1.1659208212222438e-05}, {"id": 428, "seek": 169744, "start": 1697.44, "end": 1703.88, "text": " I have custom types and pure functions and immutable values.", "tokens": [286, 362, 2375, 3467, 293, 6075, 6828, 293, 3397, 32148, 4190, 13], "temperature": 0.0, "avg_logprob": -0.21055625688911664, "compression_ratio": 1.6406926406926408, "no_speech_prob": 2.5215313144144602e-06}, {"id": 429, "seek": 169744, "start": 1703.88, "end": 1710.52, "text": " And that's, if that's all there is, then I can make so many assumptions and I can have", "tokens": [400, 300, 311, 11, 498, 300, 311, 439, 456, 307, 11, 550, 286, 393, 652, 370, 867, 17695, 293, 286, 393, 362], "temperature": 0.0, "avg_logprob": -0.21055625688911664, "compression_ratio": 1.6406926406926408, "no_speech_prob": 2.5215313144144602e-06}, {"id": 430, "seek": 169744, "start": 1710.52, "end": 1714.64, "text": " so many guarantees and I can build such interesting tools to use that.", "tokens": [370, 867, 32567, 293, 286, 393, 1322, 1270, 1880, 3873, 281, 764, 300, 13], "temperature": 0.0, "avg_logprob": -0.21055625688911664, "compression_ratio": 1.6406926406926408, "no_speech_prob": 2.5215313144144602e-06}, {"id": 431, "seek": 169744, "start": 1714.64, "end": 1719.44, "text": " I don't even know if I was like a tooling person before I got into Elm.", "tokens": [286, 500, 380, 754, 458, 498, 286, 390, 411, 257, 46593, 954, 949, 286, 658, 666, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.21055625688911664, "compression_ratio": 1.6406926406926408, "no_speech_prob": 2.5215313144144602e-06}, {"id": 432, "seek": 169744, "start": 1719.44, "end": 1724.24, "text": " Like I feel like Elm really changed that about me where it, I mean, in my coaching days,", "tokens": [1743, 286, 841, 411, 2699, 76, 534, 3105, 300, 466, 385, 689, 309, 11, 286, 914, 11, 294, 452, 15818, 1708, 11], "temperature": 0.0, "avg_logprob": -0.21055625688911664, "compression_ratio": 1.6406926406926408, "no_speech_prob": 2.5215313144144602e-06}, {"id": 433, "seek": 172424, "start": 1724.24, "end": 1727.56, "text": " I really saw the power of good tools.", "tokens": [286, 534, 1866, 264, 1347, 295, 665, 3873, 13], "temperature": 0.0, "avg_logprob": -0.18666256064235573, "compression_ratio": 1.7857142857142858, "no_speech_prob": 1.9033434455195675e-06}, {"id": 434, "seek": 172424, "start": 1727.56, "end": 1733.28, "text": " And I realized that if you're really good at editor tools, it's not, it's not a fun", "tokens": [400, 286, 5334, 300, 498, 291, 434, 534, 665, 412, 9839, 3873, 11, 309, 311, 406, 11, 309, 311, 406, 257, 1019], "temperature": 0.0, "avg_logprob": -0.18666256064235573, "compression_ratio": 1.7857142857142858, "no_speech_prob": 1.9033434455195675e-06}, {"id": 435, "seek": 172424, "start": 1733.28, "end": 1734.28, "text": " toy.", "tokens": [12058, 13], "temperature": 0.0, "avg_logprob": -0.18666256064235573, "compression_ratio": 1.7857142857142858, "no_speech_prob": 1.9033434455195675e-06}, {"id": 436, "seek": 172424, "start": 1734.28, "end": 1738.48, "text": " It is like a very powerful tool that transforms you as a developer.", "tokens": [467, 307, 411, 257, 588, 4005, 2290, 300, 35592, 291, 382, 257, 10754, 13], "temperature": 0.0, "avg_logprob": -0.18666256064235573, "compression_ratio": 1.7857142857142858, "no_speech_prob": 1.9033434455195675e-06}, {"id": 437, "seek": 172424, "start": 1738.48, "end": 1744.68, "text": " I think like, I think if you're able to navigate around refactoring tools and work, I find", "tokens": [286, 519, 411, 11, 286, 519, 498, 291, 434, 1075, 281, 12350, 926, 1895, 578, 3662, 3873, 293, 589, 11, 286, 915], "temperature": 0.0, "avg_logprob": -0.18666256064235573, "compression_ratio": 1.7857142857142858, "no_speech_prob": 1.9033434455195675e-06}, {"id": 438, "seek": 172424, "start": 1744.68, "end": 1749.44, "text": " that so powerful, like working with guaranteed refactorings, which like if you're working", "tokens": [300, 370, 4005, 11, 411, 1364, 365, 18031, 1895, 15104, 1109, 11, 597, 411, 498, 291, 434, 1364], "temperature": 0.0, "avg_logprob": -0.18666256064235573, "compression_ratio": 1.7857142857142858, "no_speech_prob": 1.9033434455195675e-06}, {"id": 439, "seek": 174944, "start": 1749.44, "end": 1755.8400000000001, "text": " with Java or Kotlin, it's like really powerful what you can do just working with like refactoring", "tokens": [365, 10745, 420, 30123, 5045, 11, 309, 311, 411, 534, 4005, 437, 291, 393, 360, 445, 1364, 365, 411, 1895, 578, 3662], "temperature": 0.0, "avg_logprob": -0.2036357133284859, "compression_ratio": 1.6203703703703705, "no_speech_prob": 1.30817227272928e-06}, {"id": 440, "seek": 174944, "start": 1755.8400000000001, "end": 1758.3200000000002, "text": " operations that you can trust.", "tokens": [7705, 300, 291, 393, 3361, 13], "temperature": 0.0, "avg_logprob": -0.2036357133284859, "compression_ratio": 1.6203703703703705, "no_speech_prob": 1.30817227272928e-06}, {"id": 441, "seek": 174944, "start": 1758.3200000000002, "end": 1766.88, "text": " But the potential there in Elm is even greater because there are way fewer sharp edges that", "tokens": [583, 264, 3995, 456, 294, 2699, 76, 307, 754, 5044, 570, 456, 366, 636, 13366, 8199, 8819, 300], "temperature": 0.0, "avg_logprob": -0.2036357133284859, "compression_ratio": 1.6203703703703705, "no_speech_prob": 1.30817227272928e-06}, {"id": 442, "seek": 174944, "start": 1766.88, "end": 1767.88, "text": " you can encounter.", "tokens": [291, 393, 8593, 13], "temperature": 0.0, "avg_logprob": -0.2036357133284859, "compression_ratio": 1.6203703703703705, "no_speech_prob": 1.30817227272928e-06}, {"id": 443, "seek": 174944, "start": 1767.88, "end": 1773.3200000000002, "text": " Well, as you say, Elm has removed a lot of features and in a way it has removed pretty", "tokens": [1042, 11, 382, 291, 584, 11, 2699, 76, 575, 7261, 257, 688, 295, 4122, 293, 294, 257, 636, 309, 575, 7261, 1238], "temperature": 0.0, "avg_logprob": -0.2036357133284859, "compression_ratio": 1.6203703703703705, "no_speech_prob": 1.30817227272928e-06}, {"id": 444, "seek": 174944, "start": 1773.3200000000002, "end": 1775.0800000000002, "text": " much all the foot guns.", "tokens": [709, 439, 264, 2671, 10153, 13], "temperature": 0.0, "avg_logprob": -0.2036357133284859, "compression_ratio": 1.6203703703703705, "no_speech_prob": 1.30817227272928e-06}, {"id": 445, "seek": 177508, "start": 1775.08, "end": 1780.32, "text": " It also has removed a lot of escape hatches because in some of the escape hatches, you", "tokens": [467, 611, 575, 7261, 257, 688, 295, 7615, 17387, 279, 570, 294, 512, 295, 264, 7615, 17387, 279, 11, 291], "temperature": 0.0, "avg_logprob": -0.3093300110254532, "compression_ratio": 1.4858757062146892, "no_speech_prob": 1.4144370652502403e-06}, {"id": 446, "seek": 177508, "start": 1780.32, "end": 1781.84, "text": " have a gun.", "tokens": [362, 257, 3874, 13], "temperature": 0.0, "avg_logprob": -0.3093300110254532, "compression_ratio": 1.4858757062146892, "no_speech_prob": 1.4144370652502403e-06}, {"id": 447, "seek": 177508, "start": 1781.84, "end": 1785.32, "text": " We are in, in the basement of America.", "tokens": [492, 366, 294, 11, 294, 264, 16893, 295, 3374, 13], "temperature": 0.0, "avg_logprob": -0.3093300110254532, "compression_ratio": 1.4858757062146892, "no_speech_prob": 1.4144370652502403e-06}, {"id": 448, "seek": 177508, "start": 1785.32, "end": 1787.32, "text": " I don't know.", "tokens": [286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.3093300110254532, "compression_ratio": 1.4858757062146892, "no_speech_prob": 1.4144370652502403e-06}, {"id": 449, "seek": 177508, "start": 1787.32, "end": 1790.9199999999998, "text": " Plenty of guns everywhere.", "tokens": [2149, 4179, 295, 10153, 5315, 13], "temperature": 0.0, "avg_logprob": -0.3093300110254532, "compression_ratio": 1.4858757062146892, "no_speech_prob": 1.4144370652502403e-06}, {"id": 450, "seek": 177508, "start": 1790.9199999999998, "end": 1797.02, "text": " And as you say, like there are trade-offs to doing things in one language or another", "tokens": [400, 382, 291, 584, 11, 411, 456, 366, 4923, 12, 19231, 281, 884, 721, 294, 472, 2856, 420, 1071], "temperature": 0.0, "avg_logprob": -0.3093300110254532, "compression_ratio": 1.4858757062146892, "no_speech_prob": 1.4144370652502403e-06}, {"id": 451, "seek": 179702, "start": 1797.02, "end": 1805.44, "text": " and making one tool in JavaScript is, might be much easier than writing in Elm or a similar", "tokens": [293, 1455, 472, 2290, 294, 15778, 307, 11, 1062, 312, 709, 3571, 813, 3579, 294, 2699, 76, 420, 257, 2531], "temperature": 0.0, "avg_logprob": -0.22047250167183255, "compression_ratio": 1.518348623853211, "no_speech_prob": 4.052365341067343e-07}, {"id": 452, "seek": 179702, "start": 1805.44, "end": 1809.0, "text": " language with those same limitations.", "tokens": [2856, 365, 729, 912, 15705, 13], "temperature": 0.0, "avg_logprob": -0.22047250167183255, "compression_ratio": 1.518348623853211, "no_speech_prob": 4.052365341067343e-07}, {"id": 453, "seek": 179702, "start": 1809.0, "end": 1813.04, "text": " But you don't get the same things in return.", "tokens": [583, 291, 500, 380, 483, 264, 912, 721, 294, 2736, 13], "temperature": 0.0, "avg_logprob": -0.22047250167183255, "compression_ratio": 1.518348623853211, "no_speech_prob": 4.052365341067343e-07}, {"id": 454, "seek": 179702, "start": 1813.04, "end": 1819.04, "text": " So in Elm, like I'm almost amazed that I forgot to say that, but like there are no errors.", "tokens": [407, 294, 2699, 76, 11, 411, 286, 478, 1920, 20507, 300, 286, 5298, 281, 584, 300, 11, 457, 411, 456, 366, 572, 13603, 13], "temperature": 0.0, "avg_logprob": -0.22047250167183255, "compression_ratio": 1.518348623853211, "no_speech_prob": 4.052365341067343e-07}, {"id": 455, "seek": 179702, "start": 1819.04, "end": 1820.04, "text": " There are no crashes.", "tokens": [821, 366, 572, 28642, 13], "temperature": 0.0, "avg_logprob": -0.22047250167183255, "compression_ratio": 1.518348623853211, "no_speech_prob": 4.052365341067343e-07}, {"id": 456, "seek": 179702, "start": 1820.04, "end": 1823.12, "text": " Like, yeah, that's kind of the main things.", "tokens": [1743, 11, 1338, 11, 300, 311, 733, 295, 264, 2135, 721, 13], "temperature": 0.0, "avg_logprob": -0.22047250167183255, "compression_ratio": 1.518348623853211, "no_speech_prob": 4.052365341067343e-07}, {"id": 457, "seek": 182312, "start": 1823.12, "end": 1829.56, "text": " So for instance, if you write things in Lambda or in Elm pages, your code will not crash.", "tokens": [407, 337, 5197, 11, 498, 291, 2464, 721, 294, 45691, 420, 294, 2699, 76, 7183, 11, 428, 3089, 486, 406, 8252, 13], "temperature": 0.0, "avg_logprob": -0.21494680581633577, "compression_ratio": 1.6475770925110131, "no_speech_prob": 5.368518145587586e-07}, {"id": 458, "seek": 182312, "start": 1829.56, "end": 1832.12, "text": " It will not have any errors.", "tokens": [467, 486, 406, 362, 604, 13603, 13], "temperature": 0.0, "avg_logprob": -0.21494680581633577, "compression_ratio": 1.6475770925110131, "no_speech_prob": 5.368518145587586e-07}, {"id": 459, "seek": 182312, "start": 1832.12, "end": 1839.4399999999998, "text": " You could probably have a framework like Lambda or Elm pages for JavaScript or other languages", "tokens": [509, 727, 1391, 362, 257, 8388, 411, 45691, 420, 2699, 76, 7183, 337, 15778, 420, 661, 8650], "temperature": 0.0, "avg_logprob": -0.21494680581633577, "compression_ratio": 1.6475770925110131, "no_speech_prob": 5.368518145587586e-07}, {"id": 460, "seek": 182312, "start": 1839.4399999999998, "end": 1845.6799999999998, "text": " like that, but you're not going to be able to prevent it from crashing.", "tokens": [411, 300, 11, 457, 291, 434, 406, 516, 281, 312, 1075, 281, 4871, 309, 490, 26900, 13], "temperature": 0.0, "avg_logprob": -0.21494680581633577, "compression_ratio": 1.6475770925110131, "no_speech_prob": 5.368518145587586e-07}, {"id": 461, "seek": 182312, "start": 1845.6799999999998, "end": 1853.08, "text": " Or maybe it's possible, but you're going to have to do so much work on making that work.", "tokens": [1610, 1310, 309, 311, 1944, 11, 457, 291, 434, 516, 281, 362, 281, 360, 370, 709, 589, 322, 1455, 300, 589, 13], "temperature": 0.0, "avg_logprob": -0.21494680581633577, "compression_ratio": 1.6475770925110131, "no_speech_prob": 5.368518145587586e-07}, {"id": 462, "seek": 185308, "start": 1853.08, "end": 1857.04, "text": " So you're going to have to add additional limitations to your language.", "tokens": [407, 291, 434, 516, 281, 362, 281, 909, 4497, 15705, 281, 428, 2856, 13], "temperature": 0.0, "avg_logprob": -0.2514373306679515, "compression_ratio": 1.619047619047619, "no_speech_prob": 2.40603139900486e-06}, {"id": 463, "seek": 185308, "start": 1857.04, "end": 1863.32, "text": " So for instance, say like, well, you can use, it's just JavaScript, but don't use eval,", "tokens": [407, 337, 5197, 11, 584, 411, 11, 731, 11, 291, 393, 764, 11, 309, 311, 445, 15778, 11, 457, 500, 380, 764, 1073, 304, 11], "temperature": 0.0, "avg_logprob": -0.2514373306679515, "compression_ratio": 1.619047619047619, "no_speech_prob": 2.40603139900486e-06}, {"id": 464, "seek": 185308, "start": 1863.32, "end": 1871.0, "text": " don't use subclassing, don't use, I don't know, whatever feature doesn't work in this", "tokens": [500, 380, 764, 1422, 11665, 278, 11, 500, 380, 764, 11, 286, 500, 380, 458, 11, 2035, 4111, 1177, 380, 589, 294, 341], "temperature": 0.0, "avg_logprob": -0.2514373306679515, "compression_ratio": 1.619047619047619, "no_speech_prob": 2.40603139900486e-06}, {"id": 465, "seek": 185308, "start": 1871.0, "end": 1872.9399999999998, "text": " imaginary situation.", "tokens": [26164, 2590, 13], "temperature": 0.0, "avg_logprob": -0.2514373306679515, "compression_ratio": 1.619047619047619, "no_speech_prob": 2.40603139900486e-06}, {"id": 466, "seek": 185308, "start": 1872.9399999999998, "end": 1876.0, "text": " Or you're going to just do a lot more analysis work.", "tokens": [1610, 291, 434, 516, 281, 445, 360, 257, 688, 544, 5215, 589, 13], "temperature": 0.0, "avg_logprob": -0.2514373306679515, "compression_ratio": 1.619047619047619, "no_speech_prob": 2.40603139900486e-06}, {"id": 467, "seek": 185308, "start": 1876.0, "end": 1882.08, "text": " Like oh, please add all these ESLint plugins to make sure you're not falling into one of", "tokens": [1743, 1954, 11, 1767, 909, 439, 613, 12564, 43, 686, 33759, 281, 652, 988, 291, 434, 406, 7440, 666, 472, 295], "temperature": 0.0, "avg_logprob": -0.2514373306679515, "compression_ratio": 1.619047619047619, "no_speech_prob": 2.40603139900486e-06}, {"id": 468, "seek": 188208, "start": 1882.08, "end": 1888.3999999999999, "text": " these traps or using these foot guns or all these things that you need to worry about.", "tokens": [613, 24173, 420, 1228, 613, 2671, 10153, 420, 439, 613, 721, 300, 291, 643, 281, 3292, 466, 13], "temperature": 0.0, "avg_logprob": -0.2433336752432364, "compression_ratio": 1.5320197044334976, "no_speech_prob": 2.0904442408209434e-06}, {"id": 469, "seek": 188208, "start": 1888.3999999999999, "end": 1891.08, "text": " Like in Elm, it's just much simpler.", "tokens": [1743, 294, 2699, 76, 11, 309, 311, 445, 709, 18587, 13], "temperature": 0.0, "avg_logprob": -0.2433336752432364, "compression_ratio": 1.5320197044334976, "no_speech_prob": 2.0904442408209434e-06}, {"id": 470, "seek": 188208, "start": 1891.08, "end": 1893.4399999999998, "text": " That's the default approach.", "tokens": [663, 311, 264, 7576, 3109, 13], "temperature": 0.0, "avg_logprob": -0.2433336752432364, "compression_ratio": 1.5320197044334976, "no_speech_prob": 2.0904442408209434e-06}, {"id": 471, "seek": 188208, "start": 1893.4399999999998, "end": 1900.6399999999999, "text": " And then tooling authors, package authors in Elm have just this ethos of trying to make", "tokens": [400, 550, 46593, 16552, 11, 7372, 16552, 294, 2699, 76, 362, 445, 341, 6468, 329, 295, 1382, 281, 652], "temperature": 0.0, "avg_logprob": -0.2433336752432364, "compression_ratio": 1.5320197044334976, "no_speech_prob": 2.0904442408209434e-06}, {"id": 472, "seek": 188208, "start": 1900.6399999999999, "end": 1906.48, "text": " things type safe, which just improves the situation for Elm even more.", "tokens": [721, 2010, 3273, 11, 597, 445, 24771, 264, 2590, 337, 2699, 76, 754, 544, 13], "temperature": 0.0, "avg_logprob": -0.2433336752432364, "compression_ratio": 1.5320197044334976, "no_speech_prob": 2.0904442408209434e-06}, {"id": 473, "seek": 190648, "start": 1906.48, "end": 1912.72, "text": " Sometimes at the cost of a little bit more verbose API or things that are not as nice", "tokens": [4803, 412, 264, 2063, 295, 257, 707, 857, 544, 9595, 541, 9362, 420, 721, 300, 366, 406, 382, 1481], "temperature": 0.0, "avg_logprob": -0.3291005089169457, "compression_ratio": 1.6, "no_speech_prob": 6.78663752751163e-07}, {"id": 474, "seek": 190648, "start": 1912.72, "end": 1915.28, "text": " to use because you need to handle all possible cases.", "tokens": [281, 764, 570, 291, 643, 281, 4813, 439, 1944, 3331, 13], "temperature": 0.0, "avg_logprob": -0.3291005089169457, "compression_ratio": 1.6, "no_speech_prob": 6.78663752751163e-07}, {"id": 475, "seek": 190648, "start": 1915.28, "end": 1919.6, "text": " But in practice, like the result is really, really good.", "tokens": [583, 294, 3124, 11, 411, 264, 1874, 307, 534, 11, 534, 665, 13], "temperature": 0.0, "avg_logprob": -0.3291005089169457, "compression_ratio": 1.6, "no_speech_prob": 6.78663752751163e-07}, {"id": 476, "seek": 190648, "start": 1919.6, "end": 1924.44, "text": " And you're just going to have a hard time having the same results in another language.", "tokens": [400, 291, 434, 445, 516, 281, 362, 257, 1152, 565, 1419, 264, 912, 3542, 294, 1071, 2856, 13], "temperature": 0.0, "avg_logprob": -0.3291005089169457, "compression_ratio": 1.6, "no_speech_prob": 6.78663752751163e-07}, {"id": 477, "seek": 190648, "start": 1924.44, "end": 1929.8, "text": " At least when Elm is a good fit for your project, like not saying Elm is always a good fit.", "tokens": [1711, 1935, 562, 2699, 76, 307, 257, 665, 3318, 337, 428, 1716, 11, 411, 406, 1566, 2699, 76, 307, 1009, 257, 665, 3318, 13], "temperature": 0.0, "avg_logprob": -0.3291005089169457, "compression_ratio": 1.6, "no_speech_prob": 6.78663752751163e-07}, {"id": 478, "seek": 190648, "start": 1929.8, "end": 1931.64, "text": " Like we're, but.", "tokens": [1743, 321, 434, 11, 457, 13], "temperature": 0.0, "avg_logprob": -0.3291005089169457, "compression_ratio": 1.6, "no_speech_prob": 6.78663752751163e-07}, {"id": 479, "seek": 193164, "start": 1931.64, "end": 1937.8400000000001, "text": " Yeah, and obviously there is a trade off with convenience, you know, just being able to", "tokens": [865, 11, 293, 2745, 456, 307, 257, 4923, 766, 365, 19283, 11, 291, 458, 11, 445, 885, 1075, 281], "temperature": 0.0, "avg_logprob": -0.2292659466083233, "compression_ratio": 1.5622317596566524, "no_speech_prob": 2.6425304895383306e-06}, {"id": 480, "seek": 193164, "start": 1937.8400000000001, "end": 1945.5600000000002, "text": " grab an off the shelf NPM package or, you know, React hook or component library, whatever", "tokens": [4444, 364, 766, 264, 15222, 426, 18819, 7372, 420, 11, 291, 458, 11, 30644, 6328, 420, 6542, 6405, 11, 2035], "temperature": 0.0, "avg_logprob": -0.2292659466083233, "compression_ratio": 1.5622317596566524, "no_speech_prob": 2.6425304895383306e-06}, {"id": 481, "seek": 193164, "start": 1945.5600000000002, "end": 1946.64, "text": " it may be.", "tokens": [309, 815, 312, 13], "temperature": 0.0, "avg_logprob": -0.2292659466083233, "compression_ratio": 1.5622317596566524, "no_speech_prob": 2.6425304895383306e-06}, {"id": 482, "seek": 193164, "start": 1946.64, "end": 1948.16, "text": " You know, there's a trade off.", "tokens": [509, 458, 11, 456, 311, 257, 4923, 766, 13], "temperature": 0.0, "avg_logprob": -0.2292659466083233, "compression_ratio": 1.5622317596566524, "no_speech_prob": 2.6425304895383306e-06}, {"id": 483, "seek": 193164, "start": 1948.16, "end": 1952.96, "text": " And this is a choice that we all make when we're using Elm.", "tokens": [400, 341, 307, 257, 3922, 300, 321, 439, 652, 562, 321, 434, 1228, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.2292659466083233, "compression_ratio": 1.5622317596566524, "no_speech_prob": 2.6425304895383306e-06}, {"id": 484, "seek": 193164, "start": 1952.96, "end": 1959.3200000000002, "text": " And I mean, in a way, like I feel like you and I really want to do everything we can", "tokens": [400, 286, 914, 11, 294, 257, 636, 11, 411, 286, 841, 411, 291, 293, 286, 534, 528, 281, 360, 1203, 321, 393], "temperature": 0.0, "avg_logprob": -0.2292659466083233, "compression_ratio": 1.5622317596566524, "no_speech_prob": 2.6425304895383306e-06}, {"id": 485, "seek": 195932, "start": 1959.32, "end": 1965.04, "text": " to make the ecosystem as compelling as we can to narrow the gap of those trade offs.", "tokens": [281, 652, 264, 11311, 382, 20050, 382, 321, 393, 281, 9432, 264, 7417, 295, 729, 4923, 39457, 13], "temperature": 0.0, "avg_logprob": -0.2440522003173828, "compression_ratio": 1.7836734693877552, "no_speech_prob": 2.36875257542124e-06}, {"id": 486, "seek": 195932, "start": 1965.04, "end": 1972.4399999999998, "text": " Because like inherently, yes, there is a certain like there's people want convenience and Elm", "tokens": [1436, 411, 27993, 11, 2086, 11, 456, 307, 257, 1629, 411, 456, 311, 561, 528, 19283, 293, 2699, 76], "temperature": 0.0, "avg_logprob": -0.2440522003173828, "compression_ratio": 1.7836734693877552, "no_speech_prob": 2.36875257542124e-06}, {"id": 487, "seek": 195932, "start": 1972.4399999999998, "end": 1977.8, "text": " takes away convenience in a fundamental way that gives you something back that's very", "tokens": [2516, 1314, 19283, 294, 257, 8088, 636, 300, 2709, 291, 746, 646, 300, 311, 588], "temperature": 0.0, "avg_logprob": -0.2440522003173828, "compression_ratio": 1.7836734693877552, "no_speech_prob": 2.36875257542124e-06}, {"id": 488, "seek": 195932, "start": 1977.8, "end": 1978.8, "text": " valuable.", "tokens": [8263, 13], "temperature": 0.0, "avg_logprob": -0.2440522003173828, "compression_ratio": 1.7836734693877552, "no_speech_prob": 2.36875257542124e-06}, {"id": 489, "seek": 195932, "start": 1978.8, "end": 1983.52, "text": " It gives you back the ability to reason about your code in a totally different way and the", "tokens": [467, 2709, 291, 646, 264, 3485, 281, 1778, 466, 428, 3089, 294, 257, 3879, 819, 636, 293, 264], "temperature": 0.0, "avg_logprob": -0.2440522003173828, "compression_ratio": 1.7836734693877552, "no_speech_prob": 2.36875257542124e-06}, {"id": 490, "seek": 195932, "start": 1983.52, "end": 1987.1599999999999, "text": " ability to have guarantees and trust your code in a very different way.", "tokens": [3485, 281, 362, 32567, 293, 3361, 428, 3089, 294, 257, 588, 819, 636, 13], "temperature": 0.0, "avg_logprob": -0.2440522003173828, "compression_ratio": 1.7836734693877552, "no_speech_prob": 2.36875257542124e-06}, {"id": 491, "seek": 198716, "start": 1987.16, "end": 1992.88, "text": " But it takes away convenience and that's just a fundamental truth about the core trade offs", "tokens": [583, 309, 2516, 1314, 19283, 293, 300, 311, 445, 257, 8088, 3494, 466, 264, 4965, 4923, 39457], "temperature": 0.0, "avg_logprob": -0.19887272004158266, "compression_ratio": 1.7547892720306513, "no_speech_prob": 1.7880495306599187e-06}, {"id": 492, "seek": 198716, "start": 1992.88, "end": 1994.2, "text": " that Elm makes.", "tokens": [300, 2699, 76, 1669, 13], "temperature": 0.0, "avg_logprob": -0.19887272004158266, "compression_ratio": 1.7547892720306513, "no_speech_prob": 1.7880495306599187e-06}, {"id": 493, "seek": 198716, "start": 1994.2, "end": 1996.74, "text": " And some people are just not going to like that.", "tokens": [400, 512, 561, 366, 445, 406, 516, 281, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.19887272004158266, "compression_ratio": 1.7547892720306513, "no_speech_prob": 1.7880495306599187e-06}, {"id": 494, "seek": 198716, "start": 1996.74, "end": 2000.5600000000002, "text": " Some people are not going to want to be constrained in that way.", "tokens": [2188, 561, 366, 406, 516, 281, 528, 281, 312, 38901, 294, 300, 636, 13], "temperature": 0.0, "avg_logprob": -0.19887272004158266, "compression_ratio": 1.7547892720306513, "no_speech_prob": 1.7880495306599187e-06}, {"id": 495, "seek": 198716, "start": 2000.5600000000002, "end": 2001.8400000000001, "text": " They're going to say, hey, you know what?", "tokens": [814, 434, 516, 281, 584, 11, 4177, 11, 291, 458, 437, 30], "temperature": 0.0, "avg_logprob": -0.19887272004158266, "compression_ratio": 1.7547892720306513, "no_speech_prob": 1.7880495306599187e-06}, {"id": 496, "seek": 198716, "start": 2001.8400000000001, "end": 2003.28, "text": " Like I'm an adult.", "tokens": [1743, 286, 478, 364, 5075, 13], "temperature": 0.0, "avg_logprob": -0.19887272004158266, "compression_ratio": 1.7547892720306513, "no_speech_prob": 1.7880495306599187e-06}, {"id": 497, "seek": 198716, "start": 2003.28, "end": 2008.52, "text": " I want to be able to have a global variable if that's how I want to solve my problem.", "tokens": [286, 528, 281, 312, 1075, 281, 362, 257, 4338, 7006, 498, 300, 311, 577, 286, 528, 281, 5039, 452, 1154, 13], "temperature": 0.0, "avg_logprob": -0.19887272004158266, "compression_ratio": 1.7547892720306513, "no_speech_prob": 1.7880495306599187e-06}, {"id": 498, "seek": 198716, "start": 2008.52, "end": 2016.24, "text": " I want to be able to bypass the compiler checks and just use a type and not have to write", "tokens": [286, 528, 281, 312, 1075, 281, 24996, 264, 31958, 13834, 293, 445, 764, 257, 2010, 293, 406, 362, 281, 2464], "temperature": 0.0, "avg_logprob": -0.19887272004158266, "compression_ratio": 1.7547892720306513, "no_speech_prob": 1.7880495306599187e-06}, {"id": 499, "seek": 201624, "start": 2016.24, "end": 2018.0, "text": " a decoder for it and things like that.", "tokens": [257, 979, 19866, 337, 309, 293, 721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.2474398164667635, "compression_ratio": 1.6451612903225807, "no_speech_prob": 3.0415494620683603e-06}, {"id": 500, "seek": 201624, "start": 2018.0, "end": 2024.2, "text": " And that's a reasonable preference, but it's just a very different world.", "tokens": [400, 300, 311, 257, 10585, 17502, 11, 457, 309, 311, 445, 257, 588, 819, 1002, 13], "temperature": 0.0, "avg_logprob": -0.2474398164667635, "compression_ratio": 1.6451612903225807, "no_speech_prob": 3.0415494620683603e-06}, {"id": 501, "seek": 201624, "start": 2024.2, "end": 2031.52, "text": " And but, you know, I mean, I think that working with Tailwind in Elm is super compelling.", "tokens": [400, 457, 11, 291, 458, 11, 286, 914, 11, 286, 519, 300, 1364, 365, 46074, 12199, 294, 2699, 76, 307, 1687, 20050, 13], "temperature": 0.0, "avg_logprob": -0.2474398164667635, "compression_ratio": 1.6451612903225807, "no_speech_prob": 3.0415494620683603e-06}, {"id": 502, "seek": 201624, "start": 2031.52, "end": 2037.24, "text": " And like that's, you know, as we fill out the ecosystem with more of these things, we", "tokens": [400, 411, 300, 311, 11, 291, 458, 11, 382, 321, 2836, 484, 264, 11311, 365, 544, 295, 613, 721, 11, 321], "temperature": 0.0, "avg_logprob": -0.2474398164667635, "compression_ratio": 1.6451612903225807, "no_speech_prob": 3.0415494620683603e-06}, {"id": 503, "seek": 201624, "start": 2037.24, "end": 2041.32, "text": " get closer to that vision, which it's not going to be.", "tokens": [483, 4966, 281, 300, 5201, 11, 597, 309, 311, 406, 516, 281, 312, 13], "temperature": 0.0, "avg_logprob": -0.2474398164667635, "compression_ratio": 1.6451612903225807, "no_speech_prob": 3.0415494620683603e-06}, {"id": 504, "seek": 201624, "start": 2041.32, "end": 2043.6, "text": " I don't think it's ever going to be as big as JavaScript.", "tokens": [286, 500, 380, 519, 309, 311, 1562, 516, 281, 312, 382, 955, 382, 15778, 13], "temperature": 0.0, "avg_logprob": -0.2474398164667635, "compression_ratio": 1.6451612903225807, "no_speech_prob": 3.0415494620683603e-06}, {"id": 505, "seek": 201624, "start": 2043.6, "end": 2044.6, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.2474398164667635, "compression_ratio": 1.6451612903225807, "no_speech_prob": 3.0415494620683603e-06}, {"id": 506, "seek": 204460, "start": 2044.6, "end": 2049.72, "text": " It's just I think inherently like you take away people's convenience and fewer people", "tokens": [467, 311, 445, 286, 519, 27993, 411, 291, 747, 1314, 561, 311, 19283, 293, 13366, 561], "temperature": 0.0, "avg_logprob": -0.25659498162225847, "compression_ratio": 1.6095617529880477, "no_speech_prob": 1.8738576272880891e-06}, {"id": 507, "seek": 204460, "start": 2049.72, "end": 2051.96, "text": " will be attracted to that world.", "tokens": [486, 312, 15912, 281, 300, 1002, 13], "temperature": 0.0, "avg_logprob": -0.25659498162225847, "compression_ratio": 1.6095617529880477, "no_speech_prob": 1.8738576272880891e-06}, {"id": 508, "seek": 204460, "start": 2051.96, "end": 2052.96, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.25659498162225847, "compression_ratio": 1.6095617529880477, "no_speech_prob": 1.8738576272880891e-06}, {"id": 509, "seek": 204460, "start": 2052.96, "end": 2053.96, "text": " But.", "tokens": [583, 13], "temperature": 0.0, "avg_logprob": -0.25659498162225847, "compression_ratio": 1.6095617529880477, "no_speech_prob": 1.8738576272880891e-06}, {"id": 510, "seek": 204460, "start": 2053.96, "end": 2058.04, "text": " But in some cases, like people are going to adopt it and they'll be fine with it.", "tokens": [583, 294, 512, 3331, 11, 411, 561, 366, 516, 281, 6878, 309, 293, 436, 603, 312, 2489, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.25659498162225847, "compression_ratio": 1.6095617529880477, "no_speech_prob": 1.8738576272880891e-06}, {"id": 511, "seek": 204460, "start": 2058.04, "end": 2065.12, "text": " Like all the functional tools that we have in Elm, like map and filter and reduce and", "tokens": [1743, 439, 264, 11745, 3873, 300, 321, 362, 294, 2699, 76, 11, 411, 4471, 293, 6608, 293, 5407, 293], "temperature": 0.0, "avg_logprob": -0.25659498162225847, "compression_ratio": 1.6095617529880477, "no_speech_prob": 1.8738576272880891e-06}, {"id": 512, "seek": 204460, "start": 2065.12, "end": 2066.12, "text": " whatever.", "tokens": [2035, 13], "temperature": 0.0, "avg_logprob": -0.25659498162225847, "compression_ratio": 1.6095617529880477, "no_speech_prob": 1.8738576272880891e-06}, {"id": 513, "seek": 204460, "start": 2066.12, "end": 2072.6, "text": " Well, we can see those in popping up in all other languages, anonymous functions as well.", "tokens": [1042, 11, 321, 393, 536, 729, 294, 18374, 493, 294, 439, 661, 8650, 11, 24932, 6828, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.25659498162225847, "compression_ratio": 1.6095617529880477, "no_speech_prob": 1.8738576272880891e-06}, {"id": 514, "seek": 204460, "start": 2072.6, "end": 2073.6, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.25659498162225847, "compression_ratio": 1.6095617529880477, "no_speech_prob": 1.8738576272880891e-06}, {"id": 515, "seek": 207360, "start": 2073.6, "end": 2076.6, "text": " So people are getting used to some of the features.", "tokens": [407, 561, 366, 1242, 1143, 281, 512, 295, 264, 4122, 13], "temperature": 0.0, "avg_logprob": -0.23350583828561675, "compression_ratio": 1.6477732793522266, "no_speech_prob": 3.555770717866835e-06}, {"id": 516, "seek": 207360, "start": 2076.6, "end": 2082.88, "text": " And I would kind of say like Elm's some of Elm's features are like seatbelts.", "tokens": [400, 286, 576, 733, 295, 584, 411, 2699, 76, 311, 512, 295, 2699, 76, 311, 4122, 366, 411, 6121, 5390, 1373, 13], "temperature": 0.0, "avg_logprob": -0.23350583828561675, "compression_ratio": 1.6477732793522266, "no_speech_prob": 3.555770717866835e-06}, {"id": 517, "seek": 207360, "start": 2082.88, "end": 2087.12, "text": " People hated them when they had to start using them.", "tokens": [3432, 17398, 552, 562, 436, 632, 281, 722, 1228, 552, 13], "temperature": 0.0, "avg_logprob": -0.23350583828561675, "compression_ratio": 1.6477732793522266, "no_speech_prob": 3.555770717866835e-06}, {"id": 518, "seek": 207360, "start": 2087.12, "end": 2089.36, "text": " I'm guessing I was still too young back then.", "tokens": [286, 478, 17939, 286, 390, 920, 886, 2037, 646, 550, 13], "temperature": 0.0, "avg_logprob": -0.23350583828561675, "compression_ratio": 1.6477732793522266, "no_speech_prob": 3.555770717866835e-06}, {"id": 519, "seek": 207360, "start": 2089.36, "end": 2090.36, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.23350583828561675, "compression_ratio": 1.6477732793522266, "no_speech_prob": 3.555770717866835e-06}, {"id": 520, "seek": 207360, "start": 2090.36, "end": 2091.36, "text": " Oh, yeah.", "tokens": [876, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.23350583828561675, "compression_ratio": 1.6477732793522266, "no_speech_prob": 3.555770717866835e-06}, {"id": 521, "seek": 207360, "start": 2091.36, "end": 2092.56, "text": " But now everyone has them.", "tokens": [583, 586, 1518, 575, 552, 13], "temperature": 0.0, "avg_logprob": -0.23350583828561675, "compression_ratio": 1.6477732793522266, "no_speech_prob": 3.555770717866835e-06}, {"id": 522, "seek": 207360, "start": 2092.56, "end": 2096.4, "text": " And I don't think a lot of people will just say, well, this is for nothing.", "tokens": [400, 286, 500, 380, 519, 257, 688, 295, 561, 486, 445, 584, 11, 731, 11, 341, 307, 337, 1825, 13], "temperature": 0.0, "avg_logprob": -0.23350583828561675, "compression_ratio": 1.6477732793522266, "no_speech_prob": 3.555770717866835e-06}, {"id": 523, "seek": 207360, "start": 2096.4, "end": 2098.3199999999997, "text": " Like this is useless.", "tokens": [1743, 341, 307, 14115, 13], "temperature": 0.0, "avg_logprob": -0.23350583828561675, "compression_ratio": 1.6477732793522266, "no_speech_prob": 3.555770717866835e-06}, {"id": 524, "seek": 207360, "start": 2098.3199999999997, "end": 2100.48, "text": " People know it's going to be helpful.", "tokens": [3432, 458, 309, 311, 516, 281, 312, 4961, 13], "temperature": 0.0, "avg_logprob": -0.23350583828561675, "compression_ratio": 1.6477732793522266, "no_speech_prob": 3.555770717866835e-06}, {"id": 525, "seek": 210048, "start": 2100.48, "end": 2105.8, "text": " Some people will still decide to take them off or not to put them on.", "tokens": [2188, 561, 486, 920, 4536, 281, 747, 552, 766, 420, 406, 281, 829, 552, 322, 13], "temperature": 0.0, "avg_logprob": -0.29033124923706055, "compression_ratio": 1.6069868995633187, "no_speech_prob": 8.93850392458262e-06}, {"id": 526, "seek": 210048, "start": 2105.8, "end": 2108.88, "text": " And well, it's going to be very scary for them.", "tokens": [400, 731, 11, 309, 311, 516, 281, 312, 588, 6958, 337, 552, 13], "temperature": 0.0, "avg_logprob": -0.29033124923706055, "compression_ratio": 1.6069868995633187, "no_speech_prob": 8.93850392458262e-06}, {"id": 527, "seek": 210048, "start": 2108.88, "end": 2111.4, "text": " Should anything happen, you lose some guarantees.", "tokens": [6454, 1340, 1051, 11, 291, 3624, 512, 32567, 13], "temperature": 0.0, "avg_logprob": -0.29033124923706055, "compression_ratio": 1.6069868995633187, "no_speech_prob": 8.93850392458262e-06}, {"id": 528, "seek": 210048, "start": 2111.4, "end": 2112.4, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.29033124923706055, "compression_ratio": 1.6069868995633187, "no_speech_prob": 8.93850392458262e-06}, {"id": 529, "seek": 210048, "start": 2112.4, "end": 2121.12, "text": " And yeah, sometimes the tradeoffs are very much in favor of one design or compared to", "tokens": [400, 1338, 11, 2171, 264, 4923, 19231, 366, 588, 709, 294, 2294, 295, 472, 1715, 420, 5347, 281], "temperature": 0.0, "avg_logprob": -0.29033124923706055, "compression_ratio": 1.6069868995633187, "no_speech_prob": 8.93850392458262e-06}, {"id": 530, "seek": 210048, "start": 2121.12, "end": 2122.12, "text": " another seatbelts.", "tokens": [1071, 6121, 5390, 1373, 13], "temperature": 0.0, "avg_logprob": -0.29033124923706055, "compression_ratio": 1.6069868995633187, "no_speech_prob": 8.93850392458262e-06}, {"id": 531, "seek": 210048, "start": 2122.12, "end": 2129.2400000000002, "text": " It's not a lot of a lot of constraints, but it adds a lot of guarantee about like helping", "tokens": [467, 311, 406, 257, 688, 295, 257, 688, 295, 18491, 11, 457, 309, 10860, 257, 688, 295, 10815, 466, 411, 4315], "temperature": 0.0, "avg_logprob": -0.29033124923706055, "compression_ratio": 1.6069868995633187, "no_speech_prob": 8.93850392458262e-06}, {"id": 532, "seek": 212924, "start": 2129.24, "end": 2131.56, "text": " you survive a crash.", "tokens": [291, 7867, 257, 8252, 13], "temperature": 0.0, "avg_logprob": -0.25812625885009766, "compression_ratio": 1.5576923076923077, "no_speech_prob": 2.0579659576469567e-06}, {"id": 533, "seek": 212924, "start": 2131.56, "end": 2137.72, "text": " So it's definitely worth the effort and not worth encountering the risk.", "tokens": [407, 309, 311, 2138, 3163, 264, 4630, 293, 406, 3163, 8593, 278, 264, 3148, 13], "temperature": 0.0, "avg_logprob": -0.25812625885009766, "compression_ratio": 1.5576923076923077, "no_speech_prob": 2.0579659576469567e-06}, {"id": 534, "seek": 212924, "start": 2137.72, "end": 2143.68, "text": " And I'd say in Elm, like there's just so many things that handling all cases, handling that", "tokens": [400, 286, 1116, 584, 294, 2699, 76, 11, 411, 456, 311, 445, 370, 867, 721, 300, 13175, 439, 3331, 11, 13175, 300], "temperature": 0.0, "avg_logprob": -0.25812625885009766, "compression_ratio": 1.5576923076923077, "no_speech_prob": 2.0579659576469567e-06}, {"id": 535, "seek": 212924, "start": 2143.68, "end": 2147.7599999999998, "text": " something is null or nothing, it's worth it.", "tokens": [746, 307, 18184, 420, 1825, 11, 309, 311, 3163, 309, 13], "temperature": 0.0, "avg_logprob": -0.25812625885009766, "compression_ratio": 1.5576923076923077, "no_speech_prob": 2.0579659576469567e-06}, {"id": 536, "seek": 212924, "start": 2147.7599999999998, "end": 2151.2799999999997, "text": " It's not always practical, but yeah, it's a very compelling story.", "tokens": [467, 311, 406, 1009, 8496, 11, 457, 1338, 11, 309, 311, 257, 588, 20050, 1657, 13], "temperature": 0.0, "avg_logprob": -0.25812625885009766, "compression_ratio": 1.5576923076923077, "no_speech_prob": 2.0579659576469567e-06}, {"id": 537, "seek": 212924, "start": 2151.2799999999997, "end": 2152.6, "text": " I mean, it is interesting.", "tokens": [286, 914, 11, 309, 307, 1880, 13], "temperature": 0.0, "avg_logprob": -0.25812625885009766, "compression_ratio": 1.5576923076923077, "no_speech_prob": 2.0579659576469567e-06}, {"id": 538, "seek": 215260, "start": 2152.6, "end": 2162.2799999999997, "text": " Like I think TypeScript has shown that like, I think that 99% guarantees are in a lot of", "tokens": [1743, 286, 519, 15576, 14237, 575, 4898, 300, 411, 11, 286, 519, 300, 11803, 4, 32567, 366, 294, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.23023668924967447, "compression_ratio": 1.4887892376681615, "no_speech_prob": 7.690186407671717e-07}, {"id": 539, "seek": 215260, "start": 2162.2799999999997, "end": 2163.72, "text": " people's minds.", "tokens": [561, 311, 9634, 13], "temperature": 0.0, "avg_logprob": -0.23023668924967447, "compression_ratio": 1.4887892376681615, "no_speech_prob": 7.690186407671717e-07}, {"id": 540, "seek": 215260, "start": 2163.72, "end": 2164.72, "text": " Fine.", "tokens": [12024, 13], "temperature": 0.0, "avg_logprob": -0.23023668924967447, "compression_ratio": 1.4887892376681615, "no_speech_prob": 7.690186407671717e-07}, {"id": 541, "seek": 215260, "start": 2164.72, "end": 2165.72, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.23023668924967447, "compression_ratio": 1.4887892376681615, "no_speech_prob": 7.690186407671717e-07}, {"id": 542, "seek": 215260, "start": 2165.72, "end": 2166.72, "text": " And, and that's okay.", "tokens": [400, 11, 293, 300, 311, 1392, 13], "temperature": 0.0, "avg_logprob": -0.23023668924967447, "compression_ratio": 1.4887892376681615, "no_speech_prob": 7.690186407671717e-07}, {"id": 543, "seek": 215260, "start": 2166.72, "end": 2173.64, "text": " But a lot of people calling JSON dot parse and it returning in any type, it's like, yeah,", "tokens": [583, 257, 688, 295, 561, 5141, 31828, 5893, 48377, 293, 309, 12678, 294, 604, 2010, 11, 309, 311, 411, 11, 1338, 11], "temperature": 0.0, "avg_logprob": -0.23023668924967447, "compression_ratio": 1.4887892376681615, "no_speech_prob": 7.690186407671717e-07}, {"id": 544, "seek": 215260, "start": 2173.64, "end": 2174.64, "text": " that's fine.", "tokens": [300, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.23023668924967447, "compression_ratio": 1.4887892376681615, "no_speech_prob": 7.690186407671717e-07}, {"id": 545, "seek": 215260, "start": 2174.64, "end": 2182.36, "text": " You know, or maybe they're like, well, I'll use Zod or IOTS and do a decoder style thing.", "tokens": [509, 458, 11, 420, 1310, 436, 434, 411, 11, 731, 11, 286, 603, 764, 1176, 378, 420, 286, 5068, 50, 293, 360, 257, 979, 19866, 3758, 551, 13], "temperature": 0.0, "avg_logprob": -0.23023668924967447, "compression_ratio": 1.4887892376681615, "no_speech_prob": 7.690186407671717e-07}, {"id": 546, "seek": 218236, "start": 2182.36, "end": 2188.32, "text": " And be really careful about not introducing any types, but some people are like a lot", "tokens": [400, 312, 534, 5026, 466, 406, 15424, 604, 3467, 11, 457, 512, 561, 366, 411, 257, 688], "temperature": 0.0, "avg_logprob": -0.23905248844877203, "compression_ratio": 1.6926406926406927, "no_speech_prob": 1.228899691341212e-06}, {"id": 547, "seek": 218236, "start": 2188.32, "end": 2194.0, "text": " of people see TypeScript more as a developer tool and a productivity tool and an auto-completion", "tokens": [295, 561, 536, 15576, 14237, 544, 382, 257, 10754, 2290, 293, 257, 15604, 2290, 293, 364, 8399, 12, 1112, 14657, 313], "temperature": 0.0, "avg_logprob": -0.23905248844877203, "compression_ratio": 1.6926406926406927, "no_speech_prob": 1.228899691341212e-06}, {"id": 548, "seek": 218236, "start": 2194.0, "end": 2200.56, "text": " tool rather than something that prevents crashes in their system and something, I mean, you", "tokens": [2290, 2831, 813, 746, 300, 22367, 28642, 294, 641, 1185, 293, 746, 11, 286, 914, 11, 291], "temperature": 0.0, "avg_logprob": -0.23905248844877203, "compression_ratio": 1.6926406926406927, "no_speech_prob": 1.228899691341212e-06}, {"id": 549, "seek": 218236, "start": 2200.56, "end": 2204.88, "text": " know, prevent some, but it doesn't prevent all and people, people aren't expecting it", "tokens": [458, 11, 4871, 512, 11, 457, 309, 1177, 380, 4871, 439, 293, 561, 11, 561, 3212, 380, 9650, 309], "temperature": 0.0, "avg_logprob": -0.23905248844877203, "compression_ratio": 1.6926406926406927, "no_speech_prob": 1.228899691341212e-06}, {"id": 550, "seek": 218236, "start": 2204.88, "end": 2206.76, "text": " to and they're okay with that.", "tokens": [281, 293, 436, 434, 1392, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.23905248844877203, "compression_ratio": 1.6926406926406927, "no_speech_prob": 1.228899691341212e-06}, {"id": 551, "seek": 220676, "start": 2206.76, "end": 2212.6800000000003, "text": " But yeah, when we can have an ecosystem built around this, it just opens up these interesting", "tokens": [583, 1338, 11, 562, 321, 393, 362, 364, 11311, 3094, 926, 341, 11, 309, 445, 9870, 493, 613, 1880], "temperature": 0.0, "avg_logprob": -0.22439403193337576, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.3287548199514276e-06}, {"id": 552, "seek": 220676, "start": 2212.6800000000003, "end": 2217.7200000000003, "text": " possibilities, which we haven't really even scratched the surface of with editor tooling,", "tokens": [12178, 11, 597, 321, 2378, 380, 534, 754, 40513, 264, 3753, 295, 365, 9839, 46593, 11], "temperature": 0.0, "avg_logprob": -0.22439403193337576, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.3287548199514276e-06}, {"id": 553, "seek": 220676, "start": 2217.7200000000003, "end": 2219.32, "text": " refactoring tools.", "tokens": [1895, 578, 3662, 3873, 13], "temperature": 0.0, "avg_logprob": -0.22439403193337576, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.3287548199514276e-06}, {"id": 554, "seek": 220676, "start": 2219.32, "end": 2226.1000000000004, "text": " You know, I mean, Elm Review has like filled a lot of this gap, but Elm Review still has", "tokens": [509, 458, 11, 286, 914, 11, 2699, 76, 19954, 575, 411, 6412, 257, 688, 295, 341, 7417, 11, 457, 2699, 76, 19954, 920, 575], "temperature": 0.0, "avg_logprob": -0.22439403193337576, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.3287548199514276e-06}, {"id": 555, "seek": 220676, "start": 2226.1000000000004, "end": 2229.4, "text": " so much more that it could do, I'm sure.", "tokens": [370, 709, 544, 300, 309, 727, 360, 11, 286, 478, 988, 13], "temperature": 0.0, "avg_logprob": -0.22439403193337576, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.3287548199514276e-06}, {"id": 556, "seek": 220676, "start": 2229.4, "end": 2230.4, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.22439403193337576, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.3287548199514276e-06}, {"id": 557, "seek": 220676, "start": 2230.4, "end": 2234.2400000000002, "text": " So like, we're really just scratching the surface of what we can do with this.", "tokens": [407, 411, 11, 321, 434, 534, 445, 29699, 264, 3753, 295, 437, 321, 393, 360, 365, 341, 13], "temperature": 0.0, "avg_logprob": -0.22439403193337576, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.3287548199514276e-06}, {"id": 558, "seek": 223424, "start": 2234.24, "end": 2239.6, "text": " Not to mention that, you know, as you talked about, like the thoughtfulness of the API", "tokens": [1726, 281, 2152, 300, 11, 291, 458, 11, 382, 291, 2825, 466, 11, 411, 264, 21566, 1287, 295, 264, 9362], "temperature": 0.0, "avg_logprob": -0.22464339230038705, "compression_ratio": 1.6718146718146718, "no_speech_prob": 1.20983725082624e-06}, {"id": 559, "seek": 223424, "start": 2239.6, "end": 2242.56, "text": " design that we see is really humbling.", "tokens": [1715, 300, 321, 536, 307, 534, 1484, 18262, 13], "temperature": 0.0, "avg_logprob": -0.22464339230038705, "compression_ratio": 1.6718146718146718, "no_speech_prob": 1.20983725082624e-06}, {"id": 560, "seek": 223424, "start": 2242.56, "end": 2247.2, "text": " And I mean, I love being a part of this community for that reason.", "tokens": [400, 286, 914, 11, 286, 959, 885, 257, 644, 295, 341, 1768, 337, 300, 1778, 13], "temperature": 0.0, "avg_logprob": -0.22464339230038705, "compression_ratio": 1.6718146718146718, "no_speech_prob": 1.20983725082624e-06}, {"id": 561, "seek": 223424, "start": 2247.2, "end": 2252.4799999999996, "text": " Like it's just like people really put a lot of care into the domain and they really think", "tokens": [1743, 309, 311, 445, 411, 561, 534, 829, 257, 688, 295, 1127, 666, 264, 9274, 293, 436, 534, 519], "temperature": 0.0, "avg_logprob": -0.22464339230038705, "compression_ratio": 1.6718146718146718, "no_speech_prob": 1.20983725082624e-06}, {"id": 562, "seek": 223424, "start": 2252.4799999999996, "end": 2257.3599999999997, "text": " through like they put so much care into that user's experience.", "tokens": [807, 411, 436, 829, 370, 709, 1127, 666, 300, 4195, 311, 1752, 13], "temperature": 0.0, "avg_logprob": -0.22464339230038705, "compression_ratio": 1.6718146718146718, "no_speech_prob": 1.20983725082624e-06}, {"id": 563, "seek": 223424, "start": 2257.3599999999997, "end": 2263.12, "text": " Like what is it going to be like using this package and what things could go wrong and", "tokens": [1743, 437, 307, 309, 516, 281, 312, 411, 1228, 341, 7372, 293, 437, 721, 727, 352, 2085, 293], "temperature": 0.0, "avg_logprob": -0.22464339230038705, "compression_ratio": 1.6718146718146718, "no_speech_prob": 1.20983725082624e-06}, {"id": 564, "seek": 226312, "start": 2263.12, "end": 2268.3599999999997, "text": " what things can I make so the user doesn't have to ever think about going wrong because", "tokens": [437, 721, 393, 286, 652, 370, 264, 4195, 1177, 380, 362, 281, 1562, 519, 466, 516, 2085, 570], "temperature": 0.0, "avg_logprob": -0.21551901228884432, "compression_ratio": 1.6744186046511629, "no_speech_prob": 1.3081561291983235e-06}, {"id": 565, "seek": 226312, "start": 2268.3599999999997, "end": 2269.8399999999997, "text": " I can prevent it entirely.", "tokens": [286, 393, 4871, 309, 7696, 13], "temperature": 0.0, "avg_logprob": -0.21551901228884432, "compression_ratio": 1.6744186046511629, "no_speech_prob": 1.3081561291983235e-06}, {"id": 566, "seek": 226312, "start": 2269.8399999999997, "end": 2275.08, "text": " And what things can I model that can go wrong because I can't avoid it, but I can make it", "tokens": [400, 437, 721, 393, 286, 2316, 300, 393, 352, 2085, 570, 286, 393, 380, 5042, 309, 11, 457, 286, 393, 652, 309], "temperature": 0.0, "avg_logprob": -0.21551901228884432, "compression_ratio": 1.6744186046511629, "no_speech_prob": 1.3081561291983235e-06}, {"id": 567, "seek": 226312, "start": 2275.08, "end": 2279.12, "text": " explicit and nice to work with and make those choices.", "tokens": [13691, 293, 1481, 281, 589, 365, 293, 652, 729, 7994, 13], "temperature": 0.0, "avg_logprob": -0.21551901228884432, "compression_ratio": 1.6744186046511629, "no_speech_prob": 1.3081561291983235e-06}, {"id": 568, "seek": 226312, "start": 2279.12, "end": 2285.48, "text": " So and as we talked about in our documentation episode, the Elm package docs are a big part", "tokens": [407, 293, 382, 321, 2825, 466, 294, 527, 14333, 3500, 11, 264, 2699, 76, 7372, 45623, 366, 257, 955, 644], "temperature": 0.0, "avg_logprob": -0.21551901228884432, "compression_ratio": 1.6744186046511629, "no_speech_prob": 1.3081561291983235e-06}, {"id": 569, "seek": 226312, "start": 2285.48, "end": 2286.64, "text": " of that.", "tokens": [295, 300, 13], "temperature": 0.0, "avg_logprob": -0.21551901228884432, "compression_ratio": 1.6744186046511629, "no_speech_prob": 1.3081561291983235e-06}, {"id": 570, "seek": 228664, "start": 2286.64, "end": 2293.92, "text": " And I mean, navigating documentation back when I was doing Ruby on Rails development", "tokens": [400, 286, 914, 11, 32054, 14333, 646, 562, 286, 390, 884, 19907, 322, 48526, 3250], "temperature": 0.0, "avg_logprob": -0.23042429555760752, "compression_ratio": 1.6963562753036436, "no_speech_prob": 2.19067555917718e-06}, {"id": 571, "seek": 228664, "start": 2293.92, "end": 2299.04, "text": " and JavaScript development, you know, sometimes tough, like finding what you were looking", "tokens": [293, 15778, 3250, 11, 291, 458, 11, 2171, 4930, 11, 411, 5006, 437, 291, 645, 1237], "temperature": 0.0, "avg_logprob": -0.23042429555760752, "compression_ratio": 1.6963562753036436, "no_speech_prob": 2.19067555917718e-06}, {"id": 572, "seek": 228664, "start": 2299.04, "end": 2302.58, "text": " for and like, what, what can I, what can I call?", "tokens": [337, 293, 411, 11, 437, 11, 437, 393, 286, 11, 437, 393, 286, 818, 30], "temperature": 0.0, "avg_logprob": -0.23042429555760752, "compression_ratio": 1.6963562753036436, "no_speech_prob": 2.19067555917718e-06}, {"id": 573, "seek": 228664, "start": 2302.58, "end": 2310.44, "text": " Because there's meta programming and things are, you know, except different types of values,", "tokens": [1436, 456, 311, 19616, 9410, 293, 721, 366, 11, 291, 458, 11, 3993, 819, 3467, 295, 4190, 11], "temperature": 0.0, "avg_logprob": -0.23042429555760752, "compression_ratio": 1.6963562753036436, "no_speech_prob": 2.19067555917718e-06}, {"id": 574, "seek": 228664, "start": 2310.44, "end": 2315.08, "text": " you know, except an object or null or undefined and have different behavior based on what", "tokens": [291, 458, 11, 3993, 364, 2657, 420, 18184, 420, 674, 5666, 2001, 293, 362, 819, 5223, 2361, 322, 437], "temperature": 0.0, "avg_logprob": -0.23042429555760752, "compression_ratio": 1.6963562753036436, "no_speech_prob": 2.19067555917718e-06}, {"id": 575, "seek": 228664, "start": 2315.08, "end": 2316.08, "text": " you pass in.", "tokens": [291, 1320, 294, 13], "temperature": 0.0, "avg_logprob": -0.23042429555760752, "compression_ratio": 1.6963562753036436, "no_speech_prob": 2.19067555917718e-06}, {"id": 576, "seek": 231608, "start": 2316.08, "end": 2321.92, "text": " So it's very, very pleasant to work with Elm APIs and very easy to navigate.", "tokens": [407, 309, 311, 588, 11, 588, 16232, 281, 589, 365, 2699, 76, 21445, 293, 588, 1858, 281, 12350, 13], "temperature": 0.0, "avg_logprob": -0.2827633478308237, "compression_ratio": 1.5534883720930233, "no_speech_prob": 1.267910761271196e-06}, {"id": 577, "seek": 231608, "start": 2321.92, "end": 2328.64, "text": " And it's just so, yeah, like I think, and in general, like I think I really at my core", "tokens": [400, 309, 311, 445, 370, 11, 1338, 11, 411, 286, 519, 11, 293, 294, 2674, 11, 411, 286, 519, 286, 534, 412, 452, 4965], "temperature": 0.0, "avg_logprob": -0.2827633478308237, "compression_ratio": 1.5534883720930233, "no_speech_prob": 1.267910761271196e-06}, {"id": 578, "seek": 231608, "start": 2328.64, "end": 2336.16, "text": " believe in this idea of working with pure functions as, as the basis of what we're writing", "tokens": [1697, 294, 341, 1558, 295, 1364, 365, 6075, 6828, 382, 11, 382, 264, 5143, 295, 437, 321, 434, 3579], "temperature": 0.0, "avg_logprob": -0.2827633478308237, "compression_ratio": 1.5534883720930233, "no_speech_prob": 1.267910761271196e-06}, {"id": 579, "seek": 231608, "start": 2336.16, "end": 2340.4, "text": " and building out all of these things around them.", "tokens": [293, 2390, 484, 439, 295, 613, 721, 926, 552, 13], "temperature": 0.0, "avg_logprob": -0.2827633478308237, "compression_ratio": 1.5534883720930233, "no_speech_prob": 1.267910761271196e-06}, {"id": 580, "seek": 231608, "start": 2340.4, "end": 2342.56, "text": " Again, like the mocks, right?", "tokens": [3764, 11, 411, 264, 705, 2761, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2827633478308237, "compression_ratio": 1.5534883720930233, "no_speech_prob": 1.267910761271196e-06}, {"id": 581, "seek": 234256, "start": 2342.56, "end": 2352.7599999999998, "text": " Like if you're a mock man, it's just like, it solves that problem by inverting things.", "tokens": [1743, 498, 291, 434, 257, 17362, 587, 11, 309, 311, 445, 411, 11, 309, 39890, 300, 1154, 538, 28653, 783, 721, 13], "temperature": 0.0, "avg_logprob": -0.21969279464410277, "compression_ratio": 1.7969543147208122, "no_speech_prob": 1.4823398259977694e-06}, {"id": 582, "seek": 234256, "start": 2352.7599999999998, "end": 2359.68, "text": " If you can't do non-deterministic things, if you can't mutate state and perform side", "tokens": [759, 291, 393, 380, 360, 2107, 12, 49136, 259, 3142, 721, 11, 498, 291, 393, 380, 5839, 473, 1785, 293, 2042, 1252], "temperature": 0.0, "avg_logprob": -0.21969279464410277, "compression_ratio": 1.7969543147208122, "no_speech_prob": 1.4823398259977694e-06}, {"id": 583, "seek": 234256, "start": 2359.68, "end": 2365.34, "text": " effects and do non-deterministic outputs from, from within your code, you can only do it", "tokens": [5065, 293, 360, 2107, 12, 49136, 259, 3142, 23930, 490, 11, 490, 1951, 428, 3089, 11, 291, 393, 787, 360, 309], "temperature": 0.0, "avg_logprob": -0.21969279464410277, "compression_ratio": 1.7969543147208122, "no_speech_prob": 1.4823398259977694e-06}, {"id": 584, "seek": 234256, "start": 2365.34, "end": 2367.24, "text": " from outside of your code.", "tokens": [490, 2380, 295, 428, 3089, 13], "temperature": 0.0, "avg_logprob": -0.21969279464410277, "compression_ratio": 1.7969543147208122, "no_speech_prob": 1.4823398259977694e-06}, {"id": 585, "seek": 234256, "start": 2367.24, "end": 2370.96, "text": " You can only pass it in from outside of your code as a dependency.", "tokens": [509, 393, 787, 1320, 309, 294, 490, 2380, 295, 428, 3089, 382, 257, 33621, 13], "temperature": 0.0, "avg_logprob": -0.21969279464410277, "compression_ratio": 1.7969543147208122, "no_speech_prob": 1.4823398259977694e-06}, {"id": 586, "seek": 237096, "start": 2370.96, "end": 2376.16, "text": " You've inverted that as a language feature, which is amazing.", "tokens": [509, 600, 38969, 300, 382, 257, 2856, 4111, 11, 597, 307, 2243, 13], "temperature": 0.0, "avg_logprob": -0.2074971670632834, "compression_ratio": 1.676056338028169, "no_speech_prob": 1.9333328964421526e-06}, {"id": 587, "seek": 237096, "start": 2376.16, "end": 2383.32, "text": " And I can't understate the value of that to me, having that as not a guideline and a principle", "tokens": [400, 286, 393, 380, 833, 15406, 264, 2158, 295, 300, 281, 385, 11, 1419, 300, 382, 406, 257, 41653, 293, 257, 8665], "temperature": 0.0, "avg_logprob": -0.2074971670632834, "compression_ratio": 1.676056338028169, "no_speech_prob": 1.9333328964421526e-06}, {"id": 588, "seek": 237096, "start": 2383.32, "end": 2389.64, "text": " and a best practice, but as a part of the language is very powerful.", "tokens": [293, 257, 1151, 3124, 11, 457, 382, 257, 644, 295, 264, 2856, 307, 588, 4005, 13], "temperature": 0.0, "avg_logprob": -0.2074971670632834, "compression_ratio": 1.676056338028169, "no_speech_prob": 1.9333328964421526e-06}, {"id": 589, "seek": 237096, "start": 2389.64, "end": 2392.64, "text": " And so I just deeply believe in that.", "tokens": [400, 370, 286, 445, 8760, 1697, 294, 300, 13], "temperature": 0.0, "avg_logprob": -0.2074971670632834, "compression_ratio": 1.676056338028169, "no_speech_prob": 1.9333328964421526e-06}, {"id": 590, "seek": 237096, "start": 2392.64, "end": 2400.92, "text": " I also believe in that not just for my beliefs about like best practices for coding you know,", "tokens": [286, 611, 1697, 294, 300, 406, 445, 337, 452, 13585, 466, 411, 1151, 7525, 337, 17720, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.2074971670632834, "compression_ratio": 1.676056338028169, "no_speech_prob": 1.9333328964421526e-06}, {"id": 591, "seek": 240092, "start": 2400.92, "end": 2407.44, "text": " taking small steps and making things testable and all these sorts of things, but also for", "tokens": [1940, 1359, 4439, 293, 1455, 721, 1500, 712, 293, 439, 613, 7527, 295, 721, 11, 457, 611, 337], "temperature": 0.0, "avg_logprob": -0.25697423973862005, "compression_ratio": 1.7155555555555555, "no_speech_prob": 4.222763891448267e-06}, {"id": 592, "seek": 240092, "start": 2407.44, "end": 2408.44, "text": " frameworks.", "tokens": [29834, 13], "temperature": 0.0, "avg_logprob": -0.25697423973862005, "compression_ratio": 1.7155555555555555, "no_speech_prob": 4.222763891448267e-06}, {"id": 593, "seek": 240092, "start": 2408.44, "end": 2413.76, "text": " Like I believe that it's a very good way to target things as a framework author to, to", "tokens": [1743, 286, 1697, 300, 309, 311, 257, 588, 665, 636, 281, 3779, 721, 382, 257, 8388, 3793, 281, 11, 281], "temperature": 0.0, "avg_logprob": -0.25697423973862005, "compression_ratio": 1.7155555555555555, "no_speech_prob": 4.222763891448267e-06}, {"id": 594, "seek": 240092, "start": 2413.76, "end": 2419.6, "text": " just neatly define like, here's the interface for this thing.", "tokens": [445, 36634, 6964, 411, 11, 510, 311, 264, 9226, 337, 341, 551, 13], "temperature": 0.0, "avg_logprob": -0.25697423973862005, "compression_ratio": 1.7155555555555555, "no_speech_prob": 4.222763891448267e-06}, {"id": 595, "seek": 240092, "start": 2419.6, "end": 2424.8, "text": " And I, as the framework, I'm going to be the interface between you and the outside world,", "tokens": [400, 286, 11, 382, 264, 8388, 11, 286, 478, 516, 281, 312, 264, 9226, 1296, 291, 293, 264, 2380, 1002, 11], "temperature": 0.0, "avg_logprob": -0.25697423973862005, "compression_ratio": 1.7155555555555555, "no_speech_prob": 4.222763891448267e-06}, {"id": 596, "seek": 240092, "start": 2424.8, "end": 2427.0, "text": " but I'm going to clearly define the contract.", "tokens": [457, 286, 478, 516, 281, 4448, 6964, 264, 4364, 13], "temperature": 0.0, "avg_logprob": -0.25697423973862005, "compression_ratio": 1.7155555555555555, "no_speech_prob": 4.222763891448267e-06}, {"id": 597, "seek": 242700, "start": 2427.0, "end": 2432.0, "text": " Choose your contract of what you can ask me to do, and I'll go do the dirty stuff in the", "tokens": [21661, 428, 4364, 295, 437, 291, 393, 1029, 385, 281, 360, 11, 293, 286, 603, 352, 360, 264, 9360, 1507, 294, 264], "temperature": 0.0, "avg_logprob": -0.23660439181040568, "compression_ratio": 1.5391705069124424, "no_speech_prob": 8.01322403276572e-06}, {"id": 598, "seek": 242700, "start": 2432.0, "end": 2435.92, "text": " outside world that performs side effects and does impure things.", "tokens": [2380, 1002, 300, 26213, 1252, 5065, 293, 775, 704, 540, 721, 13], "temperature": 0.0, "avg_logprob": -0.23660439181040568, "compression_ratio": 1.5391705069124424, "no_speech_prob": 8.01322403276572e-06}, {"id": 599, "seek": 242700, "start": 2435.92, "end": 2442.32, "text": " So building Elm pages, that's been something I've really started to believe more deeply", "tokens": [407, 2390, 2699, 76, 7183, 11, 300, 311, 668, 746, 286, 600, 534, 1409, 281, 1697, 544, 8760], "temperature": 0.0, "avg_logprob": -0.23660439181040568, "compression_ratio": 1.5391705069124424, "no_speech_prob": 8.01322403276572e-06}, {"id": 600, "seek": 242700, "start": 2442.32, "end": 2451.48, "text": " as well is that Elm is actually a very powerful tool for, as a target for framework authors.", "tokens": [382, 731, 307, 300, 2699, 76, 307, 767, 257, 588, 4005, 2290, 337, 11, 382, 257, 3779, 337, 8388, 16552, 13], "temperature": 0.0, "avg_logprob": -0.23660439181040568, "compression_ratio": 1.5391705069124424, "no_speech_prob": 8.01322403276572e-06}, {"id": 601, "seek": 245148, "start": 2451.48, "end": 2458.4, "text": " And I, well, actually the day that we're recording this is the day after I released Elm Pages", "tokens": [400, 286, 11, 731, 11, 767, 264, 786, 300, 321, 434, 6613, 341, 307, 264, 786, 934, 286, 4736, 2699, 76, 430, 1660], "temperature": 0.0, "avg_logprob": -0.28949699761732567, "compression_ratio": 1.5855855855855856, "no_speech_prob": 1.6026774574129377e-06}, {"id": 602, "seek": 245148, "start": 2458.4, "end": 2460.76, "text": " V3.", "tokens": [691, 18, 13], "temperature": 0.0, "avg_logprob": -0.28949699761732567, "compression_ratio": 1.5855855855855856, "no_speech_prob": 1.6026774574129377e-06}, {"id": 603, "seek": 245148, "start": 2460.76, "end": 2467.64, "text": " And I hope that there will be more big framework releases like this to come in the Elm ecosystem,", "tokens": [400, 286, 1454, 300, 456, 486, 312, 544, 955, 8388, 16952, 411, 341, 281, 808, 294, 264, 2699, 76, 11311, 11], "temperature": 0.0, "avg_logprob": -0.28949699761732567, "compression_ratio": 1.5855855855855856, "no_speech_prob": 1.6026774574129377e-06}, {"id": 604, "seek": 245148, "start": 2467.64, "end": 2470.72, "text": " because I think it's a very promising part of the Elm language.", "tokens": [570, 286, 519, 309, 311, 257, 588, 20257, 644, 295, 264, 2699, 76, 2856, 13], "temperature": 0.0, "avg_logprob": -0.28949699761732567, "compression_ratio": 1.5855855855855856, "no_speech_prob": 1.6026774574129377e-06}, {"id": 605, "seek": 245148, "start": 2470.72, "end": 2476.0, "text": " And I hope it's for the maintainer because it's been a lot of work.", "tokens": [400, 286, 1454, 309, 311, 337, 264, 6909, 260, 570, 309, 311, 668, 257, 688, 295, 589, 13], "temperature": 0.0, "avg_logprob": -0.28949699761732567, "compression_ratio": 1.5855855855855856, "no_speech_prob": 1.6026774574129377e-06}, {"id": 606, "seek": 245148, "start": 2476.0, "end": 2477.0, "text": " It has.", "tokens": [467, 575, 13], "temperature": 0.0, "avg_logprob": -0.28949699761732567, "compression_ratio": 1.5855855855855856, "no_speech_prob": 1.6026774574129377e-06}, {"id": 607, "seek": 245148, "start": 2477.0, "end": 2478.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.28949699761732567, "compression_ratio": 1.5855855855855856, "no_speech_prob": 1.6026774574129377e-06}, {"id": 608, "seek": 245148, "start": 2478.0, "end": 2479.0, "text": " Very true.", "tokens": [4372, 2074, 13], "temperature": 0.0, "avg_logprob": -0.28949699761732567, "compression_ratio": 1.5855855855855856, "no_speech_prob": 1.6026774574129377e-06}, {"id": 609, "seek": 247900, "start": 2479.0, "end": 2486.96, "text": " Yeah, I think we could do with maybe a suite of tools to empower framework authors.", "tokens": [865, 11, 286, 519, 321, 727, 360, 365, 1310, 257, 14205, 295, 3873, 281, 11071, 8388, 16552, 13], "temperature": 0.0, "avg_logprob": -0.21407460591879235, "compression_ratio": 1.5670103092783505, "no_speech_prob": 1.6796129784779623e-06}, {"id": 610, "seek": 247900, "start": 2486.96, "end": 2493.16, "text": " I'm not sure if that would be at the compiler level or a set of meta tools, but whatever", "tokens": [286, 478, 406, 988, 498, 300, 576, 312, 412, 264, 31958, 1496, 420, 257, 992, 295, 19616, 3873, 11, 457, 2035], "temperature": 0.0, "avg_logprob": -0.21407460591879235, "compression_ratio": 1.5670103092783505, "no_speech_prob": 1.6796129784779623e-06}, {"id": 611, "seek": 247900, "start": 2493.16, "end": 2496.48, "text": " it is, yeah, we could definitely empower.", "tokens": [309, 307, 11, 1338, 11, 321, 727, 2138, 11071, 13], "temperature": 0.0, "avg_logprob": -0.21407460591879235, "compression_ratio": 1.5670103092783505, "no_speech_prob": 1.6796129784779623e-06}, {"id": 612, "seek": 247900, "start": 2496.48, "end": 2502.16, "text": " And in general, I think, I mean, I think that's what I most wish for the Elm ecosystem is", "tokens": [400, 294, 2674, 11, 286, 519, 11, 286, 914, 11, 286, 519, 300, 311, 437, 286, 881, 3172, 337, 264, 2699, 76, 11311, 307], "temperature": 0.0, "avg_logprob": -0.21407460591879235, "compression_ratio": 1.5670103092783505, "no_speech_prob": 1.6796129784779623e-06}, {"id": 613, "seek": 250216, "start": 2502.16, "end": 2510.68, "text": " that we could empower authors of tools to do more, like having more access to type information", "tokens": [300, 321, 727, 11071, 16552, 295, 3873, 281, 360, 544, 11, 411, 1419, 544, 2105, 281, 2010, 1589], "temperature": 0.0, "avg_logprob": -0.2677178581555684, "compression_ratio": 1.6311111111111112, "no_speech_prob": 3.4464248983567813e-06}, {"id": 614, "seek": 250216, "start": 2510.68, "end": 2512.12, "text": " and things like that.", "tokens": [293, 721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.2677178581555684, "compression_ratio": 1.6311111111111112, "no_speech_prob": 3.4464248983567813e-06}, {"id": 615, "seek": 250216, "start": 2512.12, "end": 2518.52, "text": " Like if we have that, I feel like so many powerful tools would come out of that.", "tokens": [1743, 498, 321, 362, 300, 11, 286, 841, 411, 370, 867, 4005, 3873, 576, 808, 484, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.2677178581555684, "compression_ratio": 1.6311111111111112, "no_speech_prob": 3.4464248983567813e-06}, {"id": 616, "seek": 250216, "start": 2518.52, "end": 2519.52, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2677178581555684, "compression_ratio": 1.6311111111111112, "no_speech_prob": 3.4464248983567813e-06}, {"id": 617, "seek": 250216, "start": 2519.52, "end": 2523.16, "text": " See, you're not even asking for new features in the language.", "tokens": [3008, 11, 291, 434, 406, 754, 3365, 337, 777, 4122, 294, 264, 2856, 13], "temperature": 0.0, "avg_logprob": -0.2677178581555684, "compression_ratio": 1.6311111111111112, "no_speech_prob": 3.4464248983567813e-06}, {"id": 618, "seek": 250216, "start": 2523.16, "end": 2524.44, "text": " Right, exactly.", "tokens": [1779, 11, 2293, 13], "temperature": 0.0, "avg_logprob": -0.2677178581555684, "compression_ratio": 1.6311111111111112, "no_speech_prob": 3.4464248983567813e-06}, {"id": 619, "seek": 250216, "start": 2524.44, "end": 2529.92, "text": " You just want the things that we have to be even easier to access to make even better", "tokens": [509, 445, 528, 264, 721, 300, 321, 362, 281, 312, 754, 3571, 281, 2105, 281, 652, 754, 1101], "temperature": 0.0, "avg_logprob": -0.2677178581555684, "compression_ratio": 1.6311111111111112, "no_speech_prob": 3.4464248983567813e-06}, {"id": 620, "seek": 252992, "start": 2529.92, "end": 2533.04, "text": " tools or better frameworks or better packages.", "tokens": [3873, 420, 1101, 29834, 420, 1101, 17401, 13], "temperature": 0.0, "avg_logprob": -0.222315168872322, "compression_ratio": 1.6150793650793651, "no_speech_prob": 1.65365315751842e-06}, {"id": 621, "seek": 252992, "start": 2533.04, "end": 2535.44, "text": " Yes, exactly.", "tokens": [1079, 11, 2293, 13], "temperature": 0.0, "avg_logprob": -0.222315168872322, "compression_ratio": 1.6150793650793651, "no_speech_prob": 1.65365315751842e-06}, {"id": 622, "seek": 252992, "start": 2535.44, "end": 2538.84, "text": " Because there's so much rich information that the compiler has.", "tokens": [1436, 456, 311, 370, 709, 4593, 1589, 300, 264, 31958, 575, 13], "temperature": 0.0, "avg_logprob": -0.222315168872322, "compression_ratio": 1.6150793650793651, "no_speech_prob": 1.65365315751842e-06}, {"id": 623, "seek": 252992, "start": 2538.84, "end": 2545.84, "text": " And when you pair that together with the guarantees that the language gives you, the tooling", "tokens": [400, 562, 291, 6119, 300, 1214, 365, 264, 32567, 300, 264, 2856, 2709, 291, 11, 264, 46593], "temperature": 0.0, "avg_logprob": -0.222315168872322, "compression_ratio": 1.6150793650793651, "no_speech_prob": 1.65365315751842e-06}, {"id": 624, "seek": 252992, "start": 2545.84, "end": 2548.12, "text": " possibilities are endless.", "tokens": [12178, 366, 16144, 13], "temperature": 0.0, "avg_logprob": -0.222315168872322, "compression_ratio": 1.6150793650793651, "no_speech_prob": 1.65365315751842e-06}, {"id": 625, "seek": 252992, "start": 2548.12, "end": 2553.84, "text": " But if we had an easier way to make use of those and didn't have to reinvent the wheel", "tokens": [583, 498, 321, 632, 364, 3571, 636, 281, 652, 764, 295, 729, 293, 994, 380, 362, 281, 33477, 264, 5589], "temperature": 0.0, "avg_logprob": -0.222315168872322, "compression_ratio": 1.6150793650793651, "no_speech_prob": 1.65365315751842e-06}, {"id": 626, "seek": 252992, "start": 2553.84, "end": 2559.4, "text": " every time as tooling authors, I think it would enable a lot of innovation.", "tokens": [633, 565, 382, 46593, 16552, 11, 286, 519, 309, 576, 9528, 257, 688, 295, 8504, 13], "temperature": 0.0, "avg_logprob": -0.222315168872322, "compression_ratio": 1.6150793650793651, "no_speech_prob": 1.65365315751842e-06}, {"id": 627, "seek": 255940, "start": 2559.4, "end": 2564.34, "text": " And that's like, I think that's really what Elm needs to blossom.", "tokens": [400, 300, 311, 411, 11, 286, 519, 300, 311, 534, 437, 2699, 76, 2203, 281, 38524, 13], "temperature": 0.0, "avg_logprob": -0.2567223288796165, "compression_ratio": 1.703056768558952, "no_speech_prob": 1.1658719813567586e-05}, {"id": 628, "seek": 255940, "start": 2564.34, "end": 2570.28, "text": " Like you said, it's not, it's not so much new, like there aren't that many language", "tokens": [1743, 291, 848, 11, 309, 311, 406, 11, 309, 311, 406, 370, 709, 777, 11, 411, 456, 3212, 380, 300, 867, 2856], "temperature": 0.0, "avg_logprob": -0.2567223288796165, "compression_ratio": 1.703056768558952, "no_speech_prob": 1.1658719813567586e-05}, {"id": 629, "seek": 255940, "start": 2570.28, "end": 2577.44, "text": " features that Elm really needs, maybe a handful of small improvements, but nothing, nothing", "tokens": [4122, 300, 2699, 76, 534, 2203, 11, 1310, 257, 16458, 295, 1359, 13797, 11, 457, 1825, 11, 1825], "temperature": 0.0, "avg_logprob": -0.2567223288796165, "compression_ratio": 1.703056768558952, "no_speech_prob": 1.1658719813567586e-05}, {"id": 630, "seek": 255940, "start": 2577.44, "end": 2578.44, "text": " massive.", "tokens": [5994, 13], "temperature": 0.0, "avg_logprob": -0.2567223288796165, "compression_ratio": 1.703056768558952, "no_speech_prob": 1.1658719813567586e-05}, {"id": 631, "seek": 255940, "start": 2578.44, "end": 2580.48, "text": " There's like, that's not the main thing it needs.", "tokens": [821, 311, 411, 11, 300, 311, 406, 264, 2135, 551, 309, 2203, 13], "temperature": 0.0, "avg_logprob": -0.2567223288796165, "compression_ratio": 1.703056768558952, "no_speech_prob": 1.1658719813567586e-05}, {"id": 632, "seek": 255940, "start": 2580.48, "end": 2587.2400000000002, "text": " I do feel like we're both on the, of the opinion, like what Elm is missing is more tools.", "tokens": [286, 360, 841, 411, 321, 434, 1293, 322, 264, 11, 295, 264, 4800, 11, 411, 437, 2699, 76, 307, 5361, 307, 544, 3873, 13], "temperature": 0.0, "avg_logprob": -0.2567223288796165, "compression_ratio": 1.703056768558952, "no_speech_prob": 1.1658719813567586e-05}, {"id": 633, "seek": 258724, "start": 2587.24, "end": 2590.0, "text": " At least that was what we said.", "tokens": [1711, 1935, 300, 390, 437, 321, 848, 13], "temperature": 0.0, "avg_logprob": -0.2738844283083652, "compression_ratio": 1.5727699530516432, "no_speech_prob": 1.3080604048809619e-06}, {"id": 634, "seek": 258724, "start": 2590.0, "end": 2596.68, "text": " And I'm sure that if we, if other people talked about the same topic in Elm, like more regular", "tokens": [400, 286, 478, 988, 300, 498, 321, 11, 498, 661, 561, 2825, 466, 264, 912, 4829, 294, 2699, 76, 11, 411, 544, 3890], "temperature": 0.0, "avg_logprob": -0.2738844283083652, "compression_ratio": 1.5727699530516432, "no_speech_prob": 1.3080604048809619e-06}, {"id": 635, "seek": 258724, "start": 2596.68, "end": 2602.2, "text": " users of Elm, just people who write Elm to do their day job, then they would have a very", "tokens": [5022, 295, 2699, 76, 11, 445, 561, 567, 2464, 2699, 76, 281, 360, 641, 786, 1691, 11, 550, 436, 576, 362, 257, 588], "temperature": 0.0, "avg_logprob": -0.2738844283083652, "compression_ratio": 1.5727699530516432, "no_speech_prob": 1.3080604048809619e-06}, {"id": 636, "seek": 258724, "start": 2602.2, "end": 2606.8399999999997, "text": " different reply to this or different opinion of this.", "tokens": [819, 16972, 281, 341, 420, 819, 4800, 295, 341, 13], "temperature": 0.0, "avg_logprob": -0.2738844283083652, "compression_ratio": 1.5727699530516432, "no_speech_prob": 1.3080604048809619e-06}, {"id": 637, "seek": 258724, "start": 2606.8399999999997, "end": 2610.4399999999996, "text": " At least I don't think they would focus on tooling as much.", "tokens": [1711, 1935, 286, 500, 380, 519, 436, 576, 1879, 322, 46593, 382, 709, 13], "temperature": 0.0, "avg_logprob": -0.2738844283083652, "compression_ratio": 1.5727699530516432, "no_speech_prob": 1.3080604048809619e-06}, {"id": 638, "seek": 258724, "start": 2610.4399999999996, "end": 2611.4399999999996, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2738844283083652, "compression_ratio": 1.5727699530516432, "no_speech_prob": 1.3080604048809619e-06}, {"id": 639, "seek": 261144, "start": 2611.44, "end": 2617.8, "text": " In practice, I think most people, they want better tools and for people in the JavaScript", "tokens": [682, 3124, 11, 286, 519, 881, 561, 11, 436, 528, 1101, 3873, 293, 337, 561, 294, 264, 15778], "temperature": 0.0, "avg_logprob": -0.27919874298438596, "compression_ratio": 1.6805555555555556, "no_speech_prob": 1.5292878288164502e-06}, {"id": 640, "seek": 261144, "start": 2617.8, "end": 2623.48, "text": " world, for instance, that often comes, that often comes from new language features or", "tokens": [1002, 11, 337, 5197, 11, 300, 2049, 1487, 11, 300, 2049, 1487, 490, 777, 2856, 4122, 420], "temperature": 0.0, "avg_logprob": -0.27919874298438596, "compression_ratio": 1.6805555555555556, "no_speech_prob": 1.5292878288164502e-06}, {"id": 641, "seek": 261144, "start": 2623.48, "end": 2626.7200000000003, "text": " new framework or new build tools or whatever.", "tokens": [777, 8388, 420, 777, 1322, 3873, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.27919874298438596, "compression_ratio": 1.6805555555555556, "no_speech_prob": 1.5292878288164502e-06}, {"id": 642, "seek": 261144, "start": 2626.7200000000003, "end": 2630.36, "text": " So yeah, also tooling, but also sometimes new language features.", "tokens": [407, 1338, 11, 611, 46593, 11, 457, 611, 2171, 777, 2856, 4122, 13], "temperature": 0.0, "avg_logprob": -0.27919874298438596, "compression_ratio": 1.6805555555555556, "no_speech_prob": 1.5292878288164502e-06}, {"id": 643, "seek": 261144, "start": 2630.36, "end": 2631.36, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.27919874298438596, "compression_ratio": 1.6805555555555556, "no_speech_prob": 1.5292878288164502e-06}, {"id": 644, "seek": 261144, "start": 2631.36, "end": 2635.7200000000003, "text": " I mean, we, we would definitely benefit a lot from a larger ecosystem.", "tokens": [286, 914, 11, 321, 11, 321, 576, 2138, 5121, 257, 688, 490, 257, 4833, 11311, 13], "temperature": 0.0, "avg_logprob": -0.27919874298438596, "compression_ratio": 1.6805555555555556, "no_speech_prob": 1.5292878288164502e-06}, {"id": 645, "seek": 263572, "start": 2635.72, "end": 2642.12, "text": " You know, I mean, it would be great to, if you want to use a particular, you know, view,", "tokens": [509, 458, 11, 286, 914, 11, 309, 576, 312, 869, 281, 11, 498, 291, 528, 281, 764, 257, 1729, 11, 291, 458, 11, 1910, 11], "temperature": 0.0, "avg_logprob": -0.23667975033030791, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.76029618614848e-06}, {"id": 646, "seek": 263572, "start": 2642.12, "end": 2648.4399999999996, "text": " view library, it would be great if there were some no brainer choices for doing material", "tokens": [1910, 6405, 11, 309, 576, 312, 869, 498, 456, 645, 512, 572, 3567, 260, 7994, 337, 884, 2527], "temperature": 0.0, "avg_logprob": -0.23667975033030791, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.76029618614848e-06}, {"id": 647, "seek": 263572, "start": 2648.4399999999996, "end": 2652.16, "text": " UI or Ant design or whatever it is in Elm.", "tokens": [15682, 420, 5130, 1715, 420, 2035, 309, 307, 294, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.23667975033030791, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.76029618614848e-06}, {"id": 648, "seek": 263572, "start": 2652.16, "end": 2657.14, "text": " That would definitely be a huge boon for, for the Elm community, I think.", "tokens": [663, 576, 2138, 312, 257, 2603, 748, 266, 337, 11, 337, 264, 2699, 76, 1768, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.23667975033030791, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.76029618614848e-06}, {"id": 649, "seek": 263572, "start": 2657.14, "end": 2660.56, "text": " Another reason why I care about Elm is just, I find it fun.", "tokens": [3996, 1778, 983, 286, 1127, 466, 2699, 76, 307, 445, 11, 286, 915, 309, 1019, 13], "temperature": 0.0, "avg_logprob": -0.23667975033030791, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.76029618614848e-06}, {"id": 650, "seek": 266056, "start": 2660.56, "end": 2667.04, "text": " It's like just working on, no, not even working on Elm things.", "tokens": [467, 311, 411, 445, 1364, 322, 11, 572, 11, 406, 754, 1364, 322, 2699, 76, 721, 13], "temperature": 0.0, "avg_logprob": -0.26418775535491573, "compression_ratio": 1.5485714285714285, "no_speech_prob": 9.874157740341616e-07}, {"id": 651, "seek": 266056, "start": 2667.04, "end": 2668.88, "text": " It's like working with Elm.", "tokens": [467, 311, 411, 1364, 365, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.26418775535491573, "compression_ratio": 1.5485714285714285, "no_speech_prob": 9.874157740341616e-07}, {"id": 652, "seek": 266056, "start": 2668.88, "end": 2674.72, "text": " I'm for instance, super happy that I've built Elm review in Elm, at least mostly in Elm.", "tokens": [286, 478, 337, 5197, 11, 1687, 2055, 300, 286, 600, 3094, 2699, 76, 3131, 294, 2699, 76, 11, 412, 1935, 5240, 294, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.26418775535491573, "compression_ratio": 1.5485714285714285, "no_speech_prob": 9.874157740341616e-07}, {"id": 653, "seek": 266056, "start": 2674.72, "end": 2682.96, "text": " The Elm parts are the more, the most fun ones and just the, yeah, the, the sheer simplicity", "tokens": [440, 2699, 76, 3166, 366, 264, 544, 11, 264, 881, 1019, 2306, 293, 445, 264, 11, 1338, 11, 264, 11, 264, 23061, 25632], "temperature": 0.0, "avg_logprob": -0.26418775535491573, "compression_ratio": 1.5485714285714285, "no_speech_prob": 9.874157740341616e-07}, {"id": 654, "seek": 268296, "start": 2682.96, "end": 2690.68, "text": " of refactoring and adding new features and making sure you don't have to, not having", "tokens": [295, 1895, 578, 3662, 293, 5127, 777, 4122, 293, 1455, 988, 291, 500, 380, 362, 281, 11, 406, 1419], "temperature": 0.0, "avg_logprob": -0.28015336223032283, "compression_ratio": 1.5391705069124424, "no_speech_prob": 1.5778954320921912e-06}, {"id": 655, "seek": 268296, "start": 2690.68, "end": 2696.1, "text": " to think about all the edge cases because the compiler will remind you about those.", "tokens": [281, 519, 466, 439, 264, 4691, 3331, 570, 264, 31958, 486, 4160, 291, 466, 729, 13], "temperature": 0.0, "avg_logprob": -0.28015336223032283, "compression_ratio": 1.5391705069124424, "no_speech_prob": 1.5778954320921912e-06}, {"id": 656, "seek": 268296, "start": 2696.1, "end": 2698.48, "text": " It's just feels so nice.", "tokens": [467, 311, 445, 3417, 370, 1481, 13], "temperature": 0.0, "avg_logprob": -0.28015336223032283, "compression_ratio": 1.5391705069124424, "no_speech_prob": 1.5778954320921912e-06}, {"id": 657, "seek": 268296, "start": 2698.48, "end": 2705.44, "text": " It's just very enjoyable, very relaxing compared to when I work on Elm review, but on the CLI", "tokens": [467, 311, 445, 588, 20305, 11, 588, 20103, 5347, 281, 562, 286, 589, 322, 2699, 76, 3131, 11, 457, 322, 264, 12855, 40], "temperature": 0.0, "avg_logprob": -0.28015336223032283, "compression_ratio": 1.5391705069124424, "no_speech_prob": 1.5778954320921912e-06}, {"id": 658, "seek": 268296, "start": 2705.44, "end": 2709.32, "text": " part, which is in parts written in JavaScript.", "tokens": [644, 11, 597, 307, 294, 3166, 3720, 294, 15778, 13], "temperature": 0.0, "avg_logprob": -0.28015336223032283, "compression_ratio": 1.5391705069124424, "no_speech_prob": 1.5778954320921912e-06}, {"id": 659, "seek": 270932, "start": 2709.32, "end": 2716.6000000000004, "text": " Now with a slightly bit TypeScript or JavaScript with JS doc and it's not a fun.", "tokens": [823, 365, 257, 4748, 857, 15576, 14237, 420, 15778, 365, 33063, 3211, 293, 309, 311, 406, 257, 1019, 13], "temperature": 0.0, "avg_logprob": -0.2751279037989927, "compression_ratio": 1.5462555066079295, "no_speech_prob": 3.726515842572553e-06}, {"id": 660, "seek": 270932, "start": 2716.6000000000004, "end": 2718.7200000000003, "text": " Yeah, I feel the same way.", "tokens": [865, 11, 286, 841, 264, 912, 636, 13], "temperature": 0.0, "avg_logprob": -0.2751279037989927, "compression_ratio": 1.5462555066079295, "no_speech_prob": 3.726515842572553e-06}, {"id": 661, "seek": 270932, "start": 2718.7200000000003, "end": 2725.2400000000002, "text": " And I definitely make the sacrifice of writing JavaScript and TypeScript to build these meta", "tokens": [400, 286, 2138, 652, 264, 11521, 295, 3579, 15778, 293, 15576, 14237, 281, 1322, 613, 19616], "temperature": 0.0, "avg_logprob": -0.2751279037989927, "compression_ratio": 1.5462555066079295, "no_speech_prob": 3.726515842572553e-06}, {"id": 662, "seek": 270932, "start": 2725.2400000000002, "end": 2728.1600000000003, "text": " frameworks to make it nicer to work in the Elm ecosystem.", "tokens": [29834, 281, 652, 309, 22842, 281, 589, 294, 264, 2699, 76, 11311, 13], "temperature": 0.0, "avg_logprob": -0.2751279037989927, "compression_ratio": 1.5462555066079295, "no_speech_prob": 3.726515842572553e-06}, {"id": 663, "seek": 270932, "start": 2728.1600000000003, "end": 2735.52, "text": " But then once I can move away from that and just say, okay, I built all this infrastructure.", "tokens": [583, 550, 1564, 286, 393, 1286, 1314, 490, 300, 293, 445, 584, 11, 1392, 11, 286, 3094, 439, 341, 6896, 13], "temperature": 0.0, "avg_logprob": -0.2751279037989927, "compression_ratio": 1.5462555066079295, "no_speech_prob": 3.726515842572553e-06}, {"id": 664, "seek": 273552, "start": 2735.52, "end": 2740.56, "text": " Now let me sit down and write an Elm pages script, you know, or let me write a route", "tokens": [823, 718, 385, 1394, 760, 293, 2464, 364, 2699, 76, 7183, 5755, 11, 291, 458, 11, 420, 718, 385, 2464, 257, 7955], "temperature": 0.0, "avg_logprob": -0.21591600745615333, "compression_ratio": 1.625, "no_speech_prob": 1.4593547348340508e-06}, {"id": 665, "seek": 273552, "start": 2740.56, "end": 2742.64, "text": " module in my Elm pages app.", "tokens": [10088, 294, 452, 2699, 76, 7183, 724, 13], "temperature": 0.0, "avg_logprob": -0.21591600745615333, "compression_ratio": 1.625, "no_speech_prob": 1.4593547348340508e-06}, {"id": 666, "seek": 273552, "start": 2742.64, "end": 2747.96, "text": " Like yeah, I feel so happy just having that explicitness and the Elm compiler to help", "tokens": [1743, 1338, 11, 286, 841, 370, 2055, 445, 1419, 300, 28021, 6394, 293, 264, 2699, 76, 31958, 281, 854], "temperature": 0.0, "avg_logprob": -0.21591600745615333, "compression_ratio": 1.625, "no_speech_prob": 1.4593547348340508e-06}, {"id": 667, "seek": 273552, "start": 2747.96, "end": 2748.96, "text": " me.", "tokens": [385, 13], "temperature": 0.0, "avg_logprob": -0.21591600745615333, "compression_ratio": 1.625, "no_speech_prob": 1.4593547348340508e-06}, {"id": 668, "seek": 273552, "start": 2748.96, "end": 2752.7599999999998, "text": " And again, like not having to wonder, does this throw an exception?", "tokens": [400, 797, 11, 411, 406, 1419, 281, 2441, 11, 775, 341, 3507, 364, 11183, 30], "temperature": 0.0, "avg_logprob": -0.21591600745615333, "compression_ratio": 1.625, "no_speech_prob": 1.4593547348340508e-06}, {"id": 669, "seek": 273552, "start": 2752.7599999999998, "end": 2759.24, "text": " Does, does this change some state somewhere, you know, or should this use the shovel operator", "tokens": [4402, 11, 775, 341, 1319, 512, 1785, 4079, 11, 291, 458, 11, 420, 820, 341, 764, 264, 29789, 12973], "temperature": 0.0, "avg_logprob": -0.21591600745615333, "compression_ratio": 1.625, "no_speech_prob": 1.4593547348340508e-06}, {"id": 670, "seek": 275924, "start": 2759.24, "end": 2768.8799999999997, "text": " or a map or a for loop or an each loop, you know, or it just see like, it really does", "tokens": [420, 257, 4471, 420, 257, 337, 6367, 420, 364, 1184, 6367, 11, 291, 458, 11, 420, 309, 445, 536, 411, 11, 309, 534, 775], "temperature": 0.0, "avg_logprob": -0.1939847961930204, "compression_ratio": 1.7257383966244726, "no_speech_prob": 6.083500352360716e-07}, {"id": 671, "seek": 275924, "start": 2768.8799999999997, "end": 2774.0, "text": " feel like there's, there's almost one way to express a lot of Elm code.", "tokens": [841, 411, 456, 311, 11, 456, 311, 1920, 472, 636, 281, 5109, 257, 688, 295, 2699, 76, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1939847961930204, "compression_ratio": 1.7257383966244726, "no_speech_prob": 6.083500352360716e-07}, {"id": 672, "seek": 275924, "start": 2774.0, "end": 2779.4399999999996, "text": " Of course it's not literally one way, but it, it, it feels like you write Elm and it,", "tokens": [2720, 1164, 309, 311, 406, 3736, 472, 636, 11, 457, 309, 11, 309, 11, 309, 3417, 411, 291, 2464, 2699, 76, 293, 309, 11], "temperature": 0.0, "avg_logprob": -0.1939847961930204, "compression_ratio": 1.7257383966244726, "no_speech_prob": 6.083500352360716e-07}, {"id": 673, "seek": 275924, "start": 2779.4399999999996, "end": 2781.3999999999996, "text": " you don't have to think about all these details.", "tokens": [291, 500, 380, 362, 281, 519, 466, 439, 613, 4365, 13], "temperature": 0.0, "avg_logprob": -0.1939847961930204, "compression_ratio": 1.7257383966244726, "no_speech_prob": 6.083500352360716e-07}, {"id": 674, "seek": 275924, "start": 2781.3999999999996, "end": 2787.02, "text": " You think about what is the problem I'm solving and, and you can refactor your code.", "tokens": [509, 519, 466, 437, 307, 264, 1154, 286, 478, 12606, 293, 11, 293, 291, 393, 1895, 15104, 428, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1939847961930204, "compression_ratio": 1.7257383966244726, "no_speech_prob": 6.083500352360716e-07}, {"id": 675, "seek": 275924, "start": 2787.02, "end": 2788.7599999999998, "text": " It's fun to refactor your code.", "tokens": [467, 311, 1019, 281, 1895, 15104, 428, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1939847961930204, "compression_ratio": 1.7257383966244726, "no_speech_prob": 6.083500352360716e-07}, {"id": 676, "seek": 278876, "start": 2788.76, "end": 2790.2400000000002, "text": " It's not scary.", "tokens": [467, 311, 406, 6958, 13], "temperature": 0.0, "avg_logprob": -0.22844094745183396, "compression_ratio": 1.6083333333333334, "no_speech_prob": 4.860374701820547e-06}, {"id": 677, "seek": 278876, "start": 2790.2400000000002, "end": 2792.6800000000003, "text": " And like, well, here we go.", "tokens": [400, 411, 11, 731, 11, 510, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.22844094745183396, "compression_ratio": 1.6083333333333334, "no_speech_prob": 4.860374701820547e-06}, {"id": 678, "seek": 278876, "start": 2792.6800000000003, "end": 2794.1200000000003, "text": " Probably going to break a bunch of stuff.", "tokens": [9210, 516, 281, 1821, 257, 3840, 295, 1507, 13], "temperature": 0.0, "avg_logprob": -0.22844094745183396, "compression_ratio": 1.6083333333333334, "no_speech_prob": 4.860374701820547e-06}, {"id": 679, "seek": 278876, "start": 2794.1200000000003, "end": 2799.96, "text": " And if you, if you write tests with Elm, it's even easier to, to refactor your Elm code.", "tokens": [400, 498, 291, 11, 498, 291, 2464, 6921, 365, 2699, 76, 11, 309, 311, 754, 3571, 281, 11, 281, 1895, 15104, 428, 2699, 76, 3089, 13], "temperature": 0.0, "avg_logprob": -0.22844094745183396, "compression_ratio": 1.6083333333333334, "no_speech_prob": 4.860374701820547e-06}, {"id": 680, "seek": 278876, "start": 2799.96, "end": 2802.1600000000003, "text": " And it's very easy to write tests in Elm.", "tokens": [400, 309, 311, 588, 1858, 281, 2464, 6921, 294, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.22844094745183396, "compression_ratio": 1.6083333333333334, "no_speech_prob": 4.860374701820547e-06}, {"id": 681, "seek": 278876, "start": 2802.1600000000003, "end": 2804.48, "text": " It's so nice to write tests in Elm.", "tokens": [467, 311, 370, 1481, 281, 2464, 6921, 294, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.22844094745183396, "compression_ratio": 1.6083333333333334, "no_speech_prob": 4.860374701820547e-06}, {"id": 682, "seek": 278876, "start": 2804.48, "end": 2811.2400000000002, "text": " And the kinds of tools that we see, like Martin Stewart wrote Lambdaera program tests, which", "tokens": [400, 264, 3685, 295, 3873, 300, 321, 536, 11, 411, 9184, 25951, 4114, 45691, 1663, 1461, 6921, 11, 597], "temperature": 0.0, "avg_logprob": -0.22844094745183396, "compression_ratio": 1.6083333333333334, "no_speech_prob": 4.860374701820547e-06}, {"id": 683, "seek": 278876, "start": 2811.2400000000002, "end": 2814.34, "text": " I'm absolutely amazed by just emulating.", "tokens": [286, 478, 3122, 20507, 538, 445, 846, 12162, 13], "temperature": 0.0, "avg_logprob": -0.22844094745183396, "compression_ratio": 1.6083333333333334, "no_speech_prob": 4.860374701820547e-06}, {"id": 684, "seek": 281434, "start": 2814.34, "end": 2821.08, "text": " So similar to Elm program tests, where you have something that, that emulates a browser,", "tokens": [407, 2531, 281, 2699, 76, 1461, 6921, 11, 689, 291, 362, 746, 300, 11, 300, 846, 26192, 257, 11185, 11], "temperature": 0.0, "avg_logprob": -0.24203884358308753, "compression_ratio": 1.7137096774193548, "no_speech_prob": 2.006137123089502e-07}, {"id": 685, "seek": 281434, "start": 2821.08, "end": 2826.2400000000002, "text": " letting you click on something in an Elm view and navigate around an Elm application and", "tokens": [8295, 291, 2052, 322, 746, 294, 364, 2699, 76, 1910, 293, 12350, 926, 364, 2699, 76, 3861, 293], "temperature": 0.0, "avg_logprob": -0.24203884358308753, "compression_ratio": 1.7137096774193548, "no_speech_prob": 2.006137123089502e-07}, {"id": 686, "seek": 281434, "start": 2826.2400000000002, "end": 2828.8, "text": " make assertions about what the view shows.", "tokens": [652, 19810, 626, 466, 437, 264, 1910, 3110, 13], "temperature": 0.0, "avg_logprob": -0.24203884358308753, "compression_ratio": 1.7137096774193548, "no_speech_prob": 2.006137123089502e-07}, {"id": 687, "seek": 281434, "start": 2828.8, "end": 2834.9, "text": " Lambdaera program test builds upon that, but it lets you simulate multiple connected clients", "tokens": [45691, 1663, 1461, 1500, 15182, 3564, 300, 11, 457, 309, 6653, 291, 27817, 3866, 4582, 6982], "temperature": 0.0, "avg_logprob": -0.24203884358308753, "compression_ratio": 1.7137096774193548, "no_speech_prob": 2.006137123089502e-07}, {"id": 688, "seek": 281434, "start": 2834.9, "end": 2841.44, "text": " interacting with an actual Lambdaera backend and actually executing that backend code.", "tokens": [18017, 365, 364, 3539, 45691, 1663, 38087, 293, 767, 32368, 300, 38087, 3089, 13], "temperature": 0.0, "avg_logprob": -0.24203884358308753, "compression_ratio": 1.7137096774193548, "no_speech_prob": 2.006137123089502e-07}, {"id": 689, "seek": 281434, "start": 2841.44, "end": 2843.6000000000004, "text": " And it's not mocking it.", "tokens": [400, 309, 311, 406, 49792, 309, 13], "temperature": 0.0, "avg_logprob": -0.24203884358308753, "compression_ratio": 1.7137096774193548, "no_speech_prob": 2.006137123089502e-07}, {"id": 690, "seek": 284360, "start": 2843.6, "end": 2847.44, "text": " It's running the same code that's going to run in your backend in production and the", "tokens": [467, 311, 2614, 264, 912, 3089, 300, 311, 516, 281, 1190, 294, 428, 38087, 294, 4265, 293, 264], "temperature": 0.0, "avg_logprob": -0.20526234965679074, "compression_ratio": 1.9121338912133892, "no_speech_prob": 9.570460406393977e-07}, {"id": 691, "seek": 284360, "start": 2847.44, "end": 2850.88, "text": " same code that's going to run on your frontend in production.", "tokens": [912, 3089, 300, 311, 516, 281, 1190, 322, 428, 1868, 521, 294, 4265, 13], "temperature": 0.0, "avg_logprob": -0.20526234965679074, "compression_ratio": 1.9121338912133892, "no_speech_prob": 9.570460406393977e-07}, {"id": 692, "seek": 284360, "start": 2850.88, "end": 2852.24, "text": " And you can trust it.", "tokens": [400, 291, 393, 3361, 309, 13], "temperature": 0.0, "avg_logprob": -0.20526234965679074, "compression_ratio": 1.9121338912133892, "no_speech_prob": 9.570460406393977e-07}, {"id": 693, "seek": 284360, "start": 2852.24, "end": 2859.0, "text": " And there is the browser emulation piece, but that's a pretty thin layer, you know,", "tokens": [400, 456, 307, 264, 11185, 846, 2776, 2522, 11, 457, 300, 311, 257, 1238, 5862, 4583, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.20526234965679074, "compression_ratio": 1.9121338912133892, "no_speech_prob": 9.570460406393977e-07}, {"id": 694, "seek": 284360, "start": 2859.0, "end": 2861.88, "text": " clicking on things and triggering on click events.", "tokens": [9697, 322, 721, 293, 40406, 322, 2052, 3931, 13], "temperature": 0.0, "avg_logprob": -0.20526234965679074, "compression_ratio": 1.9121338912133892, "no_speech_prob": 9.570460406393977e-07}, {"id": 695, "seek": 284360, "start": 2861.88, "end": 2866.06, "text": " So besides that, you know, that it's going to behave the exact same way, but it's as", "tokens": [407, 11868, 300, 11, 291, 458, 11, 300, 309, 311, 516, 281, 15158, 264, 1900, 912, 636, 11, 457, 309, 311, 382], "temperature": 0.0, "avg_logprob": -0.20526234965679074, "compression_ratio": 1.9121338912133892, "no_speech_prob": 9.570460406393977e-07}, {"id": 696, "seek": 284360, "start": 2866.06, "end": 2870.68, "text": " fast as a unit test because it's not spinning up a headless browser.", "tokens": [2370, 382, 257, 4985, 1500, 570, 309, 311, 406, 15640, 493, 257, 1378, 1832, 11185, 13], "temperature": 0.0, "avg_logprob": -0.20526234965679074, "compression_ratio": 1.9121338912133892, "no_speech_prob": 9.570460406393977e-07}, {"id": 697, "seek": 287068, "start": 2870.68, "end": 2875.3999999999996, "text": " And in the case of Lambdaera program tests, it's emulating multiple connected clients", "tokens": [400, 294, 264, 1389, 295, 45691, 1663, 1461, 6921, 11, 309, 311, 846, 12162, 3866, 4582, 6982], "temperature": 0.0, "avg_logprob": -0.24832533239349117, "compression_ratio": 1.7481751824817517, "no_speech_prob": 2.190724899264751e-06}, {"id": 698, "seek": 287068, "start": 2875.3999999999996, "end": 2878.44, "text": " to like a real time backend framework.", "tokens": [281, 411, 257, 957, 565, 38087, 8388, 13], "temperature": 0.0, "avg_logprob": -0.24832533239349117, "compression_ratio": 1.7481751824817517, "no_speech_prob": 2.190724899264751e-06}, {"id": 699, "seek": 287068, "start": 2878.44, "end": 2881.8399999999997, "text": " And you can actually view it stepping through it.", "tokens": [400, 291, 393, 767, 1910, 309, 16821, 807, 309, 13], "temperature": 0.0, "avg_logprob": -0.24832533239349117, "compression_ratio": 1.7481751824817517, "no_speech_prob": 2.190724899264751e-06}, {"id": 700, "seek": 287068, "start": 2881.8399999999997, "end": 2883.56, "text": " It's just unreal.", "tokens": [467, 311, 445, 25754, 13], "temperature": 0.0, "avg_logprob": -0.24832533239349117, "compression_ratio": 1.7481751824817517, "no_speech_prob": 2.190724899264751e-06}, {"id": 701, "seek": 287068, "start": 2883.56, "end": 2889.24, "text": " And the, and this was something that Martin Stewart was like hacking on something.", "tokens": [400, 264, 11, 293, 341, 390, 746, 300, 9184, 25951, 390, 411, 31422, 322, 746, 13], "temperature": 0.0, "avg_logprob": -0.24832533239349117, "compression_ratio": 1.7481751824817517, "no_speech_prob": 2.190724899264751e-06}, {"id": 702, "seek": 287068, "start": 2889.24, "end": 2893.08, "text": " He's like, Oh yeah, it'd be nice if I could like write a test for multiple connected clients", "tokens": [634, 311, 411, 11, 876, 1338, 11, 309, 1116, 312, 1481, 498, 286, 727, 411, 2464, 257, 1500, 337, 3866, 4582, 6982], "temperature": 0.0, "avg_logprob": -0.24832533239349117, "compression_ratio": 1.7481751824817517, "no_speech_prob": 2.190724899264751e-06}, {"id": 703, "seek": 287068, "start": 2893.08, "end": 2897.2, "text": " to make sure I've got these race conditions ironed out.", "tokens": [281, 652, 988, 286, 600, 658, 613, 4569, 4487, 6497, 292, 484, 13], "temperature": 0.0, "avg_logprob": -0.24832533239349117, "compression_ratio": 1.7481751824817517, "no_speech_prob": 2.190724899264751e-06}, {"id": 704, "seek": 287068, "start": 2897.2, "end": 2900.16, "text": " And it'd be nice if I could visualize the state of it.", "tokens": [400, 309, 1116, 312, 1481, 498, 286, 727, 23273, 264, 1785, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.24832533239349117, "compression_ratio": 1.7481751824817517, "no_speech_prob": 2.190724899264751e-06}, {"id": 705, "seek": 290016, "start": 2900.16, "end": 2903.2799999999997, "text": " And he just kind of hacks it together and he's like, Oh yeah, it actually works out", "tokens": [400, 415, 445, 733, 295, 33617, 309, 1214, 293, 415, 311, 411, 11, 876, 1338, 11, 309, 767, 1985, 484], "temperature": 0.0, "avg_logprob": -0.22172472553868447, "compression_ratio": 1.8870967741935485, "no_speech_prob": 5.682290520780953e-06}, {"id": 706, "seek": 290016, "start": 2903.2799999999997, "end": 2905.56, "text": " perfectly and it's really easy and elegant.", "tokens": [6239, 293, 309, 311, 534, 1858, 293, 21117, 13], "temperature": 0.0, "avg_logprob": -0.22172472553868447, "compression_ratio": 1.8870967741935485, "no_speech_prob": 5.682290520780953e-06}, {"id": 707, "seek": 290016, "start": 2905.56, "end": 2907.2799999999997, "text": " And that's how it is.", "tokens": [400, 300, 311, 577, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.22172472553868447, "compression_ratio": 1.8870967741935485, "no_speech_prob": 5.682290520780953e-06}, {"id": 708, "seek": 290016, "start": 2907.2799999999997, "end": 2913.16, "text": " Like I feel like that's something inherent in Elm that things don't end up, you pull", "tokens": [1743, 286, 841, 411, 300, 311, 746, 26387, 294, 2699, 76, 300, 721, 500, 380, 917, 493, 11, 291, 2235], "temperature": 0.0, "avg_logprob": -0.22172472553868447, "compression_ratio": 1.8870967741935485, "no_speech_prob": 5.682290520780953e-06}, {"id": 709, "seek": 290016, "start": 2913.16, "end": 2918.64, "text": " on the thread and it gets messier and messier and you, and it works really nicely until", "tokens": [322, 264, 7207, 293, 309, 2170, 2082, 811, 293, 2082, 811, 293, 291, 11, 293, 309, 1985, 534, 9594, 1826], "temperature": 0.0, "avg_logprob": -0.22172472553868447, "compression_ratio": 1.8870967741935485, "no_speech_prob": 5.682290520780953e-06}, {"id": 710, "seek": 290016, "start": 2918.64, "end": 2921.3399999999997, "text": " you start pulling on that thread and then it falls apart.", "tokens": [291, 722, 8407, 322, 300, 7207, 293, 550, 309, 8804, 4936, 13], "temperature": 0.0, "avg_logprob": -0.22172472553868447, "compression_ratio": 1.8870967741935485, "no_speech_prob": 5.682290520780953e-06}, {"id": 711, "seek": 290016, "start": 2921.3399999999997, "end": 2926.3199999999997, "text": " In Elm I feel like you start pulling on that thread and it, it comes together even more", "tokens": [682, 2699, 76, 286, 841, 411, 291, 722, 8407, 322, 300, 7207, 293, 309, 11, 309, 1487, 1214, 754, 544], "temperature": 0.0, "avg_logprob": -0.22172472553868447, "compression_ratio": 1.8870967741935485, "no_speech_prob": 5.682290520780953e-06}, {"id": 712, "seek": 292632, "start": 2926.32, "end": 2931.6400000000003, "text": " cleanly because it's, there's an elegance and a simplicity to Elm itself.", "tokens": [2541, 356, 570, 309, 311, 11, 456, 311, 364, 14459, 719, 293, 257, 25632, 281, 2699, 76, 2564, 13], "temperature": 0.0, "avg_logprob": -0.2615379117569833, "compression_ratio": 1.6519823788546255, "no_speech_prob": 2.7852243533743604e-07}, {"id": 713, "seek": 292632, "start": 2931.6400000000003, "end": 2932.6400000000003, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2615379117569833, "compression_ratio": 1.6519823788546255, "no_speech_prob": 2.7852243533743604e-07}, {"id": 714, "seek": 292632, "start": 2932.6400000000003, "end": 2939.48, "text": " It requires some work to, to, to remove all the hairy parts, but yeah, absolutely.", "tokens": [467, 7029, 512, 589, 281, 11, 281, 11, 281, 4159, 439, 264, 42346, 3166, 11, 457, 1338, 11, 3122, 13], "temperature": 0.0, "avg_logprob": -0.2615379117569833, "compression_ratio": 1.6519823788546255, "no_speech_prob": 2.7852243533743604e-07}, {"id": 715, "seek": 292632, "start": 2939.48, "end": 2947.82, "text": " It requires a lot of work, but you're like, the potential is there to build amazing tools", "tokens": [467, 7029, 257, 688, 295, 589, 11, 457, 291, 434, 411, 11, 264, 3995, 307, 456, 281, 1322, 2243, 3873], "temperature": 0.0, "avg_logprob": -0.2615379117569833, "compression_ratio": 1.6519823788546255, "no_speech_prob": 2.7852243533743604e-07}, {"id": 716, "seek": 292632, "start": 2947.82, "end": 2951.4, "text": " that like don't have these caveats and these messy edges.", "tokens": [300, 411, 500, 380, 362, 613, 11730, 1720, 293, 613, 16191, 8819, 13], "temperature": 0.0, "avg_logprob": -0.2615379117569833, "compression_ratio": 1.6519823788546255, "no_speech_prob": 2.7852243533743604e-07}, {"id": 717, "seek": 292632, "start": 2951.4, "end": 2954.0800000000004, "text": " If you're willing to put in that work as a tooling author.", "tokens": [759, 291, 434, 4950, 281, 829, 294, 300, 589, 382, 257, 46593, 3793, 13], "temperature": 0.0, "avg_logprob": -0.2615379117569833, "compression_ratio": 1.6519823788546255, "no_speech_prob": 2.7852243533743604e-07}, {"id": 718, "seek": 292632, "start": 2954.0800000000004, "end": 2955.0800000000004, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2615379117569833, "compression_ratio": 1.6519823788546255, "no_speech_prob": 2.7852243533743604e-07}, {"id": 719, "seek": 295508, "start": 2955.08, "end": 2960.3199999999997, "text": " I'm thinking of Cypress for instance, where Cypress is a testing framework where you can", "tokens": [286, 478, 1953, 295, 10295, 11637, 337, 5197, 11, 689, 10295, 11637, 307, 257, 4997, 8388, 689, 291, 393], "temperature": 0.0, "avg_logprob": -0.2951391843649057, "compression_ratio": 1.6869918699186992, "no_speech_prob": 5.507220521394629e-06}, {"id": 720, "seek": 295508, "start": 2960.3199999999997, "end": 2968.04, "text": " emulate your browser and it actually runs a browser and it's super powerful, but everywhere", "tokens": [45497, 428, 11185, 293, 309, 767, 6676, 257, 11185, 293, 309, 311, 1687, 4005, 11, 457, 5315], "temperature": 0.0, "avg_logprob": -0.2951391843649057, "compression_ratio": 1.6869918699186992, "no_speech_prob": 5.507220521394629e-06}, {"id": 721, "seek": 295508, "start": 2968.04, "end": 2973.92, "text": " in its docs it says things like, don't do this or don't do things this way.", "tokens": [294, 1080, 45623, 309, 1619, 721, 411, 11, 500, 380, 360, 341, 420, 500, 380, 360, 721, 341, 636, 13], "temperature": 0.0, "avg_logprob": -0.2951391843649057, "compression_ratio": 1.6869918699186992, "no_speech_prob": 5.507220521394629e-06}, {"id": 722, "seek": 295508, "start": 2973.92, "end": 2978.7999999999997, "text": " And whenever you go to another test, then we just start from scratch.", "tokens": [400, 5699, 291, 352, 281, 1071, 1500, 11, 550, 321, 445, 722, 490, 8459, 13], "temperature": 0.0, "avg_logprob": -0.2951391843649057, "compression_ratio": 1.6869918699186992, "no_speech_prob": 5.507220521394629e-06}, {"id": 723, "seek": 295508, "start": 2978.7999999999997, "end": 2984.68, "text": " It's like kind of the same experience that you just said, like you, you pull on a thread", "tokens": [467, 311, 411, 733, 295, 264, 912, 1752, 300, 291, 445, 848, 11, 411, 291, 11, 291, 2235, 322, 257, 7207], "temperature": 0.0, "avg_logprob": -0.2951391843649057, "compression_ratio": 1.6869918699186992, "no_speech_prob": 5.507220521394629e-06}, {"id": 724, "seek": 298468, "start": 2984.68, "end": 2991.0, "text": " and the result is nice, but at some point if things get hairy and in the case of Cypress,", "tokens": [293, 264, 1874, 307, 1481, 11, 457, 412, 512, 935, 498, 721, 483, 42346, 293, 294, 264, 1389, 295, 10295, 11637, 11], "temperature": 0.0, "avg_logprob": -0.2761918733704765, "compression_ratio": 1.6844444444444444, "no_speech_prob": 9.97266124613816e-06}, {"id": 725, "seek": 298468, "start": 2991.0, "end": 2996.6, "text": " because it's JavaScript, it's playing with a browser, which is complicated in practice.", "tokens": [570, 309, 311, 15778, 11, 309, 311, 2433, 365, 257, 11185, 11, 597, 307, 6179, 294, 3124, 13], "temperature": 0.0, "avg_logprob": -0.2761918733704765, "compression_ratio": 1.6844444444444444, "no_speech_prob": 9.97266124613816e-06}, {"id": 726, "seek": 298468, "start": 2996.6, "end": 2999.24, "text": " Well, they don't put out something nice.", "tokens": [1042, 11, 436, 500, 380, 829, 484, 746, 1481, 13], "temperature": 0.0, "avg_logprob": -0.2761918733704765, "compression_ratio": 1.6844444444444444, "no_speech_prob": 9.97266124613816e-06}, {"id": 727, "seek": 298468, "start": 2999.24, "end": 3002.68, "text": " They just say, okay, well not start from here.", "tokens": [814, 445, 584, 11, 1392, 11, 731, 406, 722, 490, 510, 13], "temperature": 0.0, "avg_logprob": -0.2761918733704765, "compression_ratio": 1.6844444444444444, "no_speech_prob": 9.97266124613816e-06}, {"id": 728, "seek": 298468, "start": 3002.68, "end": 3003.7999999999997, "text": " You should not do this.", "tokens": [509, 820, 406, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.2761918733704765, "compression_ratio": 1.6844444444444444, "no_speech_prob": 9.97266124613816e-06}, {"id": 729, "seek": 298468, "start": 3003.7999999999997, "end": 3005.72, "text": " You should not do that.", "tokens": [509, 820, 406, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.2761918733704765, "compression_ratio": 1.6844444444444444, "no_speech_prob": 9.97266124613816e-06}, {"id": 730, "seek": 298468, "start": 3005.72, "end": 3010.0, "text": " And the result is not as nice and you don't get the same results.", "tokens": [400, 264, 1874, 307, 406, 382, 1481, 293, 291, 500, 380, 483, 264, 912, 3542, 13], "temperature": 0.0, "avg_logprob": -0.2761918733704765, "compression_ratio": 1.6844444444444444, "no_speech_prob": 9.97266124613816e-06}, {"id": 731, "seek": 301000, "start": 3010.0, "end": 3016.88, "text": " Like it's slower, well for good reasons potentially, but it can crash.", "tokens": [1743, 309, 311, 14009, 11, 731, 337, 665, 4112, 7263, 11, 457, 309, 393, 8252, 13], "temperature": 0.0, "avg_logprob": -0.2454948001437717, "compression_ratio": 1.5431472081218274, "no_speech_prob": 2.561193468864076e-06}, {"id": 732, "seek": 301000, "start": 3016.88, "end": 3020.84, "text": " It can crash in weird ways.", "tokens": [467, 393, 8252, 294, 3657, 2098, 13], "temperature": 0.0, "avg_logprob": -0.2454948001437717, "compression_ratio": 1.5431472081218274, "no_speech_prob": 2.561193468864076e-06}, {"id": 733, "seek": 301000, "start": 3020.84, "end": 3025.52, "text": " I might be a little bit biased, but you get what I mean.", "tokens": [286, 1062, 312, 257, 707, 857, 28035, 11, 457, 291, 483, 437, 286, 914, 13], "temperature": 0.0, "avg_logprob": -0.2454948001437717, "compression_ratio": 1.5431472081218274, "no_speech_prob": 2.561193468864076e-06}, {"id": 734, "seek": 301000, "start": 3025.52, "end": 3026.52, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2454948001437717, "compression_ratio": 1.5431472081218274, "no_speech_prob": 2.561193468864076e-06}, {"id": 735, "seek": 301000, "start": 3026.52, "end": 3032.76, "text": " I mean, you know, I think that's what we get for the price of Elm, the price of writing", "tokens": [286, 914, 11, 291, 458, 11, 286, 519, 300, 311, 437, 321, 483, 337, 264, 3218, 295, 2699, 76, 11, 264, 3218, 295, 3579], "temperature": 0.0, "avg_logprob": -0.2454948001437717, "compression_ratio": 1.5431472081218274, "no_speech_prob": 2.561193468864076e-06}, {"id": 736, "seek": 301000, "start": 3032.76, "end": 3037.8, "text": " pure functions, which is a limitation that we take on.", "tokens": [6075, 6828, 11, 597, 307, 257, 27432, 300, 321, 747, 322, 13], "temperature": 0.0, "avg_logprob": -0.2454948001437717, "compression_ratio": 1.5431472081218274, "no_speech_prob": 2.561193468864076e-06}, {"id": 737, "seek": 303780, "start": 3037.8, "end": 3040.1200000000003, "text": " And that's what we get from that, right?", "tokens": [400, 300, 311, 437, 321, 483, 490, 300, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.28404283101579786, "compression_ratio": 1.7469387755102042, "no_speech_prob": 2.6424472707731184e-06}, {"id": 738, "seek": 303780, "start": 3040.1200000000003, "end": 3042.48, "text": " So really interesting things emerge from that.", "tokens": [407, 534, 1880, 721, 21511, 490, 300, 13], "temperature": 0.0, "avg_logprob": -0.28404283101579786, "compression_ratio": 1.7469387755102042, "no_speech_prob": 2.6424472707731184e-06}, {"id": 739, "seek": 303780, "start": 3042.48, "end": 3047.7000000000003, "text": " But that's why tooling is so important in Elm, because we paid that price.", "tokens": [583, 300, 311, 983, 46593, 307, 370, 1021, 294, 2699, 76, 11, 570, 321, 4835, 300, 3218, 13], "temperature": 0.0, "avg_logprob": -0.28404283101579786, "compression_ratio": 1.7469387755102042, "no_speech_prob": 2.6424472707731184e-06}, {"id": 740, "seek": 303780, "start": 3047.7000000000003, "end": 3054.2400000000002, "text": " So give us our money's worth by giving us amazing tools and dedicating your life to", "tokens": [407, 976, 505, 527, 1460, 311, 3163, 538, 2902, 505, 2243, 3873, 293, 4172, 30541, 428, 993, 281], "temperature": 0.0, "avg_logprob": -0.28404283101579786, "compression_ratio": 1.7469387755102042, "no_speech_prob": 2.6424472707731184e-06}, {"id": 741, "seek": 303780, "start": 3054.2400000000002, "end": 3057.32, "text": " building really cool tools, tooling authors.", "tokens": [2390, 534, 1627, 3873, 11, 46593, 16552, 13], "temperature": 0.0, "avg_logprob": -0.28404283101579786, "compression_ratio": 1.7469387755102042, "no_speech_prob": 2.6424472707731184e-06}, {"id": 742, "seek": 303780, "start": 3057.32, "end": 3058.6800000000003, "text": " So that's why we do it.", "tokens": [407, 300, 311, 983, 321, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.28404283101579786, "compression_ratio": 1.7469387755102042, "no_speech_prob": 2.6424472707731184e-06}, {"id": 743, "seek": 303780, "start": 3058.6800000000003, "end": 3065.04, "text": " I will dedicate my life to make these awesome tools that rely on the purity and functional", "tokens": [286, 486, 30718, 452, 993, 281, 652, 613, 3476, 3873, 300, 10687, 322, 264, 34382, 293, 11745], "temperature": 0.0, "avg_logprob": -0.28404283101579786, "compression_ratio": 1.7469387755102042, "no_speech_prob": 2.6424472707731184e-06}, {"id": 744, "seek": 303780, "start": 3065.04, "end": 3067.04, "text": " and blah, blah, blah.", "tokens": [293, 12288, 11, 12288, 11, 12288, 13], "temperature": 0.0, "avg_logprob": -0.28404283101579786, "compression_ratio": 1.7469387755102042, "no_speech_prob": 2.6424472707731184e-06}, {"id": 745, "seek": 306704, "start": 3067.04, "end": 3068.04, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.23856426420665922, "compression_ratio": 1.5637860082304527, "no_speech_prob": 3.288531388534466e-06}, {"id": 746, "seek": 306704, "start": 3068.04, "end": 3069.12, "text": " So that's not my villain story.", "tokens": [407, 300, 311, 406, 452, 17906, 1657, 13], "temperature": 0.0, "avg_logprob": -0.23856426420665922, "compression_ratio": 1.5637860082304527, "no_speech_prob": 3.288531388534466e-06}, {"id": 747, "seek": 306704, "start": 3069.12, "end": 3072.68, "text": " That's my priesthood story or something.", "tokens": [663, 311, 452, 15703, 3809, 1657, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.23856426420665922, "compression_ratio": 1.5637860082304527, "no_speech_prob": 3.288531388534466e-06}, {"id": 748, "seek": 306704, "start": 3072.68, "end": 3073.68, "text": " Maybe it's a curse.", "tokens": [2704, 309, 311, 257, 17139, 13], "temperature": 0.0, "avg_logprob": -0.23856426420665922, "compression_ratio": 1.5637860082304527, "no_speech_prob": 3.288531388534466e-06}, {"id": 749, "seek": 306704, "start": 3073.68, "end": 3078.96, "text": " I don't know what it is, but here we are.", "tokens": [286, 500, 380, 458, 437, 309, 307, 11, 457, 510, 321, 366, 13], "temperature": 0.0, "avg_logprob": -0.23856426420665922, "compression_ratio": 1.5637860082304527, "no_speech_prob": 3.288531388534466e-06}, {"id": 750, "seek": 306704, "start": 3078.96, "end": 3084.7599999999998, "text": " You talked earlier about people who do TypeScript and they're happy with the new guarantees", "tokens": [509, 2825, 3071, 466, 561, 567, 360, 15576, 14237, 293, 436, 434, 2055, 365, 264, 777, 32567], "temperature": 0.0, "avg_logprob": -0.23856426420665922, "compression_ratio": 1.5637860082304527, "no_speech_prob": 3.288531388534466e-06}, {"id": 751, "seek": 306704, "start": 3084.7599999999998, "end": 3088.44, "text": " that they gain from TypeScript compared to JavaScript.", "tokens": [300, 436, 6052, 490, 15576, 14237, 5347, 281, 15778, 13], "temperature": 0.0, "avg_logprob": -0.23856426420665922, "compression_ratio": 1.5637860082304527, "no_speech_prob": 3.288531388534466e-06}, {"id": 752, "seek": 306704, "start": 3088.44, "end": 3093.72, "text": " And I mean, it was a lot of work to convince those people to use TypeScript for good reason,", "tokens": [400, 286, 914, 11, 309, 390, 257, 688, 295, 589, 281, 13447, 729, 561, 281, 764, 15576, 14237, 337, 665, 1778, 11], "temperature": 0.0, "avg_logprob": -0.23856426420665922, "compression_ratio": 1.5637860082304527, "no_speech_prob": 3.288531388534466e-06}, {"id": 753, "seek": 309372, "start": 3093.72, "end": 3099.2799999999997, "text": " because it has a lot of complexity still and a lot of build steps and all that.", "tokens": [570, 309, 575, 257, 688, 295, 14024, 920, 293, 257, 688, 295, 1322, 4439, 293, 439, 300, 13], "temperature": 0.0, "avg_logprob": -0.22256976634532483, "compression_ratio": 1.7035573122529644, "no_speech_prob": 4.494612767302897e-06}, {"id": 754, "seek": 309372, "start": 3099.2799999999997, "end": 3103.68, "text": " And some people got convinced and some people are now very, very happy with it.", "tokens": [400, 512, 561, 658, 12561, 293, 512, 561, 366, 586, 588, 11, 588, 2055, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.22256976634532483, "compression_ratio": 1.7035573122529644, "no_speech_prob": 4.494612767302897e-06}, {"id": 755, "seek": 309372, "start": 3103.68, "end": 3109.12, "text": " And TypeScript is now pretty much the standard, even compared to JavaScript, at least in the", "tokens": [400, 15576, 14237, 307, 586, 1238, 709, 264, 3832, 11, 754, 5347, 281, 15778, 11, 412, 1935, 294, 264], "temperature": 0.0, "avg_logprob": -0.22256976634532483, "compression_ratio": 1.7035573122529644, "no_speech_prob": 4.494612767302897e-06}, {"id": 756, "seek": 309372, "start": 3109.12, "end": 3111.12, "text": " circles that I...", "tokens": [13040, 300, 286, 485], "temperature": 0.0, "avg_logprob": -0.22256976634532483, "compression_ratio": 1.7035573122529644, "no_speech_prob": 4.494612767302897e-06}, {"id": 757, "seek": 309372, "start": 3111.12, "end": 3114.12, "text": " Sometimes you just don't know how bad you have it, right?", "tokens": [4803, 291, 445, 500, 380, 458, 577, 1578, 291, 362, 309, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.22256976634532483, "compression_ratio": 1.7035573122529644, "no_speech_prob": 4.494612767302897e-06}, {"id": 758, "seek": 309372, "start": 3114.12, "end": 3119.48, "text": " Like the people who did JavaScript and not TypeScript, they didn't know how good it was", "tokens": [1743, 264, 561, 567, 630, 15778, 293, 406, 15576, 14237, 11, 436, 994, 380, 458, 577, 665, 309, 390], "temperature": 0.0, "avg_logprob": -0.22256976634532483, "compression_ratio": 1.7035573122529644, "no_speech_prob": 4.494612767302897e-06}, {"id": 759, "seek": 309372, "start": 3119.48, "end": 3121.58, "text": " to have types.", "tokens": [281, 362, 3467, 13], "temperature": 0.0, "avg_logprob": -0.22256976634532483, "compression_ratio": 1.7035573122529644, "no_speech_prob": 4.494612767302897e-06}, {"id": 760, "seek": 312158, "start": 3121.58, "end": 3127.6, "text": " We often say that they've been bitten by Java and they're pretty lousy type system.", "tokens": [492, 2049, 584, 300, 436, 600, 668, 34608, 538, 10745, 293, 436, 434, 1238, 287, 563, 88, 2010, 1185, 13], "temperature": 0.0, "avg_logprob": -0.2374764621847927, "compression_ratio": 1.5130434782608695, "no_speech_prob": 3.689827394737222e-07}, {"id": 761, "seek": 312158, "start": 3127.6, "end": 3128.92, "text": " And that might be true.", "tokens": [400, 300, 1062, 312, 2074, 13], "temperature": 0.0, "avg_logprob": -0.2374764621847927, "compression_ratio": 1.5130434782608695, "no_speech_prob": 3.689827394737222e-07}, {"id": 762, "seek": 312158, "start": 3128.92, "end": 3135.7799999999997, "text": " But yeah, if you go to Reason or to Elm or to F Sharp, the types are really nice.", "tokens": [583, 1338, 11, 498, 291, 352, 281, 39693, 420, 281, 2699, 76, 420, 281, 479, 31654, 11, 264, 3467, 366, 534, 1481, 13], "temperature": 0.0, "avg_logprob": -0.2374764621847927, "compression_ratio": 1.5130434782608695, "no_speech_prob": 3.689827394737222e-07}, {"id": 763, "seek": 312158, "start": 3135.7799999999997, "end": 3143.84, "text": " And I would say from TypeScript compared to Elm, you now have a type checker, which works", "tokens": [400, 286, 576, 584, 490, 15576, 14237, 5347, 281, 2699, 76, 11, 291, 586, 362, 257, 2010, 1520, 260, 11, 597, 1985], "temperature": 0.0, "avg_logprob": -0.2374764621847927, "compression_ratio": 1.5130434782608695, "no_speech_prob": 3.689827394737222e-07}, {"id": 764, "seek": 312158, "start": 3143.84, "end": 3144.84, "text": " well.", "tokens": [731, 13], "temperature": 0.0, "avg_logprob": -0.2374764621847927, "compression_ratio": 1.5130434782608695, "no_speech_prob": 3.689827394737222e-07}, {"id": 765, "seek": 312158, "start": 3144.84, "end": 3148.64, "text": " It doesn't use the same technology or the same idea behind it.", "tokens": [467, 1177, 380, 764, 264, 912, 2899, 420, 264, 912, 1558, 2261, 309, 13], "temperature": 0.0, "avg_logprob": -0.2374764621847927, "compression_ratio": 1.5130434782608695, "no_speech_prob": 3.689827394737222e-07}, {"id": 766, "seek": 314864, "start": 3148.64, "end": 3152.46, "text": " So the TypeScript one is not as reliable.", "tokens": [407, 264, 15576, 14237, 472, 307, 406, 382, 12924, 13], "temperature": 0.0, "avg_logprob": -0.34053155354091097, "compression_ratio": 1.6844262295081966, "no_speech_prob": 1.2878298321084003e-06}, {"id": 767, "seek": 314864, "start": 3152.46, "end": 3156.7599999999998, "text": " Like something that is still missing is side effect tracking.", "tokens": [1743, 746, 300, 307, 920, 5361, 307, 1252, 1802, 11603, 13], "temperature": 0.0, "avg_logprob": -0.34053155354091097, "compression_ratio": 1.6844262295081966, "no_speech_prob": 1.2878298321084003e-06}, {"id": 768, "seek": 314864, "start": 3156.7599999999998, "end": 3161.72, "text": " And I don't think the TypeScript people know how bad they have it, that they have to handle", "tokens": [400, 286, 500, 380, 519, 264, 15576, 14237, 561, 458, 577, 1578, 436, 362, 309, 11, 300, 436, 362, 281, 4813], "temperature": 0.0, "avg_logprob": -0.34053155354091097, "compression_ratio": 1.6844262295081966, "no_speech_prob": 1.2878298321084003e-06}, {"id": 769, "seek": 314864, "start": 3161.72, "end": 3163.56, "text": " all those side effects.", "tokens": [439, 729, 1252, 5065, 13], "temperature": 0.0, "avg_logprob": -0.34053155354091097, "compression_ratio": 1.6844262295081966, "no_speech_prob": 1.2878298321084003e-06}, {"id": 770, "seek": 314864, "start": 3163.56, "end": 3165.92, "text": " Yeah, right.", "tokens": [865, 11, 558, 13], "temperature": 0.0, "avg_logprob": -0.34053155354091097, "compression_ratio": 1.6844262295081966, "no_speech_prob": 1.2878298321084003e-06}, {"id": 771, "seek": 314864, "start": 3165.92, "end": 3171.64, "text": " Every time I go to the Netherlands, I'm just always amazed by something that is very simple", "tokens": [2048, 565, 286, 352, 281, 264, 20873, 11, 286, 478, 445, 1009, 20507, 538, 746, 300, 307, 588, 2199], "temperature": 0.0, "avg_logprob": -0.34053155354091097, "compression_ratio": 1.6844262295081966, "no_speech_prob": 1.2878298321084003e-06}, {"id": 772, "seek": 314864, "start": 3171.64, "end": 3173.2, "text": " and that is traffic lights.", "tokens": [293, 300, 307, 6419, 5811, 13], "temperature": 0.0, "avg_logprob": -0.34053155354091097, "compression_ratio": 1.6844262295081966, "no_speech_prob": 1.2878298321084003e-06}, {"id": 773, "seek": 314864, "start": 3173.2, "end": 3175.96, "text": " Have you ever been to the Netherlands?", "tokens": [3560, 291, 1562, 668, 281, 264, 20873, 30], "temperature": 0.0, "avg_logprob": -0.34053155354091097, "compression_ratio": 1.6844262295081966, "no_speech_prob": 1.2878298321084003e-06}, {"id": 774, "seek": 314864, "start": 3175.96, "end": 3177.52, "text": " No, I'd like to go.", "tokens": [883, 11, 286, 1116, 411, 281, 352, 13], "temperature": 0.0, "avg_logprob": -0.34053155354091097, "compression_ratio": 1.6844262295081966, "no_speech_prob": 1.2878298321084003e-06}, {"id": 775, "seek": 317752, "start": 3177.52, "end": 3184.84, "text": " Okay, well, the road infrastructure is very nice because you've got bikes everywhere.", "tokens": [1033, 11, 731, 11, 264, 3060, 6896, 307, 588, 1481, 570, 291, 600, 658, 16035, 5315, 13], "temperature": 0.0, "avg_logprob": -0.30721894089056523, "compression_ratio": 1.6567796610169492, "no_speech_prob": 3.4461131690477487e-06}, {"id": 776, "seek": 317752, "start": 3184.84, "end": 3191.52, "text": " You get a separated bike lane and a separate pedestrian lane on top of the normal roads.", "tokens": [509, 483, 257, 12005, 5656, 12705, 293, 257, 4994, 33947, 12705, 322, 1192, 295, 264, 2710, 11344, 13], "temperature": 0.0, "avg_logprob": -0.30721894089056523, "compression_ratio": 1.6567796610169492, "no_speech_prob": 3.4461131690477487e-06}, {"id": 777, "seek": 317752, "start": 3191.52, "end": 3193.72, "text": " And the traffic lights are just amazing.", "tokens": [400, 264, 6419, 5811, 366, 445, 2243, 13], "temperature": 0.0, "avg_logprob": -0.30721894089056523, "compression_ratio": 1.6567796610169492, "no_speech_prob": 3.4461131690477487e-06}, {"id": 778, "seek": 317752, "start": 3193.72, "end": 3199.64, "text": " Like for instance, if you're in a car and you go to a crossroad, so we've got traffic", "tokens": [1743, 337, 5197, 11, 498, 291, 434, 294, 257, 1032, 293, 291, 352, 281, 257, 3278, 8417, 11, 370, 321, 600, 658, 6419], "temperature": 0.0, "avg_logprob": -0.30721894089056523, "compression_ratio": 1.6567796610169492, "no_speech_prob": 3.4461131690477487e-06}, {"id": 779, "seek": 317752, "start": 3199.64, "end": 3202.08, "text": " lights everywhere stopping people.", "tokens": [5811, 5315, 12767, 561, 13], "temperature": 0.0, "avg_logprob": -0.30721894089056523, "compression_ratio": 1.6567796610169492, "no_speech_prob": 3.4461131690477487e-06}, {"id": 780, "seek": 317752, "start": 3202.08, "end": 3205.84, "text": " And if you're the only one who's driving through that.", "tokens": [400, 498, 291, 434, 264, 787, 472, 567, 311, 4840, 807, 300, 13], "temperature": 0.0, "avg_logprob": -0.30721894089056523, "compression_ratio": 1.6567796610169492, "no_speech_prob": 3.4461131690477487e-06}, {"id": 781, "seek": 320584, "start": 3205.84, "end": 3209.7200000000003, "text": " So for instance, if you're driving in the middle of the night, then the traffic light", "tokens": [407, 337, 5197, 11, 498, 291, 434, 4840, 294, 264, 2808, 295, 264, 1818, 11, 550, 264, 6419, 1442], "temperature": 0.0, "avg_logprob": -0.24541665649414063, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.8570827907969942e-06}, {"id": 782, "seek": 320584, "start": 3209.7200000000003, "end": 3210.96, "text": " will be red.", "tokens": [486, 312, 2182, 13], "temperature": 0.0, "avg_logprob": -0.24541665649414063, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.8570827907969942e-06}, {"id": 783, "seek": 320584, "start": 3210.96, "end": 3216.36, "text": " And once you arrive at this traffic light, it will go green and you can just go now because", "tokens": [400, 1564, 291, 8881, 412, 341, 6419, 1442, 11, 309, 486, 352, 3092, 293, 291, 393, 445, 352, 586, 570], "temperature": 0.0, "avg_logprob": -0.24541665649414063, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.8570827907969942e-06}, {"id": 784, "seek": 320584, "start": 3216.36, "end": 3220.36, "text": " the traffic light knows there's no one around.", "tokens": [264, 6419, 1442, 3255, 456, 311, 572, 472, 926, 13], "temperature": 0.0, "avg_logprob": -0.24541665649414063, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.8570827907969942e-06}, {"id": 785, "seek": 320584, "start": 3220.36, "end": 3223.88, "text": " And every time I go there, I'm like, ah, this is so amazing.", "tokens": [400, 633, 565, 286, 352, 456, 11, 286, 478, 411, 11, 3716, 11, 341, 307, 370, 2243, 13], "temperature": 0.0, "avg_logprob": -0.24541665649414063, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.8570827907969942e-06}, {"id": 786, "seek": 320584, "start": 3223.88, "end": 3230.96, "text": " And then I go back to France and I get to a traffic light that is red and I look everywhere", "tokens": [400, 550, 286, 352, 646, 281, 6190, 293, 286, 483, 281, 257, 6419, 1442, 300, 307, 2182, 293, 286, 574, 5315], "temperature": 0.0, "avg_logprob": -0.24541665649414063, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.8570827907969942e-06}, {"id": 787, "seek": 320584, "start": 3230.96, "end": 3232.76, "text": " and there's no one in sight.", "tokens": [293, 456, 311, 572, 472, 294, 7860, 13], "temperature": 0.0, "avg_logprob": -0.24541665649414063, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.8570827907969942e-06}, {"id": 788, "seek": 320584, "start": 3232.76, "end": 3234.6400000000003, "text": " No pedestrian, no bike lanes.", "tokens": [883, 33947, 11, 572, 5656, 25397, 13], "temperature": 0.0, "avg_logprob": -0.24541665649414063, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.8570827907969942e-06}, {"id": 789, "seek": 323464, "start": 3234.64, "end": 3238.64, "text": " Oh, well, there are no bike lanes and no other cars.", "tokens": [876, 11, 731, 11, 456, 366, 572, 5656, 25397, 293, 572, 661, 5163, 13], "temperature": 0.0, "avg_logprob": -0.259717337939204, "compression_ratio": 1.6261261261261262, "no_speech_prob": 8.798696399026085e-06}, {"id": 790, "seek": 323464, "start": 3238.64, "end": 3241.0, "text": " I'm like, why am I waiting?", "tokens": [286, 478, 411, 11, 983, 669, 286, 3806, 30], "temperature": 0.0, "avg_logprob": -0.259717337939204, "compression_ratio": 1.6261261261261262, "no_speech_prob": 8.798696399026085e-06}, {"id": 791, "seek": 323464, "start": 3241.0, "end": 3247.7999999999997, "text": " And just being able to have a green light right away would improve traffic for sure", "tokens": [400, 445, 885, 1075, 281, 362, 257, 3092, 1442, 558, 1314, 576, 3470, 6419, 337, 988], "temperature": 0.0, "avg_logprob": -0.259717337939204, "compression_ratio": 1.6261261261261262, "no_speech_prob": 8.798696399026085e-06}, {"id": 792, "seek": 323464, "start": 3247.7999999999997, "end": 3251.24, "text": " because people don't stop for nothing.", "tokens": [570, 561, 500, 380, 1590, 337, 1825, 13], "temperature": 0.0, "avg_logprob": -0.259717337939204, "compression_ratio": 1.6261261261261262, "no_speech_prob": 8.798696399026085e-06}, {"id": 793, "seek": 323464, "start": 3251.24, "end": 3258.2799999999997, "text": " You don't have a large lane of cars just waiting for this red light.", "tokens": [509, 500, 380, 362, 257, 2416, 12705, 295, 5163, 445, 3806, 337, 341, 2182, 1442, 13], "temperature": 0.0, "avg_logprob": -0.259717337939204, "compression_ratio": 1.6261261261261262, "no_speech_prob": 8.798696399026085e-06}, {"id": 794, "seek": 323464, "start": 3258.2799999999997, "end": 3263.04, "text": " And the people, at least in France, I don't think they know how bad they have it because", "tokens": [400, 264, 561, 11, 412, 1935, 294, 6190, 11, 286, 500, 380, 519, 436, 458, 577, 1578, 436, 362, 309, 570], "temperature": 0.0, "avg_logprob": -0.259717337939204, "compression_ratio": 1.6261261261261262, "no_speech_prob": 8.798696399026085e-06}, {"id": 795, "seek": 326304, "start": 3263.04, "end": 3267.4, "text": " they haven't seen, they haven't been to the Netherlands.", "tokens": [436, 2378, 380, 1612, 11, 436, 2378, 380, 668, 281, 264, 20873, 13], "temperature": 0.0, "avg_logprob": -0.3175435747419085, "compression_ratio": 1.654320987654321, "no_speech_prob": 2.6015122784883715e-06}, {"id": 796, "seek": 326304, "start": 3267.4, "end": 3271.36, "text": " When they have, they go there for bad reasons like French tourists.", "tokens": [1133, 436, 362, 11, 436, 352, 456, 337, 1578, 4112, 411, 5522, 20273, 13], "temperature": 0.0, "avg_logprob": -0.3175435747419085, "compression_ratio": 1.654320987654321, "no_speech_prob": 2.6015122784883715e-06}, {"id": 797, "seek": 326304, "start": 3271.36, "end": 3272.36, "text": " Right, right.", "tokens": [1779, 11, 558, 13], "temperature": 0.0, "avg_logprob": -0.3175435747419085, "compression_ratio": 1.654320987654321, "no_speech_prob": 2.6015122784883715e-06}, {"id": 798, "seek": 326304, "start": 3272.36, "end": 3276.44, "text": " And yeah, I think for typescript, it's the same.", "tokens": [400, 1338, 11, 286, 519, 337, 3467, 5944, 11, 309, 311, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.3175435747419085, "compression_ratio": 1.654320987654321, "no_speech_prob": 2.6015122784883715e-06}, {"id": 799, "seek": 326304, "start": 3276.44, "end": 3279.84, "text": " Like if you go to Elm, you won't have the same type system.", "tokens": [1743, 498, 291, 352, 281, 2699, 76, 11, 291, 1582, 380, 362, 264, 912, 2010, 1185, 13], "temperature": 0.0, "avg_logprob": -0.3175435747419085, "compression_ratio": 1.654320987654321, "no_speech_prob": 2.6015122784883715e-06}, {"id": 800, "seek": 326304, "start": 3279.84, "end": 3281.84, "text": " It will be a much nicer one.", "tokens": [467, 486, 312, 257, 709, 22842, 472, 13], "temperature": 0.0, "avg_logprob": -0.3175435747419085, "compression_ratio": 1.654320987654321, "no_speech_prob": 2.6015122784883715e-06}, {"id": 801, "seek": 326304, "start": 3281.84, "end": 3285.12, "text": " Limiting, potentially, but much nicer.", "tokens": [16406, 1748, 11, 7263, 11, 457, 709, 22842, 13], "temperature": 0.0, "avg_logprob": -0.3175435747419085, "compression_ratio": 1.654320987654321, "no_speech_prob": 2.6015122784883715e-06}, {"id": 802, "seek": 326304, "start": 3285.12, "end": 3291.48, "text": " Side effects, not an issue, but you don't know how bad you have it when you have that.", "tokens": [19026, 5065, 11, 406, 364, 2734, 11, 457, 291, 500, 380, 458, 577, 1578, 291, 362, 309, 562, 291, 362, 300, 13], "temperature": 0.0, "avg_logprob": -0.3175435747419085, "compression_ratio": 1.654320987654321, "no_speech_prob": 2.6015122784883715e-06}, {"id": 803, "seek": 329148, "start": 3291.48, "end": 3296.84, "text": " So trade-offs everywhere, but sometimes the results are very, very nice.", "tokens": [407, 4923, 12, 19231, 5315, 11, 457, 2171, 264, 3542, 366, 588, 11, 588, 1481, 13], "temperature": 0.0, "avg_logprob": -0.2825468113992067, "compression_ratio": 1.5919282511210762, "no_speech_prob": 2.2600120246352162e-06}, {"id": 804, "seek": 329148, "start": 3296.84, "end": 3301.72, "text": " And I think it would be nice for people to try out those things.", "tokens": [400, 286, 519, 309, 576, 312, 1481, 337, 561, 281, 853, 484, 729, 721, 13], "temperature": 0.0, "avg_logprob": -0.2825468113992067, "compression_ratio": 1.5919282511210762, "no_speech_prob": 2.2600120246352162e-06}, {"id": 805, "seek": 329148, "start": 3301.72, "end": 3303.36, "text": " And by the way, go to the Netherlands.", "tokens": [400, 538, 264, 636, 11, 352, 281, 264, 20873, 13], "temperature": 0.0, "avg_logprob": -0.2825468113992067, "compression_ratio": 1.5919282511210762, "no_speech_prob": 2.2600120246352162e-06}, {"id": 806, "seek": 329148, "start": 3303.36, "end": 3304.36, "text": " It's a nice place.", "tokens": [467, 311, 257, 1481, 1081, 13], "temperature": 0.0, "avg_logprob": -0.2825468113992067, "compression_ratio": 1.5919282511210762, "no_speech_prob": 2.2600120246352162e-06}, {"id": 807, "seek": 329148, "start": 3304.36, "end": 3306.04, "text": " Yes, I definitely will.", "tokens": [1079, 11, 286, 2138, 486, 13], "temperature": 0.0, "avg_logprob": -0.2825468113992067, "compression_ratio": 1.5919282511210762, "no_speech_prob": 2.2600120246352162e-06}, {"id": 808, "seek": 329148, "start": 3306.04, "end": 3307.04, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2825468113992067, "compression_ratio": 1.5919282511210762, "no_speech_prob": 2.2600120246352162e-06}, {"id": 809, "seek": 329148, "start": 3307.04, "end": 3309.52, "text": " But don't take the plane too much.", "tokens": [583, 500, 380, 747, 264, 5720, 886, 709, 13], "temperature": 0.0, "avg_logprob": -0.2825468113992067, "compression_ratio": 1.5919282511210762, "no_speech_prob": 2.2600120246352162e-06}, {"id": 810, "seek": 329148, "start": 3309.52, "end": 3310.52, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2825468113992067, "compression_ratio": 1.5919282511210762, "no_speech_prob": 2.2600120246352162e-06}, {"id": 811, "seek": 329148, "start": 3310.52, "end": 3311.52, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2825468113992067, "compression_ratio": 1.5919282511210762, "no_speech_prob": 2.2600120246352162e-06}, {"id": 812, "seek": 329148, "start": 3311.52, "end": 3312.52, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2825468113992067, "compression_ratio": 1.5919282511210762, "no_speech_prob": 2.2600120246352162e-06}, {"id": 813, "seek": 329148, "start": 3312.52, "end": 3320.16, "text": " I mean, it's definitely, you kind of buy into a way of working and thinking.", "tokens": [286, 914, 11, 309, 311, 2138, 11, 291, 733, 295, 2256, 666, 257, 636, 295, 1364, 293, 1953, 13], "temperature": 0.0, "avg_logprob": -0.2825468113992067, "compression_ratio": 1.5919282511210762, "no_speech_prob": 2.2600120246352162e-06}, {"id": 814, "seek": 332016, "start": 3320.16, "end": 3322.52, "text": " And I find it really interesting.", "tokens": [400, 286, 915, 309, 534, 1880, 13], "temperature": 0.0, "avg_logprob": -0.22785756985346475, "compression_ratio": 1.720524017467249, "no_speech_prob": 1.2203471669636201e-05}, {"id": 815, "seek": 332016, "start": 3322.52, "end": 3328.8399999999997, "text": " My time as a coach, doing my coaching work really influenced me on this as well, of how", "tokens": [1222, 565, 382, 257, 6560, 11, 884, 452, 15818, 589, 534, 15269, 385, 322, 341, 382, 731, 11, 295, 577], "temperature": 0.0, "avg_logprob": -0.22785756985346475, "compression_ratio": 1.720524017467249, "no_speech_prob": 1.2203471669636201e-05}, {"id": 816, "seek": 332016, "start": 3328.8399999999997, "end": 3334.48, "text": " much somebody's mental model of something can influence the way they interpret what's", "tokens": [709, 2618, 311, 4973, 2316, 295, 746, 393, 6503, 264, 636, 436, 7302, 437, 311], "temperature": 0.0, "avg_logprob": -0.22785756985346475, "compression_ratio": 1.720524017467249, "no_speech_prob": 1.2203471669636201e-05}, {"id": 817, "seek": 332016, "start": 3334.48, "end": 3335.56, "text": " going on.", "tokens": [516, 322, 13], "temperature": 0.0, "avg_logprob": -0.22785756985346475, "compression_ratio": 1.720524017467249, "no_speech_prob": 1.2203471669636201e-05}, {"id": 818, "seek": 332016, "start": 3335.56, "end": 3344.8799999999997, "text": " So for example, like a lot of my coaching work, I was trying to get teams not being", "tokens": [407, 337, 1365, 11, 411, 257, 688, 295, 452, 15818, 589, 11, 286, 390, 1382, 281, 483, 5491, 406, 885], "temperature": 0.0, "avg_logprob": -0.22785756985346475, "compression_ratio": 1.720524017467249, "no_speech_prob": 1.2203471669636201e-05}, {"id": 819, "seek": 332016, "start": 3344.8799999999997, "end": 3350.12, "text": " blocked by things, not being blocked by needing things from other teams, but being empowered", "tokens": [15470, 538, 721, 11, 406, 885, 15470, 538, 18006, 721, 490, 661, 5491, 11, 457, 885, 27898], "temperature": 0.0, "avg_logprob": -0.22785756985346475, "compression_ratio": 1.720524017467249, "no_speech_prob": 1.2203471669636201e-05}, {"id": 820, "seek": 335012, "start": 3350.12, "end": 3355.72, "text": " to work on things on their own and being able to ship things all within one team and being", "tokens": [281, 589, 322, 721, 322, 641, 1065, 293, 885, 1075, 281, 5374, 721, 439, 1951, 472, 1469, 293, 885], "temperature": 0.0, "avg_logprob": -0.22339454857078758, "compression_ratio": 1.7135135135135136, "no_speech_prob": 7.764911970298272e-06}, {"id": 821, "seek": 335012, "start": 3355.72, "end": 3360.44, "text": " able to deploy something with the push of a button.", "tokens": [1075, 281, 7274, 746, 365, 264, 2944, 295, 257, 2960, 13], "temperature": 0.0, "avg_logprob": -0.22339454857078758, "compression_ratio": 1.7135135135135136, "no_speech_prob": 7.764911970298272e-06}, {"id": 822, "seek": 335012, "start": 3360.44, "end": 3368.0, "text": " But if you're perceiving things as being more efficient by another team working on something,", "tokens": [583, 498, 291, 434, 9016, 2123, 721, 382, 885, 544, 7148, 538, 1071, 1469, 1364, 322, 746, 11], "temperature": 0.0, "avg_logprob": -0.22339454857078758, "compression_ratio": 1.7135135135135136, "no_speech_prob": 7.764911970298272e-06}, {"id": 823, "seek": 335012, "start": 3368.0, "end": 3374.52, "text": " then you're going to interpret the pain points around that in a different light.", "tokens": [550, 291, 434, 516, 281, 7302, 264, 1822, 2793, 926, 300, 294, 257, 819, 1442, 13], "temperature": 0.0, "avg_logprob": -0.22339454857078758, "compression_ratio": 1.7135135135135136, "no_speech_prob": 7.764911970298272e-06}, {"id": 824, "seek": 337452, "start": 3374.52, "end": 3380.64, "text": " Whereas if you perceive the pain of fitting pieces together, where two different teams", "tokens": [13813, 498, 291, 20281, 264, 1822, 295, 15669, 3755, 1214, 11, 689, 732, 819, 5491], "temperature": 0.0, "avg_logprob": -0.23096396047857742, "compression_ratio": 1.669811320754717, "no_speech_prob": 9.874250963548548e-07}, {"id": 825, "seek": 337452, "start": 3380.64, "end": 3386.68, "text": " built something and now you go to integrate those two pieces and they don't work, or these", "tokens": [3094, 746, 293, 586, 291, 352, 281, 13365, 729, 732, 3755, 293, 436, 500, 380, 589, 11, 420, 613], "temperature": 0.0, "avg_logprob": -0.23096396047857742, "compression_ratio": 1.669811320754717, "no_speech_prob": 9.874250963548548e-07}, {"id": 826, "seek": 337452, "start": 3386.68, "end": 3391.32, "text": " two systems don't understand each other, or they have a very heavy handed contract with", "tokens": [732, 3652, 500, 380, 1223, 1184, 661, 11, 420, 436, 362, 257, 588, 4676, 16013, 4364, 365], "temperature": 0.0, "avg_logprob": -0.23096396047857742, "compression_ratio": 1.669811320754717, "no_speech_prob": 9.874250963548548e-07}, {"id": 827, "seek": 337452, "start": 3391.32, "end": 3398.96, "text": " each other because it's not people operating within the same context, or you're going to", "tokens": [1184, 661, 570, 309, 311, 406, 561, 7447, 1951, 264, 912, 4319, 11, 420, 291, 434, 516, 281], "temperature": 0.0, "avg_logprob": -0.23096396047857742, "compression_ratio": 1.669811320754717, "no_speech_prob": 9.874250963548548e-07}, {"id": 828, "seek": 339896, "start": 3398.96, "end": 3404.56, "text": " ship something and you have five months of work that you're going to spend one month", "tokens": [5374, 746, 293, 291, 362, 1732, 2493, 295, 589, 300, 291, 434, 516, 281, 3496, 472, 1618], "temperature": 0.0, "avg_logprob": -0.2262916411122968, "compression_ratio": 1.9328063241106719, "no_speech_prob": 1.644210897211451e-05}, {"id": 829, "seek": 339896, "start": 3404.56, "end": 3407.28, "text": " testing.", "tokens": [4997, 13], "temperature": 0.0, "avg_logprob": -0.2262916411122968, "compression_ratio": 1.9328063241106719, "no_speech_prob": 1.644210897211451e-05}, {"id": 830, "seek": 339896, "start": 3407.28, "end": 3411.32, "text": " You're going to perceive that very differently if you have a mental model that says, well,", "tokens": [509, 434, 516, 281, 20281, 300, 588, 7614, 498, 291, 362, 257, 4973, 2316, 300, 1619, 11, 731, 11], "temperature": 0.0, "avg_logprob": -0.2262916411122968, "compression_ratio": 1.9328063241106719, "no_speech_prob": 1.644210897211451e-05}, {"id": 831, "seek": 339896, "start": 3411.32, "end": 3413.2400000000002, "text": " let's be efficient with our testing.", "tokens": [718, 311, 312, 7148, 365, 527, 4997, 13], "temperature": 0.0, "avg_logprob": -0.2262916411122968, "compression_ratio": 1.9328063241106719, "no_speech_prob": 1.644210897211451e-05}, {"id": 832, "seek": 339896, "start": 3413.2400000000002, "end": 3418.04, "text": " We have to manually test this, so let's be efficient by batching everything up.", "tokens": [492, 362, 281, 16945, 1500, 341, 11, 370, 718, 311, 312, 7148, 538, 15245, 278, 1203, 493, 13], "temperature": 0.0, "avg_logprob": -0.2262916411122968, "compression_ratio": 1.9328063241106719, "no_speech_prob": 1.644210897211451e-05}, {"id": 833, "seek": 339896, "start": 3418.04, "end": 3422.56, "text": " We don't want to ship something today and then have to go test the whole app.", "tokens": [492, 500, 380, 528, 281, 5374, 746, 965, 293, 550, 362, 281, 352, 1500, 264, 1379, 724, 13], "temperature": 0.0, "avg_logprob": -0.2262916411122968, "compression_ratio": 1.9328063241106719, "no_speech_prob": 1.644210897211451e-05}, {"id": 834, "seek": 339896, "start": 3422.56, "end": 3423.56, "text": " That would be inefficient.", "tokens": [663, 576, 312, 43495, 13], "temperature": 0.0, "avg_logprob": -0.2262916411122968, "compression_ratio": 1.9328063241106719, "no_speech_prob": 1.644210897211451e-05}, {"id": 835, "seek": 339896, "start": 3423.56, "end": 3428.0, "text": " Well, if that's your mental model of things, then it is going to look inefficient.", "tokens": [1042, 11, 498, 300, 311, 428, 4973, 2316, 295, 721, 11, 550, 309, 307, 516, 281, 574, 43495, 13], "temperature": 0.0, "avg_logprob": -0.2262916411122968, "compression_ratio": 1.9328063241106719, "no_speech_prob": 1.644210897211451e-05}, {"id": 836, "seek": 342800, "start": 3428.0, "end": 3436.0, "text": " But if you have a different mental model, then you look at it as the more we batch things", "tokens": [583, 498, 291, 362, 257, 819, 4973, 2316, 11, 550, 291, 574, 412, 309, 382, 264, 544, 321, 15245, 721], "temperature": 0.0, "avg_logprob": -0.2663519433204164, "compression_ratio": 1.8527918781725887, "no_speech_prob": 7.811449904693291e-07}, {"id": 837, "seek": 342800, "start": 3436.0, "end": 3439.92, "text": " up, the more that can break at once.", "tokens": [493, 11, 264, 544, 300, 393, 1821, 412, 1564, 13], "temperature": 0.0, "avg_logprob": -0.2663519433204164, "compression_ratio": 1.8527918781725887, "no_speech_prob": 7.811449904693291e-07}, {"id": 838, "seek": 342800, "start": 3439.92, "end": 3445.52, "text": " And the more we've lost context from the thing that we've worked on to know what we're looking", "tokens": [400, 264, 544, 321, 600, 2731, 4319, 490, 264, 551, 300, 321, 600, 2732, 322, 281, 458, 437, 321, 434, 1237], "temperature": 0.0, "avg_logprob": -0.2663519433204164, "compression_ratio": 1.8527918781725887, "no_speech_prob": 7.811449904693291e-07}, {"id": 839, "seek": 342800, "start": 3445.52, "end": 3446.52, "text": " for.", "tokens": [337, 13], "temperature": 0.0, "avg_logprob": -0.2663519433204164, "compression_ratio": 1.8527918781725887, "no_speech_prob": 7.811449904693291e-07}, {"id": 840, "seek": 342800, "start": 3446.52, "end": 3452.16, "text": " And the less we've automated testing things and the less confident we can be about our", "tokens": [400, 264, 1570, 321, 600, 18473, 4997, 721, 293, 264, 1570, 6679, 321, 393, 312, 466, 527], "temperature": 0.0, "avg_logprob": -0.2663519433204164, "compression_ratio": 1.8527918781725887, "no_speech_prob": 7.811449904693291e-07}, {"id": 841, "seek": 342800, "start": 3452.16, "end": 3455.24, "text": " deploy process and the less we automate our deploy.", "tokens": [7274, 1399, 293, 264, 1570, 321, 31605, 527, 7274, 13], "temperature": 0.0, "avg_logprob": -0.2663519433204164, "compression_ratio": 1.8527918781725887, "no_speech_prob": 7.811449904693291e-07}, {"id": 842, "seek": 345524, "start": 3455.24, "end": 3460.9199999999996, "text": " So looking at it through different lenses totally transforms the way that you see it.", "tokens": [407, 1237, 412, 309, 807, 819, 18059, 3879, 35592, 264, 636, 300, 291, 536, 309, 13], "temperature": 0.0, "avg_logprob": -0.22730331814166196, "compression_ratio": 1.685483870967742, "no_speech_prob": 2.0580284854077036e-06}, {"id": 843, "seek": 345524, "start": 3460.9199999999996, "end": 3465.56, "text": " I think it's the same with looking at the tradeoffs of Elm versus TypeScript.", "tokens": [286, 519, 309, 311, 264, 912, 365, 1237, 412, 264, 4923, 19231, 295, 2699, 76, 5717, 15576, 14237, 13], "temperature": 0.0, "avg_logprob": -0.22730331814166196, "compression_ratio": 1.685483870967742, "no_speech_prob": 2.0580284854077036e-06}, {"id": 844, "seek": 345524, "start": 3465.56, "end": 3474.2999999999997, "text": " If you're looking at it as the value of guarantees versus the inconvenience of having to pass", "tokens": [759, 291, 434, 1237, 412, 309, 382, 264, 2158, 295, 32567, 5717, 264, 28752, 1182, 295, 1419, 281, 1320], "temperature": 0.0, "avg_logprob": -0.22730331814166196, "compression_ratio": 1.685483870967742, "no_speech_prob": 2.0580284854077036e-06}, {"id": 845, "seek": 345524, "start": 3474.2999999999997, "end": 3479.3199999999997, "text": " through side effects explicitly, not being able to trigger them from anywhere, the hindrance", "tokens": [807, 1252, 5065, 20803, 11, 406, 885, 1075, 281, 7875, 552, 490, 4992, 11, 264, 20138, 32493], "temperature": 0.0, "avg_logprob": -0.22730331814166196, "compression_ratio": 1.685483870967742, "no_speech_prob": 2.0580284854077036e-06}, {"id": 846, "seek": 345524, "start": 3479.3199999999997, "end": 3482.7999999999997, "text": " that that causes you, you're going to perceive it very differently.", "tokens": [300, 300, 7700, 291, 11, 291, 434, 516, 281, 20281, 309, 588, 7614, 13], "temperature": 0.0, "avg_logprob": -0.22730331814166196, "compression_ratio": 1.685483870967742, "no_speech_prob": 2.0580284854077036e-06}, {"id": 847, "seek": 348280, "start": 3482.8, "end": 3488.6000000000004, "text": " And I think some people just have a different mental model and a different preference fundamentally.", "tokens": [400, 286, 519, 512, 561, 445, 362, 257, 819, 4973, 2316, 293, 257, 819, 17502, 17879, 13], "temperature": 0.0, "avg_logprob": -0.22843412399291993, "compression_ratio": 1.7285067873303168, "no_speech_prob": 4.029381670989096e-06}, {"id": 848, "seek": 348280, "start": 3488.6000000000004, "end": 3490.0800000000004, "text": " And I think that's fine.", "tokens": [400, 286, 519, 300, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.22843412399291993, "compression_ratio": 1.7285067873303168, "no_speech_prob": 4.029381670989096e-06}, {"id": 849, "seek": 348280, "start": 3490.0800000000004, "end": 3498.1600000000003, "text": " But for those who, I mean, my bottom line is if you make a set of tradeoffs, then cash", "tokens": [583, 337, 729, 567, 11, 286, 914, 11, 452, 2767, 1622, 307, 498, 291, 652, 257, 992, 295, 4923, 19231, 11, 550, 6388], "temperature": 0.0, "avg_logprob": -0.22843412399291993, "compression_ratio": 1.7285067873303168, "no_speech_prob": 4.029381670989096e-06}, {"id": 850, "seek": 348280, "start": 3498.1600000000003, "end": 3502.84, "text": " in the good things from those tradeoffs.", "tokens": [294, 264, 665, 721, 490, 729, 4923, 19231, 13], "temperature": 0.0, "avg_logprob": -0.22843412399291993, "compression_ratio": 1.7285067873303168, "no_speech_prob": 4.029381670989096e-06}, {"id": 851, "seek": 348280, "start": 3502.84, "end": 3508.6000000000004, "text": " You've paid the cost of making the sacrifices of the cons of that tradeoff.", "tokens": [509, 600, 4835, 264, 2063, 295, 1455, 264, 25094, 295, 264, 1014, 295, 300, 4923, 4506, 13], "temperature": 0.0, "avg_logprob": -0.22843412399291993, "compression_ratio": 1.7285067873303168, "no_speech_prob": 4.029381670989096e-06}, {"id": 852, "seek": 348280, "start": 3508.6000000000004, "end": 3512.0800000000004, "text": " So get all the pros from that tradeoff that you can.", "tokens": [407, 483, 439, 264, 6267, 490, 300, 4923, 4506, 300, 291, 393, 13], "temperature": 0.0, "avg_logprob": -0.22843412399291993, "compression_ratio": 1.7285067873303168, "no_speech_prob": 4.029381670989096e-06}, {"id": 853, "seek": 351208, "start": 3512.08, "end": 3513.08, "text": " And right.", "tokens": [400, 558, 13], "temperature": 0.0, "avg_logprob": -0.2700948091310875, "compression_ratio": 1.5921052631578947, "no_speech_prob": 2.5865072529995814e-05}, {"id": 854, "seek": 351208, "start": 3513.08, "end": 3517.08, "text": " But you need to know which tradeoffs you made.", "tokens": [583, 291, 643, 281, 458, 597, 4923, 19231, 291, 1027, 13], "temperature": 0.0, "avg_logprob": -0.2700948091310875, "compression_ratio": 1.5921052631578947, "no_speech_prob": 2.5865072529995814e-05}, {"id": 855, "seek": 351208, "start": 3517.08, "end": 3523.2, "text": " If you only know JavaScript, what are the tradeoffs of JavaScript compared to other", "tokens": [759, 291, 787, 458, 15778, 11, 437, 366, 264, 4923, 19231, 295, 15778, 5347, 281, 661], "temperature": 0.0, "avg_logprob": -0.2700948091310875, "compression_ratio": 1.5921052631578947, "no_speech_prob": 2.5865072529995814e-05}, {"id": 856, "seek": 351208, "start": 3523.2, "end": 3524.2, "text": " things?", "tokens": [721, 30], "temperature": 0.0, "avg_logprob": -0.2700948091310875, "compression_ratio": 1.5921052631578947, "no_speech_prob": 2.5865072529995814e-05}, {"id": 857, "seek": 351208, "start": 3524.2, "end": 3525.2, "text": " Like where does it shine?", "tokens": [1743, 689, 775, 309, 12207, 30], "temperature": 0.0, "avg_logprob": -0.2700948091310875, "compression_ratio": 1.5921052631578947, "no_speech_prob": 2.5865072529995814e-05}, {"id": 858, "seek": 351208, "start": 3525.2, "end": 3526.2, "text": " Absolutely.", "tokens": [7021, 13], "temperature": 0.0, "avg_logprob": -0.2700948091310875, "compression_ratio": 1.5921052631578947, "no_speech_prob": 2.5865072529995814e-05}, {"id": 859, "seek": 351208, "start": 3526.2, "end": 3527.2, "text": " Absolutely.", "tokens": [7021, 13], "temperature": 0.0, "avg_logprob": -0.2700948091310875, "compression_ratio": 1.5921052631578947, "no_speech_prob": 2.5865072529995814e-05}, {"id": 860, "seek": 351208, "start": 3527.2, "end": 3528.2, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.2700948091310875, "compression_ratio": 1.5921052631578947, "no_speech_prob": 2.5865072529995814e-05}, {"id": 861, "seek": 351208, "start": 3528.2, "end": 3533.44, "text": " And I mean, I think, I mean, I've heard a lot of people say that try Elm out, you'll", "tokens": [400, 286, 914, 11, 286, 519, 11, 286, 914, 11, 286, 600, 2198, 257, 688, 295, 561, 584, 300, 853, 2699, 76, 484, 11, 291, 603], "temperature": 0.0, "avg_logprob": -0.2700948091310875, "compression_ratio": 1.5921052631578947, "no_speech_prob": 2.5865072529995814e-05}, {"id": 862, "seek": 351208, "start": 3533.44, "end": 3537.4, "text": " learn something even if you end up not using it in your production stack.", "tokens": [1466, 746, 754, 498, 291, 917, 493, 406, 1228, 309, 294, 428, 4265, 8630, 13], "temperature": 0.0, "avg_logprob": -0.2700948091310875, "compression_ratio": 1.5921052631578947, "no_speech_prob": 2.5865072529995814e-05}, {"id": 863, "seek": 353740, "start": 3537.4, "end": 3542.14, "text": " So I definitely think it's a good learning experience for people to try it out regardless", "tokens": [407, 286, 2138, 519, 309, 311, 257, 665, 2539, 1752, 337, 561, 281, 853, 309, 484, 10060], "temperature": 0.0, "avg_logprob": -0.3255919415017833, "compression_ratio": 1.6392156862745098, "no_speech_prob": 4.49499384558294e-06}, {"id": 864, "seek": 353740, "start": 3542.14, "end": 3543.88, "text": " of whether they end up using it.", "tokens": [295, 1968, 436, 917, 493, 1228, 309, 13], "temperature": 0.0, "avg_logprob": -0.3255919415017833, "compression_ratio": 1.6392156862745098, "no_speech_prob": 4.49499384558294e-06}, {"id": 865, "seek": 353740, "start": 3543.88, "end": 3547.76, "text": " It's interesting because when you say, tell people how to write good code, it's usually", "tokens": [467, 311, 1880, 570, 562, 291, 584, 11, 980, 561, 577, 281, 2464, 665, 3089, 11, 309, 311, 2673], "temperature": 0.0, "avg_logprob": -0.3255919415017833, "compression_ratio": 1.6392156862745098, "no_speech_prob": 4.49499384558294e-06}, {"id": 866, "seek": 353740, "start": 3547.76, "end": 3554.08, "text": " like stay simple, write good names and just use simple functions.", "tokens": [411, 1754, 2199, 11, 2464, 665, 5288, 293, 445, 764, 2199, 6828, 13], "temperature": 0.0, "avg_logprob": -0.3255919415017833, "compression_ratio": 1.6392156862745098, "no_speech_prob": 4.49499384558294e-06}, {"id": 867, "seek": 353740, "start": 3554.08, "end": 3555.08, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.3255919415017833, "compression_ratio": 1.6392156862745098, "no_speech_prob": 4.49499384558294e-06}, {"id": 868, "seek": 353740, "start": 3555.08, "end": 3557.32, "text": " That in practice, that's what it boils down to.", "tokens": [663, 294, 3124, 11, 300, 311, 437, 309, 35049, 760, 281, 13], "temperature": 0.0, "avg_logprob": -0.3255919415017833, "compression_ratio": 1.6392156862745098, "no_speech_prob": 4.49499384558294e-06}, {"id": 869, "seek": 353740, "start": 3557.32, "end": 3560.12, "text": " Like keep codes very simple.", "tokens": [1743, 1066, 14211, 588, 2199, 13], "temperature": 0.0, "avg_logprob": -0.3255919415017833, "compression_ratio": 1.6392156862745098, "no_speech_prob": 4.49499384558294e-06}, {"id": 870, "seek": 353740, "start": 3560.12, "end": 3561.12, "text": " Kiss.", "tokens": [24297, 13], "temperature": 0.0, "avg_logprob": -0.3255919415017833, "compression_ratio": 1.6392156862745098, "no_speech_prob": 4.49499384558294e-06}, {"id": 871, "seek": 353740, "start": 3561.12, "end": 3565.4, "text": " Keep it stupid, simple, silly, simple, silly.", "tokens": [5527, 309, 6631, 11, 2199, 11, 11774, 11, 2199, 11, 11774, 13], "temperature": 0.0, "avg_logprob": -0.3255919415017833, "compression_ratio": 1.6392156862745098, "no_speech_prob": 4.49499384558294e-06}, {"id": 872, "seek": 353740, "start": 3565.4, "end": 3566.4, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.3255919415017833, "compression_ratio": 1.6392156862745098, "no_speech_prob": 4.49499384558294e-06}, {"id": 873, "seek": 356640, "start": 3566.4, "end": 3568.56, "text": " Is that stupid?", "tokens": [1119, 300, 6631, 30], "temperature": 0.0, "avg_logprob": -0.3667919988217561, "compression_ratio": 1.5940170940170941, "no_speech_prob": 1.6796755062387092e-06}, {"id": 874, "seek": 356640, "start": 3568.56, "end": 3570.28, "text": " Usually people say keep it simple, stupid.", "tokens": [11419, 561, 584, 1066, 309, 2199, 11, 6631, 13], "temperature": 0.0, "avg_logprob": -0.3667919988217561, "compression_ratio": 1.5940170940170941, "no_speech_prob": 1.6796755062387092e-06}, {"id": 875, "seek": 356640, "start": 3570.28, "end": 3571.88, "text": " I was just being silly.", "tokens": [286, 390, 445, 885, 11774, 13], "temperature": 0.0, "avg_logprob": -0.3667919988217561, "compression_ratio": 1.5940170940170941, "no_speech_prob": 1.6796755062387092e-06}, {"id": 876, "seek": 356640, "start": 3571.88, "end": 3575.44, "text": " Well, I mean, it's maybe a less offensive one.", "tokens": [1042, 11, 286, 914, 11, 309, 311, 1310, 257, 1570, 15710, 472, 13], "temperature": 0.0, "avg_logprob": -0.3667919988217561, "compression_ratio": 1.5940170940170941, "no_speech_prob": 1.6796755062387092e-06}, {"id": 877, "seek": 356640, "start": 3575.44, "end": 3576.44, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.3667919988217561, "compression_ratio": 1.5940170940170941, "no_speech_prob": 1.6796755062387092e-06}, {"id": 878, "seek": 356640, "start": 3576.44, "end": 3579.28, "text": " Not the one that I had heard at least.", "tokens": [1726, 264, 472, 300, 286, 632, 2198, 412, 1935, 13], "temperature": 0.0, "avg_logprob": -0.3667919988217561, "compression_ratio": 1.5940170940170941, "no_speech_prob": 1.6796755062387092e-06}, {"id": 879, "seek": 356640, "start": 3579.28, "end": 3586.2000000000003, "text": " I mean, in practice, like if you want to go towards better and simple code, you go to", "tokens": [286, 914, 11, 294, 3124, 11, 411, 498, 291, 528, 281, 352, 3030, 1101, 293, 2199, 3089, 11, 291, 352, 281], "temperature": 0.0, "avg_logprob": -0.3667919988217561, "compression_ratio": 1.5940170940170941, "no_speech_prob": 1.6796755062387092e-06}, {"id": 880, "seek": 356640, "start": 3586.2000000000003, "end": 3590.6, "text": " words code that it looks like Elm and Elm just makes that the default.", "tokens": [2283, 3089, 300, 309, 1542, 411, 2699, 76, 293, 2699, 76, 445, 1669, 300, 264, 7576, 13], "temperature": 0.0, "avg_logprob": -0.3667919988217561, "compression_ratio": 1.5940170940170941, "no_speech_prob": 1.6796755062387092e-06}, {"id": 881, "seek": 356640, "start": 3590.6, "end": 3591.6, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.3667919988217561, "compression_ratio": 1.5940170940170941, "no_speech_prob": 1.6796755062387092e-06}, {"id": 882, "seek": 356640, "start": 3591.6, "end": 3593.04, "text": " Also like the only thing you can do.", "tokens": [2743, 411, 264, 787, 551, 291, 393, 360, 13], "temperature": 0.0, "avg_logprob": -0.3667919988217561, "compression_ratio": 1.5940170940170941, "no_speech_prob": 1.6796755062387092e-06}, {"id": 883, "seek": 359304, "start": 3593.04, "end": 3600.68, "text": " So we might feel like a limitation, but in practice, like, yeah, it's just good code", "tokens": [407, 321, 1062, 841, 411, 257, 27432, 11, 457, 294, 3124, 11, 411, 11, 1338, 11, 309, 311, 445, 665, 3089], "temperature": 0.0, "avg_logprob": -0.2768086637004038, "compression_ratio": 1.5395348837209302, "no_speech_prob": 8.579071959502471e-07}, {"id": 884, "seek": 359304, "start": 3600.68, "end": 3603.88, "text": " because that's what good code tends to words.", "tokens": [570, 300, 311, 437, 665, 3089, 12258, 281, 2283, 13], "temperature": 0.0, "avg_logprob": -0.2768086637004038, "compression_ratio": 1.5395348837209302, "no_speech_prob": 8.579071959502471e-07}, {"id": 885, "seek": 359304, "start": 3603.88, "end": 3604.88, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2768086637004038, "compression_ratio": 1.5395348837209302, "no_speech_prob": 8.579071959502471e-07}, {"id": 886, "seek": 359304, "start": 3604.88, "end": 3611.66, "text": " I mean, I definitely am convinced personally, my, like all of the things that I've learned", "tokens": [286, 914, 11, 286, 2138, 669, 12561, 5665, 11, 452, 11, 411, 439, 295, 264, 721, 300, 286, 600, 3264], "temperature": 0.0, "avg_logprob": -0.2768086637004038, "compression_ratio": 1.5395348837209302, "no_speech_prob": 8.579071959502471e-07}, {"id": 887, "seek": 359304, "start": 3611.66, "end": 3618.2, "text": " about what makes a code base maintainable are very aligned with Elm and happen very", "tokens": [466, 437, 1669, 257, 3089, 3096, 6909, 712, 366, 588, 17962, 365, 2699, 76, 293, 1051, 588], "temperature": 0.0, "avg_logprob": -0.2768086637004038, "compression_ratio": 1.5395348837209302, "no_speech_prob": 8.579071959502471e-07}, {"id": 888, "seek": 359304, "start": 3618.2, "end": 3619.88, "text": " naturally with Elm.", "tokens": [8195, 365, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.2768086637004038, "compression_ratio": 1.5395348837209302, "no_speech_prob": 8.579071959502471e-07}, {"id": 889, "seek": 361988, "start": 3619.88, "end": 3625.08, "text": " Making code traceable, you know, decoupling things, inversion of control, all these types", "tokens": [14595, 3089, 13508, 712, 11, 291, 458, 11, 979, 263, 11970, 721, 11, 43576, 295, 1969, 11, 439, 613, 3467], "temperature": 0.0, "avg_logprob": -0.25784146785736084, "compression_ratio": 1.609442060085837, "no_speech_prob": 1.5293927617676673e-06}, {"id": 890, "seek": 361988, "start": 3625.08, "end": 3626.08, "text": " of practices.", "tokens": [295, 7525, 13], "temperature": 0.0, "avg_logprob": -0.25784146785736084, "compression_ratio": 1.609442060085837, "no_speech_prob": 1.5293927617676673e-06}, {"id": 891, "seek": 361988, "start": 3626.08, "end": 3628.88, "text": " It's very natural with Elm.", "tokens": [467, 311, 588, 3303, 365, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.25784146785736084, "compression_ratio": 1.609442060085837, "no_speech_prob": 1.5293927617676673e-06}, {"id": 892, "seek": 361988, "start": 3628.88, "end": 3635.48, "text": " Also like it's hard to imagine with how core parse don't validate and these types of principles", "tokens": [2743, 411, 309, 311, 1152, 281, 3811, 365, 577, 4965, 48377, 500, 380, 29562, 293, 613, 3467, 295, 9156], "temperature": 0.0, "avg_logprob": -0.25784146785736084, "compression_ratio": 1.609442060085837, "no_speech_prob": 1.5293927617676673e-06}, {"id": 893, "seek": 361988, "start": 3635.48, "end": 3640.7000000000003, "text": " make impossible states impossible are to how I think about writing good code and fixing", "tokens": [652, 6243, 4368, 6243, 366, 281, 577, 286, 519, 466, 3579, 665, 3089, 293, 19442], "temperature": 0.0, "avg_logprob": -0.25784146785736084, "compression_ratio": 1.609442060085837, "no_speech_prob": 1.5293927617676673e-06}, {"id": 894, "seek": 361988, "start": 3640.7000000000003, "end": 3643.12, "text": " bugs and keeping them fixed.", "tokens": [15120, 293, 5145, 552, 6806, 13], "temperature": 0.0, "avg_logprob": -0.25784146785736084, "compression_ratio": 1.609442060085837, "no_speech_prob": 1.5293927617676673e-06}, {"id": 895, "seek": 361988, "start": 3643.12, "end": 3644.4, "text": " I don't think I could go back.", "tokens": [286, 500, 380, 519, 286, 727, 352, 646, 13], "temperature": 0.0, "avg_logprob": -0.25784146785736084, "compression_ratio": 1.609442060085837, "no_speech_prob": 1.5293927617676673e-06}, {"id": 896, "seek": 364440, "start": 3644.4, "end": 3650.84, "text": " I don't know, I don't know how I would write code without tools in my tool belt that make", "tokens": [286, 500, 380, 458, 11, 286, 500, 380, 458, 577, 286, 576, 2464, 3089, 1553, 3873, 294, 452, 2290, 10750, 300, 652], "temperature": 0.0, "avg_logprob": -0.20222328804634712, "compression_ratio": 1.688976377952756, "no_speech_prob": 5.122838047100231e-07}, {"id": 897, "seek": 364440, "start": 3650.84, "end": 3652.32, "text": " it really easy to do that.", "tokens": [309, 534, 1858, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.20222328804634712, "compression_ratio": 1.688976377952756, "no_speech_prob": 5.122838047100231e-07}, {"id": 898, "seek": 364440, "start": 3652.32, "end": 3660.04, "text": " And when I, when I'm writing TypeScript personally, I honestly don't do that much of things like", "tokens": [400, 562, 286, 11, 562, 286, 478, 3579, 15576, 14237, 5665, 11, 286, 6095, 500, 380, 360, 300, 709, 295, 721, 411], "temperature": 0.0, "avg_logprob": -0.20222328804634712, "compression_ratio": 1.688976377952756, "no_speech_prob": 5.122838047100231e-07}, {"id": 899, "seek": 364440, "start": 3660.04, "end": 3663.56, "text": " parse don't validate and make impossible states impossible.", "tokens": [48377, 500, 380, 29562, 293, 652, 6243, 4368, 6243, 13], "temperature": 0.0, "avg_logprob": -0.20222328804634712, "compression_ratio": 1.688976377952756, "no_speech_prob": 5.122838047100231e-07}, {"id": 900, "seek": 364440, "start": 3663.56, "end": 3667.4, "text": " It's just cumbersome and I don't really get the full guarantee.", "tokens": [467, 311, 445, 12713, 1616, 423, 293, 286, 500, 380, 534, 483, 264, 1577, 10815, 13], "temperature": 0.0, "avg_logprob": -0.20222328804634712, "compression_ratio": 1.688976377952756, "no_speech_prob": 5.122838047100231e-07}, {"id": 901, "seek": 364440, "start": 3667.4, "end": 3674.2400000000002, "text": " So it feels like, why am I bending over backwards to make discriminated unions that like, I", "tokens": [407, 309, 3417, 411, 11, 983, 669, 286, 22487, 670, 12204, 281, 652, 20828, 770, 24914, 300, 411, 11, 286], "temperature": 0.0, "avg_logprob": -0.20222328804634712, "compression_ratio": 1.688976377952756, "no_speech_prob": 5.122838047100231e-07}, {"id": 902, "seek": 367424, "start": 3674.24, "end": 3676.3599999999997, "text": " can't really trust.", "tokens": [393, 380, 534, 3361, 13], "temperature": 0.0, "avg_logprob": -0.32200579021288, "compression_ratio": 1.5458937198067633, "no_speech_prob": 1.4144364968160517e-06}, {"id": 903, "seek": 367424, "start": 3676.3599999999997, "end": 3680.72, "text": " It feels like it's going against the grain of how the whole ecosystem is working that", "tokens": [467, 3417, 411, 309, 311, 516, 1970, 264, 12837, 295, 577, 264, 1379, 11311, 307, 1364, 300], "temperature": 0.0, "avg_logprob": -0.32200579021288, "compression_ratio": 1.5458937198067633, "no_speech_prob": 1.4144364968160517e-06}, {"id": 904, "seek": 367424, "start": 3680.72, "end": 3681.72, "text": " I'm using.", "tokens": [286, 478, 1228, 13], "temperature": 0.0, "avg_logprob": -0.32200579021288, "compression_ratio": 1.5458937198067633, "no_speech_prob": 1.4144364968160517e-06}, {"id": 905, "seek": 367424, "start": 3681.72, "end": 3682.72, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.32200579021288, "compression_ratio": 1.5458937198067633, "no_speech_prob": 1.4144364968160517e-06}, {"id": 906, "seek": 367424, "start": 3682.72, "end": 3689.7599999999998, "text": " On top of that, it's also like, there's this distraction or there's this temptation, this", "tokens": [1282, 1192, 295, 300, 11, 309, 311, 611, 411, 11, 456, 311, 341, 30217, 420, 456, 311, 341, 30423, 11, 341], "temperature": 0.0, "avg_logprob": -0.32200579021288, "compression_ratio": 1.5458937198067633, "no_speech_prob": 1.4144364968160517e-06}, {"id": 907, "seek": 367424, "start": 3689.7599999999998, "end": 3696.52, "text": " little devil telling you like, Oh, Hey, this could be much simpler if you just mutate this", "tokens": [707, 13297, 3585, 291, 411, 11, 876, 11, 1911, 11, 341, 727, 312, 709, 18587, 498, 291, 445, 5839, 473, 341], "temperature": 0.0, "avg_logprob": -0.32200579021288, "compression_ratio": 1.5458937198067633, "no_speech_prob": 1.4144364968160517e-06}, {"id": 908, "seek": 367424, "start": 3696.52, "end": 3697.52, "text": " argument.", "tokens": [6770, 13], "temperature": 0.0, "avg_logprob": -0.32200579021288, "compression_ratio": 1.5458937198067633, "no_speech_prob": 1.4144364968160517e-06}, {"id": 909, "seek": 367424, "start": 3697.52, "end": 3698.52, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.32200579021288, "compression_ratio": 1.5458937198067633, "no_speech_prob": 1.4144364968160517e-06}, {"id": 910, "seek": 369852, "start": 3698.52, "end": 3707.28, "text": " Like, and potentially for good reason, because also like can be more performance.", "tokens": [1743, 11, 293, 7263, 337, 665, 1778, 11, 570, 611, 411, 393, 312, 544, 3389, 13], "temperature": 0.0, "avg_logprob": -0.3159179488817851, "compression_ratio": 1.5063829787234042, "no_speech_prob": 5.043316946284904e-07}, {"id": 911, "seek": 369852, "start": 3707.28, "end": 3708.28, "text": " Sure.", "tokens": [4894, 13], "temperature": 0.0, "avg_logprob": -0.3159179488817851, "compression_ratio": 1.5063829787234042, "no_speech_prob": 5.043316946284904e-07}, {"id": 912, "seek": 369852, "start": 3708.28, "end": 3714.48, "text": " But there's always this temptation to write code in a, not a nice way.", "tokens": [583, 456, 311, 1009, 341, 30423, 281, 2464, 3089, 294, 257, 11, 406, 257, 1481, 636, 13], "temperature": 0.0, "avg_logprob": -0.3159179488817851, "compression_ratio": 1.5063829787234042, "no_speech_prob": 5.043316946284904e-07}, {"id": 913, "seek": 369852, "start": 3714.48, "end": 3721.0, "text": " That is, I just find distracting and sometimes I get tempted in practice to do that.", "tokens": [663, 307, 11, 286, 445, 915, 36689, 293, 2171, 286, 483, 29941, 294, 3124, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.3159179488817851, "compression_ratio": 1.5063829787234042, "no_speech_prob": 5.043316946284904e-07}, {"id": 914, "seek": 369852, "start": 3721.0, "end": 3723.6, "text": " And that's how my code turns out.", "tokens": [400, 300, 311, 577, 452, 3089, 4523, 484, 13], "temperature": 0.0, "avg_logprob": -0.3159179488817851, "compression_ratio": 1.5063829787234042, "no_speech_prob": 5.043316946284904e-07}, {"id": 915, "seek": 369852, "start": 3723.6, "end": 3728.4, "text": " And that will, or the might create problems, but you don't have that in Elm.", "tokens": [400, 300, 486, 11, 420, 264, 1062, 1884, 2740, 11, 457, 291, 500, 380, 362, 300, 294, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.3159179488817851, "compression_ratio": 1.5063829787234042, "no_speech_prob": 5.043316946284904e-07}, {"id": 916, "seek": 372840, "start": 3728.4, "end": 3729.84, "text": " And that feels just nice.", "tokens": [400, 300, 3417, 445, 1481, 13], "temperature": 0.0, "avg_logprob": -0.2798423537288804, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.1907414975430584e-06}, {"id": 917, "seek": 372840, "start": 3729.84, "end": 3732.28, "text": " Like it's not an option.", "tokens": [1743, 309, 311, 406, 364, 3614, 13], "temperature": 0.0, "avg_logprob": -0.2798423537288804, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.1907414975430584e-06}, {"id": 918, "seek": 372840, "start": 3732.28, "end": 3734.32, "text": " Stop thinking about it.", "tokens": [5535, 1953, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.2798423537288804, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.1907414975430584e-06}, {"id": 919, "seek": 372840, "start": 3734.32, "end": 3737.2000000000003, "text": " Just write the good code from the start.", "tokens": [1449, 2464, 264, 665, 3089, 490, 264, 722, 13], "temperature": 0.0, "avg_logprob": -0.2798423537288804, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.1907414975430584e-06}, {"id": 920, "seek": 372840, "start": 3737.2000000000003, "end": 3743.56, "text": " And if it's not great, then you can refactor it because refactoring is safe.", "tokens": [400, 498, 309, 311, 406, 869, 11, 550, 291, 393, 1895, 15104, 309, 570, 1895, 578, 3662, 307, 3273, 13], "temperature": 0.0, "avg_logprob": -0.2798423537288804, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.1907414975430584e-06}, {"id": 921, "seek": 372840, "start": 3743.56, "end": 3744.56, "text": " Great.", "tokens": [3769, 13], "temperature": 0.0, "avg_logprob": -0.2798423537288804, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.1907414975430584e-06}, {"id": 922, "seek": 372840, "start": 3744.56, "end": 3746.36, "text": " It feels good.", "tokens": [467, 3417, 665, 13], "temperature": 0.0, "avg_logprob": -0.2798423537288804, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.1907414975430584e-06}, {"id": 923, "seek": 372840, "start": 3746.36, "end": 3748.36, "text": " Little angels everywhere.", "tokens": [8022, 18175, 5315, 13], "temperature": 0.0, "avg_logprob": -0.2798423537288804, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.1907414975430584e-06}, {"id": 924, "seek": 372840, "start": 3748.36, "end": 3749.36, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2798423537288804, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.1907414975430584e-06}, {"id": 925, "seek": 372840, "start": 3749.36, "end": 3750.36, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2798423537288804, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.1907414975430584e-06}, {"id": 926, "seek": 375036, "start": 3750.36, "end": 3758.6, "text": " And it just, it really does feel like Elm takes it a step further, you know, like something", "tokens": [400, 309, 445, 11, 309, 534, 775, 841, 411, 2699, 76, 2516, 309, 257, 1823, 3052, 11, 291, 458, 11, 411, 746], "temperature": 0.0, "avg_logprob": -0.23929390349945465, "compression_ratio": 1.5252525252525253, "no_speech_prob": 1.2677849099418381e-06}, {"id": 927, "seek": 375036, "start": 3758.6, "end": 3760.88, "text": " like Haskell or pure script.", "tokens": [411, 8646, 43723, 420, 6075, 5755, 13], "temperature": 0.0, "avg_logprob": -0.23929390349945465, "compression_ratio": 1.5252525252525253, "no_speech_prob": 1.2677849099418381e-06}, {"id": 928, "seek": 375036, "start": 3760.88, "end": 3767.04, "text": " Like I've never felt that drawn to, to some of these other languages, because again, there's", "tokens": [1743, 286, 600, 1128, 2762, 300, 10117, 281, 11, 281, 512, 295, 613, 661, 8650, 11, 570, 797, 11, 456, 311], "temperature": 0.0, "avg_logprob": -0.23929390349945465, "compression_ratio": 1.5252525252525253, "no_speech_prob": 1.2677849099418381e-06}, {"id": 929, "seek": 375036, "start": 3767.04, "end": 3774.1200000000003, "text": " just like Elm really makes this hard choice of like not having escape patches and having", "tokens": [445, 411, 2699, 76, 534, 1669, 341, 1152, 3922, 295, 411, 406, 1419, 7615, 26531, 293, 1419], "temperature": 0.0, "avg_logprob": -0.23929390349945465, "compression_ratio": 1.5252525252525253, "no_speech_prob": 1.2677849099418381e-06}, {"id": 930, "seek": 377412, "start": 3774.12, "end": 3781.56, "text": " pure functions and exhaustive case checks and all these things that are, it's just like", "tokens": [6075, 6828, 293, 14687, 488, 1389, 13834, 293, 439, 613, 721, 300, 366, 11, 309, 311, 445, 411], "temperature": 0.0, "avg_logprob": -0.217060008801912, "compression_ratio": 1.6050420168067228, "no_speech_prob": 1.0676671990950126e-06}, {"id": 931, "seek": 377412, "start": 3781.56, "end": 3783.44, "text": " airtight at the core.", "tokens": [1988, 41738, 412, 264, 4965, 13], "temperature": 0.0, "avg_logprob": -0.217060008801912, "compression_ratio": 1.6050420168067228, "no_speech_prob": 1.0676671990950126e-06}, {"id": 932, "seek": 377412, "start": 3783.44, "end": 3789.7999999999997, "text": " Like all of its core decisions are made around being airtight and then having pragmatic APIs", "tokens": [1743, 439, 295, 1080, 4965, 5327, 366, 1027, 926, 885, 1988, 41738, 293, 550, 1419, 46904, 21445], "temperature": 0.0, "avg_logprob": -0.217060008801912, "compression_ratio": 1.6050420168067228, "no_speech_prob": 1.0676671990950126e-06}, {"id": 933, "seek": 377412, "start": 3789.7999999999997, "end": 3798.18, "text": " that are focused, like making, you know, which maybe somebody who's really big into Haskell", "tokens": [300, 366, 5178, 11, 411, 1455, 11, 291, 458, 11, 597, 1310, 2618, 567, 311, 534, 955, 666, 8646, 43723], "temperature": 0.0, "avg_logprob": -0.217060008801912, "compression_ratio": 1.6050420168067228, "no_speech_prob": 1.0676671990950126e-06}, {"id": 934, "seek": 377412, "start": 3798.18, "end": 3803.12, "text": " would say, well, yeah, but you're missing out on the power of a lot of things that type", "tokens": [576, 584, 11, 731, 11, 1338, 11, 457, 291, 434, 5361, 484, 322, 264, 1347, 295, 257, 688, 295, 721, 300, 2010], "temperature": 0.0, "avg_logprob": -0.217060008801912, "compression_ratio": 1.6050420168067228, "no_speech_prob": 1.0676671990950126e-06}, {"id": 935, "seek": 380312, "start": 3803.12, "end": 3804.48, "text": " systems can provide to you.", "tokens": [3652, 393, 2893, 281, 291, 13], "temperature": 0.0, "avg_logprob": -0.22896730523360403, "compression_ratio": 1.6578947368421053, "no_speech_prob": 2.2252622784435516e-06}, {"id": 936, "seek": 380312, "start": 3804.48, "end": 3810.04, "text": " And you're missing out on some of the ease that you have from things like type classes", "tokens": [400, 291, 434, 5361, 484, 322, 512, 295, 264, 12708, 300, 291, 362, 490, 721, 411, 2010, 5359], "temperature": 0.0, "avg_logprob": -0.22896730523360403, "compression_ratio": 1.6578947368421053, "no_speech_prob": 2.2252622784435516e-06}, {"id": 937, "seek": 380312, "start": 3810.04, "end": 3811.04, "text": " and stuff.", "tokens": [293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.22896730523360403, "compression_ratio": 1.6578947368421053, "no_speech_prob": 2.2252622784435516e-06}, {"id": 938, "seek": 380312, "start": 3811.04, "end": 3813.7599999999998, "text": " And there, there are definitely trade-offs there.", "tokens": [400, 456, 11, 456, 366, 2138, 4923, 12, 19231, 456, 13], "temperature": 0.0, "avg_logprob": -0.22896730523360403, "compression_ratio": 1.6578947368421053, "no_speech_prob": 2.2252622784435516e-06}, {"id": 939, "seek": 380312, "start": 3813.7599999999998, "end": 3816.6, "text": " There are definitely valuable things that come from that.", "tokens": [821, 366, 2138, 8263, 721, 300, 808, 490, 300, 13], "temperature": 0.0, "avg_logprob": -0.22896730523360403, "compression_ratio": 1.6578947368421053, "no_speech_prob": 2.2252622784435516e-06}, {"id": 940, "seek": 380312, "start": 3816.6, "end": 3823.3599999999997, "text": " But Elm, it goes all in on saying no escape patches.", "tokens": [583, 2699, 76, 11, 309, 1709, 439, 294, 322, 1566, 572, 7615, 26531, 13], "temperature": 0.0, "avg_logprob": -0.22896730523360403, "compression_ratio": 1.6578947368421053, "no_speech_prob": 2.2252622784435516e-06}, {"id": 941, "seek": 380312, "start": 3823.3599999999997, "end": 3829.16, "text": " It's an airtight system that you can completely trace and understand pure functions all the", "tokens": [467, 311, 364, 1988, 41738, 1185, 300, 291, 393, 2584, 13508, 293, 1223, 6075, 6828, 439, 264], "temperature": 0.0, "avg_logprob": -0.22896730523360403, "compression_ratio": 1.6578947368421053, "no_speech_prob": 2.2252622784435516e-06}, {"id": 942, "seek": 382916, "start": 3829.16, "end": 3837.2, "text": " way, and let's be pragmatic and talk about things in more domain terms than category", "tokens": [636, 11, 293, 718, 311, 312, 46904, 293, 751, 466, 721, 294, 544, 9274, 2115, 813, 7719], "temperature": 0.0, "avg_logprob": -0.2548579547716224, "compression_ratio": 1.6785714285714286, "no_speech_prob": 2.3687223347224062e-06}, {"id": 943, "seek": 382916, "start": 3837.2, "end": 3839.92, "text": " theory terms or things like that.", "tokens": [5261, 2115, 420, 721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.2548579547716224, "compression_ratio": 1.6785714285714286, "no_speech_prob": 2.3687223347224062e-06}, {"id": 944, "seek": 382916, "start": 3839.92, "end": 3845.3999999999996, "text": " And to me, that just really resonates like that, that that's my love language, just like", "tokens": [400, 281, 385, 11, 300, 445, 534, 41051, 411, 300, 11, 300, 300, 311, 452, 959, 2856, 11, 445, 411], "temperature": 0.0, "avg_logprob": -0.2548579547716224, "compression_ratio": 1.6785714285714286, "no_speech_prob": 2.3687223347224062e-06}, {"id": 945, "seek": 382916, "start": 3845.3999999999996, "end": 3851.8399999999997, "text": " speaking in domain language and simple, understandable, traceable code that you know exactly what", "tokens": [4124, 294, 9274, 2856, 293, 2199, 11, 25648, 11, 13508, 712, 3089, 300, 291, 458, 2293, 437], "temperature": 0.0, "avg_logprob": -0.2548579547716224, "compression_ratio": 1.6785714285714286, "no_speech_prob": 2.3687223347224062e-06}, {"id": 946, "seek": 382916, "start": 3851.8399999999997, "end": 3853.52, "text": " it does and its pure functions.", "tokens": [309, 775, 293, 1080, 6075, 6828, 13], "temperature": 0.0, "avg_logprob": -0.2548579547716224, "compression_ratio": 1.6785714285714286, "no_speech_prob": 2.3687223347224062e-06}, {"id": 947, "seek": 382916, "start": 3853.52, "end": 3856.08, "text": " Like it just works for me at the core.", "tokens": [1743, 309, 445, 1985, 337, 385, 412, 264, 4965, 13], "temperature": 0.0, "avg_logprob": -0.2548579547716224, "compression_ratio": 1.6785714285714286, "no_speech_prob": 2.3687223347224062e-06}, {"id": 948, "seek": 385608, "start": 3856.08, "end": 3859.7999999999997, "text": " And Elm does that in a way that I think is very unique.", "tokens": [400, 2699, 76, 775, 300, 294, 257, 636, 300, 286, 519, 307, 588, 3845, 13], "temperature": 0.0, "avg_logprob": -0.2438738716973199, "compression_ratio": 1.545045045045045, "no_speech_prob": 5.093278105050558e-06}, {"id": 949, "seek": 385608, "start": 3859.7999999999997, "end": 3866.96, "text": " And I think I definitely am keen to see what Richard Feldman's project Rock does.", "tokens": [400, 286, 519, 286, 2138, 669, 20297, 281, 536, 437, 9809, 42677, 1601, 311, 1716, 6922, 775, 13], "temperature": 0.0, "avg_logprob": -0.2438738716973199, "compression_ratio": 1.545045045045045, "no_speech_prob": 5.093278105050558e-06}, {"id": 950, "seek": 385608, "start": 3866.96, "end": 3874.16, "text": " I think that like he is kind of bringing a similar ethos to a different context and more,", "tokens": [286, 519, 300, 411, 415, 307, 733, 295, 5062, 257, 2531, 6468, 329, 281, 257, 819, 4319, 293, 544, 11], "temperature": 0.0, "avg_logprob": -0.2438738716973199, "compression_ratio": 1.545045045045045, "no_speech_prob": 5.093278105050558e-06}, {"id": 951, "seek": 385608, "start": 3874.16, "end": 3879.2599999999998, "text": " you know, more of a sort of the types of things you would do with Rust back end, more performance", "tokens": [291, 458, 11, 544, 295, 257, 1333, 295, 264, 3467, 295, 721, 291, 576, 360, 365, 34952, 646, 917, 11, 544, 3389], "temperature": 0.0, "avg_logprob": -0.2438738716973199, "compression_ratio": 1.545045045045045, "no_speech_prob": 5.093278105050558e-06}, {"id": 952, "seek": 385608, "start": 3879.2599999999998, "end": 3881.58, "text": " focused projects.", "tokens": [5178, 4455, 13], "temperature": 0.0, "avg_logprob": -0.2438738716973199, "compression_ratio": 1.545045045045045, "no_speech_prob": 5.093278105050558e-06}, {"id": 953, "seek": 388158, "start": 3881.58, "end": 3886.72, "text": " But I think he's bringing a similar ethos there that I'm very keen to see what he does", "tokens": [583, 286, 519, 415, 311, 5062, 257, 2531, 6468, 329, 456, 300, 286, 478, 588, 20297, 281, 536, 437, 415, 775], "temperature": 0.0, "avg_logprob": -0.2857870591425263, "compression_ratio": 1.6025641025641026, "no_speech_prob": 7.071241270750761e-06}, {"id": 954, "seek": 388158, "start": 3886.72, "end": 3887.72, "text": " with.", "tokens": [365, 13], "temperature": 0.0, "avg_logprob": -0.2857870591425263, "compression_ratio": 1.6025641025641026, "no_speech_prob": 7.071241270750761e-06}, {"id": 955, "seek": 388158, "start": 3887.72, "end": 3890.48, "text": " I think that will pull up my heartstrings as well.", "tokens": [286, 519, 300, 486, 2235, 493, 452, 1917, 50035, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.2857870591425263, "compression_ratio": 1.6025641025641026, "no_speech_prob": 7.071241270750761e-06}, {"id": 956, "seek": 388158, "start": 3890.48, "end": 3893.48, "text": " Yeah, I'm looking forward to playing with it more as well.", "tokens": [865, 11, 286, 478, 1237, 2128, 281, 2433, 365, 309, 544, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.2857870591425263, "compression_ratio": 1.6025641025641026, "no_speech_prob": 7.071241270750761e-06}, {"id": 957, "seek": 388158, "start": 3893.48, "end": 3900.36, "text": " And I really hope they don't make any choices that go counter to what we like about Elm,", "tokens": [400, 286, 534, 1454, 436, 500, 380, 652, 604, 7994, 300, 352, 5682, 281, 437, 321, 411, 466, 2699, 76, 11], "temperature": 0.0, "avg_logprob": -0.2857870591425263, "compression_ratio": 1.6025641025641026, "no_speech_prob": 7.071241270750761e-06}, {"id": 958, "seek": 388158, "start": 3900.36, "end": 3902.2799999999997, "text": " the large parts.", "tokens": [264, 2416, 3166, 13], "temperature": 0.0, "avg_logprob": -0.2857870591425263, "compression_ratio": 1.6025641025641026, "no_speech_prob": 7.071241270750761e-06}, {"id": 959, "seek": 388158, "start": 3902.2799999999997, "end": 3905.7599999999998, "text": " From everything I've seen so far, it has.", "tokens": [3358, 1203, 286, 600, 1612, 370, 1400, 11, 309, 575, 13], "temperature": 0.0, "avg_logprob": -0.2857870591425263, "compression_ratio": 1.6025641025641026, "no_speech_prob": 7.071241270750761e-06}, {"id": 960, "seek": 388158, "start": 3905.7599999999998, "end": 3906.7599999999998, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2857870591425263, "compression_ratio": 1.6025641025641026, "no_speech_prob": 7.071241270750761e-06}, {"id": 961, "seek": 388158, "start": 3906.7599999999998, "end": 3907.7599999999998, "text": " But yeah, I agree.", "tokens": [583, 1338, 11, 286, 3986, 13], "temperature": 0.0, "avg_logprob": -0.2857870591425263, "compression_ratio": 1.6025641025641026, "no_speech_prob": 7.071241270750761e-06}, {"id": 962, "seek": 390776, "start": 3907.76, "end": 3913.2000000000003, "text": " Yeah, we kind of mentioned like it's about pushing Elm to its limits.", "tokens": [865, 11, 321, 733, 295, 2835, 411, 309, 311, 466, 7380, 2699, 76, 281, 1080, 10406, 13], "temperature": 0.0, "avg_logprob": -0.30131434486025854, "compression_ratio": 1.5230125523012552, "no_speech_prob": 2.0903310087305726e-06}, {"id": 963, "seek": 390776, "start": 3913.2000000000003, "end": 3919.1600000000003, "text": " But as a tooling author, it's also just simply intellectually fun to see how far you can", "tokens": [583, 382, 257, 46593, 3793, 11, 309, 311, 611, 445, 2935, 46481, 1019, 281, 536, 577, 1400, 291, 393], "temperature": 0.0, "avg_logprob": -0.30131434486025854, "compression_ratio": 1.5230125523012552, "no_speech_prob": 2.0903310087305726e-06}, {"id": 964, "seek": 390776, "start": 3919.1600000000003, "end": 3920.1600000000003, "text": " push it.", "tokens": [2944, 309, 13], "temperature": 0.0, "avg_logprob": -0.30131434486025854, "compression_ratio": 1.5230125523012552, "no_speech_prob": 2.0903310087305726e-06}, {"id": 965, "seek": 390776, "start": 3920.1600000000003, "end": 3925.1600000000003, "text": " For instance, I had a lot of fun making pull requests to Elm Optimize Level 2.", "tokens": [1171, 5197, 11, 286, 632, 257, 688, 295, 1019, 1455, 2235, 12475, 281, 2699, 76, 35013, 1125, 16872, 568, 13], "temperature": 0.0, "avg_logprob": -0.30131434486025854, "compression_ratio": 1.5230125523012552, "no_speech_prob": 2.0903310087305726e-06}, {"id": 966, "seek": 390776, "start": 3925.1600000000003, "end": 3934.0, "text": " Yeah, to make things even faster, but relying on the fact that it's Elm codes that I'm optimizing.", "tokens": [865, 11, 281, 652, 721, 754, 4663, 11, 457, 24140, 322, 264, 1186, 300, 309, 311, 2699, 76, 14211, 300, 286, 478, 40425, 13], "temperature": 0.0, "avg_logprob": -0.30131434486025854, "compression_ratio": 1.5230125523012552, "no_speech_prob": 2.0903310087305726e-06}, {"id": 967, "seek": 390776, "start": 3934.0, "end": 3935.5200000000004, "text": " Right, right.", "tokens": [1779, 11, 558, 13], "temperature": 0.0, "avg_logprob": -0.30131434486025854, "compression_ratio": 1.5230125523012552, "no_speech_prob": 2.0903310087305726e-06}, {"id": 968, "seek": 390776, "start": 3935.5200000000004, "end": 3936.5200000000004, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.30131434486025854, "compression_ratio": 1.5230125523012552, "no_speech_prob": 2.0903310087305726e-06}, {"id": 969, "seek": 393652, "start": 3936.52, "end": 3941.72, "text": " You can do isomorphic things with Elm code because if it can give you the same result", "tokens": [509, 393, 360, 307, 32702, 299, 721, 365, 2699, 76, 3089, 570, 498, 309, 393, 976, 291, 264, 912, 1874], "temperature": 0.0, "avg_logprob": -0.40046136719839914, "compression_ratio": 1.6470588235294117, "no_speech_prob": 5.954843345534755e-06}, {"id": 970, "seek": 393652, "start": 3941.72, "end": 3946.32, "text": " and it's pure, so it's so easy to swap it out for something else that does the same", "tokens": [293, 309, 311, 6075, 11, 370, 309, 311, 370, 1858, 281, 18135, 309, 484, 337, 746, 1646, 300, 775, 264, 912], "temperature": 0.0, "avg_logprob": -0.40046136719839914, "compression_ratio": 1.6470588235294117, "no_speech_prob": 5.954843345534755e-06}, {"id": 971, "seek": 393652, "start": 3946.32, "end": 3949.08, "text": " thing, then you can do whatever dirty tricks you want.", "tokens": [551, 11, 550, 291, 393, 360, 2035, 9360, 11733, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.40046136719839914, "compression_ratio": 1.6470588235294117, "no_speech_prob": 5.954843345534755e-06}, {"id": 972, "seek": 393652, "start": 3949.08, "end": 3950.72, "text": " Yeah, yeah, exactly.", "tokens": [865, 11, 1338, 11, 2293, 13], "temperature": 0.0, "avg_logprob": -0.40046136719839914, "compression_ratio": 1.6470588235294117, "no_speech_prob": 5.954843345534755e-06}, {"id": 973, "seek": 393652, "start": 3950.72, "end": 3956.32, "text": " Yeah, also like Tail Recursion module concept I worked on that I made blog posts about,", "tokens": [865, 11, 611, 411, 46074, 9647, 2156, 313, 10088, 3410, 286, 2732, 322, 300, 286, 1027, 6968, 12300, 466, 11], "temperature": 0.0, "avg_logprob": -0.40046136719839914, "compression_ratio": 1.6470588235294117, "no_speech_prob": 5.954843345534755e-06}, {"id": 974, "seek": 393652, "start": 3956.32, "end": 3965.12, "text": " because it's still Elm, but now the compiler can change the resulting source code, the", "tokens": [570, 309, 311, 920, 2699, 76, 11, 457, 586, 264, 31958, 393, 1319, 264, 16505, 4009, 3089, 11, 264], "temperature": 0.0, "avg_logprob": -0.40046136719839914, "compression_ratio": 1.6470588235294117, "no_speech_prob": 5.954843345534755e-06}, {"id": 975, "seek": 396512, "start": 3965.12, "end": 3968.88, "text": " resulting JavaScript in a way that is more optimized.", "tokens": [16505, 15778, 294, 257, 636, 300, 307, 544, 26941, 13], "temperature": 0.0, "avg_logprob": -0.3356484088701071, "compression_ratio": 1.5727272727272728, "no_speech_prob": 1.6536756675122888e-06}, {"id": 976, "seek": 396512, "start": 3968.88, "end": 3974.16, "text": " And that would unlock some ways of running Elm code that are currently like not stack", "tokens": [400, 300, 576, 11634, 512, 2098, 295, 2614, 2699, 76, 3089, 300, 366, 4362, 411, 406, 8630], "temperature": 0.0, "avg_logprob": -0.3356484088701071, "compression_ratio": 1.5727272727272728, "no_speech_prob": 1.6536756675122888e-06}, {"id": 977, "seek": 396512, "start": 3974.16, "end": 3975.68, "text": " safe or something.", "tokens": [3273, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.3356484088701071, "compression_ratio": 1.5727272727272728, "no_speech_prob": 1.6536756675122888e-06}, {"id": 978, "seek": 396512, "start": 3975.68, "end": 3976.68, "text": " That would be amazing.", "tokens": [663, 576, 312, 2243, 13], "temperature": 0.0, "avg_logprob": -0.3356484088701071, "compression_ratio": 1.5727272727272728, "no_speech_prob": 1.6536756675122888e-06}, {"id": 979, "seek": 396512, "start": 3976.68, "end": 3981.7999999999997, "text": " Is that a feature for the language or is it just like optimization?", "tokens": [1119, 300, 257, 4111, 337, 264, 2856, 420, 307, 309, 445, 411, 19618, 30], "temperature": 0.0, "avg_logprob": -0.3356484088701071, "compression_ratio": 1.5727272727272728, "no_speech_prob": 1.6536756675122888e-06}, {"id": 980, "seek": 396512, "start": 3981.7999999999997, "end": 3982.7999999999997, "text": " That's a good question.", "tokens": [663, 311, 257, 665, 1168, 13], "temperature": 0.0, "avg_logprob": -0.3356484088701071, "compression_ratio": 1.5727272727272728, "no_speech_prob": 1.6536756675122888e-06}, {"id": 981, "seek": 396512, "start": 3982.7999999999997, "end": 3985.7999999999997, "text": " Stack safety is a feature.", "tokens": [37649, 4514, 307, 257, 4111, 13], "temperature": 0.0, "avg_logprob": -0.3356484088701071, "compression_ratio": 1.5727272727272728, "no_speech_prob": 1.6536756675122888e-06}, {"id": 982, "seek": 396512, "start": 3985.7999999999997, "end": 3988.12, "text": " Yeah, it's borderline.", "tokens": [865, 11, 309, 311, 7838, 1889, 13], "temperature": 0.0, "avg_logprob": -0.3356484088701071, "compression_ratio": 1.5727272727272728, "no_speech_prob": 1.6536756675122888e-06}, {"id": 983, "seek": 396512, "start": 3988.12, "end": 3991.0, "text": " It's still Elm, but...", "tokens": [467, 311, 920, 2699, 76, 11, 457, 485], "temperature": 0.0, "avg_logprob": -0.3356484088701071, "compression_ratio": 1.5727272727272728, "no_speech_prob": 1.6536756675122888e-06}, {"id": 984, "seek": 399100, "start": 3991.0, "end": 3996.72, "text": " I mean, put it this way, if Elm didn't have tail call optimization, then certain use cases", "tokens": [286, 914, 11, 829, 309, 341, 636, 11, 498, 2699, 76, 994, 380, 362, 6838, 818, 19618, 11, 550, 1629, 764, 3331], "temperature": 0.0, "avg_logprob": -0.2464150928315662, "compression_ratio": 1.579150579150579, "no_speech_prob": 1.1365453929101932e-06}, {"id": 985, "seek": 399100, "start": 3996.72, "end": 3998.4, "text": " wouldn't be possible.", "tokens": [2759, 380, 312, 1944, 13], "temperature": 0.0, "avg_logprob": -0.2464150928315662, "compression_ratio": 1.579150579150579, "no_speech_prob": 1.1365453929101932e-06}, {"id": 986, "seek": 399100, "start": 3998.4, "end": 4001.68, "text": " And being able to make a guarantee about that is definitely compelling.", "tokens": [400, 885, 1075, 281, 652, 257, 10815, 466, 300, 307, 2138, 20050, 13], "temperature": 0.0, "avg_logprob": -0.2464150928315662, "compression_ratio": 1.579150579150579, "no_speech_prob": 1.1365453929101932e-06}, {"id": 987, "seek": 399100, "start": 4001.68, "end": 4011.12, "text": " So yeah, I think in conclusion, like Elm is just such a nice bundle of features that are", "tokens": [407, 1338, 11, 286, 519, 294, 10063, 11, 411, 2699, 76, 307, 445, 1270, 257, 1481, 24438, 295, 4122, 300, 366], "temperature": 0.0, "avg_logprob": -0.2464150928315662, "compression_ratio": 1.579150579150579, "no_speech_prob": 1.1365453929101932e-06}, {"id": 988, "seek": 399100, "start": 4011.12, "end": 4015.16, "text": " put together in a very nice and polished way.", "tokens": [829, 1214, 294, 257, 588, 1481, 293, 29079, 636, 13], "temperature": 0.0, "avg_logprob": -0.2464150928315662, "compression_ratio": 1.579150579150579, "no_speech_prob": 1.1365453929101932e-06}, {"id": 989, "seek": 399100, "start": 4015.16, "end": 4020.68, "text": " The fact that it doesn't crash, the fact that its language is super simple and teachable,", "tokens": [440, 1186, 300, 309, 1177, 380, 8252, 11, 264, 1186, 300, 1080, 2856, 307, 1687, 2199, 293, 2924, 712, 11], "temperature": 0.0, "avg_logprob": -0.2464150928315662, "compression_ratio": 1.579150579150579, "no_speech_prob": 1.1365453929101932e-06}, {"id": 990, "seek": 402068, "start": 4020.68, "end": 4026.12, "text": " compared to Haskell for instance, the fact that the resulting code is good code and maintainable", "tokens": [5347, 281, 8646, 43723, 337, 5197, 11, 264, 1186, 300, 264, 16505, 3089, 307, 665, 3089, 293, 6909, 712], "temperature": 0.0, "avg_logprob": -0.25776636123657226, "compression_ratio": 1.7467248908296944, "no_speech_prob": 2.9479683689714875e-06}, {"id": 991, "seek": 402068, "start": 4026.12, "end": 4032.96, "text": " code and that you can have tools around it that are just so powerful that just make so", "tokens": [3089, 293, 300, 291, 393, 362, 3873, 926, 309, 300, 366, 445, 370, 4005, 300, 445, 652, 370], "temperature": 0.0, "avg_logprob": -0.25776636123657226, "compression_ratio": 1.7467248908296944, "no_speech_prob": 2.9479683689714875e-06}, {"id": 992, "seek": 402068, "start": 4032.96, "end": 4039.0, "text": " much good use of all the guarantees that the language gives you and the compiler gives", "tokens": [709, 665, 764, 295, 439, 264, 32567, 300, 264, 2856, 2709, 291, 293, 264, 31958, 2709], "temperature": 0.0, "avg_logprob": -0.25776636123657226, "compression_ratio": 1.7467248908296944, "no_speech_prob": 2.9479683689714875e-06}, {"id": 993, "seek": 402068, "start": 4039.0, "end": 4040.0, "text": " you.", "tokens": [291, 13], "temperature": 0.0, "avg_logprob": -0.25776636123657226, "compression_ratio": 1.7467248908296944, "no_speech_prob": 2.9479683689714875e-06}, {"id": 994, "seek": 402068, "start": 4040.0, "end": 4047.3999999999996, "text": " And I'm sure I'm forgetting more things, but it's just such a dense, small, little language", "tokens": [400, 286, 478, 988, 286, 478, 25428, 544, 721, 11, 457, 309, 311, 445, 1270, 257, 18011, 11, 1359, 11, 707, 2856], "temperature": 0.0, "avg_logprob": -0.25776636123657226, "compression_ratio": 1.7467248908296944, "no_speech_prob": 2.9479683689714875e-06}, {"id": 995, "seek": 402068, "start": 4047.3999999999996, "end": 4050.6, "text": " that is with so much good in it.", "tokens": [300, 307, 365, 370, 709, 665, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.25776636123657226, "compression_ratio": 1.7467248908296944, "no_speech_prob": 2.9479683689714875e-06}, {"id": 996, "seek": 405060, "start": 4050.6, "end": 4052.08, "text": " It's just super enjoyable.", "tokens": [467, 311, 445, 1687, 20305, 13], "temperature": 0.0, "avg_logprob": -0.27690425285926235, "compression_ratio": 1.6270491803278688, "no_speech_prob": 1.0952570846711751e-05}, {"id": 997, "seek": 405060, "start": 4052.08, "end": 4057.64, "text": " And a community of inspiring people who believe in that stuff too, which is really cool, you", "tokens": [400, 257, 1768, 295, 15883, 561, 567, 1697, 294, 300, 1507, 886, 11, 597, 307, 534, 1627, 11, 291], "temperature": 0.0, "avg_logprob": -0.27690425285926235, "compression_ratio": 1.6270491803278688, "no_speech_prob": 1.0952570846711751e-05}, {"id": 998, "seek": 405060, "start": 4057.64, "end": 4062.44, "text": " know, and who pull up their sleeves and try to build cool things with it.", "tokens": [458, 11, 293, 567, 2235, 493, 641, 24555, 293, 853, 281, 1322, 1627, 721, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.27690425285926235, "compression_ratio": 1.6270491803278688, "no_speech_prob": 1.0952570846711751e-05}, {"id": 999, "seek": 405060, "start": 4062.44, "end": 4069.44, "text": " Yeah, I really like the ethos of the community, like everyone trying to make good stuff.", "tokens": [865, 11, 286, 534, 411, 264, 6468, 329, 295, 264, 1768, 11, 411, 1518, 1382, 281, 652, 665, 1507, 13], "temperature": 0.0, "avg_logprob": -0.27690425285926235, "compression_ratio": 1.6270491803278688, "no_speech_prob": 1.0952570846711751e-05}, {"id": 1000, "seek": 405060, "start": 4069.44, "end": 4075.0, "text": " Yeah, and just the quality of the average Elm package is pretty impressive.", "tokens": [865, 11, 293, 445, 264, 3125, 295, 264, 4274, 2699, 76, 7372, 307, 1238, 8992, 13], "temperature": 0.0, "avg_logprob": -0.27690425285926235, "compression_ratio": 1.6270491803278688, "no_speech_prob": 1.0952570846711751e-05}, {"id": 1001, "seek": 405060, "start": 4075.0, "end": 4077.96, "text": " Yeah, so that's why we care about Elm.", "tokens": [865, 11, 370, 300, 311, 983, 321, 1127, 466, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.27690425285926235, "compression_ratio": 1.6270491803278688, "no_speech_prob": 1.0952570846711751e-05}, {"id": 1002, "seek": 407796, "start": 4077.96, "end": 4082.76, "text": " Well, this was a fun trip down memory lane.", "tokens": [1042, 11, 341, 390, 257, 1019, 4931, 760, 4675, 12705, 13], "temperature": 0.0, "avg_logprob": -0.38277636076274674, "compression_ratio": 1.4689265536723164, "no_speech_prob": 7.40844461688539e-06}, {"id": 1003, "seek": 407796, "start": 4082.76, "end": 4089.4, "text": " And perhaps you're a superhero trying to build cool static analysis and I'm a super villain", "tokens": [400, 4317, 291, 434, 257, 19428, 1382, 281, 1322, 1627, 13437, 5215, 293, 286, 478, 257, 1687, 17906], "temperature": 0.0, "avg_logprob": -0.38277636076274674, "compression_ratio": 1.4689265536723164, "no_speech_prob": 7.40844461688539e-06}, {"id": 1004, "seek": 407796, "start": 4089.4, "end": 4095.0, "text": " trying to destroy all mocking in the universe.", "tokens": [1382, 281, 5293, 439, 49792, 294, 264, 6445, 13], "temperature": 0.0, "avg_logprob": -0.38277636076274674, "compression_ratio": 1.4689265536723164, "no_speech_prob": 7.40844461688539e-06}, {"id": 1005, "seek": 407796, "start": 4095.0, "end": 4097.88, "text": " Mock man!", "tokens": [376, 1560, 587, 0], "temperature": 0.0, "avg_logprob": -0.38277636076274674, "compression_ratio": 1.4689265536723164, "no_speech_prob": 7.40844461688539e-06}, {"id": 1006, "seek": 407796, "start": 4097.88, "end": 4102.24, "text": " I'm one step closer.", "tokens": [286, 478, 472, 1823, 4966, 13], "temperature": 0.0, "avg_logprob": -0.38277636076274674, "compression_ratio": 1.4689265536723164, "no_speech_prob": 7.40844461688539e-06}, {"id": 1007, "seek": 407796, "start": 4102.24, "end": 4105.12, "text": " Well Jeroen, until next time.", "tokens": [1042, 508, 2032, 268, 11, 1826, 958, 565, 13], "temperature": 0.0, "avg_logprob": -0.38277636076274674, "compression_ratio": 1.4689265536723164, "no_speech_prob": 7.40844461688539e-06}, {"id": 1008, "seek": 410512, "start": 4105.12, "end": 4113.0, "text": " Until next time.", "tokens": [50364, 9088, 958, 565, 13, 50758], "temperature": 0.0, "avg_logprob": -0.5133623395647321, "compression_ratio": 0.6666666666666666, "no_speech_prob": 5.503799911821261e-05}], "language": "en"}