{"text": " Hello, Jeroen. Hello, Dillon. Today we've invited a special guest. You might have to help me with the pronunciation there. Yeah, I wish I could help you, but I'm not the one that speaks French in this room. Oh, there's our special guest, Lindsay Wardell. Lindsay, thanks for joining us. Yeah, thanks for inviting me. What are we talking about today, Lindsay? Vite, which is the front-end development tool created by Evan Yu, who is the creator of Vue.js. I wish we had a French speaker on this podcast to help us on how to pronounce that. It would be helpful. Yeah, I'm still surprised by the pun, because I thought, oh, he's going to make some joke about, oh, we need to hurry up and record this or something, like, Vite, Vite. That would have worked, but no. That would have been too clever. In Vite. Going for the lowbrow here. So what is the proper pronunciation? Yeah, well, Lindsay, before we started recording, you said that you were discussing how to pronounce Vite. Yeah, so in a former time, I was a podcaster on the show Vue.js on Vue. And when the Vite framework was originally announced and released, we were talking about it, and none of us could figure out how it was supposed to be pronounced. I think at the time we were saying Vite, because we just couldn't figure it out, but we kept going back and forth. Vite, Vite, should you drop a vowel, should you drop a consonant? None of us actually know French, and the only French word we know is Vue, which I assume we're also pronouncing wrong. Yes. So we just kind of gave up, and the Vite documentation says Vite at this point, and that's how Evan Yu pronounces it. But I just assume that we're all wrong. Well, for Vite, it's not too bad. So the proper pronunciation is Vite. So it's pretty much the same, but the E is shorter, Vite. And Vue is Vu. So that's pretty wrong, I'd say. That's pretty wrong, yeah. I wonder if it's just payback, because Evan Yu is a native Chinese speaker, right? And he's like, all right, you're making me write all this code in English. Now I'm going to make all you English speakers try to poorly pronounce French words. I always assumed it was kind of like to make it sound like his name, Evan Yu, Vue. Yeah, that's cool. I think the original inspiration was he was just trying to find words that described a Vue layer, and he ended up on that one, and it was available on NPM. So at this point, the entire Vue ecosystem is just named after French stuff. That's clever. And it's three letters. Three letters are good for file extensions. Oh, definitely. Yeah. I think you can say Vue. I just say Vue. I think if you're in the know, you can say Vue, but if you use React or Svelte or something, you need to say Vue.js just to be specific. You mean if you're in the React.js ecosystem? Yes. But don't say AngularJS, because that's another thing. Yeah, that's a problem. Thinking about it, and this is off topic from Vite, but Vue did work on AngularJS, and that's part of where the inspiration for Vue came from. So maybe that's part of why Vue is originally Vue.js, and it's since shifted. I don't know. Wait, it's not Vue.js anymore? I mean, if you go to the docs, let me pull it up right now. Vue.js, the pervasive JavaScript framework and guide. Yeah, it just says what is Vue. Okay. Don't mind if you pronounce it Vite, I think it's close enough. I will forgive you if you do so. Thank you. So what is Vue? Sorry, what is Vite? We're not going to talk about Vue on this podcast more than we need to, because that's not what we're here to talk about. What is Vite? So Vite is front-end tooling is how they build it on their site. And I've actually had a hard time coming up with a one-sentence definition that fits into the normal boxes, because what it gives you is first a development environment. So as you're working in your code, it spins up the dev server, you're able to import your code, it does some processing as needed, especially if you're writing Elm code. And then when you go to build, it uses a build process, but it's a completely different build process than what it's using during development. So you could compare it to a bundler, but it's not quite a bundler. And you could compare it to other systems' development environments, but it's not just a development environment. It kind of fits into all of these different sections, kind of like the cracks, especially when you're working in JavaScript, but other languages as well. It fits into the cracks where things aren't as good and makes them much better. And that's why I'm having so much trouble figuring out what it's actually doing. Is it a bundler? Is it this other thing? Okay, it's in between. Gotcha. And actually Vite itself is not a custom bundler. It's using two different bundlers under the hood for doing its job. So during development, primarily it's using rollup for all of your code. If it needs to do any pre-processing, it'll use esbuild, unlike dependencies. But for any of the code that you write yourself, it's using rollup and compiling your code into ES modules so that it can just run natively in your browser without having to be bundled into a single JavaScript file. And then when you're ready to go to production, it will push everything through esbuild and create a single bundle at the end of the day. So Vite itself is not a custom bundler. It's just using other bundlers and putting it together in a unique way. And what are ES modules and esbuild? So esbuild is a tool written in Go for compiling JavaScript. I don't have the specific details in front of me, but I've been told it's very fast. It's one of the up and coming ones. I don't think it's reached a 1.0, but that's not something unfamiliar to us. Fair, fair. That's what esbuild is. It is specifically a bundler. And the other bundler that's used is rollup. Rollup, or I guess you could say rollup.js, was created by Rich Harris of Svelte. And it's going off in its own direction at this point. I don't think he's as involved as it used to be. But that's what's used during the development experience. I find it helpful to compare Vite to Webpack because if you just try to define it, it's kind of like, is it a dev server? Is it a bundler? What is it? But if you think about Webpack, I imagine many of our listeners have used Webpack. And you try to just set up Webpack. You configure Webpack, you write a bunch of config files, you install a bunch of plugins. And then if you're trying to bundle everything, you run the bundle command. And then what if you want to run a dev server? Then there's kind of like maybe another package or plugin you install that helps you get a dev server, but things kind of run differently. So when you compare Vite to that history, I feel like one of the main problems that Vite solves, in contrast to Webpack, is it gives you an environment where you can run a dev server or you can run a build, and it uses kind of the same setup. It will do more minification and things like that for the production build than it does in the dev server, but you can sort of use your same setup. And there's less configuration to write compared to Webpack. That sounds accurate to me. The thought that I have looking at it is in the Elm ecosystem, we talk about JavaScript fatigue a lot when we're talking about JavaScript. So if you're building a React application, you need React, and then you need Redux, and then you need something else. And if you want immutable data, you need something else. And if you want a linter, you need, and so on and so on and so on. Whereas Elm, it's just Elm. And Vite kind of feels the same while remaining a JavaScript thing. If you're needing to build an application, you're going to need a bundler. You're going to need a dev server. You're going to need to do hot module reload, ideally. And that's all very complicated. And we can see how complicated it is in JavaScript because of things like create React app, or in Vue 2.0, they had the Vue CLI, which also used Webpack. So Vite is geared towards solving that problem where you have the dev server, you have the bundler, you have everything that you need just kind of built into one tool. So can you sort of pick up things about your config? For example, if you want to import TypeScript files, then you don't need any special setup because ES build automatically can transpile TypeScript files, and it's built on top of ES build. So it will use your TS config, and it uses various configuration files and these standard conventions to run the bundling. Is that right? That's supported out of the box. Other things are supported out of the box, such as WebAssembly. You can just import a WebAssembly file and start it up in your application, and it works fine. You don't get hot module reload on WebAssembly, obviously, but you can import the WebAssembly file directly. On TypeScript, though, one of the interesting notes is because of how Vite is handling it and passing the TypeScript file to ES build for the compilation step, you don't need any actual type checking in your TypeScript. It's just performing the transpilation. So if you're wanting the lovely type checking that we're used to, you need to set that up in your IDE. Okay, or use a different terminal to run the TypeScript checker. So I'm still confused as to why it's using two different bundlers, one in production and one in development mode. Is it because ES build is only meant for production builds and rollup is meant for both, but it's not as good in production or something like that? The main reason that Vite is using two different bundlers at the moment is because ES build is still under development. It hasn't reached 1.0. So while it's very fast, it can't handle everything at the best efficiency. So for the time being, Vite is using rollup and ES build for two different parts of the experience. The long-term plan is to settle on just one, and that's probably going to end up being ES build because of its speed. But for the time being, they're still having to use the two. There's also the nice benefit with that of having the plugin ecosystem that incorporates Vite specific features, but also the rollup plugins. So if you want to use a rollup plugin in Vite, you can just import it and use it as normal. You don't have to worry about, is this compatible? Because it just is. But only in development mode? It will still work in production. I cannot speak to how it does that magic, but I know it does. Oh, interesting. So that's interesting because I imagine many people do associate ES build with being like a JS and TypeScript transpiler. I have seen in the docs things about CSS files, so I guess it is a general purpose bundler as well. That's interesting. ES build? Yes. I believe that is the long-term goal. I'm not 100% on that. I write applications. Yeah. It seems like a real trend I'm seeing these days in the JS ecosystem is trying to come up with a set of agreed upon standards rather than just everything having bespoke approaches to things. So rollup plugins have a specific format and Vite said, okay, well, there's this sort of plugin API and let's just use that same API. And if we're using that same convention, we can use ES build and for the dev server and everything can play nicer together because they're using the same conventions. Yeah. One of the big pushes was not having to worry about a development configuration and a production configuration. And one of the other niceties was there's a project called Vitest, which is just going to throw the French out the window again. I mean, that's not even a French word at all. It just means you have to pronounce the first bit wrong. It might be a double entendre though, which is not a French idiom, I think. Of course not. But Vitest is intended as a replacement for something like Jest. So instead of having to do all of your testing in Webpack and have a separate configuration for your tests from the application, you can just use your global Vite configuration, write your tests, and everything just works. I saw the name a few times before, Vitest, but I never understood that it was a test framework. I just thought it was, well, Vite means fast, so Vitest is fastest. So it's something to make things faster again or something. Okay, it's a test framework. Gotcha. Yeah, and that was created by Anthony Foo, who is on the core team for Vite. He's been extremely prolific in creating tooling around Vue and Vite. Definitely if you're interested in this ecosystem, I would suggest checking him out. Yeah, it's been extremely active. Vite is just such a well-supported tool these days. I know TurboPack was recently announced, and then there were some somewhat controversial figures that were given. I know Evan, you had some things to say about the methods for coming up with these benchmark comparisons between TurboPack and Vite. It's just like Vite is so well-maintained that I'm not ready to jump onto a new train at this point. Vite seems great, and it seems like an agreed-upon standard, and it uses these standard conventions. So I'm all on board for Vite, personally. Have you tried it on a few projects at all? I use it internally for Elm pages for the V3 beta. I'm using it. There's an SSR mode that tooling authors can use to serve up pages. So yeah, Elm pages V3 comes completely with a built-in Vite server. So you can use it to have SCSS files or tailwind configuration, or import TypeScript code into your entry-point JavaScript file in your Elm pages project. It all just works out of the box. Back in Elm pages V2, I became somewhat disillusioned by the whole webpack world. Some tools, some front-end frameworks like Gatsby and things like that, would expose ways to add your own webpack plugins so you could hook into the webpack internals. That just felt like such a weird inversion where you can mess up internals in a way that could actually break the framework. That didn't feel right. And then it felt like there are so many possible configurations people could build. I just came to this conclusion, Elm pages is going to focus on just compiling your Elm code and setting up everything and just focusing on that. If you want SCSS files, if you want to import TypeScript files, there's a TypeScript compiler that turns that into JavaScript. There's an SCSS compiler that turns that into CSS files. And Elm pages doesn't care how you get your CSS and JavaScript files to it, but that's the only thing it understands. I called it a bring your own bundler philosophy. But Vite completely changed my perspective on that because it came with this sort of standards-based approach where it's like, if you have an SCSS file, you can import it. And you have the thing you need to compile SCSS installed. You don't need to configure it to explain how to transpile SCSS files because that's a standard. You just include an SCSS file in your index.html and it figures that out. Or you include a.ts file in your.html and it figures that out. And then you just compile it. Or you include a.ts file in your script in your index.html file and it figures that out. Or you include a.ts file in your script in your index.html file and it knows what to do with that. And so it completely changed my perspective on that. And I integrated Vite in Elm pages v3 and it's been great. The front end ecosystem in general. I'm really excited to hear how it's in Elm pages v3 and I'm looking forward to trying it more myself. But Vite is being used by Vue, by Svelte, by Solid, by Astro. I think there's some integrations for things like Eleventy as well. So there's a lot of projects that are now using Vite and adopting it in the background and bringing together this whole ecosystem. So that everyone's on the same basic tooling from the start. Then you just add the framework and libraries on top of it that you want. Exactly. Yeah. Yeah. It's a breath of fresh air, especially like, you know, Jeroen and I have talked about this world where you have like, everybody has a custom Babel configuration that gives them like slightly different JS syntax. And then you've got JSX and TSX and then variants on that and all these things. And it's just like, can we just agree like what the basic syntax is and just like not mess with that stuff? So all the tooling can just not need all this customization to just tell it like what syntax is and how things work. And it just feels like the pendulum is swinging back there. Things got a little bit out of hand and now we're like, let's just kind of take a more conventional approach. Yeah. I imagine it's also because the JavaScript community is less intent on shipping new things. Like they're not building a new JSX as far as I know. And it's just like, okay, well people are using JSX. Okay. Let's include it. People are using TypeScript. Let's include it. People are using SCSS. Let's include it. In that way you have a standard because that's what people use. And there are new versions of JavaScript coming on every year. So let's just add support for them whenever they arrive and that's it. So that does make things a lot easier. Yeah. And in the Elm ecosystem, like we've had this for a long time because Elm 0.19 has been released a few years ago and not much has changed since then. So for us, it's very stable as well, but for very different reasons. I think I've come to a point where I'll admit I've only used Elm 0.19. I started in the Elm ecosystem right after it released. So I have not yet seen the pain of having to transfer between versions. Yes. Same here. I think I started looking at it in 0.16 or 0.17. Yeah. 0.16 when there were still signals. 0.19 was released like a month before and hasn't changed since. One other piece that we haven't touched on, and I realized Dillon, you asked the question, I forgot to answer it. ESM, which is a huge piece of what makes the Vite development experience so lovely. And as I'm describing this, I'm going to be describing it from a JavaScript perspective primarily because that's where you see the biggest benefit. But this also helps with Elm development as well. During development using Vite, all of the scripts, all of the code, everything is just compiled into standard native ES modules. ES in this case being ECMAScript. You mean that even things that use CommonJS or other formats that you use like require, they get compiled to use import and export syntax? Yes. Good job. During the development process, everything is in ES modules. Rather than the experience that we've had with Webpack, for example, of you have to wait for all of the code to compile before you can even start up your application in the browser. I had an experience at a previous job on a Vue application that used Webpack. Start the application, go and get a snack, come back, it's done, it's ready, now I can finally get to work. Depending on the file that you change, all of that would have to happen again. With Vite, because everything is ES module, it's A, every single file, if you make a change, only that file is replaced in the browser. The browser is acting as the bundler because you're just sending all of the code to it and it's loading things using the native syntax. The other benefit to that is if you're on a page and only some of the code is getting loaded on that particular page, Vite won't bother compiling the rest of it for the time. It will only load the route that you're using and it will only load the code that you're using. Right, and when you're talking about native imports, we should clarify that CommonJS imports are something that bundlers know how to pack up into a bundled asset, but browsers have no idea what require means. If you see require in the browser, it just explodes and says, I don't know what that is. Yep. But if you say import... CommonJS is a remnant from the early days of Node where everyone said, well, we need a way to bundle things and we need modules. And so between the front end needing something like that and the back end needing something like that, the pseudo standard that was developed was CommonJS. But when the TC39 was working on how do we actually standardize this? There is a community standard right now. They felt that going with require and going with the CommonJS syntax was not what best served the JavaScript ecosystem. And so they went with the import syntax that is more modern, we're more familiar with today. So that is what is used in the browser by default. And you could actually do this without a bundler as well. If you wanted to create a section of your code that used ES modules in the browser, no compiler necessary, you would just have to set the script type to module. And suddenly you can import things and you could export things if you really wanted to. And everything would work as you're used to when you're using a compiled language that uses that same syntax. You said you need to change the script type in package.json? No, just in the so if you have an index.html file, and you wanted to import JavaScript as a module, you could just create a script tag and say script type module. Gotcha. Yep. And then you can use your import syntax and use that as you would if you were using a bundler. All right. It's a little different, right? Like if it's a script type module, can you not do things in the top level? Everything has to be like you can export things, but you can't just have top level code. Am I understanding that correctly? I believe there are some restrictions. I don't remember exactly which ones they are. Okay, but it's supposed to be better for tree shaking and things like that, right? Like for static analysis purposes, there are some benefits to ESM standards. There are, if you're using a bundler, yes. The difficulty with ESM, even today as a standard, is that if you're using ESM in production, there will be a waterfall of HTTP requests. Totally. So if you have a large single page application, you're going to fire off JavaScript request after JavaScript request until the whole thing is loaded that you need. And that's not really ideal, even today. Wasn't that what HTTP 2 was meant for? Solving that kind of issues? I think the main problem is that if you load up your index.html file and it references a single JavaScript file, you fetch that file, but then it's going to reference other files. So it's not that you can't do the requests in parallel, it's that it doesn't know what requests to make. Yeah, of course. Yeah. And there do exist plugins that like hoist module preload directives to figure out what that waterfall is going to have and then add preload directives to tell you. But yeah, generally, people just in the production build just turn everything into a single bundled asset instead, or well, not necessarily a single one, but they chunk the assets rather than just having everything be ESM imports. So if somebody wants to try using Vite with Elm, what is the minimal thing they can do to get started with that? And what's the simplest way they can get started with that? So if someone wanted to take Vite and just run, for example, npm create vite, set up a new project, whether they're using another JavaScript framework or just vanilla JavaScript, the first step that would need to be done is install the Elm plugin. And that plugin is just called Vite plugin Elm. And it is lovely. I've been using it for some time on my own projects. I'm sure you're familiar with it as well, Dillon. Then in your Vite config, there's a Vite.config.js file. And you have two, as a bare minimum, you need two imports. One is import define config from Vite. And that gives you the configuration file and also gives you TypeScript typing, which is helpful as you're working in that file. So you don't need to be constantly referencing the documentation. And then you need to import the plugin itself. And then as far as the configuration goes, the way the file is structured, you just say export default define config, which is a function, takes an object. And as a key, you say plugins, which takes an array, and then you invoke the Elm plugin as a function inside of that array, and you're done. That's all you need to do to integrate Elm into a Vite application. From there, you of course need to run Elm init, create your Elm file and import it into the JavaScript. But you can import it as if it were JavaScript at that point. You can just import Elm from main.elm and instantiate your application as you normally would. So that would be the bare minimum to get Elm working inside of Vite. What I would recommend as a simple way to do that instead is, this is a shameless plug, by the way, I have a template for creating Vite applications using Elm that includes nice tooling such as Elm test and Elm review and some example code to go with that as well. So that would be my recommendation. And that is just called Vite template Elm. And you can find that on GitHub, lindsaykwardell slash Vite Elm template. Sorry, I said Vite template Elm and it's Vite Elm template. I'm good at knowing what my own things are called. Yeah, that's great. What we tend to do is just name things the easiest way. The only question is like, which order is it? Yeah. I mean, you could have said template Elm Vite and that would be terribly wrong. But we would still get it. Yeah, it's got to be Vite first. And I think I went with Elm second because that's the language. I don't know. Yeah, so that would be the simplest way to get started. So you get the hot module reload, which actually works with Elm as well. It's lovely. I really appreciate it. You also get the integration with Vite static asset handling. Vite not only can handle TypeScript and JavaScript and WebAssembly and CSS, but you can also import images straight into it. And there's a nice little plugin. It's an Elm package that will prefix things properly so that Elm code gets compiled to JavaScript code that actually handles the assets in a way that Vite likes. You can do it manually. It's just a string, but it's nice to have something a little stronger. The tooling is all installed via Elm tooling, so you can spin things up in your CI CD. So you get Elm, Elm format, Elm JSON, Elm test. You get Elm review and unit test examples. And there's a GitHub Action CI for running tests, just as an example. So that's what the template includes. It's not intended to be like, this is the best solution, but this is a simple solution that shows everything you would need. Yeah, it's pretty exciting how little boilerplate there is for getting started with something that is not a cute tool that sort of gets you started and then you outgrow. It's a very simple setup that gets you up and running quickly. But then it's the tool that everybody uses now that has a ton of support and can do whatever you grow into doing later. So that is a breath of fresh air, for sure. I mean, Webpack also did that, but you had to configure it a lot. Yeah. My inspiration for this template was actually using the Create Elm app, which is built on Webpack. I had an application written in that and I kept running into situations where I felt like I needed to eject and then handle the Webpack config myself, and I just really didn't want to. So when the plugin came out that supported Elm and Vite, I immediately ported the application over to Webpack. And then backtracked to a template that I could reuse in future applications. Yeah. Do you also have the concept of ejecting in your template? There is nothing to eject. The nice thing about Vite is everything is self-contained, but if you need to override something, it's very easy to do so. And that philosophy carried over from Vue.js as well, where you had a config. Yes, it used Webpack, but you didn't need to worry about ejecting. You just extended it with your own stuff. For those who don't know, ejecting is when you use Create Elm app or Create React app, you run commands through that CLI, like Create Elm app, Create Elm app run, Create Elm app start or whatever. But then whenever you did something too custom, you would have to opt out of using Create React app, Create Elm app. And at that point, you have to eject and you're on your own. And I found it always very scary, like, oh, what if I want to do something custom? Oh, now I have to eject. Oh, now there are so many things that were handled for me automatically that are not anymore. So I'm really happy that you don't have that concept. It's just like, these are the scripts and you do whatever you want. And they're all simple. Yeah. That's really nice. And if you want to extend it with a JavaScript framework, like Vue or Svelte or Solid or React or something, it's really easy to do so because it is just using Vite. I have the opposite problem, Dillon, where I want people to have all the foot guns. Because I don't want to lock it down. I want people to play with it and explore and feel comfortable with Elm, interacting with the tooling that they already have. Yeah. I mean, the beautiful thing is like all these Create React app, Create Elm app, they were addressing a real need, a real pain point at the time, which was that Webpack was this, you know, very verbose configuration that like you go and copy paste these like very complicated setups just to like, tell it you want like raw imports for CSS. Or you want like, you want it to transpile Elm and things would break frequently. And you're just like, I just I just want to like import an Elm file. I just want to import SCSS. Like, can I just do that? And it's like, yeah, well, here's this configuration. But there's this one thing that's kind of broken in it. And it made things more customizable than they needed to be. And so it gave you an overly general purpose way of configuring things, which most of the time isn't what people want. They just want to use SCSS. That's, that's all. They just want to import Elm. That's all. And so now... I don't know if you can tell that Dimon had horror stories about Webpack. Well, Elm Pages v2 was built as a Webpack plugin. So I have horror stories. It was painful. It was very painful. Writing custom Webpack plugins was very sparsely documented and error prone and difficult to debug. It was like, honestly, probably the hardest technical accomplishment of my career was getting that thing working. It was... And I'm not proud of that. It just was. But so like create React app and create Elm app were addressing a real pain point, which is just you needed a simpler abstraction for how to configure a basic Elm app or basic React app. And then Eject was, well, let's address the problem that you might outgrow that and need to do something more custom. But if you don't, then we can hide some of that complexity from you. But now with Vite, it's like, well, there's really not that much complexity to hide. You just use the Elm plugin and now you can import Elm. Like we don't need to create a wrapper tool that abstracts the complexity of the basic setup for that for you. So, man, I think it's a pretty good time in the web ecosystem, I would say. I think we've really gotten some nice, nice tools. So, yeah. Are there any other kinds of assets that Vite can process that you enjoy using, Lindsay, when you're working with Vite? Primarily what I've used has been CSS, TypeScript and images. So I haven't dug in a ton to all of the flexibility that it offers there. I did play around a bit with WebAssembly and compiling Rust and running that inside of Vite. That was really fun. I don't know Rust well enough to make use of it, but I did some simple addition and called it in JavaScript. So that made me happy. One of the other features, though, that I really like that ties into this use of standards is using web workers inside of Vite. So when you instantiate a web worker, there's the web standard way of doing it. And Vite just supports that standard. So if you want to instantiate a web worker, you just call it the exact same way. Or there's a special syntax as well that they offer from a previous version of Vite, but it's no longer the recommended way. So you could call new worker just like you would if you were in a standard JavaScript file, reference the URL for your worker JavaScript. Or you can import worker from worker and then append it with a query parameter of worker. And you want to give people a short introduction to what a web worker is? Absolutely. Web workers are if you have a long running or high calculation task in JavaScript or just the front end in general, and you need to run that. Typically, if you're just doing it in the main application, you're going to cause issues with the browser. Example of this can be CSS not updating properly if somebody moves their mouse and the hover animation doesn't change, that could be what's happening. The goal of a web worker is to get it off of the main thread and into its own subsection of the browser. And then you can pass messages to and from the web worker just via JavaScript. So, for example, on my blog, I wrote a blog post about this where you could have two Elm applications, one being the view layer and one being the web worker. And these two Elm applications are just communicating via this messaging protocol and then passing the messages into their ports. So it becomes an effective way to have two Elm applications talk to each other if you need to do complex calculations inside of Elm. Yeah, Elm's architecture is actually very interesting for this because of the way it separates the sort of DOM mutation. And because of the whole virtual DOM diffing and everything, conceptually, you can really separate the state part of it from the DOM updating part of it, which is basically what web workers can't touch the DOM, but they can run code. And it's a good kind of way to split things up. Yeah, and the fact that Elm has platform.worker that doesn't require looking at the DOM, so you can just render that in a headless environment such as a worker or a node. But you can use that to instantiate an Elm application that can then just communicate via ports. It takes an input and that's all of the inputs to its update function. Yeah, I think this could definitely be a really interesting thing to experiment with. I could imagine at a framework level abstracting this way, especially because I think there's a clear segregation between the processes. So you have to use array buffers to send messages back and forth, which is a little bit awkward. Can you send JSON as well, maybe? I believe you can just send JSON. You can send JSON too? Yeah. My side projects in Elm is a turn-based strategy game and I'm using a web worker to do the AI calculations. Nice. So I just send the game state over as JSON. So from Elm to Elm again? Yes. Because it's too slow to have it in the Elm main thread? Yep. The problem I was having in the game context, in a late stage of the game, there were a lot of pieces on the board, there was a lot of options available to the computer, and it would have to cycle through all of the cells, all of the units, all of the combinations of units, and make a decision on what to do. And when it was doing that in the main thread, all of the CSS would stop working. So if you tried to do anything, or even just open the menu and say, I'm done playing, get me out of here, you couldn't do that. So I switched that all to being sent via JSON to a web worker, and then just decoding it back into Elm, performing the calculation, and then shipping it back. So it can still take time, because it's having to do all those calculations, but it's not blocking the CSS anymore. That would be really interesting if there was some abstraction where you could basically say, here's a message to send back when this long-running computation is done on a web worker thread. And then you could say, I'm awaiting the AI response for this, and I'm going to show this as loading until I get that message and update my model, having gotten the computation from the AI's prediction or whatever. Could be really interesting. So Vite, why do we need a special syntax for importing something as a web worker with Vite? How does it help us with that? I believe the original problem was how Vite was doing its compilation to ES modules. The worker syntax was just not playing nicely with how the bundling was happening under the hood. So the version I was working with at the time, I believe, was Vite 2. Vite 4.0 has now released, and looking at the docs, they now support the standard new worker syntax. And when you were talking about this, importing this WebAssembly Rust, was Vite actually running the Rust compilation step for you, or was it importing Wasm that you had compiled from Rust? There is a plugin for Vite that will compile Wasm. However, it still has to be a separate step from running the Vite dev server. But you are using the Vite config at that point, you're using the standard tooling that you're using for the rest of your application. You just need to compile that first, then start your dev server. So when I was playing with it, I had a separate step before actually instantiating the Vite dev server. But I could just run npm run dev, and I didn't have to think about it. I don't understand. How come you need to have a separate step for that? It may have changed, but the last time I looked, the Wasm file isn't actually generated until you do the compilation. Otherwise, you're just writing Rust files and you're in the Rust environment. So when you're compiling Rust, you need to say, I'm targeting WebAssembly, and that's what generates the Wasm file for you to import inside of Vite. I thought of the way that Vite worked is you have an index.html file, and you have a bunch of imports. And if you import something like something.wasm, then it figures out, okay, I know this file, and it comes from this step. Is that the problem? It doesn't know which task makes it? I believe if you updated the Wasm file, it would work fine. The setup that I was using had it as part of spinning up the dev environment. So I don't think it would be hot reload in that sense, because WebAssembly can't do that, I believe. But you do get the benefit of if you do a refresh, then it's there. I wonder if you would be able to set up like a Vite plugin to say when I import a Rust file, compile it to Wasm and then import that. I would love that. So you mentioned that there is hot reload even for Elm. Can you explain what it does exactly and how well it hot reloads? Sure. So for people less familiar, hot module reload is if you are working... I'm going to use JavaScript as an example. If you're working in a JavaScript application, and you have three different files that you're working in, and you change one of them, hot module reload first will grab that new code that you've written, load it into the browser. But also execute that and make the change. So if you're changing what the UI should look like, it will make that change for you. If you're changing the logic of a function, it will make that change for you. It will replace the code, and you don't have to refresh your entire page. I feel very spoiled by this feature whenever it's available. I've tried working with other frameworks that don't have it, and it makes me very sad. So where it comes in handy in Elm is the same. If you're working in an Elm application, and you just change the logic of a function, Elm will hot reload and just replace the logic of the function. The downside where it comes to Elm is if you're modifying functions in the same file where you define what your model is, or where the core of your application is, it will hot reload that whole thing. So if you are working in an Elm application with a single file, and you make a change, it will reload the entire file. So your entire application will initialize again. So if you are breaking your Elm application down into separate files where you've got a file per type, for example, and that type has certain functions, and you make the changes to the file of that type, that file will reload, your code will continue to run, your model will still be there, everything will be in the state that it was. But now the new functions will be available that you just wrote. So it works with Elm, and I still highly appreciate not having to hit the refresh button on my page myself. But there are some gotchas because of how Elm works and where the model is stored. Right, yeah. I think I remember Simon Nadal talking on this episode for Elmwatch about techniques he made to improve that. But yeah, this sounds pretty hard to do. Like if your model changes, for instance, then you have to refresh the whole page anyway. Although now that you mention it, I do remember at one point changing my model, referencing the key, and seeing a null appear on screen, which was very weird. Yep, that's not wanted. Yeah, I find most of the time, the reason I want hot module reloading is if I'm tweaking a view, I don't want to have to keep finding the state I was in that shows that view. But if I'm changing my model and the way that messages are flowing through the system, then I'm fine just refreshing and starting that process over. So it usually works pretty well. Yeah, I've been pretty happy with how the hot reloading works in Elm. Similar experience. It helps a lot more when you're working on the UI layer. But again, just not having to think as much about, am I looking at the correct version of my application? Did it refresh? Did I refresh the page? It helps a lot just with the process of building an application. So you can look at your code, rate the changes, switch back to the browser. And because of how fast Vite is, typically it's already done by the time you get back. You're not alt-tabbing fast enough. That's it. I need to work on my alt-tab game. That's what I need to do. Why might someone consider alternatives to Vite? Maybe you're all in on Vite, but I'm curious. Do you think there are use cases where someone would want to not use Vite with Elm? That's a good question. I don't. So I will fully admit I am all in on Vite. I came from the Vue ecosystem. Evan, you created this. I really appreciate his work and I just kind of stick with it. The fact that the rest of the JavaScript ecosystem has gone in this direction as well gives me added comfort in that. That said, I think it's perfectly reasonable to take a different course if that is what feels more comfortable. And I think that's what it comes down to, is comfort. So, for example, there's Parcel, which you don't even have to use a plugin to get Elm working. Elm just works. There's tools like ES Build, or please don't use Webpack, but there's Webpack too. If you really want to go in that other direction and not down this path, I think there's some kinds of developers that really prefer that configuration of all the nitty gritty over having something that's pre-configured that they can update. The other big one is if you want to use ES Build and you don't want all the other benefits of Vite, you could just use ES Build, for example. I know plenty of projects and companies that are doing just that if they want to use Vite. Whether it's Elm or not, ES Build is a wonderful tool on its own. It's still in development, but it's pretty good. So if you didn't want all the extra goodies that come with Vite, they don't benefit you for whatever reason. It's perfectly reasonable to just go with something more lower level and just get a bundler. I think those would be the main reasons I would go with something else. The only one that I knew about and used sometimes was Parcel. Just because it worked without any configuration or so. And the alternative at the time was Webpack. There's one that works without a configuration and the other one that doesn't work with a lot of configuration. So the choice was quite easy. I wouldn't be able to tell what the difference is between Vite and Parcel. I think in many ways that's a good thing. If they do the same thing, yeah. They do pretty much the same thing for what you need. And so it comes down to a preference, which one feels more comfortable to use. I think for me, the big reason I lean towards Vite besides I came from the Vue ecosystem is I'm jumping between other frameworks a lot of the time for other side projects. And being able to, for example, in a Nuxt application, Nuxt.js, it's a server-side rendering framework for Vue. Because it's using Vite, I can just import the Elm plugin. And now I have the power of Nuxt on the backend and the components if I really want to. And then for anything that feels like it should be in Elm, I can just render that in Elm instead. And I can just mix and match a whole lot easier. And similarly, going the other direction, if I'm a Vue developer or I'm a React developer and I want to try out Elm, or I want to try out Svelte, or I want to try out whatever, but we're an Elm podcast. If you want to try out something else and you're using Vite already, it's as simple as just getting started. If you're using Elm, just plug it in. If you're wanting to use Vue, just plug it in. And then you can start using that thing, whatever it is. And the fact that so much of the ecosystem is already built on that, you've got Nuxt, you've got Astro, you've got SvelteKit, SolidStart. There's just so much that's built into that. I really like the ability to jump between the different tools and the different frameworks and the different applications. And it's all the same configuration underneath. And I know what I'm getting into. So that's when I'm evaluating a new project such as Elm Pages v3, I'm looking to see what is it using under the hood. And, oh, it's Vite. Awesome. I'm probably going to use this. Yeah. I was adding something to the docs site for Elm Pages for basically like, I think I even saw some GDPR thing about some litigation because people were loading Google fonts directly. And it was violating people's privacy because it was unnecessarily pinging Google servers when people loaded a page just to load a font. And I'm like, wow, that's been like this standard way I do things, just load a Google font. And for a long time, people said, well, it's a good practice because you cache the font. So if somebody else has loaded it with Google fonts, it will be in their cache. But actually, that no longer happens on browsers because they realized that that was like a fingerprinting vector that could let people identify a user based on which assets had been cached on their site. So caches are sandboxed by domain. And so you no longer have even that benefit. Plus, when you have to connect to another domain, you have to do the whole handshake and open up that connection to another domain. So it's faster if you load the asset from the site that is being hosted at. And so how do you how do you do that? Install a single Vite plugin, tell it the Google fonts you have, and then it just knows how to do it. And it's so easy. And I can do that now in the Elm pages doc site, which, of course, if it was not written in Elm pages, that would be embarrassing. It's written in Elm pages. But I just open up the Vite config and then add that plugin to for downloading Google fonts. And it's so easy to use. So it's pretty cool being able to hook into this like vibrant ecosystem, which like everybody has decided is a good idea right now. So when do you get tracked now? Is it when you build the application? Google knows when you run your build. Yeah. Okay, good. Yes. We wouldn't want to take that away from them, right? As long as they can't shut it down, that's fine. Google knows if you've been bad or good, so be good for goodness sake. Oh, no. I mean, it's true, but oh, no. On Vite real quick and the integrations, I just pulled up an article written by Patak, who's one of the core developers on Vite at this point as well. And there's just so many integrations that Vite has that I didn't even remember as we were talking about it. So, for example, there's plugins for Ruby. So if you've got Ruby on the back end, typically you're going to be using something like Webpacker to bundle your JavaScript as the default. So there's a way to replace that with Vite, and you can just have a really nice tool for JavaScript on the front end. And same for Laravel. There's a plugin for Laravel that lets you just use Vite instead of its equivalent of Webpack. And there's also tools like Cypress or Storybook that are more development tools. You've either got your end-to-end testing or your component library or something. But it can all use Vite across the stack. You don't have to worry about these separate configurations. You don't have to worry about which environment to make in and trying to get the tools to talk to each other. It's just a streamlined way to use the same configuration and the same expectation of how the code works across your entire code base. Just so I don't misunderstand it, Ruby doesn't get compiled to ESM, right? Correct. That's just Ruby on Rails doing Ruby on Rails things. Okay. So Vite is not only compiling for or bundling for a front end, but it's also able to run servers, right? Is my understanding correct now? Because Laravel is a backend technology as far as I understand it. This is more an integration so that as you're working with Ruby or Laravel, rather than having to compile your JavaScript via Webpack or via something else or not at all, you're integrating Vite into that experience. Okay. Right. Which means if you try to download hello.scss, or when you render your HTML in Ruby, I'm assuming it has to post-process that with Vite. So it's some setup that runs on the server to make sure it has those assets, I'm assuming. Yep. Even in production? In production, it's using a bundle at that point. Okay. That said, because you mentioned Vite on the server, there is Vite Node or Node Vite. I think it's Vite Node. And that's what Vitest uses in order to run Vite on a Node environment for running unit tests. But it's not really intended, at least for the time being, as a solution to write a server in. So nobody's going to be writing blog posts on how to set up Express using Vite Node. Are you sure about that? They might now, but... I mean, if there's one thing I know about JavaScript developers, it's if it's possible to do it, they're going to do it. And that's fair. For better or worse. Sometimes it's better. Sometimes it is. All right. Well, Lindsay, do you know any good resources for getting started? Do you have any recommendations for things to watch or listen to or read if somebody wants to learn more about Vite and get started? I think that's going to be a nuanced answer depending on what you're looking for. If you just want to get familiar with Vite, I would just go to the website, vitejs.dev, and kind of just read through, find what's interesting for you. There's the awesome Vite repository that has an amazing list of resources that are using Vite. A lot of it's going to be about Vue and React, but there's a little bit of Elm in there. And I think the third thing I would suggest is on YouTube, last year in October was ViteConf 2022, where I gave a talk on the same thing about using Vite and Elm together. And I will admit that talk was directed more at people who aren't familiar with Elm than people who aren't familiar with Vite. But you can check that talk out as well as all of the other talks. It was a 24-hour conference. There was a lot of content in there about all the different frameworks, all of the different tooling, and how this ecosystem is really shaping up and coming together. So those would be the resources I would point at first, and then just kind of explore and see what feels good. Amazing. And where can people follow you? I am on Twitter at lindsaykwardell. I am also on Mastodon at lindsaykwardell at mastodon.social. Fabulous. All right. Well, Lindsay, it was a pleasure having you on. Thanks so much for coming on the show. Thanks for inviting me. This was great. And you're in. Until next time. Until next time.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.0, "text": " Hello, Jeroen.", "tokens": [2425, 11, 508, 2032, 268, 13], "temperature": 0.0, "avg_logprob": -0.3887820644233063, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.6094232201576233}, {"id": 1, "seek": 0, "start": 2.4, "end": 7.4, "text": " Hello, Dillon.", "tokens": [2425, 11, 28160, 13], "temperature": 0.0, "avg_logprob": -0.3887820644233063, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.6094232201576233}, {"id": 2, "seek": 0, "start": 3.4, "end": 8.4, "text": " Today we've invited a special guest.", "tokens": [2692, 321, 600, 9185, 257, 2121, 8341, 13], "temperature": 0.0, "avg_logprob": -0.3887820644233063, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.6094232201576233}, {"id": 3, "seek": 0, "start": 9.6, "end": 14.6, "text": " You might have to help me with the pronunciation there.", "tokens": [509, 1062, 362, 281, 854, 385, 365, 264, 23338, 456, 13], "temperature": 0.0, "avg_logprob": -0.3887820644233063, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.6094232201576233}, {"id": 4, "seek": 0, "start": 11.6, "end": 16.6, "text": " Yeah, I wish I could help you, but I'm not the one that speaks French in this room.", "tokens": [865, 11, 286, 3172, 286, 727, 854, 291, 11, 457, 286, 478, 406, 264, 472, 300, 10789, 5522, 294, 341, 1808, 13], "temperature": 0.0, "avg_logprob": -0.3887820644233063, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.6094232201576233}, {"id": 5, "seek": 0, "start": 15.4, "end": 20.400000000000002, "text": " Oh, there's our special guest, Lindsay Wardell.", "tokens": [876, 11, 456, 311, 527, 2121, 8341, 11, 35017, 23794, 898, 13], "temperature": 0.0, "avg_logprob": -0.3887820644233063, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.6094232201576233}, {"id": 6, "seek": 0, "start": 17.8, "end": 22.8, "text": " Lindsay, thanks for joining us.", "tokens": [35017, 11, 3231, 337, 5549, 505, 13], "temperature": 0.0, "avg_logprob": -0.3887820644233063, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.6094232201576233}, {"id": 7, "seek": 0, "start": 19.400000000000002, "end": 24.400000000000002, "text": " Yeah, thanks for inviting me.", "tokens": [865, 11, 3231, 337, 18202, 385, 13], "temperature": 0.0, "avg_logprob": -0.3887820644233063, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.6094232201576233}, {"id": 8, "seek": 0, "start": 21.2, "end": 26.2, "text": " What are we talking about today, Lindsay?", "tokens": [708, 366, 321, 1417, 466, 965, 11, 35017, 30], "temperature": 0.0, "avg_logprob": -0.3887820644233063, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.6094232201576233}, {"id": 9, "seek": 2620, "start": 26.2, "end": 31.2, "text": " Vite, which is the front-end development tool created by Evan Yu, who is the creator of Vue.js.", "tokens": [691, 642, 11, 597, 307, 264, 1868, 12, 521, 3250, 2290, 2942, 538, 22613, 10767, 11, 567, 307, 264, 14181, 295, 691, 622, 13, 25530, 13], "temperature": 0.0, "avg_logprob": -0.3473874904491283, "compression_ratio": 1.524793388429752, "no_speech_prob": 0.004529070574790239}, {"id": 10, "seek": 2620, "start": 33.0, "end": 38.0, "text": " I wish we had a French speaker on this podcast to help us on how to pronounce that.", "tokens": [286, 3172, 321, 632, 257, 5522, 8145, 322, 341, 7367, 281, 854, 505, 322, 577, 281, 19567, 300, 13], "temperature": 0.0, "avg_logprob": -0.3473874904491283, "compression_ratio": 1.524793388429752, "no_speech_prob": 0.004529070574790239}, {"id": 11, "seek": 2620, "start": 38.2, "end": 43.2, "text": " It would be helpful.", "tokens": [467, 576, 312, 4961, 13], "temperature": 0.0, "avg_logprob": -0.3473874904491283, "compression_ratio": 1.524793388429752, "no_speech_prob": 0.004529070574790239}, {"id": 12, "seek": 2620, "start": 39.519999999999996, "end": 44.519999999999996, "text": " Yeah, I'm still surprised by the pun, because I thought, oh, he's going to make some joke about,", "tokens": [865, 11, 286, 478, 920, 6100, 538, 264, 4468, 11, 570, 286, 1194, 11, 1954, 11, 415, 311, 516, 281, 652, 512, 7647, 466, 11], "temperature": 0.0, "avg_logprob": -0.3473874904491283, "compression_ratio": 1.524793388429752, "no_speech_prob": 0.004529070574790239}, {"id": 13, "seek": 2620, "start": 46.8, "end": 51.8, "text": " oh, we need to hurry up and record this or something, like, Vite, Vite.", "tokens": [1954, 11, 321, 643, 281, 11025, 493, 293, 2136, 341, 420, 746, 11, 411, 11, 691, 642, 11, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.3473874904491283, "compression_ratio": 1.524793388429752, "no_speech_prob": 0.004529070574790239}, {"id": 14, "seek": 5180, "start": 51.8, "end": 56.8, "text": " That would have worked, but no.", "tokens": [663, 576, 362, 2732, 11, 457, 572, 13], "temperature": 0.0, "avg_logprob": -0.3234124331130195, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.0003195565950591117}, {"id": 15, "seek": 5180, "start": 54.8, "end": 59.8, "text": " That would have been too clever.", "tokens": [663, 576, 362, 668, 886, 13494, 13], "temperature": 0.0, "avg_logprob": -0.3234124331130195, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.0003195565950591117}, {"id": 16, "seek": 5180, "start": 56.8, "end": 61.8, "text": " In Vite.", "tokens": [682, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.3234124331130195, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.0003195565950591117}, {"id": 17, "seek": 5180, "start": 59.8, "end": 64.8, "text": " Going for the lowbrow here.", "tokens": [10963, 337, 264, 2295, 1443, 305, 510, 13], "temperature": 0.0, "avg_logprob": -0.3234124331130195, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.0003195565950591117}, {"id": 18, "seek": 5180, "start": 62.8, "end": 67.8, "text": " So what is the proper pronunciation?", "tokens": [407, 437, 307, 264, 2296, 23338, 30], "temperature": 0.0, "avg_logprob": -0.3234124331130195, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.0003195565950591117}, {"id": 19, "seek": 5180, "start": 64.8, "end": 69.8, "text": " Yeah, well, Lindsay, before we started recording, you said that you were discussing how to pronounce Vite.", "tokens": [865, 11, 731, 11, 35017, 11, 949, 321, 1409, 6613, 11, 291, 848, 300, 291, 645, 10850, 577, 281, 19567, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.3234124331130195, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.0003195565950591117}, {"id": 20, "seek": 5180, "start": 71.8, "end": 76.8, "text": " Yeah, so in a former time, I was a podcaster on the show Vue.js on Vue.", "tokens": [865, 11, 370, 294, 257, 5819, 565, 11, 286, 390, 257, 2497, 42640, 322, 264, 855, 691, 622, 13, 25530, 322, 691, 622, 13], "temperature": 0.0, "avg_logprob": -0.3234124331130195, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.0003195565950591117}, {"id": 21, "seek": 7680, "start": 76.8, "end": 81.8, "text": " And when the Vite framework was originally announced and released, we were talking about it,", "tokens": [400, 562, 264, 691, 642, 8388, 390, 7993, 7548, 293, 4736, 11, 321, 645, 1417, 466, 309, 11], "temperature": 0.0, "avg_logprob": -0.23227611509691767, "compression_ratio": 1.7174721189591078, "no_speech_prob": 9.50994945014827e-06}, {"id": 22, "seek": 7680, "start": 83.8, "end": 88.8, "text": " and none of us could figure out how it was supposed to be pronounced.", "tokens": [293, 6022, 295, 505, 727, 2573, 484, 577, 309, 390, 3442, 281, 312, 23155, 13], "temperature": 0.0, "avg_logprob": -0.23227611509691767, "compression_ratio": 1.7174721189591078, "no_speech_prob": 9.50994945014827e-06}, {"id": 23, "seek": 7680, "start": 87.8, "end": 92.8, "text": " I think at the time we were saying Vite, because we just couldn't figure it out, but we kept going back and forth.", "tokens": [286, 519, 412, 264, 565, 321, 645, 1566, 691, 642, 11, 570, 321, 445, 2809, 380, 2573, 309, 484, 11, 457, 321, 4305, 516, 646, 293, 5220, 13], "temperature": 0.0, "avg_logprob": -0.23227611509691767, "compression_ratio": 1.7174721189591078, "no_speech_prob": 9.50994945014827e-06}, {"id": 24, "seek": 7680, "start": 93.8, "end": 98.8, "text": " Vite, Vite, should you drop a vowel, should you drop a consonant?", "tokens": [691, 642, 11, 691, 642, 11, 820, 291, 3270, 257, 29410, 11, 820, 291, 3270, 257, 43647, 30], "temperature": 0.0, "avg_logprob": -0.23227611509691767, "compression_ratio": 1.7174721189591078, "no_speech_prob": 9.50994945014827e-06}, {"id": 25, "seek": 7680, "start": 97.8, "end": 102.8, "text": " None of us actually know French, and the only French word we know is Vue, which I assume we're also pronouncing wrong.", "tokens": [14492, 295, 505, 767, 458, 5522, 11, 293, 264, 787, 5522, 1349, 321, 458, 307, 691, 622, 11, 597, 286, 6552, 321, 434, 611, 14144, 2175, 2085, 13], "temperature": 0.0, "avg_logprob": -0.23227611509691767, "compression_ratio": 1.7174721189591078, "no_speech_prob": 9.50994945014827e-06}, {"id": 26, "seek": 10280, "start": 102.8, "end": 107.8, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.21492410475207913, "compression_ratio": 1.547872340425532, "no_speech_prob": 1.3827489055984188e-05}, {"id": 27, "seek": 10280, "start": 107.8, "end": 112.8, "text": " So we just kind of gave up, and the Vite documentation says Vite at this point, and that's how Evan Yu pronounces it.", "tokens": [407, 321, 445, 733, 295, 2729, 493, 11, 293, 264, 691, 642, 14333, 1619, 691, 642, 412, 341, 935, 11, 293, 300, 311, 577, 22613, 10767, 14144, 887, 309, 13], "temperature": 0.0, "avg_logprob": -0.21492410475207913, "compression_ratio": 1.547872340425532, "no_speech_prob": 1.3827489055984188e-05}, {"id": 28, "seek": 10280, "start": 114.8, "end": 119.8, "text": " But I just assume that we're all wrong.", "tokens": [583, 286, 445, 6552, 300, 321, 434, 439, 2085, 13], "temperature": 0.0, "avg_logprob": -0.21492410475207913, "compression_ratio": 1.547872340425532, "no_speech_prob": 1.3827489055984188e-05}, {"id": 29, "seek": 10280, "start": 117.8, "end": 122.8, "text": " Well, for Vite, it's not too bad.", "tokens": [1042, 11, 337, 691, 642, 11, 309, 311, 406, 886, 1578, 13], "temperature": 0.0, "avg_logprob": -0.21492410475207913, "compression_ratio": 1.547872340425532, "no_speech_prob": 1.3827489055984188e-05}, {"id": 30, "seek": 10280, "start": 119.8, "end": 124.8, "text": " So the proper pronunciation is Vite.", "tokens": [407, 264, 2296, 23338, 307, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.21492410475207913, "compression_ratio": 1.547872340425532, "no_speech_prob": 1.3827489055984188e-05}, {"id": 31, "seek": 10280, "start": 122.8, "end": 127.8, "text": " So it's pretty much the same, but the E is shorter, Vite.", "tokens": [407, 309, 311, 1238, 709, 264, 912, 11, 457, 264, 462, 307, 11639, 11, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.21492410475207913, "compression_ratio": 1.547872340425532, "no_speech_prob": 1.3827489055984188e-05}, {"id": 32, "seek": 12780, "start": 127.8, "end": 132.8, "text": " And Vue is Vu.", "tokens": [400, 691, 622, 307, 37703, 13], "temperature": 0.0, "avg_logprob": -0.18522321260892427, "compression_ratio": 1.5686274509803921, "no_speech_prob": 7.88836769061163e-06}, {"id": 33, "seek": 12780, "start": 129.8, "end": 134.8, "text": " So that's pretty wrong, I'd say.", "tokens": [407, 300, 311, 1238, 2085, 11, 286, 1116, 584, 13], "temperature": 0.0, "avg_logprob": -0.18522321260892427, "compression_ratio": 1.5686274509803921, "no_speech_prob": 7.88836769061163e-06}, {"id": 34, "seek": 12780, "start": 130.8, "end": 135.8, "text": " That's pretty wrong, yeah.", "tokens": [663, 311, 1238, 2085, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.18522321260892427, "compression_ratio": 1.5686274509803921, "no_speech_prob": 7.88836769061163e-06}, {"id": 35, "seek": 12780, "start": 132.8, "end": 137.8, "text": " I wonder if it's just payback, because Evan Yu is a native Chinese speaker, right?", "tokens": [286, 2441, 498, 309, 311, 445, 1689, 3207, 11, 570, 22613, 10767, 307, 257, 8470, 4649, 8145, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18522321260892427, "compression_ratio": 1.5686274509803921, "no_speech_prob": 7.88836769061163e-06}, {"id": 36, "seek": 12780, "start": 137.8, "end": 142.8, "text": " And he's like, all right, you're making me write all this code in English.", "tokens": [400, 415, 311, 411, 11, 439, 558, 11, 291, 434, 1455, 385, 2464, 439, 341, 3089, 294, 3669, 13], "temperature": 0.0, "avg_logprob": -0.18522321260892427, "compression_ratio": 1.5686274509803921, "no_speech_prob": 7.88836769061163e-06}, {"id": 37, "seek": 12780, "start": 142.8, "end": 147.8, "text": " Now I'm going to make all you English speakers try to poorly pronounce French words.", "tokens": [823, 286, 478, 516, 281, 652, 439, 291, 3669, 9518, 853, 281, 22271, 19567, 5522, 2283, 13], "temperature": 0.0, "avg_logprob": -0.18522321260892427, "compression_ratio": 1.5686274509803921, "no_speech_prob": 7.88836769061163e-06}, {"id": 38, "seek": 12780, "start": 150.8, "end": 155.8, "text": " I always assumed it was kind of like to make it sound like his name, Evan Yu, Vue.", "tokens": [286, 1009, 15895, 309, 390, 733, 295, 411, 281, 652, 309, 1626, 411, 702, 1315, 11, 22613, 10767, 11, 691, 622, 13], "temperature": 0.0, "avg_logprob": -0.18522321260892427, "compression_ratio": 1.5686274509803921, "no_speech_prob": 7.88836769061163e-06}, {"id": 39, "seek": 15580, "start": 155.8, "end": 160.8, "text": " Yeah, that's cool.", "tokens": [865, 11, 300, 311, 1627, 13], "temperature": 0.0, "avg_logprob": -0.18303097360502413, "compression_ratio": 1.5656934306569343, "no_speech_prob": 2.5866796931950375e-05}, {"id": 40, "seek": 15580, "start": 157.8, "end": 162.8, "text": " I think the original inspiration was he was just trying to find words that described a Vue layer, and he ended up on that one, and it was available on NPM.", "tokens": [286, 519, 264, 3380, 10249, 390, 415, 390, 445, 1382, 281, 915, 2283, 300, 7619, 257, 691, 622, 4583, 11, 293, 415, 4590, 493, 322, 300, 472, 11, 293, 309, 390, 2435, 322, 426, 18819, 13], "temperature": 0.0, "avg_logprob": -0.18303097360502413, "compression_ratio": 1.5656934306569343, "no_speech_prob": 2.5866796931950375e-05}, {"id": 41, "seek": 15580, "start": 168.8, "end": 173.8, "text": " So at this point, the entire Vue ecosystem is just named after French stuff.", "tokens": [407, 412, 341, 935, 11, 264, 2302, 691, 622, 11311, 307, 445, 4926, 934, 5522, 1507, 13], "temperature": 0.0, "avg_logprob": -0.18303097360502413, "compression_ratio": 1.5656934306569343, "no_speech_prob": 2.5866796931950375e-05}, {"id": 42, "seek": 15580, "start": 173.8, "end": 178.8, "text": " That's clever.", "tokens": [663, 311, 13494, 13], "temperature": 0.0, "avg_logprob": -0.18303097360502413, "compression_ratio": 1.5656934306569343, "no_speech_prob": 2.5866796931950375e-05}, {"id": 43, "seek": 15580, "start": 174.8, "end": 179.8, "text": " And it's three letters.", "tokens": [400, 309, 311, 1045, 7825, 13], "temperature": 0.0, "avg_logprob": -0.18303097360502413, "compression_ratio": 1.5656934306569343, "no_speech_prob": 2.5866796931950375e-05}, {"id": 44, "seek": 15580, "start": 175.8, "end": 180.8, "text": " Three letters are good for file extensions.", "tokens": [6244, 7825, 366, 665, 337, 3991, 25129, 13], "temperature": 0.0, "avg_logprob": -0.18303097360502413, "compression_ratio": 1.5656934306569343, "no_speech_prob": 2.5866796931950375e-05}, {"id": 45, "seek": 15580, "start": 178.8, "end": 183.8, "text": " Oh, definitely.", "tokens": [876, 11, 2138, 13], "temperature": 0.0, "avg_logprob": -0.18303097360502413, "compression_ratio": 1.5656934306569343, "no_speech_prob": 2.5866796931950375e-05}, {"id": 46, "seek": 15580, "start": 179.8, "end": 184.8, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.18303097360502413, "compression_ratio": 1.5656934306569343, "no_speech_prob": 2.5866796931950375e-05}, {"id": 47, "seek": 18480, "start": 184.8, "end": 189.8, "text": " I think you can say Vue.", "tokens": [286, 519, 291, 393, 584, 691, 622, 13], "temperature": 0.0, "avg_logprob": -0.20362795723809135, "compression_ratio": 1.744186046511628, "no_speech_prob": 1.3844934073858894e-05}, {"id": 48, "seek": 18480, "start": 185.8, "end": 190.8, "text": " I just say Vue.", "tokens": [286, 445, 584, 691, 622, 13], "temperature": 0.0, "avg_logprob": -0.20362795723809135, "compression_ratio": 1.744186046511628, "no_speech_prob": 1.3844934073858894e-05}, {"id": 49, "seek": 18480, "start": 187.8, "end": 192.8, "text": " I think if you're in the know, you can say Vue, but if you use React or Svelte or something, you need to say Vue.js just to be specific.", "tokens": [286, 519, 498, 291, 434, 294, 264, 458, 11, 291, 393, 584, 691, 622, 11, 457, 498, 291, 764, 30644, 420, 318, 779, 975, 420, 746, 11, 291, 643, 281, 584, 691, 622, 13, 25530, 445, 281, 312, 2685, 13], "temperature": 0.0, "avg_logprob": -0.20362795723809135, "compression_ratio": 1.744186046511628, "no_speech_prob": 1.3844934073858894e-05}, {"id": 50, "seek": 18480, "start": 192.8, "end": 197.8, "text": " You mean if you're in the React.js ecosystem?", "tokens": [509, 914, 498, 291, 434, 294, 264, 30644, 13, 25530, 11311, 30], "temperature": 0.0, "avg_logprob": -0.20362795723809135, "compression_ratio": 1.744186046511628, "no_speech_prob": 1.3844934073858894e-05}, {"id": 51, "seek": 18480, "start": 196.8, "end": 201.8, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.20362795723809135, "compression_ratio": 1.744186046511628, "no_speech_prob": 1.3844934073858894e-05}, {"id": 52, "seek": 18480, "start": 197.8, "end": 202.8, "text": " But don't say AngularJS, because that's another thing.", "tokens": [583, 500, 380, 584, 34107, 41, 50, 11, 570, 300, 311, 1071, 551, 13], "temperature": 0.0, "avg_logprob": -0.20362795723809135, "compression_ratio": 1.744186046511628, "no_speech_prob": 1.3844934073858894e-05}, {"id": 53, "seek": 18480, "start": 200.8, "end": 205.8, "text": " Yeah, that's a problem.", "tokens": [865, 11, 300, 311, 257, 1154, 13], "temperature": 0.0, "avg_logprob": -0.20362795723809135, "compression_ratio": 1.744186046511628, "no_speech_prob": 1.3844934073858894e-05}, {"id": 54, "seek": 18480, "start": 204.8, "end": 209.8, "text": " Thinking about it, and this is off topic from Vite, but Vue did work on AngularJS, and that's part of where the inspiration for Vue came from.", "tokens": [24460, 466, 309, 11, 293, 341, 307, 766, 4829, 490, 691, 642, 11, 457, 691, 622, 630, 589, 322, 34107, 41, 50, 11, 293, 300, 311, 644, 295, 689, 264, 10249, 337, 691, 622, 1361, 490, 13], "temperature": 0.0, "avg_logprob": -0.20362795723809135, "compression_ratio": 1.744186046511628, "no_speech_prob": 1.3844934073858894e-05}, {"id": 55, "seek": 20980, "start": 209.8, "end": 214.8, "text": " So maybe that's part of why Vue is originally Vue.js, and it's since shifted.", "tokens": [407, 1310, 300, 311, 644, 295, 983, 691, 622, 307, 7993, 691, 622, 13, 25530, 11, 293, 309, 311, 1670, 18892, 13], "temperature": 0.0, "avg_logprob": -0.22063330030932868, "compression_ratio": 1.4196891191709844, "no_speech_prob": 1.9525192328728735e-05}, {"id": 56, "seek": 20980, "start": 216.8, "end": 221.8, "text": " I don't know.", "tokens": [286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.22063330030932868, "compression_ratio": 1.4196891191709844, "no_speech_prob": 1.9525192328728735e-05}, {"id": 57, "seek": 20980, "start": 218.8, "end": 223.8, "text": " Wait, it's not Vue.js anymore?", "tokens": [3802, 11, 309, 311, 406, 691, 622, 13, 25530, 3602, 30], "temperature": 0.0, "avg_logprob": -0.22063330030932868, "compression_ratio": 1.4196891191709844, "no_speech_prob": 1.9525192328728735e-05}, {"id": 58, "seek": 20980, "start": 220.8, "end": 225.8, "text": " I mean, if you go to the docs, let me pull it up right now.", "tokens": [286, 914, 11, 498, 291, 352, 281, 264, 45623, 11, 718, 385, 2235, 309, 493, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.22063330030932868, "compression_ratio": 1.4196891191709844, "no_speech_prob": 1.9525192328728735e-05}, {"id": 59, "seek": 20980, "start": 224.8, "end": 229.8, "text": " Vue.js, the pervasive JavaScript framework and guide.", "tokens": [691, 622, 13, 25530, 11, 264, 680, 39211, 15778, 8388, 293, 5934, 13], "temperature": 0.0, "avg_logprob": -0.22063330030932868, "compression_ratio": 1.4196891191709844, "no_speech_prob": 1.9525192328728735e-05}, {"id": 60, "seek": 20980, "start": 231.8, "end": 236.8, "text": " Yeah, it just says what is Vue.", "tokens": [865, 11, 309, 445, 1619, 437, 307, 691, 622, 13], "temperature": 0.0, "avg_logprob": -0.22063330030932868, "compression_ratio": 1.4196891191709844, "no_speech_prob": 1.9525192328728735e-05}, {"id": 61, "seek": 20980, "start": 233.8, "end": 238.8, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.22063330030932868, "compression_ratio": 1.4196891191709844, "no_speech_prob": 1.9525192328728735e-05}, {"id": 62, "seek": 23880, "start": 238.8, "end": 243.8, "text": " Don't mind if you pronounce it Vite, I think it's close enough.", "tokens": [1468, 380, 1575, 498, 291, 19567, 309, 691, 642, 11, 286, 519, 309, 311, 1998, 1547, 13], "temperature": 0.0, "avg_logprob": -0.1681047167096819, "compression_ratio": 1.5972222222222223, "no_speech_prob": 4.198191163595766e-05}, {"id": 63, "seek": 23880, "start": 241.8, "end": 246.8, "text": " I will forgive you if you do so.", "tokens": [286, 486, 10718, 291, 498, 291, 360, 370, 13], "temperature": 0.0, "avg_logprob": -0.1681047167096819, "compression_ratio": 1.5972222222222223, "no_speech_prob": 4.198191163595766e-05}, {"id": 64, "seek": 23880, "start": 244.8, "end": 249.8, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.1681047167096819, "compression_ratio": 1.5972222222222223, "no_speech_prob": 4.198191163595766e-05}, {"id": 65, "seek": 23880, "start": 247.8, "end": 252.8, "text": " So what is Vue?", "tokens": [407, 437, 307, 691, 622, 30], "temperature": 0.0, "avg_logprob": -0.1681047167096819, "compression_ratio": 1.5972222222222223, "no_speech_prob": 4.198191163595766e-05}, {"id": 66, "seek": 23880, "start": 249.8, "end": 254.8, "text": " Sorry, what is Vite?", "tokens": [4919, 11, 437, 307, 691, 642, 30], "temperature": 0.0, "avg_logprob": -0.1681047167096819, "compression_ratio": 1.5972222222222223, "no_speech_prob": 4.198191163595766e-05}, {"id": 67, "seek": 23880, "start": 251.8, "end": 256.8, "text": " We're not going to talk about Vue on this podcast more than we need to, because that's not what we're here to talk about.", "tokens": [492, 434, 406, 516, 281, 751, 466, 691, 622, 322, 341, 7367, 544, 813, 321, 643, 281, 11, 570, 300, 311, 406, 437, 321, 434, 510, 281, 751, 466, 13], "temperature": 0.0, "avg_logprob": -0.1681047167096819, "compression_ratio": 1.5972222222222223, "no_speech_prob": 4.198191163595766e-05}, {"id": 68, "seek": 23880, "start": 258.8, "end": 263.8, "text": " What is Vite?", "tokens": [708, 307, 691, 642, 30], "temperature": 0.0, "avg_logprob": -0.1681047167096819, "compression_ratio": 1.5972222222222223, "no_speech_prob": 4.198191163595766e-05}, {"id": 69, "seek": 23880, "start": 260.8, "end": 265.8, "text": " So Vite is front-end tooling is how they build it on their site.", "tokens": [407, 691, 642, 307, 1868, 12, 521, 46593, 307, 577, 436, 1322, 309, 322, 641, 3621, 13], "temperature": 0.0, "avg_logprob": -0.1681047167096819, "compression_ratio": 1.5972222222222223, "no_speech_prob": 4.198191163595766e-05}, {"id": 70, "seek": 26580, "start": 265.8, "end": 270.8, "text": " And I've actually had a hard time coming up with a one-sentence definition that fits into the normal boxes,", "tokens": [400, 286, 600, 767, 632, 257, 1152, 565, 1348, 493, 365, 257, 472, 12, 49315, 655, 7123, 300, 9001, 666, 264, 2710, 9002, 11], "temperature": 0.0, "avg_logprob": -0.17076986263959837, "compression_ratio": 1.7214285714285715, "no_speech_prob": 5.649388549500145e-05}, {"id": 71, "seek": 26580, "start": 272.8, "end": 277.8, "text": " because what it gives you is first a development environment.", "tokens": [570, 437, 309, 2709, 291, 307, 700, 257, 3250, 2823, 13], "temperature": 0.0, "avg_logprob": -0.17076986263959837, "compression_ratio": 1.7214285714285715, "no_speech_prob": 5.649388549500145e-05}, {"id": 72, "seek": 26580, "start": 276.8, "end": 281.8, "text": " So as you're working in your code, it spins up the dev server, you're able to import your code,", "tokens": [407, 382, 291, 434, 1364, 294, 428, 3089, 11, 309, 31587, 493, 264, 1905, 7154, 11, 291, 434, 1075, 281, 974, 428, 3089, 11], "temperature": 0.0, "avg_logprob": -0.17076986263959837, "compression_ratio": 1.7214285714285715, "no_speech_prob": 5.649388549500145e-05}, {"id": 73, "seek": 26580, "start": 282.8, "end": 287.8, "text": " it does some processing as needed, especially if you're writing Elm code.", "tokens": [309, 775, 512, 9007, 382, 2978, 11, 2318, 498, 291, 434, 3579, 2699, 76, 3089, 13], "temperature": 0.0, "avg_logprob": -0.17076986263959837, "compression_ratio": 1.7214285714285715, "no_speech_prob": 5.649388549500145e-05}, {"id": 74, "seek": 26580, "start": 287.8, "end": 292.8, "text": " And then when you go to build, it uses a build process, but it's a completely different build process than what it's using during development.", "tokens": [400, 550, 562, 291, 352, 281, 1322, 11, 309, 4960, 257, 1322, 1399, 11, 457, 309, 311, 257, 2584, 819, 1322, 1399, 813, 437, 309, 311, 1228, 1830, 3250, 13], "temperature": 0.0, "avg_logprob": -0.17076986263959837, "compression_ratio": 1.7214285714285715, "no_speech_prob": 5.649388549500145e-05}, {"id": 75, "seek": 29280, "start": 292.8, "end": 297.8, "text": " So you could compare it to a bundler, but it's not quite a bundler.", "tokens": [407, 291, 727, 6794, 309, 281, 257, 13882, 1918, 11, 457, 309, 311, 406, 1596, 257, 13882, 1918, 13], "temperature": 0.0, "avg_logprob": -0.17948253631591796, "compression_ratio": 1.7887931034482758, "no_speech_prob": 2.7968641006737016e-05}, {"id": 76, "seek": 29280, "start": 297.8, "end": 302.8, "text": " And you could compare it to other systems' development environments, but it's not just a development environment.", "tokens": [400, 291, 727, 6794, 309, 281, 661, 3652, 6, 3250, 12388, 11, 457, 309, 311, 406, 445, 257, 3250, 2823, 13], "temperature": 0.0, "avg_logprob": -0.17948253631591796, "compression_ratio": 1.7887931034482758, "no_speech_prob": 2.7968641006737016e-05}, {"id": 77, "seek": 29280, "start": 304.8, "end": 309.8, "text": " It kind of fits into all of these different sections, kind of like the cracks,", "tokens": [467, 733, 295, 9001, 666, 439, 295, 613, 819, 10863, 11, 733, 295, 411, 264, 21770, 11], "temperature": 0.0, "avg_logprob": -0.17948253631591796, "compression_ratio": 1.7887931034482758, "no_speech_prob": 2.7968641006737016e-05}, {"id": 78, "seek": 29280, "start": 309.8, "end": 314.8, "text": " especially when you're working in JavaScript, but other languages as well.", "tokens": [2318, 562, 291, 434, 1364, 294, 15778, 11, 457, 661, 8650, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.17948253631591796, "compression_ratio": 1.7887931034482758, "no_speech_prob": 2.7968641006737016e-05}, {"id": 79, "seek": 29280, "start": 313.8, "end": 318.8, "text": " It fits into the cracks where things aren't as good and makes them much better.", "tokens": [467, 9001, 666, 264, 21770, 689, 721, 3212, 380, 382, 665, 293, 1669, 552, 709, 1101, 13], "temperature": 0.0, "avg_logprob": -0.17948253631591796, "compression_ratio": 1.7887931034482758, "no_speech_prob": 2.7968641006737016e-05}, {"id": 80, "seek": 31880, "start": 318.8, "end": 323.8, "text": " And that's why I'm having so much trouble figuring out what it's actually doing.", "tokens": [400, 300, 311, 983, 286, 478, 1419, 370, 709, 5253, 15213, 484, 437, 309, 311, 767, 884, 13], "temperature": 0.0, "avg_logprob": -0.23785185813903809, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.00020018784562125802}, {"id": 81, "seek": 31880, "start": 322.8, "end": 327.8, "text": " Is it a bundler? Is it this other thing?", "tokens": [1119, 309, 257, 13882, 1918, 30, 1119, 309, 341, 661, 551, 30], "temperature": 0.0, "avg_logprob": -0.23785185813903809, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.00020018784562125802}, {"id": 82, "seek": 31880, "start": 327.8, "end": 332.8, "text": " Okay, it's in between. Gotcha.", "tokens": [1033, 11, 309, 311, 294, 1296, 13, 42109, 13], "temperature": 0.0, "avg_logprob": -0.23785185813903809, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.00020018784562125802}, {"id": 83, "seek": 31880, "start": 330.8, "end": 335.8, "text": " And actually Vite itself is not a custom bundler.", "tokens": [400, 767, 691, 642, 2564, 307, 406, 257, 2375, 13882, 1918, 13], "temperature": 0.0, "avg_logprob": -0.23785185813903809, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.00020018784562125802}, {"id": 84, "seek": 31880, "start": 335.8, "end": 340.8, "text": " It's using two different bundlers under the hood for doing its job.", "tokens": [467, 311, 1228, 732, 819, 13882, 11977, 833, 264, 13376, 337, 884, 1080, 1691, 13], "temperature": 0.0, "avg_logprob": -0.23785185813903809, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.00020018784562125802}, {"id": 85, "seek": 31880, "start": 339.8, "end": 344.8, "text": " So during development, primarily it's using rollup for all of your code.", "tokens": [407, 1830, 3250, 11, 10029, 309, 311, 1228, 3373, 1010, 337, 439, 295, 428, 3089, 13], "temperature": 0.0, "avg_logprob": -0.23785185813903809, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.00020018784562125802}, {"id": 86, "seek": 34480, "start": 344.8, "end": 349.8, "text": " If it needs to do any pre-processing, it'll use esbuild, unlike dependencies.", "tokens": [759, 309, 2203, 281, 360, 604, 659, 12, 41075, 278, 11, 309, 603, 764, 785, 11516, 11, 8343, 36606, 13], "temperature": 0.0, "avg_logprob": -0.2016657908028419, "compression_ratio": 1.6082089552238805, "no_speech_prob": 4.539343717624433e-05}, {"id": 87, "seek": 34480, "start": 349.8, "end": 354.8, "text": " But for any of the code that you write yourself, it's using rollup and compiling your code into ES modules", "tokens": [583, 337, 604, 295, 264, 3089, 300, 291, 2464, 1803, 11, 309, 311, 1228, 3373, 1010, 293, 715, 4883, 428, 3089, 666, 12564, 16679], "temperature": 0.0, "avg_logprob": -0.2016657908028419, "compression_ratio": 1.6082089552238805, "no_speech_prob": 4.539343717624433e-05}, {"id": 88, "seek": 34480, "start": 355.8, "end": 360.8, "text": " so that it can just run natively in your browser without having to be bundled into a single JavaScript file.", "tokens": [370, 300, 309, 393, 445, 1190, 8470, 356, 294, 428, 11185, 1553, 1419, 281, 312, 13882, 1493, 666, 257, 2167, 15778, 3991, 13], "temperature": 0.0, "avg_logprob": -0.2016657908028419, "compression_ratio": 1.6082089552238805, "no_speech_prob": 4.539343717624433e-05}, {"id": 89, "seek": 34480, "start": 361.8, "end": 366.8, "text": " And then when you're ready to go to production, it will push everything through esbuild", "tokens": [400, 550, 562, 291, 434, 1919, 281, 352, 281, 4265, 11, 309, 486, 2944, 1203, 807, 785, 11516], "temperature": 0.0, "avg_logprob": -0.2016657908028419, "compression_ratio": 1.6082089552238805, "no_speech_prob": 4.539343717624433e-05}, {"id": 90, "seek": 34480, "start": 367.8, "end": 372.8, "text": " and create a single bundle at the end of the day.", "tokens": [293, 1884, 257, 2167, 24438, 412, 264, 917, 295, 264, 786, 13], "temperature": 0.0, "avg_logprob": -0.2016657908028419, "compression_ratio": 1.6082089552238805, "no_speech_prob": 4.539343717624433e-05}, {"id": 91, "seek": 37280, "start": 372.8, "end": 377.8, "text": " So Vite itself is not a custom bundler.", "tokens": [407, 691, 642, 2564, 307, 406, 257, 2375, 13882, 1918, 13], "temperature": 0.0, "avg_logprob": -0.14093692362809382, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.832420381717384e-05}, {"id": 92, "seek": 37280, "start": 375.8, "end": 380.8, "text": " It's just using other bundlers and putting it together in a unique way.", "tokens": [467, 311, 445, 1228, 661, 13882, 11977, 293, 3372, 309, 1214, 294, 257, 3845, 636, 13], "temperature": 0.0, "avg_logprob": -0.14093692362809382, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.832420381717384e-05}, {"id": 93, "seek": 37280, "start": 379.8, "end": 384.8, "text": " And what are ES modules and esbuild?", "tokens": [400, 437, 366, 12564, 16679, 293, 785, 11516, 30], "temperature": 0.0, "avg_logprob": -0.14093692362809382, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.832420381717384e-05}, {"id": 94, "seek": 37280, "start": 382.8, "end": 387.8, "text": " So esbuild is a tool written in Go for compiling JavaScript.", "tokens": [407, 785, 11516, 307, 257, 2290, 3720, 294, 1037, 337, 715, 4883, 15778, 13], "temperature": 0.0, "avg_logprob": -0.14093692362809382, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.832420381717384e-05}, {"id": 95, "seek": 37280, "start": 387.8, "end": 392.8, "text": " I don't have the specific details in front of me, but I've been told it's very fast.", "tokens": [286, 500, 380, 362, 264, 2685, 4365, 294, 1868, 295, 385, 11, 457, 286, 600, 668, 1907, 309, 311, 588, 2370, 13], "temperature": 0.0, "avg_logprob": -0.14093692362809382, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.832420381717384e-05}, {"id": 96, "seek": 37280, "start": 392.8, "end": 397.8, "text": " It's one of the up and coming ones.", "tokens": [467, 311, 472, 295, 264, 493, 293, 1348, 2306, 13], "temperature": 0.0, "avg_logprob": -0.14093692362809382, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.832420381717384e-05}, {"id": 97, "seek": 37280, "start": 394.8, "end": 399.8, "text": " I don't think it's reached a 1.0, but that's not something unfamiliar to us.", "tokens": [286, 500, 380, 519, 309, 311, 6488, 257, 502, 13, 15, 11, 457, 300, 311, 406, 746, 29415, 281, 505, 13], "temperature": 0.0, "avg_logprob": -0.14093692362809382, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.832420381717384e-05}, {"id": 98, "seek": 39980, "start": 399.8, "end": 404.8, "text": " Fair, fair.", "tokens": [12157, 11, 3143, 13], "temperature": 0.0, "avg_logprob": -0.17660380854751123, "compression_ratio": 1.594890510948905, "no_speech_prob": 1.9033651597055723e-06}, {"id": 99, "seek": 39980, "start": 401.8, "end": 406.8, "text": " That's what esbuild is.", "tokens": [663, 311, 437, 785, 11516, 307, 13], "temperature": 0.0, "avg_logprob": -0.17660380854751123, "compression_ratio": 1.594890510948905, "no_speech_prob": 1.9033651597055723e-06}, {"id": 100, "seek": 39980, "start": 402.8, "end": 407.8, "text": " It is specifically a bundler.", "tokens": [467, 307, 4682, 257, 13882, 1918, 13], "temperature": 0.0, "avg_logprob": -0.17660380854751123, "compression_ratio": 1.594890510948905, "no_speech_prob": 1.9033651597055723e-06}, {"id": 101, "seek": 39980, "start": 404.8, "end": 409.8, "text": " And the other bundler that's used is rollup.", "tokens": [400, 264, 661, 13882, 1918, 300, 311, 1143, 307, 3373, 1010, 13], "temperature": 0.0, "avg_logprob": -0.17660380854751123, "compression_ratio": 1.594890510948905, "no_speech_prob": 1.9033651597055723e-06}, {"id": 102, "seek": 39980, "start": 407.8, "end": 412.8, "text": " Rollup, or I guess you could say rollup.js, was created by Rich Harris of Svelte.", "tokens": [9926, 1010, 11, 420, 286, 2041, 291, 727, 584, 3373, 1010, 13, 25530, 11, 390, 2942, 538, 6781, 17426, 295, 318, 779, 975, 13], "temperature": 0.0, "avg_logprob": -0.17660380854751123, "compression_ratio": 1.594890510948905, "no_speech_prob": 1.9033651597055723e-06}, {"id": 103, "seek": 39980, "start": 413.8, "end": 418.8, "text": " And it's going off in its own direction at this point.", "tokens": [400, 309, 311, 516, 766, 294, 1080, 1065, 3513, 412, 341, 935, 13], "temperature": 0.0, "avg_logprob": -0.17660380854751123, "compression_ratio": 1.594890510948905, "no_speech_prob": 1.9033651597055723e-06}, {"id": 104, "seek": 39980, "start": 415.8, "end": 420.8, "text": " I don't think he's as involved as it used to be.", "tokens": [286, 500, 380, 519, 415, 311, 382, 3288, 382, 309, 1143, 281, 312, 13], "temperature": 0.0, "avg_logprob": -0.17660380854751123, "compression_ratio": 1.594890510948905, "no_speech_prob": 1.9033651597055723e-06}, {"id": 105, "seek": 39980, "start": 418.8, "end": 423.8, "text": " But that's what's used during the development experience.", "tokens": [583, 300, 311, 437, 311, 1143, 1830, 264, 3250, 1752, 13], "temperature": 0.0, "avg_logprob": -0.17660380854751123, "compression_ratio": 1.594890510948905, "no_speech_prob": 1.9033651597055723e-06}, {"id": 106, "seek": 39980, "start": 421.8, "end": 426.8, "text": " I find it helpful to compare Vite to Webpack because if you just try to define it,", "tokens": [286, 915, 309, 4961, 281, 6794, 691, 642, 281, 9573, 9539, 570, 498, 291, 445, 853, 281, 6964, 309, 11], "temperature": 0.0, "avg_logprob": -0.17660380854751123, "compression_ratio": 1.594890510948905, "no_speech_prob": 1.9033651597055723e-06}, {"id": 107, "seek": 42680, "start": 426.8, "end": 431.8, "text": " it's kind of like, is it a dev server?", "tokens": [309, 311, 733, 295, 411, 11, 307, 309, 257, 1905, 7154, 30], "temperature": 0.0, "avg_logprob": -0.1819281902128053, "compression_ratio": 1.6603773584905661, "no_speech_prob": 6.962172847124748e-06}, {"id": 108, "seek": 42680, "start": 429.8, "end": 434.8, "text": " Is it a bundler?", "tokens": [1119, 309, 257, 13882, 1918, 30], "temperature": 0.0, "avg_logprob": -0.1819281902128053, "compression_ratio": 1.6603773584905661, "no_speech_prob": 6.962172847124748e-06}, {"id": 109, "seek": 42680, "start": 430.8, "end": 435.8, "text": " What is it?", "tokens": [708, 307, 309, 30], "temperature": 0.0, "avg_logprob": -0.1819281902128053, "compression_ratio": 1.6603773584905661, "no_speech_prob": 6.962172847124748e-06}, {"id": 110, "seek": 42680, "start": 430.8, "end": 435.8, "text": " But if you think about Webpack, I imagine many of our listeners have used Webpack.", "tokens": [583, 498, 291, 519, 466, 9573, 9539, 11, 286, 3811, 867, 295, 527, 23274, 362, 1143, 9573, 9539, 13], "temperature": 0.0, "avg_logprob": -0.1819281902128053, "compression_ratio": 1.6603773584905661, "no_speech_prob": 6.962172847124748e-06}, {"id": 111, "seek": 42680, "start": 436.8, "end": 441.8, "text": " And you try to just set up Webpack.", "tokens": [400, 291, 853, 281, 445, 992, 493, 9573, 9539, 13], "temperature": 0.0, "avg_logprob": -0.1819281902128053, "compression_ratio": 1.6603773584905661, "no_speech_prob": 6.962172847124748e-06}, {"id": 112, "seek": 42680, "start": 439.8, "end": 444.8, "text": " You configure Webpack, you write a bunch of config files, you install a bunch of plugins.", "tokens": [509, 22162, 9573, 9539, 11, 291, 2464, 257, 3840, 295, 6662, 7098, 11, 291, 3625, 257, 3840, 295, 33759, 13], "temperature": 0.0, "avg_logprob": -0.1819281902128053, "compression_ratio": 1.6603773584905661, "no_speech_prob": 6.962172847124748e-06}, {"id": 113, "seek": 42680, "start": 447.8, "end": 452.8, "text": " And then if you're trying to bundle everything, you run the bundle command.", "tokens": [400, 550, 498, 291, 434, 1382, 281, 24438, 1203, 11, 291, 1190, 264, 24438, 5622, 13], "temperature": 0.0, "avg_logprob": -0.1819281902128053, "compression_ratio": 1.6603773584905661, "no_speech_prob": 6.962172847124748e-06}, {"id": 114, "seek": 45280, "start": 452.8, "end": 457.8, "text": " And then what if you want to run a dev server?", "tokens": [400, 550, 437, 498, 291, 528, 281, 1190, 257, 1905, 7154, 30], "temperature": 0.0, "avg_logprob": -0.2009644083457418, "compression_ratio": 1.696969696969697, "no_speech_prob": 5.173832960281288e-06}, {"id": 115, "seek": 45280, "start": 454.8, "end": 459.8, "text": " Then there's kind of like maybe another package or plugin you install that helps you get a dev server,", "tokens": [1396, 456, 311, 733, 295, 411, 1310, 1071, 7372, 420, 23407, 291, 3625, 300, 3665, 291, 483, 257, 1905, 7154, 11], "temperature": 0.0, "avg_logprob": -0.2009644083457418, "compression_ratio": 1.696969696969697, "no_speech_prob": 5.173832960281288e-06}, {"id": 116, "seek": 45280, "start": 460.8, "end": 465.8, "text": " but things kind of run differently.", "tokens": [457, 721, 733, 295, 1190, 7614, 13], "temperature": 0.0, "avg_logprob": -0.2009644083457418, "compression_ratio": 1.696969696969697, "no_speech_prob": 5.173832960281288e-06}, {"id": 117, "seek": 45280, "start": 462.8, "end": 467.8, "text": " So when you compare Vite to that history, I feel like one of the main problems that Vite solves,", "tokens": [407, 562, 291, 6794, 691, 642, 281, 300, 2503, 11, 286, 841, 411, 472, 295, 264, 2135, 2740, 300, 691, 642, 39890, 11], "temperature": 0.0, "avg_logprob": -0.2009644083457418, "compression_ratio": 1.696969696969697, "no_speech_prob": 5.173832960281288e-06}, {"id": 118, "seek": 45280, "start": 471.8, "end": 476.8, "text": " in contrast to Webpack, is it gives you an environment where you can run a dev server or you can run a build,", "tokens": [294, 8712, 281, 9573, 9539, 11, 307, 309, 2709, 291, 364, 2823, 689, 291, 393, 1190, 257, 1905, 7154, 420, 291, 393, 1190, 257, 1322, 11], "temperature": 0.0, "avg_logprob": -0.2009644083457418, "compression_ratio": 1.696969696969697, "no_speech_prob": 5.173832960281288e-06}, {"id": 119, "seek": 47680, "start": 476.8, "end": 481.8, "text": " and it uses kind of the same setup.", "tokens": [293, 309, 4960, 733, 295, 264, 912, 8657, 13], "temperature": 0.0, "avg_logprob": -0.18428828669529335, "compression_ratio": 1.6181102362204725, "no_speech_prob": 1.2805327969545033e-05}, {"id": 120, "seek": 47680, "start": 480.8, "end": 485.8, "text": " It will do more minification and things like that for the production build than it does in the dev server,", "tokens": [467, 486, 360, 544, 923, 3774, 293, 721, 411, 300, 337, 264, 4265, 1322, 813, 309, 775, 294, 264, 1905, 7154, 11], "temperature": 0.0, "avg_logprob": -0.18428828669529335, "compression_ratio": 1.6181102362204725, "no_speech_prob": 1.2805327969545033e-05}, {"id": 121, "seek": 47680, "start": 486.8, "end": 491.8, "text": " but you can sort of use your same setup.", "tokens": [457, 291, 393, 1333, 295, 764, 428, 912, 8657, 13], "temperature": 0.0, "avg_logprob": -0.18428828669529335, "compression_ratio": 1.6181102362204725, "no_speech_prob": 1.2805327969545033e-05}, {"id": 122, "seek": 47680, "start": 490.8, "end": 495.8, "text": " And there's less configuration to write compared to Webpack.", "tokens": [400, 456, 311, 1570, 11694, 281, 2464, 5347, 281, 9573, 9539, 13], "temperature": 0.0, "avg_logprob": -0.18428828669529335, "compression_ratio": 1.6181102362204725, "no_speech_prob": 1.2805327969545033e-05}, {"id": 123, "seek": 47680, "start": 494.8, "end": 499.8, "text": " That sounds accurate to me.", "tokens": [663, 3263, 8559, 281, 385, 13], "temperature": 0.0, "avg_logprob": -0.18428828669529335, "compression_ratio": 1.6181102362204725, "no_speech_prob": 1.2805327969545033e-05}, {"id": 124, "seek": 47680, "start": 496.8, "end": 501.8, "text": " The thought that I have looking at it is in the Elm ecosystem, we talk about JavaScript fatigue a lot when we're talking about JavaScript.", "tokens": [440, 1194, 300, 286, 362, 1237, 412, 309, 307, 294, 264, 2699, 76, 11311, 11, 321, 751, 466, 15778, 20574, 257, 688, 562, 321, 434, 1417, 466, 15778, 13], "temperature": 0.0, "avg_logprob": -0.18428828669529335, "compression_ratio": 1.6181102362204725, "no_speech_prob": 1.2805327969545033e-05}, {"id": 125, "seek": 50180, "start": 501.8, "end": 506.8, "text": " So if you're building a React application, you need React, and then you need Redux,", "tokens": [407, 498, 291, 434, 2390, 257, 30644, 3861, 11, 291, 643, 30644, 11, 293, 550, 291, 643, 4477, 2449, 11], "temperature": 0.0, "avg_logprob": -0.20158427311823918, "compression_ratio": 2.02262443438914, "no_speech_prob": 1.8630686099641025e-05}, {"id": 126, "seek": 50180, "start": 508.8, "end": 513.8, "text": " and then you need something else.", "tokens": [293, 550, 291, 643, 746, 1646, 13], "temperature": 0.0, "avg_logprob": -0.20158427311823918, "compression_ratio": 2.02262443438914, "no_speech_prob": 1.8630686099641025e-05}, {"id": 127, "seek": 50180, "start": 511.8, "end": 516.8, "text": " And if you want immutable data, you need something else.", "tokens": [400, 498, 291, 528, 3397, 32148, 1412, 11, 291, 643, 746, 1646, 13], "temperature": 0.0, "avg_logprob": -0.20158427311823918, "compression_ratio": 2.02262443438914, "no_speech_prob": 1.8630686099641025e-05}, {"id": 128, "seek": 50180, "start": 513.8, "end": 518.8, "text": " And if you want a linter, you need, and so on and so on and so on.", "tokens": [400, 498, 291, 528, 257, 287, 5106, 11, 291, 643, 11, 293, 370, 322, 293, 370, 322, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.20158427311823918, "compression_ratio": 2.02262443438914, "no_speech_prob": 1.8630686099641025e-05}, {"id": 129, "seek": 50180, "start": 516.8, "end": 521.8, "text": " Whereas Elm, it's just Elm.", "tokens": [13813, 2699, 76, 11, 309, 311, 445, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.20158427311823918, "compression_ratio": 2.02262443438914, "no_speech_prob": 1.8630686099641025e-05}, {"id": 130, "seek": 50180, "start": 518.8, "end": 523.8, "text": " And Vite kind of feels the same while remaining a JavaScript thing.", "tokens": [400, 691, 642, 733, 295, 3417, 264, 912, 1339, 8877, 257, 15778, 551, 13], "temperature": 0.0, "avg_logprob": -0.20158427311823918, "compression_ratio": 2.02262443438914, "no_speech_prob": 1.8630686099641025e-05}, {"id": 131, "seek": 50180, "start": 522.8, "end": 527.8, "text": " If you're needing to build an application, you're going to need a bundler.", "tokens": [759, 291, 434, 18006, 281, 1322, 364, 3861, 11, 291, 434, 516, 281, 643, 257, 13882, 1918, 13], "temperature": 0.0, "avg_logprob": -0.20158427311823918, "compression_ratio": 2.02262443438914, "no_speech_prob": 1.8630686099641025e-05}, {"id": 132, "seek": 50180, "start": 525.8, "end": 530.8, "text": " You're going to need a dev server.", "tokens": [509, 434, 516, 281, 643, 257, 1905, 7154, 13], "temperature": 0.0, "avg_logprob": -0.20158427311823918, "compression_ratio": 2.02262443438914, "no_speech_prob": 1.8630686099641025e-05}, {"id": 133, "seek": 53080, "start": 530.8, "end": 535.8, "text": " You're going to need to do hot module reload, ideally.", "tokens": [509, 434, 516, 281, 643, 281, 360, 2368, 10088, 25628, 11, 22915, 13], "temperature": 0.0, "avg_logprob": -0.2202663248235529, "compression_ratio": 1.573076923076923, "no_speech_prob": 1.3845826288161334e-05}, {"id": 134, "seek": 53080, "start": 533.8, "end": 538.8, "text": " And that's all very complicated.", "tokens": [400, 300, 311, 439, 588, 6179, 13], "temperature": 0.0, "avg_logprob": -0.2202663248235529, "compression_ratio": 1.573076923076923, "no_speech_prob": 1.3845826288161334e-05}, {"id": 135, "seek": 53080, "start": 535.8, "end": 540.8, "text": " And we can see how complicated it is in JavaScript because of things like create React app,", "tokens": [400, 321, 393, 536, 577, 6179, 309, 307, 294, 15778, 570, 295, 721, 411, 1884, 30644, 724, 11], "temperature": 0.0, "avg_logprob": -0.2202663248235529, "compression_ratio": 1.573076923076923, "no_speech_prob": 1.3845826288161334e-05}, {"id": 136, "seek": 53080, "start": 540.8, "end": 545.8, "text": " or in Vue 2.0, they had the Vue CLI, which also used Webpack.", "tokens": [420, 294, 691, 622, 568, 13, 15, 11, 436, 632, 264, 691, 622, 12855, 40, 11, 597, 611, 1143, 9573, 9539, 13], "temperature": 0.0, "avg_logprob": -0.2202663248235529, "compression_ratio": 1.573076923076923, "no_speech_prob": 1.3845826288161334e-05}, {"id": 137, "seek": 53080, "start": 545.8, "end": 550.8, "text": " So Vite is geared towards solving that problem where you have the dev server, you have the bundler,", "tokens": [407, 691, 642, 307, 35924, 3030, 12606, 300, 1154, 689, 291, 362, 264, 1905, 7154, 11, 291, 362, 264, 13882, 1918, 11], "temperature": 0.0, "avg_logprob": -0.2202663248235529, "compression_ratio": 1.573076923076923, "no_speech_prob": 1.3845826288161334e-05}, {"id": 138, "seek": 53080, "start": 551.8, "end": 556.8, "text": " you have everything that you need just kind of built into one tool.", "tokens": [291, 362, 1203, 300, 291, 643, 445, 733, 295, 3094, 666, 472, 2290, 13], "temperature": 0.0, "avg_logprob": -0.2202663248235529, "compression_ratio": 1.573076923076923, "no_speech_prob": 1.3845826288161334e-05}, {"id": 139, "seek": 55680, "start": 556.8, "end": 561.8, "text": " So can you sort of pick up things about your config?", "tokens": [407, 393, 291, 1333, 295, 1888, 493, 721, 466, 428, 6662, 30], "temperature": 0.0, "avg_logprob": -0.2473610526637027, "compression_ratio": 1.6266094420600858, "no_speech_prob": 1.2805325241060928e-05}, {"id": 140, "seek": 55680, "start": 560.8, "end": 565.8, "text": " For example, if you want to import TypeScript files,", "tokens": [1171, 1365, 11, 498, 291, 528, 281, 974, 15576, 14237, 7098, 11], "temperature": 0.0, "avg_logprob": -0.2473610526637027, "compression_ratio": 1.6266094420600858, "no_speech_prob": 1.2805325241060928e-05}, {"id": 141, "seek": 55680, "start": 566.8, "end": 571.8, "text": " then you don't need any special setup because ES build automatically can transpile TypeScript files,", "tokens": [550, 291, 500, 380, 643, 604, 2121, 8657, 570, 12564, 1322, 6772, 393, 7132, 794, 15576, 14237, 7098, 11], "temperature": 0.0, "avg_logprob": -0.2473610526637027, "compression_ratio": 1.6266094420600858, "no_speech_prob": 1.2805325241060928e-05}, {"id": 142, "seek": 55680, "start": 572.8, "end": 577.8, "text": " and it's built on top of ES build.", "tokens": [293, 309, 311, 3094, 322, 1192, 295, 12564, 1322, 13], "temperature": 0.0, "avg_logprob": -0.2473610526637027, "compression_ratio": 1.6266094420600858, "no_speech_prob": 1.2805325241060928e-05}, {"id": 143, "seek": 55680, "start": 574.8, "end": 579.8, "text": " So it will use your TS config, and it uses various configuration files", "tokens": [407, 309, 486, 764, 428, 37645, 6662, 11, 293, 309, 4960, 3683, 11694, 7098], "temperature": 0.0, "avg_logprob": -0.2473610526637027, "compression_ratio": 1.6266094420600858, "no_speech_prob": 1.2805325241060928e-05}, {"id": 144, "seek": 55680, "start": 580.8, "end": 585.8, "text": " and these standard conventions to run the bundling. Is that right?", "tokens": [293, 613, 3832, 33520, 281, 1190, 264, 13882, 1688, 13, 1119, 300, 558, 30], "temperature": 0.0, "avg_logprob": -0.2473610526637027, "compression_ratio": 1.6266094420600858, "no_speech_prob": 1.2805325241060928e-05}, {"id": 145, "seek": 58580, "start": 585.8, "end": 590.8, "text": " That's supported out of the box.", "tokens": [663, 311, 8104, 484, 295, 264, 2424, 13], "temperature": 0.0, "avg_logprob": -0.19467748006184896, "compression_ratio": 1.7557251908396947, "no_speech_prob": 2.178189424739685e-05}, {"id": 146, "seek": 58580, "start": 586.8, "end": 591.8, "text": " Other things are supported out of the box, such as WebAssembly.", "tokens": [5358, 721, 366, 8104, 484, 295, 264, 2424, 11, 1270, 382, 9573, 10884, 19160, 13], "temperature": 0.0, "avg_logprob": -0.19467748006184896, "compression_ratio": 1.7557251908396947, "no_speech_prob": 2.178189424739685e-05}, {"id": 147, "seek": 58580, "start": 589.8, "end": 594.8, "text": " You can just import a WebAssembly file and start it up in your application, and it works fine.", "tokens": [509, 393, 445, 974, 257, 9573, 10884, 19160, 3991, 293, 722, 309, 493, 294, 428, 3861, 11, 293, 309, 1985, 2489, 13], "temperature": 0.0, "avg_logprob": -0.19467748006184896, "compression_ratio": 1.7557251908396947, "no_speech_prob": 2.178189424739685e-05}, {"id": 148, "seek": 58580, "start": 595.8, "end": 600.8, "text": " You don't get hot module reload on WebAssembly, obviously,", "tokens": [509, 500, 380, 483, 2368, 10088, 25628, 322, 9573, 10884, 19160, 11, 2745, 11], "temperature": 0.0, "avg_logprob": -0.19467748006184896, "compression_ratio": 1.7557251908396947, "no_speech_prob": 2.178189424739685e-05}, {"id": 149, "seek": 58580, "start": 598.8, "end": 603.8, "text": " but you can import the WebAssembly file directly.", "tokens": [457, 291, 393, 974, 264, 9573, 10884, 19160, 3991, 3838, 13], "temperature": 0.0, "avg_logprob": -0.19467748006184896, "compression_ratio": 1.7557251908396947, "no_speech_prob": 2.178189424739685e-05}, {"id": 150, "seek": 58580, "start": 602.8, "end": 607.8, "text": " On TypeScript, though, one of the interesting notes is because of how Vite is handling it", "tokens": [1282, 15576, 14237, 11, 1673, 11, 472, 295, 264, 1880, 5570, 307, 570, 295, 577, 691, 642, 307, 13175, 309], "temperature": 0.0, "avg_logprob": -0.19467748006184896, "compression_ratio": 1.7557251908396947, "no_speech_prob": 2.178189424739685e-05}, {"id": 151, "seek": 58580, "start": 607.8, "end": 612.8, "text": " and passing the TypeScript file to ES build for the compilation step,", "tokens": [293, 8437, 264, 15576, 14237, 3991, 281, 12564, 1322, 337, 264, 40261, 1823, 11], "temperature": 0.0, "avg_logprob": -0.19467748006184896, "compression_ratio": 1.7557251908396947, "no_speech_prob": 2.178189424739685e-05}, {"id": 152, "seek": 61280, "start": 612.8, "end": 617.8, "text": " you don't need any actual type checking in your TypeScript.", "tokens": [291, 500, 380, 643, 604, 3539, 2010, 8568, 294, 428, 15576, 14237, 13], "temperature": 0.0, "avg_logprob": -0.20252550565279448, "compression_ratio": 1.6372549019607843, "no_speech_prob": 2.6425757368997438e-06}, {"id": 153, "seek": 61280, "start": 615.8, "end": 620.8, "text": " It's just performing the transpilation.", "tokens": [467, 311, 445, 10205, 264, 7132, 16067, 13], "temperature": 0.0, "avg_logprob": -0.20252550565279448, "compression_ratio": 1.6372549019607843, "no_speech_prob": 2.6425757368997438e-06}, {"id": 154, "seek": 61280, "start": 618.8, "end": 623.8, "text": " So if you're wanting the lovely type checking that we're used to,", "tokens": [407, 498, 291, 434, 7935, 264, 7496, 2010, 8568, 300, 321, 434, 1143, 281, 11], "temperature": 0.0, "avg_logprob": -0.20252550565279448, "compression_ratio": 1.6372549019607843, "no_speech_prob": 2.6425757368997438e-06}, {"id": 155, "seek": 61280, "start": 621.8, "end": 626.8, "text": " you need to set that up in your IDE.", "tokens": [291, 643, 281, 992, 300, 493, 294, 428, 40930, 13], "temperature": 0.0, "avg_logprob": -0.20252550565279448, "compression_ratio": 1.6372549019607843, "no_speech_prob": 2.6425757368997438e-06}, {"id": 156, "seek": 61280, "start": 624.8, "end": 629.8, "text": " Okay, or use a different terminal to run the TypeScript checker.", "tokens": [1033, 11, 420, 764, 257, 819, 14709, 281, 1190, 264, 15576, 14237, 1520, 260, 13], "temperature": 0.0, "avg_logprob": -0.20252550565279448, "compression_ratio": 1.6372549019607843, "no_speech_prob": 2.6425757368997438e-06}, {"id": 157, "seek": 61280, "start": 631.8, "end": 636.8, "text": " So I'm still confused as to why it's using two different bundlers,", "tokens": [407, 286, 478, 920, 9019, 382, 281, 983, 309, 311, 1228, 732, 819, 13882, 11977, 11], "temperature": 0.0, "avg_logprob": -0.20252550565279448, "compression_ratio": 1.6372549019607843, "no_speech_prob": 2.6425757368997438e-06}, {"id": 158, "seek": 63680, "start": 636.8, "end": 641.8, "text": " one in production and one in development mode.", "tokens": [472, 294, 4265, 293, 472, 294, 3250, 4391, 13], "temperature": 0.0, "avg_logprob": -0.1639415812942217, "compression_ratio": 1.7208333333333334, "no_speech_prob": 6.854239927633898e-06}, {"id": 159, "seek": 63680, "start": 638.8, "end": 643.8, "text": " Is it because ES build is only meant for production builds and rollup is meant for both,", "tokens": [1119, 309, 570, 12564, 1322, 307, 787, 4140, 337, 4265, 15182, 293, 3373, 1010, 307, 4140, 337, 1293, 11], "temperature": 0.0, "avg_logprob": -0.1639415812942217, "compression_ratio": 1.7208333333333334, "no_speech_prob": 6.854239927633898e-06}, {"id": 160, "seek": 63680, "start": 644.8, "end": 649.8, "text": " but it's not as good in production or something like that?", "tokens": [457, 309, 311, 406, 382, 665, 294, 4265, 420, 746, 411, 300, 30], "temperature": 0.0, "avg_logprob": -0.1639415812942217, "compression_ratio": 1.7208333333333334, "no_speech_prob": 6.854239927633898e-06}, {"id": 161, "seek": 63680, "start": 647.8, "end": 652.8, "text": " The main reason that Vite is using two different bundlers at the moment", "tokens": [440, 2135, 1778, 300, 691, 642, 307, 1228, 732, 819, 13882, 11977, 412, 264, 1623], "temperature": 0.0, "avg_logprob": -0.1639415812942217, "compression_ratio": 1.7208333333333334, "no_speech_prob": 6.854239927633898e-06}, {"id": 162, "seek": 63680, "start": 651.8, "end": 656.8, "text": " is because ES build is still under development.", "tokens": [307, 570, 12564, 1322, 307, 920, 833, 3250, 13], "temperature": 0.0, "avg_logprob": -0.1639415812942217, "compression_ratio": 1.7208333333333334, "no_speech_prob": 6.854239927633898e-06}, {"id": 163, "seek": 63680, "start": 653.8, "end": 658.8, "text": " It hasn't reached 1.0.", "tokens": [467, 6132, 380, 6488, 502, 13, 15, 13], "temperature": 0.0, "avg_logprob": -0.1639415812942217, "compression_ratio": 1.7208333333333334, "no_speech_prob": 6.854239927633898e-06}, {"id": 164, "seek": 63680, "start": 655.8, "end": 660.8, "text": " So while it's very fast, it can't handle everything at the best efficiency.", "tokens": [407, 1339, 309, 311, 588, 2370, 11, 309, 393, 380, 4813, 1203, 412, 264, 1151, 10493, 13], "temperature": 0.0, "avg_logprob": -0.1639415812942217, "compression_ratio": 1.7208333333333334, "no_speech_prob": 6.854239927633898e-06}, {"id": 165, "seek": 66080, "start": 660.8, "end": 665.8, "text": " So for the time being, Vite is using rollup and ES build", "tokens": [407, 337, 264, 565, 885, 11, 691, 642, 307, 1228, 3373, 1010, 293, 12564, 1322], "temperature": 0.0, "avg_logprob": -0.18191292089059813, "compression_ratio": 1.7073170731707317, "no_speech_prob": 1.2218528354424052e-05}, {"id": 166, "seek": 66080, "start": 665.8, "end": 670.8, "text": " for two different parts of the experience.", "tokens": [337, 732, 819, 3166, 295, 264, 1752, 13], "temperature": 0.0, "avg_logprob": -0.18191292089059813, "compression_ratio": 1.7073170731707317, "no_speech_prob": 1.2218528354424052e-05}, {"id": 167, "seek": 66080, "start": 668.8, "end": 673.8, "text": " The long-term plan is to settle on just one,", "tokens": [440, 938, 12, 7039, 1393, 307, 281, 11852, 322, 445, 472, 11], "temperature": 0.0, "avg_logprob": -0.18191292089059813, "compression_ratio": 1.7073170731707317, "no_speech_prob": 1.2218528354424052e-05}, {"id": 168, "seek": 66080, "start": 671.8, "end": 676.8, "text": " and that's probably going to end up being ES build because of its speed.", "tokens": [293, 300, 311, 1391, 516, 281, 917, 493, 885, 12564, 1322, 570, 295, 1080, 3073, 13], "temperature": 0.0, "avg_logprob": -0.18191292089059813, "compression_ratio": 1.7073170731707317, "no_speech_prob": 1.2218528354424052e-05}, {"id": 169, "seek": 66080, "start": 674.8, "end": 679.8, "text": " But for the time being, they're still having to use the two.", "tokens": [583, 337, 264, 565, 885, 11, 436, 434, 920, 1419, 281, 764, 264, 732, 13], "temperature": 0.0, "avg_logprob": -0.18191292089059813, "compression_ratio": 1.7073170731707317, "no_speech_prob": 1.2218528354424052e-05}, {"id": 170, "seek": 66080, "start": 677.8, "end": 682.8, "text": " There's also the nice benefit with that of having the plugin ecosystem", "tokens": [821, 311, 611, 264, 1481, 5121, 365, 300, 295, 1419, 264, 23407, 11311], "temperature": 0.0, "avg_logprob": -0.18191292089059813, "compression_ratio": 1.7073170731707317, "no_speech_prob": 1.2218528354424052e-05}, {"id": 171, "seek": 66080, "start": 683.8, "end": 688.8, "text": " that incorporates Vite specific features, but also the rollup plugins.", "tokens": [300, 50193, 691, 642, 2685, 4122, 11, 457, 611, 264, 3373, 1010, 33759, 13], "temperature": 0.0, "avg_logprob": -0.18191292089059813, "compression_ratio": 1.7073170731707317, "no_speech_prob": 1.2218528354424052e-05}, {"id": 172, "seek": 68880, "start": 688.8, "end": 693.8, "text": " So if you want to use a rollup plugin in Vite,", "tokens": [407, 498, 291, 528, 281, 764, 257, 3373, 1010, 23407, 294, 691, 642, 11], "temperature": 0.0, "avg_logprob": -0.18689415671608664, "compression_ratio": 1.5527272727272727, "no_speech_prob": 1.4510234905174002e-05}, {"id": 173, "seek": 68880, "start": 691.8, "end": 696.8, "text": " you can just import it and use it as normal.", "tokens": [291, 393, 445, 974, 309, 293, 764, 309, 382, 2710, 13], "temperature": 0.0, "avg_logprob": -0.18689415671608664, "compression_ratio": 1.5527272727272727, "no_speech_prob": 1.4510234905174002e-05}, {"id": 174, "seek": 68880, "start": 693.8, "end": 698.8, "text": " You don't have to worry about, is this compatible?", "tokens": [509, 500, 380, 362, 281, 3292, 466, 11, 307, 341, 18218, 30], "temperature": 0.0, "avg_logprob": -0.18689415671608664, "compression_ratio": 1.5527272727272727, "no_speech_prob": 1.4510234905174002e-05}, {"id": 175, "seek": 68880, "start": 696.8, "end": 701.8, "text": " Because it just is.", "tokens": [1436, 309, 445, 307, 13], "temperature": 0.0, "avg_logprob": -0.18689415671608664, "compression_ratio": 1.5527272727272727, "no_speech_prob": 1.4510234905174002e-05}, {"id": 176, "seek": 68880, "start": 698.8, "end": 703.8, "text": " But only in development mode?", "tokens": [583, 787, 294, 3250, 4391, 30], "temperature": 0.0, "avg_logprob": -0.18689415671608664, "compression_ratio": 1.5527272727272727, "no_speech_prob": 1.4510234905174002e-05}, {"id": 177, "seek": 68880, "start": 699.8, "end": 704.8, "text": " It will still work in production.", "tokens": [467, 486, 920, 589, 294, 4265, 13], "temperature": 0.0, "avg_logprob": -0.18689415671608664, "compression_ratio": 1.5527272727272727, "no_speech_prob": 1.4510234905174002e-05}, {"id": 178, "seek": 68880, "start": 701.8, "end": 706.8, "text": " I cannot speak to how it does that magic, but I know it does.", "tokens": [286, 2644, 1710, 281, 577, 309, 775, 300, 5585, 11, 457, 286, 458, 309, 775, 13], "temperature": 0.0, "avg_logprob": -0.18689415671608664, "compression_ratio": 1.5527272727272727, "no_speech_prob": 1.4510234905174002e-05}, {"id": 179, "seek": 68880, "start": 704.8, "end": 709.8, "text": " Oh, interesting.", "tokens": [876, 11, 1880, 13], "temperature": 0.0, "avg_logprob": -0.18689415671608664, "compression_ratio": 1.5527272727272727, "no_speech_prob": 1.4510234905174002e-05}, {"id": 180, "seek": 68880, "start": 705.8, "end": 710.8, "text": " So that's interesting because I imagine many people do associate ES build", "tokens": [407, 300, 311, 1880, 570, 286, 3811, 867, 561, 360, 14644, 12564, 1322], "temperature": 0.0, "avg_logprob": -0.18689415671608664, "compression_ratio": 1.5527272727272727, "no_speech_prob": 1.4510234905174002e-05}, {"id": 181, "seek": 68880, "start": 711.8, "end": 716.8, "text": " with being like a JS and TypeScript transpiler.", "tokens": [365, 885, 411, 257, 33063, 293, 15576, 14237, 7132, 5441, 13], "temperature": 0.0, "avg_logprob": -0.18689415671608664, "compression_ratio": 1.5527272727272727, "no_speech_prob": 1.4510234905174002e-05}, {"id": 182, "seek": 71680, "start": 716.8, "end": 721.8, "text": " I have seen in the docs things about CSS files,", "tokens": [286, 362, 1612, 294, 264, 45623, 721, 466, 24387, 7098, 11], "temperature": 0.0, "avg_logprob": -0.19238214289888422, "compression_ratio": 1.4057971014492754, "no_speech_prob": 1.4285124052548781e-05}, {"id": 183, "seek": 71680, "start": 720.8, "end": 725.8, "text": " so I guess it is a general purpose bundler as well.", "tokens": [370, 286, 2041, 309, 307, 257, 2674, 4334, 13882, 1918, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.19238214289888422, "compression_ratio": 1.4057971014492754, "no_speech_prob": 1.4285124052548781e-05}, {"id": 184, "seek": 71680, "start": 724.8, "end": 729.8, "text": " That's interesting.", "tokens": [663, 311, 1880, 13], "temperature": 0.0, "avg_logprob": -0.19238214289888422, "compression_ratio": 1.4057971014492754, "no_speech_prob": 1.4285124052548781e-05}, {"id": 185, "seek": 71680, "start": 725.8, "end": 730.8, "text": " ES build?", "tokens": [12564, 1322, 30], "temperature": 0.0, "avg_logprob": -0.19238214289888422, "compression_ratio": 1.4057971014492754, "no_speech_prob": 1.4285124052548781e-05}, {"id": 186, "seek": 71680, "start": 726.8, "end": 731.8, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.19238214289888422, "compression_ratio": 1.4057971014492754, "no_speech_prob": 1.4285124052548781e-05}, {"id": 187, "seek": 71680, "start": 727.8, "end": 732.8, "text": " I believe that is the long-term goal.", "tokens": [286, 1697, 300, 307, 264, 938, 12, 7039, 3387, 13], "temperature": 0.0, "avg_logprob": -0.19238214289888422, "compression_ratio": 1.4057971014492754, "no_speech_prob": 1.4285124052548781e-05}, {"id": 188, "seek": 71680, "start": 730.8, "end": 735.8, "text": " I'm not 100% on that.", "tokens": [286, 478, 406, 2319, 4, 322, 300, 13], "temperature": 0.0, "avg_logprob": -0.19238214289888422, "compression_ratio": 1.4057971014492754, "no_speech_prob": 1.4285124052548781e-05}, {"id": 189, "seek": 71680, "start": 733.8, "end": 738.8, "text": " I write applications.", "tokens": [286, 2464, 5821, 13], "temperature": 0.0, "avg_logprob": -0.19238214289888422, "compression_ratio": 1.4057971014492754, "no_speech_prob": 1.4285124052548781e-05}, {"id": 190, "seek": 71680, "start": 735.8, "end": 740.8, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.19238214289888422, "compression_ratio": 1.4057971014492754, "no_speech_prob": 1.4285124052548781e-05}, {"id": 191, "seek": 71680, "start": 737.8, "end": 742.8, "text": " It seems like a real trend I'm seeing these days in the JS ecosystem", "tokens": [467, 2544, 411, 257, 957, 6028, 286, 478, 2577, 613, 1708, 294, 264, 33063, 11311], "temperature": 0.0, "avg_logprob": -0.19238214289888422, "compression_ratio": 1.4057971014492754, "no_speech_prob": 1.4285124052548781e-05}, {"id": 192, "seek": 74280, "start": 742.8, "end": 747.8, "text": " is trying to come up with a set of agreed upon standards", "tokens": [307, 1382, 281, 808, 493, 365, 257, 992, 295, 9166, 3564, 7787], "temperature": 0.0, "avg_logprob": -0.23112817244096237, "compression_ratio": 1.48, "no_speech_prob": 3.321222175145522e-05}, {"id": 193, "seek": 74280, "start": 747.8, "end": 752.8, "text": " rather than just everything having bespoke approaches to things.", "tokens": [2831, 813, 445, 1203, 1419, 4097, 48776, 11587, 281, 721, 13], "temperature": 0.0, "avg_logprob": -0.23112817244096237, "compression_ratio": 1.48, "no_speech_prob": 3.321222175145522e-05}, {"id": 194, "seek": 74280, "start": 752.8, "end": 757.8, "text": " So rollup plugins have a specific format and Vite said,", "tokens": [407, 3373, 1010, 33759, 362, 257, 2685, 7877, 293, 691, 642, 848, 11], "temperature": 0.0, "avg_logprob": -0.23112817244096237, "compression_ratio": 1.48, "no_speech_prob": 3.321222175145522e-05}, {"id": 195, "seek": 74280, "start": 758.8, "end": 763.8, "text": " okay, well, there's this sort of plugin API and let's just use that same", "tokens": [1392, 11, 731, 11, 456, 311, 341, 1333, 295, 23407, 9362, 293, 718, 311, 445, 764, 300, 912], "temperature": 0.0, "avg_logprob": -0.23112817244096237, "compression_ratio": 1.48, "no_speech_prob": 3.321222175145522e-05}, {"id": 196, "seek": 74280, "start": 764.8, "end": 769.8, "text": " API. And if we're using that same convention,", "tokens": [9362, 13, 400, 498, 321, 434, 1228, 300, 912, 10286, 11], "temperature": 0.0, "avg_logprob": -0.23112817244096237, "compression_ratio": 1.48, "no_speech_prob": 3.321222175145522e-05}, {"id": 197, "seek": 76980, "start": 769.8, "end": 774.8, "text": " we can use ES build and for the dev server and everything can play nicer", "tokens": [321, 393, 764, 12564, 1322, 293, 337, 264, 1905, 7154, 293, 1203, 393, 862, 22842], "temperature": 0.0, "avg_logprob": -0.2407761699748489, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.922296723932959e-05}, {"id": 198, "seek": 76980, "start": 773.8, "end": 778.8, "text": " together because they're using the same conventions.", "tokens": [1214, 570, 436, 434, 1228, 264, 912, 33520, 13], "temperature": 0.0, "avg_logprob": -0.2407761699748489, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.922296723932959e-05}, {"id": 199, "seek": 76980, "start": 776.8, "end": 781.8, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2407761699748489, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.922296723932959e-05}, {"id": 200, "seek": 76980, "start": 777.8, "end": 782.8, "text": " One of the big pushes was not having to worry about a development", "tokens": [1485, 295, 264, 955, 21020, 390, 406, 1419, 281, 3292, 466, 257, 3250], "temperature": 0.0, "avg_logprob": -0.2407761699748489, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.922296723932959e-05}, {"id": 201, "seek": 76980, "start": 780.8, "end": 785.8, "text": " configuration and a production configuration.", "tokens": [11694, 293, 257, 4265, 11694, 13], "temperature": 0.0, "avg_logprob": -0.2407761699748489, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.922296723932959e-05}, {"id": 202, "seek": 76980, "start": 783.8, "end": 788.8, "text": " And one of the other niceties was there's a project called Vitest,", "tokens": [400, 472, 295, 264, 661, 6201, 43469, 390, 456, 311, 257, 1716, 1219, 691, 642, 372, 11], "temperature": 0.0, "avg_logprob": -0.2407761699748489, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.922296723932959e-05}, {"id": 203, "seek": 76980, "start": 789.8, "end": 794.8, "text": " which is just going to throw the French out the window again.", "tokens": [597, 307, 445, 516, 281, 3507, 264, 5522, 484, 264, 4910, 797, 13], "temperature": 0.0, "avg_logprob": -0.2407761699748489, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.922296723932959e-05}, {"id": 204, "seek": 76980, "start": 791.8, "end": 796.8, "text": " I mean, that's not even a French word at all.", "tokens": [286, 914, 11, 300, 311, 406, 754, 257, 5522, 1349, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.2407761699748489, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.922296723932959e-05}, {"id": 205, "seek": 79680, "start": 796.8, "end": 801.8, "text": " It just means you have to pronounce the first bit wrong.", "tokens": [467, 445, 1355, 291, 362, 281, 19567, 264, 700, 857, 2085, 13], "temperature": 0.0, "avg_logprob": -0.20201804751441593, "compression_ratio": 1.632, "no_speech_prob": 2.7106878405902535e-05}, {"id": 206, "seek": 79680, "start": 799.8, "end": 804.8, "text": " It might be a double entendre though, which is not a French idiom, I think.", "tokens": [467, 1062, 312, 257, 3834, 16612, 265, 1673, 11, 597, 307, 406, 257, 5522, 18014, 298, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.20201804751441593, "compression_ratio": 1.632, "no_speech_prob": 2.7106878405902535e-05}, {"id": 207, "seek": 79680, "start": 803.8, "end": 808.8, "text": " Of course not.", "tokens": [2720, 1164, 406, 13], "temperature": 0.0, "avg_logprob": -0.20201804751441593, "compression_ratio": 1.632, "no_speech_prob": 2.7106878405902535e-05}, {"id": 208, "seek": 79680, "start": 807.8, "end": 812.8, "text": " But Vitest is intended as a replacement for something like Jest.", "tokens": [583, 691, 642, 372, 307, 10226, 382, 257, 14419, 337, 746, 411, 24918, 13], "temperature": 0.0, "avg_logprob": -0.20201804751441593, "compression_ratio": 1.632, "no_speech_prob": 2.7106878405902535e-05}, {"id": 209, "seek": 79680, "start": 812.8, "end": 817.8, "text": " So instead of having to do all of your testing in Webpack and have a", "tokens": [407, 2602, 295, 1419, 281, 360, 439, 295, 428, 4997, 294, 9573, 9539, 293, 362, 257], "temperature": 0.0, "avg_logprob": -0.20201804751441593, "compression_ratio": 1.632, "no_speech_prob": 2.7106878405902535e-05}, {"id": 210, "seek": 79680, "start": 816.8, "end": 821.8, "text": " separate configuration for your tests from the application,", "tokens": [4994, 11694, 337, 428, 6921, 490, 264, 3861, 11], "temperature": 0.0, "avg_logprob": -0.20201804751441593, "compression_ratio": 1.632, "no_speech_prob": 2.7106878405902535e-05}, {"id": 211, "seek": 79680, "start": 819.8, "end": 824.8, "text": " you can just use your global Vite configuration, write your tests,", "tokens": [291, 393, 445, 764, 428, 4338, 691, 642, 11694, 11, 2464, 428, 6921, 11], "temperature": 0.0, "avg_logprob": -0.20201804751441593, "compression_ratio": 1.632, "no_speech_prob": 2.7106878405902535e-05}, {"id": 212, "seek": 82480, "start": 824.8, "end": 829.8, "text": " and everything just works.", "tokens": [293, 1203, 445, 1985, 13], "temperature": 0.0, "avg_logprob": -0.1784072754875062, "compression_ratio": 1.6953125, "no_speech_prob": 1.5205970157694537e-05}, {"id": 213, "seek": 82480, "start": 826.8, "end": 831.8, "text": " I saw the name a few times before, Vitest, but I never understood", "tokens": [286, 1866, 264, 1315, 257, 1326, 1413, 949, 11, 691, 642, 372, 11, 457, 286, 1128, 7320], "temperature": 0.0, "avg_logprob": -0.1784072754875062, "compression_ratio": 1.6953125, "no_speech_prob": 1.5205970157694537e-05}, {"id": 214, "seek": 82480, "start": 830.8, "end": 835.8, "text": " that it was a test framework.", "tokens": [300, 309, 390, 257, 1500, 8388, 13], "temperature": 0.0, "avg_logprob": -0.1784072754875062, "compression_ratio": 1.6953125, "no_speech_prob": 1.5205970157694537e-05}, {"id": 215, "seek": 82480, "start": 832.8, "end": 837.8, "text": " I just thought it was, well, Vite means fast, so Vitest is fastest.", "tokens": [286, 445, 1194, 309, 390, 11, 731, 11, 691, 642, 1355, 2370, 11, 370, 691, 642, 372, 307, 14573, 13], "temperature": 0.0, "avg_logprob": -0.1784072754875062, "compression_ratio": 1.6953125, "no_speech_prob": 1.5205970157694537e-05}, {"id": 216, "seek": 82480, "start": 837.8, "end": 842.8, "text": " So it's something to make things faster again or something.", "tokens": [407, 309, 311, 746, 281, 652, 721, 4663, 797, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.1784072754875062, "compression_ratio": 1.6953125, "no_speech_prob": 1.5205970157694537e-05}, {"id": 217, "seek": 82480, "start": 840.8, "end": 845.8, "text": " Okay, it's a test framework. Gotcha.", "tokens": [1033, 11, 309, 311, 257, 1500, 8388, 13, 42109, 13], "temperature": 0.0, "avg_logprob": -0.1784072754875062, "compression_ratio": 1.6953125, "no_speech_prob": 1.5205970157694537e-05}, {"id": 218, "seek": 82480, "start": 843.8, "end": 848.8, "text": " Yeah, and that was created by Anthony Foo, who is on the core team for Vite.", "tokens": [865, 11, 293, 300, 390, 2942, 538, 15853, 479, 1986, 11, 567, 307, 322, 264, 4965, 1469, 337, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.1784072754875062, "compression_ratio": 1.6953125, "no_speech_prob": 1.5205970157694537e-05}, {"id": 219, "seek": 82480, "start": 847.8, "end": 852.8, "text": " He's been extremely prolific in creating tooling around Vue and Vite.", "tokens": [634, 311, 668, 4664, 24398, 1089, 294, 4084, 46593, 926, 691, 622, 293, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.1784072754875062, "compression_ratio": 1.6953125, "no_speech_prob": 1.5205970157694537e-05}, {"id": 220, "seek": 85280, "start": 852.8, "end": 857.8, "text": " Definitely if you're interested in this ecosystem, I would suggest checking him out.", "tokens": [12151, 498, 291, 434, 3102, 294, 341, 11311, 11, 286, 576, 3402, 8568, 796, 484, 13], "temperature": 0.0, "avg_logprob": -0.18743709453101298, "compression_ratio": 1.550185873605948, "no_speech_prob": 1.7777265384211205e-05}, {"id": 221, "seek": 85280, "start": 856.8, "end": 861.8, "text": " Yeah, it's been extremely active.", "tokens": [865, 11, 309, 311, 668, 4664, 4967, 13], "temperature": 0.0, "avg_logprob": -0.18743709453101298, "compression_ratio": 1.550185873605948, "no_speech_prob": 1.7777265384211205e-05}, {"id": 222, "seek": 85280, "start": 858.8, "end": 863.8, "text": " Vite is just such a well-supported tool these days.", "tokens": [691, 642, 307, 445, 1270, 257, 731, 12, 36622, 14813, 2290, 613, 1708, 13], "temperature": 0.0, "avg_logprob": -0.18743709453101298, "compression_ratio": 1.550185873605948, "no_speech_prob": 1.7777265384211205e-05}, {"id": 223, "seek": 85280, "start": 861.8, "end": 866.8, "text": " I know TurboPack was recently announced, and then there were some somewhat", "tokens": [286, 458, 35848, 47, 501, 390, 3938, 7548, 11, 293, 550, 456, 645, 512, 8344], "temperature": 0.0, "avg_logprob": -0.18743709453101298, "compression_ratio": 1.550185873605948, "no_speech_prob": 1.7777265384211205e-05}, {"id": 224, "seek": 85280, "start": 866.8, "end": 871.8, "text": " controversial figures that were given.", "tokens": [17323, 9624, 300, 645, 2212, 13], "temperature": 0.0, "avg_logprob": -0.18743709453101298, "compression_ratio": 1.550185873605948, "no_speech_prob": 1.7777265384211205e-05}, {"id": 225, "seek": 85280, "start": 868.8, "end": 873.8, "text": " I know Evan, you had some things to say about the methods for coming up", "tokens": [286, 458, 22613, 11, 291, 632, 512, 721, 281, 584, 466, 264, 7150, 337, 1348, 493], "temperature": 0.0, "avg_logprob": -0.18743709453101298, "compression_ratio": 1.550185873605948, "no_speech_prob": 1.7777265384211205e-05}, {"id": 226, "seek": 85280, "start": 874.8, "end": 879.8, "text": " with these benchmark comparisons between TurboPack and Vite.", "tokens": [365, 613, 18927, 33157, 1296, 35848, 47, 501, 293, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.18743709453101298, "compression_ratio": 1.550185873605948, "no_speech_prob": 1.7777265384211205e-05}, {"id": 227, "seek": 87980, "start": 879.8, "end": 884.8, "text": " It's just like Vite is so well-maintained that I'm not ready to jump onto a new train at this point.", "tokens": [467, 311, 445, 411, 691, 642, 307, 370, 731, 12, 76, 5114, 3563, 300, 286, 478, 406, 1919, 281, 3012, 3911, 257, 777, 3847, 412, 341, 935, 13], "temperature": 0.0, "avg_logprob": -0.2376637231735956, "compression_ratio": 1.5644444444444445, "no_speech_prob": 5.224696360528469e-05}, {"id": 228, "seek": 87980, "start": 887.8, "end": 892.8, "text": " Vite seems great, and it seems like an agreed-upon standard, and it uses these standard conventions.", "tokens": [691, 642, 2544, 869, 11, 293, 309, 2544, 411, 364, 9166, 12, 1010, 266, 3832, 11, 293, 309, 4960, 613, 3832, 33520, 13], "temperature": 0.0, "avg_logprob": -0.2376637231735956, "compression_ratio": 1.5644444444444445, "no_speech_prob": 5.224696360528469e-05}, {"id": 229, "seek": 87980, "start": 893.8, "end": 898.8, "text": " So I'm all on board for Vite, personally.", "tokens": [407, 286, 478, 439, 322, 3150, 337, 691, 642, 11, 5665, 13], "temperature": 0.0, "avg_logprob": -0.2376637231735956, "compression_ratio": 1.5644444444444445, "no_speech_prob": 5.224696360528469e-05}, {"id": 230, "seek": 87980, "start": 896.8, "end": 901.8, "text": " Have you tried it on a few projects at all?", "tokens": [3560, 291, 3031, 309, 322, 257, 1326, 4455, 412, 439, 30], "temperature": 0.0, "avg_logprob": -0.2376637231735956, "compression_ratio": 1.5644444444444445, "no_speech_prob": 5.224696360528469e-05}, {"id": 231, "seek": 87980, "start": 899.8, "end": 904.8, "text": " I use it internally for Elm pages for the V3 beta. I'm using it.", "tokens": [286, 764, 309, 19501, 337, 2699, 76, 7183, 337, 264, 691, 18, 9861, 13, 286, 478, 1228, 309, 13], "temperature": 0.0, "avg_logprob": -0.2376637231735956, "compression_ratio": 1.5644444444444445, "no_speech_prob": 5.224696360528469e-05}, {"id": 232, "seek": 90480, "start": 904.8, "end": 909.8, "text": " There's an SSR mode that tooling authors can use to serve up pages.", "tokens": [821, 311, 364, 12238, 49, 4391, 300, 46593, 16552, 393, 764, 281, 4596, 493, 7183, 13], "temperature": 0.0, "avg_logprob": -0.2612969534737723, "compression_ratio": 1.4871794871794872, "no_speech_prob": 2.046199188043829e-05}, {"id": 233, "seek": 90480, "start": 910.8, "end": 915.8, "text": " So yeah, Elm pages V3 comes completely with a built-in Vite server.", "tokens": [407, 1338, 11, 2699, 76, 7183, 691, 18, 1487, 2584, 365, 257, 3094, 12, 259, 691, 642, 7154, 13], "temperature": 0.0, "avg_logprob": -0.2612969534737723, "compression_ratio": 1.4871794871794872, "no_speech_prob": 2.046199188043829e-05}, {"id": 234, "seek": 90480, "start": 916.8, "end": 921.8, "text": " So you can use it to have SCSS files or tailwind configuration, or import TypeScript code into your entry-point JavaScript file in your Elm pages project.", "tokens": [407, 291, 393, 764, 309, 281, 362, 9028, 21929, 7098, 420, 6838, 12199, 11694, 11, 420, 974, 15576, 14237, 3089, 666, 428, 8729, 12, 6053, 15778, 3991, 294, 428, 2699, 76, 7183, 1716, 13], "temperature": 0.0, "avg_logprob": -0.2612969534737723, "compression_ratio": 1.4871794871794872, "no_speech_prob": 2.046199188043829e-05}, {"id": 235, "seek": 92180, "start": 921.8, "end": 926.8, "text": " It all just works out of the box.", "tokens": [467, 439, 445, 1985, 484, 295, 264, 2424, 13], "temperature": 0.0, "avg_logprob": -0.39873724272756866, "compression_ratio": 1.3793103448275863, "no_speech_prob": 1.0129763722943608e-05}, {"id": 236, "seek": 92180, "start": 932.8, "end": 937.8, "text": " Back in Elm pages V2, I became somewhat disillusioned by the whole webpack world.", "tokens": [5833, 294, 2699, 76, 7183, 691, 17, 11, 286, 3062, 8344, 717, 373, 5704, 292, 538, 264, 1379, 3670, 9539, 1002, 13], "temperature": 0.0, "avg_logprob": -0.39873724272756866, "compression_ratio": 1.3793103448275863, "no_speech_prob": 1.0129763722943608e-05}, {"id": 237, "seek": 93780, "start": 937.8, "end": 947.8, "text": " Some tools, some front-end frameworks like Gatsby and things like that, would expose ways to add your own webpack plugins so you could hook into the webpack internals.", "tokens": [2188, 3873, 11, 512, 1868, 12, 521, 29834, 411, 460, 1720, 2322, 293, 721, 411, 300, 11, 576, 19219, 2098, 281, 909, 428, 1065, 3670, 9539, 33759, 370, 291, 727, 6328, 666, 264, 3670, 9539, 2154, 1124, 13], "temperature": 0.0, "avg_logprob": -0.26936984407729, "compression_ratio": 1.5698924731182795, "no_speech_prob": 3.26854751619976e-05}, {"id": 238, "seek": 93780, "start": 957.8, "end": 962.8, "text": " That just felt like such a weird inversion where you can mess up internals in a way that could actually break the framework.", "tokens": [663, 445, 2762, 411, 1270, 257, 3657, 43576, 689, 291, 393, 2082, 493, 2154, 1124, 294, 257, 636, 300, 727, 767, 1821, 264, 8388, 13], "temperature": 0.0, "avg_logprob": -0.26936984407729, "compression_ratio": 1.5698924731182795, "no_speech_prob": 3.26854751619976e-05}, {"id": 239, "seek": 96280, "start": 962.8, "end": 967.8, "text": " That didn't feel right.", "tokens": [663, 994, 380, 841, 558, 13], "temperature": 0.0, "avg_logprob": -0.24360380067930118, "compression_ratio": 1.6266094420600858, "no_speech_prob": 2.3550319383502938e-05}, {"id": 240, "seek": 96280, "start": 968.8, "end": 973.8, "text": " And then it felt like there are so many possible configurations people could build.", "tokens": [400, 550, 309, 2762, 411, 456, 366, 370, 867, 1944, 31493, 561, 727, 1322, 13], "temperature": 0.0, "avg_logprob": -0.24360380067930118, "compression_ratio": 1.6266094420600858, "no_speech_prob": 2.3550319383502938e-05}, {"id": 241, "seek": 96280, "start": 973.8, "end": 978.8, "text": " I just came to this conclusion, Elm pages is going to focus on just compiling your Elm code and setting up everything and just focusing on that.", "tokens": [286, 445, 1361, 281, 341, 10063, 11, 2699, 76, 7183, 307, 516, 281, 1879, 322, 445, 715, 4883, 428, 2699, 76, 3089, 293, 3287, 493, 1203, 293, 445, 8416, 322, 300, 13], "temperature": 0.0, "avg_logprob": -0.24360380067930118, "compression_ratio": 1.6266094420600858, "no_speech_prob": 2.3550319383502938e-05}, {"id": 242, "seek": 96280, "start": 982.8, "end": 987.8, "text": " If you want SCSS files, if you want to import TypeScript files, there's a TypeScript compiler that turns that into JavaScript.", "tokens": [759, 291, 528, 9028, 21929, 7098, 11, 498, 291, 528, 281, 974, 15576, 14237, 7098, 11, 456, 311, 257, 15576, 14237, 31958, 300, 4523, 300, 666, 15778, 13], "temperature": 0.0, "avg_logprob": -0.24360380067930118, "compression_ratio": 1.6266094420600858, "no_speech_prob": 2.3550319383502938e-05}, {"id": 243, "seek": 98780, "start": 987.8, "end": 992.8, "text": " There's an SCSS compiler that turns that into CSS files.", "tokens": [821, 311, 364, 9028, 21929, 31958, 300, 4523, 300, 666, 24387, 7098, 13], "temperature": 0.0, "avg_logprob": -0.3355096373895202, "compression_ratio": 1.5612648221343874, "no_speech_prob": 3.426511830184609e-05}, {"id": 244, "seek": 98780, "start": 992.8, "end": 997.8, "text": " And Elm pages doesn't care how you get your CSS and JavaScript files to it, but that's the only thing it understands.", "tokens": [400, 2699, 76, 7183, 1177, 380, 1127, 577, 291, 483, 428, 24387, 293, 15778, 7098, 281, 309, 11, 457, 300, 311, 264, 787, 551, 309, 15146, 13], "temperature": 0.0, "avg_logprob": -0.3355096373895202, "compression_ratio": 1.5612648221343874, "no_speech_prob": 3.426511830184609e-05}, {"id": 245, "seek": 98780, "start": 998.8, "end": 1003.8, "text": " I called it a bring your own bundler philosophy.", "tokens": [286, 1219, 309, 257, 1565, 428, 1065, 13882, 1918, 10675, 13], "temperature": 0.0, "avg_logprob": -0.3355096373895202, "compression_ratio": 1.5612648221343874, "no_speech_prob": 3.426511830184609e-05}, {"id": 246, "seek": 98780, "start": 1003.8, "end": 1008.8, "text": " But Vite completely changed my perspective on that because it came with this sort of standards-based approach where it's like, if you have an SCSS file, you can import it.", "tokens": [583, 691, 642, 2584, 3105, 452, 4585, 322, 300, 570, 309, 1361, 365, 341, 1333, 295, 7787, 12, 6032, 3109, 689, 309, 311, 411, 11, 498, 291, 362, 364, 9028, 21929, 3991, 11, 291, 393, 974, 309, 13], "temperature": 0.0, "avg_logprob": -0.3355096373895202, "compression_ratio": 1.5612648221343874, "no_speech_prob": 3.426511830184609e-05}, {"id": 247, "seek": 100880, "start": 1008.8, "end": 1013.8, "text": " And you have the thing you need to compile SCSS installed.", "tokens": [400, 291, 362, 264, 551, 291, 643, 281, 31413, 9028, 21929, 8899, 13], "temperature": 0.0, "avg_logprob": -0.4191983401120364, "compression_ratio": 1.7988826815642458, "no_speech_prob": 3.7048350350232795e-05}, {"id": 248, "seek": 100880, "start": 1013.8, "end": 1018.8, "text": " You don't need to configure it to explain how to transpile SCSS files because that's a standard.", "tokens": [509, 500, 380, 643, 281, 22162, 309, 281, 2903, 577, 281, 7132, 794, 9028, 21929, 7098, 570, 300, 311, 257, 3832, 13], "temperature": 0.0, "avg_logprob": -0.4191983401120364, "compression_ratio": 1.7988826815642458, "no_speech_prob": 3.7048350350232795e-05}, {"id": 249, "seek": 100880, "start": 1018.8, "end": 1023.8, "text": " You just include an SCSS file in your index.html and it figures that out.", "tokens": [509, 445, 4090, 364, 9028, 21929, 3991, 294, 428, 8186, 13, 357, 15480, 293, 309, 9624, 300, 484, 13], "temperature": 0.0, "avg_logprob": -0.4191983401120364, "compression_ratio": 1.7988826815642458, "no_speech_prob": 3.7048350350232795e-05}, {"id": 250, "seek": 100880, "start": 1023.8, "end": 1028.8, "text": " Or you include a.ts file in your.html and it figures that out.", "tokens": [1610, 291, 4090, 257, 2411, 1373, 3991, 294, 428, 2411, 357, 15480, 293, 309, 9624, 300, 484, 13], "temperature": 0.0, "avg_logprob": -0.4191983401120364, "compression_ratio": 1.7988826815642458, "no_speech_prob": 3.7048350350232795e-05}, {"id": 251, "seek": 100880, "start": 1028.8, "end": 1033.8, "text": " And then you just compile it.", "tokens": [400, 550, 291, 445, 31413, 309, 13], "temperature": 0.0, "avg_logprob": -0.4191983401120364, "compression_ratio": 1.7988826815642458, "no_speech_prob": 3.7048350350232795e-05}, {"id": 252, "seek": 103380, "start": 1033.8, "end": 1038.8, "text": " Or you include a.ts file in your script in your index.html file and it figures that out.", "tokens": [1610, 291, 4090, 257, 2411, 1373, 3991, 294, 428, 5755, 294, 428, 8186, 13, 357, 15480, 3991, 293, 309, 9624, 300, 484, 13], "temperature": 0.0, "avg_logprob": -0.2327592077334065, "compression_ratio": 1.8917748917748918, "no_speech_prob": 3.7051715480629355e-05}, {"id": 253, "seek": 103380, "start": 1038.8, "end": 1043.8, "text": " Or you include a.ts file in your script in your index.html file and it knows what to do with that.", "tokens": [1610, 291, 4090, 257, 2411, 1373, 3991, 294, 428, 5755, 294, 428, 8186, 13, 357, 15480, 3991, 293, 309, 3255, 437, 281, 360, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.2327592077334065, "compression_ratio": 1.8917748917748918, "no_speech_prob": 3.7051715480629355e-05}, {"id": 254, "seek": 103380, "start": 1043.8, "end": 1048.8, "text": " And so it completely changed my perspective on that.", "tokens": [400, 370, 309, 2584, 3105, 452, 4585, 322, 300, 13], "temperature": 0.0, "avg_logprob": -0.2327592077334065, "compression_ratio": 1.8917748917748918, "no_speech_prob": 3.7051715480629355e-05}, {"id": 255, "seek": 103380, "start": 1048.8, "end": 1053.8, "text": " And I integrated Vite in Elm pages v3 and it's been great.", "tokens": [400, 286, 10919, 691, 642, 294, 2699, 76, 7183, 371, 18, 293, 309, 311, 668, 869, 13], "temperature": 0.0, "avg_logprob": -0.2327592077334065, "compression_ratio": 1.8917748917748918, "no_speech_prob": 3.7051715480629355e-05}, {"id": 256, "seek": 103380, "start": 1053.8, "end": 1058.8, "text": " The front end ecosystem in general. I'm really excited to hear how it's in Elm pages v3 and I'm looking forward to trying it more myself.", "tokens": [440, 1868, 917, 11311, 294, 2674, 13, 286, 478, 534, 2919, 281, 1568, 577, 309, 311, 294, 2699, 76, 7183, 371, 18, 293, 286, 478, 1237, 2128, 281, 1382, 309, 544, 2059, 13], "temperature": 0.0, "avg_logprob": -0.2327592077334065, "compression_ratio": 1.8917748917748918, "no_speech_prob": 3.7051715480629355e-05}, {"id": 257, "seek": 105880, "start": 1058.8, "end": 1063.8, "text": " But Vite is being used by Vue, by Svelte, by Solid, by Astro.", "tokens": [583, 691, 642, 307, 885, 1143, 538, 691, 622, 11, 538, 318, 779, 975, 11, 538, 26664, 11, 538, 12884, 340, 13], "temperature": 0.0, "avg_logprob": -0.18417966933477492, "compression_ratio": 1.6056910569105691, "no_speech_prob": 1.892264663183596e-05}, {"id": 258, "seek": 105880, "start": 1063.8, "end": 1068.8, "text": " I think there's some integrations for things like Eleventy as well.", "tokens": [286, 519, 456, 311, 512, 3572, 763, 337, 721, 411, 8024, 2475, 88, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.18417966933477492, "compression_ratio": 1.6056910569105691, "no_speech_prob": 1.892264663183596e-05}, {"id": 259, "seek": 105880, "start": 1068.8, "end": 1073.8, "text": " So there's a lot of projects that are now using Vite and adopting it in the background and bringing together this whole ecosystem.", "tokens": [407, 456, 311, 257, 688, 295, 4455, 300, 366, 586, 1228, 691, 642, 293, 32328, 309, 294, 264, 3678, 293, 5062, 1214, 341, 1379, 11311, 13], "temperature": 0.0, "avg_logprob": -0.18417966933477492, "compression_ratio": 1.6056910569105691, "no_speech_prob": 1.892264663183596e-05}, {"id": 260, "seek": 105880, "start": 1073.8, "end": 1078.8, "text": " So that everyone's on the same basic tooling from the start.", "tokens": [407, 300, 1518, 311, 322, 264, 912, 3875, 46593, 490, 264, 722, 13], "temperature": 0.0, "avg_logprob": -0.18417966933477492, "compression_ratio": 1.6056910569105691, "no_speech_prob": 1.892264663183596e-05}, {"id": 261, "seek": 105880, "start": 1078.8, "end": 1083.8, "text": " Then you just add the framework and libraries on top of it that you want.", "tokens": [1396, 291, 445, 909, 264, 8388, 293, 15148, 322, 1192, 295, 309, 300, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.18417966933477492, "compression_ratio": 1.6056910569105691, "no_speech_prob": 1.892264663183596e-05}, {"id": 262, "seek": 108380, "start": 1083.8, "end": 1088.8, "text": " Exactly. Yeah.", "tokens": [7587, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.28090280956692165, "compression_ratio": 1.6153846153846154, "no_speech_prob": 5.9184752899454907e-05}, {"id": 263, "seek": 108380, "start": 1088.8, "end": 1093.8, "text": " Yeah. It's a breath of fresh air, especially like, you know, Jeroen and I have talked about this world where you have like,", "tokens": [865, 13, 467, 311, 257, 6045, 295, 4451, 1988, 11, 2318, 411, 11, 291, 458, 11, 508, 2032, 268, 293, 286, 362, 2825, 466, 341, 1002, 689, 291, 362, 411, 11], "temperature": 0.0, "avg_logprob": -0.28090280956692165, "compression_ratio": 1.6153846153846154, "no_speech_prob": 5.9184752899454907e-05}, {"id": 264, "seek": 108380, "start": 1093.8, "end": 1098.8, "text": " everybody has a custom Babel configuration that gives them like slightly different JS syntax.", "tokens": [2201, 575, 257, 2375, 15820, 338, 11694, 300, 2709, 552, 411, 4748, 819, 33063, 28431, 13], "temperature": 0.0, "avg_logprob": -0.28090280956692165, "compression_ratio": 1.6153846153846154, "no_speech_prob": 5.9184752899454907e-05}, {"id": 265, "seek": 108380, "start": 1098.8, "end": 1103.8, "text": " And then you've got JSX and TSX and then variants on that and all these things.", "tokens": [400, 550, 291, 600, 658, 33063, 55, 293, 37645, 55, 293, 550, 21669, 322, 300, 293, 439, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.28090280956692165, "compression_ratio": 1.6153846153846154, "no_speech_prob": 5.9184752899454907e-05}, {"id": 266, "seek": 108380, "start": 1103.8, "end": 1108.8, "text": " And it's just like, can we just agree like what the basic syntax is and just like not mess with that stuff?", "tokens": [400, 309, 311, 445, 411, 11, 393, 321, 445, 3986, 411, 437, 264, 3875, 28431, 307, 293, 445, 411, 406, 2082, 365, 300, 1507, 30], "temperature": 0.0, "avg_logprob": -0.28090280956692165, "compression_ratio": 1.6153846153846154, "no_speech_prob": 5.9184752899454907e-05}, {"id": 267, "seek": 110880, "start": 1108.8, "end": 1113.8, "text": " So all the tooling can just not need all this customization to just tell it like what syntax is and how things work.", "tokens": [407, 439, 264, 46593, 393, 445, 406, 643, 439, 341, 39387, 281, 445, 980, 309, 411, 437, 28431, 307, 293, 577, 721, 589, 13], "temperature": 0.0, "avg_logprob": -0.21553027111551035, "compression_ratio": 1.5376344086021505, "no_speech_prob": 2.930525988631416e-05}, {"id": 268, "seek": 110880, "start": 1121.8, "end": 1126.8, "text": " And it just feels like the pendulum is swinging back there.", "tokens": [400, 309, 445, 3417, 411, 264, 44103, 307, 29500, 646, 456, 13], "temperature": 0.0, "avg_logprob": -0.21553027111551035, "compression_ratio": 1.5376344086021505, "no_speech_prob": 2.930525988631416e-05}, {"id": 269, "seek": 110880, "start": 1126.8, "end": 1131.8, "text": " Things got a little bit out of hand and now we're like, let's just kind of take a more conventional approach.", "tokens": [9514, 658, 257, 707, 857, 484, 295, 1011, 293, 586, 321, 434, 411, 11, 718, 311, 445, 733, 295, 747, 257, 544, 16011, 3109, 13], "temperature": 0.0, "avg_logprob": -0.21553027111551035, "compression_ratio": 1.5376344086021505, "no_speech_prob": 2.930525988631416e-05}, {"id": 270, "seek": 113180, "start": 1131.8, "end": 1136.8, "text": " Yeah. I imagine it's also because the JavaScript community is less intent on shipping new things.", "tokens": [865, 13, 286, 3811, 309, 311, 611, 570, 264, 15778, 1768, 307, 1570, 8446, 322, 14122, 777, 721, 13], "temperature": 0.0, "avg_logprob": -0.23553006465618426, "compression_ratio": 1.7117117117117118, "no_speech_prob": 2.6270934540661983e-05}, {"id": 271, "seek": 113180, "start": 1136.8, "end": 1141.8, "text": " Like they're not building a new JSX as far as I know.", "tokens": [1743, 436, 434, 406, 2390, 257, 777, 33063, 55, 382, 1400, 382, 286, 458, 13], "temperature": 0.0, "avg_logprob": -0.23553006465618426, "compression_ratio": 1.7117117117117118, "no_speech_prob": 2.6270934540661983e-05}, {"id": 272, "seek": 113180, "start": 1141.8, "end": 1146.8, "text": " And it's just like, okay, well people are using JSX. Okay. Let's include it.", "tokens": [400, 309, 311, 445, 411, 11, 1392, 11, 731, 561, 366, 1228, 33063, 55, 13, 1033, 13, 961, 311, 4090, 309, 13], "temperature": 0.0, "avg_logprob": -0.23553006465618426, "compression_ratio": 1.7117117117117118, "no_speech_prob": 2.6270934540661983e-05}, {"id": 273, "seek": 113180, "start": 1146.8, "end": 1151.8, "text": " People are using TypeScript. Let's include it. People are using SCSS. Let's include it.", "tokens": [3432, 366, 1228, 15576, 14237, 13, 961, 311, 4090, 309, 13, 3432, 366, 1228, 9028, 21929, 13, 961, 311, 4090, 309, 13], "temperature": 0.0, "avg_logprob": -0.23553006465618426, "compression_ratio": 1.7117117117117118, "no_speech_prob": 2.6270934540661983e-05}, {"id": 274, "seek": 113180, "start": 1151.8, "end": 1156.8, "text": " In that way you have a standard because that's what people use.", "tokens": [682, 300, 636, 291, 362, 257, 3832, 570, 300, 311, 437, 561, 764, 13], "temperature": 0.0, "avg_logprob": -0.23553006465618426, "compression_ratio": 1.7117117117117118, "no_speech_prob": 2.6270934540661983e-05}, {"id": 275, "seek": 115680, "start": 1156.8, "end": 1161.8, "text": " And there are new versions of JavaScript coming on every year.", "tokens": [400, 456, 366, 777, 9606, 295, 15778, 1348, 322, 633, 1064, 13], "temperature": 0.0, "avg_logprob": -0.20983423505510604, "compression_ratio": 1.5568627450980392, "no_speech_prob": 1.8924669348052703e-05}, {"id": 276, "seek": 115680, "start": 1161.8, "end": 1166.8, "text": " So let's just add support for them whenever they arrive and that's it.", "tokens": [407, 718, 311, 445, 909, 1406, 337, 552, 5699, 436, 8881, 293, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.20983423505510604, "compression_ratio": 1.5568627450980392, "no_speech_prob": 1.8924669348052703e-05}, {"id": 277, "seek": 115680, "start": 1166.8, "end": 1171.8, "text": " So that does make things a lot easier. Yeah.", "tokens": [407, 300, 775, 652, 721, 257, 688, 3571, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.20983423505510604, "compression_ratio": 1.5568627450980392, "no_speech_prob": 1.8924669348052703e-05}, {"id": 278, "seek": 115680, "start": 1171.8, "end": 1176.8, "text": " And in the Elm ecosystem, like we've had this for a long time because Elm 0.19 has been released a few years ago and not much has changed since then.", "tokens": [400, 294, 264, 2699, 76, 11311, 11, 411, 321, 600, 632, 341, 337, 257, 938, 565, 570, 2699, 76, 1958, 13, 3405, 575, 668, 4736, 257, 1326, 924, 2057, 293, 406, 709, 575, 3105, 1670, 550, 13], "temperature": 0.0, "avg_logprob": -0.20983423505510604, "compression_ratio": 1.5568627450980392, "no_speech_prob": 1.8924669348052703e-05}, {"id": 279, "seek": 115680, "start": 1180.8, "end": 1185.8, "text": " So for us, it's very stable as well, but for very different reasons.", "tokens": [407, 337, 505, 11, 309, 311, 588, 8351, 382, 731, 11, 457, 337, 588, 819, 4112, 13], "temperature": 0.0, "avg_logprob": -0.20983423505510604, "compression_ratio": 1.5568627450980392, "no_speech_prob": 1.8924669348052703e-05}, {"id": 280, "seek": 118580, "start": 1185.8, "end": 1190.8, "text": " I think I've come to a point where I'll admit I've only used Elm 0.19.", "tokens": [286, 519, 286, 600, 808, 281, 257, 935, 689, 286, 603, 9796, 286, 600, 787, 1143, 2699, 76, 1958, 13, 3405, 13], "temperature": 0.0, "avg_logprob": -0.23355053317162297, "compression_ratio": 1.50990099009901, "no_speech_prob": 6.10840434092097e-05}, {"id": 281, "seek": 118580, "start": 1190.8, "end": 1195.8, "text": " I started in the Elm ecosystem right after it released.", "tokens": [286, 1409, 294, 264, 2699, 76, 11311, 558, 934, 309, 4736, 13], "temperature": 0.0, "avg_logprob": -0.23355053317162297, "compression_ratio": 1.50990099009901, "no_speech_prob": 6.10840434092097e-05}, {"id": 282, "seek": 118580, "start": 1195.8, "end": 1200.8, "text": " So I have not yet seen the pain of having to transfer between versions.", "tokens": [407, 286, 362, 406, 1939, 1612, 264, 1822, 295, 1419, 281, 5003, 1296, 9606, 13], "temperature": 0.0, "avg_logprob": -0.23355053317162297, "compression_ratio": 1.50990099009901, "no_speech_prob": 6.10840434092097e-05}, {"id": 283, "seek": 118580, "start": 1200.8, "end": 1205.8, "text": " Yes. Same here. I think I started looking at it in 0.16 or 0.17.", "tokens": [1079, 13, 10635, 510, 13, 286, 519, 286, 1409, 1237, 412, 309, 294, 1958, 13, 6866, 420, 1958, 13, 7773, 13], "temperature": 0.0, "avg_logprob": -0.23355053317162297, "compression_ratio": 1.50990099009901, "no_speech_prob": 6.10840434092097e-05}, {"id": 284, "seek": 118580, "start": 1205.8, "end": 1210.8, "text": " Yeah. 0.16 when there were still signals.", "tokens": [865, 13, 1958, 13, 6866, 562, 456, 645, 920, 12354, 13], "temperature": 0.0, "avg_logprob": -0.23355053317162297, "compression_ratio": 1.50990099009901, "no_speech_prob": 6.10840434092097e-05}, {"id": 285, "seek": 121080, "start": 1210.8, "end": 1215.8, "text": " 0.19 was released like a month before and hasn't changed since.", "tokens": [1958, 13, 3405, 390, 4736, 411, 257, 1618, 949, 293, 6132, 380, 3105, 1670, 13], "temperature": 0.0, "avg_logprob": -0.18518352508544922, "compression_ratio": 1.5525423728813559, "no_speech_prob": 0.00012521554890554398}, {"id": 286, "seek": 121080, "start": 1215.8, "end": 1220.8, "text": " One other piece that we haven't touched on, and I realized Dillon, you asked the question, I forgot to answer it.", "tokens": [1485, 661, 2522, 300, 321, 2378, 380, 9828, 322, 11, 293, 286, 5334, 28160, 11, 291, 2351, 264, 1168, 11, 286, 5298, 281, 1867, 309, 13], "temperature": 0.0, "avg_logprob": -0.18518352508544922, "compression_ratio": 1.5525423728813559, "no_speech_prob": 0.00012521554890554398}, {"id": 287, "seek": 121080, "start": 1220.8, "end": 1225.8, "text": " ESM, which is a huge piece of what makes the Vite development experience so lovely.", "tokens": [12564, 44, 11, 597, 307, 257, 2603, 2522, 295, 437, 1669, 264, 691, 642, 3250, 1752, 370, 7496, 13], "temperature": 0.0, "avg_logprob": -0.18518352508544922, "compression_ratio": 1.5525423728813559, "no_speech_prob": 0.00012521554890554398}, {"id": 288, "seek": 121080, "start": 1225.8, "end": 1230.8, "text": " And as I'm describing this, I'm going to be describing it from a JavaScript perspective primarily because that's where you see the biggest benefit.", "tokens": [400, 382, 286, 478, 16141, 341, 11, 286, 478, 516, 281, 312, 16141, 309, 490, 257, 15778, 4585, 10029, 570, 300, 311, 689, 291, 536, 264, 3880, 5121, 13], "temperature": 0.0, "avg_logprob": -0.18518352508544922, "compression_ratio": 1.5525423728813559, "no_speech_prob": 0.00012521554890554398}, {"id": 289, "seek": 121080, "start": 1230.8, "end": 1235.8, "text": " But this also helps with Elm development as well.", "tokens": [583, 341, 611, 3665, 365, 2699, 76, 3250, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.18518352508544922, "compression_ratio": 1.5525423728813559, "no_speech_prob": 0.00012521554890554398}, {"id": 290, "seek": 123580, "start": 1235.8, "end": 1248.8, "text": " During development using Vite, all of the scripts, all of the code, everything is just compiled into standard native ES modules.", "tokens": [6842, 3250, 1228, 691, 642, 11, 439, 295, 264, 23294, 11, 439, 295, 264, 3089, 11, 1203, 307, 445, 36548, 666, 3832, 8470, 12564, 16679, 13], "temperature": 0.0, "avg_logprob": -0.25844415441735996, "compression_ratio": 1.5148514851485149, "no_speech_prob": 5.389133366406895e-05}, {"id": 291, "seek": 123580, "start": 1248.8, "end": 1250.8, "text": " ES in this case being ECMAScript.", "tokens": [12564, 294, 341, 1389, 885, 19081, 44, 3160, 5944, 13], "temperature": 0.0, "avg_logprob": -0.25844415441735996, "compression_ratio": 1.5148514851485149, "no_speech_prob": 5.389133366406895e-05}, {"id": 292, "seek": 123580, "start": 1250.8, "end": 1262.8, "text": " You mean that even things that use CommonJS or other formats that you use like require, they get compiled to use import and export syntax?", "tokens": [509, 914, 300, 754, 721, 300, 764, 18235, 41, 50, 420, 661, 25879, 300, 291, 764, 411, 3651, 11, 436, 483, 36548, 281, 764, 974, 293, 10725, 28431, 30], "temperature": 0.0, "avg_logprob": -0.25844415441735996, "compression_ratio": 1.5148514851485149, "no_speech_prob": 5.389133366406895e-05}, {"id": 293, "seek": 123580, "start": 1262.8, "end": 1263.8, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.25844415441735996, "compression_ratio": 1.5148514851485149, "no_speech_prob": 5.389133366406895e-05}, {"id": 294, "seek": 126380, "start": 1263.8, "end": 1265.8, "text": " Good job.", "tokens": [2205, 1691, 13], "temperature": 0.0, "avg_logprob": -0.17719214303152903, "compression_ratio": 1.6781609195402298, "no_speech_prob": 2.7531994419405237e-05}, {"id": 295, "seek": 126380, "start": 1265.8, "end": 1269.8, "text": " During the development process, everything is in ES modules.", "tokens": [6842, 264, 3250, 1399, 11, 1203, 307, 294, 12564, 16679, 13], "temperature": 0.0, "avg_logprob": -0.17719214303152903, "compression_ratio": 1.6781609195402298, "no_speech_prob": 2.7531994419405237e-05}, {"id": 296, "seek": 126380, "start": 1269.8, "end": 1280.8, "text": " Rather than the experience that we've had with Webpack, for example, of you have to wait for all of the code to compile before you can even start up your application in the browser.", "tokens": [16571, 813, 264, 1752, 300, 321, 600, 632, 365, 9573, 9539, 11, 337, 1365, 11, 295, 291, 362, 281, 1699, 337, 439, 295, 264, 3089, 281, 31413, 949, 291, 393, 754, 722, 493, 428, 3861, 294, 264, 11185, 13], "temperature": 0.0, "avg_logprob": -0.17719214303152903, "compression_ratio": 1.6781609195402298, "no_speech_prob": 2.7531994419405237e-05}, {"id": 297, "seek": 126380, "start": 1280.8, "end": 1283.8, "text": " I had an experience at a previous job on a Vue application that used Webpack.", "tokens": [286, 632, 364, 1752, 412, 257, 3894, 1691, 322, 257, 691, 622, 3861, 300, 1143, 9573, 9539, 13], "temperature": 0.0, "avg_logprob": -0.17719214303152903, "compression_ratio": 1.6781609195402298, "no_speech_prob": 2.7531994419405237e-05}, {"id": 298, "seek": 126380, "start": 1283.8, "end": 1290.8, "text": " Start the application, go and get a snack, come back, it's done, it's ready, now I can finally get to work.", "tokens": [6481, 264, 3861, 11, 352, 293, 483, 257, 13288, 11, 808, 646, 11, 309, 311, 1096, 11, 309, 311, 1919, 11, 586, 286, 393, 2721, 483, 281, 589, 13], "temperature": 0.0, "avg_logprob": -0.17719214303152903, "compression_ratio": 1.6781609195402298, "no_speech_prob": 2.7531994419405237e-05}, {"id": 299, "seek": 129080, "start": 1290.8, "end": 1294.8, "text": " Depending on the file that you change, all of that would have to happen again.", "tokens": [22539, 322, 264, 3991, 300, 291, 1319, 11, 439, 295, 300, 576, 362, 281, 1051, 797, 13], "temperature": 0.0, "avg_logprob": -0.18880442915291623, "compression_ratio": 1.650943396226415, "no_speech_prob": 8.480005635647103e-05}, {"id": 300, "seek": 129080, "start": 1294.8, "end": 1304.8, "text": " With Vite, because everything is ES module, it's A, every single file, if you make a change, only that file is replaced in the browser.", "tokens": [2022, 691, 642, 11, 570, 1203, 307, 12564, 10088, 11, 309, 311, 316, 11, 633, 2167, 3991, 11, 498, 291, 652, 257, 1319, 11, 787, 300, 3991, 307, 10772, 294, 264, 11185, 13], "temperature": 0.0, "avg_logprob": -0.18880442915291623, "compression_ratio": 1.650943396226415, "no_speech_prob": 8.480005635647103e-05}, {"id": 301, "seek": 129080, "start": 1304.8, "end": 1312.8, "text": " The browser is acting as the bundler because you're just sending all of the code to it and it's loading things using the native syntax.", "tokens": [440, 11185, 307, 6577, 382, 264, 13882, 1918, 570, 291, 434, 445, 7750, 439, 295, 264, 3089, 281, 309, 293, 309, 311, 15114, 721, 1228, 264, 8470, 28431, 13], "temperature": 0.0, "avg_logprob": -0.18880442915291623, "compression_ratio": 1.650943396226415, "no_speech_prob": 8.480005635647103e-05}, {"id": 302, "seek": 131280, "start": 1312.8, "end": 1323.8, "text": " The other benefit to that is if you're on a page and only some of the code is getting loaded on that particular page, Vite won't bother compiling the rest of it for the time.", "tokens": [440, 661, 5121, 281, 300, 307, 498, 291, 434, 322, 257, 3028, 293, 787, 512, 295, 264, 3089, 307, 1242, 13210, 322, 300, 1729, 3028, 11, 691, 642, 1582, 380, 8677, 715, 4883, 264, 1472, 295, 309, 337, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.16338149360988452, "compression_ratio": 1.7197452229299364, "no_speech_prob": 6.602811481570825e-05}, {"id": 303, "seek": 131280, "start": 1323.8, "end": 1327.8, "text": " It will only load the route that you're using and it will only load the code that you're using.", "tokens": [467, 486, 787, 3677, 264, 7955, 300, 291, 434, 1228, 293, 309, 486, 787, 3677, 264, 3089, 300, 291, 434, 1228, 13], "temperature": 0.0, "avg_logprob": -0.16338149360988452, "compression_ratio": 1.7197452229299364, "no_speech_prob": 6.602811481570825e-05}, {"id": 304, "seek": 132780, "start": 1327.8, "end": 1344.8, "text": " Right, and when you're talking about native imports, we should clarify that CommonJS imports are something that bundlers know how to pack up into a bundled asset, but browsers have no idea what require means.", "tokens": [1779, 11, 293, 562, 291, 434, 1417, 466, 8470, 41596, 11, 321, 820, 17594, 300, 18235, 41, 50, 41596, 366, 746, 300, 13882, 11977, 458, 577, 281, 2844, 493, 666, 257, 13882, 1493, 11999, 11, 457, 36069, 362, 572, 1558, 437, 3651, 1355, 13], "temperature": 0.0, "avg_logprob": -0.20291441962832496, "compression_ratio": 1.5352112676056338, "no_speech_prob": 3.320431642350741e-05}, {"id": 305, "seek": 132780, "start": 1344.8, "end": 1349.8, "text": " If you see require in the browser, it just explodes and says, I don't know what that is.", "tokens": [759, 291, 536, 3651, 294, 264, 11185, 11, 309, 445, 42610, 293, 1619, 11, 286, 500, 380, 458, 437, 300, 307, 13], "temperature": 0.0, "avg_logprob": -0.20291441962832496, "compression_ratio": 1.5352112676056338, "no_speech_prob": 3.320431642350741e-05}, {"id": 306, "seek": 132780, "start": 1349.8, "end": 1350.8, "text": " Yep.", "tokens": [7010, 13], "temperature": 0.0, "avg_logprob": -0.20291441962832496, "compression_ratio": 1.5352112676056338, "no_speech_prob": 3.320431642350741e-05}, {"id": 307, "seek": 132780, "start": 1350.8, "end": 1351.8, "text": " But if you say import...", "tokens": [583, 498, 291, 584, 974, 485], "temperature": 0.0, "avg_logprob": -0.20291441962832496, "compression_ratio": 1.5352112676056338, "no_speech_prob": 3.320431642350741e-05}, {"id": 308, "seek": 135180, "start": 1351.8, "end": 1361.8, "text": " CommonJS is a remnant from the early days of Node where everyone said, well, we need a way to bundle things and we need modules.", "tokens": [18235, 41, 50, 307, 257, 890, 25928, 490, 264, 2440, 1708, 295, 38640, 689, 1518, 848, 11, 731, 11, 321, 643, 257, 636, 281, 24438, 721, 293, 321, 643, 16679, 13], "temperature": 0.0, "avg_logprob": -0.206714428172392, "compression_ratio": 1.6465116279069767, "no_speech_prob": 5.738480103900656e-05}, {"id": 309, "seek": 135180, "start": 1361.8, "end": 1370.8, "text": " And so between the front end needing something like that and the back end needing something like that, the pseudo standard that was developed was CommonJS.", "tokens": [400, 370, 1296, 264, 1868, 917, 18006, 746, 411, 300, 293, 264, 646, 917, 18006, 746, 411, 300, 11, 264, 35899, 3832, 300, 390, 4743, 390, 18235, 41, 50, 13], "temperature": 0.0, "avg_logprob": -0.206714428172392, "compression_ratio": 1.6465116279069767, "no_speech_prob": 5.738480103900656e-05}, {"id": 310, "seek": 135180, "start": 1370.8, "end": 1377.8, "text": " But when the TC39 was working on how do we actually standardize this?", "tokens": [583, 562, 264, 34150, 12493, 390, 1364, 322, 577, 360, 321, 767, 3832, 1125, 341, 30], "temperature": 0.0, "avg_logprob": -0.206714428172392, "compression_ratio": 1.6465116279069767, "no_speech_prob": 5.738480103900656e-05}, {"id": 311, "seek": 137780, "start": 1377.8, "end": 1386.8, "text": " There is a community standard right now. They felt that going with require and going with the CommonJS syntax was not what best served the JavaScript ecosystem.", "tokens": [821, 307, 257, 1768, 3832, 558, 586, 13, 814, 2762, 300, 516, 365, 3651, 293, 516, 365, 264, 18235, 41, 50, 28431, 390, 406, 437, 1151, 7584, 264, 15778, 11311, 13], "temperature": 0.0, "avg_logprob": -0.1796537443648937, "compression_ratio": 1.5947136563876652, "no_speech_prob": 8.749975677346811e-05}, {"id": 312, "seek": 137780, "start": 1386.8, "end": 1392.8, "text": " And so they went with the import syntax that is more modern, we're more familiar with today.", "tokens": [400, 370, 436, 1437, 365, 264, 974, 28431, 300, 307, 544, 4363, 11, 321, 434, 544, 4963, 365, 965, 13], "temperature": 0.0, "avg_logprob": -0.1796537443648937, "compression_ratio": 1.5947136563876652, "no_speech_prob": 8.749975677346811e-05}, {"id": 313, "seek": 137780, "start": 1392.8, "end": 1396.8, "text": " So that is what is used in the browser by default.", "tokens": [407, 300, 307, 437, 307, 1143, 294, 264, 11185, 538, 7576, 13], "temperature": 0.0, "avg_logprob": -0.1796537443648937, "compression_ratio": 1.5947136563876652, "no_speech_prob": 8.749975677346811e-05}, {"id": 314, "seek": 137780, "start": 1396.8, "end": 1398.8, "text": " And you could actually do this without a bundler as well.", "tokens": [400, 291, 727, 767, 360, 341, 1553, 257, 13882, 1918, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1796537443648937, "compression_ratio": 1.5947136563876652, "no_speech_prob": 8.749975677346811e-05}, {"id": 315, "seek": 139880, "start": 1398.8, "end": 1408.8, "text": " If you wanted to create a section of your code that used ES modules in the browser, no compiler necessary, you would just have to set the script type to module.", "tokens": [759, 291, 1415, 281, 1884, 257, 3541, 295, 428, 3089, 300, 1143, 12564, 16679, 294, 264, 11185, 11, 572, 31958, 4818, 11, 291, 576, 445, 362, 281, 992, 264, 5755, 2010, 281, 10088, 13], "temperature": 0.0, "avg_logprob": -0.16943322395791813, "compression_ratio": 1.7679324894514767, "no_speech_prob": 5.6495468015782535e-05}, {"id": 316, "seek": 139880, "start": 1408.8, "end": 1412.8, "text": " And suddenly you can import things and you could export things if you really wanted to.", "tokens": [400, 5800, 291, 393, 974, 721, 293, 291, 727, 10725, 721, 498, 291, 534, 1415, 281, 13], "temperature": 0.0, "avg_logprob": -0.16943322395791813, "compression_ratio": 1.7679324894514767, "no_speech_prob": 5.6495468015782535e-05}, {"id": 317, "seek": 139880, "start": 1412.8, "end": 1418.8, "text": " And everything would work as you're used to when you're using a compiled language that uses that same syntax.", "tokens": [400, 1203, 576, 589, 382, 291, 434, 1143, 281, 562, 291, 434, 1228, 257, 36548, 2856, 300, 4960, 300, 912, 28431, 13], "temperature": 0.0, "avg_logprob": -0.16943322395791813, "compression_ratio": 1.7679324894514767, "no_speech_prob": 5.6495468015782535e-05}, {"id": 318, "seek": 139880, "start": 1418.8, "end": 1423.8, "text": " You said you need to change the script type in package.json?", "tokens": [509, 848, 291, 643, 281, 1319, 264, 5755, 2010, 294, 7372, 13, 73, 3015, 30], "temperature": 0.0, "avg_logprob": -0.16943322395791813, "compression_ratio": 1.7679324894514767, "no_speech_prob": 5.6495468015782535e-05}, {"id": 319, "seek": 142380, "start": 1423.8, "end": 1433.8, "text": " No, just in the so if you have an index.html file, and you wanted to import JavaScript as a module, you could just create a script tag and say script type module.", "tokens": [883, 11, 445, 294, 264, 370, 498, 291, 362, 364, 8186, 13, 357, 15480, 3991, 11, 293, 291, 1415, 281, 974, 15778, 382, 257, 10088, 11, 291, 727, 445, 1884, 257, 5755, 6162, 293, 584, 5755, 2010, 10088, 13], "temperature": 0.0, "avg_logprob": -0.21886872022579879, "compression_ratio": 1.543956043956044, "no_speech_prob": 4.00625795009546e-05}, {"id": 320, "seek": 142380, "start": 1433.8, "end": 1434.8, "text": " Gotcha. Yep.", "tokens": [42109, 13, 7010, 13], "temperature": 0.0, "avg_logprob": -0.21886872022579879, "compression_ratio": 1.543956043956044, "no_speech_prob": 4.00625795009546e-05}, {"id": 321, "seek": 142380, "start": 1434.8, "end": 1440.8, "text": " And then you can use your import syntax and use that as you would if you were using a bundler.", "tokens": [400, 550, 291, 393, 764, 428, 974, 28431, 293, 764, 300, 382, 291, 576, 498, 291, 645, 1228, 257, 13882, 1918, 13], "temperature": 0.0, "avg_logprob": -0.21886872022579879, "compression_ratio": 1.543956043956044, "no_speech_prob": 4.00625795009546e-05}, {"id": 322, "seek": 142380, "start": 1440.8, "end": 1441.8, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.21886872022579879, "compression_ratio": 1.543956043956044, "no_speech_prob": 4.00625795009546e-05}, {"id": 323, "seek": 144180, "start": 1441.8, "end": 1455.8, "text": " It's a little different, right? Like if it's a script type module, can you not do things in the top level? Everything has to be like you can export things, but you can't just have top level code. Am I understanding that correctly?", "tokens": [467, 311, 257, 707, 819, 11, 558, 30, 1743, 498, 309, 311, 257, 5755, 2010, 10088, 11, 393, 291, 406, 360, 721, 294, 264, 1192, 1496, 30, 5471, 575, 281, 312, 411, 291, 393, 10725, 721, 11, 457, 291, 393, 380, 445, 362, 1192, 1496, 3089, 13, 2012, 286, 3701, 300, 8944, 30], "temperature": 0.0, "avg_logprob": -0.1832998480115618, "compression_ratio": 1.6784452296819787, "no_speech_prob": 6.1440805438905954e-06}, {"id": 324, "seek": 144180, "start": 1455.8, "end": 1459.8, "text": " I believe there are some restrictions. I don't remember exactly which ones they are.", "tokens": [286, 1697, 456, 366, 512, 14191, 13, 286, 500, 380, 1604, 2293, 597, 2306, 436, 366, 13], "temperature": 0.0, "avg_logprob": -0.1832998480115618, "compression_ratio": 1.6784452296819787, "no_speech_prob": 6.1440805438905954e-06}, {"id": 325, "seek": 144180, "start": 1459.8, "end": 1469.8, "text": " Okay, but it's supposed to be better for tree shaking and things like that, right? Like for static analysis purposes, there are some benefits to ESM standards.", "tokens": [1033, 11, 457, 309, 311, 3442, 281, 312, 1101, 337, 4230, 15415, 293, 721, 411, 300, 11, 558, 30, 1743, 337, 13437, 5215, 9932, 11, 456, 366, 512, 5311, 281, 12564, 44, 7787, 13], "temperature": 0.0, "avg_logprob": -0.1832998480115618, "compression_ratio": 1.6784452296819787, "no_speech_prob": 6.1440805438905954e-06}, {"id": 326, "seek": 146980, "start": 1469.8, "end": 1472.8, "text": " There are, if you're using a bundler, yes.", "tokens": [821, 366, 11, 498, 291, 434, 1228, 257, 13882, 1918, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.17778684655014348, "compression_ratio": 1.6554621848739495, "no_speech_prob": 2.4682798539288342e-05}, {"id": 327, "seek": 146980, "start": 1472.8, "end": 1483.8, "text": " The difficulty with ESM, even today as a standard, is that if you're using ESM in production, there will be a waterfall of HTTP requests.", "tokens": [440, 10360, 365, 12564, 44, 11, 754, 965, 382, 257, 3832, 11, 307, 300, 498, 291, 434, 1228, 12564, 44, 294, 4265, 11, 456, 486, 312, 257, 27848, 295, 33283, 12475, 13], "temperature": 0.0, "avg_logprob": -0.17778684655014348, "compression_ratio": 1.6554621848739495, "no_speech_prob": 2.4682798539288342e-05}, {"id": 328, "seek": 146980, "start": 1483.8, "end": 1484.8, "text": " Totally.", "tokens": [22837, 13], "temperature": 0.0, "avg_logprob": -0.17778684655014348, "compression_ratio": 1.6554621848739495, "no_speech_prob": 2.4682798539288342e-05}, {"id": 329, "seek": 146980, "start": 1484.8, "end": 1495.8, "text": " So if you have a large single page application, you're going to fire off JavaScript request after JavaScript request until the whole thing is loaded that you need. And that's not really ideal, even today.", "tokens": [407, 498, 291, 362, 257, 2416, 2167, 3028, 3861, 11, 291, 434, 516, 281, 2610, 766, 15778, 5308, 934, 15778, 5308, 1826, 264, 1379, 551, 307, 13210, 300, 291, 643, 13, 400, 300, 311, 406, 534, 7157, 11, 754, 965, 13], "temperature": 0.0, "avg_logprob": -0.17778684655014348, "compression_ratio": 1.6554621848739495, "no_speech_prob": 2.4682798539288342e-05}, {"id": 330, "seek": 149580, "start": 1495.8, "end": 1500.8, "text": " Wasn't that what HTTP 2 was meant for? Solving that kind of issues?", "tokens": [28782, 380, 300, 437, 33283, 568, 390, 4140, 337, 30, 7026, 798, 300, 733, 295, 2663, 30], "temperature": 0.0, "avg_logprob": -0.17408304798359775, "compression_ratio": 1.5974025974025974, "no_speech_prob": 3.393136239537853e-06}, {"id": 331, "seek": 149580, "start": 1500.8, "end": 1510.8, "text": " I think the main problem is that if you load up your index.html file and it references a single JavaScript file, you fetch that file, but then it's going to reference other files.", "tokens": [286, 519, 264, 2135, 1154, 307, 300, 498, 291, 3677, 493, 428, 8186, 13, 357, 15480, 3991, 293, 309, 15400, 257, 2167, 15778, 3991, 11, 291, 23673, 300, 3991, 11, 457, 550, 309, 311, 516, 281, 6408, 661, 7098, 13], "temperature": 0.0, "avg_logprob": -0.17408304798359775, "compression_ratio": 1.5974025974025974, "no_speech_prob": 3.393136239537853e-06}, {"id": 332, "seek": 149580, "start": 1510.8, "end": 1514.8, "text": " So it's not that you can't do the requests in parallel, it's that it doesn't know what requests to make.", "tokens": [407, 309, 311, 406, 300, 291, 393, 380, 360, 264, 12475, 294, 8952, 11, 309, 311, 300, 309, 1177, 380, 458, 437, 12475, 281, 652, 13], "temperature": 0.0, "avg_logprob": -0.17408304798359775, "compression_ratio": 1.5974025974025974, "no_speech_prob": 3.393136239537853e-06}, {"id": 333, "seek": 149580, "start": 1514.8, "end": 1516.8, "text": " Yeah, of course.", "tokens": [865, 11, 295, 1164, 13], "temperature": 0.0, "avg_logprob": -0.17408304798359775, "compression_ratio": 1.5974025974025974, "no_speech_prob": 3.393136239537853e-06}, {"id": 334, "seek": 151680, "start": 1516.8, "end": 1531.8, "text": " Yeah. And there do exist plugins that like hoist module preload directives to figure out what that waterfall is going to have and then add preload directives to tell you.", "tokens": [865, 13, 400, 456, 360, 2514, 33759, 300, 411, 1106, 468, 10088, 659, 2907, 2047, 1539, 281, 2573, 484, 437, 300, 27848, 307, 516, 281, 362, 293, 550, 909, 659, 2907, 2047, 1539, 281, 980, 291, 13], "temperature": 0.0, "avg_logprob": -0.1934892491596501, "compression_ratio": 1.452991452991453, "no_speech_prob": 2.6687965146265924e-05}, {"id": 335, "seek": 153180, "start": 1531.8, "end": 1548.8, "text": " But yeah, generally, people just in the production build just turn everything into a single bundled asset instead, or well, not necessarily a single one, but they chunk the assets rather than just having everything be ESM imports.", "tokens": [583, 1338, 11, 5101, 11, 561, 445, 294, 264, 4265, 1322, 445, 1261, 1203, 666, 257, 2167, 13882, 1493, 11999, 2602, 11, 420, 731, 11, 406, 4725, 257, 2167, 472, 11, 457, 436, 16635, 264, 9769, 2831, 813, 445, 1419, 1203, 312, 12564, 44, 41596, 13], "temperature": 0.0, "avg_logprob": -0.24771526336669922, "compression_ratio": 1.4556962025316456, "no_speech_prob": 2.8572030714713037e-06}, {"id": 336, "seek": 154880, "start": 1548.8, "end": 1561.8, "text": " So if somebody wants to try using Vite with Elm, what is the minimal thing they can do to get started with that? And what's the simplest way they can get started with that?", "tokens": [407, 498, 2618, 2738, 281, 853, 1228, 691, 642, 365, 2699, 76, 11, 437, 307, 264, 13206, 551, 436, 393, 360, 281, 483, 1409, 365, 300, 30, 400, 437, 311, 264, 22811, 636, 436, 393, 483, 1409, 365, 300, 30], "temperature": 0.0, "avg_logprob": -0.1956691091710871, "compression_ratio": 1.4453781512605042, "no_speech_prob": 2.3186817998066545e-05}, {"id": 337, "seek": 156180, "start": 1561.8, "end": 1578.8, "text": " So if someone wanted to take Vite and just run, for example, npm create vite, set up a new project, whether they're using another JavaScript framework or just vanilla JavaScript, the first step that would need to be done is install the Elm plugin.", "tokens": [407, 498, 1580, 1415, 281, 747, 691, 642, 293, 445, 1190, 11, 337, 1365, 11, 297, 14395, 1884, 371, 642, 11, 992, 493, 257, 777, 1716, 11, 1968, 436, 434, 1228, 1071, 15778, 8388, 420, 445, 17528, 15778, 11, 264, 700, 1823, 300, 576, 643, 281, 312, 1096, 307, 3625, 264, 2699, 76, 23407, 13], "temperature": 0.0, "avg_logprob": -0.18084274805509126, "compression_ratio": 1.6147859922178989, "no_speech_prob": 3.0239642001106404e-05}, {"id": 338, "seek": 156180, "start": 1578.8, "end": 1587.8, "text": " And that plugin is just called Vite plugin Elm. And it is lovely. I've been using it for some time on my own projects. I'm sure you're familiar with it as well, Dillon.", "tokens": [400, 300, 23407, 307, 445, 1219, 691, 642, 23407, 2699, 76, 13, 400, 309, 307, 7496, 13, 286, 600, 668, 1228, 309, 337, 512, 565, 322, 452, 1065, 4455, 13, 286, 478, 988, 291, 434, 4963, 365, 309, 382, 731, 11, 28160, 13], "temperature": 0.0, "avg_logprob": -0.18084274805509126, "compression_ratio": 1.6147859922178989, "no_speech_prob": 3.0239642001106404e-05}, {"id": 339, "seek": 158780, "start": 1587.8, "end": 1599.8, "text": " Then in your Vite config, there's a Vite.config.js file. And you have two, as a bare minimum, you need two imports. One is import define config from Vite.", "tokens": [1396, 294, 428, 691, 642, 6662, 11, 456, 311, 257, 691, 642, 13, 1671, 20646, 13, 25530, 3991, 13, 400, 291, 362, 732, 11, 382, 257, 6949, 7285, 11, 291, 643, 732, 41596, 13, 1485, 307, 974, 6964, 6662, 490, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.24167646210769128, "compression_ratio": 1.6232558139534883, "no_speech_prob": 0.00021992401161696762}, {"id": 340, "seek": 158780, "start": 1599.8, "end": 1609.8, "text": " And that gives you the configuration file and also gives you TypeScript typing, which is helpful as you're working in that file. So you don't need to be constantly referencing the documentation.", "tokens": [400, 300, 2709, 291, 264, 11694, 3991, 293, 611, 2709, 291, 15576, 14237, 18444, 11, 597, 307, 4961, 382, 291, 434, 1364, 294, 300, 3991, 13, 407, 291, 500, 380, 643, 281, 312, 6460, 40582, 264, 14333, 13], "temperature": 0.0, "avg_logprob": -0.24167646210769128, "compression_ratio": 1.6232558139534883, "no_speech_prob": 0.00021992401161696762}, {"id": 341, "seek": 160980, "start": 1609.8, "end": 1620.8, "text": " And then you need to import the plugin itself. And then as far as the configuration goes, the way the file is structured, you just say export default define config, which is a function, takes an object.", "tokens": [400, 550, 291, 643, 281, 974, 264, 23407, 2564, 13, 400, 550, 382, 1400, 382, 264, 11694, 1709, 11, 264, 636, 264, 3991, 307, 18519, 11, 291, 445, 584, 10725, 7576, 6964, 6662, 11, 597, 307, 257, 2445, 11, 2516, 364, 2657, 13], "temperature": 0.0, "avg_logprob": -0.1931792213803246, "compression_ratio": 1.7772020725388602, "no_speech_prob": 5.474556382978335e-05}, {"id": 342, "seek": 160980, "start": 1620.8, "end": 1628.8, "text": " And as a key, you say plugins, which takes an array, and then you invoke the Elm plugin as a function inside of that array, and you're done.", "tokens": [400, 382, 257, 2141, 11, 291, 584, 33759, 11, 597, 2516, 364, 10225, 11, 293, 550, 291, 41117, 264, 2699, 76, 23407, 382, 257, 2445, 1854, 295, 300, 10225, 11, 293, 291, 434, 1096, 13], "temperature": 0.0, "avg_logprob": -0.1931792213803246, "compression_ratio": 1.7772020725388602, "no_speech_prob": 5.474556382978335e-05}, {"id": 343, "seek": 162880, "start": 1628.8, "end": 1639.8, "text": " That's all you need to do to integrate Elm into a Vite application. From there, you of course need to run Elm init, create your Elm file and import it into the JavaScript. But you can import it as if it were JavaScript at that point.", "tokens": [663, 311, 439, 291, 643, 281, 360, 281, 13365, 2699, 76, 666, 257, 691, 642, 3861, 13, 3358, 456, 11, 291, 295, 1164, 643, 281, 1190, 2699, 76, 3157, 11, 1884, 428, 2699, 76, 3991, 293, 974, 309, 666, 264, 15778, 13, 583, 291, 393, 974, 309, 382, 498, 309, 645, 15778, 412, 300, 935, 13], "temperature": 0.0, "avg_logprob": -0.18262853622436523, "compression_ratio": 1.7142857142857142, "no_speech_prob": 4.756405178341083e-05}, {"id": 344, "seek": 162880, "start": 1639.8, "end": 1650.8, "text": " You can just import Elm from main.elm and instantiate your application as you normally would. So that would be the bare minimum to get Elm working inside of Vite.", "tokens": [509, 393, 445, 974, 2699, 76, 490, 2135, 13, 338, 76, 293, 9836, 13024, 428, 3861, 382, 291, 5646, 576, 13, 407, 300, 576, 312, 264, 6949, 7285, 281, 483, 2699, 76, 1364, 1854, 295, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.18262853622436523, "compression_ratio": 1.7142857142857142, "no_speech_prob": 4.756405178341083e-05}, {"id": 345, "seek": 165080, "start": 1650.8, "end": 1667.8, "text": " What I would recommend as a simple way to do that instead is, this is a shameless plug, by the way, I have a template for creating Vite applications using Elm that includes nice tooling such as Elm test and Elm review and some example code to go with that as well.", "tokens": [708, 286, 576, 2748, 382, 257, 2199, 636, 281, 360, 300, 2602, 307, 11, 341, 307, 257, 40164, 5452, 11, 538, 264, 636, 11, 286, 362, 257, 12379, 337, 4084, 691, 642, 5821, 1228, 2699, 76, 300, 5974, 1481, 46593, 1270, 382, 2699, 76, 1500, 293, 2699, 76, 3131, 293, 512, 1365, 3089, 281, 352, 365, 300, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.21589134633541107, "compression_ratio": 1.5085714285714287, "no_speech_prob": 0.00034060204052366316}, {"id": 346, "seek": 166780, "start": 1667.8, "end": 1681.8, "text": " So that would be my recommendation. And that is just called Vite template Elm. And you can find that on GitHub, lindsaykwardell slash Vite Elm template. Sorry, I said Vite template Elm and it's Vite Elm template. I'm good at knowing what my own things are called.", "tokens": [407, 300, 576, 312, 452, 11879, 13, 400, 300, 307, 445, 1219, 691, 642, 12379, 2699, 76, 13, 400, 291, 393, 915, 300, 322, 23331, 11, 287, 471, 21664, 74, 1007, 898, 17330, 691, 642, 2699, 76, 12379, 13, 4919, 11, 286, 848, 691, 642, 12379, 2699, 76, 293, 309, 311, 691, 642, 2699, 76, 12379, 13, 286, 478, 665, 412, 5276, 437, 452, 1065, 721, 366, 1219, 13], "temperature": 0.0, "avg_logprob": -0.21183503640664592, "compression_ratio": 1.6853448275862069, "no_speech_prob": 6.013289748807438e-05}, {"id": 347, "seek": 166780, "start": 1681.8, "end": 1684.8, "text": " Yeah, that's great.", "tokens": [865, 11, 300, 311, 869, 13], "temperature": 0.0, "avg_logprob": -0.21183503640664592, "compression_ratio": 1.6853448275862069, "no_speech_prob": 6.013289748807438e-05}, {"id": 348, "seek": 166780, "start": 1684.8, "end": 1690.8, "text": " What we tend to do is just name things the easiest way. The only question is like, which order is it?", "tokens": [708, 321, 3928, 281, 360, 307, 445, 1315, 721, 264, 12889, 636, 13, 440, 787, 1168, 307, 411, 11, 597, 1668, 307, 309, 30], "temperature": 0.0, "avg_logprob": -0.21183503640664592, "compression_ratio": 1.6853448275862069, "no_speech_prob": 6.013289748807438e-05}, {"id": 349, "seek": 166780, "start": 1690.8, "end": 1692.8, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.21183503640664592, "compression_ratio": 1.6853448275862069, "no_speech_prob": 6.013289748807438e-05}, {"id": 350, "seek": 169280, "start": 1692.8, "end": 1698.8, "text": " I mean, you could have said template Elm Vite and that would be terribly wrong. But we would still get it.", "tokens": [286, 914, 11, 291, 727, 362, 848, 12379, 2699, 76, 691, 642, 293, 300, 576, 312, 22903, 2085, 13, 583, 321, 576, 920, 483, 309, 13], "temperature": 0.0, "avg_logprob": -0.19611124898873122, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.00014883281255606562}, {"id": 351, "seek": 169280, "start": 1698.8, "end": 1712.8, "text": " Yeah, it's got to be Vite first. And I think I went with Elm second because that's the language. I don't know. Yeah, so that would be the simplest way to get started. So you get the hot module reload, which actually works with Elm as well. It's lovely. I really appreciate it.", "tokens": [865, 11, 309, 311, 658, 281, 312, 691, 642, 700, 13, 400, 286, 519, 286, 1437, 365, 2699, 76, 1150, 570, 300, 311, 264, 2856, 13, 286, 500, 380, 458, 13, 865, 11, 370, 300, 576, 312, 264, 22811, 636, 281, 483, 1409, 13, 407, 291, 483, 264, 2368, 10088, 25628, 11, 597, 767, 1985, 365, 2699, 76, 382, 731, 13, 467, 311, 7496, 13, 286, 534, 4449, 309, 13], "temperature": 0.0, "avg_logprob": -0.19611124898873122, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.00014883281255606562}, {"id": 352, "seek": 171280, "start": 1712.8, "end": 1733.8, "text": " You also get the integration with Vite static asset handling. Vite not only can handle TypeScript and JavaScript and WebAssembly and CSS, but you can also import images straight into it. And there's a nice little plugin. It's an Elm package that will prefix things properly so that Elm code gets compiled to JavaScript code that actually handles the assets in a way that Vite likes.", "tokens": [509, 611, 483, 264, 10980, 365, 691, 642, 13437, 11999, 13175, 13, 691, 642, 406, 787, 393, 4813, 15576, 14237, 293, 15778, 293, 9573, 10884, 19160, 293, 24387, 11, 457, 291, 393, 611, 974, 5267, 2997, 666, 309, 13, 400, 456, 311, 257, 1481, 707, 23407, 13, 467, 311, 364, 2699, 76, 7372, 300, 486, 46969, 721, 6108, 370, 300, 2699, 76, 3089, 2170, 36548, 281, 15778, 3089, 300, 767, 18722, 264, 9769, 294, 257, 636, 300, 691, 642, 5902, 13], "temperature": 0.0, "avg_logprob": -0.18468947691075943, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.00045823658001609147}, {"id": 353, "seek": 173380, "start": 1733.8, "end": 1761.8, "text": " You can do it manually. It's just a string, but it's nice to have something a little stronger. The tooling is all installed via Elm tooling, so you can spin things up in your CI CD. So you get Elm, Elm format, Elm JSON, Elm test. You get Elm review and unit test examples. And there's a GitHub Action CI for running tests, just as an example. So that's what the template includes. It's not intended to be like, this is the best solution, but this is a simple solution that shows everything you would need.", "tokens": [509, 393, 360, 309, 16945, 13, 467, 311, 445, 257, 6798, 11, 457, 309, 311, 1481, 281, 362, 746, 257, 707, 7249, 13, 440, 46593, 307, 439, 8899, 5766, 2699, 76, 46593, 11, 370, 291, 393, 6060, 721, 493, 294, 428, 37777, 6743, 13, 407, 291, 483, 2699, 76, 11, 2699, 76, 7877, 11, 2699, 76, 31828, 11, 2699, 76, 1500, 13, 509, 483, 2699, 76, 3131, 293, 4985, 1500, 5110, 13, 400, 456, 311, 257, 23331, 16261, 37777, 337, 2614, 6921, 11, 445, 382, 364, 1365, 13, 407, 300, 311, 437, 264, 12379, 5974, 13, 467, 311, 406, 10226, 281, 312, 411, 11, 341, 307, 264, 1151, 3827, 11, 457, 341, 307, 257, 2199, 3827, 300, 3110, 1203, 291, 576, 643, 13], "temperature": 0.0, "avg_logprob": -0.19836669080839384, "compression_ratio": 1.6946308724832215, "no_speech_prob": 0.0008040537941269577}, {"id": 354, "seek": 176180, "start": 1761.8, "end": 1790.8, "text": " Yeah, it's pretty exciting how little boilerplate there is for getting started with something that is not a cute tool that sort of gets you started and then you outgrow. It's a very simple setup that gets you up and running quickly. But then it's the tool that everybody uses now that has a ton of support and can do whatever you grow into doing later. So that is a breath of fresh air, for sure.", "tokens": [865, 11, 309, 311, 1238, 4670, 577, 707, 39228, 37008, 456, 307, 337, 1242, 1409, 365, 746, 300, 307, 406, 257, 4052, 2290, 300, 1333, 295, 2170, 291, 1409, 293, 550, 291, 484, 26685, 13, 467, 311, 257, 588, 2199, 8657, 300, 2170, 291, 493, 293, 2614, 2661, 13, 583, 550, 309, 311, 264, 2290, 300, 2201, 4960, 586, 300, 575, 257, 2952, 295, 1406, 293, 393, 360, 2035, 291, 1852, 666, 884, 1780, 13, 407, 300, 307, 257, 6045, 295, 4451, 1988, 11, 337, 988, 13], "temperature": 0.0, "avg_logprob": -0.18658765855726306, "compression_ratio": 1.6995708154506437, "no_speech_prob": 0.0036473374348133802}, {"id": 355, "seek": 179080, "start": 1790.8, "end": 1795.8, "text": " I mean, Webpack also did that, but you had to configure it a lot.", "tokens": [286, 914, 11, 9573, 9539, 611, 630, 300, 11, 457, 291, 632, 281, 22162, 309, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.21670114671861804, "compression_ratio": 1.646643109540636, "no_speech_prob": 2.9310618629097007e-05}, {"id": 356, "seek": 179080, "start": 1795.8, "end": 1819.8, "text": " Yeah. My inspiration for this template was actually using the Create Elm app, which is built on Webpack. I had an application written in that and I kept running into situations where I felt like I needed to eject and then handle the Webpack config myself, and I just really didn't want to. So when the plugin came out that supported Elm and Vite, I immediately ported the application over to Webpack.", "tokens": [865, 13, 1222, 10249, 337, 341, 12379, 390, 767, 1228, 264, 20248, 2699, 76, 724, 11, 597, 307, 3094, 322, 9573, 9539, 13, 286, 632, 364, 3861, 3720, 294, 300, 293, 286, 4305, 2614, 666, 6851, 689, 286, 2762, 411, 286, 2978, 281, 32520, 293, 550, 4813, 264, 9573, 9539, 6662, 2059, 11, 293, 286, 445, 534, 994, 380, 528, 281, 13, 407, 562, 264, 23407, 1361, 484, 300, 8104, 2699, 76, 293, 691, 642, 11, 286, 4258, 2436, 292, 264, 3861, 670, 281, 9573, 9539, 13], "temperature": 0.0, "avg_logprob": -0.21670114671861804, "compression_ratio": 1.646643109540636, "no_speech_prob": 2.9310618629097007e-05}, {"id": 357, "seek": 181980, "start": 1819.8, "end": 1823.8, "text": " And then backtracked to a template that I could reuse in future applications.", "tokens": [400, 550, 646, 19466, 292, 281, 257, 12379, 300, 286, 727, 26225, 294, 2027, 5821, 13], "temperature": 0.0, "avg_logprob": -0.22986636290679108, "compression_ratio": 1.2241379310344827, "no_speech_prob": 0.002115499461069703}, {"id": 358, "seek": 181980, "start": 1823.8, "end": 1828.8, "text": " Yeah. Do you also have the concept of ejecting in your template?", "tokens": [865, 13, 1144, 291, 611, 362, 264, 3410, 295, 32520, 278, 294, 428, 12379, 30], "temperature": 0.0, "avg_logprob": -0.22986636290679108, "compression_ratio": 1.2241379310344827, "no_speech_prob": 0.002115499461069703}, {"id": 359, "seek": 182880, "start": 1828.8, "end": 1849.8, "text": " There is nothing to eject. The nice thing about Vite is everything is self-contained, but if you need to override something, it's very easy to do so. And that philosophy carried over from Vue.js as well, where you had a config. Yes, it used Webpack, but you didn't need to worry about ejecting. You just extended it with your own stuff.", "tokens": [821, 307, 1825, 281, 32520, 13, 440, 1481, 551, 466, 691, 642, 307, 1203, 307, 2698, 12, 9000, 3563, 11, 457, 498, 291, 643, 281, 42321, 746, 11, 309, 311, 588, 1858, 281, 360, 370, 13, 400, 300, 10675, 9094, 670, 490, 691, 622, 13, 25530, 382, 731, 11, 689, 291, 632, 257, 6662, 13, 1079, 11, 309, 1143, 9573, 9539, 11, 457, 291, 994, 380, 643, 281, 3292, 466, 32520, 278, 13, 509, 445, 10913, 309, 365, 428, 1065, 1507, 13], "temperature": 0.0, "avg_logprob": -0.15873419961263968, "compression_ratio": 1.5412844036697249, "no_speech_prob": 0.00013981469965074211}, {"id": 360, "seek": 184980, "start": 1849.8, "end": 1864.8, "text": " For those who don't know, ejecting is when you use Create Elm app or Create React app, you run commands through that CLI, like Create Elm app, Create Elm app run, Create Elm app start or whatever.", "tokens": [1171, 729, 567, 500, 380, 458, 11, 32520, 278, 307, 562, 291, 764, 20248, 2699, 76, 724, 420, 20248, 30644, 724, 11, 291, 1190, 16901, 807, 300, 12855, 40, 11, 411, 20248, 2699, 76, 724, 11, 20248, 2699, 76, 724, 1190, 11, 20248, 2699, 76, 724, 722, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.2367726961771647, "compression_ratio": 1.5193798449612403, "no_speech_prob": 0.0005525341257452965}, {"id": 361, "seek": 186480, "start": 1864.8, "end": 1882.8, "text": " But then whenever you did something too custom, you would have to opt out of using Create React app, Create Elm app. And at that point, you have to eject and you're on your own. And I found it always very scary, like, oh, what if I want to do something custom?", "tokens": [583, 550, 5699, 291, 630, 746, 886, 2375, 11, 291, 576, 362, 281, 2427, 484, 295, 1228, 20248, 30644, 724, 11, 20248, 2699, 76, 724, 13, 400, 412, 300, 935, 11, 291, 362, 281, 32520, 293, 291, 434, 322, 428, 1065, 13, 400, 286, 1352, 309, 1009, 588, 6958, 11, 411, 11, 1954, 11, 437, 498, 286, 528, 281, 360, 746, 2375, 30], "temperature": 0.0, "avg_logprob": -0.2518549392472452, "compression_ratio": 1.5116279069767442, "no_speech_prob": 5.062794662080705e-05}, {"id": 362, "seek": 188280, "start": 1882.8, "end": 1899.8, "text": " Oh, now I have to eject. Oh, now there are so many things that were handled for me automatically that are not anymore. So I'm really happy that you don't have that concept. It's just like, these are the scripts and you do whatever you want. And they're all simple.", "tokens": [876, 11, 586, 286, 362, 281, 32520, 13, 876, 11, 586, 456, 366, 370, 867, 721, 300, 645, 18033, 337, 385, 6772, 300, 366, 406, 3602, 13, 407, 286, 478, 534, 2055, 300, 291, 500, 380, 362, 300, 3410, 13, 467, 311, 445, 411, 11, 613, 366, 264, 23294, 293, 291, 360, 2035, 291, 528, 13, 400, 436, 434, 439, 2199, 13], "temperature": 0.0, "avg_logprob": -0.1706878612567852, "compression_ratio": 1.5104166666666667, "no_speech_prob": 7.966448902152479e-05}, {"id": 363, "seek": 188280, "start": 1899.8, "end": 1900.8, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.1706878612567852, "compression_ratio": 1.5104166666666667, "no_speech_prob": 7.966448902152479e-05}, {"id": 364, "seek": 188280, "start": 1900.8, "end": 1901.8, "text": " That's really nice.", "tokens": [663, 311, 534, 1481, 13], "temperature": 0.0, "avg_logprob": -0.1706878612567852, "compression_ratio": 1.5104166666666667, "no_speech_prob": 7.966448902152479e-05}, {"id": 365, "seek": 190180, "start": 1901.8, "end": 1915.8, "text": " And if you want to extend it with a JavaScript framework, like Vue or Svelte or Solid or React or something, it's really easy to do so because it is just using Vite. I have the opposite problem, Dillon, where I want people to have all the foot guns.", "tokens": [400, 498, 291, 528, 281, 10101, 309, 365, 257, 15778, 8388, 11, 411, 691, 622, 420, 318, 779, 975, 420, 26664, 420, 30644, 420, 746, 11, 309, 311, 534, 1858, 281, 360, 370, 570, 309, 307, 445, 1228, 691, 642, 13, 286, 362, 264, 6182, 1154, 11, 28160, 11, 689, 286, 528, 561, 281, 362, 439, 264, 2671, 10153, 13], "temperature": 0.0, "avg_logprob": -0.18856681219421992, "compression_ratio": 1.609375, "no_speech_prob": 0.0004511933075264096}, {"id": 366, "seek": 190180, "start": 1915.8, "end": 1924.8, "text": " Because I don't want to lock it down. I want people to play with it and explore and feel comfortable with Elm, interacting with the tooling that they already have.", "tokens": [1436, 286, 500, 380, 528, 281, 4017, 309, 760, 13, 286, 528, 561, 281, 862, 365, 309, 293, 6839, 293, 841, 4619, 365, 2699, 76, 11, 18017, 365, 264, 46593, 300, 436, 1217, 362, 13], "temperature": 0.0, "avg_logprob": -0.18856681219421992, "compression_ratio": 1.609375, "no_speech_prob": 0.0004511933075264096}, {"id": 367, "seek": 192480, "start": 1924.8, "end": 1953.8, "text": " Yeah. I mean, the beautiful thing is like all these Create React app, Create Elm app, they were addressing a real need, a real pain point at the time, which was that Webpack was this, you know, very verbose configuration that like you go and copy paste these like very complicated setups just to like, tell it you want like raw imports for CSS.", "tokens": [865, 13, 286, 914, 11, 264, 2238, 551, 307, 411, 439, 613, 20248, 30644, 724, 11, 20248, 2699, 76, 724, 11, 436, 645, 14329, 257, 957, 643, 11, 257, 957, 1822, 935, 412, 264, 565, 11, 597, 390, 300, 9573, 9539, 390, 341, 11, 291, 458, 11, 588, 9595, 541, 11694, 300, 411, 291, 352, 293, 5055, 9163, 613, 411, 588, 6179, 46832, 445, 281, 411, 11, 980, 309, 291, 528, 411, 8936, 41596, 337, 24387, 13], "temperature": 0.0, "avg_logprob": -0.26247340072820213, "compression_ratio": 1.5636363636363637, "no_speech_prob": 8.749710832489654e-05}, {"id": 368, "seek": 195380, "start": 1953.8, "end": 1964.8, "text": " Or you want like, you want it to transpile Elm and things would break frequently. And you're just like, I just I just want to like import an Elm file. I just want to import SCSS.", "tokens": [1610, 291, 528, 411, 11, 291, 528, 309, 281, 7132, 794, 2699, 76, 293, 721, 576, 1821, 10374, 13, 400, 291, 434, 445, 411, 11, 286, 445, 286, 445, 528, 281, 411, 974, 364, 2699, 76, 3991, 13, 286, 445, 528, 281, 974, 9028, 21929, 13], "temperature": 0.0, "avg_logprob": -0.1894443702697754, "compression_ratio": 1.6592920353982301, "no_speech_prob": 7.721895963186398e-05}, {"id": 369, "seek": 195380, "start": 1964.8, "end": 1974.8, "text": " Like, can I just do that? And it's like, yeah, well, here's this configuration. But there's this one thing that's kind of broken in it. And it made things more customizable than they needed to be.", "tokens": [1743, 11, 393, 286, 445, 360, 300, 30, 400, 309, 311, 411, 11, 1338, 11, 731, 11, 510, 311, 341, 11694, 13, 583, 456, 311, 341, 472, 551, 300, 311, 733, 295, 5463, 294, 309, 13, 400, 309, 1027, 721, 544, 47922, 813, 436, 2978, 281, 312, 13], "temperature": 0.0, "avg_logprob": -0.1894443702697754, "compression_ratio": 1.6592920353982301, "no_speech_prob": 7.721895963186398e-05}, {"id": 370, "seek": 197480, "start": 1974.8, "end": 1987.8, "text": " And so it gave you an overly general purpose way of configuring things, which most of the time isn't what people want. They just want to use SCSS. That's, that's all. They just want to import Elm. That's all. And so now...", "tokens": [400, 370, 309, 2729, 291, 364, 24324, 2674, 4334, 636, 295, 6662, 1345, 721, 11, 597, 881, 295, 264, 565, 1943, 380, 437, 561, 528, 13, 814, 445, 528, 281, 764, 9028, 21929, 13, 663, 311, 11, 300, 311, 439, 13, 814, 445, 528, 281, 974, 2699, 76, 13, 663, 311, 439, 13, 400, 370, 586, 485], "temperature": 0.0, "avg_logprob": -0.2068033100646219, "compression_ratio": 1.50253807106599, "no_speech_prob": 1.6187384971999563e-05}, {"id": 371, "seek": 197480, "start": 1987.8, "end": 1992.8, "text": " I don't know if you can tell that Dimon had horror stories about Webpack.", "tokens": [286, 500, 380, 458, 498, 291, 393, 980, 300, 20975, 266, 632, 11501, 3676, 466, 9573, 9539, 13], "temperature": 0.0, "avg_logprob": -0.2068033100646219, "compression_ratio": 1.50253807106599, "no_speech_prob": 1.6187384971999563e-05}, {"id": 372, "seek": 199280, "start": 1992.8, "end": 2014.8, "text": " Well, Elm Pages v2 was built as a Webpack plugin. So I have horror stories. It was painful. It was very painful. Writing custom Webpack plugins was very sparsely documented and error prone and difficult to debug.", "tokens": [1042, 11, 2699, 76, 430, 1660, 371, 17, 390, 3094, 382, 257, 9573, 9539, 23407, 13, 407, 286, 362, 11501, 3676, 13, 467, 390, 11697, 13, 467, 390, 588, 11697, 13, 32774, 2375, 9573, 9539, 33759, 390, 588, 637, 685, 736, 23007, 293, 6713, 25806, 293, 2252, 281, 24083, 13], "temperature": 0.0, "avg_logprob": -0.2116943465338813, "compression_ratio": 1.4421768707482994, "no_speech_prob": 0.00010889574332395568}, {"id": 373, "seek": 201480, "start": 2014.8, "end": 2030.8, "text": " It was like, honestly, probably the hardest technical accomplishment of my career was getting that thing working. It was... And I'm not proud of that. It just was.", "tokens": [467, 390, 411, 11, 6095, 11, 1391, 264, 13158, 6191, 29144, 295, 452, 3988, 390, 1242, 300, 551, 1364, 13, 467, 390, 485, 400, 286, 478, 406, 4570, 295, 300, 13, 467, 445, 390, 13], "temperature": 0.0, "avg_logprob": -0.24564361572265625, "compression_ratio": 1.304, "no_speech_prob": 0.00016603109543211758}, {"id": 374, "seek": 203080, "start": 2030.8, "end": 2044.8, "text": " But so like create React app and create Elm app were addressing a real pain point, which is just you needed a simpler abstraction for how to configure a basic Elm app or basic React app.", "tokens": [583, 370, 411, 1884, 30644, 724, 293, 1884, 2699, 76, 724, 645, 14329, 257, 957, 1822, 935, 11, 597, 307, 445, 291, 2978, 257, 18587, 37765, 337, 577, 281, 22162, 257, 3875, 2699, 76, 724, 420, 3875, 30644, 724, 13], "temperature": 0.0, "avg_logprob": -0.20405919816758897, "compression_ratio": 1.6147186147186148, "no_speech_prob": 5.829007568536326e-05}, {"id": 375, "seek": 203080, "start": 2044.8, "end": 2056.8, "text": " And then Eject was, well, let's address the problem that you might outgrow that and need to do something more custom. But if you don't, then we can hide some of that complexity from you.", "tokens": [400, 550, 462, 1020, 390, 11, 731, 11, 718, 311, 2985, 264, 1154, 300, 291, 1062, 484, 26685, 300, 293, 643, 281, 360, 746, 544, 2375, 13, 583, 498, 291, 500, 380, 11, 550, 321, 393, 6479, 512, 295, 300, 14024, 490, 291, 13], "temperature": 0.0, "avg_logprob": -0.20405919816758897, "compression_ratio": 1.6147186147186148, "no_speech_prob": 5.829007568536326e-05}, {"id": 376, "seek": 205680, "start": 2056.8, "end": 2063.8, "text": " But now with Vite, it's like, well, there's really not that much complexity to hide. You just use the Elm plugin and now you can import Elm.", "tokens": [583, 586, 365, 691, 642, 11, 309, 311, 411, 11, 731, 11, 456, 311, 534, 406, 300, 709, 14024, 281, 6479, 13, 509, 445, 764, 264, 2699, 76, 23407, 293, 586, 291, 393, 974, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.17380213270000383, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.5445222743437625e-05}, {"id": 377, "seek": 205680, "start": 2063.8, "end": 2071.8, "text": " Like we don't need to create a wrapper tool that abstracts the complexity of the basic setup for that for you.", "tokens": [1743, 321, 500, 380, 643, 281, 1884, 257, 46906, 2290, 300, 12649, 82, 264, 14024, 295, 264, 3875, 8657, 337, 300, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.17380213270000383, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.5445222743437625e-05}, {"id": 378, "seek": 205680, "start": 2071.8, "end": 2081.8, "text": " So, man, I think it's a pretty good time in the web ecosystem, I would say. I think we've really gotten some nice, nice tools.", "tokens": [407, 11, 587, 11, 286, 519, 309, 311, 257, 1238, 665, 565, 294, 264, 3670, 11311, 11, 286, 576, 584, 13, 286, 519, 321, 600, 534, 5768, 512, 1481, 11, 1481, 3873, 13], "temperature": 0.0, "avg_logprob": -0.17380213270000383, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.5445222743437625e-05}, {"id": 379, "seek": 208180, "start": 2081.8, "end": 2090.8, "text": " So, yeah. Are there any other kinds of assets that Vite can process that you enjoy using, Lindsay, when you're working with Vite?", "tokens": [407, 11, 1338, 13, 2014, 456, 604, 661, 3685, 295, 9769, 300, 691, 642, 393, 1399, 300, 291, 2103, 1228, 11, 35017, 11, 562, 291, 434, 1364, 365, 691, 642, 30], "temperature": 0.0, "avg_logprob": -0.17048057402023162, "compression_ratio": 1.4921259842519685, "no_speech_prob": 6.14391365161282e-06}, {"id": 380, "seek": 208180, "start": 2090.8, "end": 2100.8, "text": " Primarily what I've used has been CSS, TypeScript and images. So I haven't dug in a ton to all of the flexibility that it offers there.", "tokens": [19671, 3289, 437, 286, 600, 1143, 575, 668, 24387, 11, 15576, 14237, 293, 5267, 13, 407, 286, 2378, 380, 22954, 294, 257, 2952, 281, 439, 295, 264, 12635, 300, 309, 7736, 456, 13], "temperature": 0.0, "avg_logprob": -0.17048057402023162, "compression_ratio": 1.4921259842519685, "no_speech_prob": 6.14391365161282e-06}, {"id": 381, "seek": 208180, "start": 2100.8, "end": 2106.8, "text": " I did play around a bit with WebAssembly and compiling Rust and running that inside of Vite. That was really fun.", "tokens": [286, 630, 862, 926, 257, 857, 365, 9573, 10884, 19160, 293, 715, 4883, 34952, 293, 2614, 300, 1854, 295, 691, 642, 13, 663, 390, 534, 1019, 13], "temperature": 0.0, "avg_logprob": -0.17048057402023162, "compression_ratio": 1.4921259842519685, "no_speech_prob": 6.14391365161282e-06}, {"id": 382, "seek": 210680, "start": 2106.8, "end": 2113.8, "text": " I don't know Rust well enough to make use of it, but I did some simple addition and called it in JavaScript. So that made me happy.", "tokens": [286, 500, 380, 458, 34952, 731, 1547, 281, 652, 764, 295, 309, 11, 457, 286, 630, 512, 2199, 4500, 293, 1219, 309, 294, 15778, 13, 407, 300, 1027, 385, 2055, 13], "temperature": 0.0, "avg_logprob": -0.15845034984832115, "compression_ratio": 1.597457627118644, "no_speech_prob": 7.842838385840878e-05}, {"id": 383, "seek": 210680, "start": 2113.8, "end": 2122.8, "text": " One of the other features, though, that I really like that ties into this use of standards is using web workers inside of Vite.", "tokens": [1485, 295, 264, 661, 4122, 11, 1673, 11, 300, 286, 534, 411, 300, 14039, 666, 341, 764, 295, 7787, 307, 1228, 3670, 5600, 1854, 295, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.15845034984832115, "compression_ratio": 1.597457627118644, "no_speech_prob": 7.842838385840878e-05}, {"id": 384, "seek": 210680, "start": 2122.8, "end": 2131.8, "text": " So when you instantiate a web worker, there's the web standard way of doing it. And Vite just supports that standard.", "tokens": [407, 562, 291, 9836, 13024, 257, 3670, 11346, 11, 456, 311, 264, 3670, 3832, 636, 295, 884, 309, 13, 400, 691, 642, 445, 9346, 300, 3832, 13], "temperature": 0.0, "avg_logprob": -0.15845034984832115, "compression_ratio": 1.597457627118644, "no_speech_prob": 7.842838385840878e-05}, {"id": 385, "seek": 213180, "start": 2131.8, "end": 2142.8, "text": " So if you want to instantiate a web worker, you just call it the exact same way. Or there's a special syntax as well that they offer from a previous version of Vite, but it's no longer the recommended way.", "tokens": [407, 498, 291, 528, 281, 9836, 13024, 257, 3670, 11346, 11, 291, 445, 818, 309, 264, 1900, 912, 636, 13, 1610, 456, 311, 257, 2121, 28431, 382, 731, 300, 436, 2626, 490, 257, 3894, 3037, 295, 691, 642, 11, 457, 309, 311, 572, 2854, 264, 9628, 636, 13], "temperature": 0.0, "avg_logprob": -0.18876882118753868, "compression_ratio": 1.6718146718146718, "no_speech_prob": 9.665572179073934e-06}, {"id": 386, "seek": 213180, "start": 2142.8, "end": 2151.8, "text": " So you could call new worker just like you would if you were in a standard JavaScript file, reference the URL for your worker JavaScript.", "tokens": [407, 291, 727, 818, 777, 11346, 445, 411, 291, 576, 498, 291, 645, 294, 257, 3832, 15778, 3991, 11, 6408, 264, 12905, 337, 428, 11346, 15778, 13], "temperature": 0.0, "avg_logprob": -0.18876882118753868, "compression_ratio": 1.6718146718146718, "no_speech_prob": 9.665572179073934e-06}, {"id": 387, "seek": 213180, "start": 2151.8, "end": 2157.8, "text": " Or you can import worker from worker and then append it with a query parameter of worker.", "tokens": [1610, 291, 393, 974, 11346, 490, 11346, 293, 550, 34116, 309, 365, 257, 14581, 13075, 295, 11346, 13], "temperature": 0.0, "avg_logprob": -0.18876882118753868, "compression_ratio": 1.6718146718146718, "no_speech_prob": 9.665572179073934e-06}, {"id": 388, "seek": 215780, "start": 2157.8, "end": 2162.8, "text": " And you want to give people a short introduction to what a web worker is?", "tokens": [400, 291, 528, 281, 976, 561, 257, 2099, 9339, 281, 437, 257, 3670, 11346, 307, 30], "temperature": 0.0, "avg_logprob": -0.16571229620824887, "compression_ratio": 1.5462962962962963, "no_speech_prob": 1.750215051288251e-05}, {"id": 389, "seek": 215780, "start": 2162.8, "end": 2173.8, "text": " Absolutely. Web workers are if you have a long running or high calculation task in JavaScript or just the front end in general, and you need to run that.", "tokens": [7021, 13, 9573, 5600, 366, 498, 291, 362, 257, 938, 2614, 420, 1090, 17108, 5633, 294, 15778, 420, 445, 264, 1868, 917, 294, 2674, 11, 293, 291, 643, 281, 1190, 300, 13], "temperature": 0.0, "avg_logprob": -0.16571229620824887, "compression_ratio": 1.5462962962962963, "no_speech_prob": 1.750215051288251e-05}, {"id": 390, "seek": 215780, "start": 2173.8, "end": 2179.8, "text": " Typically, if you're just doing it in the main application, you're going to cause issues with the browser.", "tokens": [23129, 11, 498, 291, 434, 445, 884, 309, 294, 264, 2135, 3861, 11, 291, 434, 516, 281, 3082, 2663, 365, 264, 11185, 13], "temperature": 0.0, "avg_logprob": -0.16571229620824887, "compression_ratio": 1.5462962962962963, "no_speech_prob": 1.750215051288251e-05}, {"id": 391, "seek": 217980, "start": 2179.8, "end": 2187.8, "text": " Example of this can be CSS not updating properly if somebody moves their mouse and the hover animation doesn't change, that could be what's happening.", "tokens": [24755, 781, 295, 341, 393, 312, 24387, 406, 25113, 6108, 498, 2618, 6067, 641, 9719, 293, 264, 20076, 9603, 1177, 380, 1319, 11, 300, 727, 312, 437, 311, 2737, 13], "temperature": 0.0, "avg_logprob": -0.17769081984894186, "compression_ratio": 1.5321100917431192, "no_speech_prob": 8.480146789224818e-05}, {"id": 392, "seek": 217980, "start": 2187.8, "end": 2193.8, "text": " The goal of a web worker is to get it off of the main thread and into its own subsection of the browser.", "tokens": [440, 3387, 295, 257, 3670, 11346, 307, 281, 483, 309, 766, 295, 264, 2135, 7207, 293, 666, 1080, 1065, 1422, 11963, 295, 264, 11185, 13], "temperature": 0.0, "avg_logprob": -0.17769081984894186, "compression_ratio": 1.5321100917431192, "no_speech_prob": 8.480146789224818e-05}, {"id": 393, "seek": 217980, "start": 2193.8, "end": 2198.8, "text": " And then you can pass messages to and from the web worker just via JavaScript.", "tokens": [400, 550, 291, 393, 1320, 7897, 281, 293, 490, 264, 3670, 11346, 445, 5766, 15778, 13], "temperature": 0.0, "avg_logprob": -0.17769081984894186, "compression_ratio": 1.5321100917431192, "no_speech_prob": 8.480146789224818e-05}, {"id": 394, "seek": 219880, "start": 2198.8, "end": 2209.8, "text": " So, for example, on my blog, I wrote a blog post about this where you could have two Elm applications, one being the view layer and one being the web worker.", "tokens": [407, 11, 337, 1365, 11, 322, 452, 6968, 11, 286, 4114, 257, 6968, 2183, 466, 341, 689, 291, 727, 362, 732, 2699, 76, 5821, 11, 472, 885, 264, 1910, 4583, 293, 472, 885, 264, 3670, 11346, 13], "temperature": 0.0, "avg_logprob": -0.1847199891742907, "compression_ratio": 1.7573221757322175, "no_speech_prob": 6.747828138031764e-06}, {"id": 395, "seek": 219880, "start": 2209.8, "end": 2215.8, "text": " And these two Elm applications are just communicating via this messaging protocol and then passing the messages into their ports.", "tokens": [400, 613, 732, 2699, 76, 5821, 366, 445, 17559, 5766, 341, 21812, 10336, 293, 550, 8437, 264, 7897, 666, 641, 18160, 13], "temperature": 0.0, "avg_logprob": -0.1847199891742907, "compression_ratio": 1.7573221757322175, "no_speech_prob": 6.747828138031764e-06}, {"id": 396, "seek": 219880, "start": 2215.8, "end": 2221.8, "text": " So it becomes an effective way to have two Elm applications talk to each other if you need to do complex calculations inside of Elm.", "tokens": [407, 309, 3643, 364, 4942, 636, 281, 362, 732, 2699, 76, 5821, 751, 281, 1184, 661, 498, 291, 643, 281, 360, 3997, 20448, 1854, 295, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.1847199891742907, "compression_ratio": 1.7573221757322175, "no_speech_prob": 6.747828138031764e-06}, {"id": 397, "seek": 222180, "start": 2221.8, "end": 2230.8, "text": " Yeah, Elm's architecture is actually very interesting for this because of the way it separates the sort of DOM mutation.", "tokens": [865, 11, 2699, 76, 311, 9482, 307, 767, 588, 1880, 337, 341, 570, 295, 264, 636, 309, 34149, 264, 1333, 295, 35727, 27960, 13], "temperature": 0.0, "avg_logprob": -0.21986188593598985, "compression_ratio": 1.6820083682008369, "no_speech_prob": 7.07177923686686e-06}, {"id": 398, "seek": 222180, "start": 2230.8, "end": 2241.8, "text": " And because of the whole virtual DOM diffing and everything, conceptually, you can really separate the state part of it from the DOM updating part of it,", "tokens": [400, 570, 295, 264, 1379, 6374, 35727, 7593, 278, 293, 1203, 11, 3410, 671, 11, 291, 393, 534, 4994, 264, 1785, 644, 295, 309, 490, 264, 35727, 25113, 644, 295, 309, 11], "temperature": 0.0, "avg_logprob": -0.21986188593598985, "compression_ratio": 1.6820083682008369, "no_speech_prob": 7.07177923686686e-06}, {"id": 399, "seek": 222180, "start": 2241.8, "end": 2247.8, "text": " which is basically what web workers can't touch the DOM, but they can run code.", "tokens": [597, 307, 1936, 437, 3670, 5600, 393, 380, 2557, 264, 35727, 11, 457, 436, 393, 1190, 3089, 13], "temperature": 0.0, "avg_logprob": -0.21986188593598985, "compression_ratio": 1.6820083682008369, "no_speech_prob": 7.07177923686686e-06}, {"id": 400, "seek": 222180, "start": 2247.8, "end": 2250.8, "text": " And it's a good kind of way to split things up.", "tokens": [400, 309, 311, 257, 665, 733, 295, 636, 281, 7472, 721, 493, 13], "temperature": 0.0, "avg_logprob": -0.21986188593598985, "compression_ratio": 1.6820083682008369, "no_speech_prob": 7.07177923686686e-06}, {"id": 401, "seek": 225080, "start": 2250.8, "end": 2256.8, "text": " Yeah, and the fact that Elm has platform.worker that doesn't require looking at the DOM,", "tokens": [865, 11, 293, 264, 1186, 300, 2699, 76, 575, 3663, 13, 49402, 300, 1177, 380, 3651, 1237, 412, 264, 35727, 11], "temperature": 0.0, "avg_logprob": -0.1880336357997014, "compression_ratio": 1.618320610687023, "no_speech_prob": 2.468273669364862e-05}, {"id": 402, "seek": 225080, "start": 2256.8, "end": 2261.8, "text": " so you can just render that in a headless environment such as a worker or a node.", "tokens": [370, 291, 393, 445, 15529, 300, 294, 257, 1378, 1832, 2823, 1270, 382, 257, 11346, 420, 257, 9984, 13], "temperature": 0.0, "avg_logprob": -0.1880336357997014, "compression_ratio": 1.618320610687023, "no_speech_prob": 2.468273669364862e-05}, {"id": 403, "seek": 225080, "start": 2261.8, "end": 2267.8, "text": " But you can use that to instantiate an Elm application that can then just communicate via ports.", "tokens": [583, 291, 393, 764, 300, 281, 9836, 13024, 364, 2699, 76, 3861, 300, 393, 550, 445, 7890, 5766, 18160, 13], "temperature": 0.0, "avg_logprob": -0.1880336357997014, "compression_ratio": 1.618320610687023, "no_speech_prob": 2.468273669364862e-05}, {"id": 404, "seek": 225080, "start": 2267.8, "end": 2271.8, "text": " It takes an input and that's all of the inputs to its update function.", "tokens": [467, 2516, 364, 4846, 293, 300, 311, 439, 295, 264, 15743, 281, 1080, 5623, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1880336357997014, "compression_ratio": 1.618320610687023, "no_speech_prob": 2.468273669364862e-05}, {"id": 405, "seek": 225080, "start": 2271.8, "end": 2277.8, "text": " Yeah, I think this could definitely be a really interesting thing to experiment with.", "tokens": [865, 11, 286, 519, 341, 727, 2138, 312, 257, 534, 1880, 551, 281, 5120, 365, 13], "temperature": 0.0, "avg_logprob": -0.1880336357997014, "compression_ratio": 1.618320610687023, "no_speech_prob": 2.468273669364862e-05}, {"id": 406, "seek": 227780, "start": 2277.8, "end": 2286.8, "text": " I could imagine at a framework level abstracting this way, especially because I think there's a clear segregation between the processes.", "tokens": [286, 727, 3811, 412, 257, 8388, 1496, 12649, 278, 341, 636, 11, 2318, 570, 286, 519, 456, 311, 257, 1850, 34317, 1296, 264, 7555, 13], "temperature": 0.0, "avg_logprob": -0.23038182939801896, "compression_ratio": 1.4798206278026906, "no_speech_prob": 6.108730303822085e-05}, {"id": 407, "seek": 227780, "start": 2286.8, "end": 2294.8, "text": " So you have to use array buffers to send messages back and forth, which is a little bit awkward.", "tokens": [407, 291, 362, 281, 764, 10225, 9204, 433, 281, 2845, 7897, 646, 293, 5220, 11, 597, 307, 257, 707, 857, 11411, 13], "temperature": 0.0, "avg_logprob": -0.23038182939801896, "compression_ratio": 1.4798206278026906, "no_speech_prob": 6.108730303822085e-05}, {"id": 408, "seek": 227780, "start": 2294.8, "end": 2298.8, "text": " Can you send JSON as well, maybe?", "tokens": [1664, 291, 2845, 31828, 382, 731, 11, 1310, 30], "temperature": 0.0, "avg_logprob": -0.23038182939801896, "compression_ratio": 1.4798206278026906, "no_speech_prob": 6.108730303822085e-05}, {"id": 409, "seek": 227780, "start": 2298.8, "end": 2300.8, "text": " I believe you can just send JSON.", "tokens": [286, 1697, 291, 393, 445, 2845, 31828, 13], "temperature": 0.0, "avg_logprob": -0.23038182939801896, "compression_ratio": 1.4798206278026906, "no_speech_prob": 6.108730303822085e-05}, {"id": 410, "seek": 227780, "start": 2300.8, "end": 2302.8, "text": " You can send JSON too? Yeah.", "tokens": [509, 393, 2845, 31828, 886, 30, 865, 13], "temperature": 0.0, "avg_logprob": -0.23038182939801896, "compression_ratio": 1.4798206278026906, "no_speech_prob": 6.108730303822085e-05}, {"id": 411, "seek": 230280, "start": 2302.8, "end": 2308.8, "text": " My side projects in Elm is a turn-based strategy game and I'm using a web worker to do the AI calculations.", "tokens": [1222, 1252, 4455, 294, 2699, 76, 307, 257, 1261, 12, 6032, 5206, 1216, 293, 286, 478, 1228, 257, 3670, 11346, 281, 360, 264, 7318, 20448, 13], "temperature": 0.0, "avg_logprob": -0.18219294086579355, "compression_ratio": 1.596958174904943, "no_speech_prob": 0.00012532506661955267}, {"id": 412, "seek": 230280, "start": 2308.8, "end": 2309.8, "text": " Nice.", "tokens": [5490, 13], "temperature": 0.0, "avg_logprob": -0.18219294086579355, "compression_ratio": 1.596958174904943, "no_speech_prob": 0.00012532506661955267}, {"id": 413, "seek": 230280, "start": 2309.8, "end": 2311.8, "text": " So I just send the game state over as JSON.", "tokens": [407, 286, 445, 2845, 264, 1216, 1785, 670, 382, 31828, 13], "temperature": 0.0, "avg_logprob": -0.18219294086579355, "compression_ratio": 1.596958174904943, "no_speech_prob": 0.00012532506661955267}, {"id": 414, "seek": 230280, "start": 2311.8, "end": 2314.8, "text": " So from Elm to Elm again?", "tokens": [407, 490, 2699, 76, 281, 2699, 76, 797, 30], "temperature": 0.0, "avg_logprob": -0.18219294086579355, "compression_ratio": 1.596958174904943, "no_speech_prob": 0.00012532506661955267}, {"id": 415, "seek": 230280, "start": 2314.8, "end": 2315.8, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.18219294086579355, "compression_ratio": 1.596958174904943, "no_speech_prob": 0.00012532506661955267}, {"id": 416, "seek": 230280, "start": 2315.8, "end": 2319.8, "text": " Because it's too slow to have it in the Elm main thread?", "tokens": [1436, 309, 311, 886, 2964, 281, 362, 309, 294, 264, 2699, 76, 2135, 7207, 30], "temperature": 0.0, "avg_logprob": -0.18219294086579355, "compression_ratio": 1.596958174904943, "no_speech_prob": 0.00012532506661955267}, {"id": 417, "seek": 230280, "start": 2319.8, "end": 2324.8, "text": " Yep. The problem I was having in the game context, in a late stage of the game,", "tokens": [7010, 13, 440, 1154, 286, 390, 1419, 294, 264, 1216, 4319, 11, 294, 257, 3469, 3233, 295, 264, 1216, 11], "temperature": 0.0, "avg_logprob": -0.18219294086579355, "compression_ratio": 1.596958174904943, "no_speech_prob": 0.00012532506661955267}, {"id": 418, "seek": 230280, "start": 2324.8, "end": 2328.8, "text": " there were a lot of pieces on the board, there was a lot of options available to the computer,", "tokens": [456, 645, 257, 688, 295, 3755, 322, 264, 3150, 11, 456, 390, 257, 688, 295, 3956, 2435, 281, 264, 3820, 11], "temperature": 0.0, "avg_logprob": -0.18219294086579355, "compression_ratio": 1.596958174904943, "no_speech_prob": 0.00012532506661955267}, {"id": 419, "seek": 232880, "start": 2328.8, "end": 2334.8, "text": " and it would have to cycle through all of the cells, all of the units, all of the combinations of units,", "tokens": [293, 309, 576, 362, 281, 6586, 807, 439, 295, 264, 5438, 11, 439, 295, 264, 6815, 11, 439, 295, 264, 21267, 295, 6815, 11], "temperature": 0.0, "avg_logprob": -0.1643878126566389, "compression_ratio": 1.6816326530612244, "no_speech_prob": 6.813814252382144e-05}, {"id": 420, "seek": 232880, "start": 2334.8, "end": 2336.8, "text": " and make a decision on what to do.", "tokens": [293, 652, 257, 3537, 322, 437, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.1643878126566389, "compression_ratio": 1.6816326530612244, "no_speech_prob": 6.813814252382144e-05}, {"id": 421, "seek": 232880, "start": 2336.8, "end": 2342.8, "text": " And when it was doing that in the main thread, all of the CSS would stop working.", "tokens": [400, 562, 309, 390, 884, 300, 294, 264, 2135, 7207, 11, 439, 295, 264, 24387, 576, 1590, 1364, 13], "temperature": 0.0, "avg_logprob": -0.1643878126566389, "compression_ratio": 1.6816326530612244, "no_speech_prob": 6.813814252382144e-05}, {"id": 422, "seek": 232880, "start": 2342.8, "end": 2348.8, "text": " So if you tried to do anything, or even just open the menu and say, I'm done playing, get me out of here, you couldn't do that.", "tokens": [407, 498, 291, 3031, 281, 360, 1340, 11, 420, 754, 445, 1269, 264, 6510, 293, 584, 11, 286, 478, 1096, 2433, 11, 483, 385, 484, 295, 510, 11, 291, 2809, 380, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.1643878126566389, "compression_ratio": 1.6816326530612244, "no_speech_prob": 6.813814252382144e-05}, {"id": 423, "seek": 232880, "start": 2348.8, "end": 2354.8, "text": " So I switched that all to being sent via JSON to a web worker,", "tokens": [407, 286, 16858, 300, 439, 281, 885, 2279, 5766, 31828, 281, 257, 3670, 11346, 11], "temperature": 0.0, "avg_logprob": -0.1643878126566389, "compression_ratio": 1.6816326530612244, "no_speech_prob": 6.813814252382144e-05}, {"id": 424, "seek": 235480, "start": 2354.8, "end": 2359.8, "text": " and then just decoding it back into Elm, performing the calculation, and then shipping it back.", "tokens": [293, 550, 445, 979, 8616, 309, 646, 666, 2699, 76, 11, 10205, 264, 17108, 11, 293, 550, 14122, 309, 646, 13], "temperature": 0.0, "avg_logprob": -0.19616139188725898, "compression_ratio": 1.6475409836065573, "no_speech_prob": 3.2698553695809096e-05}, {"id": 425, "seek": 235480, "start": 2359.8, "end": 2365.8, "text": " So it can still take time, because it's having to do all those calculations, but it's not blocking the CSS anymore.", "tokens": [407, 309, 393, 920, 747, 565, 11, 570, 309, 311, 1419, 281, 360, 439, 729, 20448, 11, 457, 309, 311, 406, 17776, 264, 24387, 3602, 13], "temperature": 0.0, "avg_logprob": -0.19616139188725898, "compression_ratio": 1.6475409836065573, "no_speech_prob": 3.2698553695809096e-05}, {"id": 426, "seek": 235480, "start": 2365.8, "end": 2370.8, "text": " That would be really interesting if there was some abstraction where you could basically say,", "tokens": [663, 576, 312, 534, 1880, 498, 456, 390, 512, 37765, 689, 291, 727, 1936, 584, 11], "temperature": 0.0, "avg_logprob": -0.19616139188725898, "compression_ratio": 1.6475409836065573, "no_speech_prob": 3.2698553695809096e-05}, {"id": 427, "seek": 235480, "start": 2370.8, "end": 2377.8, "text": " here's a message to send back when this long-running computation is done on a web worker thread.", "tokens": [510, 311, 257, 3636, 281, 2845, 646, 562, 341, 938, 12, 45482, 24903, 307, 1096, 322, 257, 3670, 11346, 7207, 13], "temperature": 0.0, "avg_logprob": -0.19616139188725898, "compression_ratio": 1.6475409836065573, "no_speech_prob": 3.2698553695809096e-05}, {"id": 428, "seek": 237780, "start": 2377.8, "end": 2387.8, "text": " And then you could say, I'm awaiting the AI response for this, and I'm going to show this as loading", "tokens": [400, 550, 291, 727, 584, 11, 286, 478, 43759, 264, 7318, 4134, 337, 341, 11, 293, 286, 478, 516, 281, 855, 341, 382, 15114], "temperature": 0.0, "avg_logprob": -0.170859859835717, "compression_ratio": 1.5378151260504203, "no_speech_prob": 1.9033651597055723e-06}, {"id": 429, "seek": 237780, "start": 2387.8, "end": 2394.8, "text": " until I get that message and update my model, having gotten the computation from the AI's prediction or whatever.", "tokens": [1826, 286, 483, 300, 3636, 293, 5623, 452, 2316, 11, 1419, 5768, 264, 24903, 490, 264, 7318, 311, 17630, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.170859859835717, "compression_ratio": 1.5378151260504203, "no_speech_prob": 1.9033651597055723e-06}, {"id": 430, "seek": 237780, "start": 2394.8, "end": 2396.8, "text": " Could be really interesting.", "tokens": [7497, 312, 534, 1880, 13], "temperature": 0.0, "avg_logprob": -0.170859859835717, "compression_ratio": 1.5378151260504203, "no_speech_prob": 1.9033651597055723e-06}, {"id": 431, "seek": 237780, "start": 2396.8, "end": 2403.8, "text": " So Vite, why do we need a special syntax for importing something as a web worker with Vite?", "tokens": [407, 691, 642, 11, 983, 360, 321, 643, 257, 2121, 28431, 337, 43866, 746, 382, 257, 3670, 11346, 365, 691, 642, 30], "temperature": 0.0, "avg_logprob": -0.170859859835717, "compression_ratio": 1.5378151260504203, "no_speech_prob": 1.9033651597055723e-06}, {"id": 432, "seek": 237780, "start": 2403.8, "end": 2405.8, "text": " How does it help us with that?", "tokens": [1012, 775, 309, 854, 505, 365, 300, 30], "temperature": 0.0, "avg_logprob": -0.170859859835717, "compression_ratio": 1.5378151260504203, "no_speech_prob": 1.9033651597055723e-06}, {"id": 433, "seek": 240580, "start": 2405.8, "end": 2411.8, "text": " I believe the original problem was how Vite was doing its compilation to ES modules.", "tokens": [286, 1697, 264, 3380, 1154, 390, 577, 691, 642, 390, 884, 1080, 40261, 281, 12564, 16679, 13], "temperature": 0.0, "avg_logprob": -0.16327358631605512, "compression_ratio": 1.6342592592592593, "no_speech_prob": 5.862735179107403e-06}, {"id": 434, "seek": 240580, "start": 2411.8, "end": 2418.8, "text": " The worker syntax was just not playing nicely with how the bundling was happening under the hood.", "tokens": [440, 11346, 28431, 390, 445, 406, 2433, 9594, 365, 577, 264, 13882, 1688, 390, 2737, 833, 264, 13376, 13], "temperature": 0.0, "avg_logprob": -0.16327358631605512, "compression_ratio": 1.6342592592592593, "no_speech_prob": 5.862735179107403e-06}, {"id": 435, "seek": 240580, "start": 2418.8, "end": 2423.8, "text": " So the version I was working with at the time, I believe, was Vite 2.", "tokens": [407, 264, 3037, 286, 390, 1364, 365, 412, 264, 565, 11, 286, 1697, 11, 390, 691, 642, 568, 13], "temperature": 0.0, "avg_logprob": -0.16327358631605512, "compression_ratio": 1.6342592592592593, "no_speech_prob": 5.862735179107403e-06}, {"id": 436, "seek": 240580, "start": 2423.8, "end": 2430.8, "text": " Vite 4.0 has now released, and looking at the docs, they now support the standard new worker syntax.", "tokens": [691, 642, 1017, 13, 15, 575, 586, 4736, 11, 293, 1237, 412, 264, 45623, 11, 436, 586, 1406, 264, 3832, 777, 11346, 28431, 13], "temperature": 0.0, "avg_logprob": -0.16327358631605512, "compression_ratio": 1.6342592592592593, "no_speech_prob": 5.862735179107403e-06}, {"id": 437, "seek": 243080, "start": 2430.8, "end": 2435.8, "text": " And when you were talking about this, importing this WebAssembly Rust,", "tokens": [400, 562, 291, 645, 1417, 466, 341, 11, 43866, 341, 9573, 10884, 19160, 34952, 11], "temperature": 0.0, "avg_logprob": -0.19941127447434415, "compression_ratio": 1.614213197969543, "no_speech_prob": 6.786591484342352e-07}, {"id": 438, "seek": 243080, "start": 2435.8, "end": 2444.8, "text": " was Vite actually running the Rust compilation step for you, or was it importing Wasm that you had compiled from Rust?", "tokens": [390, 691, 642, 767, 2614, 264, 34952, 40261, 1823, 337, 291, 11, 420, 390, 309, 43866, 3027, 76, 300, 291, 632, 36548, 490, 34952, 30], "temperature": 0.0, "avg_logprob": -0.19941127447434415, "compression_ratio": 1.614213197969543, "no_speech_prob": 6.786591484342352e-07}, {"id": 439, "seek": 243080, "start": 2444.8, "end": 2448.8, "text": " There is a plugin for Vite that will compile Wasm.", "tokens": [821, 307, 257, 23407, 337, 691, 642, 300, 486, 31413, 3027, 76, 13], "temperature": 0.0, "avg_logprob": -0.19941127447434415, "compression_ratio": 1.614213197969543, "no_speech_prob": 6.786591484342352e-07}, {"id": 440, "seek": 243080, "start": 2448.8, "end": 2453.8, "text": " However, it still has to be a separate step from running the Vite dev server.", "tokens": [2908, 11, 309, 920, 575, 281, 312, 257, 4994, 1823, 490, 2614, 264, 691, 642, 1905, 7154, 13], "temperature": 0.0, "avg_logprob": -0.19941127447434415, "compression_ratio": 1.614213197969543, "no_speech_prob": 6.786591484342352e-07}, {"id": 441, "seek": 245380, "start": 2453.8, "end": 2460.8, "text": " But you are using the Vite config at that point, you're using the standard tooling that you're using for the rest of your application.", "tokens": [583, 291, 366, 1228, 264, 691, 642, 6662, 412, 300, 935, 11, 291, 434, 1228, 264, 3832, 46593, 300, 291, 434, 1228, 337, 264, 1472, 295, 428, 3861, 13], "temperature": 0.0, "avg_logprob": -0.16319080878948344, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00020650579244829714}, {"id": 442, "seek": 245380, "start": 2460.8, "end": 2464.8, "text": " You just need to compile that first, then start your dev server.", "tokens": [509, 445, 643, 281, 31413, 300, 700, 11, 550, 722, 428, 1905, 7154, 13], "temperature": 0.0, "avg_logprob": -0.16319080878948344, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00020650579244829714}, {"id": 443, "seek": 245380, "start": 2464.8, "end": 2470.8, "text": " So when I was playing with it, I had a separate step before actually instantiating the Vite dev server.", "tokens": [407, 562, 286, 390, 2433, 365, 309, 11, 286, 632, 257, 4994, 1823, 949, 767, 9836, 72, 990, 264, 691, 642, 1905, 7154, 13], "temperature": 0.0, "avg_logprob": -0.16319080878948344, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00020650579244829714}, {"id": 444, "seek": 245380, "start": 2470.8, "end": 2474.8, "text": " But I could just run npm run dev, and I didn't have to think about it.", "tokens": [583, 286, 727, 445, 1190, 297, 14395, 1190, 1905, 11, 293, 286, 994, 380, 362, 281, 519, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.16319080878948344, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00020650579244829714}, {"id": 445, "seek": 245380, "start": 2474.8, "end": 2477.8, "text": " I don't understand. How come you need to have a separate step for that?", "tokens": [286, 500, 380, 1223, 13, 1012, 808, 291, 643, 281, 362, 257, 4994, 1823, 337, 300, 30], "temperature": 0.0, "avg_logprob": -0.16319080878948344, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00020650579244829714}, {"id": 446, "seek": 247780, "start": 2477.8, "end": 2486.8, "text": " It may have changed, but the last time I looked, the Wasm file isn't actually generated until you do the compilation.", "tokens": [467, 815, 362, 3105, 11, 457, 264, 1036, 565, 286, 2956, 11, 264, 3027, 76, 3991, 1943, 380, 767, 10833, 1826, 291, 360, 264, 40261, 13], "temperature": 0.0, "avg_logprob": -0.1781026695956703, "compression_ratio": 1.6867924528301887, "no_speech_prob": 5.143495218362659e-05}, {"id": 447, "seek": 247780, "start": 2486.8, "end": 2490.8, "text": " Otherwise, you're just writing Rust files and you're in the Rust environment.", "tokens": [10328, 11, 291, 434, 445, 3579, 34952, 7098, 293, 291, 434, 294, 264, 34952, 2823, 13], "temperature": 0.0, "avg_logprob": -0.1781026695956703, "compression_ratio": 1.6867924528301887, "no_speech_prob": 5.143495218362659e-05}, {"id": 448, "seek": 247780, "start": 2490.8, "end": 2494.8, "text": " So when you're compiling Rust, you need to say, I'm targeting WebAssembly,", "tokens": [407, 562, 291, 434, 715, 4883, 34952, 11, 291, 643, 281, 584, 11, 286, 478, 17918, 9573, 10884, 19160, 11], "temperature": 0.0, "avg_logprob": -0.1781026695956703, "compression_ratio": 1.6867924528301887, "no_speech_prob": 5.143495218362659e-05}, {"id": 449, "seek": 247780, "start": 2494.8, "end": 2498.8, "text": " and that's what generates the Wasm file for you to import inside of Vite.", "tokens": [293, 300, 311, 437, 23815, 264, 3027, 76, 3991, 337, 291, 281, 974, 1854, 295, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.1781026695956703, "compression_ratio": 1.6867924528301887, "no_speech_prob": 5.143495218362659e-05}, {"id": 450, "seek": 247780, "start": 2498.8, "end": 2506.8, "text": " I thought of the way that Vite worked is you have an index.html file, and you have a bunch of imports.", "tokens": [286, 1194, 295, 264, 636, 300, 691, 642, 2732, 307, 291, 362, 364, 8186, 13, 357, 15480, 3991, 11, 293, 291, 362, 257, 3840, 295, 41596, 13], "temperature": 0.0, "avg_logprob": -0.1781026695956703, "compression_ratio": 1.6867924528301887, "no_speech_prob": 5.143495218362659e-05}, {"id": 451, "seek": 250680, "start": 2506.8, "end": 2515.8, "text": " And if you import something like something.wasm, then it figures out, okay, I know this file, and it comes from this step.", "tokens": [400, 498, 291, 974, 746, 411, 746, 13, 6569, 76, 11, 550, 309, 9624, 484, 11, 1392, 11, 286, 458, 341, 3991, 11, 293, 309, 1487, 490, 341, 1823, 13], "temperature": 0.0, "avg_logprob": -0.21213464958723202, "compression_ratio": 1.5215311004784688, "no_speech_prob": 2.7108360882266425e-05}, {"id": 452, "seek": 250680, "start": 2515.8, "end": 2521.8, "text": " Is that the problem? It doesn't know which task makes it?", "tokens": [1119, 300, 264, 1154, 30, 467, 1177, 380, 458, 597, 5633, 1669, 309, 30], "temperature": 0.0, "avg_logprob": -0.21213464958723202, "compression_ratio": 1.5215311004784688, "no_speech_prob": 2.7108360882266425e-05}, {"id": 453, "seek": 250680, "start": 2521.8, "end": 2525.8, "text": " I believe if you updated the Wasm file, it would work fine.", "tokens": [286, 1697, 498, 291, 10588, 264, 3027, 76, 3991, 11, 309, 576, 589, 2489, 13], "temperature": 0.0, "avg_logprob": -0.21213464958723202, "compression_ratio": 1.5215311004784688, "no_speech_prob": 2.7108360882266425e-05}, {"id": 454, "seek": 250680, "start": 2525.8, "end": 2530.8, "text": " The setup that I was using had it as part of spinning up the dev environment.", "tokens": [440, 8657, 300, 286, 390, 1228, 632, 309, 382, 644, 295, 15640, 493, 264, 1905, 2823, 13], "temperature": 0.0, "avg_logprob": -0.21213464958723202, "compression_ratio": 1.5215311004784688, "no_speech_prob": 2.7108360882266425e-05}, {"id": 455, "seek": 253080, "start": 2530.8, "end": 2537.8, "text": " So I don't think it would be hot reload in that sense, because WebAssembly can't do that, I believe.", "tokens": [407, 286, 500, 380, 519, 309, 576, 312, 2368, 25628, 294, 300, 2020, 11, 570, 9573, 10884, 19160, 393, 380, 360, 300, 11, 286, 1697, 13], "temperature": 0.0, "avg_logprob": -0.18193634607458628, "compression_ratio": 1.5658536585365854, "no_speech_prob": 9.972746738640126e-06}, {"id": 456, "seek": 253080, "start": 2537.8, "end": 2541.8, "text": " But you do get the benefit of if you do a refresh, then it's there.", "tokens": [583, 291, 360, 483, 264, 5121, 295, 498, 291, 360, 257, 15134, 11, 550, 309, 311, 456, 13], "temperature": 0.0, "avg_logprob": -0.18193634607458628, "compression_ratio": 1.5658536585365854, "no_speech_prob": 9.972746738640126e-06}, {"id": 457, "seek": 253080, "start": 2541.8, "end": 2553.8, "text": " I wonder if you would be able to set up like a Vite plugin to say when I import a Rust file, compile it to Wasm and then import that.", "tokens": [286, 2441, 498, 291, 576, 312, 1075, 281, 992, 493, 411, 257, 691, 642, 23407, 281, 584, 562, 286, 974, 257, 34952, 3991, 11, 31413, 309, 281, 3027, 76, 293, 550, 974, 300, 13], "temperature": 0.0, "avg_logprob": -0.18193634607458628, "compression_ratio": 1.5658536585365854, "no_speech_prob": 9.972746738640126e-06}, {"id": 458, "seek": 253080, "start": 2553.8, "end": 2557.8, "text": " I would love that.", "tokens": [286, 576, 959, 300, 13], "temperature": 0.0, "avg_logprob": -0.18193634607458628, "compression_ratio": 1.5658536585365854, "no_speech_prob": 9.972746738640126e-06}, {"id": 459, "seek": 255780, "start": 2557.8, "end": 2560.8, "text": " So you mentioned that there is hot reload even for Elm.", "tokens": [407, 291, 2835, 300, 456, 307, 2368, 25628, 754, 337, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.23391405741373697, "compression_ratio": 1.7706766917293233, "no_speech_prob": 4.331512900535017e-05}, {"id": 460, "seek": 255780, "start": 2560.8, "end": 2566.8, "text": " Can you explain what it does exactly and how well it hot reloads?", "tokens": [1664, 291, 2903, 437, 309, 775, 2293, 293, 577, 731, 309, 2368, 25628, 82, 30], "temperature": 0.0, "avg_logprob": -0.23391405741373697, "compression_ratio": 1.7706766917293233, "no_speech_prob": 4.331512900535017e-05}, {"id": 461, "seek": 255780, "start": 2566.8, "end": 2572.8, "text": " Sure. So for people less familiar, hot module reload is if you are working...", "tokens": [4894, 13, 407, 337, 561, 1570, 4963, 11, 2368, 10088, 25628, 307, 498, 291, 366, 1364, 485], "temperature": 0.0, "avg_logprob": -0.23391405741373697, "compression_ratio": 1.7706766917293233, "no_speech_prob": 4.331512900535017e-05}, {"id": 462, "seek": 255780, "start": 2572.8, "end": 2574.8, "text": " I'm going to use JavaScript as an example.", "tokens": [286, 478, 516, 281, 764, 15778, 382, 364, 1365, 13], "temperature": 0.0, "avg_logprob": -0.23391405741373697, "compression_ratio": 1.7706766917293233, "no_speech_prob": 4.331512900535017e-05}, {"id": 463, "seek": 255780, "start": 2574.8, "end": 2581.8, "text": " If you're working in a JavaScript application, and you have three different files that you're working in, and you change one of them,", "tokens": [759, 291, 434, 1364, 294, 257, 15778, 3861, 11, 293, 291, 362, 1045, 819, 7098, 300, 291, 434, 1364, 294, 11, 293, 291, 1319, 472, 295, 552, 11], "temperature": 0.0, "avg_logprob": -0.23391405741373697, "compression_ratio": 1.7706766917293233, "no_speech_prob": 4.331512900535017e-05}, {"id": 464, "seek": 255780, "start": 2581.8, "end": 2586.8, "text": " hot module reload first will grab that new code that you've written, load it into the browser.", "tokens": [2368, 10088, 25628, 700, 486, 4444, 300, 777, 3089, 300, 291, 600, 3720, 11, 3677, 309, 666, 264, 11185, 13], "temperature": 0.0, "avg_logprob": -0.23391405741373697, "compression_ratio": 1.7706766917293233, "no_speech_prob": 4.331512900535017e-05}, {"id": 465, "seek": 258680, "start": 2586.8, "end": 2589.8, "text": " But also execute that and make the change.", "tokens": [583, 611, 14483, 300, 293, 652, 264, 1319, 13], "temperature": 0.0, "avg_logprob": -0.1662118377685547, "compression_ratio": 1.8129770992366412, "no_speech_prob": 0.00012338680971879512}, {"id": 466, "seek": 258680, "start": 2589.8, "end": 2593.8, "text": " So if you're changing what the UI should look like, it will make that change for you.", "tokens": [407, 498, 291, 434, 4473, 437, 264, 15682, 820, 574, 411, 11, 309, 486, 652, 300, 1319, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.1662118377685547, "compression_ratio": 1.8129770992366412, "no_speech_prob": 0.00012338680971879512}, {"id": 467, "seek": 258680, "start": 2593.8, "end": 2597.8, "text": " If you're changing the logic of a function, it will make that change for you.", "tokens": [759, 291, 434, 4473, 264, 9952, 295, 257, 2445, 11, 309, 486, 652, 300, 1319, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.1662118377685547, "compression_ratio": 1.8129770992366412, "no_speech_prob": 0.00012338680971879512}, {"id": 468, "seek": 258680, "start": 2597.8, "end": 2601.8, "text": " It will replace the code, and you don't have to refresh your entire page.", "tokens": [467, 486, 7406, 264, 3089, 11, 293, 291, 500, 380, 362, 281, 15134, 428, 2302, 3028, 13], "temperature": 0.0, "avg_logprob": -0.1662118377685547, "compression_ratio": 1.8129770992366412, "no_speech_prob": 0.00012338680971879512}, {"id": 469, "seek": 258680, "start": 2601.8, "end": 2604.8, "text": " I feel very spoiled by this feature whenever it's available.", "tokens": [286, 841, 588, 32439, 538, 341, 4111, 5699, 309, 311, 2435, 13], "temperature": 0.0, "avg_logprob": -0.1662118377685547, "compression_ratio": 1.8129770992366412, "no_speech_prob": 0.00012338680971879512}, {"id": 470, "seek": 258680, "start": 2604.8, "end": 2608.8, "text": " I've tried working with other frameworks that don't have it, and it makes me very sad.", "tokens": [286, 600, 3031, 1364, 365, 661, 29834, 300, 500, 380, 362, 309, 11, 293, 309, 1669, 385, 588, 4227, 13], "temperature": 0.0, "avg_logprob": -0.1662118377685547, "compression_ratio": 1.8129770992366412, "no_speech_prob": 0.00012338680971879512}, {"id": 471, "seek": 258680, "start": 2608.8, "end": 2612.8, "text": " So where it comes in handy in Elm is the same.", "tokens": [407, 689, 309, 1487, 294, 13239, 294, 2699, 76, 307, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.1662118377685547, "compression_ratio": 1.8129770992366412, "no_speech_prob": 0.00012338680971879512}, {"id": 472, "seek": 261280, "start": 2612.8, "end": 2619.8, "text": " If you're working in an Elm application, and you just change the logic of a function, Elm will hot reload and just replace the logic of the function.", "tokens": [759, 291, 434, 1364, 294, 364, 2699, 76, 3861, 11, 293, 291, 445, 1319, 264, 9952, 295, 257, 2445, 11, 2699, 76, 486, 2368, 25628, 293, 445, 7406, 264, 9952, 295, 264, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1719703840172809, "compression_ratio": 2.0042735042735043, "no_speech_prob": 4.3999367335345596e-05}, {"id": 473, "seek": 261280, "start": 2619.8, "end": 2629.8, "text": " The downside where it comes to Elm is if you're modifying functions in the same file where you define what your model is,", "tokens": [440, 25060, 689, 309, 1487, 281, 2699, 76, 307, 498, 291, 434, 42626, 6828, 294, 264, 912, 3991, 689, 291, 6964, 437, 428, 2316, 307, 11], "temperature": 0.0, "avg_logprob": -0.1719703840172809, "compression_ratio": 2.0042735042735043, "no_speech_prob": 4.3999367335345596e-05}, {"id": 474, "seek": 261280, "start": 2629.8, "end": 2633.8, "text": " or where the core of your application is, it will hot reload that whole thing.", "tokens": [420, 689, 264, 4965, 295, 428, 3861, 307, 11, 309, 486, 2368, 25628, 300, 1379, 551, 13], "temperature": 0.0, "avg_logprob": -0.1719703840172809, "compression_ratio": 2.0042735042735043, "no_speech_prob": 4.3999367335345596e-05}, {"id": 475, "seek": 261280, "start": 2633.8, "end": 2641.8, "text": " So if you are working in an Elm application with a single file, and you make a change, it will reload the entire file.", "tokens": [407, 498, 291, 366, 1364, 294, 364, 2699, 76, 3861, 365, 257, 2167, 3991, 11, 293, 291, 652, 257, 1319, 11, 309, 486, 25628, 264, 2302, 3991, 13], "temperature": 0.0, "avg_logprob": -0.1719703840172809, "compression_ratio": 2.0042735042735043, "no_speech_prob": 4.3999367335345596e-05}, {"id": 476, "seek": 264180, "start": 2641.8, "end": 2644.8, "text": " So your entire application will initialize again.", "tokens": [407, 428, 2302, 3861, 486, 5883, 1125, 797, 13], "temperature": 0.0, "avg_logprob": -0.17417157253372334, "compression_ratio": 1.7647058823529411, "no_speech_prob": 4.539546716841869e-05}, {"id": 477, "seek": 264180, "start": 2644.8, "end": 2650.8, "text": " So if you are breaking your Elm application down into separate files where you've got a file per type, for example,", "tokens": [407, 498, 291, 366, 7697, 428, 2699, 76, 3861, 760, 666, 4994, 7098, 689, 291, 600, 658, 257, 3991, 680, 2010, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.17417157253372334, "compression_ratio": 1.7647058823529411, "no_speech_prob": 4.539546716841869e-05}, {"id": 478, "seek": 264180, "start": 2650.8, "end": 2659.8, "text": " and that type has certain functions, and you make the changes to the file of that type, that file will reload, your code will continue to run,", "tokens": [293, 300, 2010, 575, 1629, 6828, 11, 293, 291, 652, 264, 2962, 281, 264, 3991, 295, 300, 2010, 11, 300, 3991, 486, 25628, 11, 428, 3089, 486, 2354, 281, 1190, 11], "temperature": 0.0, "avg_logprob": -0.17417157253372334, "compression_ratio": 1.7647058823529411, "no_speech_prob": 4.539546716841869e-05}, {"id": 479, "seek": 264180, "start": 2659.8, "end": 2663.8, "text": " your model will still be there, everything will be in the state that it was.", "tokens": [428, 2316, 486, 920, 312, 456, 11, 1203, 486, 312, 294, 264, 1785, 300, 309, 390, 13], "temperature": 0.0, "avg_logprob": -0.17417157253372334, "compression_ratio": 1.7647058823529411, "no_speech_prob": 4.539546716841869e-05}, {"id": 480, "seek": 264180, "start": 2663.8, "end": 2666.8, "text": " But now the new functions will be available that you just wrote.", "tokens": [583, 586, 264, 777, 6828, 486, 312, 2435, 300, 291, 445, 4114, 13], "temperature": 0.0, "avg_logprob": -0.17417157253372334, "compression_ratio": 1.7647058823529411, "no_speech_prob": 4.539546716841869e-05}, {"id": 481, "seek": 266680, "start": 2666.8, "end": 2673.8, "text": " So it works with Elm, and I still highly appreciate not having to hit the refresh button on my page myself.", "tokens": [407, 309, 1985, 365, 2699, 76, 11, 293, 286, 920, 5405, 4449, 406, 1419, 281, 2045, 264, 15134, 2960, 322, 452, 3028, 2059, 13], "temperature": 0.0, "avg_logprob": -0.21071661435640776, "compression_ratio": 1.4694835680751173, "no_speech_prob": 2.8855585696874186e-05}, {"id": 482, "seek": 266680, "start": 2673.8, "end": 2678.8, "text": " But there are some gotchas because of how Elm works and where the model is stored.", "tokens": [583, 456, 366, 512, 658, 41299, 570, 295, 577, 2699, 76, 1985, 293, 689, 264, 2316, 307, 12187, 13], "temperature": 0.0, "avg_logprob": -0.21071661435640776, "compression_ratio": 1.4694835680751173, "no_speech_prob": 2.8855585696874186e-05}, {"id": 483, "seek": 266680, "start": 2678.8, "end": 2688.8, "text": " Right, yeah. I think I remember Simon Nadal talking on this episode for Elmwatch about techniques he made to improve that.", "tokens": [1779, 11, 1338, 13, 286, 519, 286, 1604, 13193, 23269, 304, 1417, 322, 341, 3500, 337, 2699, 76, 15219, 466, 7512, 415, 1027, 281, 3470, 300, 13], "temperature": 0.0, "avg_logprob": -0.21071661435640776, "compression_ratio": 1.4694835680751173, "no_speech_prob": 2.8855585696874186e-05}, {"id": 484, "seek": 268880, "start": 2688.8, "end": 2697.8, "text": " But yeah, this sounds pretty hard to do. Like if your model changes, for instance, then you have to refresh the whole page anyway.", "tokens": [583, 1338, 11, 341, 3263, 1238, 1152, 281, 360, 13, 1743, 498, 428, 2316, 2962, 11, 337, 5197, 11, 550, 291, 362, 281, 15134, 264, 1379, 3028, 4033, 13], "temperature": 0.0, "avg_logprob": -0.21671009063720703, "compression_ratio": 1.5048076923076923, "no_speech_prob": 1.7502145055914298e-05}, {"id": 485, "seek": 268880, "start": 2697.8, "end": 2705.8, "text": " Although now that you mention it, I do remember at one point changing my model, referencing the key, and seeing a null appear on screen, which was very weird.", "tokens": [5780, 586, 300, 291, 2152, 309, 11, 286, 360, 1604, 412, 472, 935, 4473, 452, 2316, 11, 40582, 264, 2141, 11, 293, 2577, 257, 18184, 4204, 322, 2568, 11, 597, 390, 588, 3657, 13], "temperature": 0.0, "avg_logprob": -0.21671009063720703, "compression_ratio": 1.5048076923076923, "no_speech_prob": 1.7502145055914298e-05}, {"id": 486, "seek": 268880, "start": 2705.8, "end": 2709.8, "text": " Yep, that's not wanted.", "tokens": [7010, 11, 300, 311, 406, 1415, 13], "temperature": 0.0, "avg_logprob": -0.21671009063720703, "compression_ratio": 1.5048076923076923, "no_speech_prob": 1.7502145055914298e-05}, {"id": 487, "seek": 270980, "start": 2709.8, "end": 2720.8, "text": " Yeah, I find most of the time, the reason I want hot module reloading is if I'm tweaking a view,", "tokens": [865, 11, 286, 915, 881, 295, 264, 565, 11, 264, 1778, 286, 528, 2368, 10088, 25628, 278, 307, 498, 286, 478, 6986, 2456, 257, 1910, 11], "temperature": 0.0, "avg_logprob": -0.17880564676204197, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.0001233588409377262}, {"id": 488, "seek": 270980, "start": 2720.8, "end": 2726.8, "text": " I don't want to have to keep finding the state I was in that shows that view.", "tokens": [286, 500, 380, 528, 281, 362, 281, 1066, 5006, 264, 1785, 286, 390, 294, 300, 3110, 300, 1910, 13], "temperature": 0.0, "avg_logprob": -0.17880564676204197, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.0001233588409377262}, {"id": 489, "seek": 270980, "start": 2726.8, "end": 2732.8, "text": " But if I'm changing my model and the way that messages are flowing through the system,", "tokens": [583, 498, 286, 478, 4473, 452, 2316, 293, 264, 636, 300, 7897, 366, 13974, 807, 264, 1185, 11], "temperature": 0.0, "avg_logprob": -0.17880564676204197, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.0001233588409377262}, {"id": 490, "seek": 273280, "start": 2732.8, "end": 2739.8, "text": " then I'm fine just refreshing and starting that process over. So it usually works pretty well.", "tokens": [550, 286, 478, 2489, 445, 19772, 293, 2891, 300, 1399, 670, 13, 407, 309, 2673, 1985, 1238, 731, 13], "temperature": 0.0, "avg_logprob": -0.17267816716974432, "compression_ratio": 1.5542168674698795, "no_speech_prob": 7.842673949198797e-05}, {"id": 491, "seek": 273280, "start": 2739.8, "end": 2745.8, "text": " Yeah, I've been pretty happy with how the hot reloading works in Elm. Similar experience.", "tokens": [865, 11, 286, 600, 668, 1238, 2055, 365, 577, 264, 2368, 25628, 278, 1985, 294, 2699, 76, 13, 10905, 1752, 13], "temperature": 0.0, "avg_logprob": -0.17267816716974432, "compression_ratio": 1.5542168674698795, "no_speech_prob": 7.842673949198797e-05}, {"id": 492, "seek": 273280, "start": 2745.8, "end": 2748.8, "text": " It helps a lot more when you're working on the UI layer.", "tokens": [467, 3665, 257, 688, 544, 562, 291, 434, 1364, 322, 264, 15682, 4583, 13], "temperature": 0.0, "avg_logprob": -0.17267816716974432, "compression_ratio": 1.5542168674698795, "no_speech_prob": 7.842673949198797e-05}, {"id": 493, "seek": 273280, "start": 2748.8, "end": 2754.8, "text": " But again, just not having to think as much about, am I looking at the correct version of my application?", "tokens": [583, 797, 11, 445, 406, 1419, 281, 519, 382, 709, 466, 11, 669, 286, 1237, 412, 264, 3006, 3037, 295, 452, 3861, 30], "temperature": 0.0, "avg_logprob": -0.17267816716974432, "compression_ratio": 1.5542168674698795, "no_speech_prob": 7.842673949198797e-05}, {"id": 494, "seek": 273280, "start": 2754.8, "end": 2757.8, "text": " Did it refresh? Did I refresh the page?", "tokens": [2589, 309, 15134, 30, 2589, 286, 15134, 264, 3028, 30], "temperature": 0.0, "avg_logprob": -0.17267816716974432, "compression_ratio": 1.5542168674698795, "no_speech_prob": 7.842673949198797e-05}, {"id": 495, "seek": 275780, "start": 2757.8, "end": 2766.8, "text": " It helps a lot just with the process of building an application. So you can look at your code, rate the changes, switch back to the browser.", "tokens": [467, 3665, 257, 688, 445, 365, 264, 1399, 295, 2390, 364, 3861, 13, 407, 291, 393, 574, 412, 428, 3089, 11, 3314, 264, 2962, 11, 3679, 646, 281, 264, 11185, 13], "temperature": 0.0, "avg_logprob": -0.18174580446223623, "compression_ratio": 1.5296803652968036, "no_speech_prob": 3.321233452879824e-05}, {"id": 496, "seek": 275780, "start": 2766.8, "end": 2770.8, "text": " And because of how fast Vite is, typically it's already done by the time you get back.", "tokens": [400, 570, 295, 577, 2370, 691, 642, 307, 11, 5850, 309, 311, 1217, 1096, 538, 264, 565, 291, 483, 646, 13], "temperature": 0.0, "avg_logprob": -0.18174580446223623, "compression_ratio": 1.5296803652968036, "no_speech_prob": 3.321233452879824e-05}, {"id": 497, "seek": 275780, "start": 2770.8, "end": 2773.8, "text": " You're not alt-tabbing fast enough. That's it.", "tokens": [509, 434, 406, 4955, 12, 83, 455, 4324, 2370, 1547, 13, 663, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.18174580446223623, "compression_ratio": 1.5296803652968036, "no_speech_prob": 3.321233452879824e-05}, {"id": 498, "seek": 275780, "start": 2773.8, "end": 2778.8, "text": " I need to work on my alt-tab game. That's what I need to do.", "tokens": [286, 643, 281, 589, 322, 452, 4955, 12, 83, 455, 1216, 13, 663, 311, 437, 286, 643, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.18174580446223623, "compression_ratio": 1.5296803652968036, "no_speech_prob": 3.321233452879824e-05}, {"id": 499, "seek": 277880, "start": 2778.8, "end": 2787.8, "text": " Why might someone consider alternatives to Vite? Maybe you're all in on Vite, but I'm curious.", "tokens": [1545, 1062, 1580, 1949, 20478, 281, 691, 642, 30, 2704, 291, 434, 439, 294, 322, 691, 642, 11, 457, 286, 478, 6369, 13], "temperature": 0.0, "avg_logprob": -0.17239862221937913, "compression_ratio": 1.537190082644628, "no_speech_prob": 2.668424895091448e-05}, {"id": 500, "seek": 277880, "start": 2787.8, "end": 2792.8, "text": " Do you think there are use cases where someone would want to not use Vite with Elm?", "tokens": [1144, 291, 519, 456, 366, 764, 3331, 689, 1580, 576, 528, 281, 406, 764, 691, 642, 365, 2699, 76, 30], "temperature": 0.0, "avg_logprob": -0.17239862221937913, "compression_ratio": 1.537190082644628, "no_speech_prob": 2.668424895091448e-05}, {"id": 501, "seek": 277880, "start": 2792.8, "end": 2798.8, "text": " That's a good question. I don't. So I will fully admit I am all in on Vite.", "tokens": [663, 311, 257, 665, 1168, 13, 286, 500, 380, 13, 407, 286, 486, 4498, 9796, 286, 669, 439, 294, 322, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.17239862221937913, "compression_ratio": 1.537190082644628, "no_speech_prob": 2.668424895091448e-05}, {"id": 502, "seek": 277880, "start": 2798.8, "end": 2805.8, "text": " I came from the Vue ecosystem. Evan, you created this. I really appreciate his work and I just kind of stick with it.", "tokens": [286, 1361, 490, 264, 691, 622, 11311, 13, 22613, 11, 291, 2942, 341, 13, 286, 534, 4449, 702, 589, 293, 286, 445, 733, 295, 2897, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.17239862221937913, "compression_ratio": 1.537190082644628, "no_speech_prob": 2.668424895091448e-05}, {"id": 503, "seek": 280580, "start": 2805.8, "end": 2810.8, "text": " The fact that the rest of the JavaScript ecosystem has gone in this direction as well gives me added comfort in that.", "tokens": [440, 1186, 300, 264, 1472, 295, 264, 15778, 11311, 575, 2780, 294, 341, 3513, 382, 731, 2709, 385, 3869, 3400, 294, 300, 13], "temperature": 0.0, "avg_logprob": -0.19200138891896895, "compression_ratio": 1.627986348122867, "no_speech_prob": 6.70858207740821e-05}, {"id": 504, "seek": 280580, "start": 2810.8, "end": 2817.8, "text": " That said, I think it's perfectly reasonable to take a different course if that is what feels more comfortable.", "tokens": [663, 848, 11, 286, 519, 309, 311, 6239, 10585, 281, 747, 257, 819, 1164, 498, 300, 307, 437, 3417, 544, 4619, 13], "temperature": 0.0, "avg_logprob": -0.19200138891896895, "compression_ratio": 1.627986348122867, "no_speech_prob": 6.70858207740821e-05}, {"id": 505, "seek": 280580, "start": 2817.8, "end": 2820.8, "text": " And I think that's what it comes down to, is comfort.", "tokens": [400, 286, 519, 300, 311, 437, 309, 1487, 760, 281, 11, 307, 3400, 13], "temperature": 0.0, "avg_logprob": -0.19200138891896895, "compression_ratio": 1.627986348122867, "no_speech_prob": 6.70858207740821e-05}, {"id": 506, "seek": 280580, "start": 2820.8, "end": 2827.8, "text": " So, for example, there's Parcel, which you don't even have to use a plugin to get Elm working. Elm just works.", "tokens": [407, 11, 337, 1365, 11, 456, 311, 3457, 4933, 11, 597, 291, 500, 380, 754, 362, 281, 764, 257, 23407, 281, 483, 2699, 76, 1364, 13, 2699, 76, 445, 1985, 13], "temperature": 0.0, "avg_logprob": -0.19200138891896895, "compression_ratio": 1.627986348122867, "no_speech_prob": 6.70858207740821e-05}, {"id": 507, "seek": 280580, "start": 2827.8, "end": 2834.8, "text": " There's tools like ES Build, or please don't use Webpack, but there's Webpack too.", "tokens": [821, 311, 3873, 411, 12564, 11875, 11, 420, 1767, 500, 380, 764, 9573, 9539, 11, 457, 456, 311, 9573, 9539, 886, 13], "temperature": 0.0, "avg_logprob": -0.19200138891896895, "compression_ratio": 1.627986348122867, "no_speech_prob": 6.70858207740821e-05}, {"id": 508, "seek": 283480, "start": 2834.8, "end": 2842.8, "text": " If you really want to go in that other direction and not down this path,", "tokens": [759, 291, 534, 528, 281, 352, 294, 300, 661, 3513, 293, 406, 760, 341, 3100, 11], "temperature": 0.0, "avg_logprob": -0.1864604341222885, "compression_ratio": 1.6872246696035242, "no_speech_prob": 0.00022689896286465228}, {"id": 509, "seek": 283480, "start": 2842.8, "end": 2851.8, "text": " I think there's some kinds of developers that really prefer that configuration of all the nitty gritty over having something that's pre-configured that they can update.", "tokens": [286, 519, 456, 311, 512, 3685, 295, 8849, 300, 534, 4382, 300, 11694, 295, 439, 264, 297, 10016, 677, 10016, 670, 1419, 746, 300, 311, 659, 12, 1671, 20646, 3831, 300, 436, 393, 5623, 13], "temperature": 0.0, "avg_logprob": -0.1864604341222885, "compression_ratio": 1.6872246696035242, "no_speech_prob": 0.00022689896286465228}, {"id": 510, "seek": 283480, "start": 2851.8, "end": 2860.8, "text": " The other big one is if you want to use ES Build and you don't want all the other benefits of Vite, you could just use ES Build, for example.", "tokens": [440, 661, 955, 472, 307, 498, 291, 528, 281, 764, 12564, 11875, 293, 291, 500, 380, 528, 439, 264, 661, 5311, 295, 691, 642, 11, 291, 727, 445, 764, 12564, 11875, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.1864604341222885, "compression_ratio": 1.6872246696035242, "no_speech_prob": 0.00022689896286465228}, {"id": 511, "seek": 286080, "start": 2860.8, "end": 2865.8, "text": " I know plenty of projects and companies that are doing just that if they want to use Vite.", "tokens": [286, 458, 7140, 295, 4455, 293, 3431, 300, 366, 884, 445, 300, 498, 436, 528, 281, 764, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.16429171286338617, "compression_ratio": 1.6925795053003534, "no_speech_prob": 3.8829282857477665e-05}, {"id": 512, "seek": 286080, "start": 2865.8, "end": 2871.8, "text": " Whether it's Elm or not, ES Build is a wonderful tool on its own. It's still in development, but it's pretty good.", "tokens": [8503, 309, 311, 2699, 76, 420, 406, 11, 12564, 11875, 307, 257, 3715, 2290, 322, 1080, 1065, 13, 467, 311, 920, 294, 3250, 11, 457, 309, 311, 1238, 665, 13], "temperature": 0.0, "avg_logprob": -0.16429171286338617, "compression_ratio": 1.6925795053003534, "no_speech_prob": 3.8829282857477665e-05}, {"id": 513, "seek": 286080, "start": 2871.8, "end": 2877.8, "text": " So if you didn't want all the extra goodies that come with Vite, they don't benefit you for whatever reason.", "tokens": [407, 498, 291, 994, 380, 528, 439, 264, 2857, 44072, 300, 808, 365, 691, 642, 11, 436, 500, 380, 5121, 291, 337, 2035, 1778, 13], "temperature": 0.0, "avg_logprob": -0.16429171286338617, "compression_ratio": 1.6925795053003534, "no_speech_prob": 3.8829282857477665e-05}, {"id": 514, "seek": 286080, "start": 2877.8, "end": 2882.8, "text": " It's perfectly reasonable to just go with something more lower level and just get a bundler.", "tokens": [467, 311, 6239, 10585, 281, 445, 352, 365, 746, 544, 3126, 1496, 293, 445, 483, 257, 13882, 1918, 13], "temperature": 0.0, "avg_logprob": -0.16429171286338617, "compression_ratio": 1.6925795053003534, "no_speech_prob": 3.8829282857477665e-05}, {"id": 515, "seek": 286080, "start": 2882.8, "end": 2886.8, "text": " I think those would be the main reasons I would go with something else.", "tokens": [286, 519, 729, 576, 312, 264, 2135, 4112, 286, 576, 352, 365, 746, 1646, 13], "temperature": 0.0, "avg_logprob": -0.16429171286338617, "compression_ratio": 1.6925795053003534, "no_speech_prob": 3.8829282857477665e-05}, {"id": 516, "seek": 288680, "start": 2886.8, "end": 2892.8, "text": " The only one that I knew about and used sometimes was Parcel.", "tokens": [440, 787, 472, 300, 286, 2586, 466, 293, 1143, 2171, 390, 3457, 4933, 13], "temperature": 0.0, "avg_logprob": -0.2233940325285259, "compression_ratio": 1.7072072072072073, "no_speech_prob": 4.092727976967581e-06}, {"id": 517, "seek": 288680, "start": 2892.8, "end": 2896.8, "text": " Just because it worked without any configuration or so.", "tokens": [1449, 570, 309, 2732, 1553, 604, 11694, 420, 370, 13], "temperature": 0.0, "avg_logprob": -0.2233940325285259, "compression_ratio": 1.7072072072072073, "no_speech_prob": 4.092727976967581e-06}, {"id": 518, "seek": 288680, "start": 2896.8, "end": 2900.8, "text": " And the alternative at the time was Webpack.", "tokens": [400, 264, 8535, 412, 264, 565, 390, 9573, 9539, 13], "temperature": 0.0, "avg_logprob": -0.2233940325285259, "compression_ratio": 1.7072072072072073, "no_speech_prob": 4.092727976967581e-06}, {"id": 519, "seek": 288680, "start": 2900.8, "end": 2905.8, "text": " There's one that works without a configuration and the other one that doesn't work with a lot of configuration.", "tokens": [821, 311, 472, 300, 1985, 1553, 257, 11694, 293, 264, 661, 472, 300, 1177, 380, 589, 365, 257, 688, 295, 11694, 13], "temperature": 0.0, "avg_logprob": -0.2233940325285259, "compression_ratio": 1.7072072072072073, "no_speech_prob": 4.092727976967581e-06}, {"id": 520, "seek": 288680, "start": 2905.8, "end": 2907.8, "text": " So the choice was quite easy.", "tokens": [407, 264, 3922, 390, 1596, 1858, 13], "temperature": 0.0, "avg_logprob": -0.2233940325285259, "compression_ratio": 1.7072072072072073, "no_speech_prob": 4.092727976967581e-06}, {"id": 521, "seek": 288680, "start": 2907.8, "end": 2915.8, "text": " I wouldn't be able to tell what the difference is between Vite and Parcel.", "tokens": [286, 2759, 380, 312, 1075, 281, 980, 437, 264, 2649, 307, 1296, 691, 642, 293, 3457, 4933, 13], "temperature": 0.0, "avg_logprob": -0.2233940325285259, "compression_ratio": 1.7072072072072073, "no_speech_prob": 4.092727976967581e-06}, {"id": 522, "seek": 291580, "start": 2915.8, "end": 2918.8, "text": " I think in many ways that's a good thing.", "tokens": [286, 519, 294, 867, 2098, 300, 311, 257, 665, 551, 13], "temperature": 0.0, "avg_logprob": -0.21250649253920753, "compression_ratio": 1.6336206896551724, "no_speech_prob": 9.609087283024564e-05}, {"id": 523, "seek": 291580, "start": 2918.8, "end": 2921.8, "text": " If they do the same thing, yeah.", "tokens": [759, 436, 360, 264, 912, 551, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.21250649253920753, "compression_ratio": 1.6336206896551724, "no_speech_prob": 9.609087283024564e-05}, {"id": 524, "seek": 291580, "start": 2921.8, "end": 2924.8, "text": " They do pretty much the same thing for what you need.", "tokens": [814, 360, 1238, 709, 264, 912, 551, 337, 437, 291, 643, 13], "temperature": 0.0, "avg_logprob": -0.21250649253920753, "compression_ratio": 1.6336206896551724, "no_speech_prob": 9.609087283024564e-05}, {"id": 525, "seek": 291580, "start": 2924.8, "end": 2927.8, "text": " And so it comes down to a preference, which one feels more comfortable to use.", "tokens": [400, 370, 309, 1487, 760, 281, 257, 17502, 11, 597, 472, 3417, 544, 4619, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.21250649253920753, "compression_ratio": 1.6336206896551724, "no_speech_prob": 9.609087283024564e-05}, {"id": 526, "seek": 291580, "start": 2927.8, "end": 2934.8, "text": " I think for me, the big reason I lean towards Vite besides I came from the Vue ecosystem is", "tokens": [286, 519, 337, 385, 11, 264, 955, 1778, 286, 11659, 3030, 691, 642, 11868, 286, 1361, 490, 264, 691, 622, 11311, 307], "temperature": 0.0, "avg_logprob": -0.21250649253920753, "compression_ratio": 1.6336206896551724, "no_speech_prob": 9.609087283024564e-05}, {"id": 527, "seek": 291580, "start": 2934.8, "end": 2938.8, "text": " I'm jumping between other frameworks a lot of the time for other side projects.", "tokens": [286, 478, 11233, 1296, 661, 29834, 257, 688, 295, 264, 565, 337, 661, 1252, 4455, 13], "temperature": 0.0, "avg_logprob": -0.21250649253920753, "compression_ratio": 1.6336206896551724, "no_speech_prob": 9.609087283024564e-05}, {"id": 528, "seek": 293880, "start": 2938.8, "end": 2945.8, "text": " And being able to, for example, in a Nuxt application, Nuxt.js, it's a server-side rendering framework for Vue.", "tokens": [400, 885, 1075, 281, 11, 337, 1365, 11, 294, 257, 13612, 734, 3861, 11, 13612, 734, 13, 25530, 11, 309, 311, 257, 7154, 12, 1812, 22407, 8388, 337, 691, 622, 13], "temperature": 0.0, "avg_logprob": -0.17767346334114348, "compression_ratio": 1.6722972972972974, "no_speech_prob": 6.106689397711307e-05}, {"id": 529, "seek": 293880, "start": 2945.8, "end": 2949.8, "text": " Because it's using Vite, I can just import the Elm plugin.", "tokens": [1436, 309, 311, 1228, 691, 642, 11, 286, 393, 445, 974, 264, 2699, 76, 23407, 13], "temperature": 0.0, "avg_logprob": -0.17767346334114348, "compression_ratio": 1.6722972972972974, "no_speech_prob": 6.106689397711307e-05}, {"id": 530, "seek": 293880, "start": 2949.8, "end": 2955.8, "text": " And now I have the power of Nuxt on the backend and the components if I really want to.", "tokens": [400, 586, 286, 362, 264, 1347, 295, 13612, 734, 322, 264, 38087, 293, 264, 6677, 498, 286, 534, 528, 281, 13], "temperature": 0.0, "avg_logprob": -0.17767346334114348, "compression_ratio": 1.6722972972972974, "no_speech_prob": 6.106689397711307e-05}, {"id": 531, "seek": 293880, "start": 2955.8, "end": 2960.8, "text": " And then for anything that feels like it should be in Elm, I can just render that in Elm instead.", "tokens": [400, 550, 337, 1340, 300, 3417, 411, 309, 820, 312, 294, 2699, 76, 11, 286, 393, 445, 15529, 300, 294, 2699, 76, 2602, 13], "temperature": 0.0, "avg_logprob": -0.17767346334114348, "compression_ratio": 1.6722972972972974, "no_speech_prob": 6.106689397711307e-05}, {"id": 532, "seek": 293880, "start": 2960.8, "end": 2962.8, "text": " And I can just mix and match a whole lot easier.", "tokens": [400, 286, 393, 445, 2890, 293, 2995, 257, 1379, 688, 3571, 13], "temperature": 0.0, "avg_logprob": -0.17767346334114348, "compression_ratio": 1.6722972972972974, "no_speech_prob": 6.106689397711307e-05}, {"id": 533, "seek": 293880, "start": 2962.8, "end": 2967.8, "text": " And similarly, going the other direction, if I'm a Vue developer or I'm a React developer", "tokens": [400, 14138, 11, 516, 264, 661, 3513, 11, 498, 286, 478, 257, 691, 622, 10754, 420, 286, 478, 257, 30644, 10754], "temperature": 0.0, "avg_logprob": -0.17767346334114348, "compression_ratio": 1.6722972972972974, "no_speech_prob": 6.106689397711307e-05}, {"id": 534, "seek": 296780, "start": 2967.8, "end": 2974.8, "text": " and I want to try out Elm, or I want to try out Svelte, or I want to try out whatever, but we're an Elm podcast.", "tokens": [293, 286, 528, 281, 853, 484, 2699, 76, 11, 420, 286, 528, 281, 853, 484, 318, 779, 975, 11, 420, 286, 528, 281, 853, 484, 2035, 11, 457, 321, 434, 364, 2699, 76, 7367, 13], "temperature": 0.0, "avg_logprob": -0.16894185148327556, "compression_ratio": 1.9880952380952381, "no_speech_prob": 5.4757991165388376e-05}, {"id": 535, "seek": 296780, "start": 2974.8, "end": 2981.8, "text": " If you want to try out something else and you're using Vite already, it's as simple as just getting started.", "tokens": [759, 291, 528, 281, 853, 484, 746, 1646, 293, 291, 434, 1228, 691, 642, 1217, 11, 309, 311, 382, 2199, 382, 445, 1242, 1409, 13], "temperature": 0.0, "avg_logprob": -0.16894185148327556, "compression_ratio": 1.9880952380952381, "no_speech_prob": 5.4757991165388376e-05}, {"id": 536, "seek": 296780, "start": 2981.8, "end": 2982.8, "text": " If you're using Elm, just plug it in.", "tokens": [759, 291, 434, 1228, 2699, 76, 11, 445, 5452, 309, 294, 13], "temperature": 0.0, "avg_logprob": -0.16894185148327556, "compression_ratio": 1.9880952380952381, "no_speech_prob": 5.4757991165388376e-05}, {"id": 537, "seek": 296780, "start": 2982.8, "end": 2985.8, "text": " If you're wanting to use Vue, just plug it in.", "tokens": [759, 291, 434, 7935, 281, 764, 691, 622, 11, 445, 5452, 309, 294, 13], "temperature": 0.0, "avg_logprob": -0.16894185148327556, "compression_ratio": 1.9880952380952381, "no_speech_prob": 5.4757991165388376e-05}, {"id": 538, "seek": 296780, "start": 2985.8, "end": 2988.8, "text": " And then you can start using that thing, whatever it is.", "tokens": [400, 550, 291, 393, 722, 1228, 300, 551, 11, 2035, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.16894185148327556, "compression_ratio": 1.9880952380952381, "no_speech_prob": 5.4757991165388376e-05}, {"id": 539, "seek": 296780, "start": 2988.8, "end": 2996.8, "text": " And the fact that so much of the ecosystem is already built on that, you've got Nuxt, you've got Astro, you've got SvelteKit, SolidStart.", "tokens": [400, 264, 1186, 300, 370, 709, 295, 264, 11311, 307, 1217, 3094, 322, 300, 11, 291, 600, 658, 13612, 734, 11, 291, 600, 658, 12884, 340, 11, 291, 600, 658, 318, 779, 975, 45626, 11, 26664, 33996, 13], "temperature": 0.0, "avg_logprob": -0.16894185148327556, "compression_ratio": 1.9880952380952381, "no_speech_prob": 5.4757991165388376e-05}, {"id": 540, "seek": 299680, "start": 2996.8, "end": 2999.8, "text": " There's just so much that's built into that.", "tokens": [821, 311, 445, 370, 709, 300, 311, 3094, 666, 300, 13], "temperature": 0.0, "avg_logprob": -0.2144664965177837, "compression_ratio": 1.6589147286821706, "no_speech_prob": 4.1984778363257647e-05}, {"id": 541, "seek": 299680, "start": 2999.8, "end": 3003.8, "text": " I really like the ability to jump between the different tools and the different frameworks and the different applications.", "tokens": [286, 534, 411, 264, 3485, 281, 3012, 1296, 264, 819, 3873, 293, 264, 819, 29834, 293, 264, 819, 5821, 13], "temperature": 0.0, "avg_logprob": -0.2144664965177837, "compression_ratio": 1.6589147286821706, "no_speech_prob": 4.1984778363257647e-05}, {"id": 542, "seek": 299680, "start": 3003.8, "end": 3006.8, "text": " And it's all the same configuration underneath.", "tokens": [400, 309, 311, 439, 264, 912, 11694, 7223, 13], "temperature": 0.0, "avg_logprob": -0.2144664965177837, "compression_ratio": 1.6589147286821706, "no_speech_prob": 4.1984778363257647e-05}, {"id": 543, "seek": 299680, "start": 3006.8, "end": 3007.8, "text": " And I know what I'm getting into.", "tokens": [400, 286, 458, 437, 286, 478, 1242, 666, 13], "temperature": 0.0, "avg_logprob": -0.2144664965177837, "compression_ratio": 1.6589147286821706, "no_speech_prob": 4.1984778363257647e-05}, {"id": 544, "seek": 299680, "start": 3007.8, "end": 3015.8, "text": " So that's when I'm evaluating a new project such as Elm Pages v3, I'm looking to see what is it using under the hood.", "tokens": [407, 300, 311, 562, 286, 478, 27479, 257, 777, 1716, 1270, 382, 2699, 76, 430, 1660, 371, 18, 11, 286, 478, 1237, 281, 536, 437, 307, 309, 1228, 833, 264, 13376, 13], "temperature": 0.0, "avg_logprob": -0.2144664965177837, "compression_ratio": 1.6589147286821706, "no_speech_prob": 4.1984778363257647e-05}, {"id": 545, "seek": 299680, "start": 3015.8, "end": 3018.8, "text": " And, oh, it's Vite. Awesome. I'm probably going to use this.", "tokens": [400, 11, 1954, 11, 309, 311, 691, 642, 13, 10391, 13, 286, 478, 1391, 516, 281, 764, 341, 13], "temperature": 0.0, "avg_logprob": -0.2144664965177837, "compression_ratio": 1.6589147286821706, "no_speech_prob": 4.1984778363257647e-05}, {"id": 546, "seek": 301880, "start": 3018.8, "end": 3037.8, "text": " Yeah. I was adding something to the docs site for Elm Pages for basically like, I think I even saw some GDPR thing about some litigation because people were loading Google fonts directly.", "tokens": [865, 13, 286, 390, 5127, 746, 281, 264, 45623, 3621, 337, 2699, 76, 430, 1660, 337, 1936, 411, 11, 286, 519, 286, 754, 1866, 512, 19599, 49, 551, 466, 512, 33359, 570, 561, 645, 15114, 3329, 35316, 3838, 13], "temperature": 0.0, "avg_logprob": -0.22145913706885445, "compression_ratio": 1.5355450236966826, "no_speech_prob": 3.2696916605345905e-05}, {"id": 547, "seek": 301880, "start": 3037.8, "end": 3047.8, "text": " And it was violating people's privacy because it was unnecessarily pinging Google servers when people loaded a page just to load a font.", "tokens": [400, 309, 390, 42201, 561, 311, 11427, 570, 309, 390, 16799, 3289, 280, 8716, 3329, 15909, 562, 561, 13210, 257, 3028, 445, 281, 3677, 257, 10703, 13], "temperature": 0.0, "avg_logprob": -0.22145913706885445, "compression_ratio": 1.5355450236966826, "no_speech_prob": 3.2696916605345905e-05}, {"id": 548, "seek": 304780, "start": 3047.8, "end": 3053.8, "text": " And I'm like, wow, that's been like this standard way I do things, just load a Google font.", "tokens": [400, 286, 478, 411, 11, 6076, 11, 300, 311, 668, 411, 341, 3832, 636, 286, 360, 721, 11, 445, 3677, 257, 3329, 10703, 13], "temperature": 0.0, "avg_logprob": -0.14797463881230988, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.972642146749422e-06}, {"id": 549, "seek": 304780, "start": 3053.8, "end": 3059.8, "text": " And for a long time, people said, well, it's a good practice because you cache the font.", "tokens": [400, 337, 257, 938, 565, 11, 561, 848, 11, 731, 11, 309, 311, 257, 665, 3124, 570, 291, 19459, 264, 10703, 13], "temperature": 0.0, "avg_logprob": -0.14797463881230988, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.972642146749422e-06}, {"id": 550, "seek": 304780, "start": 3059.8, "end": 3062.8, "text": " So if somebody else has loaded it with Google fonts, it will be in their cache.", "tokens": [407, 498, 2618, 1646, 575, 13210, 309, 365, 3329, 35316, 11, 309, 486, 312, 294, 641, 19459, 13], "temperature": 0.0, "avg_logprob": -0.14797463881230988, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.972642146749422e-06}, {"id": 551, "seek": 304780, "start": 3062.8, "end": 3074.8, "text": " But actually, that no longer happens on browsers because they realized that that was like a fingerprinting vector that could let people identify a user based on which assets had been cached on their site.", "tokens": [583, 767, 11, 300, 572, 2854, 2314, 322, 36069, 570, 436, 5334, 300, 300, 390, 411, 257, 30715, 278, 8062, 300, 727, 718, 561, 5876, 257, 4195, 2361, 322, 597, 9769, 632, 668, 269, 15095, 322, 641, 3621, 13], "temperature": 0.0, "avg_logprob": -0.14797463881230988, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.972642146749422e-06}, {"id": 552, "seek": 307480, "start": 3074.8, "end": 3077.8, "text": " So caches are sandboxed by domain.", "tokens": [407, 269, 13272, 366, 42115, 292, 538, 9274, 13], "temperature": 0.0, "avg_logprob": -0.16089384659476902, "compression_ratio": 1.7357723577235773, "no_speech_prob": 2.857294020941481e-06}, {"id": 553, "seek": 307480, "start": 3077.8, "end": 3080.8, "text": " And so you no longer have even that benefit.", "tokens": [400, 370, 291, 572, 2854, 362, 754, 300, 5121, 13], "temperature": 0.0, "avg_logprob": -0.16089384659476902, "compression_ratio": 1.7357723577235773, "no_speech_prob": 2.857294020941481e-06}, {"id": 554, "seek": 307480, "start": 3080.8, "end": 3087.8, "text": " Plus, when you have to connect to another domain, you have to do the whole handshake and open up that connection to another domain.", "tokens": [7721, 11, 562, 291, 362, 281, 1745, 281, 1071, 9274, 11, 291, 362, 281, 360, 264, 1379, 2377, 34593, 293, 1269, 493, 300, 4984, 281, 1071, 9274, 13], "temperature": 0.0, "avg_logprob": -0.16089384659476902, "compression_ratio": 1.7357723577235773, "no_speech_prob": 2.857294020941481e-06}, {"id": 555, "seek": 307480, "start": 3087.8, "end": 3093.8, "text": " So it's faster if you load the asset from the site that is being hosted at.", "tokens": [407, 309, 311, 4663, 498, 291, 3677, 264, 11999, 490, 264, 3621, 300, 307, 885, 19204, 412, 13], "temperature": 0.0, "avg_logprob": -0.16089384659476902, "compression_ratio": 1.7357723577235773, "no_speech_prob": 2.857294020941481e-06}, {"id": 556, "seek": 307480, "start": 3093.8, "end": 3096.8, "text": " And so how do you how do you do that?", "tokens": [400, 370, 577, 360, 291, 577, 360, 291, 360, 300, 30], "temperature": 0.0, "avg_logprob": -0.16089384659476902, "compression_ratio": 1.7357723577235773, "no_speech_prob": 2.857294020941481e-06}, {"id": 557, "seek": 307480, "start": 3096.8, "end": 3103.8, "text": " Install a single Vite plugin, tell it the Google fonts you have, and then it just knows how to do it.", "tokens": [31982, 257, 2167, 691, 642, 23407, 11, 980, 309, 264, 3329, 35316, 291, 362, 11, 293, 550, 309, 445, 3255, 577, 281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.16089384659476902, "compression_ratio": 1.7357723577235773, "no_speech_prob": 2.857294020941481e-06}, {"id": 558, "seek": 310380, "start": 3103.8, "end": 3104.8, "text": " And it's so easy.", "tokens": [400, 309, 311, 370, 1858, 13], "temperature": 0.0, "avg_logprob": -0.1847747292105607, "compression_ratio": 1.643884892086331, "no_speech_prob": 1.6442181731690653e-05}, {"id": 559, "seek": 310380, "start": 3104.8, "end": 3111.8, "text": " And I can do that now in the Elm pages doc site, which, of course, if it was not written in Elm pages, that would be embarrassing.", "tokens": [400, 286, 393, 360, 300, 586, 294, 264, 2699, 76, 7183, 3211, 3621, 11, 597, 11, 295, 1164, 11, 498, 309, 390, 406, 3720, 294, 2699, 76, 7183, 11, 300, 576, 312, 17299, 13], "temperature": 0.0, "avg_logprob": -0.1847747292105607, "compression_ratio": 1.643884892086331, "no_speech_prob": 1.6442181731690653e-05}, {"id": 560, "seek": 310380, "start": 3111.8, "end": 3113.8, "text": " It's written in Elm pages.", "tokens": [467, 311, 3720, 294, 2699, 76, 7183, 13], "temperature": 0.0, "avg_logprob": -0.1847747292105607, "compression_ratio": 1.643884892086331, "no_speech_prob": 1.6442181731690653e-05}, {"id": 561, "seek": 310380, "start": 3113.8, "end": 3119.8, "text": " But I just open up the Vite config and then add that plugin to for downloading Google fonts.", "tokens": [583, 286, 445, 1269, 493, 264, 691, 642, 6662, 293, 550, 909, 300, 23407, 281, 337, 32529, 3329, 35316, 13], "temperature": 0.0, "avg_logprob": -0.1847747292105607, "compression_ratio": 1.643884892086331, "no_speech_prob": 1.6442181731690653e-05}, {"id": 562, "seek": 310380, "start": 3119.8, "end": 3121.8, "text": " And it's so easy to use.", "tokens": [400, 309, 311, 370, 1858, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.1847747292105607, "compression_ratio": 1.643884892086331, "no_speech_prob": 1.6442181731690653e-05}, {"id": 563, "seek": 310380, "start": 3121.8, "end": 3129.8, "text": " So it's pretty cool being able to hook into this like vibrant ecosystem, which like everybody has decided is a good idea right now.", "tokens": [407, 309, 311, 1238, 1627, 885, 1075, 281, 6328, 666, 341, 411, 21571, 11311, 11, 597, 411, 2201, 575, 3047, 307, 257, 665, 1558, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.1847747292105607, "compression_ratio": 1.643884892086331, "no_speech_prob": 1.6442181731690653e-05}, {"id": 564, "seek": 310380, "start": 3129.8, "end": 3131.8, "text": " So when do you get tracked now?", "tokens": [407, 562, 360, 291, 483, 31703, 586, 30], "temperature": 0.0, "avg_logprob": -0.1847747292105607, "compression_ratio": 1.643884892086331, "no_speech_prob": 1.6442181731690653e-05}, {"id": 565, "seek": 313180, "start": 3131.8, "end": 3134.8, "text": " Is it when you build the application?", "tokens": [1119, 309, 562, 291, 1322, 264, 3861, 30], "temperature": 0.0, "avg_logprob": -0.18612415385696124, "compression_ratio": 1.5346534653465347, "no_speech_prob": 1.4063862181501463e-05}, {"id": 566, "seek": 313180, "start": 3134.8, "end": 3136.8, "text": " Google knows when you run your build.", "tokens": [3329, 3255, 562, 291, 1190, 428, 1322, 13], "temperature": 0.0, "avg_logprob": -0.18612415385696124, "compression_ratio": 1.5346534653465347, "no_speech_prob": 1.4063862181501463e-05}, {"id": 567, "seek": 313180, "start": 3136.8, "end": 3137.8, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.18612415385696124, "compression_ratio": 1.5346534653465347, "no_speech_prob": 1.4063862181501463e-05}, {"id": 568, "seek": 313180, "start": 3137.8, "end": 3138.8, "text": " Okay, good.", "tokens": [1033, 11, 665, 13], "temperature": 0.0, "avg_logprob": -0.18612415385696124, "compression_ratio": 1.5346534653465347, "no_speech_prob": 1.4063862181501463e-05}, {"id": 569, "seek": 313180, "start": 3138.8, "end": 3139.8, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.18612415385696124, "compression_ratio": 1.5346534653465347, "no_speech_prob": 1.4063862181501463e-05}, {"id": 570, "seek": 313180, "start": 3139.8, "end": 3143.8, "text": " We wouldn't want to take that away from them, right?", "tokens": [492, 2759, 380, 528, 281, 747, 300, 1314, 490, 552, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18612415385696124, "compression_ratio": 1.5346534653465347, "no_speech_prob": 1.4063862181501463e-05}, {"id": 571, "seek": 313180, "start": 3143.8, "end": 3147.8, "text": " As long as they can't shut it down, that's fine.", "tokens": [1018, 938, 382, 436, 393, 380, 5309, 309, 760, 11, 300, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.18612415385696124, "compression_ratio": 1.5346534653465347, "no_speech_prob": 1.4063862181501463e-05}, {"id": 572, "seek": 313180, "start": 3147.8, "end": 3150.8, "text": " Google knows if you've been bad or good, so be good for goodness sake.", "tokens": [3329, 3255, 498, 291, 600, 668, 1578, 420, 665, 11, 370, 312, 665, 337, 8387, 9717, 13], "temperature": 0.0, "avg_logprob": -0.18612415385696124, "compression_ratio": 1.5346534653465347, "no_speech_prob": 1.4063862181501463e-05}, {"id": 573, "seek": 313180, "start": 3150.8, "end": 3154.8, "text": " Oh, no.", "tokens": [876, 11, 572, 13], "temperature": 0.0, "avg_logprob": -0.18612415385696124, "compression_ratio": 1.5346534653465347, "no_speech_prob": 1.4063862181501463e-05}, {"id": 574, "seek": 313180, "start": 3154.8, "end": 3159.8, "text": " I mean, it's true, but oh, no.", "tokens": [286, 914, 11, 309, 311, 2074, 11, 457, 1954, 11, 572, 13], "temperature": 0.0, "avg_logprob": -0.18612415385696124, "compression_ratio": 1.5346534653465347, "no_speech_prob": 1.4063862181501463e-05}, {"id": 575, "seek": 315980, "start": 3159.8, "end": 3168.8, "text": " On Vite real quick and the integrations, I just pulled up an article written by Patak, who's one of the core developers on Vite at this point as well.", "tokens": [1282, 691, 642, 957, 1702, 293, 264, 3572, 763, 11, 286, 445, 7373, 493, 364, 7222, 3720, 538, 4379, 514, 11, 567, 311, 472, 295, 264, 4965, 8849, 322, 691, 642, 412, 341, 935, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1806621049579821, "compression_ratio": 1.5878136200716846, "no_speech_prob": 0.00011060558608733118}, {"id": 576, "seek": 315980, "start": 3168.8, "end": 3174.8, "text": " And there's just so many integrations that Vite has that I didn't even remember as we were talking about it.", "tokens": [400, 456, 311, 445, 370, 867, 3572, 763, 300, 691, 642, 575, 300, 286, 994, 380, 754, 1604, 382, 321, 645, 1417, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.1806621049579821, "compression_ratio": 1.5878136200716846, "no_speech_prob": 0.00011060558608733118}, {"id": 577, "seek": 315980, "start": 3174.8, "end": 3176.8, "text": " So, for example, there's plugins for Ruby.", "tokens": [407, 11, 337, 1365, 11, 456, 311, 33759, 337, 19907, 13], "temperature": 0.0, "avg_logprob": -0.1806621049579821, "compression_ratio": 1.5878136200716846, "no_speech_prob": 0.00011060558608733118}, {"id": 578, "seek": 315980, "start": 3176.8, "end": 3183.8, "text": " So if you've got Ruby on the back end, typically you're going to be using something like Webpacker to bundle your JavaScript as the default.", "tokens": [407, 498, 291, 600, 658, 19907, 322, 264, 646, 917, 11, 5850, 291, 434, 516, 281, 312, 1228, 746, 411, 9573, 9539, 260, 281, 24438, 428, 15778, 382, 264, 7576, 13], "temperature": 0.0, "avg_logprob": -0.1806621049579821, "compression_ratio": 1.5878136200716846, "no_speech_prob": 0.00011060558608733118}, {"id": 579, "seek": 318380, "start": 3183.8, "end": 3190.8, "text": " So there's a way to replace that with Vite, and you can just have a really nice tool for JavaScript on the front end.", "tokens": [407, 456, 311, 257, 636, 281, 7406, 300, 365, 691, 642, 11, 293, 291, 393, 445, 362, 257, 534, 1481, 2290, 337, 15778, 322, 264, 1868, 917, 13], "temperature": 0.0, "avg_logprob": -0.14991934724556383, "compression_ratio": 1.6644518272425248, "no_speech_prob": 5.954980224487372e-06}, {"id": 580, "seek": 318380, "start": 3190.8, "end": 3192.8, "text": " And same for Laravel.", "tokens": [400, 912, 337, 33935, 779, 13], "temperature": 0.0, "avg_logprob": -0.14991934724556383, "compression_ratio": 1.6644518272425248, "no_speech_prob": 5.954980224487372e-06}, {"id": 581, "seek": 318380, "start": 3192.8, "end": 3196.8, "text": " There's a plugin for Laravel that lets you just use Vite instead of its equivalent of Webpack.", "tokens": [821, 311, 257, 23407, 337, 33935, 779, 300, 6653, 291, 445, 764, 691, 642, 2602, 295, 1080, 10344, 295, 9573, 9539, 13], "temperature": 0.0, "avg_logprob": -0.14991934724556383, "compression_ratio": 1.6644518272425248, "no_speech_prob": 5.954980224487372e-06}, {"id": 582, "seek": 318380, "start": 3196.8, "end": 3202.8, "text": " And there's also tools like Cypress or Storybook that are more development tools.", "tokens": [400, 456, 311, 611, 3873, 411, 10295, 11637, 420, 14484, 2939, 300, 366, 544, 3250, 3873, 13], "temperature": 0.0, "avg_logprob": -0.14991934724556383, "compression_ratio": 1.6644518272425248, "no_speech_prob": 5.954980224487372e-06}, {"id": 583, "seek": 318380, "start": 3202.8, "end": 3206.8, "text": " You've either got your end-to-end testing or your component library or something.", "tokens": [509, 600, 2139, 658, 428, 917, 12, 1353, 12, 521, 4997, 420, 428, 6542, 6405, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.14991934724556383, "compression_ratio": 1.6644518272425248, "no_speech_prob": 5.954980224487372e-06}, {"id": 584, "seek": 318380, "start": 3206.8, "end": 3209.8, "text": " But it can all use Vite across the stack.", "tokens": [583, 309, 393, 439, 764, 691, 642, 2108, 264, 8630, 13], "temperature": 0.0, "avg_logprob": -0.14991934724556383, "compression_ratio": 1.6644518272425248, "no_speech_prob": 5.954980224487372e-06}, {"id": 585, "seek": 318380, "start": 3209.8, "end": 3211.8, "text": " You don't have to worry about these separate configurations.", "tokens": [509, 500, 380, 362, 281, 3292, 466, 613, 4994, 31493, 13], "temperature": 0.0, "avg_logprob": -0.14991934724556383, "compression_ratio": 1.6644518272425248, "no_speech_prob": 5.954980224487372e-06}, {"id": 586, "seek": 321180, "start": 3211.8, "end": 3216.8, "text": " You don't have to worry about which environment to make in and trying to get the tools to talk to each other.", "tokens": [509, 500, 380, 362, 281, 3292, 466, 597, 2823, 281, 652, 294, 293, 1382, 281, 483, 264, 3873, 281, 751, 281, 1184, 661, 13], "temperature": 0.0, "avg_logprob": -0.1929397172825311, "compression_ratio": 1.5720164609053497, "no_speech_prob": 6.643316737608984e-06}, {"id": 587, "seek": 321180, "start": 3216.8, "end": 3225.8, "text": " It's just a streamlined way to use the same configuration and the same expectation of how the code works across your entire code base.", "tokens": [467, 311, 445, 257, 48155, 636, 281, 764, 264, 912, 11694, 293, 264, 912, 14334, 295, 577, 264, 3089, 1985, 2108, 428, 2302, 3089, 3096, 13], "temperature": 0.0, "avg_logprob": -0.1929397172825311, "compression_ratio": 1.5720164609053497, "no_speech_prob": 6.643316737608984e-06}, {"id": 588, "seek": 321180, "start": 3225.8, "end": 3231.8, "text": " Just so I don't misunderstand it, Ruby doesn't get compiled to ESM, right?", "tokens": [1449, 370, 286, 500, 380, 35736, 309, 11, 19907, 1177, 380, 483, 36548, 281, 12564, 44, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1929397172825311, "compression_ratio": 1.5720164609053497, "no_speech_prob": 6.643316737608984e-06}, {"id": 589, "seek": 321180, "start": 3231.8, "end": 3235.8, "text": " Correct. That's just Ruby on Rails doing Ruby on Rails things.", "tokens": [12753, 13, 663, 311, 445, 19907, 322, 48526, 884, 19907, 322, 48526, 721, 13], "temperature": 0.0, "avg_logprob": -0.1929397172825311, "compression_ratio": 1.5720164609053497, "no_speech_prob": 6.643316737608984e-06}, {"id": 590, "seek": 323580, "start": 3235.8, "end": 3243.8, "text": " Okay. So Vite is not only compiling for or bundling for a front end, but it's also able to run servers, right?", "tokens": [1033, 13, 407, 691, 642, 307, 406, 787, 715, 4883, 337, 420, 13882, 1688, 337, 257, 1868, 917, 11, 457, 309, 311, 611, 1075, 281, 1190, 15909, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.20711321043736727, "compression_ratio": 1.5932835820895523, "no_speech_prob": 8.267720659205224e-06}, {"id": 591, "seek": 323580, "start": 3243.8, "end": 3250.8, "text": " Is my understanding correct now? Because Laravel is a backend technology as far as I understand it.", "tokens": [1119, 452, 3701, 3006, 586, 30, 1436, 33935, 779, 307, 257, 38087, 2899, 382, 1400, 382, 286, 1223, 309, 13], "temperature": 0.0, "avg_logprob": -0.20711321043736727, "compression_ratio": 1.5932835820895523, "no_speech_prob": 8.267720659205224e-06}, {"id": 592, "seek": 323580, "start": 3250.8, "end": 3263.8, "text": " This is more an integration so that as you're working with Ruby or Laravel, rather than having to compile your JavaScript via Webpack or via something else or not at all, you're integrating Vite into that experience.", "tokens": [639, 307, 544, 364, 10980, 370, 300, 382, 291, 434, 1364, 365, 19907, 420, 33935, 779, 11, 2831, 813, 1419, 281, 31413, 428, 15778, 5766, 9573, 9539, 420, 5766, 746, 1646, 420, 406, 412, 439, 11, 291, 434, 26889, 691, 642, 666, 300, 1752, 13], "temperature": 0.0, "avg_logprob": -0.20711321043736727, "compression_ratio": 1.5932835820895523, "no_speech_prob": 8.267720659205224e-06}, {"id": 593, "seek": 326380, "start": 3263.8, "end": 3281.8, "text": " Okay. Right. Which means if you try to download hello.scss, or when you render your HTML in Ruby, I'm assuming it has to post-process that with Vite.", "tokens": [1033, 13, 1779, 13, 3013, 1355, 498, 291, 853, 281, 5484, 7751, 13, 4417, 3810, 11, 420, 562, 291, 15529, 428, 17995, 294, 19907, 11, 286, 478, 11926, 309, 575, 281, 2183, 12, 41075, 300, 365, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.19269649956815987, "compression_ratio": 1.4861111111111112, "no_speech_prob": 1.3631058209284674e-05}, {"id": 594, "seek": 326380, "start": 3281.8, "end": 3286.8, "text": " So it's some setup that runs on the server to make sure it has those assets, I'm assuming.", "tokens": [407, 309, 311, 512, 8657, 300, 6676, 322, 264, 7154, 281, 652, 988, 309, 575, 729, 9769, 11, 286, 478, 11926, 13], "temperature": 0.0, "avg_logprob": -0.19269649956815987, "compression_ratio": 1.4861111111111112, "no_speech_prob": 1.3631058209284674e-05}, {"id": 595, "seek": 326380, "start": 3286.8, "end": 3288.8, "text": " Yep. Even in production?", "tokens": [7010, 13, 2754, 294, 4265, 30], "temperature": 0.0, "avg_logprob": -0.19269649956815987, "compression_ratio": 1.4861111111111112, "no_speech_prob": 1.3631058209284674e-05}, {"id": 596, "seek": 326380, "start": 3288.8, "end": 3290.8, "text": " In production, it's using a bundle at that point.", "tokens": [682, 4265, 11, 309, 311, 1228, 257, 24438, 412, 300, 935, 13], "temperature": 0.0, "avg_logprob": -0.19269649956815987, "compression_ratio": 1.4861111111111112, "no_speech_prob": 1.3631058209284674e-05}, {"id": 597, "seek": 326380, "start": 3290.8, "end": 3292.8, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.19269649956815987, "compression_ratio": 1.4861111111111112, "no_speech_prob": 1.3631058209284674e-05}, {"id": 598, "seek": 329280, "start": 3292.8, "end": 3297.8, "text": " That said, because you mentioned Vite on the server, there is Vite Node or Node Vite. I think it's Vite Node.", "tokens": [663, 848, 11, 570, 291, 2835, 691, 642, 322, 264, 7154, 11, 456, 307, 691, 642, 38640, 420, 38640, 691, 642, 13, 286, 519, 309, 311, 691, 642, 38640, 13], "temperature": 0.0, "avg_logprob": -0.1955120524422067, "compression_ratio": 1.667953667953668, "no_speech_prob": 2.3923354092403315e-05}, {"id": 599, "seek": 329280, "start": 3297.8, "end": 3304.8, "text": " And that's what Vitest uses in order to run Vite on a Node environment for running unit tests.", "tokens": [400, 300, 311, 437, 691, 642, 372, 4960, 294, 1668, 281, 1190, 691, 642, 322, 257, 38640, 2823, 337, 2614, 4985, 6921, 13], "temperature": 0.0, "avg_logprob": -0.1955120524422067, "compression_ratio": 1.667953667953668, "no_speech_prob": 2.3923354092403315e-05}, {"id": 600, "seek": 329280, "start": 3304.8, "end": 3309.8, "text": " But it's not really intended, at least for the time being, as a solution to write a server in.", "tokens": [583, 309, 311, 406, 534, 10226, 11, 412, 1935, 337, 264, 565, 885, 11, 382, 257, 3827, 281, 2464, 257, 7154, 294, 13], "temperature": 0.0, "avg_logprob": -0.1955120524422067, "compression_ratio": 1.667953667953668, "no_speech_prob": 2.3923354092403315e-05}, {"id": 601, "seek": 329280, "start": 3309.8, "end": 3314.8, "text": " So nobody's going to be writing blog posts on how to set up Express using Vite Node.", "tokens": [407, 5079, 311, 516, 281, 312, 3579, 6968, 12300, 322, 577, 281, 992, 493, 20212, 1228, 691, 642, 38640, 13], "temperature": 0.0, "avg_logprob": -0.1955120524422067, "compression_ratio": 1.667953667953668, "no_speech_prob": 2.3923354092403315e-05}, {"id": 602, "seek": 329280, "start": 3314.8, "end": 3316.8, "text": " Are you sure about that?", "tokens": [2014, 291, 988, 466, 300, 30], "temperature": 0.0, "avg_logprob": -0.1955120524422067, "compression_ratio": 1.667953667953668, "no_speech_prob": 2.3923354092403315e-05}, {"id": 603, "seek": 329280, "start": 3316.8, "end": 3317.8, "text": " They might now, but...", "tokens": [814, 1062, 586, 11, 457, 485], "temperature": 0.0, "avg_logprob": -0.1955120524422067, "compression_ratio": 1.667953667953668, "no_speech_prob": 2.3923354092403315e-05}, {"id": 604, "seek": 331780, "start": 3317.8, "end": 3326.8, "text": " I mean, if there's one thing I know about JavaScript developers, it's if it's possible to do it, they're going to do it.", "tokens": [286, 914, 11, 498, 456, 311, 472, 551, 286, 458, 466, 15778, 8849, 11, 309, 311, 498, 309, 311, 1944, 281, 360, 309, 11, 436, 434, 516, 281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.1861408198321307, "compression_ratio": 1.623015873015873, "no_speech_prob": 3.881910743075423e-05}, {"id": 605, "seek": 331780, "start": 3326.8, "end": 3328.8, "text": " And that's fair.", "tokens": [400, 300, 311, 3143, 13], "temperature": 0.0, "avg_logprob": -0.1861408198321307, "compression_ratio": 1.623015873015873, "no_speech_prob": 3.881910743075423e-05}, {"id": 606, "seek": 331780, "start": 3328.8, "end": 3331.8, "text": " For better or worse. Sometimes it's better.", "tokens": [1171, 1101, 420, 5324, 13, 4803, 309, 311, 1101, 13], "temperature": 0.0, "avg_logprob": -0.1861408198321307, "compression_ratio": 1.623015873015873, "no_speech_prob": 3.881910743075423e-05}, {"id": 607, "seek": 331780, "start": 3331.8, "end": 3333.8, "text": " Sometimes it is.", "tokens": [4803, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.1861408198321307, "compression_ratio": 1.623015873015873, "no_speech_prob": 3.881910743075423e-05}, {"id": 608, "seek": 331780, "start": 3333.8, "end": 3338.8, "text": " All right. Well, Lindsay, do you know any good resources for getting started?", "tokens": [1057, 558, 13, 1042, 11, 35017, 11, 360, 291, 458, 604, 665, 3593, 337, 1242, 1409, 30], "temperature": 0.0, "avg_logprob": -0.1861408198321307, "compression_ratio": 1.623015873015873, "no_speech_prob": 3.881910743075423e-05}, {"id": 609, "seek": 331780, "start": 3338.8, "end": 3346.8, "text": " Do you have any recommendations for things to watch or listen to or read if somebody wants to learn more about Vite and get started?", "tokens": [1144, 291, 362, 604, 10434, 337, 721, 281, 1159, 420, 2140, 281, 420, 1401, 498, 2618, 2738, 281, 1466, 544, 466, 691, 642, 293, 483, 1409, 30], "temperature": 0.0, "avg_logprob": -0.1861408198321307, "compression_ratio": 1.623015873015873, "no_speech_prob": 3.881910743075423e-05}, {"id": 610, "seek": 334680, "start": 3346.8, "end": 3350.8, "text": " I think that's going to be a nuanced answer depending on what you're looking for.", "tokens": [286, 519, 300, 311, 516, 281, 312, 257, 45115, 1867, 5413, 322, 437, 291, 434, 1237, 337, 13], "temperature": 0.0, "avg_logprob": -0.16394922374624066, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.00011060048564104363}, {"id": 611, "seek": 334680, "start": 3350.8, "end": 3359.8, "text": " If you just want to get familiar with Vite, I would just go to the website, vitejs.dev, and kind of just read through, find what's interesting for you.", "tokens": [759, 291, 445, 528, 281, 483, 4963, 365, 691, 642, 11, 286, 576, 445, 352, 281, 264, 3144, 11, 371, 642, 25530, 13, 40343, 11, 293, 733, 295, 445, 1401, 807, 11, 915, 437, 311, 1880, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.16394922374624066, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.00011060048564104363}, {"id": 612, "seek": 334680, "start": 3359.8, "end": 3365.8, "text": " There's the awesome Vite repository that has an amazing list of resources that are using Vite.", "tokens": [821, 311, 264, 3476, 691, 642, 25841, 300, 575, 364, 2243, 1329, 295, 3593, 300, 366, 1228, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.16394922374624066, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.00011060048564104363}, {"id": 613, "seek": 334680, "start": 3365.8, "end": 3370.8, "text": " A lot of it's going to be about Vue and React, but there's a little bit of Elm in there.", "tokens": [316, 688, 295, 309, 311, 516, 281, 312, 466, 691, 622, 293, 30644, 11, 457, 456, 311, 257, 707, 857, 295, 2699, 76, 294, 456, 13], "temperature": 0.0, "avg_logprob": -0.16394922374624066, "compression_ratio": 1.6547619047619047, "no_speech_prob": 0.00011060048564104363}, {"id": 614, "seek": 337080, "start": 3370.8, "end": 3382.8, "text": " And I think the third thing I would suggest is on YouTube, last year in October was ViteConf 2022, where I gave a talk on the same thing about using Vite and Elm together.", "tokens": [400, 286, 519, 264, 2636, 551, 286, 576, 3402, 307, 322, 3088, 11, 1036, 1064, 294, 7617, 390, 691, 642, 43874, 20229, 11, 689, 286, 2729, 257, 751, 322, 264, 912, 551, 466, 1228, 691, 642, 293, 2699, 76, 1214, 13], "temperature": 0.0, "avg_logprob": -0.17809890080424187, "compression_ratio": 1.6147540983606556, "no_speech_prob": 1.4969830772315618e-05}, {"id": 615, "seek": 337080, "start": 3382.8, "end": 3388.8, "text": " And I will admit that talk was directed more at people who aren't familiar with Elm than people who aren't familiar with Vite.", "tokens": [400, 286, 486, 9796, 300, 751, 390, 12898, 544, 412, 561, 567, 3212, 380, 4963, 365, 2699, 76, 813, 561, 567, 3212, 380, 4963, 365, 691, 642, 13], "temperature": 0.0, "avg_logprob": -0.17809890080424187, "compression_ratio": 1.6147540983606556, "no_speech_prob": 1.4969830772315618e-05}, {"id": 616, "seek": 337080, "start": 3388.8, "end": 3392.8, "text": " But you can check that talk out as well as all of the other talks.", "tokens": [583, 291, 393, 1520, 300, 751, 484, 382, 731, 382, 439, 295, 264, 661, 6686, 13], "temperature": 0.0, "avg_logprob": -0.17809890080424187, "compression_ratio": 1.6147540983606556, "no_speech_prob": 1.4969830772315618e-05}, {"id": 617, "seek": 337080, "start": 3392.8, "end": 3393.8, "text": " It was a 24-hour conference.", "tokens": [467, 390, 257, 4022, 12, 18048, 7586, 13], "temperature": 0.0, "avg_logprob": -0.17809890080424187, "compression_ratio": 1.6147540983606556, "no_speech_prob": 1.4969830772315618e-05}, {"id": 618, "seek": 339380, "start": 3393.8, "end": 3401.8, "text": " There was a lot of content in there about all the different frameworks, all of the different tooling, and how this ecosystem is really shaping up and coming together.", "tokens": [821, 390, 257, 688, 295, 2701, 294, 456, 466, 439, 264, 819, 29834, 11, 439, 295, 264, 819, 46593, 11, 293, 577, 341, 11311, 307, 534, 25945, 493, 293, 1348, 1214, 13], "temperature": 0.0, "avg_logprob": -0.18307895820681788, "compression_ratio": 1.66793893129771, "no_speech_prob": 2.4682163711986504e-05}, {"id": 619, "seek": 339380, "start": 3401.8, "end": 3407.8, "text": " So those would be the resources I would point at first, and then just kind of explore and see what feels good.", "tokens": [407, 729, 576, 312, 264, 3593, 286, 576, 935, 412, 700, 11, 293, 550, 445, 733, 295, 6839, 293, 536, 437, 3417, 665, 13], "temperature": 0.0, "avg_logprob": -0.18307895820681788, "compression_ratio": 1.66793893129771, "no_speech_prob": 2.4682163711986504e-05}, {"id": 620, "seek": 339380, "start": 3407.8, "end": 3411.8, "text": " Amazing. And where can people follow you?", "tokens": [14165, 13, 400, 689, 393, 561, 1524, 291, 30], "temperature": 0.0, "avg_logprob": -0.18307895820681788, "compression_ratio": 1.66793893129771, "no_speech_prob": 2.4682163711986504e-05}, {"id": 621, "seek": 339380, "start": 3411.8, "end": 3414.8, "text": " I am on Twitter at lindsaykwardell.", "tokens": [286, 669, 322, 5794, 412, 287, 471, 21664, 74, 1007, 898, 13], "temperature": 0.0, "avg_logprob": -0.18307895820681788, "compression_ratio": 1.66793893129771, "no_speech_prob": 2.4682163711986504e-05}, {"id": 622, "seek": 339380, "start": 3414.8, "end": 3419.8, "text": " I am also on Mastodon at lindsaykwardell at mastodon.social.", "tokens": [286, 669, 611, 322, 376, 525, 378, 266, 412, 287, 471, 21664, 74, 1007, 898, 412, 27055, 378, 266, 13, 48600, 13], "temperature": 0.0, "avg_logprob": -0.18307895820681788, "compression_ratio": 1.66793893129771, "no_speech_prob": 2.4682163711986504e-05}, {"id": 623, "seek": 339380, "start": 3419.8, "end": 3420.8, "text": " Fabulous. All right.", "tokens": [17440, 6893, 13, 1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.18307895820681788, "compression_ratio": 1.66793893129771, "no_speech_prob": 2.4682163711986504e-05}, {"id": 624, "seek": 342080, "start": 3420.8, "end": 3423.8, "text": " Well, Lindsay, it was a pleasure having you on. Thanks so much for coming on the show.", "tokens": [1042, 11, 35017, 11, 309, 390, 257, 6834, 1419, 291, 322, 13, 2561, 370, 709, 337, 1348, 322, 264, 855, 13], "temperature": 0.0, "avg_logprob": -0.17709942964407113, "compression_ratio": 1.4, "no_speech_prob": 1.0127357199962717e-05}, {"id": 625, "seek": 342080, "start": 3423.8, "end": 3425.8, "text": " Thanks for inviting me. This was great.", "tokens": [2561, 337, 18202, 385, 13, 639, 390, 869, 13], "temperature": 0.0, "avg_logprob": -0.17709942964407113, "compression_ratio": 1.4, "no_speech_prob": 1.0127357199962717e-05}, {"id": 626, "seek": 342080, "start": 3425.8, "end": 3427.8, "text": " And you're in. Until next time.", "tokens": [400, 291, 434, 294, 13, 9088, 958, 565, 13], "temperature": 0.0, "avg_logprob": -0.17709942964407113, "compression_ratio": 1.4, "no_speech_prob": 1.0127357199962717e-05}, {"id": 627, "seek": 342780, "start": 3427.8, "end": 3450.8, "text": " Until next time.", "tokens": [50364, 9088, 958, 565, 13, 51514], "temperature": 0.0, "avg_logprob": -0.271246143749782, "compression_ratio": 0.6666666666666666, "no_speech_prob": 1.2955093552591279e-05}], "language": "en"}