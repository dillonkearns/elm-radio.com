{"text": " Hello Jeroen. Hey, what's up Doc? Oh, you're trying to beat me at my own game, are we? Yes, I found a pun. And I'm going with it. Even if I have to destroy the holy intro that we have. Wow, breaking with the format. Well, I will admit, I was trying to think of a good one, but I was having a little bit of writer's block, so... I'm gonna say it's funny, but I don't think I get it. But it's funny, Dillon. It's very funny. Please continue doing that. Maybe it's just me. When I think of documentation, the first thing that comes to mind is writer's block, because I am sitting there staring at a blank page, and it is very painful. But, Jeroen, as always, we endure that pain for our dear users. Definitely true, yeah. We will suffer through writing JavaScript, we will suffer through writing English words, all in the name of our users. And it's a very noble view of, I guess, all of us then? I was not trying to praise myself, but I guess I am. I don't know about you, but I do find it way more difficult than writing the code. Yeah, definitely agree. So maybe before we delve into that, what is our topic today? What is our topic? I'm gonna say it is writing great docs. Not just good docs, because, as Evan says in the Elm Philosophy tweet, it's not done until the docs are great. And I do love that as a sort of foundational principle in Elm. And, you know, I mean, when you write an Elm package, the docs are already pretty good as a starting point, because you are required to have, you know, types for all of your exposed APIs, and it comes with already a really good, easy-to-navigate set of documentation for your package. Like, honestly, better than almost any other programming language I've seen. But in addition to that, we go above and beyond, and we try to make it a really good flow through reading that and getting up and running with our package. I thought it would be fun to talk about, like, what do make docs great? What's the process for great docs? What should package authors be thinking about for making their docs great? How should users use that information to navigate docs? And, you know, maybe whether those things are relevant for documenting an application. I think one of the reasons why we tend to have great docs in Elm is because all the tools and packages that we enjoy using have great docs. So I think it's kind of a culture thing. Like, in the Elm community, whenever we release something, we write great docs. And it's kind of the same as, like, oh, well, every time we try to make something, we want it to be type-safe. That's just the culture that we have. And it's one that has been with Elm for a long time. I don't know how long, but at least before my time with Elm. And therefore, the expectation is that every time you write docs, they have to be great. And that culture at the start is very important because now it's set in stone almost. And whenever I see packages that are not great quality-wise or doc-wise, it's usually by someone who has just learned Elm and was just introduced to Elm and doesn't have the expanded experience with Elm. And that's fine, I guess. They're going to learn at some point. Interesting. So when you say that you've grown accustomed to Elm packages with great docs, can you dig in a little bit to what that means to you? Like, as a consumer of documentation, what makes them great? What are the things you notice about those packages? Well, maybe let's start with the first thing that is obvious but also quite not obvious. The whole API of the package is documented. If I remember my NPM days or JavaScript days, you had a package and the documentation for that package was the readme. And maybe like an additional website, but it's usually like the readme and everything is in readme. More on that later, I think. But the API that would be in the readme, sometimes it's just like an example like, oh, this is what you can do with this package. You can do this, and they show a simplified example because it's annoying to write a lot of documentation. And then that's it. Or they write a lot of options, but they don't write all of the ways that you can use this package, all the ways that are intended, nor the ones that are unintended, which makes sense that they're unintended. But I've seen a lot of packages where you would open an issue saying, oh, I would love to be able to do this. And they would answer, oh, well, you can import this submodule of the package, and then you can do that. But that's not documented. And now, usually you would say, oh, now I'm using internals, which is not good, and in practice, it's not good. So yeah, the fact that we have to document everything in the API, or just that they're shown in the package documentation, is already a great point, I think, in the end. Yeah, that definitely resonates with me. I can think of so many times when I've been trying to figure out how to do something with an npm package, and I'm searching through and often end up digging through obscure issues that I have to Google for and find some niche use of it that isn't documented or isn't documented in a clear place. Or I have to search through the source code and see what it's checking for. If this object property exists, then do this. If it doesn't, then do that. So it's true. By virtue of publishing an Elm package, those things are documented. So that's the bare minimum for an Elm package. So another part is every API is shown, like all the custom types or the functions that are there, all the type aliases. But whenever you try to publish a package, one of the things that the Elm compiler will tell you is that some of the functions or some of the types are not documented, and you need to. So Elm forces you to write documentation for all those exposed APIs, all those public APIs. So even if you don't think you're going to write good docs for them, you have to carefully or you have to make that decision purposefully. But sometimes it's pretty easy to just write some documentation, some explanation, oh, this function does this, and then, oh, I might as well add one little example, and now it's already very usable. So that's like that little nudge that asks you to write some documentation, even if it's empty, which I don't like, but we can talk about that later. That little nudge already pushes you to write some documentation and potentially to make it good. So when you're consuming an Elm package, what do those docs look like when they feel like they're really helping you? What's your experience? So that's one of the things I'm curious to dig into here too, because I think in order to talk about great docs, I think it's really good to put yourself in the user's shoes, and we happen to be users of Elm packages and consumers of docs for Elm packages. So what is it, like, when we're looking at those beautiful Elm package docs and they're not left blank and there's something written there, what is it that makes it really good? I think they always say, like, this is a blazingly fast package to do something, or... No, wait, sorry, that's NPM. Yeah. Sorry, I messed it up. The logo really helps you understand what it does too. Yeah, and the visual design and the 100 SCO score that you have. No, yeah, so you usually want to look at a package. The first thing that I see is the name of the package, who made it, and then a description of what it does, like, what is the purpose of this, or what does this package help you with, then some examples of how to use it. But also in some cases where you have, like, for instance, if you have, like, a package to parse some format, like, that's pretty obvious what it does. So you don't have to explain it too much. You have to explain how to use it, but not how it works under the hood or what are the advantages of using this approach. But whenever there are multiple alternatives to solution, say, GraphQL packages, what I often see is, like, the philosophy behind a package or the trade-offs, or hopefully the trade-offs of the solution. So I think explaining the philosophy or the trade-offs that are involved in this solution versus other solutions, sometimes even referencing the other solutions, is a great thing to have in your docs. Just saying it's blazingly fast is not necessarily helpful, especially if all of them say that. Right. Unless that's part of the philosophy, and it's a differentiator. Yeah, but then you would need to say, like, the reason why it's blazingly fast is either we try this new approach, or there's a trade-off, like, this is simpler, this doesn't handle all the edge cases, but for the normal cases, it's going to be way faster. And that's something that you would like to see. Right. If it's a drop-in replacement for Dict, except faster, that's the only thing that's different, then that's what you want to know. And that's a good way to describe it. And maybe in that case, the package can also handle the more complex approach. And then it's just, like, having the best of both worlds, I guess. Maybe in a somewhat convoluted way, maybe. Who knows? Mm-hmm. Mm-hmm. But yeah, I think I'm looking for all those. So, description, examples, philosophy. But yeah, description of the APIs, and how to use those, and how to use them together through a guide or through examples. That's the kind of things that I'm looking for. Right. Yeah, that resonates with me as well. I would say, when I go to open up the package documentation for an Elm package, as you say, often there will be a few alternatives, and they have the same name. They're all called ElmGraphQL, or they're all called, you know, ElmAnyDict, or, you know, ElmMarkdown, or whatever. And it's like, okay, well, so I want to know. The first thing I'm trying to find out as fast as possible is, does this, number one, can I use this for the problem I'm trying to solve? Because if I can't, I don't even want to consider if I like it, or if I like its trade-offs. Just like, what problem can I use this to solve? Is this a faster dict? No, this is ElmGraphQL. Okay, well, then I'm just going to skip it. Right. It better tell you that quickly. And you don't have much of, I mean, I can say this from personal experience, as a reader of docs, you do not have my attention for very long to tell me that. And if it's like a very long-form description of things that doesn't just, like, right at the top in a topic sentence tell me exactly what it's doing and give me information to help me decide whether it's going to help solve my problem. I might not stick around there. It's certainly not going to be a good experience looking through that package documentation. Because that's the first question I want to answer. Yeah. The thing is, like, the Elm ecosystem is pretty small for good and bad. And in this case, like, if you have two alternatives, or even like four, like, you can spend a little more time digging whether a specific package works for you. Whereas in JavaScript, like, you have 200 packages for the same thing. And yeah, you really want to go to the one that strikes you the most. Right. But if it's like a somewhat subtle thing, if it's like, oh, it's a form package, and I look at the readme, and I don't understand, like, what are the limitations? What are the, like, what are the things I can and can't do with this? Then I'm not going to, and if I can't, like, find a live demo somewhere, then I might not dig into that much further, because I'm going to end up going to something else. And it's going to have this mystique that I'm not going to want to approach it. Yeah, what you say is that you want to know about the limitations of a package. You want the package author to be honest about something, even if it sells not as well. Yeah, totally. Which is okay, because we're usually not getting paid for open source work anyway. Yeah, I was just having some interesting discussions with Ryan, the author of Elmland and Elm SPA, and we were kind of talking about, you know, Elmland or Elm SPA. Elmland is sort of a new version of Elm SPA versus Elm Pages, because v3 is sort of blurring the lines a little bit, because with Elm Pages v2, it was a much more narrowly scoped tool that was generating static sites. And with v3, you know, a site with authentication, you know, a site with user-specific dynamic content is now a use case that Elm Pages v3 supports. So it starts to get blurry. But so I tried really, it took a lot of thought actually, to try to concisely summarize what is it that would make something not a good fit for Elm Pages v3. And what I finally came up with is like, well, there's this sort of architectural decision that you're making by using Elm Pages v3, which is that I would like to build an application which communicates with an Elm backend. That backend could be your build server as you generate your static pages, or it could be a traditional server, or it could be a serverless function. But there's some sort of Elm backend context, and every time you navigate to a page, it is communicating with that Elm backend to resolve data and then sort of bootstrap the page with that data. That, I believe, is a very compelling pattern, but that's a big architectural decision. And I think that it's a compelling story that is a very strong way to build an application. But there are definitely certain clear-cut cases where it's not going to be a good fit. For example, if you're building a one-screen game, then that set of features isn't going to really help you with that. And loading textures and things like that is not what the Elm Pages backend task abstraction is designed for. It's not good for going off for 100 seconds and loading something. You want that done asynchronously in the background. It doesn't mean you can't use it, but it's not optimized for it, it doesn't really need the features that Elm Pages v3 gives you. Yes, exactly. And similarly, you can use that rule of thumb, is this feature set serving my needs for the use case I'm building for? And do I want to make this architectural decision? So that's what I finally realized is, OK, a lot of the more dynamic apps with authentication and things like that, you could choose Elm Land or Elm Pages. But the differentiator is, do I want to use this architecture? Because there are trade-offs that are associated with that. Do you want to go all-in on using things that having a backend allows you to do? Cookie-based authentication and being able to do server-level redirects and being able to submit form data and handle that in the same context using the form API. If you want to use those patterns in that architecture, then it's going to be a good fit. But not everybody is going to want to use that architecture. So that's the differentiator. And it's not like one of them is good or bad, but you need to tell people very clearly, you need to help them make that decision. Because you're the author of the tool, you have all of this context, and somehow you need to distill that down to the relevant information that someone needs to make a decision. Because that's what they're trying to do. They navigate to your tool, and the first thing they're trying to do is make a decision, is this relevant to me? Is this usable? And are there alternatives that would be better? So you need to help them make that decision. Absolutely. Yep. I think you're completely right. And then once you've decided that, you probably want to figure out how to use it. And again, if you land on a tool, you go to the Elm Review package docs, you understand what sort of use cases it helps you solve, you decide you want to use it. How do I actually do something, anything, right? As quickly as possible. I think of this actually very similarly to how I think about the coding discipline of do the simplest thing that could possibly work, or finding the shortest path to green, and taking small steps to connect things where it's working in between. You don't want a long feedback cycle where it's like, okay, do these 100 steps, then you're all set. Then you can evaluate whether you like this package or not. Then you can evaluate whether you like it, and then you'll know whether you've done those 100 steps correctly at the end of the 100 steps. Oh, yeah. There's that thing as well. Yeah. I was still in the evaluating phase of the package, where you want to know whether it fits your use case well, and whether there are any gotchas with it. Exactly. Yes. That's going to be a super frustrating experience on both accounts, where you're holding your breath, am I doing these steps correctly? You're like, I don't have time to do 100 steps. I haven't decided whether to commit to this yet. I'm not like, I'm integrating this tool now. You need to give an ELE demo. You need to give a quick start guide. I'm not sure if Elm Review has this right off the bat, but the Elm Review dash dash template flag is a great way to try it. You can say, here you go. Here's a single command. You npm install dash g, and then you run this one command. You don't even need to do that. You can just install it through npx. You can just npx it. Or you used to be able to. I don't remember. Sure enough, you do have that first thing. You've got it under a nice simple heading. Let's look at Elm Review's docs. The first thing I see is a topic sentence. Elm Review analyzes Elm projects to help find mistakes before your users find them. Screenshot. That's awesome. Now I know what it does. I get a taste of the experience. It's a single sentence. It's not like a paragraph that I'm like, oh, do I have to decide what's meaningful in this long paragraph? It's a single sentence. Then there's a new heading. What does Elm Review do? It gives you a sense of what you're going to use it for. And then there's a new heading. Try it out. And it does indeed have the quick start command npx elmreview \u2013template. Amazing. I am a happy customer if I'm going through these docs and trying to evaluate whether you use this. I'm glad to hear it. But I'm sorry, I'm not actually going to pay you. I was a little misleading. Sorry, Jeroen. It was worth the effort of doing all those years of work just to see whether you would pay me. I would hypothetically pay if there were a way to do that. As you say, you want the quick feedback. So there are multiple ways to do that. So in the case of Elm Review, it's a bit of a peculiar story where you have to install the tool and then choose your configuration. So I have this try it out section that tells you to use templates with a predefined configuration. But that's like a pretty specific use case. In most cases, let's imagine you just have a dict package. Then just a simple example that you could copy paste into a REPL, that would be very sufficient. You don't need anything more. And that's great because it also makes a perfect example for your function and it makes it very clear what something does. So that's great. In some cases that are more complex, you could have a bigger code section. But if you want people to play with it, like something visual or it's something a little bit more complex. Let's say you want to parse a CSV, then you could write an LE. The problem with the LE though is that sometimes I think it always uses the latest version of your package. So older versions of your package will have documentation that is broken. Maybe that will be fixed in the future. But the essence of the idea still holds is you want something that people can just go to without having to install your package, without having to create a small new project to try things out. You don't even have to force people to use Elm Reactor or something. And they can play with it and they can see, does this fit? Does this work? Yes, no, let's go to the next package or let's try to fix my immediate problem that I was trying to solve. In the case of something like Elm GraphQL, that is about code generation, that's a lot more complex. So I think what you do, or I know what you do, is to have an example project where you have a GraphQL schema from which you generate a lot of code. And if I remember correctly, you checked in the code so people can see it, can see the generated code. And that I find to be very important. I've seen a few places where you had to go in yourself and regenerate those files to see what they looked like. But I wanted to see, if I'm curious or if that's important to me, how those generated files will look like. So I think it's very important that you check them in so that they're available on GitHub and people can just see them. So that's a very good thing that you've done. But yeah, sometimes you need a project, sometimes you just need a code sample. Whatever makes it very easy for people to try it out is good. Right. Yeah, as you say, because it involves code generation. If it's just a vanilla package, then if you can give an LE link, I really think you should. Because if you can give a simple self-contained, like LE requires that it is self-contained. So if you can give that, it forces you to write a very simple example. And it gives people something shareable, they can play around with it. And they can extract it into their own project from some working code. Not some readme comment that they have to trust. They can actually see it and even tweak it and then integrate it into their project. I think that it's really good to have a variety of different types of content as well. Because different people, and over the course of doing different types of tasks, will want content presented in different ways. So for example, the source code itself, even like you said, generated source code. Perusing that, some types of users might want to say, well what is this actually doing to understand it? And someone else might never want to look at that. They might want to look at an actual working example, even if it's not an LE because it's using generated code. They might want to see a deployed example that makes GraphQL requests and inspects the network tab. And someone else might want to play around with it locally and run the code generator. Someone else might want to read a short guide. And these are all different formats that people have different styles. And some people read through the test folder. I actually pretty commonly will go through a project and read through the test folder. I consider that to be part of a project's documentation. Yeah, I agree. Part of the reason why I would like to see your generated code is because, or for Elm GraphQL, is because a code generator will produce Elm modules, and that's the API that I have to work with usually. So whenever I choose to work with a package, I want to know the API. And if your API is the generated code, then I kind of need to see it. Otherwise, it's very blurry or very fuzzy for me. Yes. Actually, that makes me think, like, I probably could take that Elm.json file or the docs.json file for the generated Elm GraphQL example that hits the GitHub API. What is the docs.json file? Docs.json file is an encapsulation of all of the exposed values, types, and functions for a package along with their corresponding documentation. So that is what the package docs present to us in a nice format on a site. I could ship those. I could ship that and then give people a link to documentation. That would be another cool way to present that information for a generated API using Elm Doc Preview. Aha, Elm Doc Preview. What the hell is that? Elm Doc Preview is a very good tool. We're in the glossary section. That's right. Exactly. Exactly. So Elm Doc Preview is a really nice tool that lets you, on your local machine, it lets you do a live reloading server that will show you your package documentation for an Elm package or compiler errors if there are any. It live reloads as you update your documentation. It's an invaluable tool for package authors. You can also use it for displaying documentation for application code as well. You can define an Elm-application.json file, and you can use it for in-house application documentation too, which is kind of interesting. Or you can use the Elm Doc Preview site to share links to people that will present your, if you check in the docs.json that you get by running elm make dash dash docs equals docs.json, that's how you generate the docs.json file for an Elm package. If you share that, if you commit that docs.json, then you can share a live preview link of pending documentation. And that is a really valuable process for unpublished packages that you want to get feedback on, for example. Absolutely. Yeah, it's a really valuable tool because often you're writing documentation and you're not sure how it's going to look like, and you write it and then you don't notice problems with it. That will be obvious once you've published it. So for instance, like if you indent some code in your documentation, that will be displayed as Elm code. But if you don't indent it correctly, then it might not be showing that way, and then everything will be on one line and it will be very ugly. So you don't want to notice that after you've published it. You don't want to fix a documentation issue, republish, see that it's still not looking okay, and then republish, and so on and so on. There are also a few things that the Elm package website doesn't handle correctly, like markdown tables. Great idea in theory. In practice, it's not looking great at all. So don't use those. And if you use Elm doc preview, you will notice that it's not going to look okay. There are a few issues, like if you have the add docs annotations that are done in slightly incorrect ways, then they're not going to show up okay in the package website. So you also want to know about those early on. So yeah, Elm doc preview, awesome tool to write your docs and to be able to read through them in a much easier way, like the way that your users would. Instead of having to go through your docs that are spread out all over your Elm code, which is not as great an experience. It's also very motivating to see what needs documentation and what doesn't and just read through a live preview of your docs in that layout of a package documentation site. And for me, just seeing something I don't like or that's missing makes me want to go write it. So I started to get that little kick to go do it. There's one thing where you have to have a valid docs.json file to be able to preview your docs. And that means that you need to have written documentation for every exposed thing. In practice, if you want to see it really quickly and without documenting some of the modules, then you're going to add like empty documentation comments or to-dos, which is probably a little bit better because it will be more obvious. Yeah, that's a good idea. I usually do empty ones, but yeah, to-dos is a good idea. But I do it in tandem with your no missing documentation Elm review rule. I think that's what it's called. Yeah, docs.nomissing. We can talk about those afterwards. I kind of mentioned this before, and we got lost in thought, I guess. But the one reason why we have good documentation in Elm is because there are sections built in. So every module that you expose is a different page or different section, however you want to call those, on the package website, meaning that not everything has to be in the README, which I think is pretty good. Not sure whether it's sufficient. In a lot of cases, yes. In some cases, maybe not. But it's a pretty good thing to have at least. So yeah, just the fact that you can separate some documentation from others is good. So for instance, if you have like one module, which is a lot of tiny helpers with plenty of functions that are not very important to the rest of the API, then you can separate those into one module, and they don't pollute, they don't waste space for the more important modules of your API. So I think that's a pretty important part of why docs are pretty good as a starting point. I totally agree. And just to put a fine point on that mechanically, what you're describing is so when you're writing an elm package, you can write doc comments, which is just a special comment format. You can write that for your top-level values, and you can also write that for the module. So the module has its docs, and each function and exposed value has its docs. You use an annotation in the top-level module's docs to list out all of the exposed values that you want to document. So you can group them into sections. So you can say, wiring up a form, here's the init update view function for the form. And then you can say, defining a field, here's the checkbox and whatever functions for building a field. And you can group those into sections using Markdown because the docs use Markdown format. So if you use the hash hash for an H2 heading, it separates it into headings. And you can even link to those headings. So you can link somebody. You have to sort of open up the inspector tool and click to it because it's not linked at the moment, but it gets the job done. Yeah, you kind of have to guess also what the name of the link is or what the href for the link is. I find it with the inspector. I click on it with the web inspector, yeah, and then copy that. You can try to guess it, but if you have something with a few weird symbols, like, yeah, just use the inspector. That's going to have a better time. Yeah, but that's invaluable. And I would say, like, I notice when I'm reading documentation, I will very frequently, like, often the only thing I read in a whole page are the headings. And that tells me whether or not something's relevant to me. So, like, for example, like, you totally nailed this for my preferences of docs, but I think this is a pretty general best practice for docs in Elm Review. So the review.fix module in Elm Review, the top level describes what are fixes. Like, what the heck is this thing, right? Of course, there's a whole set of associated types and functions and everything, but up front it gives you a few things. So it says guidelines, right? Maybe that's the first thing you want to know. Like, I'm writing a rule. When would I write a rule? But maybe I don't care about that right now. Maybe I'm trying to, like, I know I want to write a rule. I'm not looking for guidelines. I want to mechanically do that. Then you keep scrolling. You don't look at that heading, right? When, parentheses, not to provide an automatic fix. If you are looking for the mechanics of it, again, you keep scrolling. Okay, now creating a fix. Ah, maybe that's what I want to do. Now you see the associated types and values for creating a fix. So, yeah, I think, like, I think when writing documentation, it's important to keep in mind how people are going to consume it, which is they're going to skim, they're going to skip over headlines they don't care about, and that's okay. That's not a personal failing of yours that people don't read through top to bottom. That's just not how people operate. They don't read headlines. They're there for a reason. Put them in the top for a reason. But it really is a choose your own adventure. Actually, before we recorded, you and I were talking about Zelda Breath of the Wild and Tears of the Kingdom and how cool this sort of choose your own adventure style of, like, an open world game is where you can bounce around. You can, whatever, go straight to the final boss and skip all the powerful items and upgrades, or you can do every possible side quest and learn every mechanic of the game before going to the final. You can do it whatever order you want. That's how people do docs. They go in to do a job, and they're not going to do it in the linear order you expect most of the time, or they might. Yeah, first of all, like, I think, as you say, like, you can skim through the headings, and I think it could be valuable to have, like, a table of contents at the top of every page or somewhere on the page. That could be interesting. But, yeah, so you describe the mechanics of how you write documentation for a module. So at the top of the module, you have a module documentation, so curly braces, dash, pipe, some text, and at the end, the closing, dash, curly brace. And in between those, you write some text, some headings, and references to functions. And the thing that I really like about this is you decide, based on how you write or where you write those add docs things, how things will be presented. So if you, the way that the docs are shown do not depend on where they're defined in the page, because they could be, because in Elm there's hoisting everywhere, so the Elm could choose, well, this function is defined before this one, so I'm going to show that one before. But no, it's you define by saying add docs function A, and then later add docs function B, that function A will be displayed before function B. And if you put it in a section or after a section header, then it's going to show up in that section. And you can write those, the things however you want. So you can, as you say, you can write a story. That's kind of like how I like to see it. If you have a story to tell, if like maybe you don't need to have a story for writing a dict package. But in the case of Elm Review, there's a lot of things that I need to explain, and some of them need to be first, like guidelines, which I think when they're not details, should be read before you read the rest. Although you do whatever you want. But like I'm expecting that by default people will read things from top to bottom. And you can, yeah, you can choose how things will be displayed, and I found that to be very powerful. And there's a cool thing that Elm format does as well with add docs. So whenever you add those add docs things, it changes the exposing clause in your module, the first line in your module declaration. So module, module name, exposing, and then plenty of things. So if you have add docs for those, it will reformat them in the same order. So if you have add docs ABC and then next line add docs DEF, then you will have two lines, ABC and then DEF, in the exposing clause. And I use that as well in my application code. So if I want to make a, let's say, button module, then I write the documentation so that the API is shown as a table of contents in a way at the very top of my file. So usually I have something like a section how to create, and I have the type of the button, so add docs button, and then also the init or the different variants for init. And then I have a section with all the with functions if I choose to do so, and then a section on how to transform that to HTML, something like that. And then you can see in the exposing clause, well, button, comma, init, next line, with something, with something, with something, and at the end to HTML. And you can even put those things onto more lines, so you have with large size, with small size, with medium size, and then on the next line with color red, with color blue. These are terrible examples, but the way that I try to do those is I write them so that every line deals with one thing. So if you want to deal with the size of the button, you have one line with all those. If you want to talk about the color, you have one line with all those, maybe also the color type or something. And I find that just to have this thing is already very valuable, so that's what I do in my application code, and that's why I push at work to have some documentation, even if it's just for that, because that makes things a lot simpler. Cool. When you say some documentation, are you mostly doing empty doc comments for internal things, or do you actually write something for these internal APIs? So if it's for application code, I usually don't write any documentation because it's not mandatory there. I try to have better names. Usually things are pretty self-explanatory, especially because at work we have this way of working, we have several patterns that we use over and over. So once you know it, you don't have to explain things again. So it does not make sense to explain button.withColor when you have so many other modules where you have withColor as well. It makes a lot more sense in package code, I think, because people might be new to the pattern, and you also don't need to have as much of a great documentation experience maybe at work, especially when you have colleagues that are right next to you, and because for application code, time is more precious than for open source maintainers. I think it would depend if there's that one part of the code base where new hires have to pair with the one person at the company who really actually knows how to use this thing in order to get up and running, then maybe that is a case where it's good to do that. I would say, because I am a big fan of self-documenting code, and I will admit I very rarely write documentation for application code, and I don't think that's a bad thing. I would say, to me, I'm not a fan of writing documentation when a good name would achieve the same thing. I think it's sort of like going down the chain. I think you should always prefer communicating something through good naming and good API design when possible, and also through a good, easy way to use something. A command line interface and automation rather than a cookbook. Here are five different steps, right? That might be calling out to automate it. So like, oh, I was a good boy and I wrote some documentation for this. It's like, well, maybe you weren't such a good boy. Maybe you should have automated that. It's also because function names, that's what you see when you read code, right? You can go to the documentation in your IDE, sometimes on GitHub or through searching for yourself in the package website. But it's much easier to see the function name, and if that conveys the meaning, then that's all you need. When I write bash code, or sorry, when I look for a command to do something and someone on StackOverflow says, oh, you should run this command, pipe this command, this slash pipe this command, and I'm like, I know none of these commands, or there are some of these flags that are new to me. Well, now I need to read the documentation. So hopefully it's going to be good, but like for bash commands, everything is in like one manual. It's one readme-ish document. So it's hard to find the information you want sometimes. And also, like, there's just a lot of things. So yeah, good names is always preferable. But if you can have both, go for both. Right. And also, I mean, this is sort of maybe so obvious that we wouldn't think to mention it here because we sort of talk about this all the time. But the API design is part of the documentation. Where you look to find a function, how you group together, and it's actually something I put a lot of thought into. It's actually quite difficult to get right. Do you have one big module with a bunch of things thrown in there? Do you have a lot of small modules that have things clearly separated? I think the way you organize things into Lmodules is really a part of how you're presenting these concepts to users. What should they think of together? But it's also an ergonomic thing. How many imports are they going to need? And also, it's a sign. If you have a lot of modules, is that a lot of concepts? If you have a lot of modules, but you end up having to import all of them every time, that might not be a great experience. So it's really a delicate process to slice things up into a meaningful way. But you're presenting these ways of grouping things, not just in terms of how you import them, but how you think of them, and also how you read them. Because Elm package documentation is organized by module, it really is like the pages in your documentation. And I think that's a brilliant part of it. And again, back to your sort of opening sentiment about the baseline for quality in Elm documentation. I think that's part of it, is things are grouped where a module is a page in your docs. And so you import one thing, you read the docs about that one thing you imported, and it's all grouped together logically. So that really shapes the way I write documentation. So for example, like in Elm Pages v3, back-end task is a big part of it. So I have a back-end task.env module, which is a pretty small module. It's got a couple of things for expecting to get an environment variable and errors that can come up when you do that. Or back-end task.file, that is a module that is, you know, knows how to read files that might have some front matter formatting in them, or it might not, read a raw file, read a JSON file, things like that. It's a pretty mechanical module, but it also sort of describes that this is something that Elm Pages allows you to do, read from files. But it also references back to the back-end task API, because this is the sort of core abstraction. And so this module has really, it breaks down the mental model. It breaks down a conceptual guide, and it links out to all these different ways you could use it. So this is the opportunity to present these sort of key concepts and the API for how to use this basic building block. And then that in turn links out to all these more specific ways to use them, like back-end task.custom is another huge piece, right? It's allowing you to run arbitrary code in a JavaScript environment that you can have access to and encode data to send to it, decode data to get back. It calls an async JavaScript function, right? That is, that's a big concept to chew off. If that was part of the back-end task module's documentation, it would be kind of overwhelming. It would be bombarding the user with information to understand when they might just be like, what is a back-end task? I'm new to Elm pages. But it's linked to, and there's a short set of bullet points at the top of back-end task. So it describes what is a back-end task in a concise one-sentence way, and then what are the ways you can use it? And you can click to those and choose your own adventure from there, or you can continue reading about back-end tasks. So I think the way you group these and organize them is really key. And again, it's like one module is one page in your documentation. So the title of that module, the things that are grouped there, the scope of it, how many concepts go there are all really important considerations. Yeah, and it's really hard for us to choose what goes into each. Like, should I split this thing into more modules? I know, for instance, like Elm UI has asked themselves the same question, like, oh, I have all these borders. Should that be their own modules or module? Or should it be in the same module as these other things? And sometimes it's clear-cut, sometimes it's pretty hard, or it's arbitrary. It actually requires some surprisingly nuanced technical tricks in the Elm code sometimes to support that, like a common one being avoiding circular imports. And so in Elm, the Elm compiler forbids things importing each other. Modules can't import something that imports them. And therefore, you often need to use this trick of sort of having something scoped where it's exposed to the package. What that means, we've talked about in previous episodes, you have an Elm.json file, which for an Elm package gives you a key of exposed modules. And that's where you list out the modules that will be part of your public API. But you can have some non-exposed modules, and those non-exposed modules allow you to have types and functions which are visible to your whole package, but not visible through the exposed package. But you can expose them through type aliases, which is why you'll sometimes see type alias element equals element. What does that mean? Well, it's a package private one. Yeah, it's a trick. And so that means you have a lot of possibilities for where you can expose something. Which module do you expose that type alias from? It could be a lot of different ones. But I think there is something really key. Evan has talked about this in, I think, his talk, Growing Elm Modules. Wait, no, sorry. Life of a File. Evan's talk, Life of a File, he talks about how there's something to how you grow and expand an Elm module that is centered around a type. And I think that's really true. It should be usually one central type and some key things on how to use that thing. I mean, something like a data structure would be a queue structure or a stack or something like that would be an obvious example of that. But also back-end tasks. But back-end tasks, again, it's subtle because there are other ways to consume a back-end task, like back-end-tasks.custom. So that's a module associated with that same back-end-task type, but it's some helpers that actually aren't built around a specific type. So it's not always clear-cut. While we're on the topic of things that are too basic to mention, but let's mention them anyway, one reason why Elm docs are great is because they're simple, or because Elm code is simple. Like, I'm not going to praise it even more than I usually do, but do I? But the thing is, whenever you have simple code, like a function that adds to numbers, well, you have the function, you have a code sample, so if you say add 5, 7, you can show that it does 12, returns 12. And that's it. There are no side effects, there are no mutations. This is all that your function does. So it's really easy to understand, whereas in languages like JavaScript, if you look for the documentation for arrays, the list-like type, not the erasing something, so if you do.sort on an array, it's going to mutate it. And that's something that can be hard to convey without mentioning it explicitly, and that can be surprising as well. But you don't have those things in Elm, so things are pretty simple. And also, every function shows the type annotation, and that's very valuable as well, because a type annotation gives a lot of information, and if you don't have it, which is, again, the case in JavaScript, often less so with TypeScript nowadays, well, yeah, you have a lot more information that you can use to understand what it does. So Elm is simple, and that has great benefits, basically. Yeah, like if you're working with a different language, JavaScript, Ruby, it's very common, like, is this nullable? Which, of course, TypeScript somewhat helps with, but only somewhat. How many arguments does this take? If I pass in zero arguments, one argument, two arguments, are there different variadic forms of this, different arities for this function? Is it going to return different types based on the input I give it? Is it going to mutate the input I give it or change some global thing or perform some side effect? Is it going to do one thing if I pass in an object, and another thing if I pass in a string, and another thing if I pass in a buffer, and another thing if I pass in a promise? Does it return a promise or a non-promise? Is there going to be any effect if I just import this file? Right. Can it throw an exception? Yeah, what are the possible crashes that this can have? Right. All of these things, they are just non-existent in Elm, so I couldn't agree more. The explicitness already, your confidence in navigating an API is so much higher from just the bare minimum documentation in an Elm package. Also, I mentioned, if you have a code example, like add 5, 7, and you add a line underneath that says, this returns 7, there's a... often what you will see is dash, dash, greater than. So it basically does an arrow, and then 7. And there's a tool, which is called Elm Verify Examples, that will turn those code examples into actual tests. So you can be sure that your code sample is correct, that it returns what you said it did. So that's pretty powerful as well. I really wish I could use this for Elm review in some way. I know. I wish that it could verify that things compile, but unfortunately it doesn't at the moment. But it is a very valuable tool. Also, on the topic of code snippets, I think that's also huge. Just having code snippets, example, output, like when you're navigating functions in an API, again, you want to equip the user with what is the relevant information they're going to need. And really, even if it seems obvious from the type signature, having an example is very useful. It demystifies it, and it makes it feel real. And it's also an opportunity to give an example use case. So I think, in my opinion, I feel very strongly that every example is an opportunity to demonstrate a meaningful use case, which is why I try really hard to avoid toy examples, foobar baz, and instead try to illustrate, why would I use this feature with real-world use cases? Because now you're using that opportunity to convey information in a richer way. People are taking the same amount of time to read through something, but you've now conveyed the kinds of things this tool would be helpful for and best practices for using it. Yeah, this is something that I do purposefully in Elm Reviews documentation, is for every function that you can use to define a visitor or something, I add an example rule. So that's a lot of code, potentially, but you can see, oh, I can use this for this, and also this is how you use it. But if you just go through the documentation, you can already just copy-paste some rules and adapt them to your needs, potentially. I find that to be pretty interesting. Yeah, as an Elm Review user, I find that extremely valuable. Also, just imagine looking at with simple declaration visitor, and you're seeing, okay, it takes a function, no declaration, returns, list of error, and a module rule schema, and it returns a module rule schema which has at least one visitor. That's okay. Yes, that's telling me some information that's useful, but without an example... Really hard to use, yeah. Yeah, like, okay, well, what do I do with node declaration? Well, actually, what you're most probably going to do with a node declaration is you're going to do case node.value node of, and then you're going to enumerate the different declaration types which are imported from this module. Also, I'm a big fan of being explicit about the imports because you want to make it clear. And actually, Elm Verify examples does not require you to qualify the module you're using, but I prefer to be explicit about using unqualified module or qualified module references, so putting the module name before explicitly and putting the import to the module itself, even the one I'm documenting. It just makes it more copy-pastable and more explicit. Exactly, yeah. And also, like, when you don't qualify something in your example, it can be hard to know whether the function that you're referencing is defined in this file, which in some cases it will be, or if it's a value that is somewhere else in the code snippet or that is just omitted because it's too complex to do for the example or too annoying to do. But if you qualify it, then it's a lot more explicit, and as you say, copy-pastable, understandable. And we usually in the Elm community advise for qualified imports anyway, so let's use that in the examples anyway. That's my take at least, and I know you agree with this. Yes, and also it should be as idiomatic as possible in every way. Now, of course, people do have different styles, and there's nothing wrong with that. Some people really like using unqualified imports in certain cases, and that's totally fine, but I think that it's important to try to write in an idiomatic format. Like, for example, if you're going to use an import alias, use that everywhere and use it consistently in your examples because the thing is, everybody who uses your package will probably use that same example that you use because you're sort of defining a convention, whether or not you realize it, and so you should put some thought into how you want to import things, not just like, well, for the case of this example, I'm going to use a one-letter import or something like that. People take it and run with it. Also, so naming things is important. I am personally a fan of giving meaningful names to type variables. Now, in the case of, you know, dict comparable a, that might be fine. I don't know. What do you think about that? I think that if it's for something generic, like purposefully generic and extremely generic, then a is just fine. If it's for functions like map, where you have a something a that transforms it to something b, that's very fine as well because people understand it. If it's for anything else where you have more insights about the type variable, what it will hold, what it does represent, then I would use that instead when possible. Right. Yeah, like in the Elm Review docs, I see you, for example... You use schema state, I think. Schema state, module context. So that is... and you use the naming consistently. So at least that gives people a sense of what name to use. I'm trying to remember in ElmGraphQL, I made a change as well at some point where I was not using a type variable. I didn't have a good name for this type variable, and it actually made it a lot harder for people to understand the context. What did I name it? The scope. Okay, so yeah, in ElmGraphQL, a selection set decodes to a value, and it has a scope. The scope is a phantom type. This is a confusing concept to introduce to people, right? Some people might not have used a phantom type. Some people might have used a phantom type, but might not understand how that applies to the concept of GraphQL. So a selection set, you know, we've discussed in the past, it is scoped so that you can't, you know, if you are able to take a selection set that represents getting the first name in the scope of a user, you can't get the first name in the scope of a product. So the scope phantom type variable defines the scope of your selection. So I tried to use domain language there, and I think that's really key. Yeah, the type variable is usually something a little bit more abstract. So especially if it's used to represent some constraints, then it's worth giving it a good name, like even if it's just constraints, I don't know, I use something somewhere maybe. Yeah, and naming is also a process. You can always iterate to get a better name. You don't have to get everything around the first try. I think it's really important to notice where do you find friction as you're reading things? Where are you finding that you're conflicted about what names to use? You don't have a clear concept in your head of what term to use for something. Where are people getting confused? Where are you finding it difficult explaining a concept to other people? I think it's important to deliberately invest time in giving names to these abstractions and ideas and iterating on names there. So those are things to look for. Also getting feedback from users is key, of course. You mentioned at the beginning that whenever you thought about binding documentation, you were thinking about Varisblock. Yeah. So as you say, writing documentation is sometimes not the most fun part and it can be very hard. Also, how much should I detail? What should I detail? It's hard sometimes. But in some cases, things are just super complex to explain. I remember when preparing for Arm Review V2, I had an API to merge module context into a project context or something. The most complex part of Arm Review's API is how you mingle project context and module context. And I found that to be very hard to explain. It took me plenty of paragraphs. And I was like, this is still not amazing. And at some point, I figured out a different API for it, and it was much easier to explain. So sometimes the solution to when you have trouble explaining something is to change the API. Like you're explaining something that is too complex and you should try to find a simpler way. So that was the pain points that I had once. And the solution was do something different. And then as soon as you see, oh, now it's much easier to explain, well, that's a pretty good sign that it's a good API, probably. Exactly. Which for the same reason, that's why if you find yourself writing documentation, it can be a crutch because maybe you should have been documenting something. Maybe a hard to explain concept, maybe lots of documentation is a crutch for making the concept easier to understand, making the API simpler. So it should always be documentation should support something that's intuitive on its own, ideally. And you're going to have the best time when you're always considering changing something to make it simpler, not just documenting what you already have. And when you count, then documentation makes sense. Like if something is done a specific way for performance or because there's a bug in some package, some other package, or the web browser doesn't work as you would expect, then yeah, add the documentation comment that says, this is the reason why something is this way. Right, right. Yeah, I always love the scene in the show Silicon Valley when they're getting user feedback on the product and then the CEO is watching through this blind mirror thing and watches the users in frustration improperly using the product and he goes in and corrects them and tells them how they're all using it wrong. But of course, feedback is only as good as your willingness to listen to it. So I think you, not that you should necessarily do directly what everybody tells you you should do. That's not the right answer either. By the way, you should not listen to this episode. We only have garbage information. So see ya. Right, exactly. Yeah, but I mean, when you're getting feedback, it's telling you something. And that's the fine line there is like understanding that people are telling you pain points and hearing that they have a pain point. If some people are trying to write documentation, I also have a few Elm Review rules that can be helpful for that. So there's a package called jfmangles.com slash elmreview documentation, which has four rules, some more applicable to others than others. So there's one that is called docs.no missing, which we mentioned before, which reports missing or empty documentation. So these rules can be used for application, but they can also be used for packages. And in this case, like for packages, it will report when it's missing, just like the Elm Compiler would, but it also reports empty documentation, which I think is something we should try to avoid as much as possible. I think you disagree with it sometimes. I personally disagree with it for map two, map three, map four, map five. So my reasoning is that I see this quite often that people document map, they document map two because it's more complex, and then they don't document map three. So the documentation is empty and same for map five, et cetera. And the thing is like your documentation can be found in the package documentation, but it can also be found in the ID. And if you hover map two, you get a helpful documentation comment. But if you hover map three, then you have nothing. And that's not very helpful in my opinion. So I would much rather have map three say refer to the documentation of map two. Okay, nice. Because now you can just, you know where to look at. Potentially you can even click on it. So that's why it does not, no missing reports, empty documentation. Oh, cool. Maybe I could even make an Elm review rule to automatically do that for my map and functions. Potentially, yeah, that'd be fine. There's also a docs.review add docs rule, which is a bit of a weird name. Yeah, but I use it and it's saved me in some situations. So thank you for that. So we mentioned the add docs annotations, and there are quite a few ways where you can use them where the package documentation will not handle them correctly. Like that the compiler will usually tell you, hey, you're missing add docs or you're having add docs that are not expected. But this rule will also report those for when you use it in applications because the Elm compiler will not help you there. But there's also cases where, for instance, if you indent add docs or if you put it in at the very first line of your module documentation, then your docs will not look as expected. So if your entire module documentation is the curly braces, whatever, add docs something, then that is literally what you will see, add docs something. That's your entire documentation. And I've seen this over and over again, so I've made an Elm review rule that reports about those. And there's a few other gotchas that are similar to that. Well, so like one of the ones that has saved me many times, I actually wish that the IDE could do this for me automatically, but when I rename a module, I sometimes, most times, honestly, miss that in renaming my links within my docs. And that Elm review rule catches it for me. If it's pointing to a module which no longer exists, it catches that. No, it doesn't. That's the third rule. Okay, yes. You're making a nice segue, at least. So that's docs.reviewlinksinsections. So that one is also very interesting. As you say, you link from one module to another, from the README to another module. And yeah, if you rename something, then things are broken. Or if you make a typo, then things are broken, and you don't want your users to let you know about that. So this rule lets you know about it. It also reports the ambiguous links. So if you have a markdown section, so hashtag, hashtag, init, and you have a function called init, then they will have the same href? Yeah. Name. I think it's like the name under the hood. The same anchor? Name, attribute. Yeah. So whenever you will link to that, it will go to the first one. And you ideally want them to be different, like not ambiguous. So this will also report that. I think that's the one that reports it. But yeah, something reports it. And then there's another one that is docs.uptodate.readmelinks, where the README is a bit of a peculiar file, because you can see it on GitHub, and you can see it on the package website. And depending on how you do the links, they will be up-to-date or not up-to-date. Usually what people do is they link to the package website from the README, and they use slash latest to specify the version, which works, but not once you release a new version. Now your previous version of your package, the README will link to a function on the latest version, and that function might not exist anymore. So that's a problem. So this helps replace those latest by the current version of your version defined in your Elm.json. And whenever you upgrade your version, it will auto-fix those. So that's one reason that I have a very good time bumping the packages and keeping these links up-to-date is I bump the version, I run this rule, and all my links are correct again. And that's just very nice. It's definitely an example of something that is the correct thing to do, but in practice, without automation, something that people just would not do. It wouldn't be tenable. So it's great. Yeah, and I remember that before I made this rule, it was like, well, what should we do? And there was no clear cut answer. So those are the four rules that are there. If you can think of another one, let me know. I definitely think there are more things to be done. Yeah, and I mean, also somewhat relevant would be the forbidden keywords, is it? For checking for things like to-dos. To-do or string, is that what it is? To-do? No, that's different. Yeah, there's a package called sparksp.elmerview forbidden words where you can tell it, please report all usages of to-do or replace me. And this is whenever you make an ElmerView package, you have this rule with replace me already in there. So whenever you try to write replace me as a placeholder for some documentation, for instance, this rule will at some point let you know, hey, you should replace this. So that's very useful as well. Yeah, I also have a GitHub template called the ElmPackageStarter, and this uses most of these ElmReview rules, and I've found it pretty nice for bootstrapping a quick Elm package. And it also links to a project of mine which we've talked about in the past, the Idiomatic Elm Package Guide, which sort of lays out, I think, a set of principles for how to organize your readme and what format to manage a changelog and some boring but important things. I think these are really important. Having a changelog, if you create a new version of a package, people are going to be wondering what changed. And having an obvious format that is something you would expect across packages. Same with an examples folder. People in the Elm community, if they've kind of been around for a little while and seen some packages, they're probably going to expect the GitHub project to have an examples folder. They're probably going to expect to have a link to the package from the GitHub readme. They're probably going to expect to have a test suite with a badge that shows whether the test suite is passing. Some boring things like this that I think are worth having. Yeah. By the way, the fact that you have the changelog and sometimes the contributing instructions in the readme, that's something I see sometimes and I don't think that's the place for the readme. Especially because there are some standards where you have a file called changelog, all caps, or usually all caps,.md, and one called contributing, and there's also license and all those, plenty of other files like that. Yes, and those are meaningful to GitHub and to Elm, to the Elm compiler too. So, the license file, for example, is required by Elm. Yeah, I wouldn't like it if the changelog was maybe also special, at least was linked to in the package documentation. Absolutely, yeah. And if you could, man, wouldn't that be cool if you could kind of show the Elm diff, if you could have some syntax for the changelog where you could say the breaking changes, because Elm diff, when you do an Elm bump, it knows the breaking changes, and if you could document how it changed or why it changed, that would be really cool. Yeah, just being able to see the diff on the website, I guess, on the package website between two versions, that would be nice as well. Because often I see that a new package has been released on Slack and I watch it, I open it on my phone, and I'm like, oh, well, what has changed since the last version? Well, let me open up my laptop and run Elm diff in a terminal. Yeah, that is very useful, but it's not always a great experience. I'm not always on a computer. So another thing that is not always clear cut is like, what belongs in the package docs and what belongs in some external place, either the readme, a separate document in GitHub, or an external site? Yeah. Do you ever find reason for having something that's not included in the readme or the Elm package docs? Yeah. So Elm review, for instance, has... I say for instance, but all Elm packages are Elm review related. Maybe one day I will have something else, but for now, they're all Elm review related. Wow. After so many years of work, still only Elm review. Well, it's focus. Yeah, I guess. Well, and packages that I'm not maintaining. So there is a document, for instance, for how to integrate Elm review into other places like IDs or bots or something. So there's a documentation that describes how the CLI outputs some format that can be understood by computers. And that is not relevant to the API. So the Elm review package, the Elm package is meant to be used by people who write rules or who configure their Elm review configuration. Everything else makes little sense. There's still like all the how to get started, how to configure, how to install Elm review, which is like an additional section because there's some NPM involved. But yeah, I think there are some cases where you will need other things. The main one that I can think of, and that does not necessarily fit the Elm package website very well, is a guide. And that's something you hear sometimes as well on the Elm Slack, is that people see the Elm guide and then they wonder, oh, well, how do I learn more or how do I know which functions exist? And we kind of assume that they went to the package website and look at Elm core or they looked at other packages and then know how to read that package website, which is a given once you've got some experience with it. But like sometimes you want to know about the About tab or About page on a package and that has some relevant information. But if you haven't browsed around, then you don't know about it. So yeah, having like the Elm package websites with all the API plus a way to write a guide, that would be pretty nice. So for instance, for Elm review, there's a lot of things that I try to teach that are not necessarily related to the API. And that's why my documentation is really long. Can you think of an example? Like would it be conceptually how an Elm review, how it traverses things with visitors or something like that? Potentially, yeah, that's an implementation detail that would be worth explaining somewhere. So for instance, if you want to explain like performance considerations, like you should use this function this way and not this way, or you should have this architecture, then if that doesn't fit specifically with one function, then or in one module, then it's a bit hard to know where to place it. Also, just like guidelines on how to make great rules is at the beginning of the review the rule module, which is the main one. But like it could be its own page, right? And also, for instance, like if you have a guide, then you can actually do a tutorial, which I kind of try to do. And this is kind of why I say like, write your own story, because I'm in a way making a tutorial, but maybe the way that the docs have rendered, it doesn't always make for the greatest experience. But if I did not have to write all the API in the same page, then I would write it differently. And I would probably. Yeah, I like the way you're framing that. I mean, I think like the example of performance tuning, a review rule or something like that is, in that case, it gets to the point you were making earlier about who's the audience. And, you know, the audience for very low level details of some JSON format of something is different than the audience of how do I write a review rule? Maybe I want to make sure I'm using this internal API in our application in a particular way. Well, I don't really care about performance, these performance considerations or this low level JSON format right now. So it's a different audience. And you don't want to lump all those together. It's going to be very confusing. I think maybe if the package websites just picked up on like all the markdown files in a documentation folder or something like that, or something that is explicitly defined in the Elm JSON file, that could work very well. Yeah, George Borges has talked about this idea with, you know, Elmbook and his inspiration from the Elixir documentation, where they have both API documentation and sort of guides or markdown pages side by side. So, yeah, I think you're right that there are certainly cases. I mean, like you mentioned this example of, you know, Elm browser and then the Elm architecture in the Elm guide, right? Like a user might go to the Elm browser docs or some core package and expect a guide, but actually that lives somewhere else. But that does make sense. Like it would be too much for the scope of it to introduce the Elm programming language and the Elm architecture all in the inline module docs. And it doesn't give you enough granularity. So in that case, having these conceptual overviews doesn't fit there. Also tutorials like you might have a mini tutorial, but you don't want to have a very ambitious tutorial that requires a lot of setup and a lot of steps and a lot of do it yourself exercises inline in your module docs. It's just they should be very narrowly scoped. So something like that definitely belongs in an external tool, which some package authors have external sites. Elm pages has an external doc site. And, you know, it covers things like just a conceptual overview of Elm pages because the scope of it is very large and it wouldn't fit neatly in one module documentation page or things that happen around generated code. What module do you put that in? It's describing a set of generated modules. So there's like a file structure document that talks about navigating the file structure of an Elm pages application and what sort of modules are generated from that. You know, certain things about the philosophy and the architecture and diagrams for the architecture, the adapter API, which allows you to adapt to different deployment and hosting platforms. So, yeah, so there's definitely I mean, my rule of thumb is if something fits neatly in a modules docs, put it there. For example, back end task, I could put it in a separate, you know, it almost wants to be part of the Elm pages docs for Elm-pages.com slash docs. Like I almost want it in the listing there, but it can fit in a module doc. So I put it there instead. There's also like you can have a website, like a custom website where it says blazingly fast, you know, the obvious catchphrase, where you can just make it look good. Just marketing wise, the package's website is not super handsome. Like it's a good looking website. It's a very simple website, but you're not putting like marketing wise, the JavaScript people will tell you, hey, this is shit. Like my Vite package looks the same as the Parcel package. How can I make it obvious that this one is better without being able to choose my colors for my package documentation page? So I think there's also a case where you want to have a dedicated website. I'm not sure how much overlap there is. And when you want to have a additional, when you want to have a website and package documentation and a guide, and how you mix and match them together. So I'm kind of used to have on the package websites. And therefore, if new opportunities open up to me, like having the ability to write a guide, I'm not sure how I will write the documentation yet. There are definitely certain things that fit better in a custom site. Like you said, I mean, having more control over the styling, but also if you want to have a showcase or certain community things like in the Elm Pages site, I have something that lets you submit. There's a button to submit to the showcase. It uses Airtable and it pulls data from that API live or, you know, a blog. Should you have a blog hosted on the Elm Package site? Probably not. Yeah. You also maybe want to have like release notes that are displayed nicely, news, blogs. And yeah, as you say, like things that are not relevant to the API, but that are relevant to the package, like how many people use this, who is sponsoring this package or yeah, things like that. Right. Yeah. Yeah. And in general, there are all these different rich formats. I think they all serve their needs. Having a custom blog serves its need. Having Elm Package Docs does its job extremely well. And having them both is really useful. Things like GitHub discussions, GitHub issues, poll requests, conference talks, podcast episodes. All these things are great sources of information in different formats that serve different purposes. A GitHub discussion is a great place to showcase ideas and community projects and get feedback on things and discuss specing things out or making decisions or documenting history about something. Package Docs are not a good place for that. But if there's some quirky thing that people are frequently asking about, go ahead and link to that GitHub discussion thread that talks about the history and the spec and why that decision was made. So I think this model of linking out to a lot of different resources, keeping things very concise and focused on one purpose. But then if you're on this page and you're looking for something more, let me throw some links your way just in case. That's hugely valuable. I don't think you can understate the power of just... And even just linking to in between different module pages in an Elm Package is huge, I think. Another great thing is that whenever you have a function, it has a type annotation and the type annotation has references, different types. And whenever you have a type that is defined in your package, that becomes a link. So you can click on it and now you can see where that was defined. And that is very valuable. So if you can add more links for things that are not done that way, that's very valuable. I agree. Yeah. Also, on a related note, I think we all have the curse of knowledge, especially as authors of packages, where we have trouble understanding what it would be like navigating something because we know those things. So it's hard to revert back to a state of not knowing those things and understand, not to mention different things will be confusing for different users, coming from different avenues and different ways of thinking about things. But I think it's a really good practice to get in the habit of understanding what assumptions you're making. And there are certain habits that I've tried to build personally, where I'll try to notice when I'm making assumptions. So like one easy one is an acronym. If you're mentioning an acronym, just spell it out. Just say what the acronym stands for. You can use the acronym, but introduce at least what it stands for first. Yeah. And you can even like if it's a concept like the CAP theorem, then you can link to a Wikipedia page or something that talks about that. Or a blog post that has more information and simplifies, vulgarizes the concept. Because sometimes Wikipedia is not very, very nice, especially for mathematical things. Link to the Monad page. Right, right. Yeah, but exactly. Any terms like that, that might require some specific domain knowledge, just go ahead and link to it. You know, if you're talking about a type from a package, link to that external Elm package or NPM package or whatever it might be. I also find that sometimes, like when I'm writing out docs, I will say, if I'm using the word it or that or this, sometimes I'm like, wait a minute, are they going to know what I'm referring to? Because I just covered a lot of things and sometimes instead of it, I'll say, you know, the backend task type. And so now it's like, OK, backend tasks allow you to do that. It gives you, you know, I'll just say backend task also, you know, because it's very subtle. But I think that people can get tripped up on small details like this. So be very explicit, show all of your imports, show your work, link to things, define your terms, just like go overboard with those things. Yeah. Also, if you re-mention the backend task, you can make it a link. So people don't have to go back to the very top of the page to find the link to backend task. So that's also quite nice. And also like try to avoid words like just or simple or like they make sense in some cases. But you have to be careful about those. Like what seems simple to you or easy to you is not necessarily the case for other people. Although simple is objective, but you need to have watched Rich Hickey's talk about that. Right. Yeah. I think also being straightforward and, you know, not saying like necessarily this is the best way to do this, but saying these are the decisions. I think it's really good to be clear and explicit. These are decisions. I believe these are pros of these, this set of decisions. Perhaps here are some cons about this set of decisions, but these are the decisions. This is the philosophy. I think we talked about this in our Elm Radio episode of how and when to write an Elm package. But, you know, I think it's really valuable to just be up front with people and tell them because you can't you can't do everything. You can't make every you know, I'll make every single trade off out that no, like a trade off. You have to trade something. Which one do you want to choose? So just don't mince words. Go make some bold decisions because and allow for different approaches to coexist that make different versions of those trade offs. And so you don't have to take that responsibility of solving every problem. Yeah. Or try to find a novel way that solves everything in a nice way, which is usually what we end up doing in the Elm world somehow. Often with success and I guess the success, the failures are not published or. It's true. It's true. There's a bias there. Definitely. Yeah, it depends on the example. I guess like Elm Review does a great job sort of making the best of both worlds. Whereas something like Elm GraphQL inherently there's a decision. Do you have a query builder style or a generator style that spits out code for a specific GraphQL query? Those are trade offs that there's you just have to pick one and say, we think there are merits to this approach, but we can't make a perfect solution that makes everybody happy because there are trade offs. Well, anything else we should point people to for writing great docs? I think we've already given a lot of great tools and links, so you can see those in the show notes. Try to do your best. Try to make it to make it understandable by people. Ask for feedback and iterate like you're not going to get things right the first time you're going to have typos. You can have things that are not clear and that's fine. Just one thing. Try to avoid breaking changes as much as possible, but it's not a big deal either. Yeah, and listen to your users. I skimmed a little bit through a book that I had heard about called Docs for Developers, and I quite liked what I read. It was in a nice skimmable format, and they even talked about the importance of being skimmable, which is near and dear to my heart as a reader of some portion of documentation. I would definitely recommend checking that out. Yeah, but you don't know why it's important for things to be skimmable because you've skimmed that, right? That's right. Okay, yeah, sure. Just want to be clear about that. All right. All right. Well, Jeroen, until next time. \u266a\u266a\u266a", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.4, "text": " Hello Jeroen.", "tokens": [2425, 508, 2032, 268, 13], "temperature": 0.0, "avg_logprob": -0.3583620956965855, "compression_ratio": 1.472972972972973, "no_speech_prob": 0.08126571029424667}, {"id": 1, "seek": 0, "start": 2.4, "end": 4.4, "text": " Hey, what's up Doc?", "tokens": [1911, 11, 437, 311, 493, 16024, 30], "temperature": 0.0, "avg_logprob": -0.3583620956965855, "compression_ratio": 1.472972972972973, "no_speech_prob": 0.08126571029424667}, {"id": 2, "seek": 0, "start": 4.4, "end": 10.4, "text": " Oh, you're trying to beat me at my own game, are we?", "tokens": [876, 11, 291, 434, 1382, 281, 4224, 385, 412, 452, 1065, 1216, 11, 366, 321, 30], "temperature": 0.0, "avg_logprob": -0.3583620956965855, "compression_ratio": 1.472972972972973, "no_speech_prob": 0.08126571029424667}, {"id": 3, "seek": 0, "start": 10.4, "end": 13.4, "text": " Yes, I found a pun.", "tokens": [1079, 11, 286, 1352, 257, 4468, 13], "temperature": 0.0, "avg_logprob": -0.3583620956965855, "compression_ratio": 1.472972972972973, "no_speech_prob": 0.08126571029424667}, {"id": 4, "seek": 0, "start": 13.4, "end": 15.4, "text": " And I'm going with it.", "tokens": [400, 286, 478, 516, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.3583620956965855, "compression_ratio": 1.472972972972973, "no_speech_prob": 0.08126571029424667}, {"id": 5, "seek": 0, "start": 15.4, "end": 20.400000000000002, "text": " Even if I have to destroy the holy intro that we have.", "tokens": [2754, 498, 286, 362, 281, 5293, 264, 10622, 12897, 300, 321, 362, 13], "temperature": 0.0, "avg_logprob": -0.3583620956965855, "compression_ratio": 1.472972972972973, "no_speech_prob": 0.08126571029424667}, {"id": 6, "seek": 0, "start": 20.400000000000002, "end": 23.400000000000002, "text": " Wow, breaking with the format.", "tokens": [3153, 11, 7697, 365, 264, 7877, 13], "temperature": 0.0, "avg_logprob": -0.3583620956965855, "compression_ratio": 1.472972972972973, "no_speech_prob": 0.08126571029424667}, {"id": 7, "seek": 0, "start": 23.400000000000002, "end": 26.400000000000002, "text": " Well, I will admit, I was trying to think of a good one,", "tokens": [1042, 11, 286, 486, 9796, 11, 286, 390, 1382, 281, 519, 295, 257, 665, 472, 11], "temperature": 0.0, "avg_logprob": -0.3583620956965855, "compression_ratio": 1.472972972972973, "no_speech_prob": 0.08126571029424667}, {"id": 8, "seek": 0, "start": 26.400000000000002, "end": 29.400000000000002, "text": " but I was having a little bit of writer's block, so...", "tokens": [457, 286, 390, 1419, 257, 707, 857, 295, 9936, 311, 3461, 11, 370, 485], "temperature": 0.0, "avg_logprob": -0.3583620956965855, "compression_ratio": 1.472972972972973, "no_speech_prob": 0.08126571029424667}, {"id": 9, "seek": 2940, "start": 29.4, "end": 34.4, "text": " I'm gonna say it's funny, but I don't think I get it.", "tokens": [286, 478, 799, 584, 309, 311, 4074, 11, 457, 286, 500, 380, 519, 286, 483, 309, 13], "temperature": 0.0, "avg_logprob": -0.19571021507526265, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0005783124943263829}, {"id": 10, "seek": 2940, "start": 34.4, "end": 38.4, "text": " But it's funny, Dillon. It's very funny. Please continue doing that.", "tokens": [583, 309, 311, 4074, 11, 28160, 13, 467, 311, 588, 4074, 13, 2555, 2354, 884, 300, 13], "temperature": 0.0, "avg_logprob": -0.19571021507526265, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0005783124943263829}, {"id": 11, "seek": 2940, "start": 38.4, "end": 41.4, "text": " Maybe it's just me. When I think of documentation,", "tokens": [2704, 309, 311, 445, 385, 13, 1133, 286, 519, 295, 14333, 11], "temperature": 0.0, "avg_logprob": -0.19571021507526265, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0005783124943263829}, {"id": 12, "seek": 2940, "start": 41.4, "end": 44.4, "text": " the first thing that comes to mind is writer's block,", "tokens": [264, 700, 551, 300, 1487, 281, 1575, 307, 9936, 311, 3461, 11], "temperature": 0.0, "avg_logprob": -0.19571021507526265, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0005783124943263829}, {"id": 13, "seek": 2940, "start": 44.4, "end": 47.4, "text": " because I am sitting there staring at a blank page,", "tokens": [570, 286, 669, 3798, 456, 18043, 412, 257, 8247, 3028, 11], "temperature": 0.0, "avg_logprob": -0.19571021507526265, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0005783124943263829}, {"id": 14, "seek": 2940, "start": 47.4, "end": 49.4, "text": " and it is very painful.", "tokens": [293, 309, 307, 588, 11697, 13], "temperature": 0.0, "avg_logprob": -0.19571021507526265, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0005783124943263829}, {"id": 15, "seek": 2940, "start": 49.4, "end": 55.4, "text": " But, Jeroen, as always, we endure that pain for our dear users.", "tokens": [583, 11, 508, 2032, 268, 11, 382, 1009, 11, 321, 24732, 300, 1822, 337, 527, 6875, 5022, 13], "temperature": 0.0, "avg_logprob": -0.19571021507526265, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0005783124943263829}, {"id": 16, "seek": 2940, "start": 55.4, "end": 58.4, "text": " Definitely true, yeah.", "tokens": [12151, 2074, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.19571021507526265, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0005783124943263829}, {"id": 17, "seek": 5840, "start": 58.4, "end": 61.4, "text": " We will suffer through writing JavaScript,", "tokens": [492, 486, 9753, 807, 3579, 15778, 11], "temperature": 0.0, "avg_logprob": -0.1900847720116684, "compression_ratio": 1.5829383886255923, "no_speech_prob": 9.429515921510756e-05}, {"id": 18, "seek": 5840, "start": 61.4, "end": 64.4, "text": " we will suffer through writing English words,", "tokens": [321, 486, 9753, 807, 3579, 3669, 2283, 11], "temperature": 0.0, "avg_logprob": -0.1900847720116684, "compression_ratio": 1.5829383886255923, "no_speech_prob": 9.429515921510756e-05}, {"id": 19, "seek": 5840, "start": 64.4, "end": 66.4, "text": " all in the name of our users.", "tokens": [439, 294, 264, 1315, 295, 527, 5022, 13], "temperature": 0.0, "avg_logprob": -0.1900847720116684, "compression_ratio": 1.5829383886255923, "no_speech_prob": 9.429515921510756e-05}, {"id": 20, "seek": 5840, "start": 66.4, "end": 71.4, "text": " And it's a very noble view of, I guess, all of us then?", "tokens": [400, 309, 311, 257, 588, 20171, 1910, 295, 11, 286, 2041, 11, 439, 295, 505, 550, 30], "temperature": 0.0, "avg_logprob": -0.1900847720116684, "compression_ratio": 1.5829383886255923, "no_speech_prob": 9.429515921510756e-05}, {"id": 21, "seek": 5840, "start": 71.4, "end": 75.4, "text": " I was not trying to praise myself, but I guess I am.", "tokens": [286, 390, 406, 1382, 281, 13286, 2059, 11, 457, 286, 2041, 286, 669, 13], "temperature": 0.0, "avg_logprob": -0.1900847720116684, "compression_ratio": 1.5829383886255923, "no_speech_prob": 9.429515921510756e-05}, {"id": 22, "seek": 5840, "start": 75.4, "end": 80.4, "text": " I don't know about you, but I do find it way more difficult", "tokens": [286, 500, 380, 458, 466, 291, 11, 457, 286, 360, 915, 309, 636, 544, 2252], "temperature": 0.0, "avg_logprob": -0.1900847720116684, "compression_ratio": 1.5829383886255923, "no_speech_prob": 9.429515921510756e-05}, {"id": 23, "seek": 5840, "start": 80.4, "end": 83.4, "text": " than writing the code.", "tokens": [813, 3579, 264, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1900847720116684, "compression_ratio": 1.5829383886255923, "no_speech_prob": 9.429515921510756e-05}, {"id": 24, "seek": 5840, "start": 83.4, "end": 85.4, "text": " Yeah, definitely agree.", "tokens": [865, 11, 2138, 3986, 13], "temperature": 0.0, "avg_logprob": -0.1900847720116684, "compression_ratio": 1.5829383886255923, "no_speech_prob": 9.429515921510756e-05}, {"id": 25, "seek": 8540, "start": 85.4, "end": 88.4, "text": " So maybe before we delve into that, what is our topic today?", "tokens": [407, 1310, 949, 321, 43098, 666, 300, 11, 437, 307, 527, 4829, 965, 30], "temperature": 0.0, "avg_logprob": -0.20217117510343852, "compression_ratio": 1.604, "no_speech_prob": 0.00015989603707566857}, {"id": 26, "seek": 8540, "start": 88.4, "end": 93.4, "text": " What is our topic? I'm gonna say it is writing great docs.", "tokens": [708, 307, 527, 4829, 30, 286, 478, 799, 584, 309, 307, 3579, 869, 45623, 13], "temperature": 0.0, "avg_logprob": -0.20217117510343852, "compression_ratio": 1.604, "no_speech_prob": 0.00015989603707566857}, {"id": 27, "seek": 8540, "start": 93.4, "end": 98.4, "text": " Not just good docs, because, as Evan says in the Elm Philosophy tweet,", "tokens": [1726, 445, 665, 45623, 11, 570, 11, 382, 22613, 1619, 294, 264, 2699, 76, 43655, 15258, 11], "temperature": 0.0, "avg_logprob": -0.20217117510343852, "compression_ratio": 1.604, "no_speech_prob": 0.00015989603707566857}, {"id": 28, "seek": 8540, "start": 98.4, "end": 101.4, "text": " it's not done until the docs are great.", "tokens": [309, 311, 406, 1096, 1826, 264, 45623, 366, 869, 13], "temperature": 0.0, "avg_logprob": -0.20217117510343852, "compression_ratio": 1.604, "no_speech_prob": 0.00015989603707566857}, {"id": 29, "seek": 8540, "start": 101.4, "end": 105.4, "text": " And I do love that as a sort of foundational principle in Elm.", "tokens": [400, 286, 360, 959, 300, 382, 257, 1333, 295, 32195, 8665, 294, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.20217117510343852, "compression_ratio": 1.604, "no_speech_prob": 0.00015989603707566857}, {"id": 30, "seek": 8540, "start": 105.4, "end": 109.4, "text": " And, you know, I mean, when you write an Elm package,", "tokens": [400, 11, 291, 458, 11, 286, 914, 11, 562, 291, 2464, 364, 2699, 76, 7372, 11], "temperature": 0.0, "avg_logprob": -0.20217117510343852, "compression_ratio": 1.604, "no_speech_prob": 0.00015989603707566857}, {"id": 31, "seek": 8540, "start": 109.4, "end": 112.4, "text": " the docs are already pretty good as a starting point,", "tokens": [264, 45623, 366, 1217, 1238, 665, 382, 257, 2891, 935, 11], "temperature": 0.0, "avg_logprob": -0.20217117510343852, "compression_ratio": 1.604, "no_speech_prob": 0.00015989603707566857}, {"id": 32, "seek": 11240, "start": 112.4, "end": 119.4, "text": " because you are required to have, you know, types for all of your exposed APIs,", "tokens": [570, 291, 366, 4739, 281, 362, 11, 291, 458, 11, 3467, 337, 439, 295, 428, 9495, 21445, 11], "temperature": 0.0, "avg_logprob": -0.18456063315133067, "compression_ratio": 1.623015873015873, "no_speech_prob": 4.6106910303933546e-05}, {"id": 33, "seek": 11240, "start": 119.4, "end": 124.4, "text": " and it comes with already a really good, easy-to-navigate set of documentation", "tokens": [293, 309, 1487, 365, 1217, 257, 534, 665, 11, 1858, 12, 1353, 12, 629, 85, 328, 473, 992, 295, 14333], "temperature": 0.0, "avg_logprob": -0.18456063315133067, "compression_ratio": 1.623015873015873, "no_speech_prob": 4.6106910303933546e-05}, {"id": 34, "seek": 11240, "start": 124.4, "end": 125.4, "text": " for your package.", "tokens": [337, 428, 7372, 13], "temperature": 0.0, "avg_logprob": -0.18456063315133067, "compression_ratio": 1.623015873015873, "no_speech_prob": 4.6106910303933546e-05}, {"id": 35, "seek": 11240, "start": 125.4, "end": 130.4, "text": " Like, honestly, better than almost any other programming language I've seen.", "tokens": [1743, 11, 6095, 11, 1101, 813, 1920, 604, 661, 9410, 2856, 286, 600, 1612, 13], "temperature": 0.0, "avg_logprob": -0.18456063315133067, "compression_ratio": 1.623015873015873, "no_speech_prob": 4.6106910303933546e-05}, {"id": 36, "seek": 11240, "start": 130.4, "end": 133.4, "text": " But in addition to that, we go above and beyond,", "tokens": [583, 294, 4500, 281, 300, 11, 321, 352, 3673, 293, 4399, 11], "temperature": 0.0, "avg_logprob": -0.18456063315133067, "compression_ratio": 1.623015873015873, "no_speech_prob": 4.6106910303933546e-05}, {"id": 37, "seek": 11240, "start": 133.4, "end": 138.4, "text": " and we try to make it a really good flow through reading that", "tokens": [293, 321, 853, 281, 652, 309, 257, 534, 665, 3095, 807, 3760, 300], "temperature": 0.0, "avg_logprob": -0.18456063315133067, "compression_ratio": 1.623015873015873, "no_speech_prob": 4.6106910303933546e-05}, {"id": 38, "seek": 11240, "start": 138.4, "end": 140.4, "text": " and getting up and running with our package.", "tokens": [293, 1242, 493, 293, 2614, 365, 527, 7372, 13], "temperature": 0.0, "avg_logprob": -0.18456063315133067, "compression_ratio": 1.623015873015873, "no_speech_prob": 4.6106910303933546e-05}, {"id": 39, "seek": 14040, "start": 140.4, "end": 144.4, "text": " I thought it would be fun to talk about, like, what do make docs great?", "tokens": [286, 1194, 309, 576, 312, 1019, 281, 751, 466, 11, 411, 11, 437, 360, 652, 45623, 869, 30], "temperature": 0.0, "avg_logprob": -0.1751063260165128, "compression_ratio": 1.6996197718631179, "no_speech_prob": 1.86312372534303e-05}, {"id": 40, "seek": 14040, "start": 144.4, "end": 146.4, "text": " What's the process for great docs?", "tokens": [708, 311, 264, 1399, 337, 869, 45623, 30], "temperature": 0.0, "avg_logprob": -0.1751063260165128, "compression_ratio": 1.6996197718631179, "no_speech_prob": 1.86312372534303e-05}, {"id": 41, "seek": 14040, "start": 146.4, "end": 150.4, "text": " What should package authors be thinking about for making their docs great?", "tokens": [708, 820, 7372, 16552, 312, 1953, 466, 337, 1455, 641, 45623, 869, 30], "temperature": 0.0, "avg_logprob": -0.1751063260165128, "compression_ratio": 1.6996197718631179, "no_speech_prob": 1.86312372534303e-05}, {"id": 42, "seek": 14040, "start": 150.4, "end": 154.4, "text": " How should users use that information to navigate docs?", "tokens": [1012, 820, 5022, 764, 300, 1589, 281, 12350, 45623, 30], "temperature": 0.0, "avg_logprob": -0.1751063260165128, "compression_ratio": 1.6996197718631179, "no_speech_prob": 1.86312372534303e-05}, {"id": 43, "seek": 14040, "start": 154.4, "end": 156.4, "text": " And, you know, maybe whether those things are relevant", "tokens": [400, 11, 291, 458, 11, 1310, 1968, 729, 721, 366, 7340], "temperature": 0.0, "avg_logprob": -0.1751063260165128, "compression_ratio": 1.6996197718631179, "no_speech_prob": 1.86312372534303e-05}, {"id": 44, "seek": 14040, "start": 156.4, "end": 159.4, "text": " for documenting an application.", "tokens": [337, 42360, 364, 3861, 13], "temperature": 0.0, "avg_logprob": -0.1751063260165128, "compression_ratio": 1.6996197718631179, "no_speech_prob": 1.86312372534303e-05}, {"id": 45, "seek": 14040, "start": 159.4, "end": 163.4, "text": " I think one of the reasons why we tend to have great docs in Elm", "tokens": [286, 519, 472, 295, 264, 4112, 983, 321, 3928, 281, 362, 869, 45623, 294, 2699, 76], "temperature": 0.0, "avg_logprob": -0.1751063260165128, "compression_ratio": 1.6996197718631179, "no_speech_prob": 1.86312372534303e-05}, {"id": 46, "seek": 14040, "start": 163.4, "end": 169.4, "text": " is because all the tools and packages that we enjoy using", "tokens": [307, 570, 439, 264, 3873, 293, 17401, 300, 321, 2103, 1228], "temperature": 0.0, "avg_logprob": -0.1751063260165128, "compression_ratio": 1.6996197718631179, "no_speech_prob": 1.86312372534303e-05}, {"id": 47, "seek": 16940, "start": 169.4, "end": 171.4, "text": " have great docs.", "tokens": [362, 869, 45623, 13], "temperature": 0.0, "avg_logprob": -0.13813900384377306, "compression_ratio": 1.7167381974248928, "no_speech_prob": 4.985335181117989e-05}, {"id": 48, "seek": 16940, "start": 171.4, "end": 173.4, "text": " So I think it's kind of a culture thing.", "tokens": [407, 286, 519, 309, 311, 733, 295, 257, 3713, 551, 13], "temperature": 0.0, "avg_logprob": -0.13813900384377306, "compression_ratio": 1.7167381974248928, "no_speech_prob": 4.985335181117989e-05}, {"id": 49, "seek": 16940, "start": 173.4, "end": 177.4, "text": " Like, in the Elm community, whenever we release something,", "tokens": [1743, 11, 294, 264, 2699, 76, 1768, 11, 5699, 321, 4374, 746, 11], "temperature": 0.0, "avg_logprob": -0.13813900384377306, "compression_ratio": 1.7167381974248928, "no_speech_prob": 4.985335181117989e-05}, {"id": 50, "seek": 16940, "start": 177.4, "end": 179.4, "text": " we write great docs.", "tokens": [321, 2464, 869, 45623, 13], "temperature": 0.0, "avg_logprob": -0.13813900384377306, "compression_ratio": 1.7167381974248928, "no_speech_prob": 4.985335181117989e-05}, {"id": 51, "seek": 16940, "start": 179.4, "end": 182.4, "text": " And it's kind of the same as, like, oh, well,", "tokens": [400, 309, 311, 733, 295, 264, 912, 382, 11, 411, 11, 1954, 11, 731, 11], "temperature": 0.0, "avg_logprob": -0.13813900384377306, "compression_ratio": 1.7167381974248928, "no_speech_prob": 4.985335181117989e-05}, {"id": 52, "seek": 16940, "start": 182.4, "end": 187.4, "text": " every time we try to make something, we want it to be type-safe.", "tokens": [633, 565, 321, 853, 281, 652, 746, 11, 321, 528, 309, 281, 312, 2010, 12, 5790, 2106, 13], "temperature": 0.0, "avg_logprob": -0.13813900384377306, "compression_ratio": 1.7167381974248928, "no_speech_prob": 4.985335181117989e-05}, {"id": 53, "seek": 16940, "start": 187.4, "end": 189.4, "text": " That's just the culture that we have.", "tokens": [663, 311, 445, 264, 3713, 300, 321, 362, 13], "temperature": 0.0, "avg_logprob": -0.13813900384377306, "compression_ratio": 1.7167381974248928, "no_speech_prob": 4.985335181117989e-05}, {"id": 54, "seek": 16940, "start": 189.4, "end": 194.4, "text": " And it's one that has been with Elm for a long time.", "tokens": [400, 309, 311, 472, 300, 575, 668, 365, 2699, 76, 337, 257, 938, 565, 13], "temperature": 0.0, "avg_logprob": -0.13813900384377306, "compression_ratio": 1.7167381974248928, "no_speech_prob": 4.985335181117989e-05}, {"id": 55, "seek": 16940, "start": 194.4, "end": 198.4, "text": " I don't know how long, but at least before my time with Elm.", "tokens": [286, 500, 380, 458, 577, 938, 11, 457, 412, 1935, 949, 452, 565, 365, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.13813900384377306, "compression_ratio": 1.7167381974248928, "no_speech_prob": 4.985335181117989e-05}, {"id": 56, "seek": 19840, "start": 198.4, "end": 203.4, "text": " And therefore, the expectation is that every time you write docs,", "tokens": [400, 4412, 11, 264, 14334, 307, 300, 633, 565, 291, 2464, 45623, 11], "temperature": 0.0, "avg_logprob": -0.1669813854859607, "compression_ratio": 1.6578947368421053, "no_speech_prob": 1.2411215720931068e-05}, {"id": 57, "seek": 19840, "start": 203.4, "end": 205.4, "text": " they have to be great.", "tokens": [436, 362, 281, 312, 869, 13], "temperature": 0.0, "avg_logprob": -0.1669813854859607, "compression_ratio": 1.6578947368421053, "no_speech_prob": 1.2411215720931068e-05}, {"id": 58, "seek": 19840, "start": 205.4, "end": 209.4, "text": " And that culture at the start is very important", "tokens": [400, 300, 3713, 412, 264, 722, 307, 588, 1021], "temperature": 0.0, "avg_logprob": -0.1669813854859607, "compression_ratio": 1.6578947368421053, "no_speech_prob": 1.2411215720931068e-05}, {"id": 59, "seek": 19840, "start": 209.4, "end": 211.4, "text": " because now it's set in stone almost.", "tokens": [570, 586, 309, 311, 992, 294, 7581, 1920, 13], "temperature": 0.0, "avg_logprob": -0.1669813854859607, "compression_ratio": 1.6578947368421053, "no_speech_prob": 1.2411215720931068e-05}, {"id": 60, "seek": 19840, "start": 211.4, "end": 217.4, "text": " And whenever I see packages that are not great quality-wise or doc-wise,", "tokens": [400, 5699, 286, 536, 17401, 300, 366, 406, 869, 3125, 12, 3711, 420, 3211, 12, 3711, 11], "temperature": 0.0, "avg_logprob": -0.1669813854859607, "compression_ratio": 1.6578947368421053, "no_speech_prob": 1.2411215720931068e-05}, {"id": 61, "seek": 19840, "start": 217.4, "end": 221.4, "text": " it's usually by someone who has just learned Elm", "tokens": [309, 311, 2673, 538, 1580, 567, 575, 445, 3264, 2699, 76], "temperature": 0.0, "avg_logprob": -0.1669813854859607, "compression_ratio": 1.6578947368421053, "no_speech_prob": 1.2411215720931068e-05}, {"id": 62, "seek": 19840, "start": 221.4, "end": 223.4, "text": " and was just introduced to Elm", "tokens": [293, 390, 445, 7268, 281, 2699, 76], "temperature": 0.0, "avg_logprob": -0.1669813854859607, "compression_ratio": 1.6578947368421053, "no_speech_prob": 1.2411215720931068e-05}, {"id": 63, "seek": 19840, "start": 223.4, "end": 227.4, "text": " and doesn't have the expanded experience with Elm.", "tokens": [293, 1177, 380, 362, 264, 14342, 1752, 365, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.1669813854859607, "compression_ratio": 1.6578947368421053, "no_speech_prob": 1.2411215720931068e-05}, {"id": 64, "seek": 22740, "start": 227.4, "end": 229.4, "text": " And that's fine, I guess.", "tokens": [400, 300, 311, 2489, 11, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.14610394409724645, "compression_ratio": 1.5907335907335907, "no_speech_prob": 5.954910193395335e-06}, {"id": 65, "seek": 22740, "start": 229.4, "end": 231.4, "text": " They're going to learn at some point.", "tokens": [814, 434, 516, 281, 1466, 412, 512, 935, 13], "temperature": 0.0, "avg_logprob": -0.14610394409724645, "compression_ratio": 1.5907335907335907, "no_speech_prob": 5.954910193395335e-06}, {"id": 66, "seek": 22740, "start": 231.4, "end": 232.4, "text": " Interesting.", "tokens": [14711, 13], "temperature": 0.0, "avg_logprob": -0.14610394409724645, "compression_ratio": 1.5907335907335907, "no_speech_prob": 5.954910193395335e-06}, {"id": 67, "seek": 22740, "start": 232.4, "end": 240.4, "text": " So when you say that you've grown accustomed to Elm packages with great docs,", "tokens": [407, 562, 291, 584, 300, 291, 600, 7709, 35980, 281, 2699, 76, 17401, 365, 869, 45623, 11], "temperature": 0.0, "avg_logprob": -0.14610394409724645, "compression_ratio": 1.5907335907335907, "no_speech_prob": 5.954910193395335e-06}, {"id": 68, "seek": 22740, "start": 240.4, "end": 243.4, "text": " can you dig in a little bit to what that means to you?", "tokens": [393, 291, 2528, 294, 257, 707, 857, 281, 437, 300, 1355, 281, 291, 30], "temperature": 0.0, "avg_logprob": -0.14610394409724645, "compression_ratio": 1.5907335907335907, "no_speech_prob": 5.954910193395335e-06}, {"id": 69, "seek": 22740, "start": 243.4, "end": 247.4, "text": " Like, as a consumer of documentation, what makes them great?", "tokens": [1743, 11, 382, 257, 9711, 295, 14333, 11, 437, 1669, 552, 869, 30], "temperature": 0.0, "avg_logprob": -0.14610394409724645, "compression_ratio": 1.5907335907335907, "no_speech_prob": 5.954910193395335e-06}, {"id": 70, "seek": 22740, "start": 247.4, "end": 250.4, "text": " What are the things you notice about those packages?", "tokens": [708, 366, 264, 721, 291, 3449, 466, 729, 17401, 30], "temperature": 0.0, "avg_logprob": -0.14610394409724645, "compression_ratio": 1.5907335907335907, "no_speech_prob": 5.954910193395335e-06}, {"id": 71, "seek": 22740, "start": 250.4, "end": 254.4, "text": " Well, maybe let's start with the first thing that is obvious", "tokens": [1042, 11, 1310, 718, 311, 722, 365, 264, 700, 551, 300, 307, 6322], "temperature": 0.0, "avg_logprob": -0.14610394409724645, "compression_ratio": 1.5907335907335907, "no_speech_prob": 5.954910193395335e-06}, {"id": 72, "seek": 22740, "start": 254.4, "end": 256.4, "text": " but also quite not obvious.", "tokens": [457, 611, 1596, 406, 6322, 13], "temperature": 0.0, "avg_logprob": -0.14610394409724645, "compression_ratio": 1.5907335907335907, "no_speech_prob": 5.954910193395335e-06}, {"id": 73, "seek": 25640, "start": 256.4, "end": 261.4, "text": " The whole API of the package is documented.", "tokens": [440, 1379, 9362, 295, 264, 7372, 307, 23007, 13], "temperature": 0.0, "avg_logprob": -0.21272663448167883, "compression_ratio": 1.5885167464114833, "no_speech_prob": 3.1195111660053954e-05}, {"id": 74, "seek": 25640, "start": 261.4, "end": 265.4, "text": " If I remember my NPM days or JavaScript days,", "tokens": [759, 286, 1604, 452, 426, 18819, 1708, 420, 15778, 1708, 11], "temperature": 0.0, "avg_logprob": -0.21272663448167883, "compression_ratio": 1.5885167464114833, "no_speech_prob": 3.1195111660053954e-05}, {"id": 75, "seek": 25640, "start": 265.4, "end": 271.4, "text": " you had a package and the documentation for that package was the readme.", "tokens": [291, 632, 257, 7372, 293, 264, 14333, 337, 300, 7372, 390, 264, 1401, 1398, 13], "temperature": 0.0, "avg_logprob": -0.21272663448167883, "compression_ratio": 1.5885167464114833, "no_speech_prob": 3.1195111660053954e-05}, {"id": 76, "seek": 25640, "start": 271.4, "end": 274.4, "text": " And maybe like an additional website, but it's usually like the readme", "tokens": [400, 1310, 411, 364, 4497, 3144, 11, 457, 309, 311, 2673, 411, 264, 1401, 1398], "temperature": 0.0, "avg_logprob": -0.21272663448167883, "compression_ratio": 1.5885167464114833, "no_speech_prob": 3.1195111660053954e-05}, {"id": 77, "seek": 25640, "start": 274.4, "end": 276.4, "text": " and everything is in readme.", "tokens": [293, 1203, 307, 294, 1401, 1398, 13], "temperature": 0.0, "avg_logprob": -0.21272663448167883, "compression_ratio": 1.5885167464114833, "no_speech_prob": 3.1195111660053954e-05}, {"id": 78, "seek": 25640, "start": 276.4, "end": 279.4, "text": " More on that later, I think.", "tokens": [5048, 322, 300, 1780, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.21272663448167883, "compression_ratio": 1.5885167464114833, "no_speech_prob": 3.1195111660053954e-05}, {"id": 79, "seek": 25640, "start": 279.4, "end": 282.4, "text": " But the API that would be in the readme,", "tokens": [583, 264, 9362, 300, 576, 312, 294, 264, 1401, 1398, 11], "temperature": 0.0, "avg_logprob": -0.21272663448167883, "compression_ratio": 1.5885167464114833, "no_speech_prob": 3.1195111660053954e-05}, {"id": 80, "seek": 28240, "start": 282.4, "end": 287.4, "text": " sometimes it's just like an example like, oh, this is what you can do with this package.", "tokens": [2171, 309, 311, 445, 411, 364, 1365, 411, 11, 1954, 11, 341, 307, 437, 291, 393, 360, 365, 341, 7372, 13], "temperature": 0.0, "avg_logprob": -0.18284838407942391, "compression_ratio": 1.8317307692307692, "no_speech_prob": 2.726196726143826e-06}, {"id": 81, "seek": 28240, "start": 287.4, "end": 290.4, "text": " You can do this, and they show a simplified example", "tokens": [509, 393, 360, 341, 11, 293, 436, 855, 257, 26335, 1365], "temperature": 0.0, "avg_logprob": -0.18284838407942391, "compression_ratio": 1.8317307692307692, "no_speech_prob": 2.726196726143826e-06}, {"id": 82, "seek": 28240, "start": 290.4, "end": 295.4, "text": " because it's annoying to write a lot of documentation.", "tokens": [570, 309, 311, 11304, 281, 2464, 257, 688, 295, 14333, 13], "temperature": 0.0, "avg_logprob": -0.18284838407942391, "compression_ratio": 1.8317307692307692, "no_speech_prob": 2.726196726143826e-06}, {"id": 83, "seek": 28240, "start": 295.4, "end": 297.4, "text": " And then that's it.", "tokens": [400, 550, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.18284838407942391, "compression_ratio": 1.8317307692307692, "no_speech_prob": 2.726196726143826e-06}, {"id": 84, "seek": 28240, "start": 297.4, "end": 301.4, "text": " Or they write a lot of options,", "tokens": [1610, 436, 2464, 257, 688, 295, 3956, 11], "temperature": 0.0, "avg_logprob": -0.18284838407942391, "compression_ratio": 1.8317307692307692, "no_speech_prob": 2.726196726143826e-06}, {"id": 85, "seek": 28240, "start": 301.4, "end": 306.4, "text": " but they don't write all of the ways that you can use this package,", "tokens": [457, 436, 500, 380, 2464, 439, 295, 264, 2098, 300, 291, 393, 764, 341, 7372, 11], "temperature": 0.0, "avg_logprob": -0.18284838407942391, "compression_ratio": 1.8317307692307692, "no_speech_prob": 2.726196726143826e-06}, {"id": 86, "seek": 28240, "start": 306.4, "end": 311.4, "text": " all the ways that are intended, nor the ones that are unintended,", "tokens": [439, 264, 2098, 300, 366, 10226, 11, 6051, 264, 2306, 300, 366, 49902, 11], "temperature": 0.0, "avg_logprob": -0.18284838407942391, "compression_ratio": 1.8317307692307692, "no_speech_prob": 2.726196726143826e-06}, {"id": 87, "seek": 31140, "start": 311.4, "end": 314.4, "text": " which makes sense that they're unintended.", "tokens": [597, 1669, 2020, 300, 436, 434, 49902, 13], "temperature": 0.0, "avg_logprob": -0.2123925968752069, "compression_ratio": 1.6995708154506437, "no_speech_prob": 1.2804998732462991e-05}, {"id": 88, "seek": 31140, "start": 314.4, "end": 318.4, "text": " But I've seen a lot of packages where you would open an issue saying,", "tokens": [583, 286, 600, 1612, 257, 688, 295, 17401, 689, 291, 576, 1269, 364, 2734, 1566, 11], "temperature": 0.0, "avg_logprob": -0.2123925968752069, "compression_ratio": 1.6995708154506437, "no_speech_prob": 1.2804998732462991e-05}, {"id": 89, "seek": 31140, "start": 318.4, "end": 320.4, "text": " oh, I would love to be able to do this.", "tokens": [1954, 11, 286, 576, 959, 281, 312, 1075, 281, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.2123925968752069, "compression_ratio": 1.6995708154506437, "no_speech_prob": 1.2804998732462991e-05}, {"id": 90, "seek": 31140, "start": 320.4, "end": 326.4, "text": " And they would answer, oh, well, you can import this submodule of the package,", "tokens": [400, 436, 576, 1867, 11, 1954, 11, 731, 11, 291, 393, 974, 341, 1422, 8014, 2271, 295, 264, 7372, 11], "temperature": 0.0, "avg_logprob": -0.2123925968752069, "compression_ratio": 1.6995708154506437, "no_speech_prob": 1.2804998732462991e-05}, {"id": 91, "seek": 31140, "start": 326.4, "end": 328.4, "text": " and then you can do that.", "tokens": [293, 550, 291, 393, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.2123925968752069, "compression_ratio": 1.6995708154506437, "no_speech_prob": 1.2804998732462991e-05}, {"id": 92, "seek": 31140, "start": 328.4, "end": 330.4, "text": " But that's not documented.", "tokens": [583, 300, 311, 406, 23007, 13], "temperature": 0.0, "avg_logprob": -0.2123925968752069, "compression_ratio": 1.6995708154506437, "no_speech_prob": 1.2804998732462991e-05}, {"id": 93, "seek": 31140, "start": 330.4, "end": 336.4, "text": " And now, usually you would say, oh, now I'm using internals,", "tokens": [400, 586, 11, 2673, 291, 576, 584, 11, 1954, 11, 586, 286, 478, 1228, 2154, 1124, 11], "temperature": 0.0, "avg_logprob": -0.2123925968752069, "compression_ratio": 1.6995708154506437, "no_speech_prob": 1.2804998732462991e-05}, {"id": 94, "seek": 31140, "start": 336.4, "end": 339.4, "text": " which is not good, and in practice, it's not good.", "tokens": [597, 307, 406, 665, 11, 293, 294, 3124, 11, 309, 311, 406, 665, 13], "temperature": 0.0, "avg_logprob": -0.2123925968752069, "compression_ratio": 1.6995708154506437, "no_speech_prob": 1.2804998732462991e-05}, {"id": 95, "seek": 33940, "start": 339.4, "end": 344.4, "text": " So yeah, the fact that we have to document everything in the API,", "tokens": [407, 1338, 11, 264, 1186, 300, 321, 362, 281, 4166, 1203, 294, 264, 9362, 11], "temperature": 0.0, "avg_logprob": -0.19732518715433556, "compression_ratio": 1.6595744680851063, "no_speech_prob": 3.7852887544431724e-06}, {"id": 96, "seek": 33940, "start": 344.4, "end": 348.4, "text": " or just that they're shown in the package documentation,", "tokens": [420, 445, 300, 436, 434, 4898, 294, 264, 7372, 14333, 11], "temperature": 0.0, "avg_logprob": -0.19732518715433556, "compression_ratio": 1.6595744680851063, "no_speech_prob": 3.7852887544431724e-06}, {"id": 97, "seek": 33940, "start": 348.4, "end": 351.4, "text": " is already a great point, I think, in the end.", "tokens": [307, 1217, 257, 869, 935, 11, 286, 519, 11, 294, 264, 917, 13], "temperature": 0.0, "avg_logprob": -0.19732518715433556, "compression_ratio": 1.6595744680851063, "no_speech_prob": 3.7852887544431724e-06}, {"id": 98, "seek": 33940, "start": 351.4, "end": 353.4, "text": " Yeah, that definitely resonates with me.", "tokens": [865, 11, 300, 2138, 41051, 365, 385, 13], "temperature": 0.0, "avg_logprob": -0.19732518715433556, "compression_ratio": 1.6595744680851063, "no_speech_prob": 3.7852887544431724e-06}, {"id": 99, "seek": 33940, "start": 353.4, "end": 356.4, "text": " I can think of so many times when I've been trying to figure out", "tokens": [286, 393, 519, 295, 370, 867, 1413, 562, 286, 600, 668, 1382, 281, 2573, 484], "temperature": 0.0, "avg_logprob": -0.19732518715433556, "compression_ratio": 1.6595744680851063, "no_speech_prob": 3.7852887544431724e-06}, {"id": 100, "seek": 33940, "start": 356.4, "end": 359.4, "text": " how to do something with an npm package,", "tokens": [577, 281, 360, 746, 365, 364, 297, 14395, 7372, 11], "temperature": 0.0, "avg_logprob": -0.19732518715433556, "compression_ratio": 1.6595744680851063, "no_speech_prob": 3.7852887544431724e-06}, {"id": 101, "seek": 33940, "start": 359.4, "end": 366.4, "text": " and I'm searching through and often end up digging through obscure issues", "tokens": [293, 286, 478, 10808, 807, 293, 2049, 917, 493, 17343, 807, 34443, 2663], "temperature": 0.0, "avg_logprob": -0.19732518715433556, "compression_ratio": 1.6595744680851063, "no_speech_prob": 3.7852887544431724e-06}, {"id": 102, "seek": 36640, "start": 366.4, "end": 372.4, "text": " that I have to Google for and find some niche use of it that isn't documented", "tokens": [300, 286, 362, 281, 3329, 337, 293, 915, 512, 19956, 764, 295, 309, 300, 1943, 380, 23007], "temperature": 0.0, "avg_logprob": -0.18036173791000523, "compression_ratio": 1.6232558139534883, "no_speech_prob": 2.753509943431709e-05}, {"id": 103, "seek": 36640, "start": 372.4, "end": 376.4, "text": " or isn't documented in a clear place.", "tokens": [420, 1943, 380, 23007, 294, 257, 1850, 1081, 13], "temperature": 0.0, "avg_logprob": -0.18036173791000523, "compression_ratio": 1.6232558139534883, "no_speech_prob": 2.753509943431709e-05}, {"id": 104, "seek": 36640, "start": 376.4, "end": 381.4, "text": " Or I have to search through the source code and see what it's checking for.", "tokens": [1610, 286, 362, 281, 3164, 807, 264, 4009, 3089, 293, 536, 437, 309, 311, 8568, 337, 13], "temperature": 0.0, "avg_logprob": -0.18036173791000523, "compression_ratio": 1.6232558139534883, "no_speech_prob": 2.753509943431709e-05}, {"id": 105, "seek": 36640, "start": 381.4, "end": 384.4, "text": " If this object property exists, then do this.", "tokens": [759, 341, 2657, 4707, 8198, 11, 550, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.18036173791000523, "compression_ratio": 1.6232558139534883, "no_speech_prob": 2.753509943431709e-05}, {"id": 106, "seek": 36640, "start": 384.4, "end": 386.4, "text": " If it doesn't, then do that.", "tokens": [759, 309, 1177, 380, 11, 550, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.18036173791000523, "compression_ratio": 1.6232558139534883, "no_speech_prob": 2.753509943431709e-05}, {"id": 107, "seek": 36640, "start": 386.4, "end": 387.4, "text": " So it's true.", "tokens": [407, 309, 311, 2074, 13], "temperature": 0.0, "avg_logprob": -0.18036173791000523, "compression_ratio": 1.6232558139534883, "no_speech_prob": 2.753509943431709e-05}, {"id": 108, "seek": 36640, "start": 387.4, "end": 393.4, "text": " By virtue of publishing an Elm package, those things are documented.", "tokens": [3146, 20816, 295, 17832, 364, 2699, 76, 7372, 11, 729, 721, 366, 23007, 13], "temperature": 0.0, "avg_logprob": -0.18036173791000523, "compression_ratio": 1.6232558139534883, "no_speech_prob": 2.753509943431709e-05}, {"id": 109, "seek": 39340, "start": 393.4, "end": 396.4, "text": " So that's the bare minimum for an Elm package.", "tokens": [407, 300, 311, 264, 6949, 7285, 337, 364, 2699, 76, 7372, 13], "temperature": 0.0, "avg_logprob": -0.15497809040303134, "compression_ratio": 1.6401869158878504, "no_speech_prob": 2.2252468170336215e-06}, {"id": 110, "seek": 39340, "start": 396.4, "end": 401.4, "text": " So another part is every API is shown,", "tokens": [407, 1071, 644, 307, 633, 9362, 307, 4898, 11], "temperature": 0.0, "avg_logprob": -0.15497809040303134, "compression_ratio": 1.6401869158878504, "no_speech_prob": 2.2252468170336215e-06}, {"id": 111, "seek": 39340, "start": 401.4, "end": 406.4, "text": " like all the custom types or the functions that are there,", "tokens": [411, 439, 264, 2375, 3467, 420, 264, 6828, 300, 366, 456, 11], "temperature": 0.0, "avg_logprob": -0.15497809040303134, "compression_ratio": 1.6401869158878504, "no_speech_prob": 2.2252468170336215e-06}, {"id": 112, "seek": 39340, "start": 406.4, "end": 408.4, "text": " all the type aliases.", "tokens": [439, 264, 2010, 10198, 1957, 13], "temperature": 0.0, "avg_logprob": -0.15497809040303134, "compression_ratio": 1.6401869158878504, "no_speech_prob": 2.2252468170336215e-06}, {"id": 113, "seek": 39340, "start": 408.4, "end": 411.4, "text": " But whenever you try to publish a package,", "tokens": [583, 5699, 291, 853, 281, 11374, 257, 7372, 11], "temperature": 0.0, "avg_logprob": -0.15497809040303134, "compression_ratio": 1.6401869158878504, "no_speech_prob": 2.2252468170336215e-06}, {"id": 114, "seek": 39340, "start": 411.4, "end": 413.4, "text": " one of the things that the Elm compiler will tell you", "tokens": [472, 295, 264, 721, 300, 264, 2699, 76, 31958, 486, 980, 291], "temperature": 0.0, "avg_logprob": -0.15497809040303134, "compression_ratio": 1.6401869158878504, "no_speech_prob": 2.2252468170336215e-06}, {"id": 115, "seek": 39340, "start": 413.4, "end": 417.4, "text": " is that some of the functions or some of the types are not documented,", "tokens": [307, 300, 512, 295, 264, 6828, 420, 512, 295, 264, 3467, 366, 406, 23007, 11], "temperature": 0.0, "avg_logprob": -0.15497809040303134, "compression_ratio": 1.6401869158878504, "no_speech_prob": 2.2252468170336215e-06}, {"id": 116, "seek": 39340, "start": 417.4, "end": 419.4, "text": " and you need to.", "tokens": [293, 291, 643, 281, 13], "temperature": 0.0, "avg_logprob": -0.15497809040303134, "compression_ratio": 1.6401869158878504, "no_speech_prob": 2.2252468170336215e-06}, {"id": 117, "seek": 41940, "start": 419.4, "end": 425.4, "text": " So Elm forces you to write documentation for all those exposed APIs,", "tokens": [407, 2699, 76, 5874, 291, 281, 2464, 14333, 337, 439, 729, 9495, 21445, 11], "temperature": 0.0, "avg_logprob": -0.17736000238462937, "compression_ratio": 1.6442307692307692, "no_speech_prob": 6.681488571302907e-07}, {"id": 118, "seek": 41940, "start": 425.4, "end": 427.4, "text": " all those public APIs.", "tokens": [439, 729, 1908, 21445, 13], "temperature": 0.0, "avg_logprob": -0.17736000238462937, "compression_ratio": 1.6442307692307692, "no_speech_prob": 6.681488571302907e-07}, {"id": 119, "seek": 41940, "start": 427.4, "end": 432.4, "text": " So even if you don't think you're going to write good docs for them,", "tokens": [407, 754, 498, 291, 500, 380, 519, 291, 434, 516, 281, 2464, 665, 45623, 337, 552, 11], "temperature": 0.0, "avg_logprob": -0.17736000238462937, "compression_ratio": 1.6442307692307692, "no_speech_prob": 6.681488571302907e-07}, {"id": 120, "seek": 41940, "start": 432.4, "end": 438.4, "text": " you have to carefully or you have to make that decision purposefully.", "tokens": [291, 362, 281, 7500, 420, 291, 362, 281, 652, 300, 3537, 4334, 2277, 13], "temperature": 0.0, "avg_logprob": -0.17736000238462937, "compression_ratio": 1.6442307692307692, "no_speech_prob": 6.681488571302907e-07}, {"id": 121, "seek": 41940, "start": 438.4, "end": 442.4, "text": " But sometimes it's pretty easy to just write some documentation,", "tokens": [583, 2171, 309, 311, 1238, 1858, 281, 445, 2464, 512, 14333, 11], "temperature": 0.0, "avg_logprob": -0.17736000238462937, "compression_ratio": 1.6442307692307692, "no_speech_prob": 6.681488571302907e-07}, {"id": 122, "seek": 41940, "start": 442.4, "end": 445.4, "text": " some explanation, oh, this function does this,", "tokens": [512, 10835, 11, 1954, 11, 341, 2445, 775, 341, 11], "temperature": 0.0, "avg_logprob": -0.17736000238462937, "compression_ratio": 1.6442307692307692, "no_speech_prob": 6.681488571302907e-07}, {"id": 123, "seek": 44540, "start": 445.4, "end": 450.4, "text": " and then, oh, I might as well add one little example,", "tokens": [293, 550, 11, 1954, 11, 286, 1062, 382, 731, 909, 472, 707, 1365, 11], "temperature": 0.0, "avg_logprob": -0.17195871141221789, "compression_ratio": 1.7091836734693877, "no_speech_prob": 6.083515700083808e-07}, {"id": 124, "seek": 44540, "start": 450.4, "end": 453.4, "text": " and now it's already very usable.", "tokens": [293, 586, 309, 311, 1217, 588, 29975, 13], "temperature": 0.0, "avg_logprob": -0.17195871141221789, "compression_ratio": 1.7091836734693877, "no_speech_prob": 6.083515700083808e-07}, {"id": 125, "seek": 44540, "start": 453.4, "end": 458.4, "text": " So that's like that little nudge that asks you to write some documentation,", "tokens": [407, 300, 311, 411, 300, 707, 297, 16032, 300, 8962, 291, 281, 2464, 512, 14333, 11], "temperature": 0.0, "avg_logprob": -0.17195871141221789, "compression_ratio": 1.7091836734693877, "no_speech_prob": 6.083515700083808e-07}, {"id": 126, "seek": 44540, "start": 458.4, "end": 463.4, "text": " even if it's empty, which I don't like, but we can talk about that later.", "tokens": [754, 498, 309, 311, 6707, 11, 597, 286, 500, 380, 411, 11, 457, 321, 393, 751, 466, 300, 1780, 13], "temperature": 0.0, "avg_logprob": -0.17195871141221789, "compression_ratio": 1.7091836734693877, "no_speech_prob": 6.083515700083808e-07}, {"id": 127, "seek": 44540, "start": 463.4, "end": 468.4, "text": " That little nudge already pushes you to write some documentation", "tokens": [663, 707, 297, 16032, 1217, 21020, 291, 281, 2464, 512, 14333], "temperature": 0.0, "avg_logprob": -0.17195871141221789, "compression_ratio": 1.7091836734693877, "no_speech_prob": 6.083515700083808e-07}, {"id": 128, "seek": 44540, "start": 468.4, "end": 470.4, "text": " and potentially to make it good.", "tokens": [293, 7263, 281, 652, 309, 665, 13], "temperature": 0.0, "avg_logprob": -0.17195871141221789, "compression_ratio": 1.7091836734693877, "no_speech_prob": 6.083515700083808e-07}, {"id": 129, "seek": 47040, "start": 470.4, "end": 475.4, "text": " So when you're consuming an Elm package,", "tokens": [407, 562, 291, 434, 19867, 364, 2699, 76, 7372, 11], "temperature": 0.0, "avg_logprob": -0.18360151811079545, "compression_ratio": 1.6793248945147679, "no_speech_prob": 1.3845453395333607e-05}, {"id": 130, "seek": 47040, "start": 475.4, "end": 479.4, "text": " what do those docs look like when they feel like they're really helping you?", "tokens": [437, 360, 729, 45623, 574, 411, 562, 436, 841, 411, 436, 434, 534, 4315, 291, 30], "temperature": 0.0, "avg_logprob": -0.18360151811079545, "compression_ratio": 1.6793248945147679, "no_speech_prob": 1.3845453395333607e-05}, {"id": 131, "seek": 47040, "start": 479.4, "end": 481.4, "text": " What's your experience?", "tokens": [708, 311, 428, 1752, 30], "temperature": 0.0, "avg_logprob": -0.18360151811079545, "compression_ratio": 1.6793248945147679, "no_speech_prob": 1.3845453395333607e-05}, {"id": 132, "seek": 47040, "start": 481.4, "end": 483.4, "text": " So that's one of the things I'm curious to dig into here too,", "tokens": [407, 300, 311, 472, 295, 264, 721, 286, 478, 6369, 281, 2528, 666, 510, 886, 11], "temperature": 0.0, "avg_logprob": -0.18360151811079545, "compression_ratio": 1.6793248945147679, "no_speech_prob": 1.3845453395333607e-05}, {"id": 133, "seek": 47040, "start": 483.4, "end": 487.4, "text": " because I think in order to talk about great docs,", "tokens": [570, 286, 519, 294, 1668, 281, 751, 466, 869, 45623, 11], "temperature": 0.0, "avg_logprob": -0.18360151811079545, "compression_ratio": 1.6793248945147679, "no_speech_prob": 1.3845453395333607e-05}, {"id": 134, "seek": 47040, "start": 487.4, "end": 491.4, "text": " I think it's really good to put yourself in the user's shoes,", "tokens": [286, 519, 309, 311, 534, 665, 281, 829, 1803, 294, 264, 4195, 311, 6654, 11], "temperature": 0.0, "avg_logprob": -0.18360151811079545, "compression_ratio": 1.6793248945147679, "no_speech_prob": 1.3845453395333607e-05}, {"id": 135, "seek": 47040, "start": 491.4, "end": 494.4, "text": " and we happen to be users of Elm packages", "tokens": [293, 321, 1051, 281, 312, 5022, 295, 2699, 76, 17401], "temperature": 0.0, "avg_logprob": -0.18360151811079545, "compression_ratio": 1.6793248945147679, "no_speech_prob": 1.3845453395333607e-05}, {"id": 136, "seek": 47040, "start": 494.4, "end": 497.4, "text": " and consumers of docs for Elm packages.", "tokens": [293, 11883, 295, 45623, 337, 2699, 76, 17401, 13], "temperature": 0.0, "avg_logprob": -0.18360151811079545, "compression_ratio": 1.6793248945147679, "no_speech_prob": 1.3845453395333607e-05}, {"id": 137, "seek": 49740, "start": 497.4, "end": 502.4, "text": " So what is it, like, when we're looking at those beautiful Elm package docs", "tokens": [407, 437, 307, 309, 11, 411, 11, 562, 321, 434, 1237, 412, 729, 2238, 2699, 76, 7372, 45623], "temperature": 0.0, "avg_logprob": -0.2131105613708496, "compression_ratio": 1.5480769230769231, "no_speech_prob": 2.2602584976993967e-06}, {"id": 138, "seek": 49740, "start": 502.4, "end": 506.4, "text": " and they're not left blank and there's something written there,", "tokens": [293, 436, 434, 406, 1411, 8247, 293, 456, 311, 746, 3720, 456, 11], "temperature": 0.0, "avg_logprob": -0.2131105613708496, "compression_ratio": 1.5480769230769231, "no_speech_prob": 2.2602584976993967e-06}, {"id": 139, "seek": 49740, "start": 506.4, "end": 509.4, "text": " what is it that makes it really good?", "tokens": [437, 307, 309, 300, 1669, 309, 534, 665, 30], "temperature": 0.0, "avg_logprob": -0.2131105613708496, "compression_ratio": 1.5480769230769231, "no_speech_prob": 2.2602584976993967e-06}, {"id": 140, "seek": 49740, "start": 509.4, "end": 512.4, "text": " I think they always say, like,", "tokens": [286, 519, 436, 1009, 584, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.2131105613708496, "compression_ratio": 1.5480769230769231, "no_speech_prob": 2.2602584976993967e-06}, {"id": 141, "seek": 49740, "start": 512.4, "end": 518.4, "text": " this is a blazingly fast package to do something, or...", "tokens": [341, 307, 257, 16379, 8781, 356, 2370, 7372, 281, 360, 746, 11, 420, 485], "temperature": 0.0, "avg_logprob": -0.2131105613708496, "compression_ratio": 1.5480769230769231, "no_speech_prob": 2.2602584976993967e-06}, {"id": 142, "seek": 49740, "start": 518.4, "end": 521.4, "text": " No, wait, sorry, that's NPM.", "tokens": [883, 11, 1699, 11, 2597, 11, 300, 311, 426, 18819, 13], "temperature": 0.0, "avg_logprob": -0.2131105613708496, "compression_ratio": 1.5480769230769231, "no_speech_prob": 2.2602584976993967e-06}, {"id": 143, "seek": 49740, "start": 521.4, "end": 522.4, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2131105613708496, "compression_ratio": 1.5480769230769231, "no_speech_prob": 2.2602584976993967e-06}, {"id": 144, "seek": 49740, "start": 522.4, "end": 524.4, "text": " Sorry, I messed it up.", "tokens": [4919, 11, 286, 16507, 309, 493, 13], "temperature": 0.0, "avg_logprob": -0.2131105613708496, "compression_ratio": 1.5480769230769231, "no_speech_prob": 2.2602584976993967e-06}, {"id": 145, "seek": 52440, "start": 524.4, "end": 527.4, "text": " The logo really helps you understand what it does too.", "tokens": [440, 9699, 534, 3665, 291, 1223, 437, 309, 775, 886, 13], "temperature": 0.0, "avg_logprob": -0.20261601534756749, "compression_ratio": 1.6680851063829787, "no_speech_prob": 4.7105691010074224e-06}, {"id": 146, "seek": 52440, "start": 527.4, "end": 533.4, "text": " Yeah, and the visual design and the 100 SCO score that you have.", "tokens": [865, 11, 293, 264, 5056, 1715, 293, 264, 2319, 9028, 46, 6175, 300, 291, 362, 13], "temperature": 0.0, "avg_logprob": -0.20261601534756749, "compression_ratio": 1.6680851063829787, "no_speech_prob": 4.7105691010074224e-06}, {"id": 147, "seek": 52440, "start": 533.4, "end": 537.4, "text": " No, yeah, so you usually want to look at a package.", "tokens": [883, 11, 1338, 11, 370, 291, 2673, 528, 281, 574, 412, 257, 7372, 13], "temperature": 0.0, "avg_logprob": -0.20261601534756749, "compression_ratio": 1.6680851063829787, "no_speech_prob": 4.7105691010074224e-06}, {"id": 148, "seek": 52440, "start": 537.4, "end": 540.4, "text": " The first thing that I see is the name of the package, who made it,", "tokens": [440, 700, 551, 300, 286, 536, 307, 264, 1315, 295, 264, 7372, 11, 567, 1027, 309, 11], "temperature": 0.0, "avg_logprob": -0.20261601534756749, "compression_ratio": 1.6680851063829787, "no_speech_prob": 4.7105691010074224e-06}, {"id": 149, "seek": 52440, "start": 540.4, "end": 545.4, "text": " and then a description of what it does, like, what is the purpose of this,", "tokens": [293, 550, 257, 3855, 295, 437, 309, 775, 11, 411, 11, 437, 307, 264, 4334, 295, 341, 11], "temperature": 0.0, "avg_logprob": -0.20261601534756749, "compression_ratio": 1.6680851063829787, "no_speech_prob": 4.7105691010074224e-06}, {"id": 150, "seek": 52440, "start": 545.4, "end": 548.4, "text": " or what does this package help you with,", "tokens": [420, 437, 775, 341, 7372, 854, 291, 365, 11], "temperature": 0.0, "avg_logprob": -0.20261601534756749, "compression_ratio": 1.6680851063829787, "no_speech_prob": 4.7105691010074224e-06}, {"id": 151, "seek": 52440, "start": 548.4, "end": 551.4, "text": " then some examples of how to use it.", "tokens": [550, 512, 5110, 295, 577, 281, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.20261601534756749, "compression_ratio": 1.6680851063829787, "no_speech_prob": 4.7105691010074224e-06}, {"id": 152, "seek": 55140, "start": 551.4, "end": 555.4, "text": " But also in some cases where you have, like,", "tokens": [583, 611, 294, 512, 3331, 689, 291, 362, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.17363206863403322, "compression_ratio": 1.6504424778761062, "no_speech_prob": 4.0293602978636045e-06}, {"id": 153, "seek": 55140, "start": 555.4, "end": 559.4, "text": " for instance, if you have, like, a package to parse some format,", "tokens": [337, 5197, 11, 498, 291, 362, 11, 411, 11, 257, 7372, 281, 48377, 512, 7877, 11], "temperature": 0.0, "avg_logprob": -0.17363206863403322, "compression_ratio": 1.6504424778761062, "no_speech_prob": 4.0293602978636045e-06}, {"id": 154, "seek": 55140, "start": 559.4, "end": 562.4, "text": " like, that's pretty obvious what it does.", "tokens": [411, 11, 300, 311, 1238, 6322, 437, 309, 775, 13], "temperature": 0.0, "avg_logprob": -0.17363206863403322, "compression_ratio": 1.6504424778761062, "no_speech_prob": 4.0293602978636045e-06}, {"id": 155, "seek": 55140, "start": 562.4, "end": 565.4, "text": " So you don't have to explain it too much.", "tokens": [407, 291, 500, 380, 362, 281, 2903, 309, 886, 709, 13], "temperature": 0.0, "avg_logprob": -0.17363206863403322, "compression_ratio": 1.6504424778761062, "no_speech_prob": 4.0293602978636045e-06}, {"id": 156, "seek": 55140, "start": 565.4, "end": 570.4, "text": " You have to explain how to use it, but not how it works under the hood", "tokens": [509, 362, 281, 2903, 577, 281, 764, 309, 11, 457, 406, 577, 309, 1985, 833, 264, 13376], "temperature": 0.0, "avg_logprob": -0.17363206863403322, "compression_ratio": 1.6504424778761062, "no_speech_prob": 4.0293602978636045e-06}, {"id": 157, "seek": 55140, "start": 570.4, "end": 574.4, "text": " or what are the advantages of using this approach.", "tokens": [420, 437, 366, 264, 14906, 295, 1228, 341, 3109, 13], "temperature": 0.0, "avg_logprob": -0.17363206863403322, "compression_ratio": 1.6504424778761062, "no_speech_prob": 4.0293602978636045e-06}, {"id": 158, "seek": 55140, "start": 574.4, "end": 579.4, "text": " But whenever there are multiple alternatives to solution,", "tokens": [583, 5699, 456, 366, 3866, 20478, 281, 3827, 11], "temperature": 0.0, "avg_logprob": -0.17363206863403322, "compression_ratio": 1.6504424778761062, "no_speech_prob": 4.0293602978636045e-06}, {"id": 159, "seek": 57940, "start": 579.4, "end": 582.4, "text": " say, GraphQL packages,", "tokens": [584, 11, 21884, 13695, 17401, 11], "temperature": 0.0, "avg_logprob": -0.19745314523075405, "compression_ratio": 1.7563451776649746, "no_speech_prob": 6.64296067043324e-06}, {"id": 160, "seek": 57940, "start": 582.4, "end": 586.4, "text": " what I often see is, like, the philosophy behind a package", "tokens": [437, 286, 2049, 536, 307, 11, 411, 11, 264, 10675, 2261, 257, 7372], "temperature": 0.0, "avg_logprob": -0.19745314523075405, "compression_ratio": 1.7563451776649746, "no_speech_prob": 6.64296067043324e-06}, {"id": 161, "seek": 57940, "start": 586.4, "end": 592.4, "text": " or the trade-offs, or hopefully the trade-offs of the solution.", "tokens": [420, 264, 4923, 12, 19231, 11, 420, 4696, 264, 4923, 12, 19231, 295, 264, 3827, 13], "temperature": 0.0, "avg_logprob": -0.19745314523075405, "compression_ratio": 1.7563451776649746, "no_speech_prob": 6.64296067043324e-06}, {"id": 162, "seek": 57940, "start": 592.4, "end": 597.4, "text": " So I think explaining the philosophy or the trade-offs that are involved", "tokens": [407, 286, 519, 13468, 264, 10675, 420, 264, 4923, 12, 19231, 300, 366, 3288], "temperature": 0.0, "avg_logprob": -0.19745314523075405, "compression_ratio": 1.7563451776649746, "no_speech_prob": 6.64296067043324e-06}, {"id": 163, "seek": 57940, "start": 597.4, "end": 601.4, "text": " in this solution versus other solutions,", "tokens": [294, 341, 3827, 5717, 661, 6547, 11], "temperature": 0.0, "avg_logprob": -0.19745314523075405, "compression_ratio": 1.7563451776649746, "no_speech_prob": 6.64296067043324e-06}, {"id": 164, "seek": 57940, "start": 601.4, "end": 604.4, "text": " sometimes even referencing the other solutions,", "tokens": [2171, 754, 40582, 264, 661, 6547, 11], "temperature": 0.0, "avg_logprob": -0.19745314523075405, "compression_ratio": 1.7563451776649746, "no_speech_prob": 6.64296067043324e-06}, {"id": 165, "seek": 57940, "start": 604.4, "end": 607.4, "text": " is a great thing to have in your docs.", "tokens": [307, 257, 869, 551, 281, 362, 294, 428, 45623, 13], "temperature": 0.0, "avg_logprob": -0.19745314523075405, "compression_ratio": 1.7563451776649746, "no_speech_prob": 6.64296067043324e-06}, {"id": 166, "seek": 60740, "start": 607.4, "end": 610.4, "text": " Just saying it's blazingly fast is not necessarily helpful,", "tokens": [1449, 1566, 309, 311, 16379, 8781, 356, 2370, 307, 406, 4725, 4961, 11], "temperature": 0.0, "avg_logprob": -0.1871168574348825, "compression_ratio": 1.6825396825396826, "no_speech_prob": 2.6687805075198412e-05}, {"id": 167, "seek": 60740, "start": 610.4, "end": 613.4, "text": " especially if all of them say that.", "tokens": [2318, 498, 439, 295, 552, 584, 300, 13], "temperature": 0.0, "avg_logprob": -0.1871168574348825, "compression_ratio": 1.6825396825396826, "no_speech_prob": 2.6687805075198412e-05}, {"id": 168, "seek": 60740, "start": 613.4, "end": 617.4, "text": " Right. Unless that's part of the philosophy, and it's a differentiator.", "tokens": [1779, 13, 16581, 300, 311, 644, 295, 264, 10675, 11, 293, 309, 311, 257, 27372, 1639, 13], "temperature": 0.0, "avg_logprob": -0.1871168574348825, "compression_ratio": 1.6825396825396826, "no_speech_prob": 2.6687805075198412e-05}, {"id": 169, "seek": 60740, "start": 617.4, "end": 621.4, "text": " Yeah, but then you would need to say, like,", "tokens": [865, 11, 457, 550, 291, 576, 643, 281, 584, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.1871168574348825, "compression_ratio": 1.6825396825396826, "no_speech_prob": 2.6687805075198412e-05}, {"id": 170, "seek": 60740, "start": 621.4, "end": 626.4, "text": " the reason why it's blazingly fast is either we try this new approach,", "tokens": [264, 1778, 983, 309, 311, 16379, 8781, 356, 2370, 307, 2139, 321, 853, 341, 777, 3109, 11], "temperature": 0.0, "avg_logprob": -0.1871168574348825, "compression_ratio": 1.6825396825396826, "no_speech_prob": 2.6687805075198412e-05}, {"id": 171, "seek": 60740, "start": 626.4, "end": 629.4, "text": " or there's a trade-off, like, this is simpler,", "tokens": [420, 456, 311, 257, 4923, 12, 4506, 11, 411, 11, 341, 307, 18587, 11], "temperature": 0.0, "avg_logprob": -0.1871168574348825, "compression_ratio": 1.6825396825396826, "no_speech_prob": 2.6687805075198412e-05}, {"id": 172, "seek": 60740, "start": 629.4, "end": 631.4, "text": " this doesn't handle all the edge cases,", "tokens": [341, 1177, 380, 4813, 439, 264, 4691, 3331, 11], "temperature": 0.0, "avg_logprob": -0.1871168574348825, "compression_ratio": 1.6825396825396826, "no_speech_prob": 2.6687805075198412e-05}, {"id": 173, "seek": 60740, "start": 631.4, "end": 636.4, "text": " but for the normal cases, it's going to be way faster.", "tokens": [457, 337, 264, 2710, 3331, 11, 309, 311, 516, 281, 312, 636, 4663, 13], "temperature": 0.0, "avg_logprob": -0.1871168574348825, "compression_ratio": 1.6825396825396826, "no_speech_prob": 2.6687805075198412e-05}, {"id": 174, "seek": 63640, "start": 636.4, "end": 639.4, "text": " And that's something that you would like to see.", "tokens": [400, 300, 311, 746, 300, 291, 576, 411, 281, 536, 13], "temperature": 0.0, "avg_logprob": -0.1989179904644306, "compression_ratio": 1.6755725190839694, "no_speech_prob": 2.212504477938637e-05}, {"id": 175, "seek": 63640, "start": 639.4, "end": 643.4, "text": " Right. If it's a drop-in replacement for Dict, except faster,", "tokens": [1779, 13, 759, 309, 311, 257, 3270, 12, 259, 14419, 337, 413, 985, 11, 3993, 4663, 11], "temperature": 0.0, "avg_logprob": -0.1989179904644306, "compression_ratio": 1.6755725190839694, "no_speech_prob": 2.212504477938637e-05}, {"id": 176, "seek": 63640, "start": 643.4, "end": 647.4, "text": " that's the only thing that's different, then that's what you want to know.", "tokens": [300, 311, 264, 787, 551, 300, 311, 819, 11, 550, 300, 311, 437, 291, 528, 281, 458, 13], "temperature": 0.0, "avg_logprob": -0.1989179904644306, "compression_ratio": 1.6755725190839694, "no_speech_prob": 2.212504477938637e-05}, {"id": 177, "seek": 63640, "start": 647.4, "end": 649.4, "text": " And that's a good way to describe it.", "tokens": [400, 300, 311, 257, 665, 636, 281, 6786, 309, 13], "temperature": 0.0, "avg_logprob": -0.1989179904644306, "compression_ratio": 1.6755725190839694, "no_speech_prob": 2.212504477938637e-05}, {"id": 178, "seek": 63640, "start": 649.4, "end": 656.4, "text": " And maybe in that case, the package can also handle the more complex approach.", "tokens": [400, 1310, 294, 300, 1389, 11, 264, 7372, 393, 611, 4813, 264, 544, 3997, 3109, 13], "temperature": 0.0, "avg_logprob": -0.1989179904644306, "compression_ratio": 1.6755725190839694, "no_speech_prob": 2.212504477938637e-05}, {"id": 179, "seek": 63640, "start": 656.4, "end": 660.4, "text": " And then it's just, like, having the best of both worlds, I guess.", "tokens": [400, 550, 309, 311, 445, 11, 411, 11, 1419, 264, 1151, 295, 1293, 13401, 11, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.1989179904644306, "compression_ratio": 1.6755725190839694, "no_speech_prob": 2.212504477938637e-05}, {"id": 180, "seek": 63640, "start": 660.4, "end": 663.4, "text": " Maybe in a somewhat convoluted way, maybe. Who knows?", "tokens": [2704, 294, 257, 8344, 3754, 2308, 292, 636, 11, 1310, 13, 2102, 3255, 30], "temperature": 0.0, "avg_logprob": -0.1989179904644306, "compression_ratio": 1.6755725190839694, "no_speech_prob": 2.212504477938637e-05}, {"id": 181, "seek": 63640, "start": 663.4, "end": 664.4, "text": " Mm-hmm. Mm-hmm.", "tokens": [8266, 12, 10250, 13, 8266, 12, 10250, 13], "temperature": 0.0, "avg_logprob": -0.1989179904644306, "compression_ratio": 1.6755725190839694, "no_speech_prob": 2.212504477938637e-05}, {"id": 182, "seek": 66440, "start": 664.4, "end": 667.4, "text": " But yeah, I think I'm looking for all those.", "tokens": [583, 1338, 11, 286, 519, 286, 478, 1237, 337, 439, 729, 13], "temperature": 0.0, "avg_logprob": -0.1961142903282529, "compression_ratio": 1.6428571428571428, "no_speech_prob": 6.961945473449305e-06}, {"id": 183, "seek": 66440, "start": 667.4, "end": 671.4, "text": " So, description, examples, philosophy.", "tokens": [407, 11, 3855, 11, 5110, 11, 10675, 13], "temperature": 0.0, "avg_logprob": -0.1961142903282529, "compression_ratio": 1.6428571428571428, "no_speech_prob": 6.961945473449305e-06}, {"id": 184, "seek": 66440, "start": 671.4, "end": 677.4, "text": " But yeah, description of the APIs, and how to use those,", "tokens": [583, 1338, 11, 3855, 295, 264, 21445, 11, 293, 577, 281, 764, 729, 11], "temperature": 0.0, "avg_logprob": -0.1961142903282529, "compression_ratio": 1.6428571428571428, "no_speech_prob": 6.961945473449305e-06}, {"id": 185, "seek": 66440, "start": 677.4, "end": 681.4, "text": " and how to use them together through a guide or through examples.", "tokens": [293, 577, 281, 764, 552, 1214, 807, 257, 5934, 420, 807, 5110, 13], "temperature": 0.0, "avg_logprob": -0.1961142903282529, "compression_ratio": 1.6428571428571428, "no_speech_prob": 6.961945473449305e-06}, {"id": 186, "seek": 66440, "start": 681.4, "end": 684.4, "text": " That's the kind of things that I'm looking for.", "tokens": [663, 311, 264, 733, 295, 721, 300, 286, 478, 1237, 337, 13], "temperature": 0.0, "avg_logprob": -0.1961142903282529, "compression_ratio": 1.6428571428571428, "no_speech_prob": 6.961945473449305e-06}, {"id": 187, "seek": 66440, "start": 684.4, "end": 688.4, "text": " Right. Yeah, that resonates with me as well.", "tokens": [1779, 13, 865, 11, 300, 41051, 365, 385, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1961142903282529, "compression_ratio": 1.6428571428571428, "no_speech_prob": 6.961945473449305e-06}, {"id": 188, "seek": 68840, "start": 688.4, "end": 694.4, "text": " I would say, when I go to open up the package documentation for an Elm package,", "tokens": [286, 576, 584, 11, 562, 286, 352, 281, 1269, 493, 264, 7372, 14333, 337, 364, 2699, 76, 7372, 11], "temperature": 0.0, "avg_logprob": -0.21083666977373142, "compression_ratio": 1.5260663507109005, "no_speech_prob": 9.609239350538701e-05}, {"id": 189, "seek": 68840, "start": 694.4, "end": 699.4, "text": " as you say, often there will be a few alternatives, and they have the same name.", "tokens": [382, 291, 584, 11, 2049, 456, 486, 312, 257, 1326, 20478, 11, 293, 436, 362, 264, 912, 1315, 13], "temperature": 0.0, "avg_logprob": -0.21083666977373142, "compression_ratio": 1.5260663507109005, "no_speech_prob": 9.609239350538701e-05}, {"id": 190, "seek": 68840, "start": 699.4, "end": 707.4, "text": " They're all called ElmGraphQL, or they're all called, you know, ElmAnyDict,", "tokens": [814, 434, 439, 1219, 2699, 76, 38, 2662, 13695, 11, 420, 436, 434, 439, 1219, 11, 291, 458, 11, 2699, 76, 29647, 35, 985, 11], "temperature": 0.0, "avg_logprob": -0.21083666977373142, "compression_ratio": 1.5260663507109005, "no_speech_prob": 9.609239350538701e-05}, {"id": 191, "seek": 68840, "start": 707.4, "end": 710.4, "text": " or, you know, ElmMarkdown, or whatever.", "tokens": [420, 11, 291, 458, 11, 2699, 76, 15168, 5093, 11, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.21083666977373142, "compression_ratio": 1.5260663507109005, "no_speech_prob": 9.609239350538701e-05}, {"id": 192, "seek": 68840, "start": 710.4, "end": 713.4, "text": " And it's like, okay, well, so I want to know.", "tokens": [400, 309, 311, 411, 11, 1392, 11, 731, 11, 370, 286, 528, 281, 458, 13], "temperature": 0.0, "avg_logprob": -0.21083666977373142, "compression_ratio": 1.5260663507109005, "no_speech_prob": 9.609239350538701e-05}, {"id": 193, "seek": 71340, "start": 713.4, "end": 720.4, "text": " The first thing I'm trying to find out as fast as possible is, does this,", "tokens": [440, 700, 551, 286, 478, 1382, 281, 915, 484, 382, 2370, 382, 1944, 307, 11, 775, 341, 11], "temperature": 0.0, "avg_logprob": -0.1694708831550539, "compression_ratio": 1.653225806451613, "no_speech_prob": 2.014503479585983e-05}, {"id": 194, "seek": 71340, "start": 720.4, "end": 724.4, "text": " number one, can I use this for the problem I'm trying to solve?", "tokens": [1230, 472, 11, 393, 286, 764, 341, 337, 264, 1154, 286, 478, 1382, 281, 5039, 30], "temperature": 0.0, "avg_logprob": -0.1694708831550539, "compression_ratio": 1.653225806451613, "no_speech_prob": 2.014503479585983e-05}, {"id": 195, "seek": 71340, "start": 724.4, "end": 729.4, "text": " Because if I can't, I don't even want to consider if I like it,", "tokens": [1436, 498, 286, 393, 380, 11, 286, 500, 380, 754, 528, 281, 1949, 498, 286, 411, 309, 11], "temperature": 0.0, "avg_logprob": -0.1694708831550539, "compression_ratio": 1.653225806451613, "no_speech_prob": 2.014503479585983e-05}, {"id": 196, "seek": 71340, "start": 729.4, "end": 731.4, "text": " or if I like its trade-offs.", "tokens": [420, 498, 286, 411, 1080, 4923, 12, 19231, 13], "temperature": 0.0, "avg_logprob": -0.1694708831550539, "compression_ratio": 1.653225806451613, "no_speech_prob": 2.014503479585983e-05}, {"id": 197, "seek": 71340, "start": 731.4, "end": 734.4, "text": " Just like, what problem can I use this to solve?", "tokens": [1449, 411, 11, 437, 1154, 393, 286, 764, 341, 281, 5039, 30], "temperature": 0.0, "avg_logprob": -0.1694708831550539, "compression_ratio": 1.653225806451613, "no_speech_prob": 2.014503479585983e-05}, {"id": 198, "seek": 71340, "start": 734.4, "end": 737.4, "text": " Is this a faster dict? No, this is ElmGraphQL.", "tokens": [1119, 341, 257, 4663, 12569, 30, 883, 11, 341, 307, 2699, 76, 38, 2662, 13695, 13], "temperature": 0.0, "avg_logprob": -0.1694708831550539, "compression_ratio": 1.653225806451613, "no_speech_prob": 2.014503479585983e-05}, {"id": 199, "seek": 71340, "start": 737.4, "end": 739.4, "text": " Okay, well, then I'm just going to skip it.", "tokens": [1033, 11, 731, 11, 550, 286, 478, 445, 516, 281, 10023, 309, 13], "temperature": 0.0, "avg_logprob": -0.1694708831550539, "compression_ratio": 1.653225806451613, "no_speech_prob": 2.014503479585983e-05}, {"id": 200, "seek": 71340, "start": 739.4, "end": 742.4, "text": " Right. It better tell you that quickly.", "tokens": [1779, 13, 467, 1101, 980, 291, 300, 2661, 13], "temperature": 0.0, "avg_logprob": -0.1694708831550539, "compression_ratio": 1.653225806451613, "no_speech_prob": 2.014503479585983e-05}, {"id": 201, "seek": 74240, "start": 742.4, "end": 748.4, "text": " And you don't have much of, I mean, I can say this from personal experience,", "tokens": [400, 291, 500, 380, 362, 709, 295, 11, 286, 914, 11, 286, 393, 584, 341, 490, 2973, 1752, 11], "temperature": 0.0, "avg_logprob": -0.20463173730032785, "compression_ratio": 1.5743589743589743, "no_speech_prob": 4.133436959818937e-05}, {"id": 202, "seek": 74240, "start": 748.4, "end": 754.4, "text": " as a reader of docs, you do not have my attention for very long to tell me that.", "tokens": [382, 257, 15149, 295, 45623, 11, 291, 360, 406, 362, 452, 3202, 337, 588, 938, 281, 980, 385, 300, 13], "temperature": 0.0, "avg_logprob": -0.20463173730032785, "compression_ratio": 1.5743589743589743, "no_speech_prob": 4.133436959818937e-05}, {"id": 203, "seek": 74240, "start": 754.4, "end": 761.4, "text": " And if it's like a very long-form description of things that doesn't just,", "tokens": [400, 498, 309, 311, 411, 257, 588, 938, 12, 837, 3855, 295, 721, 300, 1177, 380, 445, 11], "temperature": 0.0, "avg_logprob": -0.20463173730032785, "compression_ratio": 1.5743589743589743, "no_speech_prob": 4.133436959818937e-05}, {"id": 204, "seek": 74240, "start": 761.4, "end": 767.4, "text": " like, right at the top in a topic sentence tell me exactly what it's doing", "tokens": [411, 11, 558, 412, 264, 1192, 294, 257, 4829, 8174, 980, 385, 2293, 437, 309, 311, 884], "temperature": 0.0, "avg_logprob": -0.20463173730032785, "compression_ratio": 1.5743589743589743, "no_speech_prob": 4.133436959818937e-05}, {"id": 205, "seek": 76740, "start": 767.4, "end": 773.4, "text": " and give me information to help me decide whether it's going to help solve my problem.", "tokens": [293, 976, 385, 1589, 281, 854, 385, 4536, 1968, 309, 311, 516, 281, 854, 5039, 452, 1154, 13], "temperature": 0.0, "avg_logprob": -0.19161679194523737, "compression_ratio": 1.5862068965517242, "no_speech_prob": 1.5205740055534989e-05}, {"id": 206, "seek": 76740, "start": 773.4, "end": 776.4, "text": " I might not stick around there.", "tokens": [286, 1062, 406, 2897, 926, 456, 13], "temperature": 0.0, "avg_logprob": -0.19161679194523737, "compression_ratio": 1.5862068965517242, "no_speech_prob": 1.5205740055534989e-05}, {"id": 207, "seek": 76740, "start": 776.4, "end": 781.4, "text": " It's certainly not going to be a good experience looking through that package documentation.", "tokens": [467, 311, 3297, 406, 516, 281, 312, 257, 665, 1752, 1237, 807, 300, 7372, 14333, 13], "temperature": 0.0, "avg_logprob": -0.19161679194523737, "compression_ratio": 1.5862068965517242, "no_speech_prob": 1.5205740055534989e-05}, {"id": 208, "seek": 76740, "start": 781.4, "end": 784.4, "text": " Because that's the first question I want to answer.", "tokens": [1436, 300, 311, 264, 700, 1168, 286, 528, 281, 1867, 13], "temperature": 0.0, "avg_logprob": -0.19161679194523737, "compression_ratio": 1.5862068965517242, "no_speech_prob": 1.5205740055534989e-05}, {"id": 209, "seek": 76740, "start": 784.4, "end": 790.4, "text": " Yeah. The thing is, like, the Elm ecosystem is pretty small for good and bad.", "tokens": [865, 13, 440, 551, 307, 11, 411, 11, 264, 2699, 76, 11311, 307, 1238, 1359, 337, 665, 293, 1578, 13], "temperature": 0.0, "avg_logprob": -0.19161679194523737, "compression_ratio": 1.5862068965517242, "no_speech_prob": 1.5205740055534989e-05}, {"id": 210, "seek": 76740, "start": 790.4, "end": 795.4, "text": " And in this case, like, if you have two alternatives, or even like four,", "tokens": [400, 294, 341, 1389, 11, 411, 11, 498, 291, 362, 732, 20478, 11, 420, 754, 411, 1451, 11], "temperature": 0.0, "avg_logprob": -0.19161679194523737, "compression_ratio": 1.5862068965517242, "no_speech_prob": 1.5205740055534989e-05}, {"id": 211, "seek": 79540, "start": 795.4, "end": 803.4, "text": " like, you can spend a little more time digging whether a specific package works for you.", "tokens": [411, 11, 291, 393, 3496, 257, 707, 544, 565, 17343, 1968, 257, 2685, 7372, 1985, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.19328119614545036, "compression_ratio": 1.561576354679803, "no_speech_prob": 1.0289209967595525e-05}, {"id": 212, "seek": 79540, "start": 803.4, "end": 811.4, "text": " Whereas in JavaScript, like, you have 200 packages for the same thing.", "tokens": [13813, 294, 15778, 11, 411, 11, 291, 362, 2331, 17401, 337, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.19328119614545036, "compression_ratio": 1.561576354679803, "no_speech_prob": 1.0289209967595525e-05}, {"id": 213, "seek": 79540, "start": 811.4, "end": 816.4, "text": " And yeah, you really want to go to the one that strikes you the most.", "tokens": [400, 1338, 11, 291, 534, 528, 281, 352, 281, 264, 472, 300, 16750, 291, 264, 881, 13], "temperature": 0.0, "avg_logprob": -0.19328119614545036, "compression_ratio": 1.561576354679803, "no_speech_prob": 1.0289209967595525e-05}, {"id": 214, "seek": 79540, "start": 816.4, "end": 824.4, "text": " Right. But if it's like a somewhat subtle thing, if it's like, oh, it's a form package,", "tokens": [1779, 13, 583, 498, 309, 311, 411, 257, 8344, 13743, 551, 11, 498, 309, 311, 411, 11, 1954, 11, 309, 311, 257, 1254, 7372, 11], "temperature": 0.0, "avg_logprob": -0.19328119614545036, "compression_ratio": 1.561576354679803, "no_speech_prob": 1.0289209967595525e-05}, {"id": 215, "seek": 82440, "start": 824.4, "end": 832.4, "text": " and I look at the readme, and I don't understand, like, what are the limitations?", "tokens": [293, 286, 574, 412, 264, 1401, 1398, 11, 293, 286, 500, 380, 1223, 11, 411, 11, 437, 366, 264, 15705, 30], "temperature": 0.0, "avg_logprob": -0.18908169738247863, "compression_ratio": 1.7946428571428572, "no_speech_prob": 5.826504639117047e-05}, {"id": 216, "seek": 82440, "start": 832.4, "end": 836.4, "text": " What are the, like, what are the things I can and can't do with this?", "tokens": [708, 366, 264, 11, 411, 11, 437, 366, 264, 721, 286, 393, 293, 393, 380, 360, 365, 341, 30], "temperature": 0.0, "avg_logprob": -0.18908169738247863, "compression_ratio": 1.7946428571428572, "no_speech_prob": 5.826504639117047e-05}, {"id": 217, "seek": 82440, "start": 836.4, "end": 841.4, "text": " Then I'm not going to, and if I can't, like, find a live demo somewhere,", "tokens": [1396, 286, 478, 406, 516, 281, 11, 293, 498, 286, 393, 380, 11, 411, 11, 915, 257, 1621, 10723, 4079, 11], "temperature": 0.0, "avg_logprob": -0.18908169738247863, "compression_ratio": 1.7946428571428572, "no_speech_prob": 5.826504639117047e-05}, {"id": 218, "seek": 82440, "start": 841.4, "end": 844.4, "text": " then I might not dig into that much further,", "tokens": [550, 286, 1062, 406, 2528, 666, 300, 709, 3052, 11], "temperature": 0.0, "avg_logprob": -0.18908169738247863, "compression_ratio": 1.7946428571428572, "no_speech_prob": 5.826504639117047e-05}, {"id": 219, "seek": 82440, "start": 844.4, "end": 847.4, "text": " because I'm going to end up going to something else.", "tokens": [570, 286, 478, 516, 281, 917, 493, 516, 281, 746, 1646, 13], "temperature": 0.0, "avg_logprob": -0.18908169738247863, "compression_ratio": 1.7946428571428572, "no_speech_prob": 5.826504639117047e-05}, {"id": 220, "seek": 82440, "start": 847.4, "end": 850.4, "text": " And it's going to have this mystique that I'm not going to want to approach it.", "tokens": [400, 309, 311, 516, 281, 362, 341, 9111, 1925, 300, 286, 478, 406, 516, 281, 528, 281, 3109, 309, 13], "temperature": 0.0, "avg_logprob": -0.18908169738247863, "compression_ratio": 1.7946428571428572, "no_speech_prob": 5.826504639117047e-05}, {"id": 221, "seek": 85040, "start": 850.4, "end": 855.4, "text": " Yeah, what you say is that you want to know about the limitations of a package.", "tokens": [865, 11, 437, 291, 584, 307, 300, 291, 528, 281, 458, 466, 264, 15705, 295, 257, 7372, 13], "temperature": 0.0, "avg_logprob": -0.2245241403579712, "compression_ratio": 1.5622317596566524, "no_speech_prob": 6.048790510249091e-06}, {"id": 222, "seek": 85040, "start": 855.4, "end": 862.4, "text": " You want the package author to be honest about something, even if it sells not as well.", "tokens": [509, 528, 264, 7372, 3793, 281, 312, 3245, 466, 746, 11, 754, 498, 309, 20897, 406, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.2245241403579712, "compression_ratio": 1.5622317596566524, "no_speech_prob": 6.048790510249091e-06}, {"id": 223, "seek": 85040, "start": 862.4, "end": 863.4, "text": " Yeah, totally.", "tokens": [865, 11, 3879, 13], "temperature": 0.0, "avg_logprob": -0.2245241403579712, "compression_ratio": 1.5622317596566524, "no_speech_prob": 6.048790510249091e-06}, {"id": 224, "seek": 85040, "start": 863.4, "end": 868.4, "text": " Which is okay, because we're usually not getting paid for open source work anyway.", "tokens": [3013, 307, 1392, 11, 570, 321, 434, 2673, 406, 1242, 4835, 337, 1269, 4009, 589, 4033, 13], "temperature": 0.0, "avg_logprob": -0.2245241403579712, "compression_ratio": 1.5622317596566524, "no_speech_prob": 6.048790510249091e-06}, {"id": 225, "seek": 85040, "start": 868.4, "end": 874.4, "text": " Yeah, I was just having some interesting discussions with Ryan,", "tokens": [865, 11, 286, 390, 445, 1419, 512, 1880, 11088, 365, 9116, 11], "temperature": 0.0, "avg_logprob": -0.2245241403579712, "compression_ratio": 1.5622317596566524, "no_speech_prob": 6.048790510249091e-06}, {"id": 226, "seek": 85040, "start": 874.4, "end": 878.4, "text": " the author of Elmland and Elm SPA,", "tokens": [264, 3793, 295, 2699, 76, 1661, 293, 2699, 76, 318, 10297, 11], "temperature": 0.0, "avg_logprob": -0.2245241403579712, "compression_ratio": 1.5622317596566524, "no_speech_prob": 6.048790510249091e-06}, {"id": 227, "seek": 87840, "start": 878.4, "end": 883.4, "text": " and we were kind of talking about, you know, Elmland or Elm SPA.", "tokens": [293, 321, 645, 733, 295, 1417, 466, 11, 291, 458, 11, 2699, 76, 1661, 420, 2699, 76, 318, 10297, 13], "temperature": 0.0, "avg_logprob": -0.15084634636932948, "compression_ratio": 1.6485148514851484, "no_speech_prob": 9.368409337184858e-06}, {"id": 228, "seek": 87840, "start": 883.4, "end": 887.4, "text": " Elmland is sort of a new version of Elm SPA versus Elm Pages,", "tokens": [2699, 76, 1661, 307, 1333, 295, 257, 777, 3037, 295, 2699, 76, 318, 10297, 5717, 2699, 76, 430, 1660, 11], "temperature": 0.0, "avg_logprob": -0.15084634636932948, "compression_ratio": 1.6485148514851484, "no_speech_prob": 9.368409337184858e-06}, {"id": 229, "seek": 87840, "start": 887.4, "end": 891.4, "text": " because v3 is sort of blurring the lines a little bit,", "tokens": [570, 371, 18, 307, 1333, 295, 14257, 2937, 264, 3876, 257, 707, 857, 11], "temperature": 0.0, "avg_logprob": -0.15084634636932948, "compression_ratio": 1.6485148514851484, "no_speech_prob": 9.368409337184858e-06}, {"id": 230, "seek": 87840, "start": 891.4, "end": 896.4, "text": " because with Elm Pages v2, it was a much more narrowly scoped tool", "tokens": [570, 365, 2699, 76, 430, 1660, 371, 17, 11, 309, 390, 257, 709, 544, 9432, 356, 795, 27277, 2290], "temperature": 0.0, "avg_logprob": -0.15084634636932948, "compression_ratio": 1.6485148514851484, "no_speech_prob": 9.368409337184858e-06}, {"id": 231, "seek": 87840, "start": 896.4, "end": 899.4, "text": " that was generating static sites.", "tokens": [300, 390, 17746, 13437, 7533, 13], "temperature": 0.0, "avg_logprob": -0.15084634636932948, "compression_ratio": 1.6485148514851484, "no_speech_prob": 9.368409337184858e-06}, {"id": 232, "seek": 87840, "start": 899.4, "end": 903.4, "text": " And with v3, you know, a site with authentication,", "tokens": [400, 365, 371, 18, 11, 291, 458, 11, 257, 3621, 365, 26643, 11], "temperature": 0.0, "avg_logprob": -0.15084634636932948, "compression_ratio": 1.6485148514851484, "no_speech_prob": 9.368409337184858e-06}, {"id": 233, "seek": 90340, "start": 903.4, "end": 909.4, "text": " you know, a site with user-specific dynamic content", "tokens": [291, 458, 11, 257, 3621, 365, 4195, 12, 29258, 8546, 2701], "temperature": 0.0, "avg_logprob": -0.19093072982061476, "compression_ratio": 1.4512820512820512, "no_speech_prob": 9.665879588283133e-06}, {"id": 234, "seek": 90340, "start": 909.4, "end": 912.4, "text": " is now a use case that Elm Pages v3 supports.", "tokens": [307, 586, 257, 764, 1389, 300, 2699, 76, 430, 1660, 371, 18, 9346, 13], "temperature": 0.0, "avg_logprob": -0.19093072982061476, "compression_ratio": 1.4512820512820512, "no_speech_prob": 9.665879588283133e-06}, {"id": 235, "seek": 90340, "start": 912.4, "end": 914.4, "text": " So it starts to get blurry.", "tokens": [407, 309, 3719, 281, 483, 37644, 13], "temperature": 0.0, "avg_logprob": -0.19093072982061476, "compression_ratio": 1.4512820512820512, "no_speech_prob": 9.665879588283133e-06}, {"id": 236, "seek": 90340, "start": 914.4, "end": 920.4, "text": " But so I tried really, it took a lot of thought actually,", "tokens": [583, 370, 286, 3031, 534, 11, 309, 1890, 257, 688, 295, 1194, 767, 11], "temperature": 0.0, "avg_logprob": -0.19093072982061476, "compression_ratio": 1.4512820512820512, "no_speech_prob": 9.665879588283133e-06}, {"id": 237, "seek": 90340, "start": 920.4, "end": 929.4, "text": " to try to concisely summarize what is it that would make something not a good fit for Elm Pages v3.", "tokens": [281, 853, 281, 1588, 271, 736, 20858, 437, 307, 309, 300, 576, 652, 746, 406, 257, 665, 3318, 337, 2699, 76, 430, 1660, 371, 18, 13], "temperature": 0.0, "avg_logprob": -0.19093072982061476, "compression_ratio": 1.4512820512820512, "no_speech_prob": 9.665879588283133e-06}, {"id": 238, "seek": 92940, "start": 929.4, "end": 933.4, "text": " And what I finally came up with is like,", "tokens": [400, 437, 286, 2721, 1361, 493, 365, 307, 411, 11], "temperature": 0.0, "avg_logprob": -0.15398175248475832, "compression_ratio": 1.6963562753036436, "no_speech_prob": 8.013247679627966e-06}, {"id": 239, "seek": 92940, "start": 933.4, "end": 938.4, "text": " well, there's this sort of architectural decision that you're making by using Elm Pages v3,", "tokens": [731, 11, 456, 311, 341, 1333, 295, 26621, 3537, 300, 291, 434, 1455, 538, 1228, 2699, 76, 430, 1660, 371, 18, 11], "temperature": 0.0, "avg_logprob": -0.15398175248475832, "compression_ratio": 1.6963562753036436, "no_speech_prob": 8.013247679627966e-06}, {"id": 240, "seek": 92940, "start": 938.4, "end": 945.4, "text": " which is that I would like to build an application which communicates with an Elm backend.", "tokens": [597, 307, 300, 286, 576, 411, 281, 1322, 364, 3861, 597, 3363, 1024, 365, 364, 2699, 76, 38087, 13], "temperature": 0.0, "avg_logprob": -0.15398175248475832, "compression_ratio": 1.6963562753036436, "no_speech_prob": 8.013247679627966e-06}, {"id": 241, "seek": 92940, "start": 945.4, "end": 950.4, "text": " That backend could be your build server as you generate your static pages,", "tokens": [663, 38087, 727, 312, 428, 1322, 7154, 382, 291, 8460, 428, 13437, 7183, 11], "temperature": 0.0, "avg_logprob": -0.15398175248475832, "compression_ratio": 1.6963562753036436, "no_speech_prob": 8.013247679627966e-06}, {"id": 242, "seek": 92940, "start": 950.4, "end": 954.4, "text": " or it could be a traditional server, or it could be a serverless function.", "tokens": [420, 309, 727, 312, 257, 5164, 7154, 11, 420, 309, 727, 312, 257, 7154, 1832, 2445, 13], "temperature": 0.0, "avg_logprob": -0.15398175248475832, "compression_ratio": 1.6963562753036436, "no_speech_prob": 8.013247679627966e-06}, {"id": 243, "seek": 92940, "start": 954.4, "end": 958.4, "text": " But there's some sort of Elm backend context,", "tokens": [583, 456, 311, 512, 1333, 295, 2699, 76, 38087, 4319, 11], "temperature": 0.0, "avg_logprob": -0.15398175248475832, "compression_ratio": 1.6963562753036436, "no_speech_prob": 8.013247679627966e-06}, {"id": 244, "seek": 95840, "start": 958.4, "end": 960.4, "text": " and every time you navigate to a page,", "tokens": [293, 633, 565, 291, 12350, 281, 257, 3028, 11], "temperature": 0.0, "avg_logprob": -0.16097321333708586, "compression_ratio": 1.657370517928287, "no_speech_prob": 1.9222861737944186e-05}, {"id": 245, "seek": 95840, "start": 960.4, "end": 964.4, "text": " it is communicating with that Elm backend to resolve data", "tokens": [309, 307, 17559, 365, 300, 2699, 76, 38087, 281, 14151, 1412], "temperature": 0.0, "avg_logprob": -0.16097321333708586, "compression_ratio": 1.657370517928287, "no_speech_prob": 1.9222861737944186e-05}, {"id": 246, "seek": 95840, "start": 964.4, "end": 968.4, "text": " and then sort of bootstrap the page with that data.", "tokens": [293, 550, 1333, 295, 11450, 372, 4007, 264, 3028, 365, 300, 1412, 13], "temperature": 0.0, "avg_logprob": -0.16097321333708586, "compression_ratio": 1.657370517928287, "no_speech_prob": 1.9222861737944186e-05}, {"id": 247, "seek": 95840, "start": 968.4, "end": 972.4, "text": " That, I believe, is a very compelling pattern,", "tokens": [663, 11, 286, 1697, 11, 307, 257, 588, 20050, 5102, 11], "temperature": 0.0, "avg_logprob": -0.16097321333708586, "compression_ratio": 1.657370517928287, "no_speech_prob": 1.9222861737944186e-05}, {"id": 248, "seek": 95840, "start": 972.4, "end": 975.4, "text": " but that's a big architectural decision.", "tokens": [457, 300, 311, 257, 955, 26621, 3537, 13], "temperature": 0.0, "avg_logprob": -0.16097321333708586, "compression_ratio": 1.657370517928287, "no_speech_prob": 1.9222861737944186e-05}, {"id": 249, "seek": 95840, "start": 975.4, "end": 982.4, "text": " And I think that it's a compelling story that is a very strong way to build an application.", "tokens": [400, 286, 519, 300, 309, 311, 257, 20050, 1657, 300, 307, 257, 588, 2068, 636, 281, 1322, 364, 3861, 13], "temperature": 0.0, "avg_logprob": -0.16097321333708586, "compression_ratio": 1.657370517928287, "no_speech_prob": 1.9222861737944186e-05}, {"id": 250, "seek": 95840, "start": 982.4, "end": 987.4, "text": " But there are definitely certain clear-cut cases where it's not going to be a good fit.", "tokens": [583, 456, 366, 2138, 1629, 1850, 12, 6672, 3331, 689, 309, 311, 406, 516, 281, 312, 257, 665, 3318, 13], "temperature": 0.0, "avg_logprob": -0.16097321333708586, "compression_ratio": 1.657370517928287, "no_speech_prob": 1.9222861737944186e-05}, {"id": 251, "seek": 98740, "start": 987.4, "end": 991.4, "text": " For example, if you're building a one-screen game,", "tokens": [1171, 1365, 11, 498, 291, 434, 2390, 257, 472, 12, 12439, 1216, 11], "temperature": 0.0, "avg_logprob": -0.18007512362498157, "compression_ratio": 1.619607843137255, "no_speech_prob": 6.240769835130777e-06}, {"id": 252, "seek": 98740, "start": 991.4, "end": 995.4, "text": " then that set of features isn't going to really help you with that.", "tokens": [550, 300, 992, 295, 4122, 1943, 380, 516, 281, 534, 854, 291, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.18007512362498157, "compression_ratio": 1.619607843137255, "no_speech_prob": 6.240769835130777e-06}, {"id": 253, "seek": 98740, "start": 995.4, "end": 1003.4, "text": " And loading textures and things like that is not what the Elm Pages backend task abstraction is designed for.", "tokens": [400, 15114, 24501, 293, 721, 411, 300, 307, 406, 437, 264, 2699, 76, 430, 1660, 38087, 5633, 37765, 307, 4761, 337, 13], "temperature": 0.0, "avg_logprob": -0.18007512362498157, "compression_ratio": 1.619607843137255, "no_speech_prob": 6.240769835130777e-06}, {"id": 254, "seek": 98740, "start": 1003.4, "end": 1008.4, "text": " It's not good for going off for 100 seconds and loading something.", "tokens": [467, 311, 406, 665, 337, 516, 766, 337, 2319, 3949, 293, 15114, 746, 13], "temperature": 0.0, "avg_logprob": -0.18007512362498157, "compression_ratio": 1.619607843137255, "no_speech_prob": 6.240769835130777e-06}, {"id": 255, "seek": 98740, "start": 1008.4, "end": 1011.4, "text": " You want that done asynchronously in the background.", "tokens": [509, 528, 300, 1096, 42642, 5098, 294, 264, 3678, 13], "temperature": 0.0, "avg_logprob": -0.18007512362498157, "compression_ratio": 1.619607843137255, "no_speech_prob": 6.240769835130777e-06}, {"id": 256, "seek": 98740, "start": 1011.4, "end": 1015.4, "text": " It doesn't mean you can't use it, but it's not optimized for it,", "tokens": [467, 1177, 380, 914, 291, 393, 380, 764, 309, 11, 457, 309, 311, 406, 26941, 337, 309, 11], "temperature": 0.0, "avg_logprob": -0.18007512362498157, "compression_ratio": 1.619607843137255, "no_speech_prob": 6.240769835130777e-06}, {"id": 257, "seek": 101540, "start": 1015.4, "end": 1019.4, "text": " it doesn't really need the features that Elm Pages v3 gives you.", "tokens": [309, 1177, 380, 534, 643, 264, 4122, 300, 2699, 76, 430, 1660, 371, 18, 2709, 291, 13], "temperature": 0.0, "avg_logprob": -0.2221257009623963, "compression_ratio": 1.4371859296482412, "no_speech_prob": 2.668736306077335e-05}, {"id": 258, "seek": 101540, "start": 1019.4, "end": 1021.4, "text": " Yes, exactly.", "tokens": [1079, 11, 2293, 13], "temperature": 0.0, "avg_logprob": -0.2221257009623963, "compression_ratio": 1.4371859296482412, "no_speech_prob": 2.668736306077335e-05}, {"id": 259, "seek": 101540, "start": 1021.4, "end": 1025.4, "text": " And similarly, you can use that rule of thumb,", "tokens": [400, 14138, 11, 291, 393, 764, 300, 4978, 295, 9298, 11], "temperature": 0.0, "avg_logprob": -0.2221257009623963, "compression_ratio": 1.4371859296482412, "no_speech_prob": 2.668736306077335e-05}, {"id": 260, "seek": 101540, "start": 1025.4, "end": 1030.4, "text": " is this feature set serving my needs for the use case I'm building for?", "tokens": [307, 341, 4111, 992, 8148, 452, 2203, 337, 264, 764, 1389, 286, 478, 2390, 337, 30], "temperature": 0.0, "avg_logprob": -0.2221257009623963, "compression_ratio": 1.4371859296482412, "no_speech_prob": 2.668736306077335e-05}, {"id": 261, "seek": 101540, "start": 1030.4, "end": 1035.4, "text": " And do I want to make this architectural decision?", "tokens": [400, 360, 286, 528, 281, 652, 341, 26621, 3537, 30], "temperature": 0.0, "avg_logprob": -0.2221257009623963, "compression_ratio": 1.4371859296482412, "no_speech_prob": 2.668736306077335e-05}, {"id": 262, "seek": 101540, "start": 1035.4, "end": 1037.4, "text": " So that's what I finally realized is,", "tokens": [407, 300, 311, 437, 286, 2721, 5334, 307, 11], "temperature": 0.0, "avg_logprob": -0.2221257009623963, "compression_ratio": 1.4371859296482412, "no_speech_prob": 2.668736306077335e-05}, {"id": 263, "seek": 103740, "start": 1037.4, "end": 1045.4, "text": " OK, a lot of the more dynamic apps with authentication and things like that,", "tokens": [2264, 11, 257, 688, 295, 264, 544, 8546, 7733, 365, 26643, 293, 721, 411, 300, 11], "temperature": 0.0, "avg_logprob": -0.20355421997780024, "compression_ratio": 1.5311004784688995, "no_speech_prob": 7.030567940091714e-05}, {"id": 264, "seek": 103740, "start": 1045.4, "end": 1049.4, "text": " you could choose Elm Land or Elm Pages.", "tokens": [291, 727, 2826, 2699, 76, 6607, 420, 2699, 76, 430, 1660, 13], "temperature": 0.0, "avg_logprob": -0.20355421997780024, "compression_ratio": 1.5311004784688995, "no_speech_prob": 7.030567940091714e-05}, {"id": 265, "seek": 103740, "start": 1049.4, "end": 1053.4, "text": " But the differentiator is, do I want to use this architecture?", "tokens": [583, 264, 27372, 1639, 307, 11, 360, 286, 528, 281, 764, 341, 9482, 30], "temperature": 0.0, "avg_logprob": -0.20355421997780024, "compression_ratio": 1.5311004784688995, "no_speech_prob": 7.030567940091714e-05}, {"id": 266, "seek": 103740, "start": 1053.4, "end": 1056.4, "text": " Because there are trade-offs that are associated with that.", "tokens": [1436, 456, 366, 4923, 12, 19231, 300, 366, 6615, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.20355421997780024, "compression_ratio": 1.5311004784688995, "no_speech_prob": 7.030567940091714e-05}, {"id": 267, "seek": 103740, "start": 1056.4, "end": 1063.4, "text": " Do you want to go all-in on using things that having a backend allows you to do?", "tokens": [1144, 291, 528, 281, 352, 439, 12, 259, 322, 1228, 721, 300, 1419, 257, 38087, 4045, 291, 281, 360, 30], "temperature": 0.0, "avg_logprob": -0.20355421997780024, "compression_ratio": 1.5311004784688995, "no_speech_prob": 7.030567940091714e-05}, {"id": 268, "seek": 106340, "start": 1063.4, "end": 1070.4, "text": " Cookie-based authentication and being able to do server-level redirects", "tokens": [42011, 12, 6032, 26643, 293, 885, 1075, 281, 360, 7154, 12, 12418, 29066, 82], "temperature": 0.0, "avg_logprob": -0.17512782236163535, "compression_ratio": 1.6570048309178744, "no_speech_prob": 5.475486977957189e-05}, {"id": 269, "seek": 106340, "start": 1070.4, "end": 1076.4, "text": " and being able to submit form data and handle that in the same context", "tokens": [293, 885, 1075, 281, 10315, 1254, 1412, 293, 4813, 300, 294, 264, 912, 4319], "temperature": 0.0, "avg_logprob": -0.17512782236163535, "compression_ratio": 1.6570048309178744, "no_speech_prob": 5.475486977957189e-05}, {"id": 270, "seek": 106340, "start": 1076.4, "end": 1078.4, "text": " using the form API.", "tokens": [1228, 264, 1254, 9362, 13], "temperature": 0.0, "avg_logprob": -0.17512782236163535, "compression_ratio": 1.6570048309178744, "no_speech_prob": 5.475486977957189e-05}, {"id": 271, "seek": 106340, "start": 1078.4, "end": 1082.4, "text": " If you want to use those patterns in that architecture,", "tokens": [759, 291, 528, 281, 764, 729, 8294, 294, 300, 9482, 11], "temperature": 0.0, "avg_logprob": -0.17512782236163535, "compression_ratio": 1.6570048309178744, "no_speech_prob": 5.475486977957189e-05}, {"id": 272, "seek": 106340, "start": 1082.4, "end": 1084.4, "text": " then it's going to be a good fit.", "tokens": [550, 309, 311, 516, 281, 312, 257, 665, 3318, 13], "temperature": 0.0, "avg_logprob": -0.17512782236163535, "compression_ratio": 1.6570048309178744, "no_speech_prob": 5.475486977957189e-05}, {"id": 273, "seek": 106340, "start": 1084.4, "end": 1087.4, "text": " But not everybody is going to want to use that architecture.", "tokens": [583, 406, 2201, 307, 516, 281, 528, 281, 764, 300, 9482, 13], "temperature": 0.0, "avg_logprob": -0.17512782236163535, "compression_ratio": 1.6570048309178744, "no_speech_prob": 5.475486977957189e-05}, {"id": 274, "seek": 106340, "start": 1087.4, "end": 1089.4, "text": " So that's the differentiator.", "tokens": [407, 300, 311, 264, 27372, 1639, 13], "temperature": 0.0, "avg_logprob": -0.17512782236163535, "compression_ratio": 1.6570048309178744, "no_speech_prob": 5.475486977957189e-05}, {"id": 275, "seek": 108940, "start": 1089.4, "end": 1093.4, "text": " And it's not like one of them is good or bad,", "tokens": [400, 309, 311, 406, 411, 472, 295, 552, 307, 665, 420, 1578, 11], "temperature": 0.0, "avg_logprob": -0.18429438273111978, "compression_ratio": 1.8780487804878048, "no_speech_prob": 9.080387826543301e-06}, {"id": 276, "seek": 108940, "start": 1093.4, "end": 1095.4, "text": " but you need to tell people very clearly,", "tokens": [457, 291, 643, 281, 980, 561, 588, 4448, 11], "temperature": 0.0, "avg_logprob": -0.18429438273111978, "compression_ratio": 1.8780487804878048, "no_speech_prob": 9.080387826543301e-06}, {"id": 277, "seek": 108940, "start": 1095.4, "end": 1098.4, "text": " you need to help them make that decision.", "tokens": [291, 643, 281, 854, 552, 652, 300, 3537, 13], "temperature": 0.0, "avg_logprob": -0.18429438273111978, "compression_ratio": 1.8780487804878048, "no_speech_prob": 9.080387826543301e-06}, {"id": 278, "seek": 108940, "start": 1098.4, "end": 1102.4, "text": " Because you're the author of the tool, you have all of this context,", "tokens": [1436, 291, 434, 264, 3793, 295, 264, 2290, 11, 291, 362, 439, 295, 341, 4319, 11], "temperature": 0.0, "avg_logprob": -0.18429438273111978, "compression_ratio": 1.8780487804878048, "no_speech_prob": 9.080387826543301e-06}, {"id": 279, "seek": 108940, "start": 1102.4, "end": 1107.4, "text": " and somehow you need to distill that down to the relevant information", "tokens": [293, 6063, 291, 643, 281, 42923, 300, 760, 281, 264, 7340, 1589], "temperature": 0.0, "avg_logprob": -0.18429438273111978, "compression_ratio": 1.8780487804878048, "no_speech_prob": 9.080387826543301e-06}, {"id": 280, "seek": 108940, "start": 1107.4, "end": 1108.4, "text": " that someone needs to make a decision.", "tokens": [300, 1580, 2203, 281, 652, 257, 3537, 13], "temperature": 0.0, "avg_logprob": -0.18429438273111978, "compression_ratio": 1.8780487804878048, "no_speech_prob": 9.080387826543301e-06}, {"id": 281, "seek": 108940, "start": 1108.4, "end": 1110.4, "text": " Because that's what they're trying to do.", "tokens": [1436, 300, 311, 437, 436, 434, 1382, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.18429438273111978, "compression_ratio": 1.8780487804878048, "no_speech_prob": 9.080387826543301e-06}, {"id": 282, "seek": 108940, "start": 1110.4, "end": 1113.4, "text": " They navigate to your tool, and the first thing they're trying to do", "tokens": [814, 12350, 281, 428, 2290, 11, 293, 264, 700, 551, 436, 434, 1382, 281, 360], "temperature": 0.0, "avg_logprob": -0.18429438273111978, "compression_ratio": 1.8780487804878048, "no_speech_prob": 9.080387826543301e-06}, {"id": 283, "seek": 108940, "start": 1113.4, "end": 1116.4, "text": " is make a decision, is this relevant to me?", "tokens": [307, 652, 257, 3537, 11, 307, 341, 7340, 281, 385, 30], "temperature": 0.0, "avg_logprob": -0.18429438273111978, "compression_ratio": 1.8780487804878048, "no_speech_prob": 9.080387826543301e-06}, {"id": 284, "seek": 111640, "start": 1116.4, "end": 1121.4, "text": " Is this usable? And are there alternatives that would be better?", "tokens": [1119, 341, 29975, 30, 400, 366, 456, 20478, 300, 576, 312, 1101, 30], "temperature": 0.0, "avg_logprob": -0.17763388983093867, "compression_ratio": 1.5564853556485356, "no_speech_prob": 3.7852457808185136e-06}, {"id": 285, "seek": 111640, "start": 1121.4, "end": 1123.4, "text": " So you need to help them make that decision.", "tokens": [407, 291, 643, 281, 854, 552, 652, 300, 3537, 13], "temperature": 0.0, "avg_logprob": -0.17763388983093867, "compression_ratio": 1.5564853556485356, "no_speech_prob": 3.7852457808185136e-06}, {"id": 286, "seek": 111640, "start": 1123.4, "end": 1126.4, "text": " Absolutely. Yep. I think you're completely right.", "tokens": [7021, 13, 7010, 13, 286, 519, 291, 434, 2584, 558, 13], "temperature": 0.0, "avg_logprob": -0.17763388983093867, "compression_ratio": 1.5564853556485356, "no_speech_prob": 3.7852457808185136e-06}, {"id": 287, "seek": 111640, "start": 1126.4, "end": 1131.4, "text": " And then once you've decided that, you probably want to figure out", "tokens": [400, 550, 1564, 291, 600, 3047, 300, 11, 291, 1391, 528, 281, 2573, 484], "temperature": 0.0, "avg_logprob": -0.17763388983093867, "compression_ratio": 1.5564853556485356, "no_speech_prob": 3.7852457808185136e-06}, {"id": 288, "seek": 111640, "start": 1131.4, "end": 1132.4, "text": " how to use it.", "tokens": [577, 281, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.17763388983093867, "compression_ratio": 1.5564853556485356, "no_speech_prob": 3.7852457808185136e-06}, {"id": 289, "seek": 111640, "start": 1132.4, "end": 1140.4, "text": " And again, if you land on a tool, you go to the Elm Review package docs,", "tokens": [400, 797, 11, 498, 291, 2117, 322, 257, 2290, 11, 291, 352, 281, 264, 2699, 76, 19954, 7372, 45623, 11], "temperature": 0.0, "avg_logprob": -0.17763388983093867, "compression_ratio": 1.5564853556485356, "no_speech_prob": 3.7852457808185136e-06}, {"id": 290, "seek": 111640, "start": 1140.4, "end": 1145.4, "text": " you understand what sort of use cases it helps you solve,", "tokens": [291, 1223, 437, 1333, 295, 764, 3331, 309, 3665, 291, 5039, 11], "temperature": 0.0, "avg_logprob": -0.17763388983093867, "compression_ratio": 1.5564853556485356, "no_speech_prob": 3.7852457808185136e-06}, {"id": 291, "seek": 114540, "start": 1145.4, "end": 1147.4, "text": " you decide you want to use it.", "tokens": [291, 4536, 291, 528, 281, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.19777615865071616, "compression_ratio": 1.6036866359447004, "no_speech_prob": 6.108531670179218e-05}, {"id": 292, "seek": 114540, "start": 1147.4, "end": 1151.4, "text": " How do I actually do something, anything, right?", "tokens": [1012, 360, 286, 767, 360, 746, 11, 1340, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.19777615865071616, "compression_ratio": 1.6036866359447004, "no_speech_prob": 6.108531670179218e-05}, {"id": 293, "seek": 114540, "start": 1151.4, "end": 1153.4, "text": " As quickly as possible.", "tokens": [1018, 2661, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.19777615865071616, "compression_ratio": 1.6036866359447004, "no_speech_prob": 6.108531670179218e-05}, {"id": 294, "seek": 114540, "start": 1153.4, "end": 1157.4, "text": " I think of this actually very similarly to how I think about", "tokens": [286, 519, 295, 341, 767, 588, 14138, 281, 577, 286, 519, 466], "temperature": 0.0, "avg_logprob": -0.19777615865071616, "compression_ratio": 1.6036866359447004, "no_speech_prob": 6.108531670179218e-05}, {"id": 295, "seek": 114540, "start": 1157.4, "end": 1162.4, "text": " the coding discipline of do the simplest thing that could possibly work,", "tokens": [264, 17720, 13635, 295, 360, 264, 22811, 551, 300, 727, 6264, 589, 11], "temperature": 0.0, "avg_logprob": -0.19777615865071616, "compression_ratio": 1.6036866359447004, "no_speech_prob": 6.108531670179218e-05}, {"id": 296, "seek": 114540, "start": 1162.4, "end": 1165.4, "text": " or finding the shortest path to green,", "tokens": [420, 5006, 264, 31875, 3100, 281, 3092, 11], "temperature": 0.0, "avg_logprob": -0.19777615865071616, "compression_ratio": 1.6036866359447004, "no_speech_prob": 6.108531670179218e-05}, {"id": 297, "seek": 114540, "start": 1165.4, "end": 1171.4, "text": " and taking small steps to connect things where it's working in between.", "tokens": [293, 1940, 1359, 4439, 281, 1745, 721, 689, 309, 311, 1364, 294, 1296, 13], "temperature": 0.0, "avg_logprob": -0.19777615865071616, "compression_ratio": 1.6036866359447004, "no_speech_prob": 6.108531670179218e-05}, {"id": 298, "seek": 117140, "start": 1171.4, "end": 1175.4, "text": " You don't want a long feedback cycle where it's like,", "tokens": [509, 500, 380, 528, 257, 938, 5824, 6586, 689, 309, 311, 411, 11], "temperature": 0.0, "avg_logprob": -0.20082621140913529, "compression_ratio": 1.8372093023255813, "no_speech_prob": 4.5659126044483855e-06}, {"id": 299, "seek": 117140, "start": 1175.4, "end": 1179.4, "text": " okay, do these 100 steps, then you're all set.", "tokens": [1392, 11, 360, 613, 2319, 4439, 11, 550, 291, 434, 439, 992, 13], "temperature": 0.0, "avg_logprob": -0.20082621140913529, "compression_ratio": 1.8372093023255813, "no_speech_prob": 4.5659126044483855e-06}, {"id": 300, "seek": 117140, "start": 1179.4, "end": 1182.4, "text": " Then you can evaluate whether you like this package or not.", "tokens": [1396, 291, 393, 13059, 1968, 291, 411, 341, 7372, 420, 406, 13], "temperature": 0.0, "avg_logprob": -0.20082621140913529, "compression_ratio": 1.8372093023255813, "no_speech_prob": 4.5659126044483855e-06}, {"id": 301, "seek": 117140, "start": 1182.4, "end": 1186.4, "text": " Then you can evaluate whether you like it,", "tokens": [1396, 291, 393, 13059, 1968, 291, 411, 309, 11], "temperature": 0.0, "avg_logprob": -0.20082621140913529, "compression_ratio": 1.8372093023255813, "no_speech_prob": 4.5659126044483855e-06}, {"id": 302, "seek": 117140, "start": 1186.4, "end": 1189.4, "text": " and then you'll know whether you've done those 100 steps correctly", "tokens": [293, 550, 291, 603, 458, 1968, 291, 600, 1096, 729, 2319, 4439, 8944], "temperature": 0.0, "avg_logprob": -0.20082621140913529, "compression_ratio": 1.8372093023255813, "no_speech_prob": 4.5659126044483855e-06}, {"id": 303, "seek": 117140, "start": 1189.4, "end": 1191.4, "text": " at the end of the 100 steps.", "tokens": [412, 264, 917, 295, 264, 2319, 4439, 13], "temperature": 0.0, "avg_logprob": -0.20082621140913529, "compression_ratio": 1.8372093023255813, "no_speech_prob": 4.5659126044483855e-06}, {"id": 304, "seek": 117140, "start": 1191.4, "end": 1194.4, "text": " Oh, yeah. There's that thing as well. Yeah.", "tokens": [876, 11, 1338, 13, 821, 311, 300, 551, 382, 731, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.20082621140913529, "compression_ratio": 1.8372093023255813, "no_speech_prob": 4.5659126044483855e-06}, {"id": 305, "seek": 117140, "start": 1194.4, "end": 1197.4, "text": " I was still in the evaluating phase of the package,", "tokens": [286, 390, 920, 294, 264, 27479, 5574, 295, 264, 7372, 11], "temperature": 0.0, "avg_logprob": -0.20082621140913529, "compression_ratio": 1.8372093023255813, "no_speech_prob": 4.5659126044483855e-06}, {"id": 306, "seek": 119740, "start": 1197.4, "end": 1203.4, "text": " where you want to know whether it fits your use case well,", "tokens": [689, 291, 528, 281, 458, 1968, 309, 9001, 428, 764, 1389, 731, 11], "temperature": 0.0, "avg_logprob": -0.18015240310528957, "compression_ratio": 1.6040816326530611, "no_speech_prob": 6.962020961509552e-06}, {"id": 307, "seek": 119740, "start": 1203.4, "end": 1206.4, "text": " and whether there are any gotchas with it.", "tokens": [293, 1968, 456, 366, 604, 658, 41299, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.18015240310528957, "compression_ratio": 1.6040816326530611, "no_speech_prob": 6.962020961509552e-06}, {"id": 308, "seek": 119740, "start": 1206.4, "end": 1208.4, "text": " Exactly. Yes.", "tokens": [7587, 13, 1079, 13], "temperature": 0.0, "avg_logprob": -0.18015240310528957, "compression_ratio": 1.6040816326530611, "no_speech_prob": 6.962020961509552e-06}, {"id": 309, "seek": 119740, "start": 1208.4, "end": 1211.4, "text": " That's going to be a super frustrating experience on both accounts,", "tokens": [663, 311, 516, 281, 312, 257, 1687, 16522, 1752, 322, 1293, 9402, 11], "temperature": 0.0, "avg_logprob": -0.18015240310528957, "compression_ratio": 1.6040816326530611, "no_speech_prob": 6.962020961509552e-06}, {"id": 310, "seek": 119740, "start": 1211.4, "end": 1214.4, "text": " where you're holding your breath, am I doing these steps correctly?", "tokens": [689, 291, 434, 5061, 428, 6045, 11, 669, 286, 884, 613, 4439, 8944, 30], "temperature": 0.0, "avg_logprob": -0.18015240310528957, "compression_ratio": 1.6040816326530611, "no_speech_prob": 6.962020961509552e-06}, {"id": 311, "seek": 119740, "start": 1214.4, "end": 1217.4, "text": " You're like, I don't have time to do 100 steps.", "tokens": [509, 434, 411, 11, 286, 500, 380, 362, 565, 281, 360, 2319, 4439, 13], "temperature": 0.0, "avg_logprob": -0.18015240310528957, "compression_ratio": 1.6040816326530611, "no_speech_prob": 6.962020961509552e-06}, {"id": 312, "seek": 119740, "start": 1217.4, "end": 1219.4, "text": " I haven't decided whether to commit to this yet.", "tokens": [286, 2378, 380, 3047, 1968, 281, 5599, 281, 341, 1939, 13], "temperature": 0.0, "avg_logprob": -0.18015240310528957, "compression_ratio": 1.6040816326530611, "no_speech_prob": 6.962020961509552e-06}, {"id": 313, "seek": 119740, "start": 1219.4, "end": 1223.4, "text": " I'm not like, I'm integrating this tool now.", "tokens": [286, 478, 406, 411, 11, 286, 478, 26889, 341, 2290, 586, 13], "temperature": 0.0, "avg_logprob": -0.18015240310528957, "compression_ratio": 1.6040816326530611, "no_speech_prob": 6.962020961509552e-06}, {"id": 314, "seek": 122340, "start": 1223.4, "end": 1227.4, "text": " You need to give an ELE demo.", "tokens": [509, 643, 281, 976, 364, 462, 2634, 10723, 13], "temperature": 0.0, "avg_logprob": -0.20821238463779665, "compression_ratio": 1.608695652173913, "no_speech_prob": 1.6963831512839533e-05}, {"id": 315, "seek": 122340, "start": 1227.4, "end": 1230.4, "text": " You need to give a quick start guide.", "tokens": [509, 643, 281, 976, 257, 1702, 722, 5934, 13], "temperature": 0.0, "avg_logprob": -0.20821238463779665, "compression_ratio": 1.608695652173913, "no_speech_prob": 1.6963831512839533e-05}, {"id": 316, "seek": 122340, "start": 1230.4, "end": 1234.4, "text": " I'm not sure if Elm Review has this right off the bat,", "tokens": [286, 478, 406, 988, 498, 2699, 76, 19954, 575, 341, 558, 766, 264, 7362, 11], "temperature": 0.0, "avg_logprob": -0.20821238463779665, "compression_ratio": 1.608695652173913, "no_speech_prob": 1.6963831512839533e-05}, {"id": 317, "seek": 122340, "start": 1234.4, "end": 1240.4, "text": " but the Elm Review dash dash template flag is a great way to try it.", "tokens": [457, 264, 2699, 76, 19954, 8240, 8240, 12379, 7166, 307, 257, 869, 636, 281, 853, 309, 13], "temperature": 0.0, "avg_logprob": -0.20821238463779665, "compression_ratio": 1.608695652173913, "no_speech_prob": 1.6963831512839533e-05}, {"id": 318, "seek": 122340, "start": 1240.4, "end": 1242.4, "text": " You can say, here you go.", "tokens": [509, 393, 584, 11, 510, 291, 352, 13], "temperature": 0.0, "avg_logprob": -0.20821238463779665, "compression_ratio": 1.608695652173913, "no_speech_prob": 1.6963831512839533e-05}, {"id": 319, "seek": 122340, "start": 1242.4, "end": 1244.4, "text": " Here's a single command.", "tokens": [1692, 311, 257, 2167, 5622, 13], "temperature": 0.0, "avg_logprob": -0.20821238463779665, "compression_ratio": 1.608695652173913, "no_speech_prob": 1.6963831512839533e-05}, {"id": 320, "seek": 122340, "start": 1244.4, "end": 1248.4, "text": " You npm install dash g, and then you run this one command.", "tokens": [509, 297, 14395, 3625, 8240, 290, 11, 293, 550, 291, 1190, 341, 472, 5622, 13], "temperature": 0.0, "avg_logprob": -0.20821238463779665, "compression_ratio": 1.608695652173913, "no_speech_prob": 1.6963831512839533e-05}, {"id": 321, "seek": 122340, "start": 1248.4, "end": 1250.4, "text": " You don't even need to do that.", "tokens": [509, 500, 380, 754, 643, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.20821238463779665, "compression_ratio": 1.608695652173913, "no_speech_prob": 1.6963831512839533e-05}, {"id": 322, "seek": 125040, "start": 1250.4, "end": 1253.4, "text": " You can just install it through npx.", "tokens": [509, 393, 445, 3625, 309, 807, 33808, 87, 13], "temperature": 0.0, "avg_logprob": -0.20989427112397693, "compression_ratio": 1.5466666666666666, "no_speech_prob": 3.041551281057764e-06}, {"id": 323, "seek": 125040, "start": 1253.4, "end": 1255.4, "text": " You can just npx it.", "tokens": [509, 393, 445, 33808, 87, 309, 13], "temperature": 0.0, "avg_logprob": -0.20989427112397693, "compression_ratio": 1.5466666666666666, "no_speech_prob": 3.041551281057764e-06}, {"id": 324, "seek": 125040, "start": 1255.4, "end": 1260.4, "text": " Or you used to be able to. I don't remember.", "tokens": [1610, 291, 1143, 281, 312, 1075, 281, 13, 286, 500, 380, 1604, 13], "temperature": 0.0, "avg_logprob": -0.20989427112397693, "compression_ratio": 1.5466666666666666, "no_speech_prob": 3.041551281057764e-06}, {"id": 325, "seek": 125040, "start": 1260.4, "end": 1264.4, "text": " Sure enough, you do have that first thing.", "tokens": [4894, 1547, 11, 291, 360, 362, 300, 700, 551, 13], "temperature": 0.0, "avg_logprob": -0.20989427112397693, "compression_ratio": 1.5466666666666666, "no_speech_prob": 3.041551281057764e-06}, {"id": 326, "seek": 125040, "start": 1264.4, "end": 1268.4, "text": " You've got it under a nice simple heading.", "tokens": [509, 600, 658, 309, 833, 257, 1481, 2199, 9864, 13], "temperature": 0.0, "avg_logprob": -0.20989427112397693, "compression_ratio": 1.5466666666666666, "no_speech_prob": 3.041551281057764e-06}, {"id": 327, "seek": 125040, "start": 1268.4, "end": 1270.4, "text": " Let's look at Elm Review's docs.", "tokens": [961, 311, 574, 412, 2699, 76, 19954, 311, 45623, 13], "temperature": 0.0, "avg_logprob": -0.20989427112397693, "compression_ratio": 1.5466666666666666, "no_speech_prob": 3.041551281057764e-06}, {"id": 328, "seek": 125040, "start": 1270.4, "end": 1273.4, "text": " The first thing I see is a topic sentence.", "tokens": [440, 700, 551, 286, 536, 307, 257, 4829, 8174, 13], "temperature": 0.0, "avg_logprob": -0.20989427112397693, "compression_ratio": 1.5466666666666666, "no_speech_prob": 3.041551281057764e-06}, {"id": 329, "seek": 125040, "start": 1273.4, "end": 1277.4, "text": " Elm Review analyzes Elm projects to help find mistakes before your users find them.", "tokens": [2699, 76, 19954, 6459, 12214, 2699, 76, 4455, 281, 854, 915, 8038, 949, 428, 5022, 915, 552, 13], "temperature": 0.0, "avg_logprob": -0.20989427112397693, "compression_ratio": 1.5466666666666666, "no_speech_prob": 3.041551281057764e-06}, {"id": 330, "seek": 127740, "start": 1277.4, "end": 1281.4, "text": " Screenshot. That's awesome. Now I know what it does.", "tokens": [2747, 9098, 12194, 13, 663, 311, 3476, 13, 823, 286, 458, 437, 309, 775, 13], "temperature": 0.0, "avg_logprob": -0.14889967643608482, "compression_ratio": 1.7056277056277056, "no_speech_prob": 8.800897376204375e-06}, {"id": 331, "seek": 127740, "start": 1281.4, "end": 1284.4, "text": " I get a taste of the experience. It's a single sentence.", "tokens": [286, 483, 257, 3939, 295, 264, 1752, 13, 467, 311, 257, 2167, 8174, 13], "temperature": 0.0, "avg_logprob": -0.14889967643608482, "compression_ratio": 1.7056277056277056, "no_speech_prob": 8.800897376204375e-06}, {"id": 332, "seek": 127740, "start": 1284.4, "end": 1291.4, "text": " It's not like a paragraph that I'm like, oh, do I have to decide what's meaningful in this long paragraph?", "tokens": [467, 311, 406, 411, 257, 18865, 300, 286, 478, 411, 11, 1954, 11, 360, 286, 362, 281, 4536, 437, 311, 10995, 294, 341, 938, 18865, 30], "temperature": 0.0, "avg_logprob": -0.14889967643608482, "compression_ratio": 1.7056277056277056, "no_speech_prob": 8.800897376204375e-06}, {"id": 333, "seek": 127740, "start": 1291.4, "end": 1294.4, "text": " It's a single sentence. Then there's a new heading.", "tokens": [467, 311, 257, 2167, 8174, 13, 1396, 456, 311, 257, 777, 9864, 13], "temperature": 0.0, "avg_logprob": -0.14889967643608482, "compression_ratio": 1.7056277056277056, "no_speech_prob": 8.800897376204375e-06}, {"id": 334, "seek": 127740, "start": 1294.4, "end": 1296.4, "text": " What does Elm Review do?", "tokens": [708, 775, 2699, 76, 19954, 360, 30], "temperature": 0.0, "avg_logprob": -0.14889967643608482, "compression_ratio": 1.7056277056277056, "no_speech_prob": 8.800897376204375e-06}, {"id": 335, "seek": 127740, "start": 1296.4, "end": 1299.4, "text": " It gives you a sense of what you're going to use it for.", "tokens": [467, 2709, 291, 257, 2020, 295, 437, 291, 434, 516, 281, 764, 309, 337, 13], "temperature": 0.0, "avg_logprob": -0.14889967643608482, "compression_ratio": 1.7056277056277056, "no_speech_prob": 8.800897376204375e-06}, {"id": 336, "seek": 127740, "start": 1299.4, "end": 1301.4, "text": " And then there's a new heading. Try it out.", "tokens": [400, 550, 456, 311, 257, 777, 9864, 13, 6526, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.14889967643608482, "compression_ratio": 1.7056277056277056, "no_speech_prob": 8.800897376204375e-06}, {"id": 337, "seek": 130140, "start": 1301.4, "end": 1308.4, "text": " And it does indeed have the quick start command npx elmreview \u2013template. Amazing.", "tokens": [400, 309, 775, 6451, 362, 264, 1702, 722, 5622, 33808, 87, 806, 76, 265, 1759, 220, 5815, 83, 5895, 473, 13, 14165, 13], "temperature": 0.0, "avg_logprob": -0.24869355388071346, "compression_ratio": 1.4390243902439024, "no_speech_prob": 1.805625834094826e-05}, {"id": 338, "seek": 130140, "start": 1308.4, "end": 1314.4, "text": " I am a happy customer if I'm going through these docs and trying to evaluate whether you use this.", "tokens": [286, 669, 257, 2055, 5474, 498, 286, 478, 516, 807, 613, 45623, 293, 1382, 281, 13059, 1968, 291, 764, 341, 13], "temperature": 0.0, "avg_logprob": -0.24869355388071346, "compression_ratio": 1.4390243902439024, "no_speech_prob": 1.805625834094826e-05}, {"id": 339, "seek": 130140, "start": 1314.4, "end": 1316.4, "text": " I'm glad to hear it.", "tokens": [286, 478, 5404, 281, 1568, 309, 13], "temperature": 0.0, "avg_logprob": -0.24869355388071346, "compression_ratio": 1.4390243902439024, "no_speech_prob": 1.805625834094826e-05}, {"id": 340, "seek": 130140, "start": 1316.4, "end": 1323.4, "text": " But I'm sorry, I'm not actually going to pay you. I was a little misleading. Sorry, Jeroen.", "tokens": [583, 286, 478, 2597, 11, 286, 478, 406, 767, 516, 281, 1689, 291, 13, 286, 390, 257, 707, 36429, 13, 4919, 11, 508, 2032, 268, 13], "temperature": 0.0, "avg_logprob": -0.24869355388071346, "compression_ratio": 1.4390243902439024, "no_speech_prob": 1.805625834094826e-05}, {"id": 341, "seek": 132340, "start": 1323.4, "end": 1331.4, "text": " It was worth the effort of doing all those years of work just to see whether you would pay me.", "tokens": [467, 390, 3163, 264, 4630, 295, 884, 439, 729, 924, 295, 589, 445, 281, 536, 1968, 291, 576, 1689, 385, 13], "temperature": 0.0, "avg_logprob": -0.16447961076777032, "compression_ratio": 1.5869565217391304, "no_speech_prob": 5.254192274151137e-06}, {"id": 342, "seek": 132340, "start": 1331.4, "end": 1337.4, "text": " I would hypothetically pay if there were a way to do that.", "tokens": [286, 576, 24371, 22652, 1689, 498, 456, 645, 257, 636, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.16447961076777032, "compression_ratio": 1.5869565217391304, "no_speech_prob": 5.254192274151137e-06}, {"id": 343, "seek": 132340, "start": 1337.4, "end": 1342.4, "text": " As you say, you want the quick feedback. So there are multiple ways to do that.", "tokens": [1018, 291, 584, 11, 291, 528, 264, 1702, 5824, 13, 407, 456, 366, 3866, 2098, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.16447961076777032, "compression_ratio": 1.5869565217391304, "no_speech_prob": 5.254192274151137e-06}, {"id": 344, "seek": 132340, "start": 1342.4, "end": 1351.4, "text": " So in the case of Elm Review, it's a bit of a peculiar story where you have to install the tool and then choose your configuration.", "tokens": [407, 294, 264, 1389, 295, 2699, 76, 19954, 11, 309, 311, 257, 857, 295, 257, 27149, 1657, 689, 291, 362, 281, 3625, 264, 2290, 293, 550, 2826, 428, 11694, 13], "temperature": 0.0, "avg_logprob": -0.16447961076777032, "compression_ratio": 1.5869565217391304, "no_speech_prob": 5.254192274151137e-06}, {"id": 345, "seek": 135140, "start": 1351.4, "end": 1357.4, "text": " So I have this try it out section that tells you to use templates with a predefined configuration.", "tokens": [407, 286, 362, 341, 853, 309, 484, 3541, 300, 5112, 291, 281, 764, 21165, 365, 257, 659, 37716, 11694, 13], "temperature": 0.0, "avg_logprob": -0.2538388797215053, "compression_ratio": 1.490909090909091, "no_speech_prob": 1.4499118151434232e-05}, {"id": 346, "seek": 135140, "start": 1357.4, "end": 1360.4, "text": " But that's like a pretty specific use case.", "tokens": [583, 300, 311, 411, 257, 1238, 2685, 764, 1389, 13], "temperature": 0.0, "avg_logprob": -0.2538388797215053, "compression_ratio": 1.490909090909091, "no_speech_prob": 1.4499118151434232e-05}, {"id": 347, "seek": 135140, "start": 1360.4, "end": 1365.4, "text": " In most cases, let's imagine you just have a dict package.", "tokens": [682, 881, 3331, 11, 718, 311, 3811, 291, 445, 362, 257, 12569, 7372, 13], "temperature": 0.0, "avg_logprob": -0.2538388797215053, "compression_ratio": 1.490909090909091, "no_speech_prob": 1.4499118151434232e-05}, {"id": 348, "seek": 135140, "start": 1365.4, "end": 1373.4, "text": " Then just a simple example that you could copy paste into a REPL, that would be very sufficient.", "tokens": [1396, 445, 257, 2199, 1365, 300, 291, 727, 5055, 9163, 666, 257, 31511, 43, 11, 300, 576, 312, 588, 11563, 13], "temperature": 0.0, "avg_logprob": -0.2538388797215053, "compression_ratio": 1.490909090909091, "no_speech_prob": 1.4499118151434232e-05}, {"id": 349, "seek": 135140, "start": 1373.4, "end": 1375.4, "text": " You don't need anything more.", "tokens": [509, 500, 380, 643, 1340, 544, 13], "temperature": 0.0, "avg_logprob": -0.2538388797215053, "compression_ratio": 1.490909090909091, "no_speech_prob": 1.4499118151434232e-05}, {"id": 350, "seek": 137540, "start": 1375.4, "end": 1384.4, "text": " And that's great because it also makes a perfect example for your function and it makes it very clear what something does.", "tokens": [400, 300, 311, 869, 570, 309, 611, 1669, 257, 2176, 1365, 337, 428, 2445, 293, 309, 1669, 309, 588, 1850, 437, 746, 775, 13], "temperature": 0.0, "avg_logprob": -0.22913344864992752, "compression_ratio": 1.648068669527897, "no_speech_prob": 3.641875446191989e-05}, {"id": 351, "seek": 137540, "start": 1384.4, "end": 1387.4, "text": " So that's great.", "tokens": [407, 300, 311, 869, 13], "temperature": 0.0, "avg_logprob": -0.22913344864992752, "compression_ratio": 1.648068669527897, "no_speech_prob": 3.641875446191989e-05}, {"id": 352, "seek": 137540, "start": 1387.4, "end": 1393.4, "text": " In some cases that are more complex, you could have a bigger code section.", "tokens": [682, 512, 3331, 300, 366, 544, 3997, 11, 291, 727, 362, 257, 3801, 3089, 3541, 13], "temperature": 0.0, "avg_logprob": -0.22913344864992752, "compression_ratio": 1.648068669527897, "no_speech_prob": 3.641875446191989e-05}, {"id": 353, "seek": 137540, "start": 1393.4, "end": 1398.4, "text": " But if you want people to play with it, like something visual or it's something a little bit more complex.", "tokens": [583, 498, 291, 528, 561, 281, 862, 365, 309, 11, 411, 746, 5056, 420, 309, 311, 746, 257, 707, 857, 544, 3997, 13], "temperature": 0.0, "avg_logprob": -0.22913344864992752, "compression_ratio": 1.648068669527897, "no_speech_prob": 3.641875446191989e-05}, {"id": 354, "seek": 137540, "start": 1398.4, "end": 1404.4, "text": " Let's say you want to parse a CSV, then you could write an LE.", "tokens": [961, 311, 584, 291, 528, 281, 48377, 257, 48814, 11, 550, 291, 727, 2464, 364, 11378, 13], "temperature": 0.0, "avg_logprob": -0.22913344864992752, "compression_ratio": 1.648068669527897, "no_speech_prob": 3.641875446191989e-05}, {"id": 355, "seek": 140440, "start": 1404.4, "end": 1411.4, "text": " The problem with the LE though is that sometimes I think it always uses the latest version of your package.", "tokens": [440, 1154, 365, 264, 11378, 1673, 307, 300, 2171, 286, 519, 309, 1009, 4960, 264, 6792, 3037, 295, 428, 7372, 13], "temperature": 0.0, "avg_logprob": -0.26006001692551833, "compression_ratio": 1.6129032258064515, "no_speech_prob": 2.246892108814791e-05}, {"id": 356, "seek": 140440, "start": 1411.4, "end": 1416.4, "text": " So older versions of your package will have documentation that is broken.", "tokens": [407, 4906, 9606, 295, 428, 7372, 486, 362, 14333, 300, 307, 5463, 13], "temperature": 0.0, "avg_logprob": -0.26006001692551833, "compression_ratio": 1.6129032258064515, "no_speech_prob": 2.246892108814791e-05}, {"id": 357, "seek": 140440, "start": 1416.4, "end": 1420.4, "text": " Maybe that will be fixed in the future.", "tokens": [2704, 300, 486, 312, 6806, 294, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.26006001692551833, "compression_ratio": 1.6129032258064515, "no_speech_prob": 2.246892108814791e-05}, {"id": 358, "seek": 140440, "start": 1420.4, "end": 1431.4, "text": " But the essence of the idea still holds is you want something that people can just go to without having to install your package,", "tokens": [583, 264, 12801, 295, 264, 1558, 920, 9190, 307, 291, 528, 746, 300, 561, 393, 445, 352, 281, 1553, 1419, 281, 3625, 428, 7372, 11], "temperature": 0.0, "avg_logprob": -0.26006001692551833, "compression_ratio": 1.6129032258064515, "no_speech_prob": 2.246892108814791e-05}, {"id": 359, "seek": 143140, "start": 1431.4, "end": 1435.4, "text": " without having to create a small new project to try things out.", "tokens": [1553, 1419, 281, 1884, 257, 1359, 777, 1716, 281, 853, 721, 484, 13], "temperature": 0.0, "avg_logprob": -0.22236622211545012, "compression_ratio": 1.5169082125603865, "no_speech_prob": 4.565403742162744e-06}, {"id": 360, "seek": 143140, "start": 1435.4, "end": 1441.4, "text": " You don't even have to force people to use Elm Reactor or something.", "tokens": [509, 500, 380, 754, 362, 281, 3464, 561, 281, 764, 2699, 76, 1300, 15104, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.22236622211545012, "compression_ratio": 1.5169082125603865, "no_speech_prob": 4.565403742162744e-06}, {"id": 361, "seek": 143140, "start": 1441.4, "end": 1446.4, "text": " And they can play with it and they can see, does this fit? Does this work?", "tokens": [400, 436, 393, 862, 365, 309, 293, 436, 393, 536, 11, 775, 341, 3318, 30, 4402, 341, 589, 30], "temperature": 0.0, "avg_logprob": -0.22236622211545012, "compression_ratio": 1.5169082125603865, "no_speech_prob": 4.565403742162744e-06}, {"id": 362, "seek": 143140, "start": 1446.4, "end": 1454.4, "text": " Yes, no, let's go to the next package or let's try to fix my immediate problem that I was trying to solve.", "tokens": [1079, 11, 572, 11, 718, 311, 352, 281, 264, 958, 7372, 420, 718, 311, 853, 281, 3191, 452, 11629, 1154, 300, 286, 390, 1382, 281, 5039, 13], "temperature": 0.0, "avg_logprob": -0.22236622211545012, "compression_ratio": 1.5169082125603865, "no_speech_prob": 4.565403742162744e-06}, {"id": 363, "seek": 145440, "start": 1454.4, "end": 1462.4, "text": " In the case of something like Elm GraphQL, that is about code generation, that's a lot more complex.", "tokens": [682, 264, 1389, 295, 746, 411, 2699, 76, 21884, 13695, 11, 300, 307, 466, 3089, 5125, 11, 300, 311, 257, 688, 544, 3997, 13], "temperature": 0.0, "avg_logprob": -0.21636185279259315, "compression_ratio": 1.625, "no_speech_prob": 2.3548363969894126e-05}, {"id": 364, "seek": 145440, "start": 1462.4, "end": 1474.4, "text": " So I think what you do, or I know what you do, is to have an example project where you have a GraphQL schema from which you generate a lot of code.", "tokens": [407, 286, 519, 437, 291, 360, 11, 420, 286, 458, 437, 291, 360, 11, 307, 281, 362, 364, 1365, 1716, 689, 291, 362, 257, 21884, 13695, 34078, 490, 597, 291, 8460, 257, 688, 295, 3089, 13], "temperature": 0.0, "avg_logprob": -0.21636185279259315, "compression_ratio": 1.625, "no_speech_prob": 2.3548363969894126e-05}, {"id": 365, "seek": 145440, "start": 1474.4, "end": 1481.4, "text": " And if I remember correctly, you checked in the code so people can see it, can see the generated code.", "tokens": [400, 498, 286, 1604, 8944, 11, 291, 10033, 294, 264, 3089, 370, 561, 393, 536, 309, 11, 393, 536, 264, 10833, 3089, 13], "temperature": 0.0, "avg_logprob": -0.21636185279259315, "compression_ratio": 1.625, "no_speech_prob": 2.3548363969894126e-05}, {"id": 366, "seek": 148140, "start": 1481.4, "end": 1484.4, "text": " And that I find to be very important.", "tokens": [400, 300, 286, 915, 281, 312, 588, 1021, 13], "temperature": 0.0, "avg_logprob": -0.19064708550771078, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0001052891748258844}, {"id": 367, "seek": 148140, "start": 1484.4, "end": 1494.4, "text": " I've seen a few places where you had to go in yourself and regenerate those files to see what they looked like.", "tokens": [286, 600, 1612, 257, 1326, 3190, 689, 291, 632, 281, 352, 294, 1803, 293, 26358, 473, 729, 7098, 281, 536, 437, 436, 2956, 411, 13], "temperature": 0.0, "avg_logprob": -0.19064708550771078, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0001052891748258844}, {"id": 368, "seek": 148140, "start": 1494.4, "end": 1502.4, "text": " But I wanted to see, if I'm curious or if that's important to me, how those generated files will look like.", "tokens": [583, 286, 1415, 281, 536, 11, 498, 286, 478, 6369, 420, 498, 300, 311, 1021, 281, 385, 11, 577, 729, 10833, 7098, 486, 574, 411, 13], "temperature": 0.0, "avg_logprob": -0.19064708550771078, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0001052891748258844}, {"id": 369, "seek": 148140, "start": 1502.4, "end": 1508.4, "text": " So I think it's very important that you check them in so that they're available on GitHub and people can just see them.", "tokens": [407, 286, 519, 309, 311, 588, 1021, 300, 291, 1520, 552, 294, 370, 300, 436, 434, 2435, 322, 23331, 293, 561, 393, 445, 536, 552, 13], "temperature": 0.0, "avg_logprob": -0.19064708550771078, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0001052891748258844}, {"id": 370, "seek": 150840, "start": 1508.4, "end": 1511.4, "text": " So that's a very good thing that you've done.", "tokens": [407, 300, 311, 257, 588, 665, 551, 300, 291, 600, 1096, 13], "temperature": 0.0, "avg_logprob": -0.20165096185146233, "compression_ratio": 1.678294573643411, "no_speech_prob": 1.3844518434780184e-05}, {"id": 371, "seek": 150840, "start": 1511.4, "end": 1515.4, "text": " But yeah, sometimes you need a project, sometimes you just need a code sample.", "tokens": [583, 1338, 11, 2171, 291, 643, 257, 1716, 11, 2171, 291, 445, 643, 257, 3089, 6889, 13], "temperature": 0.0, "avg_logprob": -0.20165096185146233, "compression_ratio": 1.678294573643411, "no_speech_prob": 1.3844518434780184e-05}, {"id": 372, "seek": 150840, "start": 1515.4, "end": 1520.4, "text": " Whatever makes it very easy for people to try it out is good.", "tokens": [8541, 1669, 309, 588, 1858, 337, 561, 281, 853, 309, 484, 307, 665, 13], "temperature": 0.0, "avg_logprob": -0.20165096185146233, "compression_ratio": 1.678294573643411, "no_speech_prob": 1.3844518434780184e-05}, {"id": 373, "seek": 150840, "start": 1520.4, "end": 1523.4, "text": " Right. Yeah, as you say, because it involves code generation.", "tokens": [1779, 13, 865, 11, 382, 291, 584, 11, 570, 309, 11626, 3089, 5125, 13], "temperature": 0.0, "avg_logprob": -0.20165096185146233, "compression_ratio": 1.678294573643411, "no_speech_prob": 1.3844518434780184e-05}, {"id": 374, "seek": 150840, "start": 1523.4, "end": 1530.4, "text": " If it's just a vanilla package, then if you can give an LE link, I really think you should.", "tokens": [759, 309, 311, 445, 257, 17528, 7372, 11, 550, 498, 291, 393, 976, 364, 11378, 2113, 11, 286, 534, 519, 291, 820, 13], "temperature": 0.0, "avg_logprob": -0.20165096185146233, "compression_ratio": 1.678294573643411, "no_speech_prob": 1.3844518434780184e-05}, {"id": 375, "seek": 150840, "start": 1530.4, "end": 1536.4, "text": " Because if you can give a simple self-contained, like LE requires that it is self-contained.", "tokens": [1436, 498, 291, 393, 976, 257, 2199, 2698, 12, 9000, 3563, 11, 411, 11378, 7029, 300, 309, 307, 2698, 12, 9000, 3563, 13], "temperature": 0.0, "avg_logprob": -0.20165096185146233, "compression_ratio": 1.678294573643411, "no_speech_prob": 1.3844518434780184e-05}, {"id": 376, "seek": 153640, "start": 1536.4, "end": 1540.4, "text": " So if you can give that, it forces you to write a very simple example.", "tokens": [407, 498, 291, 393, 976, 300, 11, 309, 5874, 291, 281, 2464, 257, 588, 2199, 1365, 13], "temperature": 0.0, "avg_logprob": -0.1749705020512376, "compression_ratio": 1.6980392156862745, "no_speech_prob": 1.061513557942817e-05}, {"id": 377, "seek": 153640, "start": 1540.4, "end": 1544.4, "text": " And it gives people something shareable, they can play around with it.", "tokens": [400, 309, 2709, 561, 746, 2073, 712, 11, 436, 393, 862, 926, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.1749705020512376, "compression_ratio": 1.6980392156862745, "no_speech_prob": 1.061513557942817e-05}, {"id": 378, "seek": 153640, "start": 1544.4, "end": 1549.4, "text": " And they can extract it into their own project from some working code.", "tokens": [400, 436, 393, 8947, 309, 666, 641, 1065, 1716, 490, 512, 1364, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1749705020512376, "compression_ratio": 1.6980392156862745, "no_speech_prob": 1.061513557942817e-05}, {"id": 379, "seek": 153640, "start": 1549.4, "end": 1553.4, "text": " Not some readme comment that they have to trust.", "tokens": [1726, 512, 1401, 1398, 2871, 300, 436, 362, 281, 3361, 13], "temperature": 0.0, "avg_logprob": -0.1749705020512376, "compression_ratio": 1.6980392156862745, "no_speech_prob": 1.061513557942817e-05}, {"id": 380, "seek": 153640, "start": 1553.4, "end": 1558.4, "text": " They can actually see it and even tweak it and then integrate it into their project.", "tokens": [814, 393, 767, 536, 309, 293, 754, 29879, 309, 293, 550, 13365, 309, 666, 641, 1716, 13], "temperature": 0.0, "avg_logprob": -0.1749705020512376, "compression_ratio": 1.6980392156862745, "no_speech_prob": 1.061513557942817e-05}, {"id": 381, "seek": 153640, "start": 1558.4, "end": 1565.4, "text": " I think that it's really good to have a variety of different types of content as well.", "tokens": [286, 519, 300, 309, 311, 534, 665, 281, 362, 257, 5673, 295, 819, 3467, 295, 2701, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1749705020512376, "compression_ratio": 1.6980392156862745, "no_speech_prob": 1.061513557942817e-05}, {"id": 382, "seek": 156540, "start": 1565.4, "end": 1571.4, "text": " Because different people, and over the course of doing different types of tasks,", "tokens": [1436, 819, 561, 11, 293, 670, 264, 1164, 295, 884, 819, 3467, 295, 9608, 11], "temperature": 0.0, "avg_logprob": -0.21898810068766275, "compression_ratio": 1.7796610169491525, "no_speech_prob": 5.389322541304864e-05}, {"id": 383, "seek": 156540, "start": 1571.4, "end": 1575.4, "text": " will want content presented in different ways.", "tokens": [486, 528, 2701, 8212, 294, 819, 2098, 13], "temperature": 0.0, "avg_logprob": -0.21898810068766275, "compression_ratio": 1.7796610169491525, "no_speech_prob": 5.389322541304864e-05}, {"id": 384, "seek": 156540, "start": 1575.4, "end": 1581.4, "text": " So for example, the source code itself, even like you said, generated source code.", "tokens": [407, 337, 1365, 11, 264, 4009, 3089, 2564, 11, 754, 411, 291, 848, 11, 10833, 4009, 3089, 13], "temperature": 0.0, "avg_logprob": -0.21898810068766275, "compression_ratio": 1.7796610169491525, "no_speech_prob": 5.389322541304864e-05}, {"id": 385, "seek": 156540, "start": 1581.4, "end": 1585.4, "text": " Perusing that, some types of users might want to say,", "tokens": [3026, 7981, 300, 11, 512, 3467, 295, 5022, 1062, 528, 281, 584, 11], "temperature": 0.0, "avg_logprob": -0.21898810068766275, "compression_ratio": 1.7796610169491525, "no_speech_prob": 5.389322541304864e-05}, {"id": 386, "seek": 156540, "start": 1585.4, "end": 1587.4, "text": " well what is this actually doing to understand it?", "tokens": [731, 437, 307, 341, 767, 884, 281, 1223, 309, 30], "temperature": 0.0, "avg_logprob": -0.21898810068766275, "compression_ratio": 1.7796610169491525, "no_speech_prob": 5.389322541304864e-05}, {"id": 387, "seek": 156540, "start": 1587.4, "end": 1589.4, "text": " And someone else might never want to look at that.", "tokens": [400, 1580, 1646, 1062, 1128, 528, 281, 574, 412, 300, 13], "temperature": 0.0, "avg_logprob": -0.21898810068766275, "compression_ratio": 1.7796610169491525, "no_speech_prob": 5.389322541304864e-05}, {"id": 388, "seek": 156540, "start": 1589.4, "end": 1593.4, "text": " They might want to look at an actual working example,", "tokens": [814, 1062, 528, 281, 574, 412, 364, 3539, 1364, 1365, 11], "temperature": 0.0, "avg_logprob": -0.21898810068766275, "compression_ratio": 1.7796610169491525, "no_speech_prob": 5.389322541304864e-05}, {"id": 389, "seek": 159340, "start": 1593.4, "end": 1596.4, "text": " even if it's not an LE because it's using generated code.", "tokens": [754, 498, 309, 311, 406, 364, 11378, 570, 309, 311, 1228, 10833, 3089, 13], "temperature": 0.0, "avg_logprob": -0.20535062283885722, "compression_ratio": 1.6859504132231404, "no_speech_prob": 8.39787935547065e-06}, {"id": 390, "seek": 159340, "start": 1596.4, "end": 1599.4, "text": " They might want to see a deployed example that makes GraphQL requests", "tokens": [814, 1062, 528, 281, 536, 257, 17826, 1365, 300, 1669, 21884, 13695, 12475], "temperature": 0.0, "avg_logprob": -0.20535062283885722, "compression_ratio": 1.6859504132231404, "no_speech_prob": 8.39787935547065e-06}, {"id": 391, "seek": 159340, "start": 1599.4, "end": 1602.4, "text": " and inspects the network tab.", "tokens": [293, 15018, 82, 264, 3209, 4421, 13], "temperature": 0.0, "avg_logprob": -0.20535062283885722, "compression_ratio": 1.6859504132231404, "no_speech_prob": 8.39787935547065e-06}, {"id": 392, "seek": 159340, "start": 1602.4, "end": 1607.4, "text": " And someone else might want to play around with it locally and run the code generator.", "tokens": [400, 1580, 1646, 1062, 528, 281, 862, 926, 365, 309, 16143, 293, 1190, 264, 3089, 19265, 13], "temperature": 0.0, "avg_logprob": -0.20535062283885722, "compression_ratio": 1.6859504132231404, "no_speech_prob": 8.39787935547065e-06}, {"id": 393, "seek": 159340, "start": 1607.4, "end": 1611.4, "text": " Someone else might want to read a short guide.", "tokens": [8734, 1646, 1062, 528, 281, 1401, 257, 2099, 5934, 13], "temperature": 0.0, "avg_logprob": -0.20535062283885722, "compression_ratio": 1.6859504132231404, "no_speech_prob": 8.39787935547065e-06}, {"id": 394, "seek": 159340, "start": 1611.4, "end": 1616.4, "text": " And these are all different formats that people have different styles.", "tokens": [400, 613, 366, 439, 819, 25879, 300, 561, 362, 819, 13273, 13], "temperature": 0.0, "avg_logprob": -0.20535062283885722, "compression_ratio": 1.6859504132231404, "no_speech_prob": 8.39787935547065e-06}, {"id": 395, "seek": 159340, "start": 1616.4, "end": 1620.4, "text": " And some people read through the test folder.", "tokens": [400, 512, 561, 1401, 807, 264, 1500, 10820, 13], "temperature": 0.0, "avg_logprob": -0.20535062283885722, "compression_ratio": 1.6859504132231404, "no_speech_prob": 8.39787935547065e-06}, {"id": 396, "seek": 162040, "start": 1620.4, "end": 1623.4, "text": " I actually pretty commonly will go through a project and read through the test folder.", "tokens": [286, 767, 1238, 12719, 486, 352, 807, 257, 1716, 293, 1401, 807, 264, 1500, 10820, 13], "temperature": 0.0, "avg_logprob": -0.2139047257443692, "compression_ratio": 1.5859030837004404, "no_speech_prob": 5.063958451501094e-05}, {"id": 397, "seek": 162040, "start": 1623.4, "end": 1627.4, "text": " I consider that to be part of a project's documentation.", "tokens": [286, 1949, 300, 281, 312, 644, 295, 257, 1716, 311, 14333, 13], "temperature": 0.0, "avg_logprob": -0.2139047257443692, "compression_ratio": 1.5859030837004404, "no_speech_prob": 5.063958451501094e-05}, {"id": 398, "seek": 162040, "start": 1627.4, "end": 1628.4, "text": " Yeah, I agree.", "tokens": [865, 11, 286, 3986, 13], "temperature": 0.0, "avg_logprob": -0.2139047257443692, "compression_ratio": 1.5859030837004404, "no_speech_prob": 5.063958451501094e-05}, {"id": 399, "seek": 162040, "start": 1628.4, "end": 1632.4, "text": " Part of the reason why I would like to see your generated code is because,", "tokens": [4100, 295, 264, 1778, 983, 286, 576, 411, 281, 536, 428, 10833, 3089, 307, 570, 11], "temperature": 0.0, "avg_logprob": -0.2139047257443692, "compression_ratio": 1.5859030837004404, "no_speech_prob": 5.063958451501094e-05}, {"id": 400, "seek": 162040, "start": 1632.4, "end": 1641.4, "text": " or for Elm GraphQL, is because a code generator will produce Elm modules,", "tokens": [420, 337, 2699, 76, 21884, 13695, 11, 307, 570, 257, 3089, 19265, 486, 5258, 2699, 76, 16679, 11], "temperature": 0.0, "avg_logprob": -0.2139047257443692, "compression_ratio": 1.5859030837004404, "no_speech_prob": 5.063958451501094e-05}, {"id": 401, "seek": 162040, "start": 1641.4, "end": 1645.4, "text": " and that's the API that I have to work with usually.", "tokens": [293, 300, 311, 264, 9362, 300, 286, 362, 281, 589, 365, 2673, 13], "temperature": 0.0, "avg_logprob": -0.2139047257443692, "compression_ratio": 1.5859030837004404, "no_speech_prob": 5.063958451501094e-05}, {"id": 402, "seek": 164540, "start": 1645.4, "end": 1651.4, "text": " So whenever I choose to work with a package, I want to know the API.", "tokens": [407, 5699, 286, 2826, 281, 589, 365, 257, 7372, 11, 286, 528, 281, 458, 264, 9362, 13], "temperature": 0.0, "avg_logprob": -0.2127468152479692, "compression_ratio": 1.465, "no_speech_prob": 7.889072549005505e-06}, {"id": 403, "seek": 164540, "start": 1651.4, "end": 1655.4, "text": " And if your API is the generated code, then I kind of need to see it.", "tokens": [400, 498, 428, 9362, 307, 264, 10833, 3089, 11, 550, 286, 733, 295, 643, 281, 536, 309, 13], "temperature": 0.0, "avg_logprob": -0.2127468152479692, "compression_ratio": 1.465, "no_speech_prob": 7.889072549005505e-06}, {"id": 404, "seek": 164540, "start": 1655.4, "end": 1659.4, "text": " Otherwise, it's very blurry or very fuzzy for me.", "tokens": [10328, 11, 309, 311, 588, 37644, 420, 588, 34710, 337, 385, 13], "temperature": 0.0, "avg_logprob": -0.2127468152479692, "compression_ratio": 1.465, "no_speech_prob": 7.889072549005505e-06}, {"id": 405, "seek": 164540, "start": 1659.4, "end": 1663.4, "text": " Yes. Actually, that makes me think, like,", "tokens": [1079, 13, 5135, 11, 300, 1669, 385, 519, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.2127468152479692, "compression_ratio": 1.465, "no_speech_prob": 7.889072549005505e-06}, {"id": 406, "seek": 164540, "start": 1663.4, "end": 1669.4, "text": " I probably could take that Elm.json file or the docs.json file", "tokens": [286, 1391, 727, 747, 300, 2699, 76, 13, 73, 3015, 3991, 420, 264, 45623, 13, 73, 3015, 3991], "temperature": 0.0, "avg_logprob": -0.2127468152479692, "compression_ratio": 1.465, "no_speech_prob": 7.889072549005505e-06}, {"id": 407, "seek": 166940, "start": 1669.4, "end": 1675.4, "text": " for the generated Elm GraphQL example that hits the GitHub API.", "tokens": [337, 264, 10833, 2699, 76, 21884, 13695, 1365, 300, 8664, 264, 23331, 9362, 13], "temperature": 0.0, "avg_logprob": -0.14569070604112414, "compression_ratio": 1.5299539170506913, "no_speech_prob": 4.610994801623747e-05}, {"id": 408, "seek": 166940, "start": 1675.4, "end": 1677.4, "text": " What is the docs.json file?", "tokens": [708, 307, 264, 45623, 13, 73, 3015, 3991, 30], "temperature": 0.0, "avg_logprob": -0.14569070604112414, "compression_ratio": 1.5299539170506913, "no_speech_prob": 4.610994801623747e-05}, {"id": 409, "seek": 166940, "start": 1677.4, "end": 1684.4, "text": " Docs.json file is an encapsulation of all of the exposed values,", "tokens": [16024, 82, 13, 73, 3015, 3991, 307, 364, 38745, 2776, 295, 439, 295, 264, 9495, 4190, 11], "temperature": 0.0, "avg_logprob": -0.14569070604112414, "compression_ratio": 1.5299539170506913, "no_speech_prob": 4.610994801623747e-05}, {"id": 410, "seek": 166940, "start": 1684.4, "end": 1690.4, "text": " types, and functions for a package along with their corresponding documentation.", "tokens": [3467, 11, 293, 6828, 337, 257, 7372, 2051, 365, 641, 11760, 14333, 13], "temperature": 0.0, "avg_logprob": -0.14569070604112414, "compression_ratio": 1.5299539170506913, "no_speech_prob": 4.610994801623747e-05}, {"id": 411, "seek": 166940, "start": 1690.4, "end": 1695.4, "text": " So that is what the package docs present to us in a nice format on a site.", "tokens": [407, 300, 307, 437, 264, 7372, 45623, 1974, 281, 505, 294, 257, 1481, 7877, 322, 257, 3621, 13], "temperature": 0.0, "avg_logprob": -0.14569070604112414, "compression_ratio": 1.5299539170506913, "no_speech_prob": 4.610994801623747e-05}, {"id": 412, "seek": 166940, "start": 1695.4, "end": 1696.4, "text": " I could ship those.", "tokens": [286, 727, 5374, 729, 13], "temperature": 0.0, "avg_logprob": -0.14569070604112414, "compression_ratio": 1.5299539170506913, "no_speech_prob": 4.610994801623747e-05}, {"id": 413, "seek": 169640, "start": 1696.4, "end": 1701.4, "text": " I could ship that and then give people a link to documentation.", "tokens": [286, 727, 5374, 300, 293, 550, 976, 561, 257, 2113, 281, 14333, 13], "temperature": 0.0, "avg_logprob": -0.1781748881382225, "compression_ratio": 1.6986899563318778, "no_speech_prob": 3.3931216876226244e-06}, {"id": 414, "seek": 169640, "start": 1701.4, "end": 1705.4, "text": " That would be another cool way to present that information for a generated API", "tokens": [663, 576, 312, 1071, 1627, 636, 281, 1974, 300, 1589, 337, 257, 10833, 9362], "temperature": 0.0, "avg_logprob": -0.1781748881382225, "compression_ratio": 1.6986899563318778, "no_speech_prob": 3.3931216876226244e-06}, {"id": 415, "seek": 169640, "start": 1705.4, "end": 1707.4, "text": " using Elm Doc Preview.", "tokens": [1228, 2699, 76, 16024, 6001, 1759, 13], "temperature": 0.0, "avg_logprob": -0.1781748881382225, "compression_ratio": 1.6986899563318778, "no_speech_prob": 3.3931216876226244e-06}, {"id": 416, "seek": 169640, "start": 1707.4, "end": 1710.4, "text": " Aha, Elm Doc Preview. What the hell is that?", "tokens": [27448, 11, 2699, 76, 16024, 6001, 1759, 13, 708, 264, 4921, 307, 300, 30], "temperature": 0.0, "avg_logprob": -0.1781748881382225, "compression_ratio": 1.6986899563318778, "no_speech_prob": 3.3931216876226244e-06}, {"id": 417, "seek": 169640, "start": 1710.4, "end": 1713.4, "text": " Elm Doc Preview is a very good tool.", "tokens": [2699, 76, 16024, 6001, 1759, 307, 257, 588, 665, 2290, 13], "temperature": 0.0, "avg_logprob": -0.1781748881382225, "compression_ratio": 1.6986899563318778, "no_speech_prob": 3.3931216876226244e-06}, {"id": 418, "seek": 169640, "start": 1713.4, "end": 1716.4, "text": " We're in the glossary section.", "tokens": [492, 434, 294, 264, 19574, 822, 3541, 13], "temperature": 0.0, "avg_logprob": -0.1781748881382225, "compression_ratio": 1.6986899563318778, "no_speech_prob": 3.3931216876226244e-06}, {"id": 419, "seek": 169640, "start": 1716.4, "end": 1718.4, "text": " That's right. Exactly. Exactly.", "tokens": [663, 311, 558, 13, 7587, 13, 7587, 13], "temperature": 0.0, "avg_logprob": -0.1781748881382225, "compression_ratio": 1.6986899563318778, "no_speech_prob": 3.3931216876226244e-06}, {"id": 420, "seek": 169640, "start": 1718.4, "end": 1723.4, "text": " So Elm Doc Preview is a really nice tool that lets you, on your local machine,", "tokens": [407, 2699, 76, 16024, 6001, 1759, 307, 257, 534, 1481, 2290, 300, 6653, 291, 11, 322, 428, 2654, 3479, 11], "temperature": 0.0, "avg_logprob": -0.1781748881382225, "compression_ratio": 1.6986899563318778, "no_speech_prob": 3.3931216876226244e-06}, {"id": 421, "seek": 172340, "start": 1723.4, "end": 1730.4, "text": " it lets you do a live reloading server that will show you your package documentation", "tokens": [309, 6653, 291, 360, 257, 1621, 25628, 278, 7154, 300, 486, 855, 291, 428, 7372, 14333], "temperature": 0.0, "avg_logprob": -0.17620684026361821, "compression_ratio": 1.7598039215686274, "no_speech_prob": 5.338128175935708e-06}, {"id": 422, "seek": 172340, "start": 1730.4, "end": 1734.4, "text": " for an Elm package or compiler errors if there are any.", "tokens": [337, 364, 2699, 76, 7372, 420, 31958, 13603, 498, 456, 366, 604, 13], "temperature": 0.0, "avg_logprob": -0.17620684026361821, "compression_ratio": 1.7598039215686274, "no_speech_prob": 5.338128175935708e-06}, {"id": 423, "seek": 172340, "start": 1734.4, "end": 1737.4, "text": " It live reloads as you update your documentation.", "tokens": [467, 1621, 25628, 82, 382, 291, 5623, 428, 14333, 13], "temperature": 0.0, "avg_logprob": -0.17620684026361821, "compression_ratio": 1.7598039215686274, "no_speech_prob": 5.338128175935708e-06}, {"id": 424, "seek": 172340, "start": 1737.4, "end": 1739.4, "text": " It's an invaluable tool for package authors.", "tokens": [467, 311, 364, 40367, 2290, 337, 7372, 16552, 13], "temperature": 0.0, "avg_logprob": -0.17620684026361821, "compression_ratio": 1.7598039215686274, "no_speech_prob": 5.338128175935708e-06}, {"id": 425, "seek": 172340, "start": 1739.4, "end": 1744.4, "text": " You can also use it for displaying documentation for application code as well.", "tokens": [509, 393, 611, 764, 309, 337, 36834, 14333, 337, 3861, 3089, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.17620684026361821, "compression_ratio": 1.7598039215686274, "no_speech_prob": 5.338128175935708e-06}, {"id": 426, "seek": 172340, "start": 1744.4, "end": 1749.4, "text": " You can define an Elm-application.json file,", "tokens": [509, 393, 6964, 364, 2699, 76, 12, 1746, 1050, 399, 13, 73, 3015, 3991, 11], "temperature": 0.0, "avg_logprob": -0.17620684026361821, "compression_ratio": 1.7598039215686274, "no_speech_prob": 5.338128175935708e-06}, {"id": 427, "seek": 174940, "start": 1749.4, "end": 1753.4, "text": " and you can use it for in-house application documentation too,", "tokens": [293, 291, 393, 764, 309, 337, 294, 12, 6410, 3861, 14333, 886, 11], "temperature": 0.0, "avg_logprob": -0.18809384797748765, "compression_ratio": 1.6267942583732058, "no_speech_prob": 1.4510348592011724e-05}, {"id": 428, "seek": 174940, "start": 1753.4, "end": 1754.4, "text": " which is kind of interesting.", "tokens": [597, 307, 733, 295, 1880, 13], "temperature": 0.0, "avg_logprob": -0.18809384797748765, "compression_ratio": 1.6267942583732058, "no_speech_prob": 1.4510348592011724e-05}, {"id": 429, "seek": 174940, "start": 1754.4, "end": 1764.4, "text": " Or you can use the Elm Doc Preview site to share links to people that will present your,", "tokens": [1610, 291, 393, 764, 264, 2699, 76, 16024, 6001, 1759, 3621, 281, 2073, 6123, 281, 561, 300, 486, 1974, 428, 11], "temperature": 0.0, "avg_logprob": -0.18809384797748765, "compression_ratio": 1.6267942583732058, "no_speech_prob": 1.4510348592011724e-05}, {"id": 430, "seek": 174940, "start": 1764.4, "end": 1772.4, "text": " if you check in the docs.json that you get by running elm make dash dash docs equals docs.json,", "tokens": [498, 291, 1520, 294, 264, 45623, 13, 73, 3015, 300, 291, 483, 538, 2614, 806, 76, 652, 8240, 8240, 45623, 6915, 45623, 13, 73, 3015, 11], "temperature": 0.0, "avg_logprob": -0.18809384797748765, "compression_ratio": 1.6267942583732058, "no_speech_prob": 1.4510348592011724e-05}, {"id": 431, "seek": 174940, "start": 1772.4, "end": 1776.4, "text": " that's how you generate the docs.json file for an Elm package.", "tokens": [300, 311, 577, 291, 8460, 264, 45623, 13, 73, 3015, 3991, 337, 364, 2699, 76, 7372, 13], "temperature": 0.0, "avg_logprob": -0.18809384797748765, "compression_ratio": 1.6267942583732058, "no_speech_prob": 1.4510348592011724e-05}, {"id": 432, "seek": 177640, "start": 1776.4, "end": 1780.4, "text": " If you share that, if you commit that docs.json,", "tokens": [759, 291, 2073, 300, 11, 498, 291, 5599, 300, 45623, 13, 73, 3015, 11], "temperature": 0.0, "avg_logprob": -0.18092047373453776, "compression_ratio": 1.663594470046083, "no_speech_prob": 4.7107973841775674e-06}, {"id": 433, "seek": 177640, "start": 1780.4, "end": 1785.4, "text": " then you can share a live preview link of pending documentation.", "tokens": [550, 291, 393, 2073, 257, 1621, 14281, 2113, 295, 32110, 14333, 13], "temperature": 0.0, "avg_logprob": -0.18092047373453776, "compression_ratio": 1.663594470046083, "no_speech_prob": 4.7107973841775674e-06}, {"id": 434, "seek": 177640, "start": 1785.4, "end": 1792.4, "text": " And that is a really valuable process for unpublished packages that you want to get feedback on, for example.", "tokens": [400, 300, 307, 257, 534, 8263, 1399, 337, 20994, 836, 4173, 17401, 300, 291, 528, 281, 483, 5824, 322, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.18092047373453776, "compression_ratio": 1.663594470046083, "no_speech_prob": 4.7107973841775674e-06}, {"id": 435, "seek": 177640, "start": 1792.4, "end": 1798.4, "text": " Absolutely. Yeah, it's a really valuable tool because often you're writing documentation", "tokens": [7021, 13, 865, 11, 309, 311, 257, 534, 8263, 2290, 570, 2049, 291, 434, 3579, 14333], "temperature": 0.0, "avg_logprob": -0.18092047373453776, "compression_ratio": 1.663594470046083, "no_speech_prob": 4.7107973841775674e-06}, {"id": 436, "seek": 177640, "start": 1798.4, "end": 1801.4, "text": " and you're not sure how it's going to look like,", "tokens": [293, 291, 434, 406, 988, 577, 309, 311, 516, 281, 574, 411, 11], "temperature": 0.0, "avg_logprob": -0.18092047373453776, "compression_ratio": 1.663594470046083, "no_speech_prob": 4.7107973841775674e-06}, {"id": 437, "seek": 180140, "start": 1801.4, "end": 1806.4, "text": " and you write it and then you don't notice problems with it.", "tokens": [293, 291, 2464, 309, 293, 550, 291, 500, 380, 3449, 2740, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.2131610003384677, "compression_ratio": 1.7887931034482758, "no_speech_prob": 1.1477768566692248e-05}, {"id": 438, "seek": 180140, "start": 1806.4, "end": 1808.4, "text": " That will be obvious once you've published it.", "tokens": [663, 486, 312, 6322, 1564, 291, 600, 6572, 309, 13], "temperature": 0.0, "avg_logprob": -0.2131610003384677, "compression_ratio": 1.7887931034482758, "no_speech_prob": 1.1477768566692248e-05}, {"id": 439, "seek": 180140, "start": 1808.4, "end": 1814.4, "text": " So for instance, like if you indent some code in your documentation,", "tokens": [407, 337, 5197, 11, 411, 498, 291, 44494, 512, 3089, 294, 428, 14333, 11], "temperature": 0.0, "avg_logprob": -0.2131610003384677, "compression_ratio": 1.7887931034482758, "no_speech_prob": 1.1477768566692248e-05}, {"id": 440, "seek": 180140, "start": 1814.4, "end": 1817.4, "text": " that will be displayed as Elm code.", "tokens": [300, 486, 312, 16372, 382, 2699, 76, 3089, 13], "temperature": 0.0, "avg_logprob": -0.2131610003384677, "compression_ratio": 1.7887931034482758, "no_speech_prob": 1.1477768566692248e-05}, {"id": 441, "seek": 180140, "start": 1817.4, "end": 1822.4, "text": " But if you don't indent it correctly, then it might not be showing that way,", "tokens": [583, 498, 291, 500, 380, 44494, 309, 8944, 11, 550, 309, 1062, 406, 312, 4099, 300, 636, 11], "temperature": 0.0, "avg_logprob": -0.2131610003384677, "compression_ratio": 1.7887931034482758, "no_speech_prob": 1.1477768566692248e-05}, {"id": 442, "seek": 180140, "start": 1822.4, "end": 1826.4, "text": " and then everything will be on one line and it will be very ugly.", "tokens": [293, 550, 1203, 486, 312, 322, 472, 1622, 293, 309, 486, 312, 588, 12246, 13], "temperature": 0.0, "avg_logprob": -0.2131610003384677, "compression_ratio": 1.7887931034482758, "no_speech_prob": 1.1477768566692248e-05}, {"id": 443, "seek": 180140, "start": 1826.4, "end": 1830.4, "text": " So you don't want to notice that after you've published it.", "tokens": [407, 291, 500, 380, 528, 281, 3449, 300, 934, 291, 600, 6572, 309, 13], "temperature": 0.0, "avg_logprob": -0.2131610003384677, "compression_ratio": 1.7887931034482758, "no_speech_prob": 1.1477768566692248e-05}, {"id": 444, "seek": 183040, "start": 1830.4, "end": 1834.4, "text": " You don't want to fix a documentation issue, republish,", "tokens": [509, 500, 380, 528, 281, 3191, 257, 14333, 2734, 11, 1085, 836, 1933, 11], "temperature": 0.0, "avg_logprob": -0.18396397126026642, "compression_ratio": 1.6477732793522266, "no_speech_prob": 2.3185413738247007e-05}, {"id": 445, "seek": 183040, "start": 1834.4, "end": 1839.4, "text": " see that it's still not looking okay, and then republish, and so on and so on.", "tokens": [536, 300, 309, 311, 920, 406, 1237, 1392, 11, 293, 550, 1085, 836, 1933, 11, 293, 370, 322, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.18396397126026642, "compression_ratio": 1.6477732793522266, "no_speech_prob": 2.3185413738247007e-05}, {"id": 446, "seek": 183040, "start": 1839.4, "end": 1845.4, "text": " There are also a few things that the Elm package website doesn't handle correctly,", "tokens": [821, 366, 611, 257, 1326, 721, 300, 264, 2699, 76, 7372, 3144, 1177, 380, 4813, 8944, 11], "temperature": 0.0, "avg_logprob": -0.18396397126026642, "compression_ratio": 1.6477732793522266, "no_speech_prob": 2.3185413738247007e-05}, {"id": 447, "seek": 183040, "start": 1845.4, "end": 1847.4, "text": " like markdown tables.", "tokens": [411, 1491, 5093, 8020, 13], "temperature": 0.0, "avg_logprob": -0.18396397126026642, "compression_ratio": 1.6477732793522266, "no_speech_prob": 2.3185413738247007e-05}, {"id": 448, "seek": 183040, "start": 1847.4, "end": 1852.4, "text": " Great idea in theory. In practice, it's not looking great at all.", "tokens": [3769, 1558, 294, 5261, 13, 682, 3124, 11, 309, 311, 406, 1237, 869, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.18396397126026642, "compression_ratio": 1.6477732793522266, "no_speech_prob": 2.3185413738247007e-05}, {"id": 449, "seek": 183040, "start": 1852.4, "end": 1854.4, "text": " So don't use those.", "tokens": [407, 500, 380, 764, 729, 13], "temperature": 0.0, "avg_logprob": -0.18396397126026642, "compression_ratio": 1.6477732793522266, "no_speech_prob": 2.3185413738247007e-05}, {"id": 450, "seek": 183040, "start": 1854.4, "end": 1859.4, "text": " And if you use Elm doc preview, you will notice that it's not going to look okay.", "tokens": [400, 498, 291, 764, 2699, 76, 3211, 14281, 11, 291, 486, 3449, 300, 309, 311, 406, 516, 281, 574, 1392, 13], "temperature": 0.0, "avg_logprob": -0.18396397126026642, "compression_ratio": 1.6477732793522266, "no_speech_prob": 2.3185413738247007e-05}, {"id": 451, "seek": 185940, "start": 1859.4, "end": 1865.4, "text": " There are a few issues, like if you have the add docs annotations", "tokens": [821, 366, 257, 1326, 2663, 11, 411, 498, 291, 362, 264, 909, 45623, 25339, 763], "temperature": 0.0, "avg_logprob": -0.18190317153930663, "compression_ratio": 1.5905172413793103, "no_speech_prob": 2.36877554016246e-06}, {"id": 452, "seek": 185940, "start": 1865.4, "end": 1869.4, "text": " that are done in slightly incorrect ways,", "tokens": [300, 366, 1096, 294, 4748, 18424, 2098, 11], "temperature": 0.0, "avg_logprob": -0.18190317153930663, "compression_ratio": 1.5905172413793103, "no_speech_prob": 2.36877554016246e-06}, {"id": 453, "seek": 185940, "start": 1869.4, "end": 1872.4, "text": " then they're not going to show up okay in the package website.", "tokens": [550, 436, 434, 406, 516, 281, 855, 493, 1392, 294, 264, 7372, 3144, 13], "temperature": 0.0, "avg_logprob": -0.18190317153930663, "compression_ratio": 1.5905172413793103, "no_speech_prob": 2.36877554016246e-06}, {"id": 454, "seek": 185940, "start": 1872.4, "end": 1875.4, "text": " So you also want to know about those early on.", "tokens": [407, 291, 611, 528, 281, 458, 466, 729, 2440, 322, 13], "temperature": 0.0, "avg_logprob": -0.18190317153930663, "compression_ratio": 1.5905172413793103, "no_speech_prob": 2.36877554016246e-06}, {"id": 455, "seek": 185940, "start": 1875.4, "end": 1879.4, "text": " So yeah, Elm doc preview, awesome tool to write your docs", "tokens": [407, 1338, 11, 2699, 76, 3211, 14281, 11, 3476, 2290, 281, 2464, 428, 45623], "temperature": 0.0, "avg_logprob": -0.18190317153930663, "compression_ratio": 1.5905172413793103, "no_speech_prob": 2.36877554016246e-06}, {"id": 456, "seek": 185940, "start": 1879.4, "end": 1883.4, "text": " and to be able to read through them in a much easier way,", "tokens": [293, 281, 312, 1075, 281, 1401, 807, 552, 294, 257, 709, 3571, 636, 11], "temperature": 0.0, "avg_logprob": -0.18190317153930663, "compression_ratio": 1.5905172413793103, "no_speech_prob": 2.36877554016246e-06}, {"id": 457, "seek": 185940, "start": 1883.4, "end": 1887.4, "text": " like the way that your users would.", "tokens": [411, 264, 636, 300, 428, 5022, 576, 13], "temperature": 0.0, "avg_logprob": -0.18190317153930663, "compression_ratio": 1.5905172413793103, "no_speech_prob": 2.36877554016246e-06}, {"id": 458, "seek": 188740, "start": 1887.4, "end": 1894.4, "text": " Instead of having to go through your docs that are spread out all over your Elm code,", "tokens": [7156, 295, 1419, 281, 352, 807, 428, 45623, 300, 366, 3974, 484, 439, 670, 428, 2699, 76, 3089, 11], "temperature": 0.0, "avg_logprob": -0.18985992603087692, "compression_ratio": 1.643835616438356, "no_speech_prob": 5.0934013415826485e-06}, {"id": 459, "seek": 188740, "start": 1894.4, "end": 1897.4, "text": " which is not as great an experience.", "tokens": [597, 307, 406, 382, 869, 364, 1752, 13], "temperature": 0.0, "avg_logprob": -0.18985992603087692, "compression_ratio": 1.643835616438356, "no_speech_prob": 5.0934013415826485e-06}, {"id": 460, "seek": 188740, "start": 1897.4, "end": 1903.4, "text": " It's also very motivating to see what needs documentation and what doesn't", "tokens": [467, 311, 611, 588, 41066, 281, 536, 437, 2203, 14333, 293, 437, 1177, 380], "temperature": 0.0, "avg_logprob": -0.18985992603087692, "compression_ratio": 1.643835616438356, "no_speech_prob": 5.0934013415826485e-06}, {"id": 461, "seek": 188740, "start": 1903.4, "end": 1907.4, "text": " and just read through a live preview of your docs", "tokens": [293, 445, 1401, 807, 257, 1621, 14281, 295, 428, 45623], "temperature": 0.0, "avg_logprob": -0.18985992603087692, "compression_ratio": 1.643835616438356, "no_speech_prob": 5.0934013415826485e-06}, {"id": 462, "seek": 188740, "start": 1907.4, "end": 1911.4, "text": " in that layout of a package documentation site.", "tokens": [294, 300, 13333, 295, 257, 7372, 14333, 3621, 13], "temperature": 0.0, "avg_logprob": -0.18985992603087692, "compression_ratio": 1.643835616438356, "no_speech_prob": 5.0934013415826485e-06}, {"id": 463, "seek": 188740, "start": 1911.4, "end": 1916.4, "text": " And for me, just seeing something I don't like or that's missing", "tokens": [400, 337, 385, 11, 445, 2577, 746, 286, 500, 380, 411, 420, 300, 311, 5361], "temperature": 0.0, "avg_logprob": -0.18985992603087692, "compression_ratio": 1.643835616438356, "no_speech_prob": 5.0934013415826485e-06}, {"id": 464, "seek": 191640, "start": 1916.4, "end": 1918.4, "text": " makes me want to go write it.", "tokens": [1669, 385, 528, 281, 352, 2464, 309, 13], "temperature": 0.0, "avg_logprob": -0.18106035842108972, "compression_ratio": 1.6435185185185186, "no_speech_prob": 2.3186203179648146e-05}, {"id": 465, "seek": 191640, "start": 1918.4, "end": 1921.4, "text": " So I started to get that little kick to go do it.", "tokens": [407, 286, 1409, 281, 483, 300, 707, 4437, 281, 352, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.18106035842108972, "compression_ratio": 1.6435185185185186, "no_speech_prob": 2.3186203179648146e-05}, {"id": 466, "seek": 191640, "start": 1921.4, "end": 1927.4, "text": " There's one thing where you have to have a valid docs.json file", "tokens": [821, 311, 472, 551, 689, 291, 362, 281, 362, 257, 7363, 45623, 13, 73, 3015, 3991], "temperature": 0.0, "avg_logprob": -0.18106035842108972, "compression_ratio": 1.6435185185185186, "no_speech_prob": 2.3186203179648146e-05}, {"id": 467, "seek": 191640, "start": 1927.4, "end": 1930.4, "text": " to be able to preview your docs.", "tokens": [281, 312, 1075, 281, 14281, 428, 45623, 13], "temperature": 0.0, "avg_logprob": -0.18106035842108972, "compression_ratio": 1.6435185185185186, "no_speech_prob": 2.3186203179648146e-05}, {"id": 468, "seek": 191640, "start": 1930.4, "end": 1933.4, "text": " And that means that you need to have written documentation", "tokens": [400, 300, 1355, 300, 291, 643, 281, 362, 3720, 14333], "temperature": 0.0, "avg_logprob": -0.18106035842108972, "compression_ratio": 1.6435185185185186, "no_speech_prob": 2.3186203179648146e-05}, {"id": 469, "seek": 191640, "start": 1933.4, "end": 1936.4, "text": " for every exposed thing.", "tokens": [337, 633, 9495, 551, 13], "temperature": 0.0, "avg_logprob": -0.18106035842108972, "compression_ratio": 1.6435185185185186, "no_speech_prob": 2.3186203179648146e-05}, {"id": 470, "seek": 191640, "start": 1936.4, "end": 1940.4, "text": " In practice, if you want to see it really quickly", "tokens": [682, 3124, 11, 498, 291, 528, 281, 536, 309, 534, 2661], "temperature": 0.0, "avg_logprob": -0.18106035842108972, "compression_ratio": 1.6435185185185186, "no_speech_prob": 2.3186203179648146e-05}, {"id": 471, "seek": 191640, "start": 1940.4, "end": 1943.4, "text": " and without documenting some of the modules,", "tokens": [293, 1553, 42360, 512, 295, 264, 16679, 11], "temperature": 0.0, "avg_logprob": -0.18106035842108972, "compression_ratio": 1.6435185185185186, "no_speech_prob": 2.3186203179648146e-05}, {"id": 472, "seek": 194340, "start": 1943.4, "end": 1950.4, "text": " then you're going to add like empty documentation comments or to-dos,", "tokens": [550, 291, 434, 516, 281, 909, 411, 6707, 14333, 3053, 420, 281, 12, 33749, 11], "temperature": 0.0, "avg_logprob": -0.20223959854670934, "compression_ratio": 1.6208333333333333, "no_speech_prob": 1.0188007308897795e-06}, {"id": 473, "seek": 194340, "start": 1950.4, "end": 1955.4, "text": " which is probably a little bit better because it will be more obvious.", "tokens": [597, 307, 1391, 257, 707, 857, 1101, 570, 309, 486, 312, 544, 6322, 13], "temperature": 0.0, "avg_logprob": -0.20223959854670934, "compression_ratio": 1.6208333333333333, "no_speech_prob": 1.0188007308897795e-06}, {"id": 474, "seek": 194340, "start": 1955.4, "end": 1957.4, "text": " Yeah, that's a good idea.", "tokens": [865, 11, 300, 311, 257, 665, 1558, 13], "temperature": 0.0, "avg_logprob": -0.20223959854670934, "compression_ratio": 1.6208333333333333, "no_speech_prob": 1.0188007308897795e-06}, {"id": 475, "seek": 194340, "start": 1957.4, "end": 1960.4, "text": " I usually do empty ones, but yeah, to-dos is a good idea.", "tokens": [286, 2673, 360, 6707, 2306, 11, 457, 1338, 11, 281, 12, 33749, 307, 257, 665, 1558, 13], "temperature": 0.0, "avg_logprob": -0.20223959854670934, "compression_ratio": 1.6208333333333333, "no_speech_prob": 1.0188007308897795e-06}, {"id": 476, "seek": 194340, "start": 1960.4, "end": 1965.4, "text": " But I do it in tandem with your no missing documentation Elm review rule.", "tokens": [583, 286, 360, 309, 294, 48120, 365, 428, 572, 5361, 14333, 2699, 76, 3131, 4978, 13], "temperature": 0.0, "avg_logprob": -0.20223959854670934, "compression_ratio": 1.6208333333333333, "no_speech_prob": 1.0188007308897795e-06}, {"id": 477, "seek": 194340, "start": 1965.4, "end": 1966.4, "text": " I think that's what it's called.", "tokens": [286, 519, 300, 311, 437, 309, 311, 1219, 13], "temperature": 0.0, "avg_logprob": -0.20223959854670934, "compression_ratio": 1.6208333333333333, "no_speech_prob": 1.0188007308897795e-06}, {"id": 478, "seek": 194340, "start": 1966.4, "end": 1968.4, "text": " Yeah, docs.nomissing.", "tokens": [865, 11, 45623, 13, 15819, 891, 278, 13], "temperature": 0.0, "avg_logprob": -0.20223959854670934, "compression_ratio": 1.6208333333333333, "no_speech_prob": 1.0188007308897795e-06}, {"id": 479, "seek": 194340, "start": 1968.4, "end": 1971.4, "text": " We can talk about those afterwards.", "tokens": [492, 393, 751, 466, 729, 10543, 13], "temperature": 0.0, "avg_logprob": -0.20223959854670934, "compression_ratio": 1.6208333333333333, "no_speech_prob": 1.0188007308897795e-06}, {"id": 480, "seek": 197140, "start": 1971.4, "end": 1977.4, "text": " I kind of mentioned this before, and we got lost in thought, I guess.", "tokens": [286, 733, 295, 2835, 341, 949, 11, 293, 321, 658, 2731, 294, 1194, 11, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.26132158915201825, "compression_ratio": 1.5336787564766838, "no_speech_prob": 1.670088204264175e-05}, {"id": 481, "seek": 197140, "start": 1977.4, "end": 1981.4, "text": " But the one reason why we have good documentation in Elm", "tokens": [583, 264, 472, 1778, 983, 321, 362, 665, 14333, 294, 2699, 76], "temperature": 0.0, "avg_logprob": -0.26132158915201825, "compression_ratio": 1.5336787564766838, "no_speech_prob": 1.670088204264175e-05}, {"id": 482, "seek": 197140, "start": 1981.4, "end": 1985.4, "text": " is because there are sections built in.", "tokens": [307, 570, 456, 366, 10863, 3094, 294, 13], "temperature": 0.0, "avg_logprob": -0.26132158915201825, "compression_ratio": 1.5336787564766838, "no_speech_prob": 1.670088204264175e-05}, {"id": 483, "seek": 197140, "start": 1985.4, "end": 1994.4, "text": " So every module that you expose is a different page or different section,", "tokens": [407, 633, 10088, 300, 291, 19219, 307, 257, 819, 3028, 420, 819, 3541, 11], "temperature": 0.0, "avg_logprob": -0.26132158915201825, "compression_ratio": 1.5336787564766838, "no_speech_prob": 1.670088204264175e-05}, {"id": 484, "seek": 197140, "start": 1994.4, "end": 1997.4, "text": " however you want to call those, on the package website,", "tokens": [4461, 291, 528, 281, 818, 729, 11, 322, 264, 7372, 3144, 11], "temperature": 0.0, "avg_logprob": -0.26132158915201825, "compression_ratio": 1.5336787564766838, "no_speech_prob": 1.670088204264175e-05}, {"id": 485, "seek": 199740, "start": 1997.4, "end": 2001.4, "text": " meaning that not everything has to be in the README,", "tokens": [3620, 300, 406, 1203, 575, 281, 312, 294, 264, 10869, 6112, 15454, 11], "temperature": 0.0, "avg_logprob": -0.15501066734050883, "compression_ratio": 1.6194331983805668, "no_speech_prob": 8.662441359774675e-06}, {"id": 486, "seek": 199740, "start": 2001.4, "end": 2004.4, "text": " which I think is pretty good.", "tokens": [597, 286, 519, 307, 1238, 665, 13], "temperature": 0.0, "avg_logprob": -0.15501066734050883, "compression_ratio": 1.6194331983805668, "no_speech_prob": 8.662441359774675e-06}, {"id": 487, "seek": 199740, "start": 2004.4, "end": 2006.4, "text": " Not sure whether it's sufficient.", "tokens": [1726, 988, 1968, 309, 311, 11563, 13], "temperature": 0.0, "avg_logprob": -0.15501066734050883, "compression_ratio": 1.6194331983805668, "no_speech_prob": 8.662441359774675e-06}, {"id": 488, "seek": 199740, "start": 2006.4, "end": 2008.4, "text": " In a lot of cases, yes.", "tokens": [682, 257, 688, 295, 3331, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.15501066734050883, "compression_ratio": 1.6194331983805668, "no_speech_prob": 8.662441359774675e-06}, {"id": 489, "seek": 199740, "start": 2008.4, "end": 2009.4, "text": " In some cases, maybe not.", "tokens": [682, 512, 3331, 11, 1310, 406, 13], "temperature": 0.0, "avg_logprob": -0.15501066734050883, "compression_ratio": 1.6194331983805668, "no_speech_prob": 8.662441359774675e-06}, {"id": 490, "seek": 199740, "start": 2009.4, "end": 2013.4, "text": " But it's a pretty good thing to have at least.", "tokens": [583, 309, 311, 257, 1238, 665, 551, 281, 362, 412, 1935, 13], "temperature": 0.0, "avg_logprob": -0.15501066734050883, "compression_ratio": 1.6194331983805668, "no_speech_prob": 8.662441359774675e-06}, {"id": 491, "seek": 199740, "start": 2013.4, "end": 2018.4, "text": " So yeah, just the fact that you can separate some documentation from others", "tokens": [407, 1338, 11, 445, 264, 1186, 300, 291, 393, 4994, 512, 14333, 490, 2357], "temperature": 0.0, "avg_logprob": -0.15501066734050883, "compression_ratio": 1.6194331983805668, "no_speech_prob": 8.662441359774675e-06}, {"id": 492, "seek": 199740, "start": 2018.4, "end": 2019.4, "text": " is good.", "tokens": [307, 665, 13], "temperature": 0.0, "avg_logprob": -0.15501066734050883, "compression_ratio": 1.6194331983805668, "no_speech_prob": 8.662441359774675e-06}, {"id": 493, "seek": 199740, "start": 2019.4, "end": 2022.4, "text": " So for instance, if you have like one module,", "tokens": [407, 337, 5197, 11, 498, 291, 362, 411, 472, 10088, 11], "temperature": 0.0, "avg_logprob": -0.15501066734050883, "compression_ratio": 1.6194331983805668, "no_speech_prob": 8.662441359774675e-06}, {"id": 494, "seek": 199740, "start": 2022.4, "end": 2026.4, "text": " which is a lot of tiny helpers with plenty of functions", "tokens": [597, 307, 257, 688, 295, 5870, 854, 433, 365, 7140, 295, 6828], "temperature": 0.0, "avg_logprob": -0.15501066734050883, "compression_ratio": 1.6194331983805668, "no_speech_prob": 8.662441359774675e-06}, {"id": 495, "seek": 202640, "start": 2026.4, "end": 2030.4, "text": " that are not very important to the rest of the API,", "tokens": [300, 366, 406, 588, 1021, 281, 264, 1472, 295, 264, 9362, 11], "temperature": 0.0, "avg_logprob": -0.17623353004455566, "compression_ratio": 1.624413145539906, "no_speech_prob": 2.3687603061262053e-06}, {"id": 496, "seek": 202640, "start": 2030.4, "end": 2033.4, "text": " then you can separate those into one module,", "tokens": [550, 291, 393, 4994, 729, 666, 472, 10088, 11], "temperature": 0.0, "avg_logprob": -0.17623353004455566, "compression_ratio": 1.624413145539906, "no_speech_prob": 2.3687603061262053e-06}, {"id": 497, "seek": 202640, "start": 2033.4, "end": 2037.4, "text": " and they don't pollute, they don't waste space", "tokens": [293, 436, 500, 380, 6418, 1169, 11, 436, 500, 380, 5964, 1901], "temperature": 0.0, "avg_logprob": -0.17623353004455566, "compression_ratio": 1.624413145539906, "no_speech_prob": 2.3687603061262053e-06}, {"id": 498, "seek": 202640, "start": 2037.4, "end": 2040.4, "text": " for the more important modules of your API.", "tokens": [337, 264, 544, 1021, 16679, 295, 428, 9362, 13], "temperature": 0.0, "avg_logprob": -0.17623353004455566, "compression_ratio": 1.624413145539906, "no_speech_prob": 2.3687603061262053e-06}, {"id": 499, "seek": 202640, "start": 2040.4, "end": 2044.4, "text": " So I think that's a pretty important part of why docs are pretty good", "tokens": [407, 286, 519, 300, 311, 257, 1238, 1021, 644, 295, 983, 45623, 366, 1238, 665], "temperature": 0.0, "avg_logprob": -0.17623353004455566, "compression_ratio": 1.624413145539906, "no_speech_prob": 2.3687603061262053e-06}, {"id": 500, "seek": 202640, "start": 2044.4, "end": 2046.4, "text": " as a starting point.", "tokens": [382, 257, 2891, 935, 13], "temperature": 0.0, "avg_logprob": -0.17623353004455566, "compression_ratio": 1.624413145539906, "no_speech_prob": 2.3687603061262053e-06}, {"id": 501, "seek": 202640, "start": 2046.4, "end": 2048.4, "text": " I totally agree.", "tokens": [286, 3879, 3986, 13], "temperature": 0.0, "avg_logprob": -0.17623353004455566, "compression_ratio": 1.624413145539906, "no_speech_prob": 2.3687603061262053e-06}, {"id": 502, "seek": 202640, "start": 2048.4, "end": 2051.4, "text": " And just to put a fine point on that mechanically,", "tokens": [400, 445, 281, 829, 257, 2489, 935, 322, 300, 4236, 984, 11], "temperature": 0.0, "avg_logprob": -0.17623353004455566, "compression_ratio": 1.624413145539906, "no_speech_prob": 2.3687603061262053e-06}, {"id": 503, "seek": 205140, "start": 2051.4, "end": 2056.4, "text": " what you're describing is so when you're writing an elm package,", "tokens": [437, 291, 434, 16141, 307, 370, 562, 291, 434, 3579, 364, 806, 76, 7372, 11], "temperature": 0.0, "avg_logprob": -0.20327457304923766, "compression_ratio": 1.8385416666666667, "no_speech_prob": 1.3631279216497205e-05}, {"id": 504, "seek": 205140, "start": 2056.4, "end": 2062.4, "text": " you can write doc comments, which is just a special comment format.", "tokens": [291, 393, 2464, 3211, 3053, 11, 597, 307, 445, 257, 2121, 2871, 7877, 13], "temperature": 0.0, "avg_logprob": -0.20327457304923766, "compression_ratio": 1.8385416666666667, "no_speech_prob": 1.3631279216497205e-05}, {"id": 505, "seek": 205140, "start": 2062.4, "end": 2066.4, "text": " You can write that for your top-level values,", "tokens": [509, 393, 2464, 300, 337, 428, 1192, 12, 12418, 4190, 11], "temperature": 0.0, "avg_logprob": -0.20327457304923766, "compression_ratio": 1.8385416666666667, "no_speech_prob": 1.3631279216497205e-05}, {"id": 506, "seek": 205140, "start": 2066.4, "end": 2068.4, "text": " and you can also write that for the module.", "tokens": [293, 291, 393, 611, 2464, 300, 337, 264, 10088, 13], "temperature": 0.0, "avg_logprob": -0.20327457304923766, "compression_ratio": 1.8385416666666667, "no_speech_prob": 1.3631279216497205e-05}, {"id": 507, "seek": 205140, "start": 2068.4, "end": 2074.4, "text": " So the module has its docs, and each function and exposed value has its docs.", "tokens": [407, 264, 10088, 575, 1080, 45623, 11, 293, 1184, 2445, 293, 9495, 2158, 575, 1080, 45623, 13], "temperature": 0.0, "avg_logprob": -0.20327457304923766, "compression_ratio": 1.8385416666666667, "no_speech_prob": 1.3631279216497205e-05}, {"id": 508, "seek": 205140, "start": 2074.4, "end": 2079.4, "text": " You use an annotation in the top-level module's docs", "tokens": [509, 764, 364, 48654, 294, 264, 1192, 12, 12418, 10088, 311, 45623], "temperature": 0.0, "avg_logprob": -0.20327457304923766, "compression_ratio": 1.8385416666666667, "no_speech_prob": 1.3631279216497205e-05}, {"id": 509, "seek": 207940, "start": 2079.4, "end": 2084.4, "text": " to list out all of the exposed values that you want to document.", "tokens": [281, 1329, 484, 439, 295, 264, 9495, 4190, 300, 291, 528, 281, 4166, 13], "temperature": 0.0, "avg_logprob": -0.1943820504581227, "compression_ratio": 1.819047619047619, "no_speech_prob": 8.664638698974159e-06}, {"id": 510, "seek": 207940, "start": 2084.4, "end": 2086.4, "text": " So you can group them into sections.", "tokens": [407, 291, 393, 1594, 552, 666, 10863, 13], "temperature": 0.0, "avg_logprob": -0.1943820504581227, "compression_ratio": 1.819047619047619, "no_speech_prob": 8.664638698974159e-06}, {"id": 511, "seek": 207940, "start": 2086.4, "end": 2089.4, "text": " So you can say, wiring up a form,", "tokens": [407, 291, 393, 584, 11, 27520, 493, 257, 1254, 11], "temperature": 0.0, "avg_logprob": -0.1943820504581227, "compression_ratio": 1.819047619047619, "no_speech_prob": 8.664638698974159e-06}, {"id": 512, "seek": 207940, "start": 2089.4, "end": 2092.4, "text": " here's the init update view function for the form.", "tokens": [510, 311, 264, 3157, 5623, 1910, 2445, 337, 264, 1254, 13], "temperature": 0.0, "avg_logprob": -0.1943820504581227, "compression_ratio": 1.819047619047619, "no_speech_prob": 8.664638698974159e-06}, {"id": 513, "seek": 207940, "start": 2092.4, "end": 2096.4, "text": " And then you can say, defining a field,", "tokens": [400, 550, 291, 393, 584, 11, 17827, 257, 2519, 11], "temperature": 0.0, "avg_logprob": -0.1943820504581227, "compression_ratio": 1.819047619047619, "no_speech_prob": 8.664638698974159e-06}, {"id": 514, "seek": 207940, "start": 2096.4, "end": 2100.4, "text": " here's the checkbox and whatever functions for building a field.", "tokens": [510, 311, 264, 1520, 4995, 293, 2035, 6828, 337, 2390, 257, 2519, 13], "temperature": 0.0, "avg_logprob": -0.1943820504581227, "compression_ratio": 1.819047619047619, "no_speech_prob": 8.664638698974159e-06}, {"id": 515, "seek": 207940, "start": 2100.4, "end": 2103.4, "text": " And you can group those into sections using Markdown", "tokens": [400, 291, 393, 1594, 729, 666, 10863, 1228, 3934, 5093], "temperature": 0.0, "avg_logprob": -0.1943820504581227, "compression_ratio": 1.819047619047619, "no_speech_prob": 8.664638698974159e-06}, {"id": 516, "seek": 207940, "start": 2103.4, "end": 2105.4, "text": " because the docs use Markdown format.", "tokens": [570, 264, 45623, 764, 3934, 5093, 7877, 13], "temperature": 0.0, "avg_logprob": -0.1943820504581227, "compression_ratio": 1.819047619047619, "no_speech_prob": 8.664638698974159e-06}, {"id": 517, "seek": 210540, "start": 2105.4, "end": 2110.4, "text": " So if you use the hash hash for an H2 heading,", "tokens": [407, 498, 291, 764, 264, 22019, 22019, 337, 364, 389, 17, 9864, 11], "temperature": 0.0, "avg_logprob": -0.17914026174972306, "compression_ratio": 1.8130081300813008, "no_speech_prob": 1.497091943747364e-05}, {"id": 518, "seek": 210540, "start": 2110.4, "end": 2112.4, "text": " it separates it into headings.", "tokens": [309, 34149, 309, 666, 1378, 1109, 13], "temperature": 0.0, "avg_logprob": -0.17914026174972306, "compression_ratio": 1.8130081300813008, "no_speech_prob": 1.497091943747364e-05}, {"id": 519, "seek": 210540, "start": 2112.4, "end": 2114.4, "text": " And you can even link to those headings.", "tokens": [400, 291, 393, 754, 2113, 281, 729, 1378, 1109, 13], "temperature": 0.0, "avg_logprob": -0.17914026174972306, "compression_ratio": 1.8130081300813008, "no_speech_prob": 1.497091943747364e-05}, {"id": 520, "seek": 210540, "start": 2114.4, "end": 2116.4, "text": " So you can link somebody.", "tokens": [407, 291, 393, 2113, 2618, 13], "temperature": 0.0, "avg_logprob": -0.17914026174972306, "compression_ratio": 1.8130081300813008, "no_speech_prob": 1.497091943747364e-05}, {"id": 521, "seek": 210540, "start": 2116.4, "end": 2119.4, "text": " You have to sort of open up the inspector tool", "tokens": [509, 362, 281, 1333, 295, 1269, 493, 264, 34564, 2290], "temperature": 0.0, "avg_logprob": -0.17914026174972306, "compression_ratio": 1.8130081300813008, "no_speech_prob": 1.497091943747364e-05}, {"id": 522, "seek": 210540, "start": 2119.4, "end": 2122.4, "text": " and click to it because it's not linked at the moment,", "tokens": [293, 2052, 281, 309, 570, 309, 311, 406, 9408, 412, 264, 1623, 11], "temperature": 0.0, "avg_logprob": -0.17914026174972306, "compression_ratio": 1.8130081300813008, "no_speech_prob": 1.497091943747364e-05}, {"id": 523, "seek": 210540, "start": 2122.4, "end": 2124.4, "text": " but it gets the job done.", "tokens": [457, 309, 2170, 264, 1691, 1096, 13], "temperature": 0.0, "avg_logprob": -0.17914026174972306, "compression_ratio": 1.8130081300813008, "no_speech_prob": 1.497091943747364e-05}, {"id": 524, "seek": 210540, "start": 2124.4, "end": 2127.4, "text": " Yeah, you kind of have to guess also what the name of the link is", "tokens": [865, 11, 291, 733, 295, 362, 281, 2041, 611, 437, 264, 1315, 295, 264, 2113, 307], "temperature": 0.0, "avg_logprob": -0.17914026174972306, "compression_ratio": 1.8130081300813008, "no_speech_prob": 1.497091943747364e-05}, {"id": 525, "seek": 210540, "start": 2127.4, "end": 2130.4, "text": " or what the href for the link is.", "tokens": [420, 437, 264, 276, 33115, 337, 264, 2113, 307, 13], "temperature": 0.0, "avg_logprob": -0.17914026174972306, "compression_ratio": 1.8130081300813008, "no_speech_prob": 1.497091943747364e-05}, {"id": 526, "seek": 210540, "start": 2130.4, "end": 2132.4, "text": " I find it with the inspector.", "tokens": [286, 915, 309, 365, 264, 34564, 13], "temperature": 0.0, "avg_logprob": -0.17914026174972306, "compression_ratio": 1.8130081300813008, "no_speech_prob": 1.497091943747364e-05}, {"id": 527, "seek": 210540, "start": 2132.4, "end": 2134.4, "text": " I click on it with the web inspector, yeah,", "tokens": [286, 2052, 322, 309, 365, 264, 3670, 34564, 11, 1338, 11], "temperature": 0.0, "avg_logprob": -0.17914026174972306, "compression_ratio": 1.8130081300813008, "no_speech_prob": 1.497091943747364e-05}, {"id": 528, "seek": 213440, "start": 2134.4, "end": 2136.4, "text": " and then copy that.", "tokens": [293, 550, 5055, 300, 13], "temperature": 0.0, "avg_logprob": -0.21155117352803549, "compression_ratio": 1.6299212598425197, "no_speech_prob": 2.7693897663993994e-06}, {"id": 529, "seek": 213440, "start": 2136.4, "end": 2139.4, "text": " You can try to guess it, but if you have something", "tokens": [509, 393, 853, 281, 2041, 309, 11, 457, 498, 291, 362, 746], "temperature": 0.0, "avg_logprob": -0.21155117352803549, "compression_ratio": 1.6299212598425197, "no_speech_prob": 2.7693897663993994e-06}, {"id": 530, "seek": 213440, "start": 2139.4, "end": 2141.4, "text": " with a few weird symbols, like, yeah,", "tokens": [365, 257, 1326, 3657, 16944, 11, 411, 11, 1338, 11], "temperature": 0.0, "avg_logprob": -0.21155117352803549, "compression_ratio": 1.6299212598425197, "no_speech_prob": 2.7693897663993994e-06}, {"id": 531, "seek": 213440, "start": 2141.4, "end": 2143.4, "text": " just use the inspector.", "tokens": [445, 764, 264, 34564, 13], "temperature": 0.0, "avg_logprob": -0.21155117352803549, "compression_ratio": 1.6299212598425197, "no_speech_prob": 2.7693897663993994e-06}, {"id": 532, "seek": 213440, "start": 2143.4, "end": 2145.4, "text": " That's going to have a better time.", "tokens": [663, 311, 516, 281, 362, 257, 1101, 565, 13], "temperature": 0.0, "avg_logprob": -0.21155117352803549, "compression_ratio": 1.6299212598425197, "no_speech_prob": 2.7693897663993994e-06}, {"id": 533, "seek": 213440, "start": 2145.4, "end": 2147.4, "text": " Yeah, but that's invaluable.", "tokens": [865, 11, 457, 300, 311, 40367, 13], "temperature": 0.0, "avg_logprob": -0.21155117352803549, "compression_ratio": 1.6299212598425197, "no_speech_prob": 2.7693897663993994e-06}, {"id": 534, "seek": 213440, "start": 2147.4, "end": 2151.4, "text": " And I would say, like, I notice when I'm reading documentation,", "tokens": [400, 286, 576, 584, 11, 411, 11, 286, 3449, 562, 286, 478, 3760, 14333, 11], "temperature": 0.0, "avg_logprob": -0.21155117352803549, "compression_ratio": 1.6299212598425197, "no_speech_prob": 2.7693897663993994e-06}, {"id": 535, "seek": 213440, "start": 2151.4, "end": 2155.4, "text": " I will very frequently, like, often the only thing I read", "tokens": [286, 486, 588, 10374, 11, 411, 11, 2049, 264, 787, 551, 286, 1401], "temperature": 0.0, "avg_logprob": -0.21155117352803549, "compression_ratio": 1.6299212598425197, "no_speech_prob": 2.7693897663993994e-06}, {"id": 536, "seek": 213440, "start": 2155.4, "end": 2158.4, "text": " in a whole page are the headings.", "tokens": [294, 257, 1379, 3028, 366, 264, 1378, 1109, 13], "temperature": 0.0, "avg_logprob": -0.21155117352803549, "compression_ratio": 1.6299212598425197, "no_speech_prob": 2.7693897663993994e-06}, {"id": 537, "seek": 213440, "start": 2158.4, "end": 2161.4, "text": " And that tells me whether or not something's relevant to me.", "tokens": [400, 300, 5112, 385, 1968, 420, 406, 746, 311, 7340, 281, 385, 13], "temperature": 0.0, "avg_logprob": -0.21155117352803549, "compression_ratio": 1.6299212598425197, "no_speech_prob": 2.7693897663993994e-06}, {"id": 538, "seek": 216140, "start": 2161.4, "end": 2165.4, "text": " So, like, for example, like, you totally nailed this", "tokens": [407, 11, 411, 11, 337, 1365, 11, 411, 11, 291, 3879, 30790, 341], "temperature": 0.0, "avg_logprob": -0.18083326933813876, "compression_ratio": 1.6398467432950192, "no_speech_prob": 2.225271146016894e-06}, {"id": 539, "seek": 216140, "start": 2165.4, "end": 2169.4, "text": " for my preferences of docs, but I think this is", "tokens": [337, 452, 21910, 295, 45623, 11, 457, 286, 519, 341, 307], "temperature": 0.0, "avg_logprob": -0.18083326933813876, "compression_ratio": 1.6398467432950192, "no_speech_prob": 2.225271146016894e-06}, {"id": 540, "seek": 216140, "start": 2169.4, "end": 2172.4, "text": " a pretty general best practice for docs in Elm Review.", "tokens": [257, 1238, 2674, 1151, 3124, 337, 45623, 294, 2699, 76, 19954, 13], "temperature": 0.0, "avg_logprob": -0.18083326933813876, "compression_ratio": 1.6398467432950192, "no_speech_prob": 2.225271146016894e-06}, {"id": 541, "seek": 216140, "start": 2172.4, "end": 2175.4, "text": " So the review.fix module in Elm Review,", "tokens": [407, 264, 3131, 13, 69, 970, 10088, 294, 2699, 76, 19954, 11], "temperature": 0.0, "avg_logprob": -0.18083326933813876, "compression_ratio": 1.6398467432950192, "no_speech_prob": 2.225271146016894e-06}, {"id": 542, "seek": 216140, "start": 2175.4, "end": 2179.4, "text": " the top level describes what are fixes.", "tokens": [264, 1192, 1496, 15626, 437, 366, 32539, 13], "temperature": 0.0, "avg_logprob": -0.18083326933813876, "compression_ratio": 1.6398467432950192, "no_speech_prob": 2.225271146016894e-06}, {"id": 543, "seek": 216140, "start": 2179.4, "end": 2181.4, "text": " Like, what the heck is this thing, right?", "tokens": [1743, 11, 437, 264, 12872, 307, 341, 551, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18083326933813876, "compression_ratio": 1.6398467432950192, "no_speech_prob": 2.225271146016894e-06}, {"id": 544, "seek": 216140, "start": 2181.4, "end": 2184.4, "text": " Of course, there's a whole set of associated types", "tokens": [2720, 1164, 11, 456, 311, 257, 1379, 992, 295, 6615, 3467], "temperature": 0.0, "avg_logprob": -0.18083326933813876, "compression_ratio": 1.6398467432950192, "no_speech_prob": 2.225271146016894e-06}, {"id": 545, "seek": 216140, "start": 2184.4, "end": 2187.4, "text": " and functions and everything, but up front it gives you", "tokens": [293, 6828, 293, 1203, 11, 457, 493, 1868, 309, 2709, 291], "temperature": 0.0, "avg_logprob": -0.18083326933813876, "compression_ratio": 1.6398467432950192, "no_speech_prob": 2.225271146016894e-06}, {"id": 546, "seek": 216140, "start": 2187.4, "end": 2188.4, "text": " a few things.", "tokens": [257, 1326, 721, 13], "temperature": 0.0, "avg_logprob": -0.18083326933813876, "compression_ratio": 1.6398467432950192, "no_speech_prob": 2.225271146016894e-06}, {"id": 547, "seek": 216140, "start": 2188.4, "end": 2190.4, "text": " So it says guidelines, right?", "tokens": [407, 309, 1619, 12470, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18083326933813876, "compression_ratio": 1.6398467432950192, "no_speech_prob": 2.225271146016894e-06}, {"id": 548, "seek": 219040, "start": 2190.4, "end": 2192.4, "text": " Maybe that's the first thing you want to know.", "tokens": [2704, 300, 311, 264, 700, 551, 291, 528, 281, 458, 13], "temperature": 0.0, "avg_logprob": -0.12610893729347852, "compression_ratio": 1.8006993006993006, "no_speech_prob": 8.801076546660624e-06}, {"id": 549, "seek": 219040, "start": 2192.4, "end": 2193.4, "text": " Like, I'm writing a rule.", "tokens": [1743, 11, 286, 478, 3579, 257, 4978, 13], "temperature": 0.0, "avg_logprob": -0.12610893729347852, "compression_ratio": 1.8006993006993006, "no_speech_prob": 8.801076546660624e-06}, {"id": 550, "seek": 219040, "start": 2193.4, "end": 2194.4, "text": " When would I write a rule?", "tokens": [1133, 576, 286, 2464, 257, 4978, 30], "temperature": 0.0, "avg_logprob": -0.12610893729347852, "compression_ratio": 1.8006993006993006, "no_speech_prob": 8.801076546660624e-06}, {"id": 551, "seek": 219040, "start": 2194.4, "end": 2196.4, "text": " But maybe I don't care about that right now.", "tokens": [583, 1310, 286, 500, 380, 1127, 466, 300, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.12610893729347852, "compression_ratio": 1.8006993006993006, "no_speech_prob": 8.801076546660624e-06}, {"id": 552, "seek": 219040, "start": 2196.4, "end": 2199.4, "text": " Maybe I'm trying to, like, I know I want to write a rule.", "tokens": [2704, 286, 478, 1382, 281, 11, 411, 11, 286, 458, 286, 528, 281, 2464, 257, 4978, 13], "temperature": 0.0, "avg_logprob": -0.12610893729347852, "compression_ratio": 1.8006993006993006, "no_speech_prob": 8.801076546660624e-06}, {"id": 553, "seek": 219040, "start": 2199.4, "end": 2201.4, "text": " I'm not looking for guidelines.", "tokens": [286, 478, 406, 1237, 337, 12470, 13], "temperature": 0.0, "avg_logprob": -0.12610893729347852, "compression_ratio": 1.8006993006993006, "no_speech_prob": 8.801076546660624e-06}, {"id": 554, "seek": 219040, "start": 2201.4, "end": 2203.4, "text": " I want to mechanically do that.", "tokens": [286, 528, 281, 4236, 984, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.12610893729347852, "compression_ratio": 1.8006993006993006, "no_speech_prob": 8.801076546660624e-06}, {"id": 555, "seek": 219040, "start": 2203.4, "end": 2204.4, "text": " Then you keep scrolling.", "tokens": [1396, 291, 1066, 29053, 13], "temperature": 0.0, "avg_logprob": -0.12610893729347852, "compression_ratio": 1.8006993006993006, "no_speech_prob": 8.801076546660624e-06}, {"id": 556, "seek": 219040, "start": 2204.4, "end": 2206.4, "text": " You don't look at that heading, right?", "tokens": [509, 500, 380, 574, 412, 300, 9864, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.12610893729347852, "compression_ratio": 1.8006993006993006, "no_speech_prob": 8.801076546660624e-06}, {"id": 557, "seek": 219040, "start": 2206.4, "end": 2210.4, "text": " When, parentheses, not to provide an automatic fix.", "tokens": [1133, 11, 34153, 11, 406, 281, 2893, 364, 12509, 3191, 13], "temperature": 0.0, "avg_logprob": -0.12610893729347852, "compression_ratio": 1.8006993006993006, "no_speech_prob": 8.801076546660624e-06}, {"id": 558, "seek": 219040, "start": 2210.4, "end": 2213.4, "text": " If you are looking for the mechanics of it,", "tokens": [759, 291, 366, 1237, 337, 264, 12939, 295, 309, 11], "temperature": 0.0, "avg_logprob": -0.12610893729347852, "compression_ratio": 1.8006993006993006, "no_speech_prob": 8.801076546660624e-06}, {"id": 559, "seek": 219040, "start": 2213.4, "end": 2214.4, "text": " again, you keep scrolling.", "tokens": [797, 11, 291, 1066, 29053, 13], "temperature": 0.0, "avg_logprob": -0.12610893729347852, "compression_ratio": 1.8006993006993006, "no_speech_prob": 8.801076546660624e-06}, {"id": 560, "seek": 219040, "start": 2214.4, "end": 2216.4, "text": " Okay, now creating a fix.", "tokens": [1033, 11, 586, 4084, 257, 3191, 13], "temperature": 0.0, "avg_logprob": -0.12610893729347852, "compression_ratio": 1.8006993006993006, "no_speech_prob": 8.801076546660624e-06}, {"id": 561, "seek": 219040, "start": 2216.4, "end": 2218.4, "text": " Ah, maybe that's what I want to do.", "tokens": [2438, 11, 1310, 300, 311, 437, 286, 528, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.12610893729347852, "compression_ratio": 1.8006993006993006, "no_speech_prob": 8.801076546660624e-06}, {"id": 562, "seek": 221840, "start": 2218.4, "end": 2222.4, "text": " Now you see the associated types and values", "tokens": [823, 291, 536, 264, 6615, 3467, 293, 4190], "temperature": 0.0, "avg_logprob": -0.20552161644245015, "compression_ratio": 1.7044534412955465, "no_speech_prob": 3.1381148346554255e-06}, {"id": 563, "seek": 221840, "start": 2222.4, "end": 2224.4, "text": " for creating a fix.", "tokens": [337, 4084, 257, 3191, 13], "temperature": 0.0, "avg_logprob": -0.20552161644245015, "compression_ratio": 1.7044534412955465, "no_speech_prob": 3.1381148346554255e-06}, {"id": 564, "seek": 221840, "start": 2224.4, "end": 2229.4, "text": " So, yeah, I think, like, I think when writing documentation,", "tokens": [407, 11, 1338, 11, 286, 519, 11, 411, 11, 286, 519, 562, 3579, 14333, 11], "temperature": 0.0, "avg_logprob": -0.20552161644245015, "compression_ratio": 1.7044534412955465, "no_speech_prob": 3.1381148346554255e-06}, {"id": 565, "seek": 221840, "start": 2229.4, "end": 2232.4, "text": " it's important to keep in mind how people are going to consume it,", "tokens": [309, 311, 1021, 281, 1066, 294, 1575, 577, 561, 366, 516, 281, 14732, 309, 11], "temperature": 0.0, "avg_logprob": -0.20552161644245015, "compression_ratio": 1.7044534412955465, "no_speech_prob": 3.1381148346554255e-06}, {"id": 566, "seek": 221840, "start": 2232.4, "end": 2235.4, "text": " which is they're going to skim, they're going to skip over", "tokens": [597, 307, 436, 434, 516, 281, 1110, 332, 11, 436, 434, 516, 281, 10023, 670], "temperature": 0.0, "avg_logprob": -0.20552161644245015, "compression_ratio": 1.7044534412955465, "no_speech_prob": 3.1381148346554255e-06}, {"id": 567, "seek": 221840, "start": 2235.4, "end": 2238.4, "text": " headlines they don't care about, and that's okay.", "tokens": [23867, 436, 500, 380, 1127, 466, 11, 293, 300, 311, 1392, 13], "temperature": 0.0, "avg_logprob": -0.20552161644245015, "compression_ratio": 1.7044534412955465, "no_speech_prob": 3.1381148346554255e-06}, {"id": 568, "seek": 221840, "start": 2238.4, "end": 2242.4, "text": " That's not a personal failing of yours that people don't read", "tokens": [663, 311, 406, 257, 2973, 18223, 295, 6342, 300, 561, 500, 380, 1401], "temperature": 0.0, "avg_logprob": -0.20552161644245015, "compression_ratio": 1.7044534412955465, "no_speech_prob": 3.1381148346554255e-06}, {"id": 569, "seek": 221840, "start": 2242.4, "end": 2243.4, "text": " through top to bottom.", "tokens": [807, 1192, 281, 2767, 13], "temperature": 0.0, "avg_logprob": -0.20552161644245015, "compression_ratio": 1.7044534412955465, "no_speech_prob": 3.1381148346554255e-06}, {"id": 570, "seek": 221840, "start": 2243.4, "end": 2245.4, "text": " That's just not how people operate.", "tokens": [663, 311, 445, 406, 577, 561, 9651, 13], "temperature": 0.0, "avg_logprob": -0.20552161644245015, "compression_ratio": 1.7044534412955465, "no_speech_prob": 3.1381148346554255e-06}, {"id": 571, "seek": 224540, "start": 2245.4, "end": 2248.4, "text": " They don't read headlines.", "tokens": [814, 500, 380, 1401, 23867, 13], "temperature": 0.0, "avg_logprob": -0.23312946817149285, "compression_ratio": 1.669291338582677, "no_speech_prob": 1.9214145140722394e-05}, {"id": 572, "seek": 224540, "start": 2248.4, "end": 2250.4, "text": " They're there for a reason.", "tokens": [814, 434, 456, 337, 257, 1778, 13], "temperature": 0.0, "avg_logprob": -0.23312946817149285, "compression_ratio": 1.669291338582677, "no_speech_prob": 1.9214145140722394e-05}, {"id": 573, "seek": 224540, "start": 2250.4, "end": 2253.4, "text": " Put them in the top for a reason.", "tokens": [4935, 552, 294, 264, 1192, 337, 257, 1778, 13], "temperature": 0.0, "avg_logprob": -0.23312946817149285, "compression_ratio": 1.669291338582677, "no_speech_prob": 1.9214145140722394e-05}, {"id": 574, "seek": 224540, "start": 2253.4, "end": 2256.4, "text": " But it really is a choose your own adventure.", "tokens": [583, 309, 534, 307, 257, 2826, 428, 1065, 9868, 13], "temperature": 0.0, "avg_logprob": -0.23312946817149285, "compression_ratio": 1.669291338582677, "no_speech_prob": 1.9214145140722394e-05}, {"id": 575, "seek": 224540, "start": 2256.4, "end": 2260.4, "text": " Actually, before we recorded, you and I were talking about", "tokens": [5135, 11, 949, 321, 8287, 11, 291, 293, 286, 645, 1417, 466], "temperature": 0.0, "avg_logprob": -0.23312946817149285, "compression_ratio": 1.669291338582677, "no_speech_prob": 1.9214145140722394e-05}, {"id": 576, "seek": 224540, "start": 2260.4, "end": 2264.4, "text": " Zelda Breath of the Wild and Tears of the Kingdom and how cool", "tokens": [25298, 38672, 295, 264, 10904, 293, 1989, 685, 295, 264, 11277, 293, 577, 1627], "temperature": 0.0, "avg_logprob": -0.23312946817149285, "compression_ratio": 1.669291338582677, "no_speech_prob": 1.9214145140722394e-05}, {"id": 577, "seek": 224540, "start": 2264.4, "end": 2266.4, "text": " this sort of choose your own adventure style of, like,", "tokens": [341, 1333, 295, 2826, 428, 1065, 9868, 3758, 295, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.23312946817149285, "compression_ratio": 1.669291338582677, "no_speech_prob": 1.9214145140722394e-05}, {"id": 578, "seek": 224540, "start": 2266.4, "end": 2270.4, "text": " an open world game is where you can bounce around.", "tokens": [364, 1269, 1002, 1216, 307, 689, 291, 393, 15894, 926, 13], "temperature": 0.0, "avg_logprob": -0.23312946817149285, "compression_ratio": 1.669291338582677, "no_speech_prob": 1.9214145140722394e-05}, {"id": 579, "seek": 224540, "start": 2270.4, "end": 2273.4, "text": " You can, whatever, go straight to the final boss and skip all", "tokens": [509, 393, 11, 2035, 11, 352, 2997, 281, 264, 2572, 5741, 293, 10023, 439], "temperature": 0.0, "avg_logprob": -0.23312946817149285, "compression_ratio": 1.669291338582677, "no_speech_prob": 1.9214145140722394e-05}, {"id": 580, "seek": 227340, "start": 2273.4, "end": 2278.4, "text": " the powerful items and upgrades, or you can do every possible", "tokens": [264, 4005, 4754, 293, 24868, 11, 420, 291, 393, 360, 633, 1944], "temperature": 0.0, "avg_logprob": -0.17977151803091063, "compression_ratio": 1.7491039426523298, "no_speech_prob": 5.682297341991216e-06}, {"id": 581, "seek": 227340, "start": 2278.4, "end": 2282.4, "text": " side quest and learn every mechanic of the game before", "tokens": [1252, 866, 293, 1466, 633, 23860, 295, 264, 1216, 949], "temperature": 0.0, "avg_logprob": -0.17977151803091063, "compression_ratio": 1.7491039426523298, "no_speech_prob": 5.682297341991216e-06}, {"id": 582, "seek": 227340, "start": 2282.4, "end": 2283.4, "text": " going to the final.", "tokens": [516, 281, 264, 2572, 13], "temperature": 0.0, "avg_logprob": -0.17977151803091063, "compression_ratio": 1.7491039426523298, "no_speech_prob": 5.682297341991216e-06}, {"id": 583, "seek": 227340, "start": 2283.4, "end": 2285.4, "text": " You can do it whatever order you want.", "tokens": [509, 393, 360, 309, 2035, 1668, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.17977151803091063, "compression_ratio": 1.7491039426523298, "no_speech_prob": 5.682297341991216e-06}, {"id": 584, "seek": 227340, "start": 2285.4, "end": 2287.4, "text": " That's how people do docs.", "tokens": [663, 311, 577, 561, 360, 45623, 13], "temperature": 0.0, "avg_logprob": -0.17977151803091063, "compression_ratio": 1.7491039426523298, "no_speech_prob": 5.682297341991216e-06}, {"id": 585, "seek": 227340, "start": 2287.4, "end": 2290.4, "text": " They go in to do a job, and they're not going to do it in", "tokens": [814, 352, 294, 281, 360, 257, 1691, 11, 293, 436, 434, 406, 516, 281, 360, 309, 294], "temperature": 0.0, "avg_logprob": -0.17977151803091063, "compression_ratio": 1.7491039426523298, "no_speech_prob": 5.682297341991216e-06}, {"id": 586, "seek": 227340, "start": 2290.4, "end": 2293.4, "text": " the linear order you expect most of the time, or they might.", "tokens": [264, 8213, 1668, 291, 2066, 881, 295, 264, 565, 11, 420, 436, 1062, 13], "temperature": 0.0, "avg_logprob": -0.17977151803091063, "compression_ratio": 1.7491039426523298, "no_speech_prob": 5.682297341991216e-06}, {"id": 587, "seek": 227340, "start": 2293.4, "end": 2296.4, "text": " Yeah, first of all, like, I think, as you say, like,", "tokens": [865, 11, 700, 295, 439, 11, 411, 11, 286, 519, 11, 382, 291, 584, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.17977151803091063, "compression_ratio": 1.7491039426523298, "no_speech_prob": 5.682297341991216e-06}, {"id": 588, "seek": 227340, "start": 2296.4, "end": 2299.4, "text": " you can skim through the headings, and I think it could", "tokens": [291, 393, 1110, 332, 807, 264, 1378, 1109, 11, 293, 286, 519, 309, 727], "temperature": 0.0, "avg_logprob": -0.17977151803091063, "compression_ratio": 1.7491039426523298, "no_speech_prob": 5.682297341991216e-06}, {"id": 589, "seek": 227340, "start": 2299.4, "end": 2302.4, "text": " be valuable to have, like, a table of contents at the top", "tokens": [312, 8263, 281, 362, 11, 411, 11, 257, 3199, 295, 15768, 412, 264, 1192], "temperature": 0.0, "avg_logprob": -0.17977151803091063, "compression_ratio": 1.7491039426523298, "no_speech_prob": 5.682297341991216e-06}, {"id": 590, "seek": 230240, "start": 2302.4, "end": 2305.4, "text": " of every page or somewhere on the page.", "tokens": [295, 633, 3028, 420, 4079, 322, 264, 3028, 13], "temperature": 0.0, "avg_logprob": -0.21008644547573355, "compression_ratio": 1.6324324324324324, "no_speech_prob": 3.6687220017483924e-06}, {"id": 591, "seek": 230240, "start": 2305.4, "end": 2308.4, "text": " That could be interesting.", "tokens": [663, 727, 312, 1880, 13], "temperature": 0.0, "avg_logprob": -0.21008644547573355, "compression_ratio": 1.6324324324324324, "no_speech_prob": 3.6687220017483924e-06}, {"id": 592, "seek": 230240, "start": 2308.4, "end": 2313.4, "text": " But, yeah, so you describe the mechanics of how you write", "tokens": [583, 11, 1338, 11, 370, 291, 6786, 264, 12939, 295, 577, 291, 2464], "temperature": 0.0, "avg_logprob": -0.21008644547573355, "compression_ratio": 1.6324324324324324, "no_speech_prob": 3.6687220017483924e-06}, {"id": 593, "seek": 230240, "start": 2313.4, "end": 2316.4, "text": " documentation for a module.", "tokens": [14333, 337, 257, 10088, 13], "temperature": 0.0, "avg_logprob": -0.21008644547573355, "compression_ratio": 1.6324324324324324, "no_speech_prob": 3.6687220017483924e-06}, {"id": 594, "seek": 230240, "start": 2316.4, "end": 2319.4, "text": " So at the top of the module, you have a module documentation,", "tokens": [407, 412, 264, 1192, 295, 264, 10088, 11, 291, 362, 257, 10088, 14333, 11], "temperature": 0.0, "avg_logprob": -0.21008644547573355, "compression_ratio": 1.6324324324324324, "no_speech_prob": 3.6687220017483924e-06}, {"id": 595, "seek": 230240, "start": 2319.4, "end": 2324.4, "text": " so curly braces, dash, pipe, some text, and at the end,", "tokens": [370, 32066, 41537, 11, 8240, 11, 11240, 11, 512, 2487, 11, 293, 412, 264, 917, 11], "temperature": 0.0, "avg_logprob": -0.21008644547573355, "compression_ratio": 1.6324324324324324, "no_speech_prob": 3.6687220017483924e-06}, {"id": 596, "seek": 230240, "start": 2324.4, "end": 2328.4, "text": " the closing, dash, curly brace.", "tokens": [264, 10377, 11, 8240, 11, 32066, 38458, 13], "temperature": 0.0, "avg_logprob": -0.21008644547573355, "compression_ratio": 1.6324324324324324, "no_speech_prob": 3.6687220017483924e-06}, {"id": 597, "seek": 232840, "start": 2328.4, "end": 2332.4, "text": " And in between those, you write some text, some headings,", "tokens": [400, 294, 1296, 729, 11, 291, 2464, 512, 2487, 11, 512, 1378, 1109, 11], "temperature": 0.0, "avg_logprob": -0.19842167695363364, "compression_ratio": 1.6497695852534562, "no_speech_prob": 2.521534270272241e-06}, {"id": 598, "seek": 232840, "start": 2332.4, "end": 2334.4, "text": " and references to functions.", "tokens": [293, 15400, 281, 6828, 13], "temperature": 0.0, "avg_logprob": -0.19842167695363364, "compression_ratio": 1.6497695852534562, "no_speech_prob": 2.521534270272241e-06}, {"id": 599, "seek": 232840, "start": 2334.4, "end": 2339.4, "text": " And the thing that I really like about this is you decide,", "tokens": [400, 264, 551, 300, 286, 534, 411, 466, 341, 307, 291, 4536, 11], "temperature": 0.0, "avg_logprob": -0.19842167695363364, "compression_ratio": 1.6497695852534562, "no_speech_prob": 2.521534270272241e-06}, {"id": 600, "seek": 232840, "start": 2339.4, "end": 2343.4, "text": " based on how you write or where you write those add docs", "tokens": [2361, 322, 577, 291, 2464, 420, 689, 291, 2464, 729, 909, 45623], "temperature": 0.0, "avg_logprob": -0.19842167695363364, "compression_ratio": 1.6497695852534562, "no_speech_prob": 2.521534270272241e-06}, {"id": 601, "seek": 232840, "start": 2343.4, "end": 2346.4, "text": " things, how things will be presented.", "tokens": [721, 11, 577, 721, 486, 312, 8212, 13], "temperature": 0.0, "avg_logprob": -0.19842167695363364, "compression_ratio": 1.6497695852534562, "no_speech_prob": 2.521534270272241e-06}, {"id": 602, "seek": 232840, "start": 2346.4, "end": 2352.4, "text": " So if you, the way that the docs are shown do not depend on", "tokens": [407, 498, 291, 11, 264, 636, 300, 264, 45623, 366, 4898, 360, 406, 5672, 322], "temperature": 0.0, "avg_logprob": -0.19842167695363364, "compression_ratio": 1.6497695852534562, "no_speech_prob": 2.521534270272241e-06}, {"id": 603, "seek": 232840, "start": 2352.4, "end": 2357.4, "text": " where they're defined in the page, because they could be,", "tokens": [689, 436, 434, 7642, 294, 264, 3028, 11, 570, 436, 727, 312, 11], "temperature": 0.0, "avg_logprob": -0.19842167695363364, "compression_ratio": 1.6497695852534562, "no_speech_prob": 2.521534270272241e-06}, {"id": 604, "seek": 235740, "start": 2357.4, "end": 2362.4, "text": " because in Elm there's hoisting everywhere, so the Elm could", "tokens": [570, 294, 2699, 76, 456, 311, 1106, 468, 278, 5315, 11, 370, 264, 2699, 76, 727], "temperature": 0.0, "avg_logprob": -0.18557771328276237, "compression_ratio": 1.834862385321101, "no_speech_prob": 1.1123629519715905e-05}, {"id": 605, "seek": 235740, "start": 2362.4, "end": 2365.4, "text": " choose, well, this function is defined before this one,", "tokens": [2826, 11, 731, 11, 341, 2445, 307, 7642, 949, 341, 472, 11], "temperature": 0.0, "avg_logprob": -0.18557771328276237, "compression_ratio": 1.834862385321101, "no_speech_prob": 1.1123629519715905e-05}, {"id": 606, "seek": 235740, "start": 2365.4, "end": 2368.4, "text": " so I'm going to show that one before.", "tokens": [370, 286, 478, 516, 281, 855, 300, 472, 949, 13], "temperature": 0.0, "avg_logprob": -0.18557771328276237, "compression_ratio": 1.834862385321101, "no_speech_prob": 1.1123629519715905e-05}, {"id": 607, "seek": 235740, "start": 2368.4, "end": 2373.4, "text": " But no, it's you define by saying add docs function A,", "tokens": [583, 572, 11, 309, 311, 291, 6964, 538, 1566, 909, 45623, 2445, 316, 11], "temperature": 0.0, "avg_logprob": -0.18557771328276237, "compression_ratio": 1.834862385321101, "no_speech_prob": 1.1123629519715905e-05}, {"id": 608, "seek": 235740, "start": 2373.4, "end": 2377.4, "text": " and then later add docs function B, that function A will be", "tokens": [293, 550, 1780, 909, 45623, 2445, 363, 11, 300, 2445, 316, 486, 312], "temperature": 0.0, "avg_logprob": -0.18557771328276237, "compression_ratio": 1.834862385321101, "no_speech_prob": 1.1123629519715905e-05}, {"id": 609, "seek": 235740, "start": 2377.4, "end": 2379.4, "text": " displayed before function B.", "tokens": [16372, 949, 2445, 363, 13], "temperature": 0.0, "avg_logprob": -0.18557771328276237, "compression_ratio": 1.834862385321101, "no_speech_prob": 1.1123629519715905e-05}, {"id": 610, "seek": 235740, "start": 2379.4, "end": 2384.4, "text": " And if you put it in a section or after a section header,", "tokens": [400, 498, 291, 829, 309, 294, 257, 3541, 420, 934, 257, 3541, 23117, 11], "temperature": 0.0, "avg_logprob": -0.18557771328276237, "compression_ratio": 1.834862385321101, "no_speech_prob": 1.1123629519715905e-05}, {"id": 611, "seek": 235740, "start": 2384.4, "end": 2386.4, "text": " then it's going to show up in that section.", "tokens": [550, 309, 311, 516, 281, 855, 493, 294, 300, 3541, 13], "temperature": 0.0, "avg_logprob": -0.18557771328276237, "compression_ratio": 1.834862385321101, "no_speech_prob": 1.1123629519715905e-05}, {"id": 612, "seek": 238640, "start": 2386.4, "end": 2390.4, "text": " And you can write those, the things however you want.", "tokens": [400, 291, 393, 2464, 729, 11, 264, 721, 4461, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.22341332741833608, "compression_ratio": 1.6886792452830188, "no_speech_prob": 3.1380736800201703e-06}, {"id": 613, "seek": 238640, "start": 2390.4, "end": 2392.4, "text": " So you can, as you say, you can write a story.", "tokens": [407, 291, 393, 11, 382, 291, 584, 11, 291, 393, 2464, 257, 1657, 13], "temperature": 0.0, "avg_logprob": -0.22341332741833608, "compression_ratio": 1.6886792452830188, "no_speech_prob": 3.1380736800201703e-06}, {"id": 614, "seek": 238640, "start": 2392.4, "end": 2395.4, "text": " That's kind of like how I like to see it.", "tokens": [663, 311, 733, 295, 411, 577, 286, 411, 281, 536, 309, 13], "temperature": 0.0, "avg_logprob": -0.22341332741833608, "compression_ratio": 1.6886792452830188, "no_speech_prob": 3.1380736800201703e-06}, {"id": 615, "seek": 238640, "start": 2395.4, "end": 2398.4, "text": " If you have a story to tell, if like maybe you don't need to", "tokens": [759, 291, 362, 257, 1657, 281, 980, 11, 498, 411, 1310, 291, 500, 380, 643, 281], "temperature": 0.0, "avg_logprob": -0.22341332741833608, "compression_ratio": 1.6886792452830188, "no_speech_prob": 3.1380736800201703e-06}, {"id": 616, "seek": 238640, "start": 2398.4, "end": 2404.4, "text": " have a story for writing a dict package.", "tokens": [362, 257, 1657, 337, 3579, 257, 12569, 7372, 13], "temperature": 0.0, "avg_logprob": -0.22341332741833608, "compression_ratio": 1.6886792452830188, "no_speech_prob": 3.1380736800201703e-06}, {"id": 617, "seek": 238640, "start": 2404.4, "end": 2409.4, "text": " But in the case of Elm Review, there's a lot of things that I", "tokens": [583, 294, 264, 1389, 295, 2699, 76, 19954, 11, 456, 311, 257, 688, 295, 721, 300, 286], "temperature": 0.0, "avg_logprob": -0.22341332741833608, "compression_ratio": 1.6886792452830188, "no_speech_prob": 3.1380736800201703e-06}, {"id": 618, "seek": 238640, "start": 2409.4, "end": 2412.4, "text": " need to explain, and some of them need to be first,", "tokens": [643, 281, 2903, 11, 293, 512, 295, 552, 643, 281, 312, 700, 11], "temperature": 0.0, "avg_logprob": -0.22341332741833608, "compression_ratio": 1.6886792452830188, "no_speech_prob": 3.1380736800201703e-06}, {"id": 619, "seek": 241240, "start": 2412.4, "end": 2417.4, "text": " like guidelines, which I think when they're not details,", "tokens": [411, 12470, 11, 597, 286, 519, 562, 436, 434, 406, 4365, 11], "temperature": 0.0, "avg_logprob": -0.20681825637817383, "compression_ratio": 1.6130434782608696, "no_speech_prob": 9.570645715939463e-07}, {"id": 620, "seek": 241240, "start": 2417.4, "end": 2421.4, "text": " should be read before you read the rest.", "tokens": [820, 312, 1401, 949, 291, 1401, 264, 1472, 13], "temperature": 0.0, "avg_logprob": -0.20681825637817383, "compression_ratio": 1.6130434782608696, "no_speech_prob": 9.570645715939463e-07}, {"id": 621, "seek": 241240, "start": 2421.4, "end": 2424.4, "text": " Although you do whatever you want.", "tokens": [5780, 291, 360, 2035, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.20681825637817383, "compression_ratio": 1.6130434782608696, "no_speech_prob": 9.570645715939463e-07}, {"id": 622, "seek": 241240, "start": 2424.4, "end": 2428.4, "text": " But like I'm expecting that by default people will read", "tokens": [583, 411, 286, 478, 9650, 300, 538, 7576, 561, 486, 1401], "temperature": 0.0, "avg_logprob": -0.20681825637817383, "compression_ratio": 1.6130434782608696, "no_speech_prob": 9.570645715939463e-07}, {"id": 623, "seek": 241240, "start": 2428.4, "end": 2430.4, "text": " things from top to bottom.", "tokens": [721, 490, 1192, 281, 2767, 13], "temperature": 0.0, "avg_logprob": -0.20681825637817383, "compression_ratio": 1.6130434782608696, "no_speech_prob": 9.570645715939463e-07}, {"id": 624, "seek": 241240, "start": 2430.4, "end": 2432.4, "text": " And you can, yeah, you can choose how things will be", "tokens": [400, 291, 393, 11, 1338, 11, 291, 393, 2826, 577, 721, 486, 312], "temperature": 0.0, "avg_logprob": -0.20681825637817383, "compression_ratio": 1.6130434782608696, "no_speech_prob": 9.570645715939463e-07}, {"id": 625, "seek": 241240, "start": 2432.4, "end": 2435.4, "text": " displayed, and I found that to be very powerful.", "tokens": [16372, 11, 293, 286, 1352, 300, 281, 312, 588, 4005, 13], "temperature": 0.0, "avg_logprob": -0.20681825637817383, "compression_ratio": 1.6130434782608696, "no_speech_prob": 9.570645715939463e-07}, {"id": 626, "seek": 241240, "start": 2435.4, "end": 2440.4, "text": " And there's a cool thing that Elm format does as well", "tokens": [400, 456, 311, 257, 1627, 551, 300, 2699, 76, 7877, 775, 382, 731], "temperature": 0.0, "avg_logprob": -0.20681825637817383, "compression_ratio": 1.6130434782608696, "no_speech_prob": 9.570645715939463e-07}, {"id": 627, "seek": 244040, "start": 2440.4, "end": 2442.4, "text": " with add docs.", "tokens": [365, 909, 45623, 13], "temperature": 0.0, "avg_logprob": -0.20335673108512972, "compression_ratio": 1.7423312883435582, "no_speech_prob": 4.356743829703191e-06}, {"id": 628, "seek": 244040, "start": 2442.4, "end": 2445.4, "text": " So whenever you add those add docs things,", "tokens": [407, 5699, 291, 909, 729, 909, 45623, 721, 11], "temperature": 0.0, "avg_logprob": -0.20335673108512972, "compression_ratio": 1.7423312883435582, "no_speech_prob": 4.356743829703191e-06}, {"id": 629, "seek": 244040, "start": 2445.4, "end": 2451.4, "text": " it changes the exposing clause in your module,", "tokens": [309, 2962, 264, 33178, 25925, 294, 428, 10088, 11], "temperature": 0.0, "avg_logprob": -0.20335673108512972, "compression_ratio": 1.7423312883435582, "no_speech_prob": 4.356743829703191e-06}, {"id": 630, "seek": 244040, "start": 2451.4, "end": 2455.4, "text": " the first line in your module declaration.", "tokens": [264, 700, 1622, 294, 428, 10088, 27606, 13], "temperature": 0.0, "avg_logprob": -0.20335673108512972, "compression_ratio": 1.7423312883435582, "no_speech_prob": 4.356743829703191e-06}, {"id": 631, "seek": 244040, "start": 2455.4, "end": 2458.4, "text": " So module, module name, exposing,", "tokens": [407, 10088, 11, 10088, 1315, 11, 33178, 11], "temperature": 0.0, "avg_logprob": -0.20335673108512972, "compression_ratio": 1.7423312883435582, "no_speech_prob": 4.356743829703191e-06}, {"id": 632, "seek": 244040, "start": 2458.4, "end": 2460.4, "text": " and then plenty of things.", "tokens": [293, 550, 7140, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.20335673108512972, "compression_ratio": 1.7423312883435582, "no_speech_prob": 4.356743829703191e-06}, {"id": 633, "seek": 244040, "start": 2460.4, "end": 2462.4, "text": " So if you have add docs for those,", "tokens": [407, 498, 291, 362, 909, 45623, 337, 729, 11], "temperature": 0.0, "avg_logprob": -0.20335673108512972, "compression_ratio": 1.7423312883435582, "no_speech_prob": 4.356743829703191e-06}, {"id": 634, "seek": 244040, "start": 2462.4, "end": 2465.4, "text": " it will reformat them in the same order.", "tokens": [309, 486, 8290, 267, 552, 294, 264, 912, 1668, 13], "temperature": 0.0, "avg_logprob": -0.20335673108512972, "compression_ratio": 1.7423312883435582, "no_speech_prob": 4.356743829703191e-06}, {"id": 635, "seek": 246540, "start": 2465.4, "end": 2471.4, "text": " So if you have add docs ABC and then next line add docs DEF,", "tokens": [407, 498, 291, 362, 909, 45623, 22342, 293, 550, 958, 1622, 909, 45623, 10113, 37, 11], "temperature": 0.0, "avg_logprob": -0.18354191499597886, "compression_ratio": 1.532258064516129, "no_speech_prob": 2.6016030005848734e-06}, {"id": 636, "seek": 246540, "start": 2471.4, "end": 2476.4, "text": " then you will have two lines, ABC and then DEF,", "tokens": [550, 291, 486, 362, 732, 3876, 11, 22342, 293, 550, 10113, 37, 11], "temperature": 0.0, "avg_logprob": -0.18354191499597886, "compression_ratio": 1.532258064516129, "no_speech_prob": 2.6016030005848734e-06}, {"id": 637, "seek": 246540, "start": 2476.4, "end": 2478.4, "text": " in the exposing clause.", "tokens": [294, 264, 33178, 25925, 13], "temperature": 0.0, "avg_logprob": -0.18354191499597886, "compression_ratio": 1.532258064516129, "no_speech_prob": 2.6016030005848734e-06}, {"id": 638, "seek": 246540, "start": 2478.4, "end": 2482.4, "text": " And I use that as well in my application code.", "tokens": [400, 286, 764, 300, 382, 731, 294, 452, 3861, 3089, 13], "temperature": 0.0, "avg_logprob": -0.18354191499597886, "compression_ratio": 1.532258064516129, "no_speech_prob": 2.6016030005848734e-06}, {"id": 639, "seek": 246540, "start": 2482.4, "end": 2487.4, "text": " So if I want to make a, let's say, button module,", "tokens": [407, 498, 286, 528, 281, 652, 257, 11, 718, 311, 584, 11, 2960, 10088, 11], "temperature": 0.0, "avg_logprob": -0.18354191499597886, "compression_ratio": 1.532258064516129, "no_speech_prob": 2.6016030005848734e-06}, {"id": 640, "seek": 246540, "start": 2487.4, "end": 2493.4, "text": " then I write the documentation so that the API is shown", "tokens": [550, 286, 2464, 264, 14333, 370, 300, 264, 9362, 307, 4898], "temperature": 0.0, "avg_logprob": -0.18354191499597886, "compression_ratio": 1.532258064516129, "no_speech_prob": 2.6016030005848734e-06}, {"id": 641, "seek": 249340, "start": 2493.4, "end": 2497.4, "text": " as a table of contents in a way at the very top of my file.", "tokens": [382, 257, 3199, 295, 15768, 294, 257, 636, 412, 264, 588, 1192, 295, 452, 3991, 13], "temperature": 0.0, "avg_logprob": -0.19887895404167896, "compression_ratio": 1.7477064220183487, "no_speech_prob": 1.9033672060686513e-06}, {"id": 642, "seek": 249340, "start": 2497.4, "end": 2503.4, "text": " So usually I have something like a section how to create,", "tokens": [407, 2673, 286, 362, 746, 411, 257, 3541, 577, 281, 1884, 11], "temperature": 0.0, "avg_logprob": -0.19887895404167896, "compression_ratio": 1.7477064220183487, "no_speech_prob": 1.9033672060686513e-06}, {"id": 643, "seek": 249340, "start": 2503.4, "end": 2506.4, "text": " and I have the type of the button,", "tokens": [293, 286, 362, 264, 2010, 295, 264, 2960, 11], "temperature": 0.0, "avg_logprob": -0.19887895404167896, "compression_ratio": 1.7477064220183487, "no_speech_prob": 1.9033672060686513e-06}, {"id": 644, "seek": 249340, "start": 2506.4, "end": 2510.4, "text": " so add docs button, and then also the init or the different", "tokens": [370, 909, 45623, 2960, 11, 293, 550, 611, 264, 3157, 420, 264, 819], "temperature": 0.0, "avg_logprob": -0.19887895404167896, "compression_ratio": 1.7477064220183487, "no_speech_prob": 1.9033672060686513e-06}, {"id": 645, "seek": 249340, "start": 2510.4, "end": 2512.4, "text": " variants for init.", "tokens": [21669, 337, 3157, 13], "temperature": 0.0, "avg_logprob": -0.19887895404167896, "compression_ratio": 1.7477064220183487, "no_speech_prob": 1.9033672060686513e-06}, {"id": 646, "seek": 249340, "start": 2512.4, "end": 2515.4, "text": " And then I have a section with all the with functions", "tokens": [400, 550, 286, 362, 257, 3541, 365, 439, 264, 365, 6828], "temperature": 0.0, "avg_logprob": -0.19887895404167896, "compression_ratio": 1.7477064220183487, "no_speech_prob": 1.9033672060686513e-06}, {"id": 647, "seek": 249340, "start": 2515.4, "end": 2519.4, "text": " if I choose to do so, and then a section on how to transform", "tokens": [498, 286, 2826, 281, 360, 370, 11, 293, 550, 257, 3541, 322, 577, 281, 4088], "temperature": 0.0, "avg_logprob": -0.19887895404167896, "compression_ratio": 1.7477064220183487, "no_speech_prob": 1.9033672060686513e-06}, {"id": 648, "seek": 249340, "start": 2519.4, "end": 2522.4, "text": " that to HTML, something like that.", "tokens": [300, 281, 17995, 11, 746, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.19887895404167896, "compression_ratio": 1.7477064220183487, "no_speech_prob": 1.9033672060686513e-06}, {"id": 649, "seek": 252240, "start": 2522.4, "end": 2526.4, "text": " And then you can see in the exposing clause, well,", "tokens": [400, 550, 291, 393, 536, 294, 264, 33178, 25925, 11, 731, 11], "temperature": 0.0, "avg_logprob": -0.20270090905305382, "compression_ratio": 1.8148148148148149, "no_speech_prob": 3.089422989432933e-06}, {"id": 650, "seek": 252240, "start": 2526.4, "end": 2530.4, "text": " button, comma, init, next line, with something, with something,", "tokens": [2960, 11, 22117, 11, 3157, 11, 958, 1622, 11, 365, 746, 11, 365, 746, 11], "temperature": 0.0, "avg_logprob": -0.20270090905305382, "compression_ratio": 1.8148148148148149, "no_speech_prob": 3.089422989432933e-06}, {"id": 651, "seek": 252240, "start": 2530.4, "end": 2533.4, "text": " with something, and at the end to HTML.", "tokens": [365, 746, 11, 293, 412, 264, 917, 281, 17995, 13], "temperature": 0.0, "avg_logprob": -0.20270090905305382, "compression_ratio": 1.8148148148148149, "no_speech_prob": 3.089422989432933e-06}, {"id": 652, "seek": 252240, "start": 2533.4, "end": 2536.4, "text": " And you can even put those things onto more lines,", "tokens": [400, 291, 393, 754, 829, 729, 721, 3911, 544, 3876, 11], "temperature": 0.0, "avg_logprob": -0.20270090905305382, "compression_ratio": 1.8148148148148149, "no_speech_prob": 3.089422989432933e-06}, {"id": 653, "seek": 252240, "start": 2536.4, "end": 2541.4, "text": " so you have with large size, with small size, with medium size,", "tokens": [370, 291, 362, 365, 2416, 2744, 11, 365, 1359, 2744, 11, 365, 6399, 2744, 11], "temperature": 0.0, "avg_logprob": -0.20270090905305382, "compression_ratio": 1.8148148148148149, "no_speech_prob": 3.089422989432933e-06}, {"id": 654, "seek": 252240, "start": 2541.4, "end": 2546.4, "text": " and then on the next line with color red, with color blue.", "tokens": [293, 550, 322, 264, 958, 1622, 365, 2017, 2182, 11, 365, 2017, 3344, 13], "temperature": 0.0, "avg_logprob": -0.20270090905305382, "compression_ratio": 1.8148148148148149, "no_speech_prob": 3.089422989432933e-06}, {"id": 655, "seek": 252240, "start": 2546.4, "end": 2551.4, "text": " These are terrible examples, but the way that I try to do those", "tokens": [1981, 366, 6237, 5110, 11, 457, 264, 636, 300, 286, 853, 281, 360, 729], "temperature": 0.0, "avg_logprob": -0.20270090905305382, "compression_ratio": 1.8148148148148149, "no_speech_prob": 3.089422989432933e-06}, {"id": 656, "seek": 255140, "start": 2551.4, "end": 2555.4, "text": " is I write them so that every line deals with one thing.", "tokens": [307, 286, 2464, 552, 370, 300, 633, 1622, 11215, 365, 472, 551, 13], "temperature": 0.0, "avg_logprob": -0.15457438593325407, "compression_ratio": 1.8384279475982532, "no_speech_prob": 7.527917205152335e-06}, {"id": 657, "seek": 255140, "start": 2555.4, "end": 2558.4, "text": " So if you want to deal with the size of the button,", "tokens": [407, 498, 291, 528, 281, 2028, 365, 264, 2744, 295, 264, 2960, 11], "temperature": 0.0, "avg_logprob": -0.15457438593325407, "compression_ratio": 1.8384279475982532, "no_speech_prob": 7.527917205152335e-06}, {"id": 658, "seek": 255140, "start": 2558.4, "end": 2560.4, "text": " you have one line with all those.", "tokens": [291, 362, 472, 1622, 365, 439, 729, 13], "temperature": 0.0, "avg_logprob": -0.15457438593325407, "compression_ratio": 1.8384279475982532, "no_speech_prob": 7.527917205152335e-06}, {"id": 659, "seek": 255140, "start": 2560.4, "end": 2563.4, "text": " If you want to talk about the color, you have one line", "tokens": [759, 291, 528, 281, 751, 466, 264, 2017, 11, 291, 362, 472, 1622], "temperature": 0.0, "avg_logprob": -0.15457438593325407, "compression_ratio": 1.8384279475982532, "no_speech_prob": 7.527917205152335e-06}, {"id": 660, "seek": 255140, "start": 2563.4, "end": 2567.4, "text": " with all those, maybe also the color type or something.", "tokens": [365, 439, 729, 11, 1310, 611, 264, 2017, 2010, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.15457438593325407, "compression_ratio": 1.8384279475982532, "no_speech_prob": 7.527917205152335e-06}, {"id": 661, "seek": 255140, "start": 2567.4, "end": 2571.4, "text": " And I find that just to have this thing is already very valuable,", "tokens": [400, 286, 915, 300, 445, 281, 362, 341, 551, 307, 1217, 588, 8263, 11], "temperature": 0.0, "avg_logprob": -0.15457438593325407, "compression_ratio": 1.8384279475982532, "no_speech_prob": 7.527917205152335e-06}, {"id": 662, "seek": 255140, "start": 2571.4, "end": 2574.4, "text": " so that's what I do in my application code,", "tokens": [370, 300, 311, 437, 286, 360, 294, 452, 3861, 3089, 11], "temperature": 0.0, "avg_logprob": -0.15457438593325407, "compression_ratio": 1.8384279475982532, "no_speech_prob": 7.527917205152335e-06}, {"id": 663, "seek": 255140, "start": 2574.4, "end": 2578.4, "text": " and that's why I push at work to have some documentation,", "tokens": [293, 300, 311, 983, 286, 2944, 412, 589, 281, 362, 512, 14333, 11], "temperature": 0.0, "avg_logprob": -0.15457438593325407, "compression_ratio": 1.8384279475982532, "no_speech_prob": 7.527917205152335e-06}, {"id": 664, "seek": 257840, "start": 2578.4, "end": 2581.4, "text": " even if it's just for that, because that makes things a lot simpler.", "tokens": [754, 498, 309, 311, 445, 337, 300, 11, 570, 300, 1669, 721, 257, 688, 18587, 13], "temperature": 0.0, "avg_logprob": -0.16763405660981112, "compression_ratio": 1.6887966804979253, "no_speech_prob": 1.7061800008377759e-06}, {"id": 665, "seek": 257840, "start": 2581.4, "end": 2584.4, "text": " Cool. When you say some documentation,", "tokens": [8561, 13, 1133, 291, 584, 512, 14333, 11], "temperature": 0.0, "avg_logprob": -0.16763405660981112, "compression_ratio": 1.6887966804979253, "no_speech_prob": 1.7061800008377759e-06}, {"id": 666, "seek": 257840, "start": 2584.4, "end": 2588.4, "text": " are you mostly doing empty doc comments for internal things,", "tokens": [366, 291, 5240, 884, 6707, 3211, 3053, 337, 6920, 721, 11], "temperature": 0.0, "avg_logprob": -0.16763405660981112, "compression_ratio": 1.6887966804979253, "no_speech_prob": 1.7061800008377759e-06}, {"id": 667, "seek": 257840, "start": 2588.4, "end": 2592.4, "text": " or do you actually write something for these internal APIs?", "tokens": [420, 360, 291, 767, 2464, 746, 337, 613, 6920, 21445, 30], "temperature": 0.0, "avg_logprob": -0.16763405660981112, "compression_ratio": 1.6887966804979253, "no_speech_prob": 1.7061800008377759e-06}, {"id": 668, "seek": 257840, "start": 2592.4, "end": 2596.4, "text": " So if it's for application code, I usually don't write any documentation", "tokens": [407, 498, 309, 311, 337, 3861, 3089, 11, 286, 2673, 500, 380, 2464, 604, 14333], "temperature": 0.0, "avg_logprob": -0.16763405660981112, "compression_ratio": 1.6887966804979253, "no_speech_prob": 1.7061800008377759e-06}, {"id": 669, "seek": 257840, "start": 2596.4, "end": 2599.4, "text": " because it's not mandatory there.", "tokens": [570, 309, 311, 406, 22173, 456, 13], "temperature": 0.0, "avg_logprob": -0.16763405660981112, "compression_ratio": 1.6887966804979253, "no_speech_prob": 1.7061800008377759e-06}, {"id": 670, "seek": 257840, "start": 2599.4, "end": 2602.4, "text": " I try to have better names.", "tokens": [286, 853, 281, 362, 1101, 5288, 13], "temperature": 0.0, "avg_logprob": -0.16763405660981112, "compression_ratio": 1.6887966804979253, "no_speech_prob": 1.7061800008377759e-06}, {"id": 671, "seek": 257840, "start": 2602.4, "end": 2606.4, "text": " Usually things are pretty self-explanatory,", "tokens": [11419, 721, 366, 1238, 2698, 12, 3121, 16554, 4745, 11], "temperature": 0.0, "avg_logprob": -0.16763405660981112, "compression_ratio": 1.6887966804979253, "no_speech_prob": 1.7061800008377759e-06}, {"id": 672, "seek": 260640, "start": 2606.4, "end": 2610.4, "text": " especially because at work we have this way of working,", "tokens": [2318, 570, 412, 589, 321, 362, 341, 636, 295, 1364, 11], "temperature": 0.0, "avg_logprob": -0.16413496090815619, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.0904221855744254e-06}, {"id": 673, "seek": 260640, "start": 2610.4, "end": 2613.4, "text": " we have several patterns that we use over and over.", "tokens": [321, 362, 2940, 8294, 300, 321, 764, 670, 293, 670, 13], "temperature": 0.0, "avg_logprob": -0.16413496090815619, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.0904221855744254e-06}, {"id": 674, "seek": 260640, "start": 2613.4, "end": 2617.4, "text": " So once you know it, you don't have to explain things again.", "tokens": [407, 1564, 291, 458, 309, 11, 291, 500, 380, 362, 281, 2903, 721, 797, 13], "temperature": 0.0, "avg_logprob": -0.16413496090815619, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.0904221855744254e-06}, {"id": 675, "seek": 260640, "start": 2617.4, "end": 2621.4, "text": " So it does not make sense to explain button.withColor", "tokens": [407, 309, 775, 406, 652, 2020, 281, 2903, 2960, 13, 11820, 34, 36182], "temperature": 0.0, "avg_logprob": -0.16413496090815619, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.0904221855744254e-06}, {"id": 676, "seek": 260640, "start": 2621.4, "end": 2626.4, "text": " when you have so many other modules where you have withColor as well.", "tokens": [562, 291, 362, 370, 867, 661, 16679, 689, 291, 362, 365, 34, 36182, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.16413496090815619, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.0904221855744254e-06}, {"id": 677, "seek": 260640, "start": 2626.4, "end": 2629.4, "text": " It makes a lot more sense in package code, I think,", "tokens": [467, 1669, 257, 688, 544, 2020, 294, 7372, 3089, 11, 286, 519, 11], "temperature": 0.0, "avg_logprob": -0.16413496090815619, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.0904221855744254e-06}, {"id": 678, "seek": 260640, "start": 2629.4, "end": 2633.4, "text": " because people might be new to the pattern,", "tokens": [570, 561, 1062, 312, 777, 281, 264, 5102, 11], "temperature": 0.0, "avg_logprob": -0.16413496090815619, "compression_ratio": 1.7244444444444444, "no_speech_prob": 2.0904221855744254e-06}, {"id": 679, "seek": 263340, "start": 2633.4, "end": 2639.4, "text": " and you also don't need to have as much of a great documentation experience", "tokens": [293, 291, 611, 500, 380, 643, 281, 362, 382, 709, 295, 257, 869, 14333, 1752], "temperature": 0.0, "avg_logprob": -0.22011553586184324, "compression_ratio": 1.6403508771929824, "no_speech_prob": 3.966915301134577e-06}, {"id": 680, "seek": 263340, "start": 2639.4, "end": 2644.4, "text": " maybe at work, especially when you have colleagues that are right next to you,", "tokens": [1310, 412, 589, 11, 2318, 562, 291, 362, 7734, 300, 366, 558, 958, 281, 291, 11], "temperature": 0.0, "avg_logprob": -0.22011553586184324, "compression_ratio": 1.6403508771929824, "no_speech_prob": 3.966915301134577e-06}, {"id": 681, "seek": 263340, "start": 2644.4, "end": 2647.4, "text": " and because for application code, time is more precious", "tokens": [293, 570, 337, 3861, 3089, 11, 565, 307, 544, 12406], "temperature": 0.0, "avg_logprob": -0.22011553586184324, "compression_ratio": 1.6403508771929824, "no_speech_prob": 3.966915301134577e-06}, {"id": 682, "seek": 263340, "start": 2647.4, "end": 2650.4, "text": " than for open source maintainers.", "tokens": [813, 337, 1269, 4009, 6909, 433, 13], "temperature": 0.0, "avg_logprob": -0.22011553586184324, "compression_ratio": 1.6403508771929824, "no_speech_prob": 3.966915301134577e-06}, {"id": 683, "seek": 263340, "start": 2650.4, "end": 2656.4, "text": " I think it would depend if there's that one part of the code base", "tokens": [286, 519, 309, 576, 5672, 498, 456, 311, 300, 472, 644, 295, 264, 3089, 3096], "temperature": 0.0, "avg_logprob": -0.22011553586184324, "compression_ratio": 1.6403508771929824, "no_speech_prob": 3.966915301134577e-06}, {"id": 684, "seek": 263340, "start": 2656.4, "end": 2662.4, "text": " where new hires have to pair with the one person at the company", "tokens": [689, 777, 276, 3145, 362, 281, 6119, 365, 264, 472, 954, 412, 264, 2237], "temperature": 0.0, "avg_logprob": -0.22011553586184324, "compression_ratio": 1.6403508771929824, "no_speech_prob": 3.966915301134577e-06}, {"id": 685, "seek": 266240, "start": 2662.4, "end": 2665.4, "text": " who really actually knows how to use this thing", "tokens": [567, 534, 767, 3255, 577, 281, 764, 341, 551], "temperature": 0.0, "avg_logprob": -0.17232139631249438, "compression_ratio": 1.5692307692307692, "no_speech_prob": 4.006192830274813e-05}, {"id": 686, "seek": 266240, "start": 2665.4, "end": 2667.4, "text": " in order to get up and running,", "tokens": [294, 1668, 281, 483, 493, 293, 2614, 11], "temperature": 0.0, "avg_logprob": -0.17232139631249438, "compression_ratio": 1.5692307692307692, "no_speech_prob": 4.006192830274813e-05}, {"id": 687, "seek": 266240, "start": 2667.4, "end": 2671.4, "text": " then maybe that is a case where it's good to do that.", "tokens": [550, 1310, 300, 307, 257, 1389, 689, 309, 311, 665, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.17232139631249438, "compression_ratio": 1.5692307692307692, "no_speech_prob": 4.006192830274813e-05}, {"id": 688, "seek": 266240, "start": 2671.4, "end": 2677.4, "text": " I would say, because I am a big fan of self-documenting code,", "tokens": [286, 576, 584, 11, 570, 286, 669, 257, 955, 3429, 295, 2698, 12, 67, 30439, 278, 3089, 11], "temperature": 0.0, "avg_logprob": -0.17232139631249438, "compression_ratio": 1.5692307692307692, "no_speech_prob": 4.006192830274813e-05}, {"id": 689, "seek": 266240, "start": 2677.4, "end": 2685.4, "text": " and I will admit I very rarely write documentation for application code,", "tokens": [293, 286, 486, 9796, 286, 588, 13752, 2464, 14333, 337, 3861, 3089, 11], "temperature": 0.0, "avg_logprob": -0.17232139631249438, "compression_ratio": 1.5692307692307692, "no_speech_prob": 4.006192830274813e-05}, {"id": 690, "seek": 266240, "start": 2685.4, "end": 2687.4, "text": " and I don't think that's a bad thing.", "tokens": [293, 286, 500, 380, 519, 300, 311, 257, 1578, 551, 13], "temperature": 0.0, "avg_logprob": -0.17232139631249438, "compression_ratio": 1.5692307692307692, "no_speech_prob": 4.006192830274813e-05}, {"id": 691, "seek": 268740, "start": 2687.4, "end": 2693.4, "text": " I would say, to me, I'm not a fan of writing documentation", "tokens": [286, 576, 584, 11, 281, 385, 11, 286, 478, 406, 257, 3429, 295, 3579, 14333], "temperature": 0.0, "avg_logprob": -0.16821391494185836, "compression_ratio": 1.634020618556701, "no_speech_prob": 1.4063723028812092e-05}, {"id": 692, "seek": 268740, "start": 2693.4, "end": 2697.4, "text": " when a good name would achieve the same thing.", "tokens": [562, 257, 665, 1315, 576, 4584, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.16821391494185836, "compression_ratio": 1.634020618556701, "no_speech_prob": 1.4063723028812092e-05}, {"id": 693, "seek": 268740, "start": 2697.4, "end": 2702.4, "text": " I think it's sort of like going down the chain.", "tokens": [286, 519, 309, 311, 1333, 295, 411, 516, 760, 264, 5021, 13], "temperature": 0.0, "avg_logprob": -0.16821391494185836, "compression_ratio": 1.634020618556701, "no_speech_prob": 1.4063723028812092e-05}, {"id": 694, "seek": 268740, "start": 2702.4, "end": 2706.4, "text": " I think you should always prefer communicating something", "tokens": [286, 519, 291, 820, 1009, 4382, 17559, 746], "temperature": 0.0, "avg_logprob": -0.16821391494185836, "compression_ratio": 1.634020618556701, "no_speech_prob": 1.4063723028812092e-05}, {"id": 695, "seek": 268740, "start": 2706.4, "end": 2711.4, "text": " through good naming and good API design when possible,", "tokens": [807, 665, 25290, 293, 665, 9362, 1715, 562, 1944, 11], "temperature": 0.0, "avg_logprob": -0.16821391494185836, "compression_ratio": 1.634020618556701, "no_speech_prob": 1.4063723028812092e-05}, {"id": 696, "seek": 268740, "start": 2711.4, "end": 2716.4, "text": " and also through a good, easy way to use something.", "tokens": [293, 611, 807, 257, 665, 11, 1858, 636, 281, 764, 746, 13], "temperature": 0.0, "avg_logprob": -0.16821391494185836, "compression_ratio": 1.634020618556701, "no_speech_prob": 1.4063723028812092e-05}, {"id": 697, "seek": 271640, "start": 2716.4, "end": 2721.4, "text": " A command line interface and automation rather than a cookbook.", "tokens": [316, 5622, 1622, 9226, 293, 17769, 2831, 813, 257, 2543, 2939, 13], "temperature": 0.0, "avg_logprob": -0.2080002653187719, "compression_ratio": 1.6602316602316602, "no_speech_prob": 1.723130844766274e-05}, {"id": 698, "seek": 271640, "start": 2721.4, "end": 2723.4, "text": " Here are five different steps, right?", "tokens": [1692, 366, 1732, 819, 4439, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2080002653187719, "compression_ratio": 1.6602316602316602, "no_speech_prob": 1.723130844766274e-05}, {"id": 699, "seek": 271640, "start": 2723.4, "end": 2725.4, "text": " That might be calling out to automate it.", "tokens": [663, 1062, 312, 5141, 484, 281, 31605, 309, 13], "temperature": 0.0, "avg_logprob": -0.2080002653187719, "compression_ratio": 1.6602316602316602, "no_speech_prob": 1.723130844766274e-05}, {"id": 700, "seek": 271640, "start": 2725.4, "end": 2729.4, "text": " So like, oh, I was a good boy and I wrote some documentation for this.", "tokens": [407, 411, 11, 1954, 11, 286, 390, 257, 665, 3237, 293, 286, 4114, 512, 14333, 337, 341, 13], "temperature": 0.0, "avg_logprob": -0.2080002653187719, "compression_ratio": 1.6602316602316602, "no_speech_prob": 1.723130844766274e-05}, {"id": 701, "seek": 271640, "start": 2729.4, "end": 2731.4, "text": " It's like, well, maybe you weren't such a good boy.", "tokens": [467, 311, 411, 11, 731, 11, 1310, 291, 4999, 380, 1270, 257, 665, 3237, 13], "temperature": 0.0, "avg_logprob": -0.2080002653187719, "compression_ratio": 1.6602316602316602, "no_speech_prob": 1.723130844766274e-05}, {"id": 702, "seek": 271640, "start": 2731.4, "end": 2733.4, "text": " Maybe you should have automated that.", "tokens": [2704, 291, 820, 362, 18473, 300, 13], "temperature": 0.0, "avg_logprob": -0.2080002653187719, "compression_ratio": 1.6602316602316602, "no_speech_prob": 1.723130844766274e-05}, {"id": 703, "seek": 271640, "start": 2733.4, "end": 2739.4, "text": " It's also because function names, that's what you see when you read code, right?", "tokens": [467, 311, 611, 570, 2445, 5288, 11, 300, 311, 437, 291, 536, 562, 291, 1401, 3089, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2080002653187719, "compression_ratio": 1.6602316602316602, "no_speech_prob": 1.723130844766274e-05}, {"id": 704, "seek": 271640, "start": 2739.4, "end": 2743.4, "text": " You can go to the documentation in your IDE,", "tokens": [509, 393, 352, 281, 264, 14333, 294, 428, 40930, 11], "temperature": 0.0, "avg_logprob": -0.2080002653187719, "compression_ratio": 1.6602316602316602, "no_speech_prob": 1.723130844766274e-05}, {"id": 705, "seek": 274340, "start": 2743.4, "end": 2749.4, "text": " sometimes on GitHub or through searching for yourself in the package website.", "tokens": [2171, 322, 23331, 420, 807, 10808, 337, 1803, 294, 264, 7372, 3144, 13], "temperature": 0.0, "avg_logprob": -0.2263807119782438, "compression_ratio": 1.6347826086956523, "no_speech_prob": 2.0261090867279563e-06}, {"id": 706, "seek": 274340, "start": 2749.4, "end": 2753.4, "text": " But it's much easier to see the function name,", "tokens": [583, 309, 311, 709, 3571, 281, 536, 264, 2445, 1315, 11], "temperature": 0.0, "avg_logprob": -0.2263807119782438, "compression_ratio": 1.6347826086956523, "no_speech_prob": 2.0261090867279563e-06}, {"id": 707, "seek": 274340, "start": 2753.4, "end": 2757.4, "text": " and if that conveys the meaning, then that's all you need.", "tokens": [293, 498, 300, 18053, 749, 264, 3620, 11, 550, 300, 311, 439, 291, 643, 13], "temperature": 0.0, "avg_logprob": -0.2263807119782438, "compression_ratio": 1.6347826086956523, "no_speech_prob": 2.0261090867279563e-06}, {"id": 708, "seek": 274340, "start": 2757.4, "end": 2763.4, "text": " When I write bash code, or sorry, when I look for a command to do something", "tokens": [1133, 286, 2464, 46183, 3089, 11, 420, 2597, 11, 562, 286, 574, 337, 257, 5622, 281, 360, 746], "temperature": 0.0, "avg_logprob": -0.2263807119782438, "compression_ratio": 1.6347826086956523, "no_speech_prob": 2.0261090867279563e-06}, {"id": 709, "seek": 274340, "start": 2763.4, "end": 2765.4, "text": " and someone on StackOverflow says,", "tokens": [293, 1580, 322, 37649, 33093, 10565, 1619, 11], "temperature": 0.0, "avg_logprob": -0.2263807119782438, "compression_ratio": 1.6347826086956523, "no_speech_prob": 2.0261090867279563e-06}, {"id": 710, "seek": 274340, "start": 2765.4, "end": 2772.4, "text": " oh, you should run this command, pipe this command, this slash pipe this command,", "tokens": [1954, 11, 291, 820, 1190, 341, 5622, 11, 11240, 341, 5622, 11, 341, 17330, 11240, 341, 5622, 11], "temperature": 0.0, "avg_logprob": -0.2263807119782438, "compression_ratio": 1.6347826086956523, "no_speech_prob": 2.0261090867279563e-06}, {"id": 711, "seek": 277240, "start": 2772.4, "end": 2774.4, "text": " and I'm like, I know none of these commands,", "tokens": [293, 286, 478, 411, 11, 286, 458, 6022, 295, 613, 16901, 11], "temperature": 0.0, "avg_logprob": -0.2031518605129778, "compression_ratio": 1.6626506024096386, "no_speech_prob": 3.2376606213802006e-06}, {"id": 712, "seek": 277240, "start": 2774.4, "end": 2779.4, "text": " or there are some of these flags that are new to me.", "tokens": [420, 456, 366, 512, 295, 613, 23265, 300, 366, 777, 281, 385, 13], "temperature": 0.0, "avg_logprob": -0.2031518605129778, "compression_ratio": 1.6626506024096386, "no_speech_prob": 3.2376606213802006e-06}, {"id": 713, "seek": 277240, "start": 2779.4, "end": 2781.4, "text": " Well, now I need to read the documentation.", "tokens": [1042, 11, 586, 286, 643, 281, 1401, 264, 14333, 13], "temperature": 0.0, "avg_logprob": -0.2031518605129778, "compression_ratio": 1.6626506024096386, "no_speech_prob": 3.2376606213802006e-06}, {"id": 714, "seek": 277240, "start": 2781.4, "end": 2785.4, "text": " So hopefully it's going to be good, but like for bash commands,", "tokens": [407, 4696, 309, 311, 516, 281, 312, 665, 11, 457, 411, 337, 46183, 16901, 11], "temperature": 0.0, "avg_logprob": -0.2031518605129778, "compression_ratio": 1.6626506024096386, "no_speech_prob": 3.2376606213802006e-06}, {"id": 715, "seek": 277240, "start": 2785.4, "end": 2788.4, "text": " everything is in like one manual.", "tokens": [1203, 307, 294, 411, 472, 9688, 13], "temperature": 0.0, "avg_logprob": -0.2031518605129778, "compression_ratio": 1.6626506024096386, "no_speech_prob": 3.2376606213802006e-06}, {"id": 716, "seek": 277240, "start": 2788.4, "end": 2791.4, "text": " It's one readme-ish document.", "tokens": [467, 311, 472, 1401, 1398, 12, 742, 4166, 13], "temperature": 0.0, "avg_logprob": -0.2031518605129778, "compression_ratio": 1.6626506024096386, "no_speech_prob": 3.2376606213802006e-06}, {"id": 717, "seek": 277240, "start": 2791.4, "end": 2794.4, "text": " So it's hard to find the information you want sometimes.", "tokens": [407, 309, 311, 1152, 281, 915, 264, 1589, 291, 528, 2171, 13], "temperature": 0.0, "avg_logprob": -0.2031518605129778, "compression_ratio": 1.6626506024096386, "no_speech_prob": 3.2376606213802006e-06}, {"id": 718, "seek": 277240, "start": 2794.4, "end": 2797.4, "text": " And also, like, there's just a lot of things.", "tokens": [400, 611, 11, 411, 11, 456, 311, 445, 257, 688, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.2031518605129778, "compression_ratio": 1.6626506024096386, "no_speech_prob": 3.2376606213802006e-06}, {"id": 719, "seek": 277240, "start": 2797.4, "end": 2800.4, "text": " So yeah, good names is always preferable.", "tokens": [407, 1338, 11, 665, 5288, 307, 1009, 4382, 712, 13], "temperature": 0.0, "avg_logprob": -0.2031518605129778, "compression_ratio": 1.6626506024096386, "no_speech_prob": 3.2376606213802006e-06}, {"id": 720, "seek": 280040, "start": 2800.4, "end": 2803.4, "text": " But if you can have both, go for both.", "tokens": [583, 498, 291, 393, 362, 1293, 11, 352, 337, 1293, 13], "temperature": 0.0, "avg_logprob": -0.15372965751437967, "compression_ratio": 1.596774193548387, "no_speech_prob": 3.393128054085537e-06}, {"id": 721, "seek": 280040, "start": 2803.4, "end": 2808.4, "text": " Right. And also, I mean, this is sort of maybe so obvious", "tokens": [1779, 13, 400, 611, 11, 286, 914, 11, 341, 307, 1333, 295, 1310, 370, 6322], "temperature": 0.0, "avg_logprob": -0.15372965751437967, "compression_ratio": 1.596774193548387, "no_speech_prob": 3.393128054085537e-06}, {"id": 722, "seek": 280040, "start": 2808.4, "end": 2810.4, "text": " that we wouldn't think to mention it here", "tokens": [300, 321, 2759, 380, 519, 281, 2152, 309, 510], "temperature": 0.0, "avg_logprob": -0.15372965751437967, "compression_ratio": 1.596774193548387, "no_speech_prob": 3.393128054085537e-06}, {"id": 723, "seek": 280040, "start": 2810.4, "end": 2813.4, "text": " because we sort of talk about this all the time.", "tokens": [570, 321, 1333, 295, 751, 466, 341, 439, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.15372965751437967, "compression_ratio": 1.596774193548387, "no_speech_prob": 3.393128054085537e-06}, {"id": 724, "seek": 280040, "start": 2813.4, "end": 2817.4, "text": " But the API design is part of the documentation.", "tokens": [583, 264, 9362, 1715, 307, 644, 295, 264, 14333, 13], "temperature": 0.0, "avg_logprob": -0.15372965751437967, "compression_ratio": 1.596774193548387, "no_speech_prob": 3.393128054085537e-06}, {"id": 725, "seek": 280040, "start": 2817.4, "end": 2823.4, "text": " Where you look to find a function, how you group together,", "tokens": [2305, 291, 574, 281, 915, 257, 2445, 11, 577, 291, 1594, 1214, 11], "temperature": 0.0, "avg_logprob": -0.15372965751437967, "compression_ratio": 1.596774193548387, "no_speech_prob": 3.393128054085537e-06}, {"id": 726, "seek": 280040, "start": 2823.4, "end": 2827.4, "text": " and it's actually something I put a lot of thought into.", "tokens": [293, 309, 311, 767, 746, 286, 829, 257, 688, 295, 1194, 666, 13], "temperature": 0.0, "avg_logprob": -0.15372965751437967, "compression_ratio": 1.596774193548387, "no_speech_prob": 3.393128054085537e-06}, {"id": 727, "seek": 280040, "start": 2827.4, "end": 2829.4, "text": " It's actually quite difficult to get right.", "tokens": [467, 311, 767, 1596, 2252, 281, 483, 558, 13], "temperature": 0.0, "avg_logprob": -0.15372965751437967, "compression_ratio": 1.596774193548387, "no_speech_prob": 3.393128054085537e-06}, {"id": 728, "seek": 282940, "start": 2829.4, "end": 2834.4, "text": " Do you have one big module with a bunch of things thrown in there?", "tokens": [1144, 291, 362, 472, 955, 10088, 365, 257, 3840, 295, 721, 11732, 294, 456, 30], "temperature": 0.0, "avg_logprob": -0.1993246532621838, "compression_ratio": 1.651063829787234, "no_speech_prob": 6.339113951980835e-06}, {"id": 729, "seek": 282940, "start": 2834.4, "end": 2838.4, "text": " Do you have a lot of small modules that have things clearly separated?", "tokens": [1144, 291, 362, 257, 688, 295, 1359, 16679, 300, 362, 721, 4448, 12005, 30], "temperature": 0.0, "avg_logprob": -0.1993246532621838, "compression_ratio": 1.651063829787234, "no_speech_prob": 6.339113951980835e-06}, {"id": 730, "seek": 282940, "start": 2838.4, "end": 2842.4, "text": " I think the way you organize things into Lmodules", "tokens": [286, 519, 264, 636, 291, 13859, 721, 666, 441, 8014, 3473], "temperature": 0.0, "avg_logprob": -0.1993246532621838, "compression_ratio": 1.651063829787234, "no_speech_prob": 6.339113951980835e-06}, {"id": 731, "seek": 282940, "start": 2842.4, "end": 2847.4, "text": " is really a part of how you're presenting these concepts to users.", "tokens": [307, 534, 257, 644, 295, 577, 291, 434, 15578, 613, 10392, 281, 5022, 13], "temperature": 0.0, "avg_logprob": -0.1993246532621838, "compression_ratio": 1.651063829787234, "no_speech_prob": 6.339113951980835e-06}, {"id": 732, "seek": 282940, "start": 2847.4, "end": 2850.4, "text": " What should they think of together?", "tokens": [708, 820, 436, 519, 295, 1214, 30], "temperature": 0.0, "avg_logprob": -0.1993246532621838, "compression_ratio": 1.651063829787234, "no_speech_prob": 6.339113951980835e-06}, {"id": 733, "seek": 282940, "start": 2850.4, "end": 2852.4, "text": " But it's also an ergonomic thing.", "tokens": [583, 309, 311, 611, 364, 42735, 21401, 551, 13], "temperature": 0.0, "avg_logprob": -0.1993246532621838, "compression_ratio": 1.651063829787234, "no_speech_prob": 6.339113951980835e-06}, {"id": 734, "seek": 282940, "start": 2852.4, "end": 2854.4, "text": " How many imports are they going to need?", "tokens": [1012, 867, 41596, 366, 436, 516, 281, 643, 30], "temperature": 0.0, "avg_logprob": -0.1993246532621838, "compression_ratio": 1.651063829787234, "no_speech_prob": 6.339113951980835e-06}, {"id": 735, "seek": 282940, "start": 2854.4, "end": 2856.4, "text": " And also, it's a sign.", "tokens": [400, 611, 11, 309, 311, 257, 1465, 13], "temperature": 0.0, "avg_logprob": -0.1993246532621838, "compression_ratio": 1.651063829787234, "no_speech_prob": 6.339113951980835e-06}, {"id": 736, "seek": 285640, "start": 2856.4, "end": 2859.4, "text": " If you have a lot of modules, is that a lot of concepts?", "tokens": [759, 291, 362, 257, 688, 295, 16679, 11, 307, 300, 257, 688, 295, 10392, 30], "temperature": 0.0, "avg_logprob": -0.17641011306217738, "compression_ratio": 1.7729257641921397, "no_speech_prob": 4.785048531630309e-06}, {"id": 737, "seek": 285640, "start": 2859.4, "end": 2862.4, "text": " If you have a lot of modules,", "tokens": [759, 291, 362, 257, 688, 295, 16679, 11], "temperature": 0.0, "avg_logprob": -0.17641011306217738, "compression_ratio": 1.7729257641921397, "no_speech_prob": 4.785048531630309e-06}, {"id": 738, "seek": 285640, "start": 2862.4, "end": 2865.4, "text": " but you end up having to import all of them every time,", "tokens": [457, 291, 917, 493, 1419, 281, 974, 439, 295, 552, 633, 565, 11], "temperature": 0.0, "avg_logprob": -0.17641011306217738, "compression_ratio": 1.7729257641921397, "no_speech_prob": 4.785048531630309e-06}, {"id": 739, "seek": 285640, "start": 2865.4, "end": 2867.4, "text": " that might not be a great experience.", "tokens": [300, 1062, 406, 312, 257, 869, 1752, 13], "temperature": 0.0, "avg_logprob": -0.17641011306217738, "compression_ratio": 1.7729257641921397, "no_speech_prob": 4.785048531630309e-06}, {"id": 740, "seek": 285640, "start": 2867.4, "end": 2874.4, "text": " So it's really a delicate process to slice things up into a meaningful way.", "tokens": [407, 309, 311, 534, 257, 21417, 1399, 281, 13153, 721, 493, 666, 257, 10995, 636, 13], "temperature": 0.0, "avg_logprob": -0.17641011306217738, "compression_ratio": 1.7729257641921397, "no_speech_prob": 4.785048531630309e-06}, {"id": 741, "seek": 285640, "start": 2874.4, "end": 2879.4, "text": " But you're presenting these ways of grouping things,", "tokens": [583, 291, 434, 15578, 613, 2098, 295, 40149, 721, 11], "temperature": 0.0, "avg_logprob": -0.17641011306217738, "compression_ratio": 1.7729257641921397, "no_speech_prob": 4.785048531630309e-06}, {"id": 742, "seek": 285640, "start": 2879.4, "end": 2883.4, "text": " not just in terms of how you import them, but how you think of them,", "tokens": [406, 445, 294, 2115, 295, 577, 291, 974, 552, 11, 457, 577, 291, 519, 295, 552, 11], "temperature": 0.0, "avg_logprob": -0.17641011306217738, "compression_ratio": 1.7729257641921397, "no_speech_prob": 4.785048531630309e-06}, {"id": 743, "seek": 285640, "start": 2883.4, "end": 2885.4, "text": " and also how you read them.", "tokens": [293, 611, 577, 291, 1401, 552, 13], "temperature": 0.0, "avg_logprob": -0.17641011306217738, "compression_ratio": 1.7729257641921397, "no_speech_prob": 4.785048531630309e-06}, {"id": 744, "seek": 288540, "start": 2885.4, "end": 2889.4, "text": " Because Elm package documentation is organized by module,", "tokens": [1436, 2699, 76, 7372, 14333, 307, 9983, 538, 10088, 11], "temperature": 0.0, "avg_logprob": -0.19362332869549187, "compression_ratio": 1.75, "no_speech_prob": 2.3552312995889224e-05}, {"id": 745, "seek": 288540, "start": 2889.4, "end": 2893.4, "text": " it really is like the pages in your documentation.", "tokens": [309, 534, 307, 411, 264, 7183, 294, 428, 14333, 13], "temperature": 0.0, "avg_logprob": -0.19362332869549187, "compression_ratio": 1.75, "no_speech_prob": 2.3552312995889224e-05}, {"id": 746, "seek": 288540, "start": 2893.4, "end": 2895.4, "text": " And I think that's a brilliant part of it.", "tokens": [400, 286, 519, 300, 311, 257, 10248, 644, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.19362332869549187, "compression_ratio": 1.75, "no_speech_prob": 2.3552312995889224e-05}, {"id": 747, "seek": 288540, "start": 2895.4, "end": 2898.4, "text": " And again, back to your sort of opening sentiment", "tokens": [400, 797, 11, 646, 281, 428, 1333, 295, 5193, 16149], "temperature": 0.0, "avg_logprob": -0.19362332869549187, "compression_ratio": 1.75, "no_speech_prob": 2.3552312995889224e-05}, {"id": 748, "seek": 288540, "start": 2898.4, "end": 2902.4, "text": " about the baseline for quality in Elm documentation.", "tokens": [466, 264, 20518, 337, 3125, 294, 2699, 76, 14333, 13], "temperature": 0.0, "avg_logprob": -0.19362332869549187, "compression_ratio": 1.75, "no_speech_prob": 2.3552312995889224e-05}, {"id": 749, "seek": 288540, "start": 2902.4, "end": 2905.4, "text": " I think that's part of it, is things are grouped", "tokens": [286, 519, 300, 311, 644, 295, 309, 11, 307, 721, 366, 41877], "temperature": 0.0, "avg_logprob": -0.19362332869549187, "compression_ratio": 1.75, "no_speech_prob": 2.3552312995889224e-05}, {"id": 750, "seek": 288540, "start": 2905.4, "end": 2909.4, "text": " where a module is a page in your docs.", "tokens": [689, 257, 10088, 307, 257, 3028, 294, 428, 45623, 13], "temperature": 0.0, "avg_logprob": -0.19362332869549187, "compression_ratio": 1.75, "no_speech_prob": 2.3552312995889224e-05}, {"id": 751, "seek": 288540, "start": 2909.4, "end": 2912.4, "text": " And so you import one thing,", "tokens": [400, 370, 291, 974, 472, 551, 11], "temperature": 0.0, "avg_logprob": -0.19362332869549187, "compression_ratio": 1.75, "no_speech_prob": 2.3552312995889224e-05}, {"id": 752, "seek": 291240, "start": 2912.4, "end": 2915.4, "text": " you read the docs about that one thing you imported,", "tokens": [291, 1401, 264, 45623, 466, 300, 472, 551, 291, 25524, 11], "temperature": 0.0, "avg_logprob": -0.17580476857848087, "compression_ratio": 1.6, "no_speech_prob": 5.5942218750715256e-06}, {"id": 753, "seek": 291240, "start": 2915.4, "end": 2918.4, "text": " and it's all grouped together logically.", "tokens": [293, 309, 311, 439, 41877, 1214, 38887, 13], "temperature": 0.0, "avg_logprob": -0.17580476857848087, "compression_ratio": 1.6, "no_speech_prob": 5.5942218750715256e-06}, {"id": 754, "seek": 291240, "start": 2918.4, "end": 2922.4, "text": " So that really shapes the way I write documentation.", "tokens": [407, 300, 534, 10854, 264, 636, 286, 2464, 14333, 13], "temperature": 0.0, "avg_logprob": -0.17580476857848087, "compression_ratio": 1.6, "no_speech_prob": 5.5942218750715256e-06}, {"id": 755, "seek": 291240, "start": 2922.4, "end": 2925.4, "text": " So for example, like in Elm Pages v3,", "tokens": [407, 337, 1365, 11, 411, 294, 2699, 76, 430, 1660, 371, 18, 11], "temperature": 0.0, "avg_logprob": -0.17580476857848087, "compression_ratio": 1.6, "no_speech_prob": 5.5942218750715256e-06}, {"id": 756, "seek": 291240, "start": 2925.4, "end": 2927.4, "text": " back-end task is a big part of it.", "tokens": [646, 12, 521, 5633, 307, 257, 955, 644, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.17580476857848087, "compression_ratio": 1.6, "no_speech_prob": 5.5942218750715256e-06}, {"id": 757, "seek": 291240, "start": 2927.4, "end": 2931.4, "text": " So I have a back-end task.env module,", "tokens": [407, 286, 362, 257, 646, 12, 521, 5633, 13, 268, 85, 10088, 11], "temperature": 0.0, "avg_logprob": -0.17580476857848087, "compression_ratio": 1.6, "no_speech_prob": 5.5942218750715256e-06}, {"id": 758, "seek": 291240, "start": 2931.4, "end": 2933.4, "text": " which is a pretty small module.", "tokens": [597, 307, 257, 1238, 1359, 10088, 13], "temperature": 0.0, "avg_logprob": -0.17580476857848087, "compression_ratio": 1.6, "no_speech_prob": 5.5942218750715256e-06}, {"id": 759, "seek": 291240, "start": 2933.4, "end": 2937.4, "text": " It's got a couple of things for expecting to get an environment variable", "tokens": [467, 311, 658, 257, 1916, 295, 721, 337, 9650, 281, 483, 364, 2823, 7006], "temperature": 0.0, "avg_logprob": -0.17580476857848087, "compression_ratio": 1.6, "no_speech_prob": 5.5942218750715256e-06}, {"id": 760, "seek": 291240, "start": 2937.4, "end": 2940.4, "text": " and errors that can come up when you do that.", "tokens": [293, 13603, 300, 393, 808, 493, 562, 291, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.17580476857848087, "compression_ratio": 1.6, "no_speech_prob": 5.5942218750715256e-06}, {"id": 761, "seek": 294040, "start": 2940.4, "end": 2944.4, "text": " Or back-end task.file, that is a module that is, you know,", "tokens": [1610, 646, 12, 521, 5633, 13, 69, 794, 11, 300, 307, 257, 10088, 300, 307, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.20435340125281531, "compression_ratio": 1.6851063829787234, "no_speech_prob": 3.4465551834728103e-06}, {"id": 762, "seek": 294040, "start": 2944.4, "end": 2950.4, "text": " knows how to read files that might have some front matter formatting in them,", "tokens": [3255, 577, 281, 1401, 7098, 300, 1062, 362, 512, 1868, 1871, 39366, 294, 552, 11], "temperature": 0.0, "avg_logprob": -0.20435340125281531, "compression_ratio": 1.6851063829787234, "no_speech_prob": 3.4465551834728103e-06}, {"id": 763, "seek": 294040, "start": 2950.4, "end": 2953.4, "text": " or it might not, read a raw file, read a JSON file, things like that.", "tokens": [420, 309, 1062, 406, 11, 1401, 257, 8936, 3991, 11, 1401, 257, 31828, 3991, 11, 721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.20435340125281531, "compression_ratio": 1.6851063829787234, "no_speech_prob": 3.4465551834728103e-06}, {"id": 764, "seek": 294040, "start": 2953.4, "end": 2959.4, "text": " It's a pretty mechanical module, but it also sort of describes", "tokens": [467, 311, 257, 1238, 12070, 10088, 11, 457, 309, 611, 1333, 295, 15626], "temperature": 0.0, "avg_logprob": -0.20435340125281531, "compression_ratio": 1.6851063829787234, "no_speech_prob": 3.4465551834728103e-06}, {"id": 765, "seek": 294040, "start": 2959.4, "end": 2964.4, "text": " that this is something that Elm Pages allows you to do, read from files.", "tokens": [300, 341, 307, 746, 300, 2699, 76, 430, 1660, 4045, 291, 281, 360, 11, 1401, 490, 7098, 13], "temperature": 0.0, "avg_logprob": -0.20435340125281531, "compression_ratio": 1.6851063829787234, "no_speech_prob": 3.4465551834728103e-06}, {"id": 766, "seek": 294040, "start": 2964.4, "end": 2969.4, "text": " But it also references back to the back-end task API,", "tokens": [583, 309, 611, 15400, 646, 281, 264, 646, 12, 521, 5633, 9362, 11], "temperature": 0.0, "avg_logprob": -0.20435340125281531, "compression_ratio": 1.6851063829787234, "no_speech_prob": 3.4465551834728103e-06}, {"id": 767, "seek": 296940, "start": 2969.4, "end": 2972.4, "text": " because this is the sort of core abstraction.", "tokens": [570, 341, 307, 264, 1333, 295, 4965, 37765, 13], "temperature": 0.0, "avg_logprob": -0.19762441427400795, "compression_ratio": 1.7521739130434784, "no_speech_prob": 1.1300773621769622e-05}, {"id": 768, "seek": 296940, "start": 2972.4, "end": 2978.4, "text": " And so this module has really, it breaks down the mental model.", "tokens": [400, 370, 341, 10088, 575, 534, 11, 309, 9857, 760, 264, 4973, 2316, 13], "temperature": 0.0, "avg_logprob": -0.19762441427400795, "compression_ratio": 1.7521739130434784, "no_speech_prob": 1.1300773621769622e-05}, {"id": 769, "seek": 296940, "start": 2978.4, "end": 2980.4, "text": " It breaks down a conceptual guide,", "tokens": [467, 9857, 760, 257, 24106, 5934, 11], "temperature": 0.0, "avg_logprob": -0.19762441427400795, "compression_ratio": 1.7521739130434784, "no_speech_prob": 1.1300773621769622e-05}, {"id": 770, "seek": 296940, "start": 2980.4, "end": 2983.4, "text": " and it links out to all these different ways you could use it.", "tokens": [293, 309, 6123, 484, 281, 439, 613, 819, 2098, 291, 727, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.19762441427400795, "compression_ratio": 1.7521739130434784, "no_speech_prob": 1.1300773621769622e-05}, {"id": 771, "seek": 296940, "start": 2983.4, "end": 2988.4, "text": " So this is the opportunity to present these sort of key concepts", "tokens": [407, 341, 307, 264, 2650, 281, 1974, 613, 1333, 295, 2141, 10392], "temperature": 0.0, "avg_logprob": -0.19762441427400795, "compression_ratio": 1.7521739130434784, "no_speech_prob": 1.1300773621769622e-05}, {"id": 772, "seek": 296940, "start": 2988.4, "end": 2992.4, "text": " and the API for how to use this basic building block.", "tokens": [293, 264, 9362, 337, 577, 281, 764, 341, 3875, 2390, 3461, 13], "temperature": 0.0, "avg_logprob": -0.19762441427400795, "compression_ratio": 1.7521739130434784, "no_speech_prob": 1.1300773621769622e-05}, {"id": 773, "seek": 296940, "start": 2992.4, "end": 2998.4, "text": " And then that in turn links out to all these more specific ways to use them,", "tokens": [400, 550, 300, 294, 1261, 6123, 484, 281, 439, 613, 544, 2685, 2098, 281, 764, 552, 11], "temperature": 0.0, "avg_logprob": -0.19762441427400795, "compression_ratio": 1.7521739130434784, "no_speech_prob": 1.1300773621769622e-05}, {"id": 774, "seek": 299840, "start": 2998.4, "end": 3002.4, "text": " like back-end task.custom is another huge piece, right?", "tokens": [411, 646, 12, 521, 5633, 13, 66, 2239, 307, 1071, 2603, 2522, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.17533127466837564, "compression_ratio": 1.6401673640167365, "no_speech_prob": 3.071808532695286e-05}, {"id": 775, "seek": 299840, "start": 3002.4, "end": 3007.4, "text": " It's allowing you to run arbitrary code in a JavaScript environment", "tokens": [467, 311, 8293, 291, 281, 1190, 23211, 3089, 294, 257, 15778, 2823], "temperature": 0.0, "avg_logprob": -0.17533127466837564, "compression_ratio": 1.6401673640167365, "no_speech_prob": 3.071808532695286e-05}, {"id": 776, "seek": 299840, "start": 3007.4, "end": 3013.4, "text": " that you can have access to and encode data to send to it, decode data to get back.", "tokens": [300, 291, 393, 362, 2105, 281, 293, 2058, 1429, 1412, 281, 2845, 281, 309, 11, 979, 1429, 1412, 281, 483, 646, 13], "temperature": 0.0, "avg_logprob": -0.17533127466837564, "compression_ratio": 1.6401673640167365, "no_speech_prob": 3.071808532695286e-05}, {"id": 777, "seek": 299840, "start": 3013.4, "end": 3016.4, "text": " It calls an async JavaScript function, right?", "tokens": [467, 5498, 364, 382, 34015, 15778, 2445, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.17533127466837564, "compression_ratio": 1.6401673640167365, "no_speech_prob": 3.071808532695286e-05}, {"id": 778, "seek": 299840, "start": 3016.4, "end": 3019.4, "text": " That is, that's a big concept to chew off.", "tokens": [663, 307, 11, 300, 311, 257, 955, 3410, 281, 21200, 766, 13], "temperature": 0.0, "avg_logprob": -0.17533127466837564, "compression_ratio": 1.6401673640167365, "no_speech_prob": 3.071808532695286e-05}, {"id": 779, "seek": 299840, "start": 3019.4, "end": 3023.4, "text": " If that was part of the back-end task module's documentation,", "tokens": [759, 300, 390, 644, 295, 264, 646, 12, 521, 5633, 10088, 311, 14333, 11], "temperature": 0.0, "avg_logprob": -0.17533127466837564, "compression_ratio": 1.6401673640167365, "no_speech_prob": 3.071808532695286e-05}, {"id": 780, "seek": 299840, "start": 3023.4, "end": 3025.4, "text": " it would be kind of overwhelming.", "tokens": [309, 576, 312, 733, 295, 13373, 13], "temperature": 0.0, "avg_logprob": -0.17533127466837564, "compression_ratio": 1.6401673640167365, "no_speech_prob": 3.071808532695286e-05}, {"id": 781, "seek": 302540, "start": 3025.4, "end": 3031.4, "text": " It would be bombarding the user with information to understand", "tokens": [467, 576, 312, 42894, 278, 264, 4195, 365, 1589, 281, 1223], "temperature": 0.0, "avg_logprob": -0.1857731221085888, "compression_ratio": 1.6414342629482073, "no_speech_prob": 1.406391675118357e-05}, {"id": 782, "seek": 302540, "start": 3031.4, "end": 3035.4, "text": " when they might just be like, what is a back-end task?", "tokens": [562, 436, 1062, 445, 312, 411, 11, 437, 307, 257, 646, 12, 521, 5633, 30], "temperature": 0.0, "avg_logprob": -0.1857731221085888, "compression_ratio": 1.6414342629482073, "no_speech_prob": 1.406391675118357e-05}, {"id": 783, "seek": 302540, "start": 3035.4, "end": 3036.4, "text": " I'm new to Elm pages.", "tokens": [286, 478, 777, 281, 2699, 76, 7183, 13], "temperature": 0.0, "avg_logprob": -0.1857731221085888, "compression_ratio": 1.6414342629482073, "no_speech_prob": 1.406391675118357e-05}, {"id": 784, "seek": 302540, "start": 3036.4, "end": 3042.4, "text": " But it's linked to, and there's a short set of bullet points at the top of back-end task.", "tokens": [583, 309, 311, 9408, 281, 11, 293, 456, 311, 257, 2099, 992, 295, 11632, 2793, 412, 264, 1192, 295, 646, 12, 521, 5633, 13], "temperature": 0.0, "avg_logprob": -0.1857731221085888, "compression_ratio": 1.6414342629482073, "no_speech_prob": 1.406391675118357e-05}, {"id": 785, "seek": 302540, "start": 3042.4, "end": 3047.4, "text": " So it describes what is a back-end task in a concise one-sentence way,", "tokens": [407, 309, 15626, 437, 307, 257, 646, 12, 521, 5633, 294, 257, 44882, 472, 12, 49315, 655, 636, 11], "temperature": 0.0, "avg_logprob": -0.1857731221085888, "compression_ratio": 1.6414342629482073, "no_speech_prob": 1.406391675118357e-05}, {"id": 786, "seek": 302540, "start": 3047.4, "end": 3051.4, "text": " and then what are the ways you can use it?", "tokens": [293, 550, 437, 366, 264, 2098, 291, 393, 764, 309, 30], "temperature": 0.0, "avg_logprob": -0.1857731221085888, "compression_ratio": 1.6414342629482073, "no_speech_prob": 1.406391675118357e-05}, {"id": 787, "seek": 302540, "start": 3051.4, "end": 3054.4, "text": " And you can click to those and choose your own adventure from there,", "tokens": [400, 291, 393, 2052, 281, 729, 293, 2826, 428, 1065, 9868, 490, 456, 11], "temperature": 0.0, "avg_logprob": -0.1857731221085888, "compression_ratio": 1.6414342629482073, "no_speech_prob": 1.406391675118357e-05}, {"id": 788, "seek": 305440, "start": 3054.4, "end": 3056.4, "text": " or you can continue reading about back-end tasks.", "tokens": [420, 291, 393, 2354, 3760, 466, 646, 12, 521, 9608, 13], "temperature": 0.0, "avg_logprob": -0.1816474345692417, "compression_ratio": 1.6691449814126393, "no_speech_prob": 6.048854174878215e-06}, {"id": 789, "seek": 305440, "start": 3056.4, "end": 3060.4, "text": " So I think the way you group these and organize them is really key.", "tokens": [407, 286, 519, 264, 636, 291, 1594, 613, 293, 13859, 552, 307, 534, 2141, 13], "temperature": 0.0, "avg_logprob": -0.1816474345692417, "compression_ratio": 1.6691449814126393, "no_speech_prob": 6.048854174878215e-06}, {"id": 790, "seek": 305440, "start": 3060.4, "end": 3065.4, "text": " And again, it's like one module is one page in your documentation.", "tokens": [400, 797, 11, 309, 311, 411, 472, 10088, 307, 472, 3028, 294, 428, 14333, 13], "temperature": 0.0, "avg_logprob": -0.1816474345692417, "compression_ratio": 1.6691449814126393, "no_speech_prob": 6.048854174878215e-06}, {"id": 791, "seek": 305440, "start": 3065.4, "end": 3070.4, "text": " So the title of that module, the things that are grouped there, the scope of it,", "tokens": [407, 264, 4876, 295, 300, 10088, 11, 264, 721, 300, 366, 41877, 456, 11, 264, 11923, 295, 309, 11], "temperature": 0.0, "avg_logprob": -0.1816474345692417, "compression_ratio": 1.6691449814126393, "no_speech_prob": 6.048854174878215e-06}, {"id": 792, "seek": 305440, "start": 3070.4, "end": 3073.4, "text": " how many concepts go there are all really important considerations.", "tokens": [577, 867, 10392, 352, 456, 366, 439, 534, 1021, 24070, 13], "temperature": 0.0, "avg_logprob": -0.1816474345692417, "compression_ratio": 1.6691449814126393, "no_speech_prob": 6.048854174878215e-06}, {"id": 793, "seek": 305440, "start": 3073.4, "end": 3078.4, "text": " Yeah, and it's really hard for us to choose what goes into each.", "tokens": [865, 11, 293, 309, 311, 534, 1152, 337, 505, 281, 2826, 437, 1709, 666, 1184, 13], "temperature": 0.0, "avg_logprob": -0.1816474345692417, "compression_ratio": 1.6691449814126393, "no_speech_prob": 6.048854174878215e-06}, {"id": 794, "seek": 305440, "start": 3078.4, "end": 3082.4, "text": " Like, should I split this thing into more modules?", "tokens": [1743, 11, 820, 286, 7472, 341, 551, 666, 544, 16679, 30], "temperature": 0.0, "avg_logprob": -0.1816474345692417, "compression_ratio": 1.6691449814126393, "no_speech_prob": 6.048854174878215e-06}, {"id": 795, "seek": 308240, "start": 3082.4, "end": 3087.4, "text": " I know, for instance, like Elm UI has asked themselves the same question,", "tokens": [286, 458, 11, 337, 5197, 11, 411, 2699, 76, 15682, 575, 2351, 2969, 264, 912, 1168, 11], "temperature": 0.0, "avg_logprob": -0.2032778263092041, "compression_ratio": 1.6293103448275863, "no_speech_prob": 1.9033502667298308e-06}, {"id": 796, "seek": 308240, "start": 3087.4, "end": 3090.4, "text": " like, oh, I have all these borders.", "tokens": [411, 11, 1954, 11, 286, 362, 439, 613, 16287, 13], "temperature": 0.0, "avg_logprob": -0.2032778263092041, "compression_ratio": 1.6293103448275863, "no_speech_prob": 1.9033502667298308e-06}, {"id": 797, "seek": 308240, "start": 3090.4, "end": 3094.4, "text": " Should that be their own modules or module?", "tokens": [6454, 300, 312, 641, 1065, 16679, 420, 10088, 30], "temperature": 0.0, "avg_logprob": -0.2032778263092041, "compression_ratio": 1.6293103448275863, "no_speech_prob": 1.9033502667298308e-06}, {"id": 798, "seek": 308240, "start": 3094.4, "end": 3098.4, "text": " Or should it be in the same module as these other things?", "tokens": [1610, 820, 309, 312, 294, 264, 912, 10088, 382, 613, 661, 721, 30], "temperature": 0.0, "avg_logprob": -0.2032778263092041, "compression_ratio": 1.6293103448275863, "no_speech_prob": 1.9033502667298308e-06}, {"id": 799, "seek": 308240, "start": 3098.4, "end": 3104.4, "text": " And sometimes it's clear-cut, sometimes it's pretty hard, or it's arbitrary.", "tokens": [400, 2171, 309, 311, 1850, 12, 6672, 11, 2171, 309, 311, 1238, 1152, 11, 420, 309, 311, 23211, 13], "temperature": 0.0, "avg_logprob": -0.2032778263092041, "compression_ratio": 1.6293103448275863, "no_speech_prob": 1.9033502667298308e-06}, {"id": 800, "seek": 308240, "start": 3104.4, "end": 3110.4, "text": " It actually requires some surprisingly nuanced technical tricks in the Elm code sometimes", "tokens": [467, 767, 7029, 512, 17600, 45115, 6191, 11733, 294, 264, 2699, 76, 3089, 2171], "temperature": 0.0, "avg_logprob": -0.2032778263092041, "compression_ratio": 1.6293103448275863, "no_speech_prob": 1.9033502667298308e-06}, {"id": 801, "seek": 311040, "start": 3110.4, "end": 3115.4, "text": " to support that, like a common one being avoiding circular imports.", "tokens": [281, 1406, 300, 11, 411, 257, 2689, 472, 885, 20220, 16476, 41596, 13], "temperature": 0.0, "avg_logprob": -0.1986024877527258, "compression_ratio": 1.6160714285714286, "no_speech_prob": 1.505693262515706e-06}, {"id": 802, "seek": 311040, "start": 3115.4, "end": 3122.4, "text": " And so in Elm, the Elm compiler forbids things importing each other.", "tokens": [400, 370, 294, 2699, 76, 11, 264, 2699, 76, 31958, 16603, 3742, 721, 43866, 1184, 661, 13], "temperature": 0.0, "avg_logprob": -0.1986024877527258, "compression_ratio": 1.6160714285714286, "no_speech_prob": 1.505693262515706e-06}, {"id": 803, "seek": 311040, "start": 3122.4, "end": 3125.4, "text": " Modules can't import something that imports them.", "tokens": [6583, 3473, 393, 380, 974, 746, 300, 41596, 552, 13], "temperature": 0.0, "avg_logprob": -0.1986024877527258, "compression_ratio": 1.6160714285714286, "no_speech_prob": 1.505693262515706e-06}, {"id": 804, "seek": 311040, "start": 3125.4, "end": 3131.4, "text": " And therefore, you often need to use this trick of sort of having something scoped", "tokens": [400, 4412, 11, 291, 2049, 643, 281, 764, 341, 4282, 295, 1333, 295, 1419, 746, 795, 27277], "temperature": 0.0, "avg_logprob": -0.1986024877527258, "compression_ratio": 1.6160714285714286, "no_speech_prob": 1.505693262515706e-06}, {"id": 805, "seek": 311040, "start": 3131.4, "end": 3133.4, "text": " where it's exposed to the package.", "tokens": [689, 309, 311, 9495, 281, 264, 7372, 13], "temperature": 0.0, "avg_logprob": -0.1986024877527258, "compression_ratio": 1.6160714285714286, "no_speech_prob": 1.505693262515706e-06}, {"id": 806, "seek": 311040, "start": 3133.4, "end": 3136.4, "text": " What that means, we've talked about in previous episodes,", "tokens": [708, 300, 1355, 11, 321, 600, 2825, 466, 294, 3894, 9313, 11], "temperature": 0.0, "avg_logprob": -0.1986024877527258, "compression_ratio": 1.6160714285714286, "no_speech_prob": 1.505693262515706e-06}, {"id": 807, "seek": 313640, "start": 3136.4, "end": 3144.4, "text": " you have an Elm.json file, which for an Elm package gives you a key of exposed modules.", "tokens": [291, 362, 364, 2699, 76, 13, 73, 3015, 3991, 11, 597, 337, 364, 2699, 76, 7372, 2709, 291, 257, 2141, 295, 9495, 16679, 13], "temperature": 0.0, "avg_logprob": -0.16511275642796566, "compression_ratio": 1.7089201877934272, "no_speech_prob": 3.500846332826768e-06}, {"id": 808, "seek": 313640, "start": 3144.4, "end": 3148.4, "text": " And that's where you list out the modules that will be part of your public API.", "tokens": [400, 300, 311, 689, 291, 1329, 484, 264, 16679, 300, 486, 312, 644, 295, 428, 1908, 9362, 13], "temperature": 0.0, "avg_logprob": -0.16511275642796566, "compression_ratio": 1.7089201877934272, "no_speech_prob": 3.500846332826768e-06}, {"id": 809, "seek": 313640, "start": 3148.4, "end": 3154.4, "text": " But you can have some non-exposed modules, and those non-exposed modules", "tokens": [583, 291, 393, 362, 512, 2107, 12, 15952, 1744, 16679, 11, 293, 729, 2107, 12, 15952, 1744, 16679], "temperature": 0.0, "avg_logprob": -0.16511275642796566, "compression_ratio": 1.7089201877934272, "no_speech_prob": 3.500846332826768e-06}, {"id": 810, "seek": 313640, "start": 3154.4, "end": 3160.4, "text": " allow you to have types and functions which are visible to your whole package,", "tokens": [2089, 291, 281, 362, 3467, 293, 6828, 597, 366, 8974, 281, 428, 1379, 7372, 11], "temperature": 0.0, "avg_logprob": -0.16511275642796566, "compression_ratio": 1.7089201877934272, "no_speech_prob": 3.500846332826768e-06}, {"id": 811, "seek": 313640, "start": 3160.4, "end": 3163.4, "text": " but not visible through the exposed package.", "tokens": [457, 406, 8974, 807, 264, 9495, 7372, 13], "temperature": 0.0, "avg_logprob": -0.16511275642796566, "compression_ratio": 1.7089201877934272, "no_speech_prob": 3.500846332826768e-06}, {"id": 812, "seek": 316340, "start": 3163.4, "end": 3167.4, "text": " But you can expose them through type aliases, which is why you'll sometimes see", "tokens": [583, 291, 393, 19219, 552, 807, 2010, 10198, 1957, 11, 597, 307, 983, 291, 603, 2171, 536], "temperature": 0.0, "avg_logprob": -0.15399133797847864, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.76939522336761e-06}, {"id": 813, "seek": 316340, "start": 3167.4, "end": 3170.4, "text": " type alias element equals element.", "tokens": [2010, 419, 4609, 4478, 6915, 4478, 13], "temperature": 0.0, "avg_logprob": -0.15399133797847864, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.76939522336761e-06}, {"id": 814, "seek": 316340, "start": 3170.4, "end": 3172.4, "text": " What does that mean?", "tokens": [708, 775, 300, 914, 30], "temperature": 0.0, "avg_logprob": -0.15399133797847864, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.76939522336761e-06}, {"id": 815, "seek": 316340, "start": 3172.4, "end": 3175.4, "text": " Well, it's a package private one.", "tokens": [1042, 11, 309, 311, 257, 7372, 4551, 472, 13], "temperature": 0.0, "avg_logprob": -0.15399133797847864, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.76939522336761e-06}, {"id": 816, "seek": 316340, "start": 3175.4, "end": 3177.4, "text": " Yeah, it's a trick.", "tokens": [865, 11, 309, 311, 257, 4282, 13], "temperature": 0.0, "avg_logprob": -0.15399133797847864, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.76939522336761e-06}, {"id": 817, "seek": 316340, "start": 3177.4, "end": 3181.4, "text": " And so that means you have a lot of possibilities for where you can expose something.", "tokens": [400, 370, 300, 1355, 291, 362, 257, 688, 295, 12178, 337, 689, 291, 393, 19219, 746, 13], "temperature": 0.0, "avg_logprob": -0.15399133797847864, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.76939522336761e-06}, {"id": 818, "seek": 316340, "start": 3181.4, "end": 3184.4, "text": " Which module do you expose that type alias from?", "tokens": [3013, 10088, 360, 291, 19219, 300, 2010, 419, 4609, 490, 30], "temperature": 0.0, "avg_logprob": -0.15399133797847864, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.76939522336761e-06}, {"id": 819, "seek": 316340, "start": 3184.4, "end": 3186.4, "text": " It could be a lot of different ones.", "tokens": [467, 727, 312, 257, 688, 295, 819, 2306, 13], "temperature": 0.0, "avg_logprob": -0.15399133797847864, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.76939522336761e-06}, {"id": 820, "seek": 316340, "start": 3186.4, "end": 3188.4, "text": " But I think there is something really key.", "tokens": [583, 286, 519, 456, 307, 746, 534, 2141, 13], "temperature": 0.0, "avg_logprob": -0.15399133797847864, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.76939522336761e-06}, {"id": 821, "seek": 316340, "start": 3188.4, "end": 3192.4, "text": " Evan has talked about this in, I think, his talk, Growing Elm Modules.", "tokens": [22613, 575, 2825, 466, 341, 294, 11, 286, 519, 11, 702, 751, 11, 32569, 2699, 76, 6583, 3473, 13], "temperature": 0.0, "avg_logprob": -0.15399133797847864, "compression_ratio": 1.7025089605734767, "no_speech_prob": 2.76939522336761e-06}, {"id": 822, "seek": 319240, "start": 3192.4, "end": 3194.4, "text": " Wait, no, sorry.", "tokens": [3802, 11, 572, 11, 2597, 13], "temperature": 0.0, "avg_logprob": -0.17196126211257207, "compression_ratio": 1.5769230769230769, "no_speech_prob": 8.013472324819304e-06}, {"id": 823, "seek": 319240, "start": 3194.4, "end": 3196.4, "text": " Life of a File.", "tokens": [7720, 295, 257, 26196, 13], "temperature": 0.0, "avg_logprob": -0.17196126211257207, "compression_ratio": 1.5769230769230769, "no_speech_prob": 8.013472324819304e-06}, {"id": 824, "seek": 319240, "start": 3196.4, "end": 3202.4, "text": " Evan's talk, Life of a File, he talks about how there's something to how you", "tokens": [22613, 311, 751, 11, 7720, 295, 257, 26196, 11, 415, 6686, 466, 577, 456, 311, 746, 281, 577, 291], "temperature": 0.0, "avg_logprob": -0.17196126211257207, "compression_ratio": 1.5769230769230769, "no_speech_prob": 8.013472324819304e-06}, {"id": 825, "seek": 319240, "start": 3202.4, "end": 3206.4, "text": " grow and expand an Elm module that is centered around a type.", "tokens": [1852, 293, 5268, 364, 2699, 76, 10088, 300, 307, 18988, 926, 257, 2010, 13], "temperature": 0.0, "avg_logprob": -0.17196126211257207, "compression_ratio": 1.5769230769230769, "no_speech_prob": 8.013472324819304e-06}, {"id": 826, "seek": 319240, "start": 3206.4, "end": 3208.4, "text": " And I think that's really true.", "tokens": [400, 286, 519, 300, 311, 534, 2074, 13], "temperature": 0.0, "avg_logprob": -0.17196126211257207, "compression_ratio": 1.5769230769230769, "no_speech_prob": 8.013472324819304e-06}, {"id": 827, "seek": 319240, "start": 3208.4, "end": 3215.4, "text": " It should be usually one central type and some key things on how to use that thing.", "tokens": [467, 820, 312, 2673, 472, 5777, 2010, 293, 512, 2141, 721, 322, 577, 281, 764, 300, 551, 13], "temperature": 0.0, "avg_logprob": -0.17196126211257207, "compression_ratio": 1.5769230769230769, "no_speech_prob": 8.013472324819304e-06}, {"id": 828, "seek": 321540, "start": 3215.4, "end": 3223.4, "text": " I mean, something like a data structure would be a queue structure or a stack or something like that", "tokens": [286, 914, 11, 746, 411, 257, 1412, 3877, 576, 312, 257, 18639, 3877, 420, 257, 8630, 420, 746, 411, 300], "temperature": 0.0, "avg_logprob": -0.21611172358194988, "compression_ratio": 1.804255319148936, "no_speech_prob": 3.1875301829131786e-06}, {"id": 829, "seek": 321540, "start": 3223.4, "end": 3226.4, "text": " would be an obvious example of that.", "tokens": [576, 312, 364, 6322, 1365, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.21611172358194988, "compression_ratio": 1.804255319148936, "no_speech_prob": 3.1875301829131786e-06}, {"id": 830, "seek": 321540, "start": 3226.4, "end": 3228.4, "text": " But also back-end tasks.", "tokens": [583, 611, 646, 12, 521, 9608, 13], "temperature": 0.0, "avg_logprob": -0.21611172358194988, "compression_ratio": 1.804255319148936, "no_speech_prob": 3.1875301829131786e-06}, {"id": 831, "seek": 321540, "start": 3228.4, "end": 3233.4, "text": " But back-end tasks, again, it's subtle because there are other ways to consume a back-end task,", "tokens": [583, 646, 12, 521, 9608, 11, 797, 11, 309, 311, 13743, 570, 456, 366, 661, 2098, 281, 14732, 257, 646, 12, 521, 5633, 11], "temperature": 0.0, "avg_logprob": -0.21611172358194988, "compression_ratio": 1.804255319148936, "no_speech_prob": 3.1875301829131786e-06}, {"id": 832, "seek": 321540, "start": 3233.4, "end": 3236.4, "text": " like back-end-tasks.custom.", "tokens": [411, 646, 12, 521, 12, 83, 296, 1694, 13, 66, 2239, 13], "temperature": 0.0, "avg_logprob": -0.21611172358194988, "compression_ratio": 1.804255319148936, "no_speech_prob": 3.1875301829131786e-06}, {"id": 833, "seek": 321540, "start": 3236.4, "end": 3241.4, "text": " So that's a module associated with that same back-end-task type, but it's some helpers", "tokens": [407, 300, 311, 257, 10088, 6615, 365, 300, 912, 646, 12, 521, 12, 83, 3863, 2010, 11, 457, 309, 311, 512, 854, 433], "temperature": 0.0, "avg_logprob": -0.21611172358194988, "compression_ratio": 1.804255319148936, "no_speech_prob": 3.1875301829131786e-06}, {"id": 834, "seek": 321540, "start": 3241.4, "end": 3244.4, "text": " that actually aren't built around a specific type.", "tokens": [300, 767, 3212, 380, 3094, 926, 257, 2685, 2010, 13], "temperature": 0.0, "avg_logprob": -0.21611172358194988, "compression_ratio": 1.804255319148936, "no_speech_prob": 3.1875301829131786e-06}, {"id": 835, "seek": 324440, "start": 3244.4, "end": 3247.4, "text": " So it's not always clear-cut.", "tokens": [407, 309, 311, 406, 1009, 1850, 12, 6672, 13], "temperature": 0.0, "avg_logprob": -0.20610062472791557, "compression_ratio": 1.4871794871794872, "no_speech_prob": 9.080093150259927e-06}, {"id": 836, "seek": 324440, "start": 3247.4, "end": 3253.4, "text": " While we're on the topic of things that are too basic to mention, but let's mention them anyway,", "tokens": [3987, 321, 434, 322, 264, 4829, 295, 721, 300, 366, 886, 3875, 281, 2152, 11, 457, 718, 311, 2152, 552, 4033, 11], "temperature": 0.0, "avg_logprob": -0.20610062472791557, "compression_ratio": 1.4871794871794872, "no_speech_prob": 9.080093150259927e-06}, {"id": 837, "seek": 324440, "start": 3253.4, "end": 3261.4, "text": " one reason why Elm docs are great is because they're simple, or because Elm code is simple.", "tokens": [472, 1778, 983, 2699, 76, 45623, 366, 869, 307, 570, 436, 434, 2199, 11, 420, 570, 2699, 76, 3089, 307, 2199, 13], "temperature": 0.0, "avg_logprob": -0.20610062472791557, "compression_ratio": 1.4871794871794872, "no_speech_prob": 9.080093150259927e-06}, {"id": 838, "seek": 324440, "start": 3261.4, "end": 3269.4, "text": " Like, I'm not going to praise it even more than I usually do, but do I?", "tokens": [1743, 11, 286, 478, 406, 516, 281, 13286, 309, 754, 544, 813, 286, 2673, 360, 11, 457, 360, 286, 30], "temperature": 0.0, "avg_logprob": -0.20610062472791557, "compression_ratio": 1.4871794871794872, "no_speech_prob": 9.080093150259927e-06}, {"id": 839, "seek": 326940, "start": 3269.4, "end": 3276.4, "text": " But the thing is, whenever you have simple code, like a function that adds to numbers,", "tokens": [583, 264, 551, 307, 11, 5699, 291, 362, 2199, 3089, 11, 411, 257, 2445, 300, 10860, 281, 3547, 11], "temperature": 0.0, "avg_logprob": -0.21930085528980603, "compression_ratio": 1.6210526315789473, "no_speech_prob": 1.3925118764746003e-06}, {"id": 840, "seek": 326940, "start": 3276.4, "end": 3283.4, "text": " well, you have the function, you have a code sample, so if you say add 5, 7,", "tokens": [731, 11, 291, 362, 264, 2445, 11, 291, 362, 257, 3089, 6889, 11, 370, 498, 291, 584, 909, 1025, 11, 1614, 11], "temperature": 0.0, "avg_logprob": -0.21930085528980603, "compression_ratio": 1.6210526315789473, "no_speech_prob": 1.3925118764746003e-06}, {"id": 841, "seek": 326940, "start": 3283.4, "end": 3287.4, "text": " you can show that it does 12, returns 12.", "tokens": [291, 393, 855, 300, 309, 775, 2272, 11, 11247, 2272, 13], "temperature": 0.0, "avg_logprob": -0.21930085528980603, "compression_ratio": 1.6210526315789473, "no_speech_prob": 1.3925118764746003e-06}, {"id": 842, "seek": 326940, "start": 3287.4, "end": 3292.4, "text": " And that's it. There are no side effects, there are no mutations.", "tokens": [400, 300, 311, 309, 13, 821, 366, 572, 1252, 5065, 11, 456, 366, 572, 29243, 13], "temperature": 0.0, "avg_logprob": -0.21930085528980603, "compression_ratio": 1.6210526315789473, "no_speech_prob": 1.3925118764746003e-06}, {"id": 843, "seek": 326940, "start": 3292.4, "end": 3296.4, "text": " This is all that your function does.", "tokens": [639, 307, 439, 300, 428, 2445, 775, 13], "temperature": 0.0, "avg_logprob": -0.21930085528980603, "compression_ratio": 1.6210526315789473, "no_speech_prob": 1.3925118764746003e-06}, {"id": 844, "seek": 329640, "start": 3296.4, "end": 3301.4, "text": " So it's really easy to understand, whereas in languages like JavaScript,", "tokens": [407, 309, 311, 534, 1858, 281, 1223, 11, 9735, 294, 8650, 411, 15778, 11], "temperature": 0.0, "avg_logprob": -0.20126122813070974, "compression_ratio": 1.4444444444444444, "no_speech_prob": 1.6959922504611313e-05}, {"id": 845, "seek": 329640, "start": 3301.4, "end": 3311.4, "text": " if you look for the documentation for arrays, the list-like type, not the erasing something,", "tokens": [498, 291, 574, 337, 264, 14333, 337, 41011, 11, 264, 1329, 12, 4092, 2010, 11, 406, 264, 1189, 3349, 746, 11], "temperature": 0.0, "avg_logprob": -0.20126122813070974, "compression_ratio": 1.4444444444444444, "no_speech_prob": 1.6959922504611313e-05}, {"id": 846, "seek": 329640, "start": 3311.4, "end": 3319.4, "text": " so if you do.sort on an array, it's going to mutate it.", "tokens": [370, 498, 291, 360, 2411, 82, 477, 322, 364, 10225, 11, 309, 311, 516, 281, 5839, 473, 309, 13], "temperature": 0.0, "avg_logprob": -0.20126122813070974, "compression_ratio": 1.4444444444444444, "no_speech_prob": 1.6959922504611313e-05}, {"id": 847, "seek": 331940, "start": 3319.4, "end": 3327.4, "text": " And that's something that can be hard to convey without mentioning it explicitly,", "tokens": [400, 300, 311, 746, 300, 393, 312, 1152, 281, 16965, 1553, 18315, 309, 20803, 11], "temperature": 0.0, "avg_logprob": -0.17223662679845636, "compression_ratio": 1.7004830917874396, "no_speech_prob": 1.7326738088740967e-06}, {"id": 848, "seek": 331940, "start": 3327.4, "end": 3330.4, "text": " and that can be surprising as well.", "tokens": [293, 300, 393, 312, 8830, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.17223662679845636, "compression_ratio": 1.7004830917874396, "no_speech_prob": 1.7326738088740967e-06}, {"id": 849, "seek": 331940, "start": 3330.4, "end": 3334.4, "text": " But you don't have those things in Elm, so things are pretty simple.", "tokens": [583, 291, 500, 380, 362, 729, 721, 294, 2699, 76, 11, 370, 721, 366, 1238, 2199, 13], "temperature": 0.0, "avg_logprob": -0.17223662679845636, "compression_ratio": 1.7004830917874396, "no_speech_prob": 1.7326738088740967e-06}, {"id": 850, "seek": 331940, "start": 3334.4, "end": 3342.4, "text": " And also, every function shows the type annotation, and that's very valuable as well,", "tokens": [400, 611, 11, 633, 2445, 3110, 264, 2010, 48654, 11, 293, 300, 311, 588, 8263, 382, 731, 11], "temperature": 0.0, "avg_logprob": -0.17223662679845636, "compression_ratio": 1.7004830917874396, "no_speech_prob": 1.7326738088740967e-06}, {"id": 851, "seek": 331940, "start": 3342.4, "end": 3348.4, "text": " because a type annotation gives a lot of information, and if you don't have it,", "tokens": [570, 257, 2010, 48654, 2709, 257, 688, 295, 1589, 11, 293, 498, 291, 500, 380, 362, 309, 11], "temperature": 0.0, "avg_logprob": -0.17223662679845636, "compression_ratio": 1.7004830917874396, "no_speech_prob": 1.7326738088740967e-06}, {"id": 852, "seek": 334840, "start": 3348.4, "end": 3354.4, "text": " which is, again, the case in JavaScript, often less so with TypeScript nowadays,", "tokens": [597, 307, 11, 797, 11, 264, 1389, 294, 15778, 11, 2049, 1570, 370, 365, 15576, 14237, 13434, 11], "temperature": 0.0, "avg_logprob": -0.18518226043037747, "compression_ratio": 1.497816593886463, "no_speech_prob": 6.854068942629965e-06}, {"id": 853, "seek": 334840, "start": 3354.4, "end": 3360.4, "text": " well, yeah, you have a lot more information that you can use to understand what it does.", "tokens": [731, 11, 1338, 11, 291, 362, 257, 688, 544, 1589, 300, 291, 393, 764, 281, 1223, 437, 309, 775, 13], "temperature": 0.0, "avg_logprob": -0.18518226043037747, "compression_ratio": 1.497816593886463, "no_speech_prob": 6.854068942629965e-06}, {"id": 854, "seek": 334840, "start": 3360.4, "end": 3366.4, "text": " So Elm is simple, and that has great benefits, basically.", "tokens": [407, 2699, 76, 307, 2199, 11, 293, 300, 575, 869, 5311, 11, 1936, 13], "temperature": 0.0, "avg_logprob": -0.18518226043037747, "compression_ratio": 1.497816593886463, "no_speech_prob": 6.854068942629965e-06}, {"id": 855, "seek": 334840, "start": 3366.4, "end": 3371.4, "text": " Yeah, like if you're working with a different language, JavaScript, Ruby,", "tokens": [865, 11, 411, 498, 291, 434, 1364, 365, 257, 819, 2856, 11, 15778, 11, 19907, 11], "temperature": 0.0, "avg_logprob": -0.18518226043037747, "compression_ratio": 1.497816593886463, "no_speech_prob": 6.854068942629965e-06}, {"id": 856, "seek": 334840, "start": 3371.4, "end": 3375.4, "text": " it's very common, like, is this nullable?", "tokens": [309, 311, 588, 2689, 11, 411, 11, 307, 341, 18184, 712, 30], "temperature": 0.0, "avg_logprob": -0.18518226043037747, "compression_ratio": 1.497816593886463, "no_speech_prob": 6.854068942629965e-06}, {"id": 857, "seek": 337540, "start": 3375.4, "end": 3379.4, "text": " Which, of course, TypeScript somewhat helps with, but only somewhat.", "tokens": [3013, 11, 295, 1164, 11, 15576, 14237, 8344, 3665, 365, 11, 457, 787, 8344, 13], "temperature": 0.0, "avg_logprob": -0.17931068644804113, "compression_ratio": 1.7553648068669527, "no_speech_prob": 5.5075870477594435e-06}, {"id": 858, "seek": 337540, "start": 3379.4, "end": 3381.4, "text": " How many arguments does this take?", "tokens": [1012, 867, 12869, 775, 341, 747, 30], "temperature": 0.0, "avg_logprob": -0.17931068644804113, "compression_ratio": 1.7553648068669527, "no_speech_prob": 5.5075870477594435e-06}, {"id": 859, "seek": 337540, "start": 3381.4, "end": 3385.4, "text": " If I pass in zero arguments, one argument, two arguments,", "tokens": [759, 286, 1320, 294, 4018, 12869, 11, 472, 6770, 11, 732, 12869, 11], "temperature": 0.0, "avg_logprob": -0.17931068644804113, "compression_ratio": 1.7553648068669527, "no_speech_prob": 5.5075870477594435e-06}, {"id": 860, "seek": 337540, "start": 3385.4, "end": 3391.4, "text": " are there different variadic forms of this, different arities for this function?", "tokens": [366, 456, 819, 3034, 43341, 6422, 295, 341, 11, 819, 594, 1088, 337, 341, 2445, 30], "temperature": 0.0, "avg_logprob": -0.17931068644804113, "compression_ratio": 1.7553648068669527, "no_speech_prob": 5.5075870477594435e-06}, {"id": 861, "seek": 337540, "start": 3391.4, "end": 3395.4, "text": " Is it going to return different types based on the input I give it?", "tokens": [1119, 309, 516, 281, 2736, 819, 3467, 2361, 322, 264, 4846, 286, 976, 309, 30], "temperature": 0.0, "avg_logprob": -0.17931068644804113, "compression_ratio": 1.7553648068669527, "no_speech_prob": 5.5075870477594435e-06}, {"id": 862, "seek": 337540, "start": 3395.4, "end": 3401.4, "text": " Is it going to mutate the input I give it or change some global thing or perform some side effect?", "tokens": [1119, 309, 516, 281, 5839, 473, 264, 4846, 286, 976, 309, 420, 1319, 512, 4338, 551, 420, 2042, 512, 1252, 1802, 30], "temperature": 0.0, "avg_logprob": -0.17931068644804113, "compression_ratio": 1.7553648068669527, "no_speech_prob": 5.5075870477594435e-06}, {"id": 863, "seek": 340140, "start": 3401.4, "end": 3406.4, "text": " Is it going to do one thing if I pass in an object, and another thing if I pass in a string,", "tokens": [1119, 309, 516, 281, 360, 472, 551, 498, 286, 1320, 294, 364, 2657, 11, 293, 1071, 551, 498, 286, 1320, 294, 257, 6798, 11], "temperature": 0.0, "avg_logprob": -0.1847016119187878, "compression_ratio": 1.9414414414414414, "no_speech_prob": 3.288740799689549e-06}, {"id": 864, "seek": 340140, "start": 3406.4, "end": 3410.4, "text": " and another thing if I pass in a buffer, and another thing if I pass in a promise?", "tokens": [293, 1071, 551, 498, 286, 1320, 294, 257, 21762, 11, 293, 1071, 551, 498, 286, 1320, 294, 257, 6228, 30], "temperature": 0.0, "avg_logprob": -0.1847016119187878, "compression_ratio": 1.9414414414414414, "no_speech_prob": 3.288740799689549e-06}, {"id": 865, "seek": 340140, "start": 3410.4, "end": 3414.4, "text": " Does it return a promise or a non-promise?", "tokens": [4402, 309, 2736, 257, 6228, 420, 257, 2107, 12, 28722, 908, 30], "temperature": 0.0, "avg_logprob": -0.1847016119187878, "compression_ratio": 1.9414414414414414, "no_speech_prob": 3.288740799689549e-06}, {"id": 866, "seek": 340140, "start": 3414.4, "end": 3418.4, "text": " Is there going to be any effect if I just import this file?", "tokens": [1119, 456, 516, 281, 312, 604, 1802, 498, 286, 445, 974, 341, 3991, 30], "temperature": 0.0, "avg_logprob": -0.1847016119187878, "compression_ratio": 1.9414414414414414, "no_speech_prob": 3.288740799689549e-06}, {"id": 867, "seek": 340140, "start": 3418.4, "end": 3421.4, "text": " Right. Can it throw an exception?", "tokens": [1779, 13, 1664, 309, 3507, 364, 11183, 30], "temperature": 0.0, "avg_logprob": -0.1847016119187878, "compression_ratio": 1.9414414414414414, "no_speech_prob": 3.288740799689549e-06}, {"id": 868, "seek": 340140, "start": 3421.4, "end": 3425.4, "text": " Yeah, what are the possible crashes that this can have?", "tokens": [865, 11, 437, 366, 264, 1944, 28642, 300, 341, 393, 362, 30], "temperature": 0.0, "avg_logprob": -0.1847016119187878, "compression_ratio": 1.9414414414414414, "no_speech_prob": 3.288740799689549e-06}, {"id": 869, "seek": 340140, "start": 3425.4, "end": 3430.4, "text": " Right. All of these things, they are just non-existent in Elm,", "tokens": [1779, 13, 1057, 295, 613, 721, 11, 436, 366, 445, 2107, 12, 18217, 317, 294, 2699, 76, 11], "temperature": 0.0, "avg_logprob": -0.1847016119187878, "compression_ratio": 1.9414414414414414, "no_speech_prob": 3.288740799689549e-06}, {"id": 870, "seek": 343040, "start": 3430.4, "end": 3432.4, "text": " so I couldn't agree more.", "tokens": [370, 286, 2809, 380, 3986, 544, 13], "temperature": 0.0, "avg_logprob": -0.28287814060846966, "compression_ratio": 1.4625, "no_speech_prob": 1.1842687854368705e-05}, {"id": 871, "seek": 343040, "start": 3432.4, "end": 3438.4, "text": " The explicitness already, your confidence in navigating an API is so much higher", "tokens": [440, 28021, 6394, 1217, 11, 428, 6687, 294, 32054, 364, 9362, 307, 370, 709, 2946], "temperature": 0.0, "avg_logprob": -0.28287814060846966, "compression_ratio": 1.4625, "no_speech_prob": 1.1842687854368705e-05}, {"id": 872, "seek": 343040, "start": 3438.4, "end": 3443.4, "text": " from just the bare minimum documentation in an Elm package.", "tokens": [490, 445, 264, 6949, 7285, 14333, 294, 364, 2699, 76, 7372, 13], "temperature": 0.0, "avg_logprob": -0.28287814060846966, "compression_ratio": 1.4625, "no_speech_prob": 1.1842687854368705e-05}, {"id": 873, "seek": 343040, "start": 3443.4, "end": 3448.4, "text": " Also, I mentioned, if you have a code example, like add 5, 7,", "tokens": [2743, 11, 286, 2835, 11, 498, 291, 362, 257, 3089, 1365, 11, 411, 909, 1025, 11, 1614, 11], "temperature": 0.0, "avg_logprob": -0.28287814060846966, "compression_ratio": 1.4625, "no_speech_prob": 1.1842687854368705e-05}, {"id": 874, "seek": 343040, "start": 3448.4, "end": 3454.4, "text": " and you add a line underneath that says, this returns 7,", "tokens": [293, 291, 909, 257, 1622, 7223, 300, 1619, 11, 341, 11247, 1614, 11], "temperature": 0.0, "avg_logprob": -0.28287814060846966, "compression_ratio": 1.4625, "no_speech_prob": 1.1842687854368705e-05}, {"id": 875, "seek": 343040, "start": 3454.4, "end": 3459.4, "text": " there's a... often what you will see is dash, dash, greater than.", "tokens": [456, 311, 257, 485, 2049, 437, 291, 486, 536, 307, 8240, 11, 8240, 11, 5044, 813, 13], "temperature": 0.0, "avg_logprob": -0.28287814060846966, "compression_ratio": 1.4625, "no_speech_prob": 1.1842687854368705e-05}, {"id": 876, "seek": 345940, "start": 3459.4, "end": 3462.4, "text": " So it basically does an arrow, and then 7.", "tokens": [407, 309, 1936, 775, 364, 11610, 11, 293, 550, 1614, 13], "temperature": 0.0, "avg_logprob": -0.1790657639503479, "compression_ratio": 1.5868544600938967, "no_speech_prob": 2.546094765421003e-05}, {"id": 877, "seek": 345940, "start": 3462.4, "end": 3466.4, "text": " And there's a tool, which is called Elm Verify Examples,", "tokens": [400, 456, 311, 257, 2290, 11, 597, 307, 1219, 2699, 76, 4281, 2505, 48591, 11], "temperature": 0.0, "avg_logprob": -0.1790657639503479, "compression_ratio": 1.5868544600938967, "no_speech_prob": 2.546094765421003e-05}, {"id": 878, "seek": 345940, "start": 3466.4, "end": 3473.4, "text": " that will turn those code examples into actual tests.", "tokens": [300, 486, 1261, 729, 3089, 5110, 666, 3539, 6921, 13], "temperature": 0.0, "avg_logprob": -0.1790657639503479, "compression_ratio": 1.5868544600938967, "no_speech_prob": 2.546094765421003e-05}, {"id": 879, "seek": 345940, "start": 3473.4, "end": 3478.4, "text": " So you can be sure that your code sample is correct,", "tokens": [407, 291, 393, 312, 988, 300, 428, 3089, 6889, 307, 3006, 11], "temperature": 0.0, "avg_logprob": -0.1790657639503479, "compression_ratio": 1.5868544600938967, "no_speech_prob": 2.546094765421003e-05}, {"id": 880, "seek": 345940, "start": 3478.4, "end": 3482.4, "text": " that it returns what you said it did.", "tokens": [300, 309, 11247, 437, 291, 848, 309, 630, 13], "temperature": 0.0, "avg_logprob": -0.1790657639503479, "compression_ratio": 1.5868544600938967, "no_speech_prob": 2.546094765421003e-05}, {"id": 881, "seek": 345940, "start": 3482.4, "end": 3484.4, "text": " So that's pretty powerful as well.", "tokens": [407, 300, 311, 1238, 4005, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1790657639503479, "compression_ratio": 1.5868544600938967, "no_speech_prob": 2.546094765421003e-05}, {"id": 882, "seek": 345940, "start": 3484.4, "end": 3488.4, "text": " I really wish I could use this for Elm review in some way.", "tokens": [286, 534, 3172, 286, 727, 764, 341, 337, 2699, 76, 3131, 294, 512, 636, 13], "temperature": 0.0, "avg_logprob": -0.1790657639503479, "compression_ratio": 1.5868544600938967, "no_speech_prob": 2.546094765421003e-05}, {"id": 883, "seek": 348840, "start": 3488.4, "end": 3493.4, "text": " I know. I wish that it could verify that things compile,", "tokens": [286, 458, 13, 286, 3172, 300, 309, 727, 16888, 300, 721, 31413, 11], "temperature": 0.0, "avg_logprob": -0.16774195248318702, "compression_ratio": 1.565217391304348, "no_speech_prob": 1.834129034250509e-05}, {"id": 884, "seek": 348840, "start": 3493.4, "end": 3496.4, "text": " but unfortunately it doesn't at the moment.", "tokens": [457, 7015, 309, 1177, 380, 412, 264, 1623, 13], "temperature": 0.0, "avg_logprob": -0.16774195248318702, "compression_ratio": 1.565217391304348, "no_speech_prob": 1.834129034250509e-05}, {"id": 885, "seek": 348840, "start": 3496.4, "end": 3499.4, "text": " But it is a very valuable tool.", "tokens": [583, 309, 307, 257, 588, 8263, 2290, 13], "temperature": 0.0, "avg_logprob": -0.16774195248318702, "compression_ratio": 1.565217391304348, "no_speech_prob": 1.834129034250509e-05}, {"id": 886, "seek": 348840, "start": 3499.4, "end": 3505.4, "text": " Also, on the topic of code snippets, I think that's also huge.", "tokens": [2743, 11, 322, 264, 4829, 295, 3089, 35623, 1385, 11, 286, 519, 300, 311, 611, 2603, 13], "temperature": 0.0, "avg_logprob": -0.16774195248318702, "compression_ratio": 1.565217391304348, "no_speech_prob": 1.834129034250509e-05}, {"id": 887, "seek": 348840, "start": 3505.4, "end": 3509.4, "text": " Just having code snippets, example, output,", "tokens": [1449, 1419, 3089, 35623, 1385, 11, 1365, 11, 5598, 11], "temperature": 0.0, "avg_logprob": -0.16774195248318702, "compression_ratio": 1.565217391304348, "no_speech_prob": 1.834129034250509e-05}, {"id": 888, "seek": 348840, "start": 3509.4, "end": 3513.4, "text": " like when you're navigating functions in an API,", "tokens": [411, 562, 291, 434, 32054, 6828, 294, 364, 9362, 11], "temperature": 0.0, "avg_logprob": -0.16774195248318702, "compression_ratio": 1.565217391304348, "no_speech_prob": 1.834129034250509e-05}, {"id": 889, "seek": 348840, "start": 3513.4, "end": 3517.4, "text": " again, you want to equip the user with what is the relevant information", "tokens": [797, 11, 291, 528, 281, 5037, 264, 4195, 365, 437, 307, 264, 7340, 1589], "temperature": 0.0, "avg_logprob": -0.16774195248318702, "compression_ratio": 1.565217391304348, "no_speech_prob": 1.834129034250509e-05}, {"id": 890, "seek": 351740, "start": 3517.4, "end": 3518.4, "text": " they're going to need.", "tokens": [436, 434, 516, 281, 643, 13], "temperature": 0.0, "avg_logprob": -0.17366821535172, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.5070970878005028e-05}, {"id": 891, "seek": 351740, "start": 3518.4, "end": 3522.4, "text": " And really, even if it seems obvious from the type signature,", "tokens": [400, 534, 11, 754, 498, 309, 2544, 6322, 490, 264, 2010, 13397, 11], "temperature": 0.0, "avg_logprob": -0.17366821535172, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.5070970878005028e-05}, {"id": 892, "seek": 351740, "start": 3522.4, "end": 3525.4, "text": " having an example is very useful.", "tokens": [1419, 364, 1365, 307, 588, 4420, 13], "temperature": 0.0, "avg_logprob": -0.17366821535172, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.5070970878005028e-05}, {"id": 893, "seek": 351740, "start": 3525.4, "end": 3529.4, "text": " It demystifies it, and it makes it feel real.", "tokens": [467, 1371, 38593, 11221, 309, 11, 293, 309, 1669, 309, 841, 957, 13], "temperature": 0.0, "avg_logprob": -0.17366821535172, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.5070970878005028e-05}, {"id": 894, "seek": 351740, "start": 3529.4, "end": 3534.4, "text": " And it's also an opportunity to give an example use case.", "tokens": [400, 309, 311, 611, 364, 2650, 281, 976, 364, 1365, 764, 1389, 13], "temperature": 0.0, "avg_logprob": -0.17366821535172, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.5070970878005028e-05}, {"id": 895, "seek": 351740, "start": 3534.4, "end": 3539.4, "text": " So I think, in my opinion, I feel very strongly that every example", "tokens": [407, 286, 519, 11, 294, 452, 4800, 11, 286, 841, 588, 10613, 300, 633, 1365], "temperature": 0.0, "avg_logprob": -0.17366821535172, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.5070970878005028e-05}, {"id": 896, "seek": 351740, "start": 3539.4, "end": 3542.4, "text": " is an opportunity to demonstrate a meaningful use case,", "tokens": [307, 364, 2650, 281, 11698, 257, 10995, 764, 1389, 11], "temperature": 0.0, "avg_logprob": -0.17366821535172, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.5070970878005028e-05}, {"id": 897, "seek": 354240, "start": 3542.4, "end": 3548.4, "text": " which is why I try really hard to avoid toy examples,", "tokens": [597, 307, 983, 286, 853, 534, 1152, 281, 5042, 12058, 5110, 11], "temperature": 0.0, "avg_logprob": -0.18167433371910682, "compression_ratio": 1.6141732283464567, "no_speech_prob": 5.2553600653482135e-06}, {"id": 898, "seek": 354240, "start": 3548.4, "end": 3551.4, "text": " foobar baz, and instead try to illustrate,", "tokens": [726, 996, 289, 27147, 11, 293, 2602, 853, 281, 23221, 11], "temperature": 0.0, "avg_logprob": -0.18167433371910682, "compression_ratio": 1.6141732283464567, "no_speech_prob": 5.2553600653482135e-06}, {"id": 899, "seek": 354240, "start": 3551.4, "end": 3556.4, "text": " why would I use this feature with real-world use cases?", "tokens": [983, 576, 286, 764, 341, 4111, 365, 957, 12, 13217, 764, 3331, 30], "temperature": 0.0, "avg_logprob": -0.18167433371910682, "compression_ratio": 1.6141732283464567, "no_speech_prob": 5.2553600653482135e-06}, {"id": 900, "seek": 354240, "start": 3556.4, "end": 3560.4, "text": " Because now you're using that opportunity to convey information", "tokens": [1436, 586, 291, 434, 1228, 300, 2650, 281, 16965, 1589], "temperature": 0.0, "avg_logprob": -0.18167433371910682, "compression_ratio": 1.6141732283464567, "no_speech_prob": 5.2553600653482135e-06}, {"id": 901, "seek": 354240, "start": 3560.4, "end": 3561.4, "text": " in a richer way.", "tokens": [294, 257, 29021, 636, 13], "temperature": 0.0, "avg_logprob": -0.18167433371910682, "compression_ratio": 1.6141732283464567, "no_speech_prob": 5.2553600653482135e-06}, {"id": 902, "seek": 354240, "start": 3561.4, "end": 3564.4, "text": " People are taking the same amount of time to read through something,", "tokens": [3432, 366, 1940, 264, 912, 2372, 295, 565, 281, 1401, 807, 746, 11], "temperature": 0.0, "avg_logprob": -0.18167433371910682, "compression_ratio": 1.6141732283464567, "no_speech_prob": 5.2553600653482135e-06}, {"id": 903, "seek": 354240, "start": 3564.4, "end": 3568.4, "text": " but you've now conveyed the kinds of things this tool would be helpful for", "tokens": [457, 291, 600, 586, 49340, 264, 3685, 295, 721, 341, 2290, 576, 312, 4961, 337], "temperature": 0.0, "avg_logprob": -0.18167433371910682, "compression_ratio": 1.6141732283464567, "no_speech_prob": 5.2553600653482135e-06}, {"id": 904, "seek": 354240, "start": 3568.4, "end": 3570.4, "text": " and best practices for using it.", "tokens": [293, 1151, 7525, 337, 1228, 309, 13], "temperature": 0.0, "avg_logprob": -0.18167433371910682, "compression_ratio": 1.6141732283464567, "no_speech_prob": 5.2553600653482135e-06}, {"id": 905, "seek": 357040, "start": 3570.4, "end": 3576.4, "text": " Yeah, this is something that I do purposefully in Elm Reviews documentation,", "tokens": [865, 11, 341, 307, 746, 300, 286, 360, 4334, 2277, 294, 2699, 76, 19954, 82, 14333, 11], "temperature": 0.0, "avg_logprob": -0.19445993814123683, "compression_ratio": 1.5454545454545454, "no_speech_prob": 5.594283720711246e-06}, {"id": 906, "seek": 357040, "start": 3576.4, "end": 3584.4, "text": " is for every function that you can use to define a visitor or something,", "tokens": [307, 337, 633, 2445, 300, 291, 393, 764, 281, 6964, 257, 28222, 420, 746, 11], "temperature": 0.0, "avg_logprob": -0.19445993814123683, "compression_ratio": 1.5454545454545454, "no_speech_prob": 5.594283720711246e-06}, {"id": 907, "seek": 357040, "start": 3584.4, "end": 3587.4, "text": " I add an example rule.", "tokens": [286, 909, 364, 1365, 4978, 13], "temperature": 0.0, "avg_logprob": -0.19445993814123683, "compression_ratio": 1.5454545454545454, "no_speech_prob": 5.594283720711246e-06}, {"id": 908, "seek": 357040, "start": 3587.4, "end": 3591.4, "text": " So that's a lot of code, potentially, but you can see,", "tokens": [407, 300, 311, 257, 688, 295, 3089, 11, 7263, 11, 457, 291, 393, 536, 11], "temperature": 0.0, "avg_logprob": -0.19445993814123683, "compression_ratio": 1.5454545454545454, "no_speech_prob": 5.594283720711246e-06}, {"id": 909, "seek": 357040, "start": 3591.4, "end": 3596.4, "text": " oh, I can use this for this, and also this is how you use it.", "tokens": [1954, 11, 286, 393, 764, 341, 337, 341, 11, 293, 611, 341, 307, 577, 291, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.19445993814123683, "compression_ratio": 1.5454545454545454, "no_speech_prob": 5.594283720711246e-06}, {"id": 910, "seek": 359640, "start": 3596.4, "end": 3600.4, "text": " But if you just go through the documentation, you can already", "tokens": [583, 498, 291, 445, 352, 807, 264, 14333, 11, 291, 393, 1217], "temperature": 0.0, "avg_logprob": -0.21877128909332583, "compression_ratio": 1.5661157024793388, "no_speech_prob": 4.092828021384776e-06}, {"id": 911, "seek": 359640, "start": 3600.4, "end": 3605.4, "text": " just copy-paste some rules and adapt them to your needs, potentially.", "tokens": [445, 5055, 12, 79, 9079, 512, 4474, 293, 6231, 552, 281, 428, 2203, 11, 7263, 13], "temperature": 0.0, "avg_logprob": -0.21877128909332583, "compression_ratio": 1.5661157024793388, "no_speech_prob": 4.092828021384776e-06}, {"id": 912, "seek": 359640, "start": 3605.4, "end": 3608.4, "text": " I find that to be pretty interesting.", "tokens": [286, 915, 300, 281, 312, 1238, 1880, 13], "temperature": 0.0, "avg_logprob": -0.21877128909332583, "compression_ratio": 1.5661157024793388, "no_speech_prob": 4.092828021384776e-06}, {"id": 913, "seek": 359640, "start": 3608.4, "end": 3612.4, "text": " Yeah, as an Elm Review user, I find that extremely valuable.", "tokens": [865, 11, 382, 364, 2699, 76, 19954, 4195, 11, 286, 915, 300, 4664, 8263, 13], "temperature": 0.0, "avg_logprob": -0.21877128909332583, "compression_ratio": 1.5661157024793388, "no_speech_prob": 4.092828021384776e-06}, {"id": 914, "seek": 359640, "start": 3612.4, "end": 3617.4, "text": " Also, just imagine looking at with simple declaration visitor,", "tokens": [2743, 11, 445, 3811, 1237, 412, 365, 2199, 27606, 28222, 11], "temperature": 0.0, "avg_logprob": -0.21877128909332583, "compression_ratio": 1.5661157024793388, "no_speech_prob": 4.092828021384776e-06}, {"id": 915, "seek": 359640, "start": 3617.4, "end": 3620.4, "text": " and you're seeing, okay, it takes a function,", "tokens": [293, 291, 434, 2577, 11, 1392, 11, 309, 2516, 257, 2445, 11], "temperature": 0.0, "avg_logprob": -0.21877128909332583, "compression_ratio": 1.5661157024793388, "no_speech_prob": 4.092828021384776e-06}, {"id": 916, "seek": 359640, "start": 3620.4, "end": 3624.4, "text": " no declaration, returns, list of error,", "tokens": [572, 27606, 11, 11247, 11, 1329, 295, 6713, 11], "temperature": 0.0, "avg_logprob": -0.21877128909332583, "compression_ratio": 1.5661157024793388, "no_speech_prob": 4.092828021384776e-06}, {"id": 917, "seek": 362440, "start": 3624.4, "end": 3629.4, "text": " and a module rule schema, and it returns a module rule schema", "tokens": [293, 257, 10088, 4978, 34078, 11, 293, 309, 11247, 257, 10088, 4978, 34078], "temperature": 0.0, "avg_logprob": -0.1965807584615854, "compression_ratio": 1.7031963470319635, "no_speech_prob": 5.594313734036405e-06}, {"id": 918, "seek": 362440, "start": 3629.4, "end": 3631.4, "text": " which has at least one visitor.", "tokens": [597, 575, 412, 1935, 472, 28222, 13], "temperature": 0.0, "avg_logprob": -0.1965807584615854, "compression_ratio": 1.7031963470319635, "no_speech_prob": 5.594313734036405e-06}, {"id": 919, "seek": 362440, "start": 3631.4, "end": 3636.4, "text": " That's okay. Yes, that's telling me some information that's useful,", "tokens": [663, 311, 1392, 13, 1079, 11, 300, 311, 3585, 385, 512, 1589, 300, 311, 4420, 11], "temperature": 0.0, "avg_logprob": -0.1965807584615854, "compression_ratio": 1.7031963470319635, "no_speech_prob": 5.594313734036405e-06}, {"id": 920, "seek": 362440, "start": 3636.4, "end": 3638.4, "text": " but without an example...", "tokens": [457, 1553, 364, 1365, 485], "temperature": 0.0, "avg_logprob": -0.1965807584615854, "compression_ratio": 1.7031963470319635, "no_speech_prob": 5.594313734036405e-06}, {"id": 921, "seek": 362440, "start": 3638.4, "end": 3640.4, "text": " Really hard to use, yeah.", "tokens": [4083, 1152, 281, 764, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.1965807584615854, "compression_ratio": 1.7031963470319635, "no_speech_prob": 5.594313734036405e-06}, {"id": 922, "seek": 362440, "start": 3640.4, "end": 3643.4, "text": " Yeah, like, okay, well, what do I do with node declaration?", "tokens": [865, 11, 411, 11, 1392, 11, 731, 11, 437, 360, 286, 360, 365, 9984, 27606, 30], "temperature": 0.0, "avg_logprob": -0.1965807584615854, "compression_ratio": 1.7031963470319635, "no_speech_prob": 5.594313734036405e-06}, {"id": 923, "seek": 362440, "start": 3643.4, "end": 3648.4, "text": " Well, actually, what you're most probably going to do", "tokens": [1042, 11, 767, 11, 437, 291, 434, 881, 1391, 516, 281, 360], "temperature": 0.0, "avg_logprob": -0.1965807584615854, "compression_ratio": 1.7031963470319635, "no_speech_prob": 5.594313734036405e-06}, {"id": 924, "seek": 362440, "start": 3648.4, "end": 3651.4, "text": " with a node declaration is you're going to do", "tokens": [365, 257, 9984, 27606, 307, 291, 434, 516, 281, 360], "temperature": 0.0, "avg_logprob": -0.1965807584615854, "compression_ratio": 1.7031963470319635, "no_speech_prob": 5.594313734036405e-06}, {"id": 925, "seek": 365140, "start": 3651.4, "end": 3656.4, "text": " case node.value node of, and then you're going to enumerate", "tokens": [1389, 9984, 13, 29155, 9984, 295, 11, 293, 550, 291, 434, 516, 281, 465, 15583, 473], "temperature": 0.0, "avg_logprob": -0.18912153709225538, "compression_ratio": 1.4832535885167464, "no_speech_prob": 3.1875533750280738e-06}, {"id": 926, "seek": 365140, "start": 3656.4, "end": 3660.4, "text": " the different declaration types which are imported from this module.", "tokens": [264, 819, 27606, 3467, 597, 366, 25524, 490, 341, 10088, 13], "temperature": 0.0, "avg_logprob": -0.18912153709225538, "compression_ratio": 1.4832535885167464, "no_speech_prob": 3.1875533750280738e-06}, {"id": 927, "seek": 365140, "start": 3660.4, "end": 3664.4, "text": " Also, I'm a big fan of being explicit about the imports", "tokens": [2743, 11, 286, 478, 257, 955, 3429, 295, 885, 13691, 466, 264, 41596], "temperature": 0.0, "avg_logprob": -0.18912153709225538, "compression_ratio": 1.4832535885167464, "no_speech_prob": 3.1875533750280738e-06}, {"id": 928, "seek": 365140, "start": 3664.4, "end": 3668.4, "text": " because you want to make it clear.", "tokens": [570, 291, 528, 281, 652, 309, 1850, 13], "temperature": 0.0, "avg_logprob": -0.18912153709225538, "compression_ratio": 1.4832535885167464, "no_speech_prob": 3.1875533750280738e-06}, {"id": 929, "seek": 365140, "start": 3668.4, "end": 3673.4, "text": " And actually, Elm Verify examples does not require you", "tokens": [400, 767, 11, 2699, 76, 4281, 2505, 5110, 775, 406, 3651, 291], "temperature": 0.0, "avg_logprob": -0.18912153709225538, "compression_ratio": 1.4832535885167464, "no_speech_prob": 3.1875533750280738e-06}, {"id": 930, "seek": 365140, "start": 3673.4, "end": 3677.4, "text": " to qualify the module you're using,", "tokens": [281, 20276, 264, 10088, 291, 434, 1228, 11], "temperature": 0.0, "avg_logprob": -0.18912153709225538, "compression_ratio": 1.4832535885167464, "no_speech_prob": 3.1875533750280738e-06}, {"id": 931, "seek": 367740, "start": 3677.4, "end": 3683.4, "text": " but I prefer to be explicit about using unqualified module", "tokens": [457, 286, 4382, 281, 312, 13691, 466, 1228, 517, 46094, 10088], "temperature": 0.0, "avg_logprob": -0.16542647225516183, "compression_ratio": 1.725, "no_speech_prob": 1.1544500466698082e-06}, {"id": 932, "seek": 367740, "start": 3683.4, "end": 3685.4, "text": " or qualified module references,", "tokens": [420, 15904, 10088, 15400, 11], "temperature": 0.0, "avg_logprob": -0.16542647225516183, "compression_ratio": 1.725, "no_speech_prob": 1.1544500466698082e-06}, {"id": 933, "seek": 367740, "start": 3685.4, "end": 3688.4, "text": " so putting the module name before explicitly", "tokens": [370, 3372, 264, 10088, 1315, 949, 20803], "temperature": 0.0, "avg_logprob": -0.16542647225516183, "compression_ratio": 1.725, "no_speech_prob": 1.1544500466698082e-06}, {"id": 934, "seek": 367740, "start": 3688.4, "end": 3691.4, "text": " and putting the import to the module itself,", "tokens": [293, 3372, 264, 974, 281, 264, 10088, 2564, 11], "temperature": 0.0, "avg_logprob": -0.16542647225516183, "compression_ratio": 1.725, "no_speech_prob": 1.1544500466698082e-06}, {"id": 935, "seek": 367740, "start": 3691.4, "end": 3693.4, "text": " even the one I'm documenting.", "tokens": [754, 264, 472, 286, 478, 42360, 13], "temperature": 0.0, "avg_logprob": -0.16542647225516183, "compression_ratio": 1.725, "no_speech_prob": 1.1544500466698082e-06}, {"id": 936, "seek": 367740, "start": 3693.4, "end": 3695.4, "text": " It just makes it more copy-pastable and more explicit.", "tokens": [467, 445, 1669, 309, 544, 5055, 12, 79, 525, 712, 293, 544, 13691, 13], "temperature": 0.0, "avg_logprob": -0.16542647225516183, "compression_ratio": 1.725, "no_speech_prob": 1.1544500466698082e-06}, {"id": 937, "seek": 367740, "start": 3695.4, "end": 3697.4, "text": " Exactly, yeah.", "tokens": [7587, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.16542647225516183, "compression_ratio": 1.725, "no_speech_prob": 1.1544500466698082e-06}, {"id": 938, "seek": 367740, "start": 3697.4, "end": 3702.4, "text": " And also, like, when you don't qualify something in your example,", "tokens": [400, 611, 11, 411, 11, 562, 291, 500, 380, 20276, 746, 294, 428, 1365, 11], "temperature": 0.0, "avg_logprob": -0.16542647225516183, "compression_ratio": 1.725, "no_speech_prob": 1.1544500466698082e-06}, {"id": 939, "seek": 367740, "start": 3702.4, "end": 3706.4, "text": " it can be hard to know whether the function that you're referencing", "tokens": [309, 393, 312, 1152, 281, 458, 1968, 264, 2445, 300, 291, 434, 40582], "temperature": 0.0, "avg_logprob": -0.16542647225516183, "compression_ratio": 1.725, "no_speech_prob": 1.1544500466698082e-06}, {"id": 940, "seek": 370640, "start": 3706.4, "end": 3710.4, "text": " is defined in this file, which in some cases it will be,", "tokens": [307, 7642, 294, 341, 3991, 11, 597, 294, 512, 3331, 309, 486, 312, 11], "temperature": 0.0, "avg_logprob": -0.191711461102521, "compression_ratio": 1.6355932203389831, "no_speech_prob": 9.817591489991173e-06}, {"id": 941, "seek": 370640, "start": 3710.4, "end": 3715.4, "text": " or if it's a value that is somewhere else in the code snippet", "tokens": [420, 498, 309, 311, 257, 2158, 300, 307, 4079, 1646, 294, 264, 3089, 35623, 302], "temperature": 0.0, "avg_logprob": -0.191711461102521, "compression_ratio": 1.6355932203389831, "no_speech_prob": 9.817591489991173e-06}, {"id": 942, "seek": 370640, "start": 3715.4, "end": 3720.4, "text": " or that is just omitted because it's too complex to do for the example", "tokens": [420, 300, 307, 445, 3406, 3944, 570, 309, 311, 886, 3997, 281, 360, 337, 264, 1365], "temperature": 0.0, "avg_logprob": -0.191711461102521, "compression_ratio": 1.6355932203389831, "no_speech_prob": 9.817591489991173e-06}, {"id": 943, "seek": 370640, "start": 3720.4, "end": 3722.4, "text": " or too annoying to do.", "tokens": [420, 886, 11304, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.191711461102521, "compression_ratio": 1.6355932203389831, "no_speech_prob": 9.817591489991173e-06}, {"id": 944, "seek": 370640, "start": 3722.4, "end": 3725.4, "text": " But if you qualify it, then it's a lot more explicit,", "tokens": [583, 498, 291, 20276, 309, 11, 550, 309, 311, 257, 688, 544, 13691, 11], "temperature": 0.0, "avg_logprob": -0.191711461102521, "compression_ratio": 1.6355932203389831, "no_speech_prob": 9.817591489991173e-06}, {"id": 945, "seek": 370640, "start": 3725.4, "end": 3727.4, "text": " and as you say, copy-pastable, understandable.", "tokens": [293, 382, 291, 584, 11, 5055, 12, 79, 525, 712, 11, 25648, 13], "temperature": 0.0, "avg_logprob": -0.191711461102521, "compression_ratio": 1.6355932203389831, "no_speech_prob": 9.817591489991173e-06}, {"id": 946, "seek": 370640, "start": 3727.4, "end": 3735.4, "text": " And we usually in the Elm community advise for qualified imports anyway,", "tokens": [400, 321, 2673, 294, 264, 2699, 76, 1768, 18312, 337, 15904, 41596, 4033, 11], "temperature": 0.0, "avg_logprob": -0.191711461102521, "compression_ratio": 1.6355932203389831, "no_speech_prob": 9.817591489991173e-06}, {"id": 947, "seek": 373540, "start": 3735.4, "end": 3739.4, "text": " so let's use that in the examples anyway.", "tokens": [370, 718, 311, 764, 300, 294, 264, 5110, 4033, 13], "temperature": 0.0, "avg_logprob": -0.16063521393632466, "compression_ratio": 1.653386454183267, "no_speech_prob": 7.071073468978284e-06}, {"id": 948, "seek": 373540, "start": 3739.4, "end": 3743.4, "text": " That's my take at least, and I know you agree with this.", "tokens": [663, 311, 452, 747, 412, 1935, 11, 293, 286, 458, 291, 3986, 365, 341, 13], "temperature": 0.0, "avg_logprob": -0.16063521393632466, "compression_ratio": 1.653386454183267, "no_speech_prob": 7.071073468978284e-06}, {"id": 949, "seek": 373540, "start": 3743.4, "end": 3748.4, "text": " Yes, and also it should be as idiomatic as possible in every way.", "tokens": [1079, 11, 293, 611, 309, 820, 312, 382, 18014, 13143, 382, 1944, 294, 633, 636, 13], "temperature": 0.0, "avg_logprob": -0.16063521393632466, "compression_ratio": 1.653386454183267, "no_speech_prob": 7.071073468978284e-06}, {"id": 950, "seek": 373540, "start": 3748.4, "end": 3751.4, "text": " Now, of course, people do have different styles,", "tokens": [823, 11, 295, 1164, 11, 561, 360, 362, 819, 13273, 11], "temperature": 0.0, "avg_logprob": -0.16063521393632466, "compression_ratio": 1.653386454183267, "no_speech_prob": 7.071073468978284e-06}, {"id": 951, "seek": 373540, "start": 3751.4, "end": 3752.4, "text": " and there's nothing wrong with that.", "tokens": [293, 456, 311, 1825, 2085, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.16063521393632466, "compression_ratio": 1.653386454183267, "no_speech_prob": 7.071073468978284e-06}, {"id": 952, "seek": 373540, "start": 3752.4, "end": 3757.4, "text": " Some people really like using unqualified imports in certain cases,", "tokens": [2188, 561, 534, 411, 1228, 517, 46094, 41596, 294, 1629, 3331, 11], "temperature": 0.0, "avg_logprob": -0.16063521393632466, "compression_ratio": 1.653386454183267, "no_speech_prob": 7.071073468978284e-06}, {"id": 953, "seek": 373540, "start": 3757.4, "end": 3760.4, "text": " and that's totally fine, but I think that it's important", "tokens": [293, 300, 311, 3879, 2489, 11, 457, 286, 519, 300, 309, 311, 1021], "temperature": 0.0, "avg_logprob": -0.16063521393632466, "compression_ratio": 1.653386454183267, "no_speech_prob": 7.071073468978284e-06}, {"id": 954, "seek": 373540, "start": 3760.4, "end": 3762.4, "text": " to try to write in an idiomatic format.", "tokens": [281, 853, 281, 2464, 294, 364, 18014, 13143, 7877, 13], "temperature": 0.0, "avg_logprob": -0.16063521393632466, "compression_ratio": 1.653386454183267, "no_speech_prob": 7.071073468978284e-06}, {"id": 955, "seek": 376240, "start": 3762.4, "end": 3766.4, "text": " Like, for example, if you're going to use an import alias,", "tokens": [1743, 11, 337, 1365, 11, 498, 291, 434, 516, 281, 764, 364, 974, 419, 4609, 11], "temperature": 0.0, "avg_logprob": -0.17195007128593248, "compression_ratio": 1.796078431372549, "no_speech_prob": 1.3006989320274442e-05}, {"id": 956, "seek": 376240, "start": 3766.4, "end": 3769.4, "text": " use that everywhere and use it consistently in your examples", "tokens": [764, 300, 5315, 293, 764, 309, 14961, 294, 428, 5110], "temperature": 0.0, "avg_logprob": -0.17195007128593248, "compression_ratio": 1.796078431372549, "no_speech_prob": 1.3006989320274442e-05}, {"id": 957, "seek": 376240, "start": 3769.4, "end": 3774.4, "text": " because the thing is, everybody who uses your package", "tokens": [570, 264, 551, 307, 11, 2201, 567, 4960, 428, 7372], "temperature": 0.0, "avg_logprob": -0.17195007128593248, "compression_ratio": 1.796078431372549, "no_speech_prob": 1.3006989320274442e-05}, {"id": 958, "seek": 376240, "start": 3774.4, "end": 3778.4, "text": " will probably use that same example that you use", "tokens": [486, 1391, 764, 300, 912, 1365, 300, 291, 764], "temperature": 0.0, "avg_logprob": -0.17195007128593248, "compression_ratio": 1.796078431372549, "no_speech_prob": 1.3006989320274442e-05}, {"id": 959, "seek": 376240, "start": 3778.4, "end": 3781.4, "text": " because you're sort of defining a convention,", "tokens": [570, 291, 434, 1333, 295, 17827, 257, 10286, 11], "temperature": 0.0, "avg_logprob": -0.17195007128593248, "compression_ratio": 1.796078431372549, "no_speech_prob": 1.3006989320274442e-05}, {"id": 960, "seek": 376240, "start": 3781.4, "end": 3785.4, "text": " whether or not you realize it, and so you should put some thought", "tokens": [1968, 420, 406, 291, 4325, 309, 11, 293, 370, 291, 820, 829, 512, 1194], "temperature": 0.0, "avg_logprob": -0.17195007128593248, "compression_ratio": 1.796078431372549, "no_speech_prob": 1.3006989320274442e-05}, {"id": 961, "seek": 376240, "start": 3785.4, "end": 3787.4, "text": " into how you want to import things, not just like,", "tokens": [666, 577, 291, 528, 281, 974, 721, 11, 406, 445, 411, 11], "temperature": 0.0, "avg_logprob": -0.17195007128593248, "compression_ratio": 1.796078431372549, "no_speech_prob": 1.3006989320274442e-05}, {"id": 962, "seek": 376240, "start": 3787.4, "end": 3790.4, "text": " well, for the case of this example, I'm going to use a one-letter import", "tokens": [731, 11, 337, 264, 1389, 295, 341, 1365, 11, 286, 478, 516, 281, 764, 257, 472, 12, 21248, 974], "temperature": 0.0, "avg_logprob": -0.17195007128593248, "compression_ratio": 1.796078431372549, "no_speech_prob": 1.3006989320274442e-05}, {"id": 963, "seek": 379040, "start": 3790.4, "end": 3793.4, "text": " or something like that.", "tokens": [420, 746, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.17404322280097254, "compression_ratio": 1.5495495495495495, "no_speech_prob": 4.092869858141057e-06}, {"id": 964, "seek": 379040, "start": 3793.4, "end": 3795.4, "text": " People take it and run with it.", "tokens": [3432, 747, 309, 293, 1190, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.17404322280097254, "compression_ratio": 1.5495495495495495, "no_speech_prob": 4.092869858141057e-06}, {"id": 965, "seek": 379040, "start": 3795.4, "end": 3799.4, "text": " Also, so naming things is important.", "tokens": [2743, 11, 370, 25290, 721, 307, 1021, 13], "temperature": 0.0, "avg_logprob": -0.17404322280097254, "compression_ratio": 1.5495495495495495, "no_speech_prob": 4.092869858141057e-06}, {"id": 966, "seek": 379040, "start": 3799.4, "end": 3803.4, "text": " I am personally a fan of giving meaningful names to type variables.", "tokens": [286, 669, 5665, 257, 3429, 295, 2902, 10995, 5288, 281, 2010, 9102, 13], "temperature": 0.0, "avg_logprob": -0.17404322280097254, "compression_ratio": 1.5495495495495495, "no_speech_prob": 4.092869858141057e-06}, {"id": 967, "seek": 379040, "start": 3803.4, "end": 3810.4, "text": " Now, in the case of, you know, dict comparable a,", "tokens": [823, 11, 294, 264, 1389, 295, 11, 291, 458, 11, 12569, 25323, 257, 11], "temperature": 0.0, "avg_logprob": -0.17404322280097254, "compression_ratio": 1.5495495495495495, "no_speech_prob": 4.092869858141057e-06}, {"id": 968, "seek": 379040, "start": 3810.4, "end": 3812.4, "text": " that might be fine.", "tokens": [300, 1062, 312, 2489, 13], "temperature": 0.0, "avg_logprob": -0.17404322280097254, "compression_ratio": 1.5495495495495495, "no_speech_prob": 4.092869858141057e-06}, {"id": 969, "seek": 379040, "start": 3812.4, "end": 3815.4, "text": " I don't know. What do you think about that?", "tokens": [286, 500, 380, 458, 13, 708, 360, 291, 519, 466, 300, 30], "temperature": 0.0, "avg_logprob": -0.17404322280097254, "compression_ratio": 1.5495495495495495, "no_speech_prob": 4.092869858141057e-06}, {"id": 970, "seek": 379040, "start": 3815.4, "end": 3819.4, "text": " I think that if it's for something generic, like purposefully generic", "tokens": [286, 519, 300, 498, 309, 311, 337, 746, 19577, 11, 411, 4334, 2277, 19577], "temperature": 0.0, "avg_logprob": -0.17404322280097254, "compression_ratio": 1.5495495495495495, "no_speech_prob": 4.092869858141057e-06}, {"id": 971, "seek": 381940, "start": 3819.4, "end": 3823.4, "text": " and extremely generic, then a is just fine.", "tokens": [293, 4664, 19577, 11, 550, 257, 307, 445, 2489, 13], "temperature": 0.0, "avg_logprob": -0.19330861970975802, "compression_ratio": 1.5837837837837838, "no_speech_prob": 2.1110619854880497e-05}, {"id": 972, "seek": 381940, "start": 3823.4, "end": 3829.4, "text": " If it's for functions like map, where you have a something a", "tokens": [759, 309, 311, 337, 6828, 411, 4471, 11, 689, 291, 362, 257, 746, 257], "temperature": 0.0, "avg_logprob": -0.19330861970975802, "compression_ratio": 1.5837837837837838, "no_speech_prob": 2.1110619854880497e-05}, {"id": 973, "seek": 381940, "start": 3829.4, "end": 3833.4, "text": " that transforms it to something b, that's very fine as well", "tokens": [300, 35592, 309, 281, 746, 272, 11, 300, 311, 588, 2489, 382, 731], "temperature": 0.0, "avg_logprob": -0.19330861970975802, "compression_ratio": 1.5837837837837838, "no_speech_prob": 2.1110619854880497e-05}, {"id": 974, "seek": 381940, "start": 3833.4, "end": 3836.4, "text": " because people understand it.", "tokens": [570, 561, 1223, 309, 13], "temperature": 0.0, "avg_logprob": -0.19330861970975802, "compression_ratio": 1.5837837837837838, "no_speech_prob": 2.1110619854880497e-05}, {"id": 975, "seek": 381940, "start": 3836.4, "end": 3840.4, "text": " If it's for anything else where you have more insights", "tokens": [759, 309, 311, 337, 1340, 1646, 689, 291, 362, 544, 14310], "temperature": 0.0, "avg_logprob": -0.19330861970975802, "compression_ratio": 1.5837837837837838, "no_speech_prob": 2.1110619854880497e-05}, {"id": 976, "seek": 381940, "start": 3840.4, "end": 3844.4, "text": " about the type variable, what it will hold,", "tokens": [466, 264, 2010, 7006, 11, 437, 309, 486, 1797, 11], "temperature": 0.0, "avg_logprob": -0.19330861970975802, "compression_ratio": 1.5837837837837838, "no_speech_prob": 2.1110619854880497e-05}, {"id": 977, "seek": 384440, "start": 3844.4, "end": 3849.4, "text": " what it does represent, then I would use that instead when possible.", "tokens": [437, 309, 775, 2906, 11, 550, 286, 576, 764, 300, 2602, 562, 1944, 13], "temperature": 0.0, "avg_logprob": -0.2812112469539464, "compression_ratio": 1.5439330543933054, "no_speech_prob": 4.78506444778759e-06}, {"id": 978, "seek": 384440, "start": 3849.4, "end": 3854.4, "text": " Right. Yeah, like in the Elm Review docs, I see you, for example...", "tokens": [1779, 13, 865, 11, 411, 294, 264, 2699, 76, 19954, 45623, 11, 286, 536, 291, 11, 337, 1365, 485], "temperature": 0.0, "avg_logprob": -0.2812112469539464, "compression_ratio": 1.5439330543933054, "no_speech_prob": 4.78506444778759e-06}, {"id": 979, "seek": 384440, "start": 3854.4, "end": 3856.4, "text": " You use schema state, I think.", "tokens": [509, 764, 34078, 1785, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.2812112469539464, "compression_ratio": 1.5439330543933054, "no_speech_prob": 4.78506444778759e-06}, {"id": 980, "seek": 384440, "start": 3856.4, "end": 3860.4, "text": " Schema state, module context.", "tokens": [2065, 5619, 1785, 11, 10088, 4319, 13], "temperature": 0.0, "avg_logprob": -0.2812112469539464, "compression_ratio": 1.5439330543933054, "no_speech_prob": 4.78506444778759e-06}, {"id": 981, "seek": 384440, "start": 3860.4, "end": 3865.4, "text": " So that is... and you use the naming consistently.", "tokens": [407, 300, 307, 485, 293, 291, 764, 264, 25290, 14961, 13], "temperature": 0.0, "avg_logprob": -0.2812112469539464, "compression_ratio": 1.5439330543933054, "no_speech_prob": 4.78506444778759e-06}, {"id": 982, "seek": 384440, "start": 3865.4, "end": 3869.4, "text": " So at least that gives people a sense of what name to use.", "tokens": [407, 412, 1935, 300, 2709, 561, 257, 2020, 295, 437, 1315, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.2812112469539464, "compression_ratio": 1.5439330543933054, "no_speech_prob": 4.78506444778759e-06}, {"id": 983, "seek": 384440, "start": 3869.4, "end": 3872.4, "text": " I'm trying to remember in ElmGraphQL, I made a change as well", "tokens": [286, 478, 1382, 281, 1604, 294, 2699, 76, 38, 2662, 13695, 11, 286, 1027, 257, 1319, 382, 731], "temperature": 0.0, "avg_logprob": -0.2812112469539464, "compression_ratio": 1.5439330543933054, "no_speech_prob": 4.78506444778759e-06}, {"id": 984, "seek": 387240, "start": 3872.4, "end": 3876.4, "text": " at some point where I was not using a type variable.", "tokens": [412, 512, 935, 689, 286, 390, 406, 1228, 257, 2010, 7006, 13], "temperature": 0.0, "avg_logprob": -0.149717406621055, "compression_ratio": 1.7063492063492063, "no_speech_prob": 6.747981842636364e-06}, {"id": 985, "seek": 387240, "start": 3876.4, "end": 3879.4, "text": " I didn't have a good name for this type variable,", "tokens": [286, 994, 380, 362, 257, 665, 1315, 337, 341, 2010, 7006, 11], "temperature": 0.0, "avg_logprob": -0.149717406621055, "compression_ratio": 1.7063492063492063, "no_speech_prob": 6.747981842636364e-06}, {"id": 986, "seek": 387240, "start": 3879.4, "end": 3883.4, "text": " and it actually made it a lot harder for people to understand the context.", "tokens": [293, 309, 767, 1027, 309, 257, 688, 6081, 337, 561, 281, 1223, 264, 4319, 13], "temperature": 0.0, "avg_logprob": -0.149717406621055, "compression_ratio": 1.7063492063492063, "no_speech_prob": 6.747981842636364e-06}, {"id": 987, "seek": 387240, "start": 3883.4, "end": 3885.4, "text": " What did I name it? The scope.", "tokens": [708, 630, 286, 1315, 309, 30, 440, 11923, 13], "temperature": 0.0, "avg_logprob": -0.149717406621055, "compression_ratio": 1.7063492063492063, "no_speech_prob": 6.747981842636364e-06}, {"id": 988, "seek": 387240, "start": 3885.4, "end": 3891.4, "text": " Okay, so yeah, in ElmGraphQL, a selection set decodes to a value,", "tokens": [1033, 11, 370, 1338, 11, 294, 2699, 76, 38, 2662, 13695, 11, 257, 9450, 992, 979, 4789, 281, 257, 2158, 11], "temperature": 0.0, "avg_logprob": -0.149717406621055, "compression_ratio": 1.7063492063492063, "no_speech_prob": 6.747981842636364e-06}, {"id": 989, "seek": 387240, "start": 3891.4, "end": 3893.4, "text": " and it has a scope.", "tokens": [293, 309, 575, 257, 11923, 13], "temperature": 0.0, "avg_logprob": -0.149717406621055, "compression_ratio": 1.7063492063492063, "no_speech_prob": 6.747981842636364e-06}, {"id": 990, "seek": 387240, "start": 3893.4, "end": 3895.4, "text": " The scope is a phantom type.", "tokens": [440, 11923, 307, 257, 903, 25796, 2010, 13], "temperature": 0.0, "avg_logprob": -0.149717406621055, "compression_ratio": 1.7063492063492063, "no_speech_prob": 6.747981842636364e-06}, {"id": 991, "seek": 387240, "start": 3895.4, "end": 3898.4, "text": " This is a confusing concept to introduce to people, right?", "tokens": [639, 307, 257, 13181, 3410, 281, 5366, 281, 561, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.149717406621055, "compression_ratio": 1.7063492063492063, "no_speech_prob": 6.747981842636364e-06}, {"id": 992, "seek": 387240, "start": 3898.4, "end": 3900.4, "text": " Some people might not have used a phantom type.", "tokens": [2188, 561, 1062, 406, 362, 1143, 257, 903, 25796, 2010, 13], "temperature": 0.0, "avg_logprob": -0.149717406621055, "compression_ratio": 1.7063492063492063, "no_speech_prob": 6.747981842636364e-06}, {"id": 993, "seek": 390040, "start": 3900.4, "end": 3902.4, "text": " Some people might have used a phantom type,", "tokens": [2188, 561, 1062, 362, 1143, 257, 903, 25796, 2010, 11], "temperature": 0.0, "avg_logprob": -0.18135388080890363, "compression_ratio": 1.7630331753554502, "no_speech_prob": 1.3631060028274078e-05}, {"id": 994, "seek": 390040, "start": 3902.4, "end": 3906.4, "text": " but might not understand how that applies to the concept of GraphQL.", "tokens": [457, 1062, 406, 1223, 577, 300, 13165, 281, 264, 3410, 295, 21884, 13695, 13], "temperature": 0.0, "avg_logprob": -0.18135388080890363, "compression_ratio": 1.7630331753554502, "no_speech_prob": 1.3631060028274078e-05}, {"id": 995, "seek": 390040, "start": 3906.4, "end": 3911.4, "text": " So a selection set, you know, we've discussed in the past,", "tokens": [407, 257, 9450, 992, 11, 291, 458, 11, 321, 600, 7152, 294, 264, 1791, 11], "temperature": 0.0, "avg_logprob": -0.18135388080890363, "compression_ratio": 1.7630331753554502, "no_speech_prob": 1.3631060028274078e-05}, {"id": 996, "seek": 390040, "start": 3911.4, "end": 3915.4, "text": " it is scoped so that you can't, you know,", "tokens": [309, 307, 795, 27277, 370, 300, 291, 393, 380, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.18135388080890363, "compression_ratio": 1.7630331753554502, "no_speech_prob": 1.3631060028274078e-05}, {"id": 997, "seek": 390040, "start": 3915.4, "end": 3920.4, "text": " if you are able to take a selection set that represents getting the first name", "tokens": [498, 291, 366, 1075, 281, 747, 257, 9450, 992, 300, 8855, 1242, 264, 700, 1315], "temperature": 0.0, "avg_logprob": -0.18135388080890363, "compression_ratio": 1.7630331753554502, "no_speech_prob": 1.3631060028274078e-05}, {"id": 998, "seek": 390040, "start": 3920.4, "end": 3923.4, "text": " in the scope of a user,", "tokens": [294, 264, 11923, 295, 257, 4195, 11], "temperature": 0.0, "avg_logprob": -0.18135388080890363, "compression_ratio": 1.7630331753554502, "no_speech_prob": 1.3631060028274078e-05}, {"id": 999, "seek": 390040, "start": 3923.4, "end": 3928.4, "text": " you can't get the first name in the scope of a product.", "tokens": [291, 393, 380, 483, 264, 700, 1315, 294, 264, 11923, 295, 257, 1674, 13], "temperature": 0.0, "avg_logprob": -0.18135388080890363, "compression_ratio": 1.7630331753554502, "no_speech_prob": 1.3631060028274078e-05}, {"id": 1000, "seek": 392840, "start": 3928.4, "end": 3933.4, "text": " So the scope phantom type variable defines the scope of your selection.", "tokens": [407, 264, 11923, 903, 25796, 2010, 7006, 23122, 264, 11923, 295, 428, 9450, 13], "temperature": 0.0, "avg_logprob": -0.1984278361002604, "compression_ratio": 1.6575342465753424, "no_speech_prob": 5.5941422942851204e-06}, {"id": 1001, "seek": 392840, "start": 3933.4, "end": 3938.4, "text": " So I tried to use domain language there, and I think that's really key.", "tokens": [407, 286, 3031, 281, 764, 9274, 2856, 456, 11, 293, 286, 519, 300, 311, 534, 2141, 13], "temperature": 0.0, "avg_logprob": -0.1984278361002604, "compression_ratio": 1.6575342465753424, "no_speech_prob": 5.5941422942851204e-06}, {"id": 1002, "seek": 392840, "start": 3938.4, "end": 3944.4, "text": " Yeah, the type variable is usually something a little bit more abstract.", "tokens": [865, 11, 264, 2010, 7006, 307, 2673, 746, 257, 707, 857, 544, 12649, 13], "temperature": 0.0, "avg_logprob": -0.1984278361002604, "compression_ratio": 1.6575342465753424, "no_speech_prob": 5.5941422942851204e-06}, {"id": 1003, "seek": 392840, "start": 3944.4, "end": 3949.4, "text": " So especially if it's used to represent some constraints,", "tokens": [407, 2318, 498, 309, 311, 1143, 281, 2906, 512, 18491, 11], "temperature": 0.0, "avg_logprob": -0.1984278361002604, "compression_ratio": 1.6575342465753424, "no_speech_prob": 5.5941422942851204e-06}, {"id": 1004, "seek": 392840, "start": 3949.4, "end": 3953.4, "text": " then it's worth giving it a good name,", "tokens": [550, 309, 311, 3163, 2902, 309, 257, 665, 1315, 11], "temperature": 0.0, "avg_logprob": -0.1984278361002604, "compression_ratio": 1.6575342465753424, "no_speech_prob": 5.5941422942851204e-06}, {"id": 1005, "seek": 392840, "start": 3953.4, "end": 3956.4, "text": " like even if it's just constraints, I don't know,", "tokens": [411, 754, 498, 309, 311, 445, 18491, 11, 286, 500, 380, 458, 11], "temperature": 0.0, "avg_logprob": -0.1984278361002604, "compression_ratio": 1.6575342465753424, "no_speech_prob": 5.5941422942851204e-06}, {"id": 1006, "seek": 395640, "start": 3956.4, "end": 3958.4, "text": " I use something somewhere maybe.", "tokens": [286, 764, 746, 4079, 1310, 13], "temperature": 0.0, "avg_logprob": -0.17868131120628286, "compression_ratio": 1.7083333333333333, "no_speech_prob": 1.5686950064264238e-05}, {"id": 1007, "seek": 395640, "start": 3958.4, "end": 3960.4, "text": " Yeah, and naming is also a process.", "tokens": [865, 11, 293, 25290, 307, 611, 257, 1399, 13], "temperature": 0.0, "avg_logprob": -0.17868131120628286, "compression_ratio": 1.7083333333333333, "no_speech_prob": 1.5686950064264238e-05}, {"id": 1008, "seek": 395640, "start": 3960.4, "end": 3964.4, "text": " You can always iterate to get a better name.", "tokens": [509, 393, 1009, 44497, 281, 483, 257, 1101, 1315, 13], "temperature": 0.0, "avg_logprob": -0.17868131120628286, "compression_ratio": 1.7083333333333333, "no_speech_prob": 1.5686950064264238e-05}, {"id": 1009, "seek": 395640, "start": 3964.4, "end": 3966.4, "text": " You don't have to get everything around the first try.", "tokens": [509, 500, 380, 362, 281, 483, 1203, 926, 264, 700, 853, 13], "temperature": 0.0, "avg_logprob": -0.17868131120628286, "compression_ratio": 1.7083333333333333, "no_speech_prob": 1.5686950064264238e-05}, {"id": 1010, "seek": 395640, "start": 3966.4, "end": 3972.4, "text": " I think it's really important to notice where do you find friction", "tokens": [286, 519, 309, 311, 534, 1021, 281, 3449, 689, 360, 291, 915, 17710], "temperature": 0.0, "avg_logprob": -0.17868131120628286, "compression_ratio": 1.7083333333333333, "no_speech_prob": 1.5686950064264238e-05}, {"id": 1011, "seek": 395640, "start": 3972.4, "end": 3975.4, "text": " as you're reading things?", "tokens": [382, 291, 434, 3760, 721, 30], "temperature": 0.0, "avg_logprob": -0.17868131120628286, "compression_ratio": 1.7083333333333333, "no_speech_prob": 1.5686950064264238e-05}, {"id": 1012, "seek": 395640, "start": 3975.4, "end": 3979.4, "text": " Where are you finding that you're conflicted about what names to use?", "tokens": [2305, 366, 291, 5006, 300, 291, 434, 6596, 292, 466, 437, 5288, 281, 764, 30], "temperature": 0.0, "avg_logprob": -0.17868131120628286, "compression_ratio": 1.7083333333333333, "no_speech_prob": 1.5686950064264238e-05}, {"id": 1013, "seek": 395640, "start": 3979.4, "end": 3984.4, "text": " You don't have a clear concept in your head of what term to use for something.", "tokens": [509, 500, 380, 362, 257, 1850, 3410, 294, 428, 1378, 295, 437, 1433, 281, 764, 337, 746, 13], "temperature": 0.0, "avg_logprob": -0.17868131120628286, "compression_ratio": 1.7083333333333333, "no_speech_prob": 1.5686950064264238e-05}, {"id": 1014, "seek": 398440, "start": 3984.4, "end": 3986.4, "text": " Where are people getting confused?", "tokens": [2305, 366, 561, 1242, 9019, 30], "temperature": 0.0, "avg_logprob": -0.2212210421292287, "compression_ratio": 1.650735294117647, "no_speech_prob": 8.939223334891722e-06}, {"id": 1015, "seek": 398440, "start": 3986.4, "end": 3991.4, "text": " Where are you finding it difficult explaining a concept to other people?", "tokens": [2305, 366, 291, 5006, 309, 2252, 13468, 257, 3410, 281, 661, 561, 30], "temperature": 0.0, "avg_logprob": -0.2212210421292287, "compression_ratio": 1.650735294117647, "no_speech_prob": 8.939223334891722e-06}, {"id": 1016, "seek": 398440, "start": 3991.4, "end": 3995.4, "text": " I think it's important to deliberately invest time in giving names", "tokens": [286, 519, 309, 311, 1021, 281, 23506, 1963, 565, 294, 2902, 5288], "temperature": 0.0, "avg_logprob": -0.2212210421292287, "compression_ratio": 1.650735294117647, "no_speech_prob": 8.939223334891722e-06}, {"id": 1017, "seek": 398440, "start": 3995.4, "end": 3999.4, "text": " to these abstractions and ideas and iterating on names there.", "tokens": [281, 613, 12649, 626, 293, 3487, 293, 17138, 990, 322, 5288, 456, 13], "temperature": 0.0, "avg_logprob": -0.2212210421292287, "compression_ratio": 1.650735294117647, "no_speech_prob": 8.939223334891722e-06}, {"id": 1018, "seek": 398440, "start": 3999.4, "end": 4002.4, "text": " So those are things to look for.", "tokens": [407, 729, 366, 721, 281, 574, 337, 13], "temperature": 0.0, "avg_logprob": -0.2212210421292287, "compression_ratio": 1.650735294117647, "no_speech_prob": 8.939223334891722e-06}, {"id": 1019, "seek": 398440, "start": 4002.4, "end": 4005.4, "text": " Also getting feedback from users is key, of course.", "tokens": [2743, 1242, 5824, 490, 5022, 307, 2141, 11, 295, 1164, 13], "temperature": 0.0, "avg_logprob": -0.2212210421292287, "compression_ratio": 1.650735294117647, "no_speech_prob": 8.939223334891722e-06}, {"id": 1020, "seek": 398440, "start": 4005.4, "end": 4007.4, "text": " You mentioned at the beginning that whenever you thought about", "tokens": [509, 2835, 412, 264, 2863, 300, 5699, 291, 1194, 466], "temperature": 0.0, "avg_logprob": -0.2212210421292287, "compression_ratio": 1.650735294117647, "no_speech_prob": 8.939223334891722e-06}, {"id": 1021, "seek": 398440, "start": 4007.4, "end": 4010.4, "text": " binding documentation, you were thinking about Varisblock.", "tokens": [17359, 14333, 11, 291, 645, 1953, 466, 14662, 271, 28830, 13], "temperature": 0.0, "avg_logprob": -0.2212210421292287, "compression_ratio": 1.650735294117647, "no_speech_prob": 8.939223334891722e-06}, {"id": 1022, "seek": 398440, "start": 4010.4, "end": 4012.4, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2212210421292287, "compression_ratio": 1.650735294117647, "no_speech_prob": 8.939223334891722e-06}, {"id": 1023, "seek": 401240, "start": 4012.4, "end": 4017.4, "text": " So as you say, writing documentation is sometimes not the most fun part", "tokens": [407, 382, 291, 584, 11, 3579, 14333, 307, 2171, 406, 264, 881, 1019, 644], "temperature": 0.0, "avg_logprob": -0.19619109080387995, "compression_ratio": 1.4427083333333333, "no_speech_prob": 5.771710220869863e-06}, {"id": 1024, "seek": 401240, "start": 4017.4, "end": 4019.4, "text": " and it can be very hard.", "tokens": [293, 309, 393, 312, 588, 1152, 13], "temperature": 0.0, "avg_logprob": -0.19619109080387995, "compression_ratio": 1.4427083333333333, "no_speech_prob": 5.771710220869863e-06}, {"id": 1025, "seek": 401240, "start": 4019.4, "end": 4023.4, "text": " Also, how much should I detail?", "tokens": [2743, 11, 577, 709, 820, 286, 2607, 30], "temperature": 0.0, "avg_logprob": -0.19619109080387995, "compression_ratio": 1.4427083333333333, "no_speech_prob": 5.771710220869863e-06}, {"id": 1026, "seek": 401240, "start": 4023.4, "end": 4025.4, "text": " What should I detail?", "tokens": [708, 820, 286, 2607, 30], "temperature": 0.0, "avg_logprob": -0.19619109080387995, "compression_ratio": 1.4427083333333333, "no_speech_prob": 5.771710220869863e-06}, {"id": 1027, "seek": 401240, "start": 4025.4, "end": 4027.4, "text": " It's hard sometimes.", "tokens": [467, 311, 1152, 2171, 13], "temperature": 0.0, "avg_logprob": -0.19619109080387995, "compression_ratio": 1.4427083333333333, "no_speech_prob": 5.771710220869863e-06}, {"id": 1028, "seek": 401240, "start": 4027.4, "end": 4031.4, "text": " But in some cases, things are just super complex to explain.", "tokens": [583, 294, 512, 3331, 11, 721, 366, 445, 1687, 3997, 281, 2903, 13], "temperature": 0.0, "avg_logprob": -0.19619109080387995, "compression_ratio": 1.4427083333333333, "no_speech_prob": 5.771710220869863e-06}, {"id": 1029, "seek": 401240, "start": 4031.4, "end": 4036.4, "text": " I remember when preparing for Arm Review V2,", "tokens": [286, 1604, 562, 10075, 337, 11893, 19954, 691, 17, 11], "temperature": 0.0, "avg_logprob": -0.19619109080387995, "compression_ratio": 1.4427083333333333, "no_speech_prob": 5.771710220869863e-06}, {"id": 1030, "seek": 403640, "start": 4036.4, "end": 4046.4, "text": " I had an API to merge module context into a project context or something.", "tokens": [286, 632, 364, 9362, 281, 22183, 10088, 4319, 666, 257, 1716, 4319, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.20459177555182043, "compression_ratio": 1.5343915343915344, "no_speech_prob": 5.420719389803708e-06}, {"id": 1031, "seek": 403640, "start": 4046.4, "end": 4051.4, "text": " The most complex part of Arm Review's API", "tokens": [440, 881, 3997, 644, 295, 11893, 19954, 311, 9362], "temperature": 0.0, "avg_logprob": -0.20459177555182043, "compression_ratio": 1.5343915343915344, "no_speech_prob": 5.420719389803708e-06}, {"id": 1032, "seek": 403640, "start": 4051.4, "end": 4055.4, "text": " is how you mingle project context and module context.", "tokens": [307, 577, 291, 275, 26209, 1716, 4319, 293, 10088, 4319, 13], "temperature": 0.0, "avg_logprob": -0.20459177555182043, "compression_ratio": 1.5343915343915344, "no_speech_prob": 5.420719389803708e-06}, {"id": 1033, "seek": 403640, "start": 4055.4, "end": 4059.4, "text": " And I found that to be very hard to explain.", "tokens": [400, 286, 1352, 300, 281, 312, 588, 1152, 281, 2903, 13], "temperature": 0.0, "avg_logprob": -0.20459177555182043, "compression_ratio": 1.5343915343915344, "no_speech_prob": 5.420719389803708e-06}, {"id": 1034, "seek": 403640, "start": 4059.4, "end": 4062.4, "text": " It took me plenty of paragraphs.", "tokens": [467, 1890, 385, 7140, 295, 48910, 13], "temperature": 0.0, "avg_logprob": -0.20459177555182043, "compression_ratio": 1.5343915343915344, "no_speech_prob": 5.420719389803708e-06}, {"id": 1035, "seek": 403640, "start": 4062.4, "end": 4065.4, "text": " And I was like, this is still not amazing.", "tokens": [400, 286, 390, 411, 11, 341, 307, 920, 406, 2243, 13], "temperature": 0.0, "avg_logprob": -0.20459177555182043, "compression_ratio": 1.5343915343915344, "no_speech_prob": 5.420719389803708e-06}, {"id": 1036, "seek": 406540, "start": 4065.4, "end": 4069.4, "text": " And at some point, I figured out a different API for it,", "tokens": [400, 412, 512, 935, 11, 286, 8932, 484, 257, 819, 9362, 337, 309, 11], "temperature": 0.0, "avg_logprob": -0.20477897242495888, "compression_ratio": 1.712962962962963, "no_speech_prob": 7.338124987654737e-07}, {"id": 1037, "seek": 406540, "start": 4069.4, "end": 4072.4, "text": " and it was much easier to explain.", "tokens": [293, 309, 390, 709, 3571, 281, 2903, 13], "temperature": 0.0, "avg_logprob": -0.20477897242495888, "compression_ratio": 1.712962962962963, "no_speech_prob": 7.338124987654737e-07}, {"id": 1038, "seek": 406540, "start": 4072.4, "end": 4077.4, "text": " So sometimes the solution to when you have trouble explaining something", "tokens": [407, 2171, 264, 3827, 281, 562, 291, 362, 5253, 13468, 746], "temperature": 0.0, "avg_logprob": -0.20477897242495888, "compression_ratio": 1.712962962962963, "no_speech_prob": 7.338124987654737e-07}, {"id": 1039, "seek": 406540, "start": 4077.4, "end": 4079.4, "text": " is to change the API.", "tokens": [307, 281, 1319, 264, 9362, 13], "temperature": 0.0, "avg_logprob": -0.20477897242495888, "compression_ratio": 1.712962962962963, "no_speech_prob": 7.338124987654737e-07}, {"id": 1040, "seek": 406540, "start": 4079.4, "end": 4082.4, "text": " Like you're explaining something that is too complex", "tokens": [1743, 291, 434, 13468, 746, 300, 307, 886, 3997], "temperature": 0.0, "avg_logprob": -0.20477897242495888, "compression_ratio": 1.712962962962963, "no_speech_prob": 7.338124987654737e-07}, {"id": 1041, "seek": 406540, "start": 4082.4, "end": 4086.4, "text": " and you should try to find a simpler way.", "tokens": [293, 291, 820, 853, 281, 915, 257, 18587, 636, 13], "temperature": 0.0, "avg_logprob": -0.20477897242495888, "compression_ratio": 1.712962962962963, "no_speech_prob": 7.338124987654737e-07}, {"id": 1042, "seek": 406540, "start": 4086.4, "end": 4090.4, "text": " So that was the pain points that I had once.", "tokens": [407, 300, 390, 264, 1822, 2793, 300, 286, 632, 1564, 13], "temperature": 0.0, "avg_logprob": -0.20477897242495888, "compression_ratio": 1.712962962962963, "no_speech_prob": 7.338124987654737e-07}, {"id": 1043, "seek": 406540, "start": 4090.4, "end": 4094.4, "text": " And the solution was do something different.", "tokens": [400, 264, 3827, 390, 360, 746, 819, 13], "temperature": 0.0, "avg_logprob": -0.20477897242495888, "compression_ratio": 1.712962962962963, "no_speech_prob": 7.338124987654737e-07}, {"id": 1044, "seek": 409440, "start": 4094.4, "end": 4098.4, "text": " And then as soon as you see, oh, now it's much easier to explain,", "tokens": [400, 550, 382, 2321, 382, 291, 536, 11, 1954, 11, 586, 309, 311, 709, 3571, 281, 2903, 11], "temperature": 0.0, "avg_logprob": -0.17505760880203936, "compression_ratio": 1.680161943319838, "no_speech_prob": 2.3186521502793767e-05}, {"id": 1045, "seek": 409440, "start": 4098.4, "end": 4101.4, "text": " well, that's a pretty good sign that it's a good API, probably.", "tokens": [731, 11, 300, 311, 257, 1238, 665, 1465, 300, 309, 311, 257, 665, 9362, 11, 1391, 13], "temperature": 0.0, "avg_logprob": -0.17505760880203936, "compression_ratio": 1.680161943319838, "no_speech_prob": 2.3186521502793767e-05}, {"id": 1046, "seek": 409440, "start": 4101.4, "end": 4102.4, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.17505760880203936, "compression_ratio": 1.680161943319838, "no_speech_prob": 2.3186521502793767e-05}, {"id": 1047, "seek": 409440, "start": 4102.4, "end": 4108.4, "text": " Which for the same reason, that's why if you find yourself", "tokens": [3013, 337, 264, 912, 1778, 11, 300, 311, 983, 498, 291, 915, 1803], "temperature": 0.0, "avg_logprob": -0.17505760880203936, "compression_ratio": 1.680161943319838, "no_speech_prob": 2.3186521502793767e-05}, {"id": 1048, "seek": 409440, "start": 4108.4, "end": 4110.4, "text": " writing documentation, it can be a crutch", "tokens": [3579, 14333, 11, 309, 393, 312, 257, 941, 9349], "temperature": 0.0, "avg_logprob": -0.17505760880203936, "compression_ratio": 1.680161943319838, "no_speech_prob": 2.3186521502793767e-05}, {"id": 1049, "seek": 409440, "start": 4110.4, "end": 4114.4, "text": " because maybe you should have been documenting something.", "tokens": [570, 1310, 291, 820, 362, 668, 42360, 746, 13], "temperature": 0.0, "avg_logprob": -0.17505760880203936, "compression_ratio": 1.680161943319838, "no_speech_prob": 2.3186521502793767e-05}, {"id": 1050, "seek": 409440, "start": 4114.4, "end": 4117.4, "text": " Maybe a hard to explain concept,", "tokens": [2704, 257, 1152, 281, 2903, 3410, 11], "temperature": 0.0, "avg_logprob": -0.17505760880203936, "compression_ratio": 1.680161943319838, "no_speech_prob": 2.3186521502793767e-05}, {"id": 1051, "seek": 409440, "start": 4117.4, "end": 4119.4, "text": " maybe lots of documentation is a crutch", "tokens": [1310, 3195, 295, 14333, 307, 257, 941, 9349], "temperature": 0.0, "avg_logprob": -0.17505760880203936, "compression_ratio": 1.680161943319838, "no_speech_prob": 2.3186521502793767e-05}, {"id": 1052, "seek": 409440, "start": 4119.4, "end": 4122.4, "text": " for making the concept easier to understand,", "tokens": [337, 1455, 264, 3410, 3571, 281, 1223, 11], "temperature": 0.0, "avg_logprob": -0.17505760880203936, "compression_ratio": 1.680161943319838, "no_speech_prob": 2.3186521502793767e-05}, {"id": 1053, "seek": 412240, "start": 4122.4, "end": 4124.4, "text": " making the API simpler.", "tokens": [1455, 264, 9362, 18587, 13], "temperature": 0.0, "avg_logprob": -0.21830141279432508, "compression_ratio": 1.696035242290749, "no_speech_prob": 1.9333201635163277e-06}, {"id": 1054, "seek": 412240, "start": 4124.4, "end": 4128.4, "text": " So it should always be documentation should support something", "tokens": [407, 309, 820, 1009, 312, 14333, 820, 1406, 746], "temperature": 0.0, "avg_logprob": -0.21830141279432508, "compression_ratio": 1.696035242290749, "no_speech_prob": 1.9333201635163277e-06}, {"id": 1055, "seek": 412240, "start": 4128.4, "end": 4131.4, "text": " that's intuitive on its own, ideally.", "tokens": [300, 311, 21769, 322, 1080, 1065, 11, 22915, 13], "temperature": 0.0, "avg_logprob": -0.21830141279432508, "compression_ratio": 1.696035242290749, "no_speech_prob": 1.9333201635163277e-06}, {"id": 1056, "seek": 412240, "start": 4131.4, "end": 4135.4, "text": " And you're going to have the best time when you're always considering", "tokens": [400, 291, 434, 516, 281, 362, 264, 1151, 565, 562, 291, 434, 1009, 8079], "temperature": 0.0, "avg_logprob": -0.21830141279432508, "compression_ratio": 1.696035242290749, "no_speech_prob": 1.9333201635163277e-06}, {"id": 1057, "seek": 412240, "start": 4135.4, "end": 4137.4, "text": " changing something to make it simpler,", "tokens": [4473, 746, 281, 652, 309, 18587, 11], "temperature": 0.0, "avg_logprob": -0.21830141279432508, "compression_ratio": 1.696035242290749, "no_speech_prob": 1.9333201635163277e-06}, {"id": 1058, "seek": 412240, "start": 4137.4, "end": 4139.4, "text": " not just documenting what you already have.", "tokens": [406, 445, 42360, 437, 291, 1217, 362, 13], "temperature": 0.0, "avg_logprob": -0.21830141279432508, "compression_ratio": 1.696035242290749, "no_speech_prob": 1.9333201635163277e-06}, {"id": 1059, "seek": 412240, "start": 4139.4, "end": 4143.4, "text": " And when you count, then documentation makes sense.", "tokens": [400, 562, 291, 1207, 11, 550, 14333, 1669, 2020, 13], "temperature": 0.0, "avg_logprob": -0.21830141279432508, "compression_ratio": 1.696035242290749, "no_speech_prob": 1.9333201635163277e-06}, {"id": 1060, "seek": 412240, "start": 4143.4, "end": 4147.4, "text": " Like if something is done a specific way for performance", "tokens": [1743, 498, 746, 307, 1096, 257, 2685, 636, 337, 3389], "temperature": 0.0, "avg_logprob": -0.21830141279432508, "compression_ratio": 1.696035242290749, "no_speech_prob": 1.9333201635163277e-06}, {"id": 1061, "seek": 414740, "start": 4147.4, "end": 4152.4, "text": " or because there's a bug in some package, some other package,", "tokens": [420, 570, 456, 311, 257, 7426, 294, 512, 7372, 11, 512, 661, 7372, 11], "temperature": 0.0, "avg_logprob": -0.19963411353100305, "compression_ratio": 1.5781990521327014, "no_speech_prob": 1.0029804116129526e-06}, {"id": 1062, "seek": 414740, "start": 4152.4, "end": 4156.4, "text": " or the web browser doesn't work as you would expect,", "tokens": [420, 264, 3670, 11185, 1177, 380, 589, 382, 291, 576, 2066, 11], "temperature": 0.0, "avg_logprob": -0.19963411353100305, "compression_ratio": 1.5781990521327014, "no_speech_prob": 1.0029804116129526e-06}, {"id": 1063, "seek": 414740, "start": 4156.4, "end": 4160.4, "text": " then yeah, add the documentation comment that says,", "tokens": [550, 1338, 11, 909, 264, 14333, 2871, 300, 1619, 11], "temperature": 0.0, "avg_logprob": -0.19963411353100305, "compression_ratio": 1.5781990521327014, "no_speech_prob": 1.0029804116129526e-06}, {"id": 1064, "seek": 414740, "start": 4160.4, "end": 4164.4, "text": " this is the reason why something is this way.", "tokens": [341, 307, 264, 1778, 983, 746, 307, 341, 636, 13], "temperature": 0.0, "avg_logprob": -0.19963411353100305, "compression_ratio": 1.5781990521327014, "no_speech_prob": 1.0029804116129526e-06}, {"id": 1065, "seek": 414740, "start": 4164.4, "end": 4166.4, "text": " Right, right.", "tokens": [1779, 11, 558, 13], "temperature": 0.0, "avg_logprob": -0.19963411353100305, "compression_ratio": 1.5781990521327014, "no_speech_prob": 1.0029804116129526e-06}, {"id": 1066, "seek": 414740, "start": 4166.4, "end": 4169.4, "text": " Yeah, I always love the scene in the show Silicon Valley", "tokens": [865, 11, 286, 1009, 959, 264, 4145, 294, 264, 855, 25351, 10666], "temperature": 0.0, "avg_logprob": -0.19963411353100305, "compression_ratio": 1.5781990521327014, "no_speech_prob": 1.0029804116129526e-06}, {"id": 1067, "seek": 414740, "start": 4169.4, "end": 4173.4, "text": " when they're getting user feedback on the product", "tokens": [562, 436, 434, 1242, 4195, 5824, 322, 264, 1674], "temperature": 0.0, "avg_logprob": -0.19963411353100305, "compression_ratio": 1.5781990521327014, "no_speech_prob": 1.0029804116129526e-06}, {"id": 1068, "seek": 417340, "start": 4173.4, "end": 4178.4, "text": " and then the CEO is watching through this blind mirror thing", "tokens": [293, 550, 264, 9282, 307, 1976, 807, 341, 6865, 8013, 551], "temperature": 0.0, "avg_logprob": -0.21758699417114258, "compression_ratio": 1.6437768240343347, "no_speech_prob": 1.078208788385382e-05}, {"id": 1069, "seek": 417340, "start": 4178.4, "end": 4183.4, "text": " and watches the users in frustration improperly using the product", "tokens": [293, 17062, 264, 5022, 294, 20491, 40651, 356, 1228, 264, 1674], "temperature": 0.0, "avg_logprob": -0.21758699417114258, "compression_ratio": 1.6437768240343347, "no_speech_prob": 1.078208788385382e-05}, {"id": 1070, "seek": 417340, "start": 4183.4, "end": 4187.4, "text": " and he goes in and corrects them and tells them how they're all using it wrong.", "tokens": [293, 415, 1709, 294, 293, 3006, 82, 552, 293, 5112, 552, 577, 436, 434, 439, 1228, 309, 2085, 13], "temperature": 0.0, "avg_logprob": -0.21758699417114258, "compression_ratio": 1.6437768240343347, "no_speech_prob": 1.078208788385382e-05}, {"id": 1071, "seek": 417340, "start": 4187.4, "end": 4193.4, "text": " But of course, feedback is only as good as your willingness to listen to it.", "tokens": [583, 295, 1164, 11, 5824, 307, 787, 382, 665, 382, 428, 25069, 281, 2140, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.21758699417114258, "compression_ratio": 1.6437768240343347, "no_speech_prob": 1.078208788385382e-05}, {"id": 1072, "seek": 417340, "start": 4193.4, "end": 4198.4, "text": " So I think you, not that you should necessarily do directly", "tokens": [407, 286, 519, 291, 11, 406, 300, 291, 820, 4725, 360, 3838], "temperature": 0.0, "avg_logprob": -0.21758699417114258, "compression_ratio": 1.6437768240343347, "no_speech_prob": 1.078208788385382e-05}, {"id": 1073, "seek": 417340, "start": 4198.4, "end": 4200.4, "text": " what everybody tells you you should do.", "tokens": [437, 2201, 5112, 291, 291, 820, 360, 13], "temperature": 0.0, "avg_logprob": -0.21758699417114258, "compression_ratio": 1.6437768240343347, "no_speech_prob": 1.078208788385382e-05}, {"id": 1074, "seek": 420040, "start": 4200.4, "end": 4203.4, "text": " That's not the right answer either.", "tokens": [663, 311, 406, 264, 558, 1867, 2139, 13], "temperature": 0.0, "avg_logprob": -0.21967132724061303, "compression_ratio": 1.5657894736842106, "no_speech_prob": 4.6830697101540864e-05}, {"id": 1075, "seek": 420040, "start": 4203.4, "end": 4205.4, "text": " By the way, you should not listen to this episode.", "tokens": [3146, 264, 636, 11, 291, 820, 406, 2140, 281, 341, 3500, 13], "temperature": 0.0, "avg_logprob": -0.21967132724061303, "compression_ratio": 1.5657894736842106, "no_speech_prob": 4.6830697101540864e-05}, {"id": 1076, "seek": 420040, "start": 4205.4, "end": 4209.4, "text": " We only have garbage information.", "tokens": [492, 787, 362, 14150, 1589, 13], "temperature": 0.0, "avg_logprob": -0.21967132724061303, "compression_ratio": 1.5657894736842106, "no_speech_prob": 4.6830697101540864e-05}, {"id": 1077, "seek": 420040, "start": 4209.4, "end": 4211.4, "text": " So see ya.", "tokens": [407, 536, 2478, 13], "temperature": 0.0, "avg_logprob": -0.21967132724061303, "compression_ratio": 1.5657894736842106, "no_speech_prob": 4.6830697101540864e-05}, {"id": 1078, "seek": 420040, "start": 4211.4, "end": 4213.4, "text": " Right, exactly.", "tokens": [1779, 11, 2293, 13], "temperature": 0.0, "avg_logprob": -0.21967132724061303, "compression_ratio": 1.5657894736842106, "no_speech_prob": 4.6830697101540864e-05}, {"id": 1079, "seek": 420040, "start": 4213.4, "end": 4217.4, "text": " Yeah, but I mean, when you're getting feedback,", "tokens": [865, 11, 457, 286, 914, 11, 562, 291, 434, 1242, 5824, 11], "temperature": 0.0, "avg_logprob": -0.21967132724061303, "compression_ratio": 1.5657894736842106, "no_speech_prob": 4.6830697101540864e-05}, {"id": 1080, "seek": 420040, "start": 4217.4, "end": 4219.4, "text": " it's telling you something.", "tokens": [309, 311, 3585, 291, 746, 13], "temperature": 0.0, "avg_logprob": -0.21967132724061303, "compression_ratio": 1.5657894736842106, "no_speech_prob": 4.6830697101540864e-05}, {"id": 1081, "seek": 420040, "start": 4219.4, "end": 4224.4, "text": " And that's the fine line there is like understanding that", "tokens": [400, 300, 311, 264, 2489, 1622, 456, 307, 411, 3701, 300], "temperature": 0.0, "avg_logprob": -0.21967132724061303, "compression_ratio": 1.5657894736842106, "no_speech_prob": 4.6830697101540864e-05}, {"id": 1082, "seek": 420040, "start": 4224.4, "end": 4229.4, "text": " people are telling you pain points and hearing that they have a pain point.", "tokens": [561, 366, 3585, 291, 1822, 2793, 293, 4763, 300, 436, 362, 257, 1822, 935, 13], "temperature": 0.0, "avg_logprob": -0.21967132724061303, "compression_ratio": 1.5657894736842106, "no_speech_prob": 4.6830697101540864e-05}, {"id": 1083, "seek": 422940, "start": 4229.4, "end": 4231.4, "text": " If some people are trying to write documentation,", "tokens": [759, 512, 561, 366, 1382, 281, 2464, 14333, 11], "temperature": 0.0, "avg_logprob": -0.2511786701523255, "compression_ratio": 1.7896995708154506, "no_speech_prob": 8.348931442014873e-05}, {"id": 1084, "seek": 422940, "start": 4231.4, "end": 4236.4, "text": " I also have a few Elm Review rules that can be helpful for that.", "tokens": [286, 611, 362, 257, 1326, 2699, 76, 19954, 4474, 300, 393, 312, 4961, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.2511786701523255, "compression_ratio": 1.7896995708154506, "no_speech_prob": 8.348931442014873e-05}, {"id": 1085, "seek": 422940, "start": 4236.4, "end": 4242.4, "text": " So there's a package called jfmangles.com slash elmreview documentation,", "tokens": [407, 456, 311, 257, 7372, 1219, 361, 69, 76, 656, 904, 13, 1112, 17330, 806, 76, 265, 1759, 14333, 11], "temperature": 0.0, "avg_logprob": -0.2511786701523255, "compression_ratio": 1.7896995708154506, "no_speech_prob": 8.348931442014873e-05}, {"id": 1086, "seek": 422940, "start": 4242.4, "end": 4247.4, "text": " which has four rules, some more applicable to others than others.", "tokens": [597, 575, 1451, 4474, 11, 512, 544, 21142, 281, 2357, 813, 2357, 13], "temperature": 0.0, "avg_logprob": -0.2511786701523255, "compression_ratio": 1.7896995708154506, "no_speech_prob": 8.348931442014873e-05}, {"id": 1087, "seek": 422940, "start": 4247.4, "end": 4251.4, "text": " So there's one that is called docs.no missing, which we mentioned before,", "tokens": [407, 456, 311, 472, 300, 307, 1219, 45623, 13, 1771, 5361, 11, 597, 321, 2835, 949, 11], "temperature": 0.0, "avg_logprob": -0.2511786701523255, "compression_ratio": 1.7896995708154506, "no_speech_prob": 8.348931442014873e-05}, {"id": 1088, "seek": 422940, "start": 4251.4, "end": 4254.4, "text": " which reports missing or empty documentation.", "tokens": [597, 7122, 5361, 420, 6707, 14333, 13], "temperature": 0.0, "avg_logprob": -0.2511786701523255, "compression_ratio": 1.7896995708154506, "no_speech_prob": 8.348931442014873e-05}, {"id": 1089, "seek": 422940, "start": 4254.4, "end": 4257.4, "text": " So these rules can be used for application,", "tokens": [407, 613, 4474, 393, 312, 1143, 337, 3861, 11], "temperature": 0.0, "avg_logprob": -0.2511786701523255, "compression_ratio": 1.7896995708154506, "no_speech_prob": 8.348931442014873e-05}, {"id": 1090, "seek": 425740, "start": 4257.4, "end": 4260.4, "text": " but they can also be used for packages.", "tokens": [457, 436, 393, 611, 312, 1143, 337, 17401, 13], "temperature": 0.0, "avg_logprob": -0.1943141033774928, "compression_ratio": 1.6844106463878328, "no_speech_prob": 1.1658303264994174e-05}, {"id": 1091, "seek": 425740, "start": 4260.4, "end": 4265.4, "text": " And in this case, like for packages, it will report when it's missing,", "tokens": [400, 294, 341, 1389, 11, 411, 337, 17401, 11, 309, 486, 2275, 562, 309, 311, 5361, 11], "temperature": 0.0, "avg_logprob": -0.1943141033774928, "compression_ratio": 1.6844106463878328, "no_speech_prob": 1.1658303264994174e-05}, {"id": 1092, "seek": 425740, "start": 4265.4, "end": 4268.4, "text": " just like the Elm Compiler would, but it also reports empty documentation,", "tokens": [445, 411, 264, 2699, 76, 6620, 5441, 576, 11, 457, 309, 611, 7122, 6707, 14333, 11], "temperature": 0.0, "avg_logprob": -0.1943141033774928, "compression_ratio": 1.6844106463878328, "no_speech_prob": 1.1658303264994174e-05}, {"id": 1093, "seek": 425740, "start": 4268.4, "end": 4272.4, "text": " which I think is something we should try to avoid as much as possible.", "tokens": [597, 286, 519, 307, 746, 321, 820, 853, 281, 5042, 382, 709, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.1943141033774928, "compression_ratio": 1.6844106463878328, "no_speech_prob": 1.1658303264994174e-05}, {"id": 1094, "seek": 425740, "start": 4272.4, "end": 4275.4, "text": " I think you disagree with it sometimes.", "tokens": [286, 519, 291, 14091, 365, 309, 2171, 13], "temperature": 0.0, "avg_logprob": -0.1943141033774928, "compression_ratio": 1.6844106463878328, "no_speech_prob": 1.1658303264994174e-05}, {"id": 1095, "seek": 425740, "start": 4275.4, "end": 4280.4, "text": " I personally disagree with it for map two, map three, map four, map five.", "tokens": [286, 5665, 14091, 365, 309, 337, 4471, 732, 11, 4471, 1045, 11, 4471, 1451, 11, 4471, 1732, 13], "temperature": 0.0, "avg_logprob": -0.1943141033774928, "compression_ratio": 1.6844106463878328, "no_speech_prob": 1.1658303264994174e-05}, {"id": 1096, "seek": 425740, "start": 4280.4, "end": 4286.4, "text": " So my reasoning is that I see this quite often that people document map,", "tokens": [407, 452, 21577, 307, 300, 286, 536, 341, 1596, 2049, 300, 561, 4166, 4471, 11], "temperature": 0.0, "avg_logprob": -0.1943141033774928, "compression_ratio": 1.6844106463878328, "no_speech_prob": 1.1658303264994174e-05}, {"id": 1097, "seek": 428640, "start": 4286.4, "end": 4289.4, "text": " they document map two because it's more complex,", "tokens": [436, 4166, 4471, 732, 570, 309, 311, 544, 3997, 11], "temperature": 0.0, "avg_logprob": -0.20119897842407228, "compression_ratio": 1.8932038834951457, "no_speech_prob": 1.922103183460422e-05}, {"id": 1098, "seek": 428640, "start": 4289.4, "end": 4291.4, "text": " and then they don't document map three.", "tokens": [293, 550, 436, 500, 380, 4166, 4471, 1045, 13], "temperature": 0.0, "avg_logprob": -0.20119897842407228, "compression_ratio": 1.8932038834951457, "no_speech_prob": 1.922103183460422e-05}, {"id": 1099, "seek": 428640, "start": 4291.4, "end": 4296.4, "text": " So the documentation is empty and same for map five, et cetera.", "tokens": [407, 264, 14333, 307, 6707, 293, 912, 337, 4471, 1732, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.20119897842407228, "compression_ratio": 1.8932038834951457, "no_speech_prob": 1.922103183460422e-05}, {"id": 1100, "seek": 428640, "start": 4296.4, "end": 4301.4, "text": " And the thing is like your documentation can be found in the package documentation,", "tokens": [400, 264, 551, 307, 411, 428, 14333, 393, 312, 1352, 294, 264, 7372, 14333, 11], "temperature": 0.0, "avg_logprob": -0.20119897842407228, "compression_ratio": 1.8932038834951457, "no_speech_prob": 1.922103183460422e-05}, {"id": 1101, "seek": 428640, "start": 4301.4, "end": 4304.4, "text": " but it can also be found in the ID.", "tokens": [457, 309, 393, 611, 312, 1352, 294, 264, 7348, 13], "temperature": 0.0, "avg_logprob": -0.20119897842407228, "compression_ratio": 1.8932038834951457, "no_speech_prob": 1.922103183460422e-05}, {"id": 1102, "seek": 428640, "start": 4304.4, "end": 4311.4, "text": " And if you hover map two, you get a helpful documentation comment.", "tokens": [400, 498, 291, 20076, 4471, 732, 11, 291, 483, 257, 4961, 14333, 2871, 13], "temperature": 0.0, "avg_logprob": -0.20119897842407228, "compression_ratio": 1.8932038834951457, "no_speech_prob": 1.922103183460422e-05}, {"id": 1103, "seek": 428640, "start": 4311.4, "end": 4315.4, "text": " But if you hover map three, then you have nothing.", "tokens": [583, 498, 291, 20076, 4471, 1045, 11, 550, 291, 362, 1825, 13], "temperature": 0.0, "avg_logprob": -0.20119897842407228, "compression_ratio": 1.8932038834951457, "no_speech_prob": 1.922103183460422e-05}, {"id": 1104, "seek": 431540, "start": 4315.4, "end": 4318.4, "text": " And that's not very helpful in my opinion.", "tokens": [400, 300, 311, 406, 588, 4961, 294, 452, 4800, 13], "temperature": 0.0, "avg_logprob": -0.2247932954268022, "compression_ratio": 1.5731225296442688, "no_speech_prob": 4.860382887272863e-06}, {"id": 1105, "seek": 431540, "start": 4318.4, "end": 4325.4, "text": " So I would much rather have map three say refer to the documentation of map two.", "tokens": [407, 286, 576, 709, 2831, 362, 4471, 1045, 584, 2864, 281, 264, 14333, 295, 4471, 732, 13], "temperature": 0.0, "avg_logprob": -0.2247932954268022, "compression_ratio": 1.5731225296442688, "no_speech_prob": 4.860382887272863e-06}, {"id": 1106, "seek": 431540, "start": 4325.4, "end": 4326.4, "text": " Okay, nice.", "tokens": [1033, 11, 1481, 13], "temperature": 0.0, "avg_logprob": -0.2247932954268022, "compression_ratio": 1.5731225296442688, "no_speech_prob": 4.860382887272863e-06}, {"id": 1107, "seek": 431540, "start": 4326.4, "end": 4330.4, "text": " Because now you can just, you know where to look at.", "tokens": [1436, 586, 291, 393, 445, 11, 291, 458, 689, 281, 574, 412, 13], "temperature": 0.0, "avg_logprob": -0.2247932954268022, "compression_ratio": 1.5731225296442688, "no_speech_prob": 4.860382887272863e-06}, {"id": 1108, "seek": 431540, "start": 4330.4, "end": 4333.4, "text": " Potentially you can even click on it.", "tokens": [9145, 3137, 291, 393, 754, 2052, 322, 309, 13], "temperature": 0.0, "avg_logprob": -0.2247932954268022, "compression_ratio": 1.5731225296442688, "no_speech_prob": 4.860382887272863e-06}, {"id": 1109, "seek": 431540, "start": 4333.4, "end": 4337.4, "text": " So that's why it does not, no missing reports, empty documentation.", "tokens": [407, 300, 311, 983, 309, 775, 406, 11, 572, 5361, 7122, 11, 6707, 14333, 13], "temperature": 0.0, "avg_logprob": -0.2247932954268022, "compression_ratio": 1.5731225296442688, "no_speech_prob": 4.860382887272863e-06}, {"id": 1110, "seek": 431540, "start": 4337.4, "end": 4338.4, "text": " Oh, cool.", "tokens": [876, 11, 1627, 13], "temperature": 0.0, "avg_logprob": -0.2247932954268022, "compression_ratio": 1.5731225296442688, "no_speech_prob": 4.860382887272863e-06}, {"id": 1111, "seek": 431540, "start": 4338.4, "end": 4343.4, "text": " Maybe I could even make an Elm review rule to automatically do that for my map and functions.", "tokens": [2704, 286, 727, 754, 652, 364, 2699, 76, 3131, 4978, 281, 6772, 360, 300, 337, 452, 4471, 293, 6828, 13], "temperature": 0.0, "avg_logprob": -0.2247932954268022, "compression_ratio": 1.5731225296442688, "no_speech_prob": 4.860382887272863e-06}, {"id": 1112, "seek": 434340, "start": 4343.4, "end": 4346.4, "text": " Potentially, yeah, that'd be fine.", "tokens": [9145, 3137, 11, 1338, 11, 300, 1116, 312, 2489, 13], "temperature": 0.0, "avg_logprob": -0.22363080882062816, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.186310083146964e-07}, {"id": 1113, "seek": 434340, "start": 4346.4, "end": 4353.4, "text": " There's also a docs.review add docs rule, which is a bit of a weird name.", "tokens": [821, 311, 611, 257, 45623, 13, 265, 1759, 909, 45623, 4978, 11, 597, 307, 257, 857, 295, 257, 3657, 1315, 13], "temperature": 0.0, "avg_logprob": -0.22363080882062816, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.186310083146964e-07}, {"id": 1114, "seek": 434340, "start": 4353.4, "end": 4357.4, "text": " Yeah, but I use it and it's saved me in some situations.", "tokens": [865, 11, 457, 286, 764, 309, 293, 309, 311, 6624, 385, 294, 512, 6851, 13], "temperature": 0.0, "avg_logprob": -0.22363080882062816, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.186310083146964e-07}, {"id": 1115, "seek": 434340, "start": 4357.4, "end": 4359.4, "text": " So thank you for that.", "tokens": [407, 1309, 291, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.22363080882062816, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.186310083146964e-07}, {"id": 1116, "seek": 434340, "start": 4359.4, "end": 4363.4, "text": " So we mentioned the add docs annotations,", "tokens": [407, 321, 2835, 264, 909, 45623, 25339, 763, 11], "temperature": 0.0, "avg_logprob": -0.22363080882062816, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.186310083146964e-07}, {"id": 1117, "seek": 434340, "start": 4363.4, "end": 4367.4, "text": " and there are quite a few ways where you can use them", "tokens": [293, 456, 366, 1596, 257, 1326, 2098, 689, 291, 393, 764, 552], "temperature": 0.0, "avg_logprob": -0.22363080882062816, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.186310083146964e-07}, {"id": 1118, "seek": 434340, "start": 4367.4, "end": 4372.4, "text": " where the package documentation will not handle them correctly.", "tokens": [689, 264, 7372, 14333, 486, 406, 4813, 552, 8944, 13], "temperature": 0.0, "avg_logprob": -0.22363080882062816, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.186310083146964e-07}, {"id": 1119, "seek": 437240, "start": 4372.4, "end": 4376.4, "text": " Like that the compiler will usually tell you, hey, you're missing add docs", "tokens": [1743, 300, 264, 31958, 486, 2673, 980, 291, 11, 4177, 11, 291, 434, 5361, 909, 45623], "temperature": 0.0, "avg_logprob": -0.21395012767044538, "compression_ratio": 1.746606334841629, "no_speech_prob": 1.095203697332181e-05}, {"id": 1120, "seek": 437240, "start": 4376.4, "end": 4380.4, "text": " or you're having add docs that are not expected.", "tokens": [420, 291, 434, 1419, 909, 45623, 300, 366, 406, 5176, 13], "temperature": 0.0, "avg_logprob": -0.21395012767044538, "compression_ratio": 1.746606334841629, "no_speech_prob": 1.095203697332181e-05}, {"id": 1121, "seek": 437240, "start": 4380.4, "end": 4386.4, "text": " But this rule will also report those for when you use it in applications", "tokens": [583, 341, 4978, 486, 611, 2275, 729, 337, 562, 291, 764, 309, 294, 5821], "temperature": 0.0, "avg_logprob": -0.21395012767044538, "compression_ratio": 1.746606334841629, "no_speech_prob": 1.095203697332181e-05}, {"id": 1122, "seek": 437240, "start": 4386.4, "end": 4388.4, "text": " because the Elm compiler will not help you there.", "tokens": [570, 264, 2699, 76, 31958, 486, 406, 854, 291, 456, 13], "temperature": 0.0, "avg_logprob": -0.21395012767044538, "compression_ratio": 1.746606334841629, "no_speech_prob": 1.095203697332181e-05}, {"id": 1123, "seek": 437240, "start": 4388.4, "end": 4394.4, "text": " But there's also cases where, for instance, if you indent add docs", "tokens": [583, 456, 311, 611, 3331, 689, 11, 337, 5197, 11, 498, 291, 44494, 909, 45623], "temperature": 0.0, "avg_logprob": -0.21395012767044538, "compression_ratio": 1.746606334841629, "no_speech_prob": 1.095203697332181e-05}, {"id": 1124, "seek": 437240, "start": 4394.4, "end": 4399.4, "text": " or if you put it in at the very first line of your module documentation,", "tokens": [420, 498, 291, 829, 309, 294, 412, 264, 588, 700, 1622, 295, 428, 10088, 14333, 11], "temperature": 0.0, "avg_logprob": -0.21395012767044538, "compression_ratio": 1.746606334841629, "no_speech_prob": 1.095203697332181e-05}, {"id": 1125, "seek": 439940, "start": 4399.4, "end": 4403.4, "text": " then your docs will not look as expected.", "tokens": [550, 428, 45623, 486, 406, 574, 382, 5176, 13], "temperature": 0.0, "avg_logprob": -0.19089793175766148, "compression_ratio": 1.7098214285714286, "no_speech_prob": 1.341860661341343e-05}, {"id": 1126, "seek": 439940, "start": 4403.4, "end": 4413.4, "text": " So if your entire module documentation is the curly braces, whatever, add docs something,", "tokens": [407, 498, 428, 2302, 10088, 14333, 307, 264, 32066, 41537, 11, 2035, 11, 909, 45623, 746, 11], "temperature": 0.0, "avg_logprob": -0.19089793175766148, "compression_ratio": 1.7098214285714286, "no_speech_prob": 1.341860661341343e-05}, {"id": 1127, "seek": 439940, "start": 4413.4, "end": 4417.4, "text": " then that is literally what you will see, add docs something.", "tokens": [550, 300, 307, 3736, 437, 291, 486, 536, 11, 909, 45623, 746, 13], "temperature": 0.0, "avg_logprob": -0.19089793175766148, "compression_ratio": 1.7098214285714286, "no_speech_prob": 1.341860661341343e-05}, {"id": 1128, "seek": 439940, "start": 4417.4, "end": 4419.4, "text": " That's your entire documentation.", "tokens": [663, 311, 428, 2302, 14333, 13], "temperature": 0.0, "avg_logprob": -0.19089793175766148, "compression_ratio": 1.7098214285714286, "no_speech_prob": 1.341860661341343e-05}, {"id": 1129, "seek": 439940, "start": 4419.4, "end": 4424.4, "text": " And I've seen this over and over again, so I've made an Elm review rule that reports about those.", "tokens": [400, 286, 600, 1612, 341, 670, 293, 670, 797, 11, 370, 286, 600, 1027, 364, 2699, 76, 3131, 4978, 300, 7122, 466, 729, 13], "temperature": 0.0, "avg_logprob": -0.19089793175766148, "compression_ratio": 1.7098214285714286, "no_speech_prob": 1.341860661341343e-05}, {"id": 1130, "seek": 439940, "start": 4424.4, "end": 4427.4, "text": " And there's a few other gotchas that are similar to that.", "tokens": [400, 456, 311, 257, 1326, 661, 658, 41299, 300, 366, 2531, 281, 300, 13], "temperature": 0.0, "avg_logprob": -0.19089793175766148, "compression_ratio": 1.7098214285714286, "no_speech_prob": 1.341860661341343e-05}, {"id": 1131, "seek": 442740, "start": 4427.4, "end": 4430.4, "text": " Well, so like one of the ones that has saved me many times,", "tokens": [1042, 11, 370, 411, 472, 295, 264, 2306, 300, 575, 6624, 385, 867, 1413, 11], "temperature": 0.0, "avg_logprob": -0.20326196421747622, "compression_ratio": 1.611336032388664, "no_speech_prob": 1.4970702068239916e-05}, {"id": 1132, "seek": 442740, "start": 4430.4, "end": 4433.4, "text": " I actually wish that the IDE could do this for me automatically,", "tokens": [286, 767, 3172, 300, 264, 40930, 727, 360, 341, 337, 385, 6772, 11], "temperature": 0.0, "avg_logprob": -0.20326196421747622, "compression_ratio": 1.611336032388664, "no_speech_prob": 1.4970702068239916e-05}, {"id": 1133, "seek": 442740, "start": 4433.4, "end": 4439.4, "text": " but when I rename a module, I sometimes, most times, honestly,", "tokens": [457, 562, 286, 36741, 257, 10088, 11, 286, 2171, 11, 881, 1413, 11, 6095, 11], "temperature": 0.0, "avg_logprob": -0.20326196421747622, "compression_ratio": 1.611336032388664, "no_speech_prob": 1.4970702068239916e-05}, {"id": 1134, "seek": 442740, "start": 4439.4, "end": 4444.4, "text": " miss that in renaming my links within my docs.", "tokens": [1713, 300, 294, 8124, 5184, 452, 6123, 1951, 452, 45623, 13], "temperature": 0.0, "avg_logprob": -0.20326196421747622, "compression_ratio": 1.611336032388664, "no_speech_prob": 1.4970702068239916e-05}, {"id": 1135, "seek": 442740, "start": 4444.4, "end": 4446.4, "text": " And that Elm review rule catches it for me.", "tokens": [400, 300, 2699, 76, 3131, 4978, 25496, 309, 337, 385, 13], "temperature": 0.0, "avg_logprob": -0.20326196421747622, "compression_ratio": 1.611336032388664, "no_speech_prob": 1.4970702068239916e-05}, {"id": 1136, "seek": 442740, "start": 4446.4, "end": 4449.4, "text": " If it's pointing to a module which no longer exists, it catches that.", "tokens": [759, 309, 311, 12166, 281, 257, 10088, 597, 572, 2854, 8198, 11, 309, 25496, 300, 13], "temperature": 0.0, "avg_logprob": -0.20326196421747622, "compression_ratio": 1.611336032388664, "no_speech_prob": 1.4970702068239916e-05}, {"id": 1137, "seek": 442740, "start": 4449.4, "end": 4452.4, "text": " No, it doesn't. That's the third rule.", "tokens": [883, 11, 309, 1177, 380, 13, 663, 311, 264, 2636, 4978, 13], "temperature": 0.0, "avg_logprob": -0.20326196421747622, "compression_ratio": 1.611336032388664, "no_speech_prob": 1.4970702068239916e-05}, {"id": 1138, "seek": 442740, "start": 4452.4, "end": 4454.4, "text": " Okay, yes.", "tokens": [1033, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.20326196421747622, "compression_ratio": 1.611336032388664, "no_speech_prob": 1.4970702068239916e-05}, {"id": 1139, "seek": 445440, "start": 4454.4, "end": 4457.4, "text": " You're making a nice segue, at least.", "tokens": [509, 434, 1455, 257, 1481, 33850, 11, 412, 1935, 13], "temperature": 0.0, "avg_logprob": -0.23098218238959878, "compression_ratio": 1.7081545064377683, "no_speech_prob": 4.860171884502051e-06}, {"id": 1140, "seek": 445440, "start": 4457.4, "end": 4460.4, "text": " So that's docs.reviewlinksinsections.", "tokens": [407, 300, 311, 45623, 13, 265, 1759, 75, 16431, 259, 40329, 13], "temperature": 0.0, "avg_logprob": -0.23098218238959878, "compression_ratio": 1.7081545064377683, "no_speech_prob": 4.860171884502051e-06}, {"id": 1141, "seek": 445440, "start": 4460.4, "end": 4463.4, "text": " So that one is also very interesting.", "tokens": [407, 300, 472, 307, 611, 588, 1880, 13], "temperature": 0.0, "avg_logprob": -0.23098218238959878, "compression_ratio": 1.7081545064377683, "no_speech_prob": 4.860171884502051e-06}, {"id": 1142, "seek": 445440, "start": 4463.4, "end": 4468.4, "text": " As you say, you link from one module to another, from the README to another module.", "tokens": [1018, 291, 584, 11, 291, 2113, 490, 472, 10088, 281, 1071, 11, 490, 264, 10869, 6112, 15454, 281, 1071, 10088, 13], "temperature": 0.0, "avg_logprob": -0.23098218238959878, "compression_ratio": 1.7081545064377683, "no_speech_prob": 4.860171884502051e-06}, {"id": 1143, "seek": 445440, "start": 4468.4, "end": 4472.4, "text": " And yeah, if you rename something, then things are broken.", "tokens": [400, 1338, 11, 498, 291, 36741, 746, 11, 550, 721, 366, 5463, 13], "temperature": 0.0, "avg_logprob": -0.23098218238959878, "compression_ratio": 1.7081545064377683, "no_speech_prob": 4.860171884502051e-06}, {"id": 1144, "seek": 445440, "start": 4472.4, "end": 4474.4, "text": " Or if you make a typo, then things are broken,", "tokens": [1610, 498, 291, 652, 257, 2125, 78, 11, 550, 721, 366, 5463, 11], "temperature": 0.0, "avg_logprob": -0.23098218238959878, "compression_ratio": 1.7081545064377683, "no_speech_prob": 4.860171884502051e-06}, {"id": 1145, "seek": 445440, "start": 4474.4, "end": 4477.4, "text": " and you don't want your users to let you know about that.", "tokens": [293, 291, 500, 380, 528, 428, 5022, 281, 718, 291, 458, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.23098218238959878, "compression_ratio": 1.7081545064377683, "no_speech_prob": 4.860171884502051e-06}, {"id": 1146, "seek": 445440, "start": 4477.4, "end": 4480.4, "text": " So this rule lets you know about it.", "tokens": [407, 341, 4978, 6653, 291, 458, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.23098218238959878, "compression_ratio": 1.7081545064377683, "no_speech_prob": 4.860171884502051e-06}, {"id": 1147, "seek": 448040, "start": 4480.4, "end": 4484.4, "text": " It also reports the ambiguous links.", "tokens": [467, 611, 7122, 264, 39465, 6123, 13], "temperature": 0.0, "avg_logprob": -0.2504458608506601, "compression_ratio": 1.5229885057471264, "no_speech_prob": 4.092734343430493e-06}, {"id": 1148, "seek": 448040, "start": 4484.4, "end": 4490.4, "text": " So if you have a markdown section, so hashtag, hashtag, init,", "tokens": [407, 498, 291, 362, 257, 1491, 5093, 3541, 11, 370, 20379, 11, 20379, 11, 3157, 11], "temperature": 0.0, "avg_logprob": -0.2504458608506601, "compression_ratio": 1.5229885057471264, "no_speech_prob": 4.092734343430493e-06}, {"id": 1149, "seek": 448040, "start": 4490.4, "end": 4496.4, "text": " and you have a function called init, then they will have the same href?", "tokens": [293, 291, 362, 257, 2445, 1219, 3157, 11, 550, 436, 486, 362, 264, 912, 276, 33115, 30], "temperature": 0.0, "avg_logprob": -0.2504458608506601, "compression_ratio": 1.5229885057471264, "no_speech_prob": 4.092734343430493e-06}, {"id": 1150, "seek": 448040, "start": 4496.4, "end": 4501.4, "text": " Yeah. Name. I think it's like the name under the hood.", "tokens": [865, 13, 13866, 13, 286, 519, 309, 311, 411, 264, 1315, 833, 264, 13376, 13], "temperature": 0.0, "avg_logprob": -0.2504458608506601, "compression_ratio": 1.5229885057471264, "no_speech_prob": 4.092734343430493e-06}, {"id": 1151, "seek": 448040, "start": 4501.4, "end": 4503.4, "text": " The same anchor?", "tokens": [440, 912, 18487, 30], "temperature": 0.0, "avg_logprob": -0.2504458608506601, "compression_ratio": 1.5229885057471264, "no_speech_prob": 4.092734343430493e-06}, {"id": 1152, "seek": 448040, "start": 4503.4, "end": 4505.4, "text": " Name, attribute. Yeah.", "tokens": [13866, 11, 19667, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.2504458608506601, "compression_ratio": 1.5229885057471264, "no_speech_prob": 4.092734343430493e-06}, {"id": 1153, "seek": 450540, "start": 4505.4, "end": 4510.4, "text": " So whenever you will link to that, it will go to the first one.", "tokens": [407, 5699, 291, 486, 2113, 281, 300, 11, 309, 486, 352, 281, 264, 700, 472, 13], "temperature": 0.0, "avg_logprob": -0.20038187385785697, "compression_ratio": 1.5622119815668203, "no_speech_prob": 8.012581929506268e-06}, {"id": 1154, "seek": 450540, "start": 4510.4, "end": 4518.4, "text": " And you ideally want them to be different, like not ambiguous.", "tokens": [400, 291, 22915, 528, 552, 281, 312, 819, 11, 411, 406, 39465, 13], "temperature": 0.0, "avg_logprob": -0.20038187385785697, "compression_ratio": 1.5622119815668203, "no_speech_prob": 8.012581929506268e-06}, {"id": 1155, "seek": 450540, "start": 4518.4, "end": 4521.4, "text": " So this will also report that.", "tokens": [407, 341, 486, 611, 2275, 300, 13], "temperature": 0.0, "avg_logprob": -0.20038187385785697, "compression_ratio": 1.5622119815668203, "no_speech_prob": 8.012581929506268e-06}, {"id": 1156, "seek": 450540, "start": 4521.4, "end": 4523.4, "text": " I think that's the one that reports it.", "tokens": [286, 519, 300, 311, 264, 472, 300, 7122, 309, 13], "temperature": 0.0, "avg_logprob": -0.20038187385785697, "compression_ratio": 1.5622119815668203, "no_speech_prob": 8.012581929506268e-06}, {"id": 1157, "seek": 450540, "start": 4523.4, "end": 4525.4, "text": " But yeah, something reports it.", "tokens": [583, 1338, 11, 746, 7122, 309, 13], "temperature": 0.0, "avg_logprob": -0.20038187385785697, "compression_ratio": 1.5622119815668203, "no_speech_prob": 8.012581929506268e-06}, {"id": 1158, "seek": 450540, "start": 4525.4, "end": 4529.4, "text": " And then there's another one that is docs.uptodate.readmelinks,", "tokens": [400, 550, 456, 311, 1071, 472, 300, 307, 45623, 13, 84, 662, 378, 473, 13, 2538, 10909, 16431, 11], "temperature": 0.0, "avg_logprob": -0.20038187385785697, "compression_ratio": 1.5622119815668203, "no_speech_prob": 8.012581929506268e-06}, {"id": 1159, "seek": 450540, "start": 4529.4, "end": 4534.4, "text": " where the README is a bit of a peculiar file,", "tokens": [689, 264, 10869, 6112, 15454, 307, 257, 857, 295, 257, 27149, 3991, 11], "temperature": 0.0, "avg_logprob": -0.20038187385785697, "compression_ratio": 1.5622119815668203, "no_speech_prob": 8.012581929506268e-06}, {"id": 1160, "seek": 453440, "start": 4534.4, "end": 4539.4, "text": " because you can see it on GitHub, and you can see it on the package website.", "tokens": [570, 291, 393, 536, 309, 322, 23331, 11, 293, 291, 393, 536, 309, 322, 264, 7372, 3144, 13], "temperature": 0.0, "avg_logprob": -0.17409895016596869, "compression_ratio": 1.7117117117117118, "no_speech_prob": 4.538207213045098e-05}, {"id": 1161, "seek": 453440, "start": 4539.4, "end": 4544.4, "text": " And depending on how you do the links, they will be up-to-date or not up-to-date.", "tokens": [400, 5413, 322, 577, 291, 360, 264, 6123, 11, 436, 486, 312, 493, 12, 1353, 12, 17393, 420, 406, 493, 12, 1353, 12, 17393, 13], "temperature": 0.0, "avg_logprob": -0.17409895016596869, "compression_ratio": 1.7117117117117118, "no_speech_prob": 4.538207213045098e-05}, {"id": 1162, "seek": 453440, "start": 4544.4, "end": 4549.4, "text": " Usually what people do is they link to the package website from the README,", "tokens": [11419, 437, 561, 360, 307, 436, 2113, 281, 264, 7372, 3144, 490, 264, 10869, 6112, 15454, 11], "temperature": 0.0, "avg_logprob": -0.17409895016596869, "compression_ratio": 1.7117117117117118, "no_speech_prob": 4.538207213045098e-05}, {"id": 1163, "seek": 453440, "start": 4549.4, "end": 4554.4, "text": " and they use slash latest to specify the version, which works,", "tokens": [293, 436, 764, 17330, 6792, 281, 16500, 264, 3037, 11, 597, 1985, 11], "temperature": 0.0, "avg_logprob": -0.17409895016596869, "compression_ratio": 1.7117117117117118, "no_speech_prob": 4.538207213045098e-05}, {"id": 1164, "seek": 453440, "start": 4554.4, "end": 4557.4, "text": " but not once you release a new version.", "tokens": [457, 406, 1564, 291, 4374, 257, 777, 3037, 13], "temperature": 0.0, "avg_logprob": -0.17409895016596869, "compression_ratio": 1.7117117117117118, "no_speech_prob": 4.538207213045098e-05}, {"id": 1165, "seek": 453440, "start": 4557.4, "end": 4561.4, "text": " Now your previous version of your package,", "tokens": [823, 428, 3894, 3037, 295, 428, 7372, 11], "temperature": 0.0, "avg_logprob": -0.17409895016596869, "compression_ratio": 1.7117117117117118, "no_speech_prob": 4.538207213045098e-05}, {"id": 1166, "seek": 456140, "start": 4561.4, "end": 4567.4, "text": " the README will link to a function on the latest version,", "tokens": [264, 10869, 6112, 15454, 486, 2113, 281, 257, 2445, 322, 264, 6792, 3037, 11], "temperature": 0.0, "avg_logprob": -0.20683930795403976, "compression_ratio": 1.569060773480663, "no_speech_prob": 4.860385615756968e-06}, {"id": 1167, "seek": 456140, "start": 4567.4, "end": 4570.4, "text": " and that function might not exist anymore.", "tokens": [293, 300, 2445, 1062, 406, 2514, 3602, 13], "temperature": 0.0, "avg_logprob": -0.20683930795403976, "compression_ratio": 1.569060773480663, "no_speech_prob": 4.860385615756968e-06}, {"id": 1168, "seek": 456140, "start": 4570.4, "end": 4573.4, "text": " So that's a problem.", "tokens": [407, 300, 311, 257, 1154, 13], "temperature": 0.0, "avg_logprob": -0.20683930795403976, "compression_ratio": 1.569060773480663, "no_speech_prob": 4.860385615756968e-06}, {"id": 1169, "seek": 456140, "start": 4573.4, "end": 4580.4, "text": " So this helps replace those latest by the current version of your version", "tokens": [407, 341, 3665, 7406, 729, 6792, 538, 264, 2190, 3037, 295, 428, 3037], "temperature": 0.0, "avg_logprob": -0.20683930795403976, "compression_ratio": 1.569060773480663, "no_speech_prob": 4.860385615756968e-06}, {"id": 1170, "seek": 456140, "start": 4580.4, "end": 4582.4, "text": " defined in your Elm.json.", "tokens": [7642, 294, 428, 2699, 76, 13, 73, 3015, 13], "temperature": 0.0, "avg_logprob": -0.20683930795403976, "compression_ratio": 1.569060773480663, "no_speech_prob": 4.860385615756968e-06}, {"id": 1171, "seek": 456140, "start": 4582.4, "end": 4588.4, "text": " And whenever you upgrade your version, it will auto-fix those.", "tokens": [400, 5699, 291, 11484, 428, 3037, 11, 309, 486, 8399, 12, 69, 970, 729, 13], "temperature": 0.0, "avg_logprob": -0.20683930795403976, "compression_ratio": 1.569060773480663, "no_speech_prob": 4.860385615756968e-06}, {"id": 1172, "seek": 458840, "start": 4588.4, "end": 4594.4, "text": " So that's one reason that I have a very good time bumping the packages", "tokens": [407, 300, 311, 472, 1778, 300, 286, 362, 257, 588, 665, 565, 9961, 278, 264, 17401], "temperature": 0.0, "avg_logprob": -0.1832937013118639, "compression_ratio": 1.6864406779661016, "no_speech_prob": 1.2217822586535476e-05}, {"id": 1173, "seek": 458840, "start": 4594.4, "end": 4599.4, "text": " and keeping these links up-to-date is I bump the version, I run this rule,", "tokens": [293, 5145, 613, 6123, 493, 12, 1353, 12, 17393, 307, 286, 9961, 264, 3037, 11, 286, 1190, 341, 4978, 11], "temperature": 0.0, "avg_logprob": -0.1832937013118639, "compression_ratio": 1.6864406779661016, "no_speech_prob": 1.2217822586535476e-05}, {"id": 1174, "seek": 458840, "start": 4599.4, "end": 4601.4, "text": " and all my links are correct again.", "tokens": [293, 439, 452, 6123, 366, 3006, 797, 13], "temperature": 0.0, "avg_logprob": -0.1832937013118639, "compression_ratio": 1.6864406779661016, "no_speech_prob": 1.2217822586535476e-05}, {"id": 1175, "seek": 458840, "start": 4601.4, "end": 4603.4, "text": " And that's just very nice.", "tokens": [400, 300, 311, 445, 588, 1481, 13], "temperature": 0.0, "avg_logprob": -0.1832937013118639, "compression_ratio": 1.6864406779661016, "no_speech_prob": 1.2217822586535476e-05}, {"id": 1176, "seek": 458840, "start": 4603.4, "end": 4608.4, "text": " It's definitely an example of something that is the correct thing to do,", "tokens": [467, 311, 2138, 364, 1365, 295, 746, 300, 307, 264, 3006, 551, 281, 360, 11], "temperature": 0.0, "avg_logprob": -0.1832937013118639, "compression_ratio": 1.6864406779661016, "no_speech_prob": 1.2217822586535476e-05}, {"id": 1177, "seek": 458840, "start": 4608.4, "end": 4612.4, "text": " but in practice, without automation, something that people just would not do.", "tokens": [457, 294, 3124, 11, 1553, 17769, 11, 746, 300, 561, 445, 576, 406, 360, 13], "temperature": 0.0, "avg_logprob": -0.1832937013118639, "compression_ratio": 1.6864406779661016, "no_speech_prob": 1.2217822586535476e-05}, {"id": 1178, "seek": 458840, "start": 4612.4, "end": 4615.4, "text": " It wouldn't be tenable. So it's great.", "tokens": [467, 2759, 380, 312, 2064, 712, 13, 407, 309, 311, 869, 13], "temperature": 0.0, "avg_logprob": -0.1832937013118639, "compression_ratio": 1.6864406779661016, "no_speech_prob": 1.2217822586535476e-05}, {"id": 1179, "seek": 461540, "start": 4615.4, "end": 4619.4, "text": " Yeah, and I remember that before I made this rule, it was like,", "tokens": [865, 11, 293, 286, 1604, 300, 949, 286, 1027, 341, 4978, 11, 309, 390, 411, 11], "temperature": 0.0, "avg_logprob": -0.20015670839420036, "compression_ratio": 1.6509803921568627, "no_speech_prob": 7.64635387895396e-06}, {"id": 1180, "seek": 461540, "start": 4619.4, "end": 4623.4, "text": " well, what should we do? And there was no clear cut answer.", "tokens": [731, 11, 437, 820, 321, 360, 30, 400, 456, 390, 572, 1850, 1723, 1867, 13], "temperature": 0.0, "avg_logprob": -0.20015670839420036, "compression_ratio": 1.6509803921568627, "no_speech_prob": 7.64635387895396e-06}, {"id": 1181, "seek": 461540, "start": 4623.4, "end": 4626.4, "text": " So those are the four rules that are there.", "tokens": [407, 729, 366, 264, 1451, 4474, 300, 366, 456, 13], "temperature": 0.0, "avg_logprob": -0.20015670839420036, "compression_ratio": 1.6509803921568627, "no_speech_prob": 7.64635387895396e-06}, {"id": 1182, "seek": 461540, "start": 4626.4, "end": 4629.4, "text": " If you can think of another one, let me know.", "tokens": [759, 291, 393, 519, 295, 1071, 472, 11, 718, 385, 458, 13], "temperature": 0.0, "avg_logprob": -0.20015670839420036, "compression_ratio": 1.6509803921568627, "no_speech_prob": 7.64635387895396e-06}, {"id": 1183, "seek": 461540, "start": 4629.4, "end": 4632.4, "text": " I definitely think there are more things to be done.", "tokens": [286, 2138, 519, 456, 366, 544, 721, 281, 312, 1096, 13], "temperature": 0.0, "avg_logprob": -0.20015670839420036, "compression_ratio": 1.6509803921568627, "no_speech_prob": 7.64635387895396e-06}, {"id": 1184, "seek": 461540, "start": 4632.4, "end": 4638.4, "text": " Yeah, and I mean, also somewhat relevant would be the forbidden keywords, is it?", "tokens": [865, 11, 293, 286, 914, 11, 611, 8344, 7340, 576, 312, 264, 25990, 21009, 11, 307, 309, 30], "temperature": 0.0, "avg_logprob": -0.20015670839420036, "compression_ratio": 1.6509803921568627, "no_speech_prob": 7.64635387895396e-06}, {"id": 1185, "seek": 461540, "start": 4638.4, "end": 4641.4, "text": " For checking for things like to-dos.", "tokens": [1171, 8568, 337, 721, 411, 281, 12, 33749, 13], "temperature": 0.0, "avg_logprob": -0.20015670839420036, "compression_ratio": 1.6509803921568627, "no_speech_prob": 7.64635387895396e-06}, {"id": 1186, "seek": 461540, "start": 4641.4, "end": 4643.4, "text": " To-do or string, is that what it is?", "tokens": [1407, 12, 2595, 420, 6798, 11, 307, 300, 437, 309, 307, 30], "temperature": 0.0, "avg_logprob": -0.20015670839420036, "compression_ratio": 1.6509803921568627, "no_speech_prob": 7.64635387895396e-06}, {"id": 1187, "seek": 464340, "start": 4643.4, "end": 4646.4, "text": " To-do? No, that's different.", "tokens": [1407, 12, 2595, 30, 883, 11, 300, 311, 819, 13], "temperature": 0.0, "avg_logprob": -0.26388378384747085, "compression_ratio": 1.4594594594594594, "no_speech_prob": 2.177295391447842e-05}, {"id": 1188, "seek": 464340, "start": 4646.4, "end": 4651.4, "text": " Yeah, there's a package called sparksp.elmerview forbidden words", "tokens": [865, 11, 456, 311, 257, 7372, 1219, 44102, 79, 13, 338, 936, 1759, 25990, 2283], "temperature": 0.0, "avg_logprob": -0.26388378384747085, "compression_ratio": 1.4594594594594594, "no_speech_prob": 2.177295391447842e-05}, {"id": 1189, "seek": 464340, "start": 4651.4, "end": 4658.4, "text": " where you can tell it, please report all usages of to-do or replace me.", "tokens": [689, 291, 393, 980, 309, 11, 1767, 2275, 439, 505, 1660, 295, 281, 12, 2595, 420, 7406, 385, 13], "temperature": 0.0, "avg_logprob": -0.26388378384747085, "compression_ratio": 1.4594594594594594, "no_speech_prob": 2.177295391447842e-05}, {"id": 1190, "seek": 464340, "start": 4658.4, "end": 4662.4, "text": " And this is whenever you make an ElmerView package,", "tokens": [400, 341, 307, 5699, 291, 652, 364, 2699, 936, 30203, 7372, 11], "temperature": 0.0, "avg_logprob": -0.26388378384747085, "compression_ratio": 1.4594594594594594, "no_speech_prob": 2.177295391447842e-05}, {"id": 1191, "seek": 464340, "start": 4662.4, "end": 4667.4, "text": " you have this rule with replace me already in there.", "tokens": [291, 362, 341, 4978, 365, 7406, 385, 1217, 294, 456, 13], "temperature": 0.0, "avg_logprob": -0.26388378384747085, "compression_ratio": 1.4594594594594594, "no_speech_prob": 2.177295391447842e-05}, {"id": 1192, "seek": 466740, "start": 4667.4, "end": 4674.4, "text": " So whenever you try to write replace me as a placeholder for some documentation,", "tokens": [407, 5699, 291, 853, 281, 2464, 7406, 385, 382, 257, 1081, 20480, 337, 512, 14333, 11], "temperature": 0.0, "avg_logprob": -0.19699506326155228, "compression_ratio": 1.5, "no_speech_prob": 2.3319271349464543e-06}, {"id": 1193, "seek": 466740, "start": 4674.4, "end": 4678.4, "text": " for instance, this rule will at some point let you know,", "tokens": [337, 5197, 11, 341, 4978, 486, 412, 512, 935, 718, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.19699506326155228, "compression_ratio": 1.5, "no_speech_prob": 2.3319271349464543e-06}, {"id": 1194, "seek": 466740, "start": 4678.4, "end": 4682.4, "text": " hey, you should replace this.", "tokens": [4177, 11, 291, 820, 7406, 341, 13], "temperature": 0.0, "avg_logprob": -0.19699506326155228, "compression_ratio": 1.5, "no_speech_prob": 2.3319271349464543e-06}, {"id": 1195, "seek": 466740, "start": 4682.4, "end": 4684.4, "text": " So that's very useful as well.", "tokens": [407, 300, 311, 588, 4420, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.19699506326155228, "compression_ratio": 1.5, "no_speech_prob": 2.3319271349464543e-06}, {"id": 1196, "seek": 466740, "start": 4684.4, "end": 4688.4, "text": " Yeah, I also have a GitHub template called the ElmPackageStarter,", "tokens": [865, 11, 286, 611, 362, 257, 23331, 12379, 1219, 264, 2699, 76, 47, 501, 609, 4520, 13631, 11], "temperature": 0.0, "avg_logprob": -0.19699506326155228, "compression_ratio": 1.5, "no_speech_prob": 2.3319271349464543e-06}, {"id": 1197, "seek": 466740, "start": 4688.4, "end": 4692.4, "text": " and this uses most of these ElmReview rules,", "tokens": [293, 341, 4960, 881, 295, 613, 2699, 76, 8524, 1759, 4474, 11], "temperature": 0.0, "avg_logprob": -0.19699506326155228, "compression_ratio": 1.5, "no_speech_prob": 2.3319271349464543e-06}, {"id": 1198, "seek": 469240, "start": 4692.4, "end": 4697.4, "text": " and I've found it pretty nice for bootstrapping a quick Elm package.", "tokens": [293, 286, 600, 1352, 309, 1238, 1481, 337, 11450, 19639, 3759, 257, 1702, 2699, 76, 7372, 13], "temperature": 0.0, "avg_logprob": -0.18843093720993193, "compression_ratio": 1.5756302521008403, "no_speech_prob": 1.38448858706397e-05}, {"id": 1199, "seek": 469240, "start": 4697.4, "end": 4701.4, "text": " And it also links to a project of mine which we've talked about in the past,", "tokens": [400, 309, 611, 6123, 281, 257, 1716, 295, 3892, 597, 321, 600, 2825, 466, 294, 264, 1791, 11], "temperature": 0.0, "avg_logprob": -0.18843093720993193, "compression_ratio": 1.5756302521008403, "no_speech_prob": 1.38448858706397e-05}, {"id": 1200, "seek": 469240, "start": 4701.4, "end": 4705.4, "text": " the Idiomatic Elm Package Guide, which sort of lays out, I think,", "tokens": [264, 40187, 13143, 2699, 76, 18466, 609, 18727, 11, 597, 1333, 295, 32714, 484, 11, 286, 519, 11], "temperature": 0.0, "avg_logprob": -0.18843093720993193, "compression_ratio": 1.5756302521008403, "no_speech_prob": 1.38448858706397e-05}, {"id": 1201, "seek": 469240, "start": 4705.4, "end": 4710.4, "text": " a set of principles for how to organize your readme", "tokens": [257, 992, 295, 9156, 337, 577, 281, 13859, 428, 1401, 1398], "temperature": 0.0, "avg_logprob": -0.18843093720993193, "compression_ratio": 1.5756302521008403, "no_speech_prob": 1.38448858706397e-05}, {"id": 1202, "seek": 469240, "start": 4710.4, "end": 4716.4, "text": " and what format to manage a changelog and some boring but important things.", "tokens": [293, 437, 7877, 281, 3067, 257, 1534, 338, 664, 293, 512, 9989, 457, 1021, 721, 13], "temperature": 0.0, "avg_logprob": -0.18843093720993193, "compression_ratio": 1.5756302521008403, "no_speech_prob": 1.38448858706397e-05}, {"id": 1203, "seek": 469240, "start": 4716.4, "end": 4719.4, "text": " I think these are really important.", "tokens": [286, 519, 613, 366, 534, 1021, 13], "temperature": 0.0, "avg_logprob": -0.18843093720993193, "compression_ratio": 1.5756302521008403, "no_speech_prob": 1.38448858706397e-05}, {"id": 1204, "seek": 471940, "start": 4719.4, "end": 4724.4, "text": " Having a changelog, if you create a new version of a package,", "tokens": [10222, 257, 1534, 338, 664, 11, 498, 291, 1884, 257, 777, 3037, 295, 257, 7372, 11], "temperature": 0.0, "avg_logprob": -0.19069542547669074, "compression_ratio": 1.654320987654321, "no_speech_prob": 2.7967838832410052e-05}, {"id": 1205, "seek": 471940, "start": 4724.4, "end": 4727.4, "text": " people are going to be wondering what changed.", "tokens": [561, 366, 516, 281, 312, 6359, 437, 3105, 13], "temperature": 0.0, "avg_logprob": -0.19069542547669074, "compression_ratio": 1.654320987654321, "no_speech_prob": 2.7967838832410052e-05}, {"id": 1206, "seek": 471940, "start": 4727.4, "end": 4733.4, "text": " And having an obvious format that is something you would expect across packages.", "tokens": [400, 1419, 364, 6322, 7877, 300, 307, 746, 291, 576, 2066, 2108, 17401, 13], "temperature": 0.0, "avg_logprob": -0.19069542547669074, "compression_ratio": 1.654320987654321, "no_speech_prob": 2.7967838832410052e-05}, {"id": 1207, "seek": 471940, "start": 4733.4, "end": 4735.4, "text": " Same with an examples folder.", "tokens": [10635, 365, 364, 5110, 10820, 13], "temperature": 0.0, "avg_logprob": -0.19069542547669074, "compression_ratio": 1.654320987654321, "no_speech_prob": 2.7967838832410052e-05}, {"id": 1208, "seek": 471940, "start": 4735.4, "end": 4739.4, "text": " People in the Elm community, if they've kind of been around for a little while", "tokens": [3432, 294, 264, 2699, 76, 1768, 11, 498, 436, 600, 733, 295, 668, 926, 337, 257, 707, 1339], "temperature": 0.0, "avg_logprob": -0.19069542547669074, "compression_ratio": 1.654320987654321, "no_speech_prob": 2.7967838832410052e-05}, {"id": 1209, "seek": 471940, "start": 4739.4, "end": 4744.4, "text": " and seen some packages, they're probably going to expect the GitHub project", "tokens": [293, 1612, 512, 17401, 11, 436, 434, 1391, 516, 281, 2066, 264, 23331, 1716], "temperature": 0.0, "avg_logprob": -0.19069542547669074, "compression_ratio": 1.654320987654321, "no_speech_prob": 2.7967838832410052e-05}, {"id": 1210, "seek": 471940, "start": 4744.4, "end": 4746.4, "text": " to have an examples folder.", "tokens": [281, 362, 364, 5110, 10820, 13], "temperature": 0.0, "avg_logprob": -0.19069542547669074, "compression_ratio": 1.654320987654321, "no_speech_prob": 2.7967838832410052e-05}, {"id": 1211, "seek": 474640, "start": 4746.4, "end": 4753.4, "text": " They're probably going to expect to have a link to the package from the GitHub readme.", "tokens": [814, 434, 1391, 516, 281, 2066, 281, 362, 257, 2113, 281, 264, 7372, 490, 264, 23331, 1401, 1398, 13], "temperature": 0.0, "avg_logprob": -0.16164896565098916, "compression_ratio": 1.7268518518518519, "no_speech_prob": 1.6186628272407688e-05}, {"id": 1212, "seek": 474640, "start": 4753.4, "end": 4757.4, "text": " They're probably going to expect to have a test suite with a badge", "tokens": [814, 434, 1391, 516, 281, 2066, 281, 362, 257, 1500, 14205, 365, 257, 25797], "temperature": 0.0, "avg_logprob": -0.16164896565098916, "compression_ratio": 1.7268518518518519, "no_speech_prob": 1.6186628272407688e-05}, {"id": 1213, "seek": 474640, "start": 4757.4, "end": 4760.4, "text": " that shows whether the test suite is passing.", "tokens": [300, 3110, 1968, 264, 1500, 14205, 307, 8437, 13], "temperature": 0.0, "avg_logprob": -0.16164896565098916, "compression_ratio": 1.7268518518518519, "no_speech_prob": 1.6186628272407688e-05}, {"id": 1214, "seek": 474640, "start": 4760.4, "end": 4765.4, "text": " Some boring things like this that I think are worth having.", "tokens": [2188, 9989, 721, 411, 341, 300, 286, 519, 366, 3163, 1419, 13], "temperature": 0.0, "avg_logprob": -0.16164896565098916, "compression_ratio": 1.7268518518518519, "no_speech_prob": 1.6186628272407688e-05}, {"id": 1215, "seek": 474640, "start": 4765.4, "end": 4769.4, "text": " Yeah. By the way, the fact that you have the changelog", "tokens": [865, 13, 3146, 264, 636, 11, 264, 1186, 300, 291, 362, 264, 1534, 338, 664], "temperature": 0.0, "avg_logprob": -0.16164896565098916, "compression_ratio": 1.7268518518518519, "no_speech_prob": 1.6186628272407688e-05}, {"id": 1216, "seek": 474640, "start": 4769.4, "end": 4775.4, "text": " and sometimes the contributing instructions in the readme,", "tokens": [293, 2171, 264, 19270, 9415, 294, 264, 1401, 1398, 11], "temperature": 0.0, "avg_logprob": -0.16164896565098916, "compression_ratio": 1.7268518518518519, "no_speech_prob": 1.6186628272407688e-05}, {"id": 1217, "seek": 477540, "start": 4775.4, "end": 4780.4, "text": " that's something I see sometimes and I don't think that's the place for the readme.", "tokens": [300, 311, 746, 286, 536, 2171, 293, 286, 500, 380, 519, 300, 311, 264, 1081, 337, 264, 1401, 1398, 13], "temperature": 0.0, "avg_logprob": -0.2284547786901493, "compression_ratio": 1.6637554585152838, "no_speech_prob": 9.972491170628928e-06}, {"id": 1218, "seek": 477540, "start": 4780.4, "end": 4787.4, "text": " Especially because there are some standards where you have a file called changelog,", "tokens": [8545, 570, 456, 366, 512, 7787, 689, 291, 362, 257, 3991, 1219, 1534, 338, 664, 11], "temperature": 0.0, "avg_logprob": -0.2284547786901493, "compression_ratio": 1.6637554585152838, "no_speech_prob": 9.972491170628928e-06}, {"id": 1219, "seek": 477540, "start": 4787.4, "end": 4793.4, "text": " all caps, or usually all caps,.md, and one called contributing,", "tokens": [439, 13855, 11, 420, 2673, 439, 13855, 11, 2411, 76, 67, 11, 293, 472, 1219, 19270, 11], "temperature": 0.0, "avg_logprob": -0.2284547786901493, "compression_ratio": 1.6637554585152838, "no_speech_prob": 9.972491170628928e-06}, {"id": 1220, "seek": 477540, "start": 4793.4, "end": 4798.4, "text": " and there's also license and all those, plenty of other files like that.", "tokens": [293, 456, 311, 611, 10476, 293, 439, 729, 11, 7140, 295, 661, 7098, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.2284547786901493, "compression_ratio": 1.6637554585152838, "no_speech_prob": 9.972491170628928e-06}, {"id": 1221, "seek": 477540, "start": 4798.4, "end": 4802.4, "text": " Yes, and those are meaningful to GitHub and to Elm, to the Elm compiler too.", "tokens": [1079, 11, 293, 729, 366, 10995, 281, 23331, 293, 281, 2699, 76, 11, 281, 264, 2699, 76, 31958, 886, 13], "temperature": 0.0, "avg_logprob": -0.2284547786901493, "compression_ratio": 1.6637554585152838, "no_speech_prob": 9.972491170628928e-06}, {"id": 1222, "seek": 480240, "start": 4802.4, "end": 4805.4, "text": " So, the license file, for example, is required by Elm.", "tokens": [407, 11, 264, 10476, 3991, 11, 337, 1365, 11, 307, 4739, 538, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.2975486862325223, "compression_ratio": 1.6842105263157894, "no_speech_prob": 4.539533256320283e-05}, {"id": 1223, "seek": 480240, "start": 4805.4, "end": 4810.4, "text": " Yeah, I wouldn't like it if the changelog was maybe also special,", "tokens": [865, 11, 286, 2759, 380, 411, 309, 498, 264, 1534, 338, 664, 390, 1310, 611, 2121, 11], "temperature": 0.0, "avg_logprob": -0.2975486862325223, "compression_ratio": 1.6842105263157894, "no_speech_prob": 4.539533256320283e-05}, {"id": 1224, "seek": 480240, "start": 4810.4, "end": 4815.4, "text": " at least was linked to in the package documentation.", "tokens": [412, 1935, 390, 9408, 281, 294, 264, 7372, 14333, 13], "temperature": 0.0, "avg_logprob": -0.2975486862325223, "compression_ratio": 1.6842105263157894, "no_speech_prob": 4.539533256320283e-05}, {"id": 1225, "seek": 480240, "start": 4815.4, "end": 4819.4, "text": " Absolutely, yeah. And if you could, man, wouldn't that be cool", "tokens": [7021, 11, 1338, 13, 400, 498, 291, 727, 11, 587, 11, 2759, 380, 300, 312, 1627], "temperature": 0.0, "avg_logprob": -0.2975486862325223, "compression_ratio": 1.6842105263157894, "no_speech_prob": 4.539533256320283e-05}, {"id": 1226, "seek": 480240, "start": 4819.4, "end": 4826.4, "text": " if you could kind of show the Elm diff, if you could have some syntax for the changelog", "tokens": [498, 291, 727, 733, 295, 855, 264, 2699, 76, 7593, 11, 498, 291, 727, 362, 512, 28431, 337, 264, 1534, 338, 664], "temperature": 0.0, "avg_logprob": -0.2975486862325223, "compression_ratio": 1.6842105263157894, "no_speech_prob": 4.539533256320283e-05}, {"id": 1227, "seek": 480240, "start": 4826.4, "end": 4831.4, "text": " where you could say the breaking changes, because Elm diff,", "tokens": [689, 291, 727, 584, 264, 7697, 2962, 11, 570, 2699, 76, 7593, 11], "temperature": 0.0, "avg_logprob": -0.2975486862325223, "compression_ratio": 1.6842105263157894, "no_speech_prob": 4.539533256320283e-05}, {"id": 1228, "seek": 483140, "start": 4831.4, "end": 4834.4, "text": " when you do an Elm bump, it knows the breaking changes,", "tokens": [562, 291, 360, 364, 2699, 76, 9961, 11, 309, 3255, 264, 7697, 2962, 11], "temperature": 0.0, "avg_logprob": -0.19377162808277568, "compression_ratio": 1.696969696969697, "no_speech_prob": 3.5342494811629876e-05}, {"id": 1229, "seek": 483140, "start": 4834.4, "end": 4838.4, "text": " and if you could document how it changed or why it changed, that would be really cool.", "tokens": [293, 498, 291, 727, 4166, 577, 309, 3105, 420, 983, 309, 3105, 11, 300, 576, 312, 534, 1627, 13], "temperature": 0.0, "avg_logprob": -0.19377162808277568, "compression_ratio": 1.696969696969697, "no_speech_prob": 3.5342494811629876e-05}, {"id": 1230, "seek": 483140, "start": 4838.4, "end": 4843.4, "text": " Yeah, just being able to see the diff on the website, I guess,", "tokens": [865, 11, 445, 885, 1075, 281, 536, 264, 7593, 322, 264, 3144, 11, 286, 2041, 11], "temperature": 0.0, "avg_logprob": -0.19377162808277568, "compression_ratio": 1.696969696969697, "no_speech_prob": 3.5342494811629876e-05}, {"id": 1231, "seek": 483140, "start": 4843.4, "end": 4846.4, "text": " on the package website between two versions, that would be nice as well.", "tokens": [322, 264, 7372, 3144, 1296, 732, 9606, 11, 300, 576, 312, 1481, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.19377162808277568, "compression_ratio": 1.696969696969697, "no_speech_prob": 3.5342494811629876e-05}, {"id": 1232, "seek": 483140, "start": 4846.4, "end": 4851.4, "text": " Because often I see that a new package has been released on Slack", "tokens": [1436, 2049, 286, 536, 300, 257, 777, 7372, 575, 668, 4736, 322, 37211], "temperature": 0.0, "avg_logprob": -0.19377162808277568, "compression_ratio": 1.696969696969697, "no_speech_prob": 3.5342494811629876e-05}, {"id": 1233, "seek": 483140, "start": 4851.4, "end": 4854.4, "text": " and I watch it, I open it on my phone, and I'm like,", "tokens": [293, 286, 1159, 309, 11, 286, 1269, 309, 322, 452, 2593, 11, 293, 286, 478, 411, 11], "temperature": 0.0, "avg_logprob": -0.19377162808277568, "compression_ratio": 1.696969696969697, "no_speech_prob": 3.5342494811629876e-05}, {"id": 1234, "seek": 483140, "start": 4854.4, "end": 4858.4, "text": " oh, well, what has changed since the last version?", "tokens": [1954, 11, 731, 11, 437, 575, 3105, 1670, 264, 1036, 3037, 30], "temperature": 0.0, "avg_logprob": -0.19377162808277568, "compression_ratio": 1.696969696969697, "no_speech_prob": 3.5342494811629876e-05}, {"id": 1235, "seek": 485840, "start": 4858.4, "end": 4864.4, "text": " Well, let me open up my laptop and run Elm diff in a terminal.", "tokens": [1042, 11, 718, 385, 1269, 493, 452, 10732, 293, 1190, 2699, 76, 7593, 294, 257, 14709, 13], "temperature": 0.0, "avg_logprob": -0.2221426619696863, "compression_ratio": 1.617117117117117, "no_speech_prob": 5.093138497613836e-06}, {"id": 1236, "seek": 485840, "start": 4864.4, "end": 4868.4, "text": " Yeah, that is very useful, but it's not always a great experience.", "tokens": [865, 11, 300, 307, 588, 4420, 11, 457, 309, 311, 406, 1009, 257, 869, 1752, 13], "temperature": 0.0, "avg_logprob": -0.2221426619696863, "compression_ratio": 1.617117117117117, "no_speech_prob": 5.093138497613836e-06}, {"id": 1237, "seek": 485840, "start": 4868.4, "end": 4870.4, "text": " I'm not always on a computer.", "tokens": [286, 478, 406, 1009, 322, 257, 3820, 13], "temperature": 0.0, "avg_logprob": -0.2221426619696863, "compression_ratio": 1.617117117117117, "no_speech_prob": 5.093138497613836e-06}, {"id": 1238, "seek": 485840, "start": 4870.4, "end": 4874.4, "text": " So another thing that is not always clear cut is like,", "tokens": [407, 1071, 551, 300, 307, 406, 1009, 1850, 1723, 307, 411, 11], "temperature": 0.0, "avg_logprob": -0.2221426619696863, "compression_ratio": 1.617117117117117, "no_speech_prob": 5.093138497613836e-06}, {"id": 1239, "seek": 485840, "start": 4874.4, "end": 4879.4, "text": " what belongs in the package docs and what belongs in some external place,", "tokens": [437, 12953, 294, 264, 7372, 45623, 293, 437, 12953, 294, 512, 8320, 1081, 11], "temperature": 0.0, "avg_logprob": -0.2221426619696863, "compression_ratio": 1.617117117117117, "no_speech_prob": 5.093138497613836e-06}, {"id": 1240, "seek": 485840, "start": 4879.4, "end": 4886.4, "text": " either the readme, a separate document in GitHub, or an external site?", "tokens": [2139, 264, 1401, 1398, 11, 257, 4994, 4166, 294, 23331, 11, 420, 364, 8320, 3621, 30], "temperature": 0.0, "avg_logprob": -0.2221426619696863, "compression_ratio": 1.617117117117117, "no_speech_prob": 5.093138497613836e-06}, {"id": 1241, "seek": 488640, "start": 4886.4, "end": 4888.4, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2611214319864909, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.8924169125966728e-05}, {"id": 1242, "seek": 488640, "start": 4888.4, "end": 4895.4, "text": " Do you ever find reason for having something that's not included in the readme or the Elm package docs?", "tokens": [1144, 291, 1562, 915, 1778, 337, 1419, 746, 300, 311, 406, 5556, 294, 264, 1401, 1398, 420, 264, 2699, 76, 7372, 45623, 30], "temperature": 0.0, "avg_logprob": -0.2611214319864909, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.8924169125966728e-05}, {"id": 1243, "seek": 488640, "start": 4895.4, "end": 4900.4, "text": " Yeah. So Elm review, for instance, has...", "tokens": [865, 13, 407, 2699, 76, 3131, 11, 337, 5197, 11, 575, 485], "temperature": 0.0, "avg_logprob": -0.2611214319864909, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.8924169125966728e-05}, {"id": 1244, "seek": 488640, "start": 4900.4, "end": 4906.4, "text": " I say for instance, but all Elm packages are Elm review related.", "tokens": [286, 584, 337, 5197, 11, 457, 439, 2699, 76, 17401, 366, 2699, 76, 3131, 4077, 13], "temperature": 0.0, "avg_logprob": -0.2611214319864909, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.8924169125966728e-05}, {"id": 1245, "seek": 488640, "start": 4906.4, "end": 4910.4, "text": " Maybe one day I will have something else, but for now, they're all Elm review related.", "tokens": [2704, 472, 786, 286, 486, 362, 746, 1646, 11, 457, 337, 586, 11, 436, 434, 439, 2699, 76, 3131, 4077, 13], "temperature": 0.0, "avg_logprob": -0.2611214319864909, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.8924169125966728e-05}, {"id": 1246, "seek": 488640, "start": 4910.4, "end": 4912.4, "text": " Wow.", "tokens": [3153, 13], "temperature": 0.0, "avg_logprob": -0.2611214319864909, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.8924169125966728e-05}, {"id": 1247, "seek": 491240, "start": 4912.4, "end": 4916.4, "text": " After so many years of work, still only Elm review.", "tokens": [2381, 370, 867, 924, 295, 589, 11, 920, 787, 2699, 76, 3131, 13], "temperature": 0.0, "avg_logprob": -0.23321195329938615, "compression_ratio": 1.4090909090909092, "no_speech_prob": 2.88474366243463e-05}, {"id": 1248, "seek": 491240, "start": 4916.4, "end": 4918.4, "text": " Well, it's focus.", "tokens": [1042, 11, 309, 311, 1879, 13], "temperature": 0.0, "avg_logprob": -0.23321195329938615, "compression_ratio": 1.4090909090909092, "no_speech_prob": 2.88474366243463e-05}, {"id": 1249, "seek": 491240, "start": 4918.4, "end": 4923.4, "text": " Yeah, I guess. Well, and packages that I'm not maintaining.", "tokens": [865, 11, 286, 2041, 13, 1042, 11, 293, 17401, 300, 286, 478, 406, 14916, 13], "temperature": 0.0, "avg_logprob": -0.23321195329938615, "compression_ratio": 1.4090909090909092, "no_speech_prob": 2.88474366243463e-05}, {"id": 1250, "seek": 491240, "start": 4923.4, "end": 4933.4, "text": " So there is a document, for instance, for how to integrate Elm review into other places like IDs or bots or something.", "tokens": [407, 456, 307, 257, 4166, 11, 337, 5197, 11, 337, 577, 281, 13365, 2699, 76, 3131, 666, 661, 3190, 411, 48212, 420, 35410, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.23321195329938615, "compression_ratio": 1.4090909090909092, "no_speech_prob": 2.88474366243463e-05}, {"id": 1251, "seek": 493340, "start": 4933.4, "end": 4942.4, "text": " So there's a documentation that describes how the CLI outputs some format that can be understood by computers.", "tokens": [407, 456, 311, 257, 14333, 300, 15626, 577, 264, 12855, 40, 23930, 512, 7877, 300, 393, 312, 7320, 538, 10807, 13], "temperature": 0.0, "avg_logprob": -0.19667872260598576, "compression_ratio": 1.532258064516129, "no_speech_prob": 3.904852746927645e-06}, {"id": 1252, "seek": 493340, "start": 4942.4, "end": 4947.4, "text": " And that is not relevant to the API.", "tokens": [400, 300, 307, 406, 7340, 281, 264, 9362, 13], "temperature": 0.0, "avg_logprob": -0.19667872260598576, "compression_ratio": 1.532258064516129, "no_speech_prob": 3.904852746927645e-06}, {"id": 1253, "seek": 493340, "start": 4947.4, "end": 4959.4, "text": " So the Elm review package, the Elm package is meant to be used by people who write rules or who configure their Elm review configuration.", "tokens": [407, 264, 2699, 76, 3131, 7372, 11, 264, 2699, 76, 7372, 307, 4140, 281, 312, 1143, 538, 561, 567, 2464, 4474, 420, 567, 22162, 641, 2699, 76, 3131, 11694, 13], "temperature": 0.0, "avg_logprob": -0.19667872260598576, "compression_ratio": 1.532258064516129, "no_speech_prob": 3.904852746927645e-06}, {"id": 1254, "seek": 495940, "start": 4959.4, "end": 4963.4, "text": " Everything else makes little sense.", "tokens": [5471, 1646, 1669, 707, 2020, 13], "temperature": 0.0, "avg_logprob": -0.18304899549975837, "compression_ratio": 1.5884773662551441, "no_speech_prob": 1.6699099433026277e-05}, {"id": 1255, "seek": 495940, "start": 4963.4, "end": 4969.4, "text": " There's still like all the how to get started, how to configure, how to install Elm review,", "tokens": [821, 311, 920, 411, 439, 264, 577, 281, 483, 1409, 11, 577, 281, 22162, 11, 577, 281, 3625, 2699, 76, 3131, 11], "temperature": 0.0, "avg_logprob": -0.18304899549975837, "compression_ratio": 1.5884773662551441, "no_speech_prob": 1.6699099433026277e-05}, {"id": 1256, "seek": 495940, "start": 4969.4, "end": 4974.4, "text": " which is like an additional section because there's some NPM involved.", "tokens": [597, 307, 411, 364, 4497, 3541, 570, 456, 311, 512, 426, 18819, 3288, 13], "temperature": 0.0, "avg_logprob": -0.18304899549975837, "compression_ratio": 1.5884773662551441, "no_speech_prob": 1.6699099433026277e-05}, {"id": 1257, "seek": 495940, "start": 4974.4, "end": 4978.4, "text": " But yeah, I think there are some cases where you will need other things.", "tokens": [583, 1338, 11, 286, 519, 456, 366, 512, 3331, 689, 291, 486, 643, 661, 721, 13], "temperature": 0.0, "avg_logprob": -0.18304899549975837, "compression_ratio": 1.5884773662551441, "no_speech_prob": 1.6699099433026277e-05}, {"id": 1258, "seek": 495940, "start": 4978.4, "end": 4987.4, "text": " The main one that I can think of, and that does not necessarily fit the Elm package website very well, is a guide.", "tokens": [440, 2135, 472, 300, 286, 393, 519, 295, 11, 293, 300, 775, 406, 4725, 3318, 264, 2699, 76, 7372, 3144, 588, 731, 11, 307, 257, 5934, 13], "temperature": 0.0, "avg_logprob": -0.18304899549975837, "compression_ratio": 1.5884773662551441, "no_speech_prob": 1.6699099433026277e-05}, {"id": 1259, "seek": 498740, "start": 4987.4, "end": 4996.4, "text": " And that's something you hear sometimes as well on the Elm Slack, is that people see the Elm guide and then they wonder,", "tokens": [400, 300, 311, 746, 291, 1568, 2171, 382, 731, 322, 264, 2699, 76, 37211, 11, 307, 300, 561, 536, 264, 2699, 76, 5934, 293, 550, 436, 2441, 11], "temperature": 0.0, "avg_logprob": -0.21472825759496444, "compression_ratio": 1.6084656084656084, "no_speech_prob": 2.7105585104436614e-05}, {"id": 1260, "seek": 498740, "start": 4996.4, "end": 5002.4, "text": " oh, well, how do I learn more or how do I know which functions exist?", "tokens": [1954, 11, 731, 11, 577, 360, 286, 1466, 544, 420, 577, 360, 286, 458, 597, 6828, 2514, 30], "temperature": 0.0, "avg_logprob": -0.21472825759496444, "compression_ratio": 1.6084656084656084, "no_speech_prob": 2.7105585104436614e-05}, {"id": 1261, "seek": 498740, "start": 5002.4, "end": 5010.4, "text": " And we kind of assume that they went to the package website and look at Elm core or they looked at other packages", "tokens": [400, 321, 733, 295, 6552, 300, 436, 1437, 281, 264, 7372, 3144, 293, 574, 412, 2699, 76, 4965, 420, 436, 2956, 412, 661, 17401], "temperature": 0.0, "avg_logprob": -0.21472825759496444, "compression_ratio": 1.6084656084656084, "no_speech_prob": 2.7105585104436614e-05}, {"id": 1262, "seek": 501040, "start": 5010.4, "end": 5017.4, "text": " and then know how to read that package website, which is a given once you've got some experience with it.", "tokens": [293, 550, 458, 577, 281, 1401, 300, 7372, 3144, 11, 597, 307, 257, 2212, 1564, 291, 600, 658, 512, 1752, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.2099750836690267, "compression_ratio": 1.6187845303867403, "no_speech_prob": 1.1298998288111761e-05}, {"id": 1263, "seek": 501040, "start": 5017.4, "end": 5027.4, "text": " But like sometimes you want to know about the About tab or About page on a package and that has some relevant information.", "tokens": [583, 411, 2171, 291, 528, 281, 458, 466, 264, 7769, 4421, 420, 7769, 3028, 322, 257, 7372, 293, 300, 575, 512, 7340, 1589, 13], "temperature": 0.0, "avg_logprob": -0.2099750836690267, "compression_ratio": 1.6187845303867403, "no_speech_prob": 1.1298998288111761e-05}, {"id": 1264, "seek": 501040, "start": 5027.4, "end": 5033.4, "text": " But if you haven't browsed around, then you don't know about it.", "tokens": [583, 498, 291, 2378, 380, 8333, 292, 926, 11, 550, 291, 500, 380, 458, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.2099750836690267, "compression_ratio": 1.6187845303867403, "no_speech_prob": 1.1298998288111761e-05}, {"id": 1265, "seek": 503340, "start": 5033.4, "end": 5044.4, "text": " So yeah, having like the Elm package websites with all the API plus a way to write a guide, that would be pretty nice.", "tokens": [407, 1338, 11, 1419, 411, 264, 2699, 76, 7372, 12891, 365, 439, 264, 9362, 1804, 257, 636, 281, 2464, 257, 5934, 11, 300, 576, 312, 1238, 1481, 13], "temperature": 0.0, "avg_logprob": -0.19811800638834634, "compression_ratio": 1.469387755102041, "no_speech_prob": 7.570928346467554e-07}, {"id": 1266, "seek": 503340, "start": 5044.4, "end": 5052.4, "text": " So for instance, for Elm review, there's a lot of things that I try to teach that are not necessarily related to the API.", "tokens": [407, 337, 5197, 11, 337, 2699, 76, 3131, 11, 456, 311, 257, 688, 295, 721, 300, 286, 853, 281, 2924, 300, 366, 406, 4725, 4077, 281, 264, 9362, 13], "temperature": 0.0, "avg_logprob": -0.19811800638834634, "compression_ratio": 1.469387755102041, "no_speech_prob": 7.570928346467554e-07}, {"id": 1267, "seek": 503340, "start": 5052.4, "end": 5057.4, "text": " And that's why my documentation is really long.", "tokens": [400, 300, 311, 983, 452, 14333, 307, 534, 938, 13], "temperature": 0.0, "avg_logprob": -0.19811800638834634, "compression_ratio": 1.469387755102041, "no_speech_prob": 7.570928346467554e-07}, {"id": 1268, "seek": 505740, "start": 5057.4, "end": 5065.4, "text": " Can you think of an example? Like would it be conceptually how an Elm review, how it traverses things with visitors or something like that?", "tokens": [1664, 291, 519, 295, 364, 1365, 30, 1743, 576, 309, 312, 3410, 671, 577, 364, 2699, 76, 3131, 11, 577, 309, 23149, 279, 721, 365, 14315, 420, 746, 411, 300, 30], "temperature": 0.0, "avg_logprob": -0.18979250512472012, "compression_ratio": 1.6194690265486726, "no_speech_prob": 9.222228982253e-06}, {"id": 1269, "seek": 505740, "start": 5065.4, "end": 5071.4, "text": " Potentially, yeah, that's an implementation detail that would be worth explaining somewhere.", "tokens": [9145, 3137, 11, 1338, 11, 300, 311, 364, 11420, 2607, 300, 576, 312, 3163, 13468, 4079, 13], "temperature": 0.0, "avg_logprob": -0.18979250512472012, "compression_ratio": 1.6194690265486726, "no_speech_prob": 9.222228982253e-06}, {"id": 1270, "seek": 505740, "start": 5071.4, "end": 5081.4, "text": " So for instance, if you want to explain like performance considerations, like you should use this function this way and not this way,", "tokens": [407, 337, 5197, 11, 498, 291, 528, 281, 2903, 411, 3389, 24070, 11, 411, 291, 820, 764, 341, 2445, 341, 636, 293, 406, 341, 636, 11], "temperature": 0.0, "avg_logprob": -0.18979250512472012, "compression_ratio": 1.6194690265486726, "no_speech_prob": 9.222228982253e-06}, {"id": 1271, "seek": 508140, "start": 5081.4, "end": 5090.4, "text": " or you should have this architecture, then if that doesn't fit specifically with one function, then or in one module,", "tokens": [420, 291, 820, 362, 341, 9482, 11, 550, 498, 300, 1177, 380, 3318, 4682, 365, 472, 2445, 11, 550, 420, 294, 472, 10088, 11], "temperature": 0.0, "avg_logprob": -0.19470937284704756, "compression_ratio": 1.5837837837837838, "no_speech_prob": 1.320309911534423e-05}, {"id": 1272, "seek": 508140, "start": 5090.4, "end": 5094.4, "text": " then it's a bit hard to know where to place it.", "tokens": [550, 309, 311, 257, 857, 1152, 281, 458, 689, 281, 1081, 309, 13], "temperature": 0.0, "avg_logprob": -0.19470937284704756, "compression_ratio": 1.5837837837837838, "no_speech_prob": 1.320309911534423e-05}, {"id": 1273, "seek": 508140, "start": 5094.4, "end": 5104.4, "text": " Also, just like guidelines on how to make great rules is at the beginning of the review the rule module, which is the main one.", "tokens": [2743, 11, 445, 411, 12470, 322, 577, 281, 652, 869, 4474, 307, 412, 264, 2863, 295, 264, 3131, 264, 4978, 10088, 11, 597, 307, 264, 2135, 472, 13], "temperature": 0.0, "avg_logprob": -0.19470937284704756, "compression_ratio": 1.5837837837837838, "no_speech_prob": 1.320309911534423e-05}, {"id": 1274, "seek": 510440, "start": 5104.4, "end": 5113.4, "text": " But like it could be its own page, right? And also, for instance, like if you have a guide, then you can actually do a tutorial,", "tokens": [583, 411, 309, 727, 312, 1080, 1065, 3028, 11, 558, 30, 400, 611, 11, 337, 5197, 11, 411, 498, 291, 362, 257, 5934, 11, 550, 291, 393, 767, 360, 257, 7073, 11], "temperature": 0.0, "avg_logprob": -0.21336239640430738, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.01425301990821e-06}, {"id": 1275, "seek": 510440, "start": 5113.4, "end": 5121.4, "text": " which I kind of try to do. And this is kind of why I say like, write your own story, because I'm in a way making a tutorial,", "tokens": [597, 286, 733, 295, 853, 281, 360, 13, 400, 341, 307, 733, 295, 983, 286, 584, 411, 11, 2464, 428, 1065, 1657, 11, 570, 286, 478, 294, 257, 636, 1455, 257, 7073, 11], "temperature": 0.0, "avg_logprob": -0.21336239640430738, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.01425301990821e-06}, {"id": 1276, "seek": 510440, "start": 5121.4, "end": 5129.4, "text": " but maybe the way that the docs have rendered, it doesn't always make for the greatest experience.", "tokens": [457, 1310, 264, 636, 300, 264, 45623, 362, 28748, 11, 309, 1177, 380, 1009, 652, 337, 264, 6636, 1752, 13], "temperature": 0.0, "avg_logprob": -0.21336239640430738, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.01425301990821e-06}, {"id": 1277, "seek": 512940, "start": 5129.4, "end": 5136.4, "text": " But if I did not have to write all the API in the same page, then I would write it differently. And I would probably.", "tokens": [583, 498, 286, 630, 406, 362, 281, 2464, 439, 264, 9362, 294, 264, 912, 3028, 11, 550, 286, 576, 2464, 309, 7614, 13, 400, 286, 576, 1391, 13], "temperature": 0.0, "avg_logprob": -0.2146581970484911, "compression_ratio": 1.7084870848708487, "no_speech_prob": 2.976811992994044e-05}, {"id": 1278, "seek": 512940, "start": 5136.4, "end": 5146.4, "text": " Yeah, I like the way you're framing that. I mean, I think like the example of performance tuning, a review rule or something like that is,", "tokens": [865, 11, 286, 411, 264, 636, 291, 434, 28971, 300, 13, 286, 914, 11, 286, 519, 411, 264, 1365, 295, 3389, 15164, 11, 257, 3131, 4978, 420, 746, 411, 300, 307, 11], "temperature": 0.0, "avg_logprob": -0.2146581970484911, "compression_ratio": 1.7084870848708487, "no_speech_prob": 2.976811992994044e-05}, {"id": 1279, "seek": 512940, "start": 5146.4, "end": 5151.4, "text": " in that case, it gets to the point you were making earlier about who's the audience.", "tokens": [294, 300, 1389, 11, 309, 2170, 281, 264, 935, 291, 645, 1455, 3071, 466, 567, 311, 264, 4034, 13], "temperature": 0.0, "avg_logprob": -0.2146581970484911, "compression_ratio": 1.7084870848708487, "no_speech_prob": 2.976811992994044e-05}, {"id": 1280, "seek": 512940, "start": 5151.4, "end": 5158.4, "text": " And, you know, the audience for very low level details of some JSON format of something is different than the audience of", "tokens": [400, 11, 291, 458, 11, 264, 4034, 337, 588, 2295, 1496, 4365, 295, 512, 31828, 7877, 295, 746, 307, 819, 813, 264, 4034, 295], "temperature": 0.0, "avg_logprob": -0.2146581970484911, "compression_ratio": 1.7084870848708487, "no_speech_prob": 2.976811992994044e-05}, {"id": 1281, "seek": 515840, "start": 5158.4, "end": 5168.4, "text": " how do I write a review rule? Maybe I want to make sure I'm using this internal API in our application in a particular way.", "tokens": [577, 360, 286, 2464, 257, 3131, 4978, 30, 2704, 286, 528, 281, 652, 988, 286, 478, 1228, 341, 6920, 9362, 294, 527, 3861, 294, 257, 1729, 636, 13], "temperature": 0.0, "avg_logprob": -0.1928565161568778, "compression_ratio": 1.4978723404255319, "no_speech_prob": 1.6441927073174156e-05}, {"id": 1282, "seek": 515840, "start": 5168.4, "end": 5176.4, "text": " Well, I don't really care about performance, these performance considerations or this low level JSON format right now.", "tokens": [1042, 11, 286, 500, 380, 534, 1127, 466, 3389, 11, 613, 3389, 24070, 420, 341, 2295, 1496, 31828, 7877, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.1928565161568778, "compression_ratio": 1.4978723404255319, "no_speech_prob": 1.6441927073174156e-05}, {"id": 1283, "seek": 515840, "start": 5176.4, "end": 5183.4, "text": " So it's a different audience. And you don't want to lump all those together. It's going to be very confusing.", "tokens": [407, 309, 311, 257, 819, 4034, 13, 400, 291, 500, 380, 528, 281, 25551, 439, 729, 1214, 13, 467, 311, 516, 281, 312, 588, 13181, 13], "temperature": 0.0, "avg_logprob": -0.1928565161568778, "compression_ratio": 1.4978723404255319, "no_speech_prob": 1.6441927073174156e-05}, {"id": 1284, "seek": 518340, "start": 5183.4, "end": 5193.4, "text": " I think maybe if the package websites just picked up on like all the markdown files in a documentation folder or something like that,", "tokens": [286, 519, 1310, 498, 264, 7372, 12891, 445, 6183, 493, 322, 411, 439, 264, 1491, 5093, 7098, 294, 257, 14333, 10820, 420, 746, 411, 300, 11], "temperature": 0.0, "avg_logprob": -0.2930904670997902, "compression_ratio": 1.5495495495495495, "no_speech_prob": 2.5865190764307044e-05}, {"id": 1285, "seek": 518340, "start": 5193.4, "end": 5199.4, "text": " or something that is explicitly defined in the Elm JSON file, that could work very well.", "tokens": [420, 746, 300, 307, 20803, 7642, 294, 264, 2699, 76, 31828, 3991, 11, 300, 727, 589, 588, 731, 13], "temperature": 0.0, "avg_logprob": -0.2930904670997902, "compression_ratio": 1.5495495495495495, "no_speech_prob": 2.5865190764307044e-05}, {"id": 1286, "seek": 518340, "start": 5199.4, "end": 5208.4, "text": " Yeah, George Borges has talked about this idea with, you know, Elmbook and his inspiration from the Elixir documentation,", "tokens": [865, 11, 7136, 13739, 2880, 575, 2825, 466, 341, 1558, 365, 11, 291, 458, 11, 2699, 76, 2939, 293, 702, 10249, 490, 264, 2699, 970, 347, 14333, 11], "temperature": 0.0, "avg_logprob": -0.2930904670997902, "compression_ratio": 1.5495495495495495, "no_speech_prob": 2.5865190764307044e-05}, {"id": 1287, "seek": 520840, "start": 5208.4, "end": 5216.4, "text": " where they have both API documentation and sort of guides or markdown pages side by side.", "tokens": [689, 436, 362, 1293, 9362, 14333, 293, 1333, 295, 17007, 420, 1491, 5093, 7183, 1252, 538, 1252, 13], "temperature": 0.0, "avg_logprob": -0.19006989707409497, "compression_ratio": 1.4444444444444444, "no_speech_prob": 2.753328953986056e-05}, {"id": 1288, "seek": 520840, "start": 5216.4, "end": 5221.4, "text": " So, yeah, I think you're right that there are certainly cases.", "tokens": [407, 11, 1338, 11, 286, 519, 291, 434, 558, 300, 456, 366, 3297, 3331, 13], "temperature": 0.0, "avg_logprob": -0.19006989707409497, "compression_ratio": 1.4444444444444444, "no_speech_prob": 2.753328953986056e-05}, {"id": 1289, "seek": 520840, "start": 5221.4, "end": 5229.4, "text": " I mean, like you mentioned this example of, you know, Elm browser and then the Elm architecture in the Elm guide, right?", "tokens": [286, 914, 11, 411, 291, 2835, 341, 1365, 295, 11, 291, 458, 11, 2699, 76, 11185, 293, 550, 264, 2699, 76, 9482, 294, 264, 2699, 76, 5934, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.19006989707409497, "compression_ratio": 1.4444444444444444, "no_speech_prob": 2.753328953986056e-05}, {"id": 1290, "seek": 522940, "start": 5229.4, "end": 5241.4, "text": " Like a user might go to the Elm browser docs or some core package and expect a guide, but actually that lives somewhere else.", "tokens": [1743, 257, 4195, 1062, 352, 281, 264, 2699, 76, 11185, 45623, 420, 512, 4965, 7372, 293, 2066, 257, 5934, 11, 457, 767, 300, 2909, 4079, 1646, 13], "temperature": 0.0, "avg_logprob": -0.2200759562050424, "compression_ratio": 1.555045871559633, "no_speech_prob": 3.372968058101833e-05}, {"id": 1291, "seek": 522940, "start": 5241.4, "end": 5249.4, "text": " But that does make sense. Like it would be too much for the scope of it to introduce the Elm programming language and the Elm architecture", "tokens": [583, 300, 775, 652, 2020, 13, 1743, 309, 576, 312, 886, 709, 337, 264, 11923, 295, 309, 281, 5366, 264, 2699, 76, 9410, 2856, 293, 264, 2699, 76, 9482], "temperature": 0.0, "avg_logprob": -0.2200759562050424, "compression_ratio": 1.555045871559633, "no_speech_prob": 3.372968058101833e-05}, {"id": 1292, "seek": 522940, "start": 5249.4, "end": 5254.4, "text": " all in the inline module docs. And it doesn't give you enough granularity.", "tokens": [439, 294, 264, 294, 1889, 10088, 45623, 13, 400, 309, 1177, 380, 976, 291, 1547, 39962, 507, 13], "temperature": 0.0, "avg_logprob": -0.2200759562050424, "compression_ratio": 1.555045871559633, "no_speech_prob": 3.372968058101833e-05}, {"id": 1293, "seek": 525440, "start": 5254.4, "end": 5262.4, "text": " So in that case, having these conceptual overviews doesn't fit there. Also tutorials like you might have a mini tutorial,", "tokens": [407, 294, 300, 1389, 11, 1419, 613, 24106, 12492, 82, 1177, 380, 3318, 456, 13, 2743, 17616, 411, 291, 1062, 362, 257, 8382, 7073, 11], "temperature": 0.0, "avg_logprob": -0.214271729992282, "compression_ratio": 1.6583333333333334, "no_speech_prob": 2.1780995666631497e-05}, {"id": 1294, "seek": 525440, "start": 5262.4, "end": 5273.4, "text": " but you don't want to have a very ambitious tutorial that requires a lot of setup and a lot of steps and a lot of do it yourself exercises inline in your module docs.", "tokens": [457, 291, 500, 380, 528, 281, 362, 257, 588, 20239, 7073, 300, 7029, 257, 688, 295, 8657, 293, 257, 688, 295, 4439, 293, 257, 688, 295, 360, 309, 1803, 11900, 294, 1889, 294, 428, 10088, 45623, 13], "temperature": 0.0, "avg_logprob": -0.214271729992282, "compression_ratio": 1.6583333333333334, "no_speech_prob": 2.1780995666631497e-05}, {"id": 1295, "seek": 525440, "start": 5273.4, "end": 5280.4, "text": " It's just they should be very narrowly scoped. So something like that definitely belongs in an external tool,", "tokens": [467, 311, 445, 436, 820, 312, 588, 9432, 356, 795, 27277, 13, 407, 746, 411, 300, 2138, 12953, 294, 364, 8320, 2290, 11], "temperature": 0.0, "avg_logprob": -0.214271729992282, "compression_ratio": 1.6583333333333334, "no_speech_prob": 2.1780995666631497e-05}, {"id": 1296, "seek": 528040, "start": 5280.4, "end": 5286.4, "text": " which some package authors have external sites. Elm pages has an external doc site.", "tokens": [597, 512, 7372, 16552, 362, 8320, 7533, 13, 2699, 76, 7183, 575, 364, 8320, 3211, 3621, 13], "temperature": 0.0, "avg_logprob": -0.20202266338259675, "compression_ratio": 1.6196581196581197, "no_speech_prob": 9.080097697733436e-06}, {"id": 1297, "seek": 528040, "start": 5286.4, "end": 5299.4, "text": " And, you know, it covers things like just a conceptual overview of Elm pages because the scope of it is very large and it wouldn't fit neatly in one module documentation page", "tokens": [400, 11, 291, 458, 11, 309, 10538, 721, 411, 445, 257, 24106, 12492, 295, 2699, 76, 7183, 570, 264, 11923, 295, 309, 307, 588, 2416, 293, 309, 2759, 380, 3318, 36634, 294, 472, 10088, 14333, 3028], "temperature": 0.0, "avg_logprob": -0.20202266338259675, "compression_ratio": 1.6196581196581197, "no_speech_prob": 9.080097697733436e-06}, {"id": 1298, "seek": 528040, "start": 5299.4, "end": 5308.4, "text": " or things that happen around generated code. What module do you put that in? It's describing a set of generated modules.", "tokens": [420, 721, 300, 1051, 926, 10833, 3089, 13, 708, 10088, 360, 291, 829, 300, 294, 30, 467, 311, 16141, 257, 992, 295, 10833, 16679, 13], "temperature": 0.0, "avg_logprob": -0.20202266338259675, "compression_ratio": 1.6196581196581197, "no_speech_prob": 9.080097697733436e-06}, {"id": 1299, "seek": 530840, "start": 5308.4, "end": 5319.4, "text": " So there's like a file structure document that talks about navigating the file structure of an Elm pages application and what sort of modules are generated from that.", "tokens": [407, 456, 311, 411, 257, 3991, 3877, 4166, 300, 6686, 466, 32054, 264, 3991, 3877, 295, 364, 2699, 76, 7183, 3861, 293, 437, 1333, 295, 16679, 366, 10833, 490, 300, 13], "temperature": 0.0, "avg_logprob": -0.20267866717444527, "compression_ratio": 1.6272727272727272, "no_speech_prob": 4.0061418985715136e-05}, {"id": 1300, "seek": 530840, "start": 5319.4, "end": 5327.4, "text": " You know, certain things about the philosophy and the architecture and diagrams for the architecture, the adapter API,", "tokens": [509, 458, 11, 1629, 721, 466, 264, 10675, 293, 264, 9482, 293, 36709, 337, 264, 9482, 11, 264, 22860, 9362, 11], "temperature": 0.0, "avg_logprob": -0.20267866717444527, "compression_ratio": 1.6272727272727272, "no_speech_prob": 4.0061418985715136e-05}, {"id": 1301, "seek": 530840, "start": 5327.4, "end": 5332.4, "text": " which allows you to adapt to different deployment and hosting platforms.", "tokens": [597, 4045, 291, 281, 6231, 281, 819, 19317, 293, 16058, 9473, 13], "temperature": 0.0, "avg_logprob": -0.20267866717444527, "compression_ratio": 1.6272727272727272, "no_speech_prob": 4.0061418985715136e-05}, {"id": 1302, "seek": 533240, "start": 5332.4, "end": 5341.4, "text": " So, yeah, so there's definitely I mean, my rule of thumb is if something fits neatly in a modules docs, put it there.", "tokens": [407, 11, 1338, 11, 370, 456, 311, 2138, 286, 914, 11, 452, 4978, 295, 9298, 307, 498, 746, 9001, 36634, 294, 257, 16679, 45623, 11, 829, 309, 456, 13], "temperature": 0.0, "avg_logprob": -0.2178179667546199, "compression_ratio": 1.6531531531531531, "no_speech_prob": 2.5866534997476265e-05}, {"id": 1303, "seek": 533240, "start": 5341.4, "end": 5353.4, "text": " For example, back end task, I could put it in a separate, you know, it almost wants to be part of the Elm pages docs for Elm-pages.com slash docs.", "tokens": [1171, 1365, 11, 646, 917, 5633, 11, 286, 727, 829, 309, 294, 257, 4994, 11, 291, 458, 11, 309, 1920, 2738, 281, 312, 644, 295, 264, 2699, 76, 7183, 45623, 337, 2699, 76, 12, 79, 1660, 13, 1112, 17330, 45623, 13], "temperature": 0.0, "avg_logprob": -0.2178179667546199, "compression_ratio": 1.6531531531531531, "no_speech_prob": 2.5866534997476265e-05}, {"id": 1304, "seek": 533240, "start": 5353.4, "end": 5360.4, "text": " Like I almost want it in the listing there, but it can fit in a module doc. So I put it there instead.", "tokens": [1743, 286, 1920, 528, 309, 294, 264, 22161, 456, 11, 457, 309, 393, 3318, 294, 257, 10088, 3211, 13, 407, 286, 829, 309, 456, 2602, 13], "temperature": 0.0, "avg_logprob": -0.2178179667546199, "compression_ratio": 1.6531531531531531, "no_speech_prob": 2.5866534997476265e-05}, {"id": 1305, "seek": 536040, "start": 5360.4, "end": 5369.4, "text": " There's also like you can have a website, like a custom website where it says blazingly fast, you know, the obvious catchphrase,", "tokens": [821, 311, 611, 411, 291, 393, 362, 257, 3144, 11, 411, 257, 2375, 3144, 689, 309, 1619, 16379, 8781, 356, 2370, 11, 291, 458, 11, 264, 6322, 3745, 44598, 651, 11], "temperature": 0.0, "avg_logprob": -0.26206467572380515, "compression_ratio": 1.69, "no_speech_prob": 1.0128766916750465e-05}, {"id": 1306, "seek": 536040, "start": 5369.4, "end": 5381.4, "text": " where you can just make it look good. Just marketing wise, the package's website is not super handsome.", "tokens": [689, 291, 393, 445, 652, 309, 574, 665, 13, 1449, 6370, 10829, 11, 264, 7372, 311, 3144, 307, 406, 1687, 13421, 13], "temperature": 0.0, "avg_logprob": -0.26206467572380515, "compression_ratio": 1.69, "no_speech_prob": 1.0128766916750465e-05}, {"id": 1307, "seek": 536040, "start": 5381.4, "end": 5388.4, "text": " Like it's a good looking website. It's a very simple website, but you're not putting like marketing wise,", "tokens": [1743, 309, 311, 257, 665, 1237, 3144, 13, 467, 311, 257, 588, 2199, 3144, 11, 457, 291, 434, 406, 3372, 411, 6370, 10829, 11], "temperature": 0.0, "avg_logprob": -0.26206467572380515, "compression_ratio": 1.69, "no_speech_prob": 1.0128766916750465e-05}, {"id": 1308, "seek": 538840, "start": 5388.4, "end": 5398.4, "text": " the JavaScript people will tell you, hey, this is shit. Like my Vite package looks the same as the Parcel package.", "tokens": [264, 15778, 561, 486, 980, 291, 11, 4177, 11, 341, 307, 4611, 13, 1743, 452, 691, 642, 7372, 1542, 264, 912, 382, 264, 3457, 4933, 7372, 13], "temperature": 0.0, "avg_logprob": -0.2727622985839844, "compression_ratio": 1.4251497005988023, "no_speech_prob": 1.341928327747155e-05}, {"id": 1309, "seek": 538840, "start": 5398.4, "end": 5409.4, "text": " How can I make it obvious that this one is better without being able to choose my colors for my package documentation page?", "tokens": [1012, 393, 286, 652, 309, 6322, 300, 341, 472, 307, 1101, 1553, 885, 1075, 281, 2826, 452, 4577, 337, 452, 7372, 14333, 3028, 30], "temperature": 0.0, "avg_logprob": -0.2727622985839844, "compression_ratio": 1.4251497005988023, "no_speech_prob": 1.341928327747155e-05}, {"id": 1310, "seek": 540940, "start": 5409.4, "end": 5419.4, "text": " So I think there's also a case where you want to have a dedicated website. I'm not sure how much overlap there is.", "tokens": [407, 286, 519, 456, 311, 611, 257, 1389, 689, 291, 528, 281, 362, 257, 8374, 3144, 13, 286, 478, 406, 988, 577, 709, 19959, 456, 307, 13], "temperature": 0.0, "avg_logprob": -0.19584243297576903, "compression_ratio": 1.733695652173913, "no_speech_prob": 1.349645458503801e-06}, {"id": 1311, "seek": 540940, "start": 5419.4, "end": 5428.4, "text": " And when you want to have a additional, when you want to have a website and package documentation and a guide,", "tokens": [400, 562, 291, 528, 281, 362, 257, 4497, 11, 562, 291, 528, 281, 362, 257, 3144, 293, 7372, 14333, 293, 257, 5934, 11], "temperature": 0.0, "avg_logprob": -0.19584243297576903, "compression_ratio": 1.733695652173913, "no_speech_prob": 1.349645458503801e-06}, {"id": 1312, "seek": 540940, "start": 5428.4, "end": 5435.4, "text": " and how you mix and match them together. So I'm kind of used to have on the package websites.", "tokens": [293, 577, 291, 2890, 293, 2995, 552, 1214, 13, 407, 286, 478, 733, 295, 1143, 281, 362, 322, 264, 7372, 12891, 13], "temperature": 0.0, "avg_logprob": -0.19584243297576903, "compression_ratio": 1.733695652173913, "no_speech_prob": 1.349645458503801e-06}, {"id": 1313, "seek": 543540, "start": 5435.4, "end": 5443.4, "text": " And therefore, if new opportunities open up to me, like having the ability to write a guide,", "tokens": [400, 4412, 11, 498, 777, 4786, 1269, 493, 281, 385, 11, 411, 1419, 264, 3485, 281, 2464, 257, 5934, 11], "temperature": 0.0, "avg_logprob": -0.19711374995684383, "compression_ratio": 1.60546875, "no_speech_prob": 5.954988864687039e-06}, {"id": 1314, "seek": 543540, "start": 5443.4, "end": 5446.4, "text": " I'm not sure how I will write the documentation yet.", "tokens": [286, 478, 406, 988, 577, 286, 486, 2464, 264, 14333, 1939, 13], "temperature": 0.0, "avg_logprob": -0.19711374995684383, "compression_ratio": 1.60546875, "no_speech_prob": 5.954988864687039e-06}, {"id": 1315, "seek": 543540, "start": 5446.4, "end": 5453.4, "text": " There are definitely certain things that fit better in a custom site. Like you said, I mean, having more control over the styling,", "tokens": [821, 366, 2138, 1629, 721, 300, 3318, 1101, 294, 257, 2375, 3621, 13, 1743, 291, 848, 11, 286, 914, 11, 1419, 544, 1969, 670, 264, 27944, 11], "temperature": 0.0, "avg_logprob": -0.19711374995684383, "compression_ratio": 1.60546875, "no_speech_prob": 5.954988864687039e-06}, {"id": 1316, "seek": 543540, "start": 5453.4, "end": 5461.4, "text": " but also if you want to have a showcase or certain community things like in the Elm Pages site, I have something that lets you submit.", "tokens": [457, 611, 498, 291, 528, 281, 362, 257, 20388, 420, 1629, 1768, 721, 411, 294, 264, 2699, 76, 430, 1660, 3621, 11, 286, 362, 746, 300, 6653, 291, 10315, 13], "temperature": 0.0, "avg_logprob": -0.19711374995684383, "compression_ratio": 1.60546875, "no_speech_prob": 5.954988864687039e-06}, {"id": 1317, "seek": 546140, "start": 5461.4, "end": 5471.4, "text": " There's a button to submit to the showcase. It uses Airtable and it pulls data from that API live or, you know, a blog.", "tokens": [821, 311, 257, 2960, 281, 10315, 281, 264, 20388, 13, 467, 4960, 316, 2498, 712, 293, 309, 16982, 1412, 490, 300, 9362, 1621, 420, 11, 291, 458, 11, 257, 6968, 13], "temperature": 0.0, "avg_logprob": -0.23828446237664475, "compression_ratio": 1.4120603015075377, "no_speech_prob": 9.368231985718012e-06}, {"id": 1318, "seek": 546140, "start": 5471.4, "end": 5474.4, "text": " Should you have a blog hosted on the Elm Package site? Probably not.", "tokens": [6454, 291, 362, 257, 6968, 19204, 322, 264, 2699, 76, 18466, 609, 3621, 30, 9210, 406, 13], "temperature": 0.0, "avg_logprob": -0.23828446237664475, "compression_ratio": 1.4120603015075377, "no_speech_prob": 9.368231985718012e-06}, {"id": 1319, "seek": 546140, "start": 5474.4, "end": 5483.4, "text": " Yeah. You also maybe want to have like release notes that are displayed nicely, news, blogs.", "tokens": [865, 13, 509, 611, 1310, 528, 281, 362, 411, 4374, 5570, 300, 366, 16372, 9594, 11, 2583, 11, 31038, 13], "temperature": 0.0, "avg_logprob": -0.23828446237664475, "compression_ratio": 1.4120603015075377, "no_speech_prob": 9.368231985718012e-06}, {"id": 1320, "seek": 548340, "start": 5483.4, "end": 5492.4, "text": " And yeah, as you say, like things that are not relevant to the API, but that are relevant to the package,", "tokens": [400, 1338, 11, 382, 291, 584, 11, 411, 721, 300, 366, 406, 7340, 281, 264, 9362, 11, 457, 300, 366, 7340, 281, 264, 7372, 11], "temperature": 0.0, "avg_logprob": -0.21052556934923228, "compression_ratio": 1.702127659574468, "no_speech_prob": 9.665669495007023e-06}, {"id": 1321, "seek": 548340, "start": 5492.4, "end": 5499.4, "text": " like how many people use this, who is sponsoring this package or yeah, things like that.", "tokens": [411, 577, 867, 561, 764, 341, 11, 567, 307, 30311, 341, 7372, 420, 1338, 11, 721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.21052556934923228, "compression_ratio": 1.702127659574468, "no_speech_prob": 9.665669495007023e-06}, {"id": 1322, "seek": 548340, "start": 5499.4, "end": 5506.4, "text": " Right. Yeah. Yeah. And in general, there are all these different rich formats. I think they all serve their needs.", "tokens": [1779, 13, 865, 13, 865, 13, 400, 294, 2674, 11, 456, 366, 439, 613, 819, 4593, 25879, 13, 286, 519, 436, 439, 4596, 641, 2203, 13], "temperature": 0.0, "avg_logprob": -0.21052556934923228, "compression_ratio": 1.702127659574468, "no_speech_prob": 9.665669495007023e-06}, {"id": 1323, "seek": 548340, "start": 5506.4, "end": 5512.4, "text": " Having a custom blog serves its need. Having Elm Package Docs does its job extremely well.", "tokens": [10222, 257, 2375, 6968, 13451, 1080, 643, 13, 10222, 2699, 76, 18466, 609, 16024, 82, 775, 1080, 1691, 4664, 731, 13], "temperature": 0.0, "avg_logprob": -0.21052556934923228, "compression_ratio": 1.702127659574468, "no_speech_prob": 9.665669495007023e-06}, {"id": 1324, "seek": 551240, "start": 5512.4, "end": 5523.4, "text": " And having them both is really useful. Things like GitHub discussions, GitHub issues, poll requests, conference talks, podcast episodes.", "tokens": [400, 1419, 552, 1293, 307, 534, 4420, 13, 9514, 411, 23331, 11088, 11, 23331, 2663, 11, 6418, 12475, 11, 7586, 6686, 11, 7367, 9313, 13], "temperature": 0.0, "avg_logprob": -0.225152316158765, "compression_ratio": 1.6771300448430493, "no_speech_prob": 8.749078551772982e-05}, {"id": 1325, "seek": 551240, "start": 5523.4, "end": 5529.4, "text": " All these things are great sources of information in different formats that serve different purposes.", "tokens": [1057, 613, 721, 366, 869, 7139, 295, 1589, 294, 819, 25879, 300, 4596, 819, 9932, 13], "temperature": 0.0, "avg_logprob": -0.225152316158765, "compression_ratio": 1.6771300448430493, "no_speech_prob": 8.749078551772982e-05}, {"id": 1326, "seek": 551240, "start": 5529.4, "end": 5539.4, "text": " A GitHub discussion is a great place to showcase ideas and community projects and get feedback on things and discuss specing things out", "tokens": [316, 23331, 5017, 307, 257, 869, 1081, 281, 20388, 3487, 293, 1768, 4455, 293, 483, 5824, 322, 721, 293, 2248, 1608, 278, 721, 484], "temperature": 0.0, "avg_logprob": -0.225152316158765, "compression_ratio": 1.6771300448430493, "no_speech_prob": 8.749078551772982e-05}, {"id": 1327, "seek": 553940, "start": 5539.4, "end": 5545.4, "text": " or making decisions or documenting history about something. Package Docs are not a good place for that.", "tokens": [420, 1455, 5327, 420, 42360, 2503, 466, 746, 13, 18466, 609, 16024, 82, 366, 406, 257, 665, 1081, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.1702951877675158, "compression_ratio": 1.646153846153846, "no_speech_prob": 5.307214451022446e-05}, {"id": 1328, "seek": 553940, "start": 5545.4, "end": 5554.4, "text": " But if there's some quirky thing that people are frequently asking about, go ahead and link to that GitHub discussion thread", "tokens": [583, 498, 456, 311, 512, 49515, 551, 300, 561, 366, 10374, 3365, 466, 11, 352, 2286, 293, 2113, 281, 300, 23331, 5017, 7207], "temperature": 0.0, "avg_logprob": -0.1702951877675158, "compression_ratio": 1.646153846153846, "no_speech_prob": 5.307214451022446e-05}, {"id": 1329, "seek": 553940, "start": 5554.4, "end": 5558.4, "text": " that talks about the history and the spec and why that decision was made.", "tokens": [300, 6686, 466, 264, 2503, 293, 264, 1608, 293, 983, 300, 3537, 390, 1027, 13], "temperature": 0.0, "avg_logprob": -0.1702951877675158, "compression_ratio": 1.646153846153846, "no_speech_prob": 5.307214451022446e-05}, {"id": 1330, "seek": 553940, "start": 5558.4, "end": 5567.4, "text": " So I think this model of linking out to a lot of different resources, keeping things very concise and focused on one purpose.", "tokens": [407, 286, 519, 341, 2316, 295, 25775, 484, 281, 257, 688, 295, 819, 3593, 11, 5145, 721, 588, 44882, 293, 5178, 322, 472, 4334, 13], "temperature": 0.0, "avg_logprob": -0.1702951877675158, "compression_ratio": 1.646153846153846, "no_speech_prob": 5.307214451022446e-05}, {"id": 1331, "seek": 556740, "start": 5567.4, "end": 5574.4, "text": " But then if you're on this page and you're looking for something more, let me throw some links your way just in case.", "tokens": [583, 550, 498, 291, 434, 322, 341, 3028, 293, 291, 434, 1237, 337, 746, 544, 11, 718, 385, 3507, 512, 6123, 428, 636, 445, 294, 1389, 13], "temperature": 0.0, "avg_logprob": -0.2194763692220052, "compression_ratio": 1.4720812182741116, "no_speech_prob": 1.8340273527428508e-05}, {"id": 1332, "seek": 556740, "start": 5574.4, "end": 5580.4, "text": " That's hugely valuable. I don't think you can understate the power of just...", "tokens": [663, 311, 27417, 8263, 13, 286, 500, 380, 519, 291, 393, 833, 15406, 264, 1347, 295, 445, 485], "temperature": 0.0, "avg_logprob": -0.2194763692220052, "compression_ratio": 1.4720812182741116, "no_speech_prob": 1.8340273527428508e-05}, {"id": 1333, "seek": 556740, "start": 5580.4, "end": 5588.4, "text": " And even just linking to in between different module pages in an Elm Package is huge, I think.", "tokens": [400, 754, 445, 25775, 281, 294, 1296, 819, 10088, 7183, 294, 364, 2699, 76, 18466, 609, 307, 2603, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.2194763692220052, "compression_ratio": 1.4720812182741116, "no_speech_prob": 1.8340273527428508e-05}, {"id": 1334, "seek": 558840, "start": 5588.4, "end": 5599.4, "text": " Another great thing is that whenever you have a function, it has a type annotation and the type annotation has references, different types.", "tokens": [3996, 869, 551, 307, 300, 5699, 291, 362, 257, 2445, 11, 309, 575, 257, 2010, 48654, 293, 264, 2010, 48654, 575, 15400, 11, 819, 3467, 13], "temperature": 0.0, "avg_logprob": -0.1865520477294922, "compression_ratio": 1.7752808988764044, "no_speech_prob": 9.96618291537743e-06}, {"id": 1335, "seek": 558840, "start": 5599.4, "end": 5605.4, "text": " And whenever you have a type that is defined in your package, that becomes a link.", "tokens": [400, 5699, 291, 362, 257, 2010, 300, 307, 7642, 294, 428, 7372, 11, 300, 3643, 257, 2113, 13], "temperature": 0.0, "avg_logprob": -0.1865520477294922, "compression_ratio": 1.7752808988764044, "no_speech_prob": 9.96618291537743e-06}, {"id": 1336, "seek": 558840, "start": 5605.4, "end": 5611.4, "text": " So you can click on it and now you can see where that was defined. And that is very valuable.", "tokens": [407, 291, 393, 2052, 322, 309, 293, 586, 291, 393, 536, 689, 300, 390, 7642, 13, 400, 300, 307, 588, 8263, 13], "temperature": 0.0, "avg_logprob": -0.1865520477294922, "compression_ratio": 1.7752808988764044, "no_speech_prob": 9.96618291537743e-06}, {"id": 1337, "seek": 561140, "start": 5611.4, "end": 5620.4, "text": " So if you can add more links for things that are not done that way, that's very valuable. I agree.", "tokens": [407, 498, 291, 393, 909, 544, 6123, 337, 721, 300, 366, 406, 1096, 300, 636, 11, 300, 311, 588, 8263, 13, 286, 3986, 13], "temperature": 0.0, "avg_logprob": -0.17917978922526043, "compression_ratio": 1.5095238095238095, "no_speech_prob": 2.318273254786618e-05}, {"id": 1338, "seek": 561140, "start": 5620.4, "end": 5627.4, "text": " Yeah. Also, on a related note, I think we all have the curse of knowledge, especially as authors of packages,", "tokens": [865, 13, 2743, 11, 322, 257, 4077, 3637, 11, 286, 519, 321, 439, 362, 264, 17139, 295, 3601, 11, 2318, 382, 16552, 295, 17401, 11], "temperature": 0.0, "avg_logprob": -0.17917978922526043, "compression_ratio": 1.5095238095238095, "no_speech_prob": 2.318273254786618e-05}, {"id": 1339, "seek": 561140, "start": 5627.4, "end": 5636.4, "text": " where we have trouble understanding what it would be like navigating something because we know those things.", "tokens": [689, 321, 362, 5253, 3701, 437, 309, 576, 312, 411, 32054, 746, 570, 321, 458, 729, 721, 13], "temperature": 0.0, "avg_logprob": -0.17917978922526043, "compression_ratio": 1.5095238095238095, "no_speech_prob": 2.318273254786618e-05}, {"id": 1340, "seek": 563640, "start": 5636.4, "end": 5647.4, "text": " So it's hard to revert back to a state of not knowing those things and understand, not to mention different things will be confusing for different users,", "tokens": [407, 309, 311, 1152, 281, 319, 3281, 646, 281, 257, 1785, 295, 406, 5276, 729, 721, 293, 1223, 11, 406, 281, 2152, 819, 721, 486, 312, 13181, 337, 819, 5022, 11], "temperature": 0.0, "avg_logprob": -0.20269834518432617, "compression_ratio": 1.7713178294573644, "no_speech_prob": 7.957514026202261e-05}, {"id": 1341, "seek": 563640, "start": 5647.4, "end": 5650.4, "text": " coming from different avenues and different ways of thinking about things.", "tokens": [1348, 490, 819, 43039, 293, 819, 2098, 295, 1953, 466, 721, 13], "temperature": 0.0, "avg_logprob": -0.20269834518432617, "compression_ratio": 1.7713178294573644, "no_speech_prob": 7.957514026202261e-05}, {"id": 1342, "seek": 563640, "start": 5650.4, "end": 5659.4, "text": " But I think it's a really good practice to get in the habit of understanding what assumptions you're making.", "tokens": [583, 286, 519, 309, 311, 257, 534, 665, 3124, 281, 483, 294, 264, 7164, 295, 3701, 437, 17695, 291, 434, 1455, 13], "temperature": 0.0, "avg_logprob": -0.20269834518432617, "compression_ratio": 1.7713178294573644, "no_speech_prob": 7.957514026202261e-05}, {"id": 1343, "seek": 563640, "start": 5659.4, "end": 5665.4, "text": " And there are certain habits that I've tried to build personally, where I'll try to notice when I'm making assumptions.", "tokens": [400, 456, 366, 1629, 14100, 300, 286, 600, 3031, 281, 1322, 5665, 11, 689, 286, 603, 853, 281, 3449, 562, 286, 478, 1455, 17695, 13], "temperature": 0.0, "avg_logprob": -0.20269834518432617, "compression_ratio": 1.7713178294573644, "no_speech_prob": 7.957514026202261e-05}, {"id": 1344, "seek": 566540, "start": 5665.4, "end": 5672.4, "text": " So like one easy one is an acronym. If you're mentioning an acronym, just spell it out.", "tokens": [407, 411, 472, 1858, 472, 307, 364, 39195, 13, 759, 291, 434, 18315, 364, 39195, 11, 445, 9827, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.23194687787224263, "compression_ratio": 1.6009389671361502, "no_speech_prob": 2.668375600478612e-05}, {"id": 1345, "seek": 566540, "start": 5672.4, "end": 5679.4, "text": " Just say what the acronym stands for. You can use the acronym, but introduce at least what it stands for first.", "tokens": [1449, 584, 437, 264, 39195, 7382, 337, 13, 509, 393, 764, 264, 39195, 11, 457, 5366, 412, 1935, 437, 309, 7382, 337, 700, 13], "temperature": 0.0, "avg_logprob": -0.23194687787224263, "compression_ratio": 1.6009389671361502, "no_speech_prob": 2.668375600478612e-05}, {"id": 1346, "seek": 566540, "start": 5679.4, "end": 5691.4, "text": " Yeah. And you can even like if it's a concept like the CAP theorem, then you can link to a Wikipedia page or something that talks about that.", "tokens": [865, 13, 400, 291, 393, 754, 411, 498, 309, 311, 257, 3410, 411, 264, 33636, 20904, 11, 550, 291, 393, 2113, 281, 257, 28999, 3028, 420, 746, 300, 6686, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.23194687787224263, "compression_ratio": 1.6009389671361502, "no_speech_prob": 2.668375600478612e-05}, {"id": 1347, "seek": 569140, "start": 5691.4, "end": 5697.4, "text": " Or a blog post that has more information and simplifies, vulgarizes the concept.", "tokens": [1610, 257, 6968, 2183, 300, 575, 544, 1589, 293, 6883, 11221, 11, 7452, 2976, 5660, 264, 3410, 13], "temperature": 0.0, "avg_logprob": -0.2751414060592651, "compression_ratio": 1.4598214285714286, "no_speech_prob": 2.014236270042602e-05}, {"id": 1348, "seek": 569140, "start": 5697.4, "end": 5704.4, "text": " Because sometimes Wikipedia is not very, very nice, especially for mathematical things.", "tokens": [1436, 2171, 28999, 307, 406, 588, 11, 588, 1481, 11, 2318, 337, 18894, 721, 13], "temperature": 0.0, "avg_logprob": -0.2751414060592651, "compression_ratio": 1.4598214285714286, "no_speech_prob": 2.014236270042602e-05}, {"id": 1349, "seek": 569140, "start": 5704.4, "end": 5707.4, "text": " Link to the Monad page.", "tokens": [8466, 281, 264, 4713, 345, 3028, 13], "temperature": 0.0, "avg_logprob": -0.2751414060592651, "compression_ratio": 1.4598214285714286, "no_speech_prob": 2.014236270042602e-05}, {"id": 1350, "seek": 569140, "start": 5707.4, "end": 5716.4, "text": " Right, right. Yeah, but exactly. Any terms like that, that might require some specific domain knowledge, just go ahead and link to it.", "tokens": [1779, 11, 558, 13, 865, 11, 457, 2293, 13, 2639, 2115, 411, 300, 11, 300, 1062, 3651, 512, 2685, 9274, 3601, 11, 445, 352, 2286, 293, 2113, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.2751414060592651, "compression_ratio": 1.4598214285714286, "no_speech_prob": 2.014236270042602e-05}, {"id": 1351, "seek": 571640, "start": 5716.4, "end": 5726.4, "text": " You know, if you're talking about a type from a package, link to that external Elm package or NPM package or whatever it might be.", "tokens": [509, 458, 11, 498, 291, 434, 1417, 466, 257, 2010, 490, 257, 7372, 11, 2113, 281, 300, 8320, 2699, 76, 7372, 420, 426, 18819, 7372, 420, 2035, 309, 1062, 312, 13], "temperature": 0.0, "avg_logprob": -0.19737762279724808, "compression_ratio": 1.5853658536585367, "no_speech_prob": 2.391905218246393e-05}, {"id": 1352, "seek": 571640, "start": 5726.4, "end": 5738.4, "text": " I also find that sometimes, like when I'm writing out docs, I will say, if I'm using the word it or that or this,", "tokens": [286, 611, 915, 300, 2171, 11, 411, 562, 286, 478, 3579, 484, 45623, 11, 286, 486, 584, 11, 498, 286, 478, 1228, 264, 1349, 309, 420, 300, 420, 341, 11], "temperature": 0.0, "avg_logprob": -0.19737762279724808, "compression_ratio": 1.5853658536585367, "no_speech_prob": 2.391905218246393e-05}, {"id": 1353, "seek": 571640, "start": 5738.4, "end": 5742.4, "text": " sometimes I'm like, wait a minute, are they going to know what I'm referring to?", "tokens": [2171, 286, 478, 411, 11, 1699, 257, 3456, 11, 366, 436, 516, 281, 458, 437, 286, 478, 13761, 281, 30], "temperature": 0.0, "avg_logprob": -0.19737762279724808, "compression_ratio": 1.5853658536585367, "no_speech_prob": 2.391905218246393e-05}, {"id": 1354, "seek": 574240, "start": 5742.4, "end": 5750.4, "text": " Because I just covered a lot of things and sometimes instead of it, I'll say, you know, the backend task type.", "tokens": [1436, 286, 445, 5343, 257, 688, 295, 721, 293, 2171, 2602, 295, 309, 11, 286, 603, 584, 11, 291, 458, 11, 264, 38087, 5633, 2010, 13], "temperature": 0.0, "avg_logprob": -0.2034502952329574, "compression_ratio": 1.6551724137931034, "no_speech_prob": 4.6108601964078844e-05}, {"id": 1355, "seek": 574240, "start": 5750.4, "end": 5755.4, "text": " And so now it's like, OK, backend tasks allow you to do that.", "tokens": [400, 370, 586, 309, 311, 411, 11, 2264, 11, 38087, 9608, 2089, 291, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.2034502952329574, "compression_ratio": 1.6551724137931034, "no_speech_prob": 4.6108601964078844e-05}, {"id": 1356, "seek": 574240, "start": 5755.4, "end": 5762.4, "text": " It gives you, you know, I'll just say backend task also, you know, because it's very subtle.", "tokens": [467, 2709, 291, 11, 291, 458, 11, 286, 603, 445, 584, 38087, 5633, 611, 11, 291, 458, 11, 570, 309, 311, 588, 13743, 13], "temperature": 0.0, "avg_logprob": -0.2034502952329574, "compression_ratio": 1.6551724137931034, "no_speech_prob": 4.6108601964078844e-05}, {"id": 1357, "seek": 574240, "start": 5762.4, "end": 5767.4, "text": " But I think that people can get tripped up on small details like this.", "tokens": [583, 286, 519, 300, 561, 393, 483, 1376, 3320, 493, 322, 1359, 4365, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.2034502952329574, "compression_ratio": 1.6551724137931034, "no_speech_prob": 4.6108601964078844e-05}, {"id": 1358, "seek": 576740, "start": 5767.4, "end": 5776.4, "text": " So be very explicit, show all of your imports, show your work, link to things, define your terms, just like go overboard with those things.", "tokens": [407, 312, 588, 13691, 11, 855, 439, 295, 428, 41596, 11, 855, 428, 589, 11, 2113, 281, 721, 11, 6964, 428, 2115, 11, 445, 411, 352, 49480, 365, 729, 721, 13], "temperature": 0.0, "avg_logprob": -0.21143996715545654, "compression_ratio": 1.7096774193548387, "no_speech_prob": 1.8922437448054552e-05}, {"id": 1359, "seek": 576740, "start": 5776.4, "end": 5782.4, "text": " Yeah. Also, if you re-mention the backend task, you can make it a link.", "tokens": [865, 13, 2743, 11, 498, 291, 319, 12, 518, 313, 264, 38087, 5633, 11, 291, 393, 652, 309, 257, 2113, 13], "temperature": 0.0, "avg_logprob": -0.21143996715545654, "compression_ratio": 1.7096774193548387, "no_speech_prob": 1.8922437448054552e-05}, {"id": 1360, "seek": 576740, "start": 5782.4, "end": 5787.4, "text": " So people don't have to go back to the very top of the page to find the link to backend task.", "tokens": [407, 561, 500, 380, 362, 281, 352, 646, 281, 264, 588, 1192, 295, 264, 3028, 281, 915, 264, 2113, 281, 38087, 5633, 13], "temperature": 0.0, "avg_logprob": -0.21143996715545654, "compression_ratio": 1.7096774193548387, "no_speech_prob": 1.8922437448054552e-05}, {"id": 1361, "seek": 576740, "start": 5787.4, "end": 5796.4, "text": " So that's also quite nice. And also like try to avoid words like just or simple or like they make sense in some cases.", "tokens": [407, 300, 311, 611, 1596, 1481, 13, 400, 611, 411, 853, 281, 5042, 2283, 411, 445, 420, 2199, 420, 411, 436, 652, 2020, 294, 512, 3331, 13], "temperature": 0.0, "avg_logprob": -0.21143996715545654, "compression_ratio": 1.7096774193548387, "no_speech_prob": 1.8922437448054552e-05}, {"id": 1362, "seek": 579640, "start": 5796.4, "end": 5803.4, "text": " But you have to be careful about those. Like what seems simple to you or easy to you is not necessarily the case for other people.", "tokens": [583, 291, 362, 281, 312, 5026, 466, 729, 13, 1743, 437, 2544, 2199, 281, 291, 420, 1858, 281, 291, 307, 406, 4725, 264, 1389, 337, 661, 561, 13], "temperature": 0.0, "avg_logprob": -0.20342426989451948, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0001292812085011974}, {"id": 1363, "seek": 579640, "start": 5803.4, "end": 5810.4, "text": " Although simple is objective, but you need to have watched Rich Hickey's talk about that.", "tokens": [5780, 2199, 307, 10024, 11, 457, 291, 643, 281, 362, 6337, 6781, 389, 299, 4119, 311, 751, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.20342426989451948, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0001292812085011974}, {"id": 1364, "seek": 579640, "start": 5810.4, "end": 5823.4, "text": " Right. Yeah. I think also being straightforward and, you know, not saying like necessarily this is the best way to do this,", "tokens": [1779, 13, 865, 13, 286, 519, 611, 885, 15325, 293, 11, 291, 458, 11, 406, 1566, 411, 4725, 341, 307, 264, 1151, 636, 281, 360, 341, 11], "temperature": 0.0, "avg_logprob": -0.20342426989451948, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0001292812085011974}, {"id": 1365, "seek": 582340, "start": 5823.4, "end": 5830.4, "text": " but saying these are the decisions. I think it's really good to be clear and explicit.", "tokens": [457, 1566, 613, 366, 264, 5327, 13, 286, 519, 309, 311, 534, 665, 281, 312, 1850, 293, 13691, 13], "temperature": 0.0, "avg_logprob": -0.19405113471733346, "compression_ratio": 1.8177339901477831, "no_speech_prob": 6.0079422837588936e-05}, {"id": 1366, "seek": 582340, "start": 5830.4, "end": 5835.4, "text": " These are decisions. I believe these are pros of these, this set of decisions.", "tokens": [1981, 366, 5327, 13, 286, 1697, 613, 366, 6267, 295, 613, 11, 341, 992, 295, 5327, 13], "temperature": 0.0, "avg_logprob": -0.19405113471733346, "compression_ratio": 1.8177339901477831, "no_speech_prob": 6.0079422837588936e-05}, {"id": 1367, "seek": 582340, "start": 5835.4, "end": 5840.4, "text": " Perhaps here are some cons about this set of decisions, but these are the decisions. This is the philosophy.", "tokens": [10517, 510, 366, 512, 1014, 466, 341, 992, 295, 5327, 11, 457, 613, 366, 264, 5327, 13, 639, 307, 264, 10675, 13], "temperature": 0.0, "avg_logprob": -0.19405113471733346, "compression_ratio": 1.8177339901477831, "no_speech_prob": 6.0079422837588936e-05}, {"id": 1368, "seek": 582340, "start": 5840.4, "end": 5846.4, "text": " I think we talked about this in our Elm Radio episode of how and when to write an Elm package.", "tokens": [286, 519, 321, 2825, 466, 341, 294, 527, 2699, 76, 17296, 3500, 295, 577, 293, 562, 281, 2464, 364, 2699, 76, 7372, 13], "temperature": 0.0, "avg_logprob": -0.19405113471733346, "compression_ratio": 1.8177339901477831, "no_speech_prob": 6.0079422837588936e-05}, {"id": 1369, "seek": 584640, "start": 5846.4, "end": 5855.4, "text": " But, you know, I think it's really valuable to just be up front with people and tell them because you can't you can't do everything.", "tokens": [583, 11, 291, 458, 11, 286, 519, 309, 311, 534, 8263, 281, 445, 312, 493, 1868, 365, 561, 293, 980, 552, 570, 291, 393, 380, 291, 393, 380, 360, 1203, 13], "temperature": 0.0, "avg_logprob": -0.23106467303107767, "compression_ratio": 1.6373056994818653, "no_speech_prob": 4.830821853829548e-05}, {"id": 1370, "seek": 584640, "start": 5855.4, "end": 5861.4, "text": " You can't make every you know, I'll make every single trade off out that no, like a trade off.", "tokens": [509, 393, 380, 652, 633, 291, 458, 11, 286, 603, 652, 633, 2167, 4923, 766, 484, 300, 572, 11, 411, 257, 4923, 766, 13], "temperature": 0.0, "avg_logprob": -0.23106467303107767, "compression_ratio": 1.6373056994818653, "no_speech_prob": 4.830821853829548e-05}, {"id": 1371, "seek": 584640, "start": 5861.4, "end": 5867.4, "text": " You have to trade something. Which one do you want to choose? So just don't mince words.", "tokens": [509, 362, 281, 4923, 746, 13, 3013, 472, 360, 291, 528, 281, 2826, 30, 407, 445, 500, 380, 923, 384, 2283, 13], "temperature": 0.0, "avg_logprob": -0.23106467303107767, "compression_ratio": 1.6373056994818653, "no_speech_prob": 4.830821853829548e-05}, {"id": 1372, "seek": 586740, "start": 5867.4, "end": 5878.4, "text": " Go make some bold decisions because and allow for different approaches to coexist that make different versions of those trade offs.", "tokens": [1037, 652, 512, 11928, 5327, 570, 293, 2089, 337, 819, 11587, 281, 48086, 300, 652, 819, 9606, 295, 729, 4923, 39457, 13], "temperature": 0.0, "avg_logprob": -0.22376335441292106, "compression_ratio": 1.5616438356164384, "no_speech_prob": 1.7501906768302433e-05}, {"id": 1373, "seek": 586740, "start": 5878.4, "end": 5883.4, "text": " And so you don't have to take that responsibility of solving every problem.", "tokens": [400, 370, 291, 500, 380, 362, 281, 747, 300, 6357, 295, 12606, 633, 1154, 13], "temperature": 0.0, "avg_logprob": -0.22376335441292106, "compression_ratio": 1.5616438356164384, "no_speech_prob": 1.7501906768302433e-05}, {"id": 1374, "seek": 586740, "start": 5883.4, "end": 5892.4, "text": " Yeah. Or try to find a novel way that solves everything in a nice way, which is usually what we end up doing in the Elm world somehow.", "tokens": [865, 13, 1610, 853, 281, 915, 257, 7613, 636, 300, 39890, 1203, 294, 257, 1481, 636, 11, 597, 307, 2673, 437, 321, 917, 493, 884, 294, 264, 2699, 76, 1002, 6063, 13], "temperature": 0.0, "avg_logprob": -0.22376335441292106, "compression_ratio": 1.5616438356164384, "no_speech_prob": 1.7501906768302433e-05}, {"id": 1375, "seek": 589240, "start": 5892.4, "end": 5898.4, "text": " Often with success and I guess the success, the failures are not published or.", "tokens": [20043, 365, 2245, 293, 286, 2041, 264, 2245, 11, 264, 20774, 366, 406, 6572, 420, 13], "temperature": 0.0, "avg_logprob": -0.27283005598114757, "compression_ratio": 1.5096153846153846, "no_speech_prob": 3.5906326957046986e-05}, {"id": 1376, "seek": 589240, "start": 5898.4, "end": 5902.4, "text": " It's true. It's true. There's a bias there. Definitely.", "tokens": [467, 311, 2074, 13, 467, 311, 2074, 13, 821, 311, 257, 12577, 456, 13, 12151, 13], "temperature": 0.0, "avg_logprob": -0.27283005598114757, "compression_ratio": 1.5096153846153846, "no_speech_prob": 3.5906326957046986e-05}, {"id": 1377, "seek": 589240, "start": 5902.4, "end": 5910.4, "text": " Yeah, it depends on the example. I guess like Elm Review does a great job sort of making the best of both worlds.", "tokens": [865, 11, 309, 5946, 322, 264, 1365, 13, 286, 2041, 411, 2699, 76, 19954, 775, 257, 869, 1691, 1333, 295, 1455, 264, 1151, 295, 1293, 13401, 13], "temperature": 0.0, "avg_logprob": -0.27283005598114757, "compression_ratio": 1.5096153846153846, "no_speech_prob": 3.5906326957046986e-05}, {"id": 1378, "seek": 589240, "start": 5910.4, "end": 5914.4, "text": " Whereas something like Elm GraphQL inherently there's a decision.", "tokens": [13813, 746, 411, 2699, 76, 21884, 13695, 27993, 456, 311, 257, 3537, 13], "temperature": 0.0, "avg_logprob": -0.27283005598114757, "compression_ratio": 1.5096153846153846, "no_speech_prob": 3.5906326957046986e-05}, {"id": 1379, "seek": 591440, "start": 5914.4, "end": 5922.4, "text": " Do you have a query builder style or a generator style that spits out code for a specific GraphQL query?", "tokens": [1144, 291, 362, 257, 14581, 27377, 3758, 420, 257, 19265, 3758, 300, 637, 1208, 484, 3089, 337, 257, 2685, 21884, 13695, 14581, 30], "temperature": 0.0, "avg_logprob": -0.16723580890231662, "compression_ratio": 1.5875, "no_speech_prob": 1.723069726722315e-05}, {"id": 1380, "seek": 591440, "start": 5922.4, "end": 5930.4, "text": " Those are trade offs that there's you just have to pick one and say, we think there are merits to this approach,", "tokens": [3950, 366, 4923, 39457, 300, 456, 311, 291, 445, 362, 281, 1888, 472, 293, 584, 11, 321, 519, 456, 366, 40923, 281, 341, 3109, 11], "temperature": 0.0, "avg_logprob": -0.16723580890231662, "compression_ratio": 1.5875, "no_speech_prob": 1.723069726722315e-05}, {"id": 1381, "seek": 591440, "start": 5930.4, "end": 5937.4, "text": " but we can't make a perfect solution that makes everybody happy because there are trade offs.", "tokens": [457, 321, 393, 380, 652, 257, 2176, 3827, 300, 1669, 2201, 2055, 570, 456, 366, 4923, 39457, 13], "temperature": 0.0, "avg_logprob": -0.16723580890231662, "compression_ratio": 1.5875, "no_speech_prob": 1.723069726722315e-05}, {"id": 1382, "seek": 591440, "start": 5937.4, "end": 5942.4, "text": " Well, anything else we should point people to for writing great docs?", "tokens": [1042, 11, 1340, 1646, 321, 820, 935, 561, 281, 337, 3579, 869, 45623, 30], "temperature": 0.0, "avg_logprob": -0.16723580890231662, "compression_ratio": 1.5875, "no_speech_prob": 1.723069726722315e-05}, {"id": 1383, "seek": 594240, "start": 5942.4, "end": 5948.4, "text": " I think we've already given a lot of great tools and links, so you can see those in the show notes.", "tokens": [286, 519, 321, 600, 1217, 2212, 257, 688, 295, 869, 3873, 293, 6123, 11, 370, 291, 393, 536, 729, 294, 264, 855, 5570, 13], "temperature": 0.0, "avg_logprob": -0.21139698697809586, "compression_ratio": 1.7093023255813953, "no_speech_prob": 6.745960035914322e-06}, {"id": 1384, "seek": 594240, "start": 5948.4, "end": 5954.4, "text": " Try to do your best. Try to make it to make it understandable by people.", "tokens": [6526, 281, 360, 428, 1151, 13, 6526, 281, 652, 309, 281, 652, 309, 25648, 538, 561, 13], "temperature": 0.0, "avg_logprob": -0.21139698697809586, "compression_ratio": 1.7093023255813953, "no_speech_prob": 6.745960035914322e-06}, {"id": 1385, "seek": 594240, "start": 5954.4, "end": 5961.4, "text": " Ask for feedback and iterate like you're not going to get things right the first time you're going to have typos.", "tokens": [12320, 337, 5824, 293, 44497, 411, 291, 434, 406, 516, 281, 483, 721, 558, 264, 700, 565, 291, 434, 516, 281, 362, 2125, 329, 13], "temperature": 0.0, "avg_logprob": -0.21139698697809586, "compression_ratio": 1.7093023255813953, "no_speech_prob": 6.745960035914322e-06}, {"id": 1386, "seek": 594240, "start": 5961.4, "end": 5964.4, "text": " You can have things that are not clear and that's fine.", "tokens": [509, 393, 362, 721, 300, 366, 406, 1850, 293, 300, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.21139698697809586, "compression_ratio": 1.7093023255813953, "no_speech_prob": 6.745960035914322e-06}, {"id": 1387, "seek": 594240, "start": 5964.4, "end": 5971.4, "text": " Just one thing. Try to avoid breaking changes as much as possible, but it's not a big deal either.", "tokens": [1449, 472, 551, 13, 6526, 281, 5042, 7697, 2962, 382, 709, 382, 1944, 11, 457, 309, 311, 406, 257, 955, 2028, 2139, 13], "temperature": 0.0, "avg_logprob": -0.21139698697809586, "compression_ratio": 1.7093023255813953, "no_speech_prob": 6.745960035914322e-06}, {"id": 1388, "seek": 597140, "start": 5971.4, "end": 5973.4, "text": " Yeah, and listen to your users.", "tokens": [865, 11, 293, 2140, 281, 428, 5022, 13], "temperature": 0.0, "avg_logprob": -0.19855033874511718, "compression_ratio": 1.6180257510729614, "no_speech_prob": 2.5858511435217224e-05}, {"id": 1389, "seek": 597140, "start": 5973.4, "end": 5979.4, "text": " I skimmed a little bit through a book that I had heard about called Docs for Developers,", "tokens": [286, 1110, 332, 1912, 257, 707, 857, 807, 257, 1446, 300, 286, 632, 2198, 466, 1219, 16024, 82, 337, 11442, 433, 11], "temperature": 0.0, "avg_logprob": -0.19855033874511718, "compression_ratio": 1.6180257510729614, "no_speech_prob": 2.5858511435217224e-05}, {"id": 1390, "seek": 597140, "start": 5979.4, "end": 5981.4, "text": " and I quite liked what I read.", "tokens": [293, 286, 1596, 4501, 437, 286, 1401, 13], "temperature": 0.0, "avg_logprob": -0.19855033874511718, "compression_ratio": 1.6180257510729614, "no_speech_prob": 2.5858511435217224e-05}, {"id": 1391, "seek": 597140, "start": 5981.4, "end": 5987.4, "text": " It was in a nice skimmable format, and they even talked about the importance of being skimmable,", "tokens": [467, 390, 294, 257, 1481, 1110, 6753, 712, 7877, 11, 293, 436, 754, 2825, 466, 264, 7379, 295, 885, 1110, 6753, 712, 11], "temperature": 0.0, "avg_logprob": -0.19855033874511718, "compression_ratio": 1.6180257510729614, "no_speech_prob": 2.5858511435217224e-05}, {"id": 1392, "seek": 597140, "start": 5987.4, "end": 5994.4, "text": " which is near and dear to my heart as a reader of some portion of documentation.", "tokens": [597, 307, 2651, 293, 6875, 281, 452, 1917, 382, 257, 15149, 295, 512, 8044, 295, 14333, 13], "temperature": 0.0, "avg_logprob": -0.19855033874511718, "compression_ratio": 1.6180257510729614, "no_speech_prob": 2.5858511435217224e-05}, {"id": 1393, "seek": 597140, "start": 5994.4, "end": 5997.4, "text": " I would definitely recommend checking that out.", "tokens": [286, 576, 2138, 2748, 8568, 300, 484, 13], "temperature": 0.0, "avg_logprob": -0.19855033874511718, "compression_ratio": 1.6180257510729614, "no_speech_prob": 2.5858511435217224e-05}, {"id": 1394, "seek": 599740, "start": 5997.4, "end": 6002.4, "text": " Yeah, but you don't know why it's important for things to be skimmable because you've skimmed that, right?", "tokens": [865, 11, 457, 291, 500, 380, 458, 983, 309, 311, 1021, 337, 721, 281, 312, 1110, 6753, 712, 570, 291, 600, 1110, 332, 1912, 300, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.19245542453814157, "compression_ratio": 1.4666666666666666, "no_speech_prob": 1.8630717022460885e-05}, {"id": 1395, "seek": 599740, "start": 6002.4, "end": 6003.4, "text": " That's right.", "tokens": [663, 311, 558, 13], "temperature": 0.0, "avg_logprob": -0.19245542453814157, "compression_ratio": 1.4666666666666666, "no_speech_prob": 1.8630717022460885e-05}, {"id": 1396, "seek": 599740, "start": 6003.4, "end": 6007.4, "text": " Okay, yeah, sure. Just want to be clear about that.", "tokens": [1033, 11, 1338, 11, 988, 13, 1449, 528, 281, 312, 1850, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.19245542453814157, "compression_ratio": 1.4666666666666666, "no_speech_prob": 1.8630717022460885e-05}, {"id": 1397, "seek": 599740, "start": 6007.4, "end": 6008.4, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.19245542453814157, "compression_ratio": 1.4666666666666666, "no_speech_prob": 1.8630717022460885e-05}, {"id": 1398, "seek": 599740, "start": 6008.4, "end": 6011.4, "text": " All right. Well, Jeroen, until next time.", "tokens": [1057, 558, 13, 1042, 11, 508, 2032, 268, 11, 1826, 958, 565, 13], "temperature": 0.0, "avg_logprob": -0.19245542453814157, "compression_ratio": 1.4666666666666666, "no_speech_prob": 1.8630717022460885e-05}, {"id": 1399, "seek": 601140, "start": 6011.4, "end": 6029.4, "text": " \u266a\u266a\u266a", "tokens": [50364, 220, 158, 247, 103, 158, 247, 103, 158, 247, 103, 51264], "temperature": 0.0, "avg_logprob": -0.6452919886662409, "compression_ratio": 0.6428571428571429, "no_speech_prob": 0.00012309118756093085}], "language": "en"}