{"text": " Hello Jeroen. Hello Dillon. This conversation is provided as is, without warranty of any kind. Just wanted our listeners to know that. Alright, alright. A pun at every start of the episode. I really don't know how you maintain this pace for your puns. I mean, you really pull your weight for them. But I just want you to know, if you ever stop doing them, it's not an issue. Just, it's fine. I have a license to pun. What are we talking about today? Today we're talking about the human side of open source. And I believe you and I have perhaps dabbled in open source a little bit, I would say. Yeah, I'd say so. I mean, how long has it been for me? I think I started in 2017 with open source. Yeah, that's starting to be quite a while already. Do you remember what your first open source was? Yeah. First contribution was fixing a license. Oh! It was fixing the dates for a license. Nice! For someone's blog. And the next one was doing the documentation for lodashfp. Which was more ambitious already. Yeah. I believe my first open source project was in 2013. And it was a random little Ruby executable for helping you with an interface to git. Which probably two of my co-workers used. Which is less than zero. Right, yeah. Oh, I guess I did publish an npm package or something around 2014 or 2015. But getting really involved in other people's projects in 2017. And that's when my project started as well. Yeah, it definitely changes the game when number one you have users and number two you have contributors. It doesn't really feel like open source if you don't at least have people opening issues and telling you about problems they're experiencing. Or things that could be improved or discussing things with you. Right, yeah. If you only publish your package or your code and you put it on github. It's very different from people interacting with you. Making suggestions, making pull requests. Telling you your code is crappy, your project sucks. Right, exactly. Which thankfully I have not had. I've had a very good interaction with all of my open source projects so far. That's awesome. One of the things on my mind today is like, why do open source? Like why do we even bother making a tool open source when we build one? What are the motivations for us, for the community? What's the benefit, what's the point of making something open source? Right, well there are several. One of them is feeling like you are helpful to people. I think that's one thing that we tend to like as software engineers, as humans as well. Just being helpful to others. Like I'm making a project, I'm making a website, I'm making a tool that helps other people. Any software project is basically to help someone. It's usually you, even if it's just like making a video game. It's helping you entertain yourself for an hour or two or two hundred. So yeah, I feel like being helpful to other people. So if something is open source, it's really accessible, people can use it. There's also the recognition part. I want to, I've made a tool or I've made something which I think is useful. And I want other people to know about it. Maybe to get my career going, to get, to have recruiters think that I am very qualified. I have actually, for instance, like made a tool once. Oh, that was in 2014, which I put on GitHub and it helped me land a job because they asked me like, Hey, do you have some code that you have available that we can look at? And I'm like, sure, you can look at this one. And they hired me pretty much because they said it had tests. So, you're running tests, you're qualified. That's awesome. Pretty low bar. I mean, I was quite junior back then, but yeah. So yeah, recognition through multiple forms, like being just a junior who knows how to code quite well or being a very famous maintainer who you can hire for consultancy on one of your projects. Yeah, yeah, those are the two I can come up with. It's mostly like helping people though. I like that. I feel the same way. I think helping people is really, there is something at the core there that you're right. Like when we're building software, like if we're building software that doesn't help any single person in the world, like why would you build it? It doesn't really solve any problems. So you want to solve some problems. And, you know, you mentioned like accessibility and I feel the same way, like with open source projects, it's just, it's more usable and accessible. It's whether that be going and installing something on NPM or copying part of the source code, because some, you know, some module in your code is doing something that somebody else needs for another project, or they want to go look at it for reference and see how you implemented something. Maybe you're using the same framework under the hood and somebody just wants to go look at the code and see how someone else did it. Yeah, there's definitely like a learning aspect to open source as well, where you look at other people's code and you learn from that. Yes. Right. And I definitely feel like doing more open source has helped me reach new levels, which would have been hard to reach if I only did programming at work. Yes, absolutely. And, you know, to your point of wanting to build things that help people, you want to leverage that too. So the more leverage you have, the more your thing can help people. And if it's open source, it can help people in these different ways. It can help people by them looking at the source code. It can help them by them being able to use it as a dependency in another open source project, because it's just an open source thing. They don't need licensing. They don't need to think about any of these considerations, but they can also use it in a proprietary project and they don't have to think about that. And, you know, for me as an open source maintainer, that gives me great joy. If people use an open source tool that I built in their business, that makes me very happy. I mean, honestly, if no businesses used the tools that I built, then I might not build them. That's like one of the main motivations. And it makes it a lot easier for businesses to build them. Like these days, it's hard to imagine a business betting on a programming language that's not open source. This has not always been the case, but there's been sort of a revolution where that's the expectation, because, you know, how are you going to feel confident about the security of a project if you can't look at the code and see what it's doing? I think there used to be sort of the opposite view maybe a decade or two ago. For languages or for projects or tools in general? For both, yeah. I mean, there's also just like the fact that it's very cheap because it's costless. Like, it doesn't cost you any penny to use it. Well, until you have to maintain it a little bit because the quality might be a little bit more, a little bit worse than if you use a proprietary solution, which should hopefully be better. Like it can go both ways, right? Right. I mean, if it's open source, then it's open to contributions. But if it's not open source, then it might be more sustainably funded. So that's sort of getting to the other side of what might be some of the downsides of open source or perhaps not strictly downsides, but challenges that I think, I feel that we're at a pretty novel stage of open source. And we have a lot of maturing to do as a software community in figuring out, like we've kind of decided that open source is the way to go for most projects, for languages and frameworks and libraries for the most part, for 95, 99% of them. But we haven't really figured out how to make the huge ambitious open source projects we depend on sustainable and avoid burnout for the people maintaining them. Burnout. Open source little friend. Yeah. So that's another side of it. And I mean, I recently spent a year and a half working full time on the on-page V3 release. And it was very rewarding. I got to build this thing that I really cared about. But it was, I mean, and I was fortunate enough to have a company helping to fund my work, but I was still the primary sponsor of my work. Right. And I think a lot of people in the open source community end up doing that. There are some projects that are lucky enough to have massive sustainable funding, but the majority of open source is not that way. I mean, when you say massive, I'm like, it's still pretty small. Like any project you can think of has very little backing compared to any projects that you can find at work. Yeah. I mean, like React, for example, would be one of the big ones that comes to mind where they have enough budget to hire full time teams of people building documentation. But it's rare and that might not last forever either. Yeah. I think actually some of them are moving towards other companies. So it's diversifying in a way, which is probably good. My memory might be wrong about this, but if it is, then yeah. No. Yeah. I mean, Dan Abramoff recently left Meta. So and he was one of the key people in the React team, but he's still going to be on the React core team just at a different company, I think. So it's just the difference is who pays him, I guess. Yeah. Yeah. And perhaps whether he'll be paid for it. I'm not sure in that particular instance, but it's definitely a challenge for the open source world. And of course, in the Elm community, we are particularly aware of this because we've seen different permutations in the life of Elm with how Evan has been funding Elm's development. And we had an episode about funding open source with Evan, and he talked about a lot of different ideas there. And a lot of the challenges of aligning the incentives between a business and an open source project is very difficult. So another thing that comes to mind for me with open source is, so what should users of an open source project expect? And what should maintainers of an open source project expect from their users? Perfection. I expect nothing less than perfection from anyone. Sometimes it feels that way. Do you mean like, for instance, if I open an issue, what should I expect? Yeah. Or if I'm a maintainer, what do users expect of me? What do I expect of them? Yes. I have a feeling you want to lean me towards someone. Well, I have opinions, but I'm curious what yours are. I mean, I know that one of the things that people dislike with open source is when you're a maintainer and there's a user who doesn't ask for something, who doesn't open an issue or make a pull request on something, and says, could you please look at this, but who would demand that you look at something, basically as if they were owed something. And that is obviously not a great expectation, which if it works out for the maintainer, sure. If it doesn't, then refer to the license. There's no warranty. The maintainer is not getting paid for any of the work. They are not compensated, so you should not expect anything from them except their benevolence, I guess, in a way, like their empathy and their willingness to work for free just to make some people happy. So is that where you wanted to lead me? Yeah, it kind of is. I knew it. I definitely feel the same way. So what should users expect from an open source project? And yeah, to me, the answer is you shouldn't expect anything. But that's obviously not great if you're just like, whatever, I don't care what this project needs. Obviously, I don't think that's the right answer either. But I think the question for me is what do you want out of the project? If you put an open source project out there, if you publish your blog as an open source project, what should people expect from you? Clearly, that's kind of it. It's like, this is my blog, and you can look at it, and you can copy some of the code if you, whatever, put the license in the right place. But that's it. People don't really expect much more. But somehow, when it's publishing a library or a framework, people can start to expect that they can set the agenda. I don't think that doesn't feel good as a maintainer when that's the vibe you're getting from somebody. But at the same time, if you create a project that people are depending on, then I think if you want that to be a sustainable thing that people are going to continue to engage with, you are somehow going to need to earn the trust of users. So that's how I look at it. It's like, what do you want this project to be? And it's totally fair if somebody wants to make a project and ride off into the sunset. That's totally fine. They're allowed to do that. And I don't blame an open-source maintainer who does that. But I think that everybody's going to have a better experience if they can set those expectations. If that's what you're doing, then say, hey, this is it. This project will never have any more commits. Don't bother opening issues because I'm not going to look at them. I think you should express that. Which in GitHub you can do through archiving, for instance. Yeah, right. Absolutely. Yeah. So I think there's somewhere in between those two extremes. But either way, I think setting expectations is a good thing. And I think... So for me, with my open-source projects, I often find that things work best when the roles are operating a certain way. So I don't see my role as an open-source maintainer as being to do everything that everybody wants for the project. And in fact, I couldn't if I wanted to. Because if I did everything that everybody wants for a project, then one person would want this, and another person would want another contradictory thing. So it's literally impossible. And that's one thing that I, as a maintainer, really appreciate, is when people recognize that I am, as a maintainer, balancing conflicting desires for a project, conflicting directions. And so while somebody might have an opinion that a particular direction is good, and I want to hear about that opinion, I really appreciate it when people recognize that it is one opinion that I'm going to need to balance out, as somebody leading an open-source project, with my opinions and other people's opinions. And theirs is just one possible direction. So I really appreciate that sentiment, because if people are coming at it in that way where they expect their preferred direction to be executed on, then it's giving you a whole other hurdle to have to jump over, where now not only do you have to potentially work on something, but you need to do all this extra effort to communicate that and set those expectations. So when people make it clear that they are not expecting you to do whatever they're asking for, it just makes it less work for the maintainer. So that's one thing you can do as a contributor, is make it clear, like, I'm just making sure these options are there for your consideration. I don't expect you to do this free labor. I don't expect you to choose my direction. But I wanted to put this out there for your consideration. So, Lint, I find it really nice when people are thinking about it as not just, like, what should you do as a maintainer, but how do we make this project operate smoothly? And how do we make sure that this project is kind of having all these great ideas presented so they can be considered? I feel like that touches on something that I quite enjoy with my projects, or at least the feeling that I get with my projects. I feel like everyone who interacts with mine, they all want, just like me, the best from the project. And we all know that that is made of trade-offs. So some people might say, I would like to have this, and then I respond, or other people respond with, well, if that is true, or if you want this, then you're going to have a problem with this situation, you're going to have this to handle as well. Plenty of trade-offs to think about and to figure out the best solution that works for the most people, or a custom way that works for you but will not work for others. That might be a solution as well. Yeah, I just feel like people have this understanding, which I love. If you have interacted with me on ElmReview in any way, shape, or form, you're a part of this. And I really appreciate it. People are thinking of what is best. And me, myself, even though I'm the maintainer, I am just someone with one opinion. In practice, I will probably make the end decision because they're my projects, but people are allowed to fork them. But I am successful at convincing people of my opinions that they're not totally wrong. And sometimes I'm just convinced that that can also happen. And I'm really happy when I get convinced as well. So that feels good. The expectations I have with people who interact with my projects is that we will have a conversation. You are submitting an idea, a bug report, and fixing or adding that feature is not necessarily going to be simple. So let's talk it out. Let's figure out a solution. And let's implement it. And that implementation part might be me by me, you, might be in a few years from now. I am spread thin, and I'm not doing this full-time because Meta is not doing Elm and is not paying me. So I'm happy that I'm getting these interactions. And that's why I feel like I have very good interactions with the Elm community, the open source. Yeah, that resonates with me a lot. So, you know, like the recognizing trade-offs, recognizing that the timeline, like users of an open source project don't get to dictate the timeline. That's not the role of the user. And they also don't get to dictate the agenda because, as you said, like they can present trade-offs, but ultimately, like the person leading an open source project, they're going to come to some conclusions that might be different than somebody else. Many times there are different ways to approach an open source project. And I think open source projects work best when they recognize that, to me, a project is a perspective. You can't try to incorporate every perspective into it because that's just watering it down. A project is choosing a perspective and committing to that. And I think they work best when they do that. And I think open source projects work best when the communication also recognizes that. When you say, this project goes with this approach. The approach you're talking about here sounds like a totally valid set of trade-offs, but here are the core values that are laid out for this project. Here are some examples that show that. Here's ideally where some of these values are written down. Or let's write them down now because I'm realizing that we have these values for this project now that this might not be aligned with. And I think the more somebody depends on a project, the higher the stakes are. So if you make it a little extras helper package in the Elm ecosystem, if somebody has a different perspective on it, then you say, hey, that sounds like a great idea. It's just not what I see for the vision of this particular extras package. So somebody else can go and make another version of it. Maybe it starts as a fork. Maybe it's a totally different thing. The stakes are very low. If you're talking about the programming language itself, Elm, the stakes are very high. And I think that emotions can run high as well when people are saying, I depend on the future of this project because this is the language I'm using. Not only is it the language I'm using, but it's a highly constrained language with the philosophy of not providing escape patches. So if you don't provide an escape patch for me, or if you don't provide a path for me, then I'm highly dependent on that. So it feels more emotionally charged in cases like that. Yeah, I think it's important. Well, I don't know if it's important. I think it's helpful, very helpful, when projects convey their goals and their non-goals, which you kind of said with the perspectives. Like my goals with Elm Review is to have something, blah, blah, blah, that is blah, blah, blah. And for my goals, but some of what people can perceive as goals are not goals. Like I don't want to turn Elm Review into a language server. That is a non-goal. Maybe that will evolve. Who knows? I don't think so. But at the moment, there are non-goals. And the same thing is for extra packages. The same thing is for Elm. Like some of the goals for the Elm language is that we make something that is really maintainable, easy for beginners, and fun maybe in a way, delightful. And those are the goals. If something makes those goals disappear, like adding a new feature that makes error messages really hard to read, type classes, for instance, is one example that I've heard of multiple times. Well, that conflicts with the goals. So the trade-offs have to be, like the benefits you get from adding such a feature have to be really high in order to compensate the loss of error-friendliness. But something that is a non-goal, like for instance, having direct FFI, direct interrupt with JavaScript, is not a goal of Elm. You have to go through these escape hatches, ports, that are available. And they are a goal of Elm to set up a nice barrier around your code. And that's the way that things were thought of. It is not meant to provide direct FFI, unless that happens to be easy, nice, and without any judgments to other features. Right, like guarantees, which is a huge part of the language. Safety and guarantees. So I'm sure, for instance, Evan would be all for type classes and FFI if we didn't lose the guarantees, and if we didn't lose the ease of use of the language. Exactly, yeah. So if someone can come up with solutions to that, then that's probably going to happen one day. If they don't, or if they conflict too much in trade-offs, it won't. So yeah, defining your goals and your non-goals, that can help people know whether they even have to suggest an idea, or how much they have to push it, or if they get pushback, like understand, we're not going to go with this approach because we have these goals. And I think that helps explain it. I don't know if I make my goals clear enough with Elm Review. I'm thinking probably not, but who knows. What about you for your project? I mean, I've definitely made an effort to lay out my goals, and I do sometimes reference them in poll requests or issues. Sometimes people will say, hey, it would be really great if ElmGraphQL could support aliases. And I'll say, well, if there were a way to support that, that was in line with these goals, then that would be great. But I've found that it makes it a lot easier to communicate when it's all around these goals. Like, you know, there's something called nonviolent communication. Sometimes people call it compassionate communication, which interests me a lot. What did you say? What did you call it? And the basic idea of it at the core is that you're basically recognizing that everybody universally has certain universal needs. You know, a need for entertainment and a need for ease and peace and things like that. These are basic core human needs that we recognize in everybody, and it's not something we would dispute. The need for rest. But just because somebody has a need for entertainment doesn't mean they can say, hey, Jeroen, do a dance right now. Because, well, okay, maybe you can. I am doing a dance right now. He's doing a dance. Pseudo-Jeroen, do a dance right now. But basically these needs, these universal needs, don't have a specific person, place, or time for how to fulfill those needs. So you can still recognize that the need is there. I have a need to be entertained, but I can't require you. It's no longer universal when I'm requiring you right now to meet that need for me. So in nonviolent communication, that would be called a strategy. That would be one strategy to meet that need, but there are multiple strategies to meet the need for entertainment. So I see it as very similar in open source, and that's really helped me navigate a lot of these open source communications. I mean, not even communication, but just receiving requests in an open source project is like understanding, okay, I get why somebody might be dependent on this particular project. And so what is their need? They're trying to solve a problem. But similarly, this happens a lot in communication with communicating needs. Often the point of conflict in communication is when we try to demand a particular strategy. I say, you're in a dance right now. If I just instead said, like, oh, man, I could go for, like, something fun and entertaining right now. If I started with that, then we could explore different ways, different strategies for meeting that need, and we would have a much easier conversation. And I feel it's much the same thing in open source. If we can start with the universal needs, it just reduces the conflict level and it makes it less stressful for the open source maintainer and the user, I believe. For example, I think the user, I want to hear what is their pain point, what is their experience, what is the problem they're solving. But often a request, a GitHub issue, starts with this project needs this, this project needs to do this. If instead they said, context, I'm using this project, I'm trying to solve this problem, I'm not sure how to do it, this is what I tried, this is what I ran into, possible solution. What if you had an API that allowed you to do this? And that gives the open source maintainer or somebody else who is looking at the issues for the project the opportunity to perhaps the solution takes the form of, oh, well, here's an API that maybe you haven't tried. Why don't you try using it this way? That might solve your problem. Or maybe there's another API, the API could take another form. Maybe we could explore that. So now it's an exploration and the tensions are less high because it's not like my way or the highway. We can explore options together without feeling like it's winner takes all, zero-sum game, one of us is going to get our way and one of us is not. And also, even if you went with this project needs this new feature and the maintainer is like, okay, sure, I'll add it. Well, maybe the feature will not be what the person requested in the first place or exactly like, oh, no, I actually wanted it to return this value when this argument is given. Oh, but that's not what I understood. But if you start with a problem to solve, then things become clear. I mean, just like in an open source project, at work they tend to say like, don't come up with, don't present solutions, present problems and present ideas. Exactly. And as you mentioned earlier, there could be different ways to address the underlying problem or maybe solving that problem is not in the scope of the project. Maybe it's a non-goal of the project or maybe it's a goal of the project but it's not a goal for the maintainer or the maintainer doesn't have time to work on that or doesn't have the motivation to work on that particular thing. And that's okay, too. And I do think I'm not saying that maintainer, I mean, obviously I believe you and I have put in huge amounts of our free time to trying to do things in response to requests people have made. Right? So we're obviously not opposed to responding to people's requests and building something for them. But I think it just is really healthy for a project to recognize that, hey, you can request something and I can say, hey, that sounds like a great idea, pull requests are welcome. Or maybe I decide to build it. And I think for me, especially like as, I mean, I have a lot of open source projects. I get a lot of feature requests in my inbox. And I can't, I literally can't do every single feature request everyone puts in my inbox. It wouldn't, if I did, I would implicitly be saying no to somebody else's feature request because by starting to work on something, I wouldn't have time to work on the other thing. And that's even if I'm working full time, like literally, it's just not possible. When you say full time, do you mean only eight hours a day? Right. Probably not. And not on weekends? Come on, put in some effort. Yeah. I mean, often not. And even then. And, you know, so I think it's, I think it depends on the type of issue, right? If there's like a blocking issue, it's a core feature of the framework and it's blocking people from solving basic use cases with the tool or library. Right. Obviously that's going to change your prioritization on it compared to some nice to have feature. Hey, this would be a really handy thing to have. And in cases like that, I'm much more likely to say, hey, that sounds really interesting. I would be glad to like do the work to review a pull request and then for the rest of this project, maintain this code, which is actually a very large cost. Right. Like when you're, when somebody is, it's not free to just pull in somebody's code because, oh, they wrote this code. When somebody writes the code, you're now committing to continue to consider how that feature affects the project. So any new features that are added, you need to consider that feature and how it interacts with new features you're adding or new bug fixes you're doing. And reviewing that code is not free. Somebody might make a pull request that has several subtle bugs. Right. So it's, it's actually, you know, there's less investment needed to make a pull request because you're not taking on responsibility for the project's long term. Like if somebody makes a pull request and there are bugs that result from that, are they then going to fix them? Or are you going to revert the feature if you find that there were bugs with it? Probably not. You might be spending some of your weekends and evenings fixing that bug, which actually happens to me frequently. Right. So it's, I think it's really good to recognize that open source, there is a cost to, to it. It's not just reviewing a pull request, but to, to taking on new scope. So I think it just helps to recognize, to have empathy for that, you know? Yeah. I feel like some of the best features that are requested and which will motivate me the most is the ones that I want myself. Like for instance, I make Elm Review and I'm a user of Elm Review. And there are some people who say, well, it would be nice if we could make a rule that does this, or if there was this rule. And I'm like, yeah, I want that as well. Like the no news record fields, for instance. Doesn't exist, would be amazing to have. And it's more likely that people that that will happen if you get me on board with the, the intent of your, with your idea. And me as a maintainer, I want my project to work as best as possible for my users because empathy, I guess. So if there are bugs that are, that I can solve, then I will solve them. If there is a pull request, even better. But yeah, if you get me on board because I want my project to be as flawless as possible, and, or you want a new feature that I also want because I want my product to be as useful as possible, then that's going to give you the best changes to, to get your idea in. I don't know how you can affect what I want though. But yeah, I guess that's part of the goals of the project as well. Like you probably know where I want to go in a way where you can kind of guess. And well, through discussion we will figure out whether I do or I won't. Yeah. I would say for me, like one, one thing that makes me far more likely to either roll up my sleeves and, and implement something myself or, or, or be interested in somebody making a pull request about a particular feature and wanting to whatever, have Slack messages coordinating that and that sort of thing is how much are they invested in it? Like if somebody, if somebody opens a GitHub issue and says, Hey, this would be really cool. And there's nothing laid out of like, what problem does this solve? Why do I have this problem? What are possible trade-offs? What are possible downsides to this new feature? What are possible approaches and implementations? Like I'm not very likely to consider a feature request if it's just a sort of not, if it's not giving me that motivation of why, why is this important? It's like, well, if you don't care enough to really lay out what problem this is solving and, and really dig into like, how would you do this? Why should I be interested enough to do that for you to, to flesh out this feature idea more deeply? So I'm probably not going to prioritize that over something else where someone has done that. Are you saying that if you get a issue saying as a title, add feature X and that the comments of, of the issue says no description, the when it's empty, but you're not getting passionate. Like you don't have a fire burning and causing you to roll up your sleeves and get to work. Really? I say that not, not just as a, like, you know, old man yells at cloud. Although partially I also say it is that, but I also say that as like, and I actually make an attempt to, to communicate those types of things on issues and say, Hey, if you think this is interesting, I'm, I'm willing to like accept a pull requests. If you can help me understand like what problem this would solve and how you would do this and how the trade-offs are going, going to look and how it's going to interfere or not interfere with this feature, you know? So I try to communicate those things. And actually pretty often people do say, okay, great. Yeah. I'd be happy to do that. And they write out super thoughtful comments and get some prior art and show me how other projects have solved this problem and maybe make a pull request or make a pull request that has some failing tests. So it, I think giving users the opportunity to do that and communicating like what, what you need as a maintainer is really good too, because at the end of the day, as you said, like, I mean, I think open source is a tool for making our projects more accessible, but also like helping people more and contributions are a tool for that. And the way we build our open source projects, the way we communicate in our open source projects are tools for that, because at the end of the day, we're putting time into this because there's something we care about putting into the world. We care about being able to have more guarantees in an Elm project by doing more powerful static analysis. That's like, I believe that's something that you care about at your core and managing an open source project effectively leverages you to be able to do that better, to, to put that vision into the world in a more effective way. So I think communicating can help people do that. And I think also like, so I often think about like the role of a, an open source maintainer or lead on an open source project as kind of like a CTO for, for a mini company. And as that company scales, the role of the CTO also changes. So, you know, if you're CTO in a company of two, then, then you're, you're the developer of the company, right? You're also making technical decisions that if that company were to take off and become a company with a hundred developers, a thousand developers, those technical decisions are going to impact the long-term roadmap for the company and the long-term success technically of the project. So that's the hat I'm wearing early on in an open source project when I'm maybe not even sure it's going to be successful, right? Maybe it'll be a failed startup. Maybe it'll be an open source project that nobody uses and, and that can happen and that's okay. But, that's the hat I'm wearing when I'm early on in an open source project. And as the project scales, I tend to play a more strategic role and I'm thinking about how do I make technical decisions? How do I help mentor people? You know, how do I get on call? Like maybe I'm going to be spending more time getting on video calls with people who want to make contributions to help them, to pair with them to help talk through certain trade-offs or technical questions. And I'm also like thinking really hard about high level strategic choices, like what's our testing strategy going to be? Are we doing some snapshot tests? Are we doing fuzz tests on this? Like what's going to ensure quality and make that high bar for anybody contributing to it? Not just me, because if it's a, if it's a big project that a lot of people depend on, I want to make it easy for a lot of people to contribute to it. And so that's something I'm really focusing a lot of my time on that. I think I uniquely need to be focused on as the CTO of the open source project as it grows. Right. So when you get someone to contribute a pull request, how much do you care about like the quality of the contribution? What are the types of things you're thinking about with quality? I'm curious. So whenever you get a pull request, you will wonder a few things like is it code? Does a code look okay? Does this handle all the different cases? Are there any obvious bugs that can be found? Is it co-style okay? Like all those things. Which ones do you care about? Which ones do you not care about? Yeah. I tend to be fairly trusting about contributions. I look for ways that a contributor can show me that they're, that they're taking ownership of those considerations. And if I'm not being given signs of that, then I'll ask to be communicated with in a way that gives me signs of that. Like, what are the things you're thinking through here? Like, can you lay that out for me? Because in general, I don't want to micromanage people's contributions. I generally want to trust them and give them some level of ownership. And, you know, there are certain quality standards that I have for the project that are pretty superficial to check. Did you write tests? Is the CI green? Right. Like, but I try to automate those as much as possible. Like I'm not going to go through and check code style and things like that because Elm format in my CI and Elm review in my CI and my approval test suite and my unit test suite do that. In the pull request, I am going to say, hey, I noticed this doesn't have tests. I'm not going to merge this until it has some tests. But other than that, I generally like to trust people. But I do try to make sure that we're having the conversation where I see that they're taking ownership and considering all these things. Because I want to give contributors ownership. Like I don't want to take that away from contributors. I want to allow them to have some flexibility in how they approach something because it's their thing. They are contributing it to a project I maintain. And so that does mean that I'm committing to taking on maintenance of it. But I also want to trust people. Yeah, I haven't thought of the ownership aspect and considered it. But otherwise, I do pretty much the same thing. Like as long as the CI is green and as long as there are tests, I'm usually okay with it. Sometimes if I'm worried about something, I will ask them to add a few tests and to fix them if needed because they need to be green. But other than that, especially if it's like a new contributor, if the code style is not to my liking for the things that Elm Review doesn't report or Elm Format doesn't report, I will tend to let those pass. I will merge their pull request and then I will go fix them afterwards. I feel like it's hard to get pull requests in sometimes as someone who is like a first-time contributor. So since the first time is the hardest, let's make that one easier. We still want something of high quality or of decent quality, but I will try to make that easier on the person. And if that puts some strain on me, I'm fine with that. And then if that person contributes more, then I will make more comments because they will also understand how I work, how the project is written, and we want things to be consistent. They will understand the various trade-offs. But on the first few pull requests, that's maybe not the essence of the contribution. Right. Yeah, that makes sense. Yeah, I'll definitely help push along first-time contributors as well in that way where if there's something that they just were missing, like, hey, there's a module that abstracts away some of these details that we use in this code base, then I may make a commit on the PR or point them to it depending on how involved it is. And yeah, regarding the ownership, I think the more you give somebody your trust and ownership over something, the more they step up to it. That's just something I've noticed. I definitely feel that way as well. So I think as maintainers, we can really set the tone where if we're not trusting our contributors, they feel that, and they feel constrained and like, we're going to check everything and basically redo their work. So they don't really look at the big picture because that's not what they're being asked to do. They're being asked to just give some code, but we're going to be micromanaging it anyway. So why would they be thinking about the big picture of how it fits in and everything? There's a TED talk I saw by this author of a book. I think it's called Turn This Ship Around. And the author was a commander or admiral or something of a nuclear submarine, I believe. And his first day on the job on this nuclear submarine, he actually was given a different type of vessel than he thought he was going to be commanding. And so he started to give these orders. And people would look confused sometimes and he'd say, what's wrong? Is there a problem? And they'd say, well, we don't have that unit on this ship or something like that. And he would realize when he was giving orders, people would sort of shut off their thinking because they'd just be like, well, it's my duty to do what was asked of me, even if it doesn't really make sense. Because you're not being asked to think about the big picture. And so he ended up realizing that if he was going to successfully run this vessel, he would need to do things differently. So he started to say, it's my intention to submerge the vessel. And what am I going to ask you? And they would start thinking about his goals. So, OK, well, is everybody going to be safe? And whatever. His checklist of things. So that was his way of mentoring everybody to make sure these are the, this is the vision that I'm setting as the captain. But I'm trusting you to execute that and take ownership over your part of it. And I'm setting the high level vision. And I think that that's a really good way to approach an open source project as well. Yeah. Yeah, that resonates with me as well. So when is an open source project done? When the maintainer leaves? When there's no maintainer left? When the maintainer gets hit by a bus? Apparently that's a thing that happens with maintainers. Yeah, quite often. Actually, I don't know any maintainer who's been hit by a bus. Definitely stay away from buses, though. No, no, no. Use public transport. It's good. It's good. Be on the bus. If you're on the bus, your odds of getting hit by a bus are lower. Probably. I mean, if you're on the bus, then you're probably trying to flee someone with a gun and you jumped from a bridge on top of the bus. Maintainers lead interesting lives. I guess. When is a project done? Honestly, when it reaches its goals and when it's perfect, in the sense of whichever author said perfection is attained when there's nothing more to remove. Something like that. Which is very far from where our projects are, I think. I mean, you have some projects that could be considered to be done or close to done. Yeah, absolutely. I mean, and I think it depends on the scope of the project, right? If it's a project that, I don't know, if it's a project that parses a URL or parses an ISO 8601 date, right? Like, is Richard's ISO 8601 date parser package done? I think it pretty much is. And I think that sometimes a project can be done when it has a particular vision. It sort of meets that vision. And then sometimes it's better, rather than trying to reinvent that project, sometimes it's better to create a different project with different goals, rather than completely transforming the goals of that project. But I think that happens quite often, and I think that's a natural part of the cycle as well. But yeah, for ElmGraphQL, for example, I think it's at a phase where it kind of delivers what it promised. And small improvements come up, and I do actively work on it, and merge pull requests and small bug fixes come up. But it's much less frequent, and the core features are there, and they're pretty much solid. Not that it's... I don't think it's a perfect project, but I think it's a dependable project. You can basically use it to do what it promises. So it's more in maintenance mode, I would say. Not that I could never ever feature. Yeah, because the project is doing pretty much all that it needs to. Right. So yeah, ElmGraphQL wanted to allow you to interact with GraphQL endpoints in a specific way. And as long as you reach that goal, and no one finds anything that needs to be added, like new support for ADSes maybe, I don't know if that's a new thing, then yeah, you're done. Right. Or close to done. Like, yeah, maintenance, fixed typos in the documentation that no one has seen before, that can happen. Nothing really big, right? Yeah, and I think that's... I mean, the scope of ElmGraphQL is definitely like... I mean, it's a non-trivial project, but it's also like a pretty clear scope. Like frameworks like ElmPages, it would be a lot harder to ever call ElmPages done. Because it's a framework. Because the goal is much bigger. I mean, you say that, but for instance, Backbone, back in the day, which I've never used, but I've heard people... I went to a Backbone meetup once in Paris, and they talked pretty much about anything else. I didn't learn any Backbone there, because Backbone did what it had to do, and they talked about other projects that worked well with Backbone. I think, for instance, Lodash or something. So the project was simple enough, in a way, and it did what it needed to do. But it was inadequate for some use cases, and therefore died out. That might be one of the reasons why it died out, I don't know. But yeah, it is possible for it to finish, if you lay the right groundwork. Or don't know how you say that. Yeah, if your vision wants to allow users to do an enormous amount of things that you're not doing, then yeah, you're far from being done, right? Yeah, I think it's extremely valuable to put a lot of thought into how you scope a project. Because, at the beginning of the episode, we talked about what should users expect from maintainers. And of course, the software comes as is. If you really don't want a big commitment, then don't take on a large scope of the project. Try to narrow the scope down. Or at least communicate what you plan to contribute to it over time. But I think, we talked to Ryan Haskell-Glatz about his approach in LMSPA with just trying to not make people blocked on his technical decisions by providing extension points. Where the framework isn't responsible for everything they want to do. And Ryan was even talking about it, he's almost afraid of taking on that responsibility of users don't have a way to do things unless I give it to them. And I think that's very wise. And I think that's a good way to run a project. You should really consider if that's what you want to do. And avoid it if at all possible. Yeah, LMSPA is one of those projects where if you limit what people can do, it's going to kill the project or it's going to frustrate users. Right. If it's an auctioneering tool, then that's a lot more accepted, I would say. Exactly. For instance, for Elm Review, I feel like if I don't allow rule authors to make something, then it's a shame. If it's something that could have been useful, then it's a shame, but it's okay. If you do that with Elm Pages or LMSPA, that's not going to float. Exactly. So one thing we haven't talked about yet at this point is how do you get feedback from users or from contributors? So, I mean, we come up with plenty of tool or feature ideas, and we know we're not always perfect in our decisions. And sometimes it takes us years to think of some things. And therefore, we need feedback. We need to know what people will want to use something for, and we need to ask them their opinion. So how do you go about that and doing that? Yeah, well, I love feedback, and I think that feedback is essential for the health of a project, in my opinion. And it's a role that users are uniquely able to play. Of course, we can give ourselves feedback, but we're kind of biased in the way we perceive things. Yeah, I mean, we are still users of our own tools. We are users. Thankfully. Otherwise, like, yeah. But there's also a huge value to getting feedback from different uses of the tool. And so I think it's an essential process. And I mean, for me, the first thing that comes to mind is just ask. Ask for feedback. I try to ask for feedback all the time. Like, you know, I would love to hear what you think of this. And I often ask that on Slack when I release a new feature. Also in GitHub issues. You know, that's another like if somebody opens an issue, then again, that conversation of somebody opening an issue and saying this needs to do this, and then peeling that back and saying, well, what problem are you trying to solve? Sometimes that turns into understanding the experience people are having more. What about you? Yeah, I guess nowadays there's a sufficient number of people who roam the Elm Review Slack channel. So there are people responding to my questions, and that feels good. Unless they're very technical. My questions, I mean, and I'm the only person who cares about this thing. Then I don't always get answers. But usually, yeah, just ask questions. I do have ideas that take months to complete. And then I write an RFC or write some kind of blog post in my notes, you know, and then I make an issue of that. I don't do that nearly enough. I have plenty of ideas that I should make available for people to comment on. And maybe they would just add like one simple comment. And I would be like, oh, yeah, that's a solution. But that just takes a lot of time still, right? Just to get it to a point where you can share it. Yeah. For instance, like the other day, I was like, here's an idea. I've thought about this for a while. I don't know if it's perfect. And it's a very long thing. I'm like, ah, I don't know if I'm in the mood of writing, of adding an example to this. Like a few use cases. Let me just get it over with and send it. And a few minutes later, someone comes down and asks, do you have any use cases or examples for this? Like, ah. Well, OK, well, now I'm going to add those. But at least the idea will get out. So, yeah, it takes a long time, especially to present ideas in a way that's still, that are still open for discussion. Right, because I don't want to have a problem that I want to solve. I have some solutions I have in mind, but I don't want to close it to other solutions, which could be better. And I hope are better because I'm not necessarily entirely satisfied with my own solutions. And sometimes the solution is like, I have an idea. I have a problem. Here's a solution I'm suggesting. And maybe the result is that is a pretty bad solution. Let's just not do it. Let's not solve this problem. Yeah, I'm a fan of the RFC process as well. I think like opening up a GitHub discussion thread and just saying, like, I even like it, even if nobody comments, which happens. Like, I find it useful as a document to outline my thoughts. And as I'm writing it in a way where I'm trying to present it in a way that's easy to understand for other people and that, you know, lays out all of the possibilities. So people can say like, hey, here are three different paths we could go down here, I think, are the tradeoffs of all of them. I might be missing some, but that process of trying to like exhaustively brainstorm all of the different approaches that are possible and all of the tradeoffs for them is valuable in itself. And it's to me, I believe it's more valuable when I believe I'm communicating it to real people, not just in my notes. Yeah, it's like when you have a duck, right? And you're explaining your problem to a duck. Right, right. Yeah, exactly. It's different when you're trying to communicate it and make sure it lands. And often I do get amazing discussions where people are sharing their use cases and ideas. So yeah, RFC processes are really valuable. Yeah. And regardless of whether they're in your notes or on GitHub, if you've written them down and you come back to it a few weeks or months after, or a few hours maybe even, you're going to come up with new ideas. So it's always quite interesting to put it in writing in a way that is well articulated. Now you can come up with new ideas. Right. And you might forget all the things you probably will forget, all the different possibilities you considered. And then down the line, a couple of years from now when somebody says, hey, why didn't we do it this way, then you dig through, you search through GitHub and you find that RFC and you're like, oh, actually I talked about the cons here. And maybe you missed a consideration or maybe you already thought it through and you just point to that. So having those historical documents can be very valuable. And now I have FOMO, I'm wondering, did I do that enough? It's a good habit. So one thing I noticed with, and I'm sure you have as well, noticed with the Elm community is that we like to tend to batch work. Evan made that quite explicit to talk about batching work. And I feel like we do it too. I don't know if we do it for the same reasons. And I was wondering, so one thing I really don't like is breaking versions. I say I really don't like them. I just mean, I tried very hard to avoid them because, especially in the case of Elm Review, there's a lot of packages that depend on Elm Review. So if Elm Review releases a new major version, then all of them need to be updated. Some of them are mine, which I can do. It will just take me a few hours more. But some of them are for other people, and that will take longer to, that will cause others pain to upgrade. And I want to avoid that as much as possible. So Elm Review has not had a major version since April 2020, which is quite an achievement in a way. I know I will want a v3 at some point. I just don't know when. I wonder whether this fear of breaking changes causes us to batch work. Because Elm enforces semantic versioning, and that means that there are some changes that I can't do without making a new major version. And if I want to avoid them, I need to think really hard about how this feature will be used in the future. How this feature will affect other things. And in that sense, I need to carefully think about things. Make RFCs, write down notes for months or years. And once I feel like I have everything thought through, then I can implement it. And I'm sure get some discoveries still. But I wonder, if you care about avoiding breaking changes, do you batch work more? What do you think? I think you do. I think that's definitely one reason for batching work. I don't even think it's the main reason for me though. I think the main reason that I tend to batch work is... First I'll say, if there's a pull request that's a typo in the docs, then I'm just going to click merge. Because I want to get that off my radar as fast as possible. Because it's just like, having it sitting around... There's this idea in getting things done, which we talked about in our productivity episode, of the two minute rule. Which is that, if you can complete something in two minutes or less, then managing that in your to-do system is going to be more costly than just doing it. Because you accrue some sort of tax by having more things in your system. So I definitely try to push things through when there's not a lot to think about. But when there are deep considerations that I need to go through, then sometimes those need to sit with me for a little bit. And I need to sleep on it, and I need to read through a bajillion RFCs that other open source projects and other language communities have made. And watch some conference talks, and read some code books, and read some non-code books, and drink a Mai Tai, and think about these things. Specifically Mai Tai? It couldn't hurt. I just don't know what it is, so yeah, maybe. Try one out, it's good. I think there's a lot of background processing for decisions for me. Have you heard this story of the man who asked for a painting of a horse? And so he asks this painter, he says, I want to commission a painting of a horse, it's like a birthday present for someone or something. And the painter says, okay, yeah sure, I'll have that for you in a month or so. And he goes back to the painter, and the painter says, are you done with the painting yet? No, no, no, I'm still painting it. And a couple weeks go by, and the painter says, hey, are you done with it yet? No, no, no, I'm still working on it. And he keeps going back, and he's not done, and eventually he goes back, and the painter gets so frustrated, he says, okay, okay, okay. And he gets out an easel and paints a horse, and then gives it to him. And he's like, well, if you did it so quickly, why didn't you just do that before? And he says, well, I've been, you know, observing horses, and watching how they run, and thinking about them, and dreaming about them. So all this time, he was working on painting the horse, even though his brush was only touching the canvas for however long, that was part of the process. And that's how I feel with coding projects, is like, it needs to sit with you, and you can't just juggle a hundred different things and really consider them. Like, you have to really get that cash into your brain about all of these things you're thinking about. And so it's more efficient in a lot of ways to, like, think about a related group of things in a project before moving on to something else. So that's how I tend to think of it. So is there any feature that I have to rush you about? You know, I actually don't mind when people politely ping on something, too. Because for me, like, it is valuable to know that somebody actually cares about something. Yeah, definitely. It gives you some motivation, like, oh yeah, yeah, no, I want that too. At least for me, because I want those things as well. Yeah. Or if somebody's blocked, I want them to be unblocked, and that's valuable information. So, you know, sometimes it's okay to just say, hey, just making sure you're, you know, having lost track of this in a polite way. Yeah. Don't write a comment saying ping, but... Otherwise it's fine. Yeah. Yeah. All right. I don't know what else we can add to this conversation to maintain it. Are you saying this conversation is done? This conversation is done. Well, then you're in. Until next time. Until next time.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.0, "text": " Hello Jeroen.", "tokens": [2425, 508, 2032, 268, 13], "temperature": 0.0, "avg_logprob": -0.31937498204848347, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.07237257808446884}, {"id": 1, "seek": 0, "start": 2.0, "end": 4.0, "text": " Hello Dillon.", "tokens": [2425, 28160, 13], "temperature": 0.0, "avg_logprob": -0.31937498204848347, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.07237257808446884}, {"id": 2, "seek": 0, "start": 4.0, "end": 9.0, "text": " This conversation is provided as is, without warranty of any kind.", "tokens": [639, 3761, 307, 5649, 382, 307, 11, 1553, 26852, 295, 604, 733, 13], "temperature": 0.0, "avg_logprob": -0.31937498204848347, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.07237257808446884}, {"id": 3, "seek": 0, "start": 9.0, "end": 11.0, "text": " Just wanted our listeners to know that.", "tokens": [1449, 1415, 527, 23274, 281, 458, 300, 13], "temperature": 0.0, "avg_logprob": -0.31937498204848347, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.07237257808446884}, {"id": 4, "seek": 0, "start": 13.0, "end": 15.0, "text": " Alright, alright.", "tokens": [2798, 11, 5845, 13], "temperature": 0.0, "avg_logprob": -0.31937498204848347, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.07237257808446884}, {"id": 5, "seek": 0, "start": 18.0, "end": 21.0, "text": " A pun at every start of the episode.", "tokens": [316, 4468, 412, 633, 722, 295, 264, 3500, 13], "temperature": 0.0, "avg_logprob": -0.31937498204848347, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.07237257808446884}, {"id": 6, "seek": 0, "start": 21.0, "end": 26.0, "text": " I really don't know how you maintain this pace for your puns.", "tokens": [286, 534, 500, 380, 458, 577, 291, 6909, 341, 11638, 337, 428, 4468, 82, 13], "temperature": 0.0, "avg_logprob": -0.31937498204848347, "compression_ratio": 1.510204081632653, "no_speech_prob": 0.07237257808446884}, {"id": 7, "seek": 2600, "start": 26.0, "end": 30.0, "text": " I mean, you really pull your weight for them.", "tokens": [286, 914, 11, 291, 534, 2235, 428, 3364, 337, 552, 13], "temperature": 0.0, "avg_logprob": -0.19437176573510265, "compression_ratio": 1.5642201834862386, "no_speech_prob": 0.0010531182633712888}, {"id": 8, "seek": 2600, "start": 30.0, "end": 36.0, "text": " But I just want you to know, if you ever stop doing them, it's not an issue.", "tokens": [583, 286, 445, 528, 291, 281, 458, 11, 498, 291, 1562, 1590, 884, 552, 11, 309, 311, 406, 364, 2734, 13], "temperature": 0.0, "avg_logprob": -0.19437176573510265, "compression_ratio": 1.5642201834862386, "no_speech_prob": 0.0010531182633712888}, {"id": 9, "seek": 2600, "start": 36.0, "end": 38.0, "text": " Just, it's fine.", "tokens": [1449, 11, 309, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.19437176573510265, "compression_ratio": 1.5642201834862386, "no_speech_prob": 0.0010531182633712888}, {"id": 10, "seek": 2600, "start": 38.0, "end": 40.0, "text": " I have a license to pun.", "tokens": [286, 362, 257, 10476, 281, 4468, 13], "temperature": 0.0, "avg_logprob": -0.19437176573510265, "compression_ratio": 1.5642201834862386, "no_speech_prob": 0.0010531182633712888}, {"id": 11, "seek": 2600, "start": 42.0, "end": 44.0, "text": " What are we talking about today?", "tokens": [708, 366, 321, 1417, 466, 965, 30], "temperature": 0.0, "avg_logprob": -0.19437176573510265, "compression_ratio": 1.5642201834862386, "no_speech_prob": 0.0010531182633712888}, {"id": 12, "seek": 2600, "start": 44.0, "end": 48.0, "text": " Today we're talking about the human side of open source.", "tokens": [2692, 321, 434, 1417, 466, 264, 1952, 1252, 295, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.19437176573510265, "compression_ratio": 1.5642201834862386, "no_speech_prob": 0.0010531182633712888}, {"id": 13, "seek": 2600, "start": 48.0, "end": 54.0, "text": " And I believe you and I have perhaps dabbled in open source a little bit, I would say.", "tokens": [400, 286, 1697, 291, 293, 286, 362, 4317, 274, 10797, 1493, 294, 1269, 4009, 257, 707, 857, 11, 286, 576, 584, 13], "temperature": 0.0, "avg_logprob": -0.19437176573510265, "compression_ratio": 1.5642201834862386, "no_speech_prob": 0.0010531182633712888}, {"id": 14, "seek": 5400, "start": 54.0, "end": 56.0, "text": " Yeah, I'd say so.", "tokens": [865, 11, 286, 1116, 584, 370, 13], "temperature": 0.0, "avg_logprob": -0.2002459233350093, "compression_ratio": 1.5096153846153846, "no_speech_prob": 0.0003349487669765949}, {"id": 15, "seek": 5400, "start": 56.0, "end": 59.0, "text": " I mean, how long has it been for me?", "tokens": [286, 914, 11, 577, 938, 575, 309, 668, 337, 385, 30], "temperature": 0.0, "avg_logprob": -0.2002459233350093, "compression_ratio": 1.5096153846153846, "no_speech_prob": 0.0003349487669765949}, {"id": 16, "seek": 5400, "start": 59.0, "end": 63.0, "text": " I think I started in 2017 with open source.", "tokens": [286, 519, 286, 1409, 294, 6591, 365, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.2002459233350093, "compression_ratio": 1.5096153846153846, "no_speech_prob": 0.0003349487669765949}, {"id": 17, "seek": 5400, "start": 63.0, "end": 66.0, "text": " Yeah, that's starting to be quite a while already.", "tokens": [865, 11, 300, 311, 2891, 281, 312, 1596, 257, 1339, 1217, 13], "temperature": 0.0, "avg_logprob": -0.2002459233350093, "compression_ratio": 1.5096153846153846, "no_speech_prob": 0.0003349487669765949}, {"id": 18, "seek": 5400, "start": 66.0, "end": 68.0, "text": " Do you remember what your first open source was?", "tokens": [1144, 291, 1604, 437, 428, 700, 1269, 4009, 390, 30], "temperature": 0.0, "avg_logprob": -0.2002459233350093, "compression_ratio": 1.5096153846153846, "no_speech_prob": 0.0003349487669765949}, {"id": 19, "seek": 5400, "start": 68.0, "end": 69.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2002459233350093, "compression_ratio": 1.5096153846153846, "no_speech_prob": 0.0003349487669765949}, {"id": 20, "seek": 5400, "start": 69.0, "end": 73.0, "text": " First contribution was fixing a license.", "tokens": [2386, 13150, 390, 19442, 257, 10476, 13], "temperature": 0.0, "avg_logprob": -0.2002459233350093, "compression_ratio": 1.5096153846153846, "no_speech_prob": 0.0003349487669765949}, {"id": 21, "seek": 5400, "start": 73.0, "end": 74.0, "text": " Oh!", "tokens": [876, 0], "temperature": 0.0, "avg_logprob": -0.2002459233350093, "compression_ratio": 1.5096153846153846, "no_speech_prob": 0.0003349487669765949}, {"id": 22, "seek": 5400, "start": 74.0, "end": 77.0, "text": " It was fixing the dates for a license.", "tokens": [467, 390, 19442, 264, 11691, 337, 257, 10476, 13], "temperature": 0.0, "avg_logprob": -0.2002459233350093, "compression_ratio": 1.5096153846153846, "no_speech_prob": 0.0003349487669765949}, {"id": 23, "seek": 5400, "start": 77.0, "end": 78.0, "text": " Nice!", "tokens": [5490, 0], "temperature": 0.0, "avg_logprob": -0.2002459233350093, "compression_ratio": 1.5096153846153846, "no_speech_prob": 0.0003349487669765949}, {"id": 24, "seek": 5400, "start": 78.0, "end": 80.0, "text": " For someone's blog.", "tokens": [1171, 1580, 311, 6968, 13], "temperature": 0.0, "avg_logprob": -0.2002459233350093, "compression_ratio": 1.5096153846153846, "no_speech_prob": 0.0003349487669765949}, {"id": 25, "seek": 8000, "start": 80.0, "end": 85.0, "text": " And the next one was doing the documentation for lodashfp.", "tokens": [400, 264, 958, 472, 390, 884, 264, 14333, 337, 33311, 1299, 69, 79, 13], "temperature": 0.0, "avg_logprob": -0.24941095099391708, "compression_ratio": 1.438095238095238, "no_speech_prob": 4.066810288350098e-05}, {"id": 26, "seek": 8000, "start": 85.0, "end": 87.0, "text": " Which was more ambitious already.", "tokens": [3013, 390, 544, 20239, 1217, 13], "temperature": 0.0, "avg_logprob": -0.24941095099391708, "compression_ratio": 1.438095238095238, "no_speech_prob": 4.066810288350098e-05}, {"id": 27, "seek": 8000, "start": 87.0, "end": 89.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.24941095099391708, "compression_ratio": 1.438095238095238, "no_speech_prob": 4.066810288350098e-05}, {"id": 28, "seek": 8000, "start": 89.0, "end": 94.0, "text": " I believe my first open source project was in 2013.", "tokens": [286, 1697, 452, 700, 1269, 4009, 1716, 390, 294, 9012, 13], "temperature": 0.0, "avg_logprob": -0.24941095099391708, "compression_ratio": 1.438095238095238, "no_speech_prob": 4.066810288350098e-05}, {"id": 29, "seek": 8000, "start": 94.0, "end": 103.0, "text": " And it was a random little Ruby executable for helping you with an interface to git.", "tokens": [400, 309, 390, 257, 4974, 707, 19907, 7568, 712, 337, 4315, 291, 365, 364, 9226, 281, 18331, 13], "temperature": 0.0, "avg_logprob": -0.24941095099391708, "compression_ratio": 1.438095238095238, "no_speech_prob": 4.066810288350098e-05}, {"id": 30, "seek": 8000, "start": 103.0, "end": 107.0, "text": " Which probably two of my co-workers used.", "tokens": [3013, 1391, 732, 295, 452, 598, 12, 37101, 1143, 13], "temperature": 0.0, "avg_logprob": -0.24941095099391708, "compression_ratio": 1.438095238095238, "no_speech_prob": 4.066810288350098e-05}, {"id": 31, "seek": 8000, "start": 107.0, "end": 109.0, "text": " Which is less than zero.", "tokens": [3013, 307, 1570, 813, 4018, 13], "temperature": 0.0, "avg_logprob": -0.24941095099391708, "compression_ratio": 1.438095238095238, "no_speech_prob": 4.066810288350098e-05}, {"id": 32, "seek": 10900, "start": 109.0, "end": 111.0, "text": " Right, yeah.", "tokens": [1779, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.2616038071481805, "compression_ratio": 1.4401913875598087, "no_speech_prob": 3.268783984822221e-05}, {"id": 33, "seek": 10900, "start": 111.0, "end": 119.0, "text": " Oh, I guess I did publish an npm package or something around 2014 or 2015.", "tokens": [876, 11, 286, 2041, 286, 630, 11374, 364, 297, 14395, 7372, 420, 746, 926, 8227, 420, 7546, 13], "temperature": 0.0, "avg_logprob": -0.2616038071481805, "compression_ratio": 1.4401913875598087, "no_speech_prob": 3.268783984822221e-05}, {"id": 34, "seek": 10900, "start": 119.0, "end": 124.0, "text": " But getting really involved in other people's projects in 2017.", "tokens": [583, 1242, 534, 3288, 294, 661, 561, 311, 4455, 294, 6591, 13], "temperature": 0.0, "avg_logprob": -0.2616038071481805, "compression_ratio": 1.4401913875598087, "no_speech_prob": 3.268783984822221e-05}, {"id": 35, "seek": 10900, "start": 124.0, "end": 127.0, "text": " And that's when my project started as well.", "tokens": [400, 300, 311, 562, 452, 1716, 1409, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.2616038071481805, "compression_ratio": 1.4401913875598087, "no_speech_prob": 3.268783984822221e-05}, {"id": 36, "seek": 10900, "start": 127.0, "end": 133.0, "text": " Yeah, it definitely changes the game when number one you have users and number two you have contributors.", "tokens": [865, 11, 309, 2138, 2962, 264, 1216, 562, 1230, 472, 291, 362, 5022, 293, 1230, 732, 291, 362, 45627, 13], "temperature": 0.0, "avg_logprob": -0.2616038071481805, "compression_ratio": 1.4401913875598087, "no_speech_prob": 3.268783984822221e-05}, {"id": 37, "seek": 13300, "start": 133.0, "end": 143.0, "text": " It doesn't really feel like open source if you don't at least have people opening issues and telling you about problems they're experiencing.", "tokens": [467, 1177, 380, 534, 841, 411, 1269, 4009, 498, 291, 500, 380, 412, 1935, 362, 561, 5193, 2663, 293, 3585, 291, 466, 2740, 436, 434, 11139, 13], "temperature": 0.0, "avg_logprob": -0.2276911735534668, "compression_ratio": 1.5755102040816327, "no_speech_prob": 1.2409420378389768e-05}, {"id": 38, "seek": 13300, "start": 143.0, "end": 146.0, "text": " Or things that could be improved or discussing things with you.", "tokens": [1610, 721, 300, 727, 312, 9689, 420, 10850, 721, 365, 291, 13], "temperature": 0.0, "avg_logprob": -0.2276911735534668, "compression_ratio": 1.5755102040816327, "no_speech_prob": 1.2409420378389768e-05}, {"id": 39, "seek": 13300, "start": 146.0, "end": 147.0, "text": " Right, yeah.", "tokens": [1779, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.2276911735534668, "compression_ratio": 1.5755102040816327, "no_speech_prob": 1.2409420378389768e-05}, {"id": 40, "seek": 13300, "start": 147.0, "end": 152.0, "text": " If you only publish your package or your code and you put it on github.", "tokens": [759, 291, 787, 11374, 428, 7372, 420, 428, 3089, 293, 291, 829, 309, 322, 290, 355, 836, 13], "temperature": 0.0, "avg_logprob": -0.2276911735534668, "compression_ratio": 1.5755102040816327, "no_speech_prob": 1.2409420378389768e-05}, {"id": 41, "seek": 13300, "start": 152.0, "end": 155.0, "text": " It's very different from people interacting with you.", "tokens": [467, 311, 588, 819, 490, 561, 18017, 365, 291, 13], "temperature": 0.0, "avg_logprob": -0.2276911735534668, "compression_ratio": 1.5755102040816327, "no_speech_prob": 1.2409420378389768e-05}, {"id": 42, "seek": 13300, "start": 155.0, "end": 158.0, "text": " Making suggestions, making pull requests.", "tokens": [14595, 13396, 11, 1455, 2235, 12475, 13], "temperature": 0.0, "avg_logprob": -0.2276911735534668, "compression_ratio": 1.5755102040816327, "no_speech_prob": 1.2409420378389768e-05}, {"id": 43, "seek": 15800, "start": 158.0, "end": 163.0, "text": " Telling you your code is crappy, your project sucks.", "tokens": [5115, 278, 291, 428, 3089, 307, 36531, 11, 428, 1716, 15846, 13], "temperature": 0.0, "avg_logprob": -0.21632372814676035, "compression_ratio": 1.5068493150684932, "no_speech_prob": 4.9847843911265954e-05}, {"id": 44, "seek": 15800, "start": 163.0, "end": 165.0, "text": " Right, exactly.", "tokens": [1779, 11, 2293, 13], "temperature": 0.0, "avg_logprob": -0.21632372814676035, "compression_ratio": 1.5068493150684932, "no_speech_prob": 4.9847843911265954e-05}, {"id": 45, "seek": 15800, "start": 165.0, "end": 168.0, "text": " Which thankfully I have not had.", "tokens": [3013, 27352, 286, 362, 406, 632, 13], "temperature": 0.0, "avg_logprob": -0.21632372814676035, "compression_ratio": 1.5068493150684932, "no_speech_prob": 4.9847843911265954e-05}, {"id": 46, "seek": 15800, "start": 168.0, "end": 173.0, "text": " I've had a very good interaction with all of my open source projects so far.", "tokens": [286, 600, 632, 257, 588, 665, 9285, 365, 439, 295, 452, 1269, 4009, 4455, 370, 1400, 13], "temperature": 0.0, "avg_logprob": -0.21632372814676035, "compression_ratio": 1.5068493150684932, "no_speech_prob": 4.9847843911265954e-05}, {"id": 47, "seek": 15800, "start": 173.0, "end": 174.0, "text": " That's awesome.", "tokens": [663, 311, 3476, 13], "temperature": 0.0, "avg_logprob": -0.21632372814676035, "compression_ratio": 1.5068493150684932, "no_speech_prob": 4.9847843911265954e-05}, {"id": 48, "seek": 15800, "start": 174.0, "end": 178.0, "text": " One of the things on my mind today is like, why do open source?", "tokens": [1485, 295, 264, 721, 322, 452, 1575, 965, 307, 411, 11, 983, 360, 1269, 4009, 30], "temperature": 0.0, "avg_logprob": -0.21632372814676035, "compression_ratio": 1.5068493150684932, "no_speech_prob": 4.9847843911265954e-05}, {"id": 49, "seek": 15800, "start": 178.0, "end": 184.0, "text": " Like why do we even bother making a tool open source when we build one?", "tokens": [1743, 983, 360, 321, 754, 8677, 1455, 257, 2290, 1269, 4009, 562, 321, 1322, 472, 30], "temperature": 0.0, "avg_logprob": -0.21632372814676035, "compression_ratio": 1.5068493150684932, "no_speech_prob": 4.9847843911265954e-05}, {"id": 50, "seek": 18400, "start": 184.0, "end": 188.0, "text": " What are the motivations for us, for the community?", "tokens": [708, 366, 264, 39034, 337, 505, 11, 337, 264, 1768, 30], "temperature": 0.0, "avg_logprob": -0.18178210538976333, "compression_ratio": 1.5776699029126213, "no_speech_prob": 2.667650369403418e-05}, {"id": 51, "seek": 18400, "start": 188.0, "end": 192.0, "text": " What's the benefit, what's the point of making something open source?", "tokens": [708, 311, 264, 5121, 11, 437, 311, 264, 935, 295, 1455, 746, 1269, 4009, 30], "temperature": 0.0, "avg_logprob": -0.18178210538976333, "compression_ratio": 1.5776699029126213, "no_speech_prob": 2.667650369403418e-05}, {"id": 52, "seek": 18400, "start": 192.0, "end": 195.0, "text": " Right, well there are several.", "tokens": [1779, 11, 731, 456, 366, 2940, 13], "temperature": 0.0, "avg_logprob": -0.18178210538976333, "compression_ratio": 1.5776699029126213, "no_speech_prob": 2.667650369403418e-05}, {"id": 53, "seek": 18400, "start": 195.0, "end": 200.0, "text": " One of them is feeling like you are helpful to people.", "tokens": [1485, 295, 552, 307, 2633, 411, 291, 366, 4961, 281, 561, 13], "temperature": 0.0, "avg_logprob": -0.18178210538976333, "compression_ratio": 1.5776699029126213, "no_speech_prob": 2.667650369403418e-05}, {"id": 54, "seek": 18400, "start": 200.0, "end": 206.0, "text": " I think that's one thing that we tend to like as software engineers, as humans as well.", "tokens": [286, 519, 300, 311, 472, 551, 300, 321, 3928, 281, 411, 382, 4722, 11955, 11, 382, 6255, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.18178210538976333, "compression_ratio": 1.5776699029126213, "no_speech_prob": 2.667650369403418e-05}, {"id": 55, "seek": 18400, "start": 206.0, "end": 208.0, "text": " Just being helpful to others.", "tokens": [1449, 885, 4961, 281, 2357, 13], "temperature": 0.0, "avg_logprob": -0.18178210538976333, "compression_ratio": 1.5776699029126213, "no_speech_prob": 2.667650369403418e-05}, {"id": 56, "seek": 20800, "start": 208.0, "end": 215.0, "text": " Like I'm making a project, I'm making a website, I'm making a tool that helps other people.", "tokens": [1743, 286, 478, 1455, 257, 1716, 11, 286, 478, 1455, 257, 3144, 11, 286, 478, 1455, 257, 2290, 300, 3665, 661, 561, 13], "temperature": 0.0, "avg_logprob": -0.19923663961476293, "compression_ratio": 1.694300518134715, "no_speech_prob": 4.9833557568490505e-05}, {"id": 57, "seek": 20800, "start": 215.0, "end": 218.0, "text": " Any software project is basically to help someone.", "tokens": [2639, 4722, 1716, 307, 1936, 281, 854, 1580, 13], "temperature": 0.0, "avg_logprob": -0.19923663961476293, "compression_ratio": 1.694300518134715, "no_speech_prob": 4.9833557568490505e-05}, {"id": 58, "seek": 20800, "start": 218.0, "end": 222.0, "text": " It's usually you, even if it's just like making a video game.", "tokens": [467, 311, 2673, 291, 11, 754, 498, 309, 311, 445, 411, 1455, 257, 960, 1216, 13], "temperature": 0.0, "avg_logprob": -0.19923663961476293, "compression_ratio": 1.694300518134715, "no_speech_prob": 4.9833557568490505e-05}, {"id": 59, "seek": 20800, "start": 222.0, "end": 228.0, "text": " It's helping you entertain yourself for an hour or two or two hundred.", "tokens": [467, 311, 4315, 291, 7655, 1803, 337, 364, 1773, 420, 732, 420, 732, 3262, 13], "temperature": 0.0, "avg_logprob": -0.19923663961476293, "compression_ratio": 1.694300518134715, "no_speech_prob": 4.9833557568490505e-05}, {"id": 60, "seek": 20800, "start": 228.0, "end": 234.0, "text": " So yeah, I feel like being helpful to other people.", "tokens": [407, 1338, 11, 286, 841, 411, 885, 4961, 281, 661, 561, 13], "temperature": 0.0, "avg_logprob": -0.19923663961476293, "compression_ratio": 1.694300518134715, "no_speech_prob": 4.9833557568490505e-05}, {"id": 61, "seek": 23400, "start": 234.0, "end": 238.0, "text": " So if something is open source, it's really accessible, people can use it.", "tokens": [407, 498, 746, 307, 1269, 4009, 11, 309, 311, 534, 9515, 11, 561, 393, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.2132896535536822, "compression_ratio": 1.6371681415929205, "no_speech_prob": 2.626789137138985e-05}, {"id": 62, "seek": 23400, "start": 238.0, "end": 241.0, "text": " There's also the recognition part.", "tokens": [821, 311, 611, 264, 11150, 644, 13], "temperature": 0.0, "avg_logprob": -0.2132896535536822, "compression_ratio": 1.6371681415929205, "no_speech_prob": 2.626789137138985e-05}, {"id": 63, "seek": 23400, "start": 241.0, "end": 247.0, "text": " I want to, I've made a tool or I've made something which I think is useful.", "tokens": [286, 528, 281, 11, 286, 600, 1027, 257, 2290, 420, 286, 600, 1027, 746, 597, 286, 519, 307, 4420, 13], "temperature": 0.0, "avg_logprob": -0.2132896535536822, "compression_ratio": 1.6371681415929205, "no_speech_prob": 2.626789137138985e-05}, {"id": 64, "seek": 23400, "start": 247.0, "end": 249.0, "text": " And I want other people to know about it.", "tokens": [400, 286, 528, 661, 561, 281, 458, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.2132896535536822, "compression_ratio": 1.6371681415929205, "no_speech_prob": 2.626789137138985e-05}, {"id": 65, "seek": 23400, "start": 249.0, "end": 258.0, "text": " Maybe to get my career going, to get, to have recruiters think that I am very qualified.", "tokens": [2704, 281, 483, 452, 3988, 516, 11, 281, 483, 11, 281, 362, 15119, 433, 519, 300, 286, 669, 588, 15904, 13], "temperature": 0.0, "avg_logprob": -0.2132896535536822, "compression_ratio": 1.6371681415929205, "no_speech_prob": 2.626789137138985e-05}, {"id": 66, "seek": 23400, "start": 258.0, "end": 263.0, "text": " I have actually, for instance, like made a tool once.", "tokens": [286, 362, 767, 11, 337, 5197, 11, 411, 1027, 257, 2290, 1564, 13], "temperature": 0.0, "avg_logprob": -0.2132896535536822, "compression_ratio": 1.6371681415929205, "no_speech_prob": 2.626789137138985e-05}, {"id": 67, "seek": 26300, "start": 263.0, "end": 271.0, "text": " Oh, that was in 2014, which I put on GitHub and it helped me land a job because they asked me like,", "tokens": [876, 11, 300, 390, 294, 8227, 11, 597, 286, 829, 322, 23331, 293, 309, 4254, 385, 2117, 257, 1691, 570, 436, 2351, 385, 411, 11], "temperature": 0.0, "avg_logprob": -0.24682089747214803, "compression_ratio": 1.599056603773585, "no_speech_prob": 2.1111110982019454e-05}, {"id": 68, "seek": 26300, "start": 271.0, "end": 276.0, "text": " Hey, do you have some code that you have available that we can look at?", "tokens": [1911, 11, 360, 291, 362, 512, 3089, 300, 291, 362, 2435, 300, 321, 393, 574, 412, 30], "temperature": 0.0, "avg_logprob": -0.24682089747214803, "compression_ratio": 1.599056603773585, "no_speech_prob": 2.1111110982019454e-05}, {"id": 69, "seek": 26300, "start": 276.0, "end": 278.0, "text": " And I'm like, sure, you can look at this one.", "tokens": [400, 286, 478, 411, 11, 988, 11, 291, 393, 574, 412, 341, 472, 13], "temperature": 0.0, "avg_logprob": -0.24682089747214803, "compression_ratio": 1.599056603773585, "no_speech_prob": 2.1111110982019454e-05}, {"id": 70, "seek": 26300, "start": 278.0, "end": 282.0, "text": " And they hired me pretty much because they said it had tests.", "tokens": [400, 436, 13144, 385, 1238, 709, 570, 436, 848, 309, 632, 6921, 13], "temperature": 0.0, "avg_logprob": -0.24682089747214803, "compression_ratio": 1.599056603773585, "no_speech_prob": 2.1111110982019454e-05}, {"id": 71, "seek": 26300, "start": 282.0, "end": 288.0, "text": " So, you're running tests, you're qualified.", "tokens": [407, 11, 291, 434, 2614, 6921, 11, 291, 434, 15904, 13], "temperature": 0.0, "avg_logprob": -0.24682089747214803, "compression_ratio": 1.599056603773585, "no_speech_prob": 2.1111110982019454e-05}, {"id": 72, "seek": 26300, "start": 288.0, "end": 289.0, "text": " That's awesome.", "tokens": [663, 311, 3476, 13], "temperature": 0.0, "avg_logprob": -0.24682089747214803, "compression_ratio": 1.599056603773585, "no_speech_prob": 2.1111110982019454e-05}, {"id": 73, "seek": 28900, "start": 289.0, "end": 294.0, "text": " Pretty low bar. I mean, I was quite junior back then, but yeah.", "tokens": [10693, 2295, 2159, 13, 286, 914, 11, 286, 390, 1596, 16195, 646, 550, 11, 457, 1338, 13], "temperature": 0.0, "avg_logprob": -0.21977179391043528, "compression_ratio": 1.5330396475770924, "no_speech_prob": 1.028901715471875e-05}, {"id": 74, "seek": 28900, "start": 294.0, "end": 302.0, "text": " So yeah, recognition through multiple forms, like being just a junior who knows how to code quite well", "tokens": [407, 1338, 11, 11150, 807, 3866, 6422, 11, 411, 885, 445, 257, 16195, 567, 3255, 577, 281, 3089, 1596, 731], "temperature": 0.0, "avg_logprob": -0.21977179391043528, "compression_ratio": 1.5330396475770924, "no_speech_prob": 1.028901715471875e-05}, {"id": 75, "seek": 28900, "start": 302.0, "end": 313.0, "text": " or being a very famous maintainer who you can hire for consultancy on one of your projects.", "tokens": [420, 885, 257, 588, 4618, 6909, 260, 567, 291, 393, 11158, 337, 7189, 6717, 322, 472, 295, 428, 4455, 13], "temperature": 0.0, "avg_logprob": -0.21977179391043528, "compression_ratio": 1.5330396475770924, "no_speech_prob": 1.028901715471875e-05}, {"id": 76, "seek": 28900, "start": 313.0, "end": 316.0, "text": " Yeah, yeah, those are the two I can come up with.", "tokens": [865, 11, 1338, 11, 729, 366, 264, 732, 286, 393, 808, 493, 365, 13], "temperature": 0.0, "avg_logprob": -0.21977179391043528, "compression_ratio": 1.5330396475770924, "no_speech_prob": 1.028901715471875e-05}, {"id": 77, "seek": 28900, "start": 316.0, "end": 318.0, "text": " It's mostly like helping people though.", "tokens": [467, 311, 5240, 411, 4315, 561, 1673, 13], "temperature": 0.0, "avg_logprob": -0.21977179391043528, "compression_ratio": 1.5330396475770924, "no_speech_prob": 1.028901715471875e-05}, {"id": 78, "seek": 31800, "start": 318.0, "end": 320.0, "text": " I like that. I feel the same way.", "tokens": [286, 411, 300, 13, 286, 841, 264, 912, 636, 13], "temperature": 0.0, "avg_logprob": -0.2166924136025565, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.0003005456819664687}, {"id": 79, "seek": 31800, "start": 320.0, "end": 326.0, "text": " I think helping people is really, there is something at the core there that you're right.", "tokens": [286, 519, 4315, 561, 307, 534, 11, 456, 307, 746, 412, 264, 4965, 456, 300, 291, 434, 558, 13], "temperature": 0.0, "avg_logprob": -0.2166924136025565, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.0003005456819664687}, {"id": 80, "seek": 31800, "start": 326.0, "end": 332.0, "text": " Like when we're building software, like if we're building software that doesn't help any single person in the world,", "tokens": [1743, 562, 321, 434, 2390, 4722, 11, 411, 498, 321, 434, 2390, 4722, 300, 1177, 380, 854, 604, 2167, 954, 294, 264, 1002, 11], "temperature": 0.0, "avg_logprob": -0.2166924136025565, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.0003005456819664687}, {"id": 81, "seek": 31800, "start": 332.0, "end": 335.0, "text": " like why would you build it? It doesn't really solve any problems.", "tokens": [411, 983, 576, 291, 1322, 309, 30, 467, 1177, 380, 534, 5039, 604, 2740, 13], "temperature": 0.0, "avg_logprob": -0.2166924136025565, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.0003005456819664687}, {"id": 82, "seek": 31800, "start": 335.0, "end": 337.0, "text": " So you want to solve some problems.", "tokens": [407, 291, 528, 281, 5039, 512, 2740, 13], "temperature": 0.0, "avg_logprob": -0.2166924136025565, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.0003005456819664687}, {"id": 83, "seek": 31800, "start": 337.0, "end": 345.0, "text": " And, you know, you mentioned like accessibility and I feel the same way, like with open source projects,", "tokens": [400, 11, 291, 458, 11, 291, 2835, 411, 15002, 293, 286, 841, 264, 912, 636, 11, 411, 365, 1269, 4009, 4455, 11], "temperature": 0.0, "avg_logprob": -0.2166924136025565, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.0003005456819664687}, {"id": 84, "seek": 34500, "start": 345.0, "end": 348.0, "text": " it's just, it's more usable and accessible.", "tokens": [309, 311, 445, 11, 309, 311, 544, 29975, 293, 9515, 13], "temperature": 0.0, "avg_logprob": -0.20966484967400045, "compression_ratio": 1.7261904761904763, "no_speech_prob": 1.1658587027341127e-05}, {"id": 85, "seek": 34500, "start": 348.0, "end": 357.0, "text": " It's whether that be going and installing something on NPM or copying part of the source code,", "tokens": [467, 311, 1968, 300, 312, 516, 293, 20762, 746, 322, 426, 18819, 420, 27976, 644, 295, 264, 4009, 3089, 11], "temperature": 0.0, "avg_logprob": -0.20966484967400045, "compression_ratio": 1.7261904761904763, "no_speech_prob": 1.1658587027341127e-05}, {"id": 86, "seek": 34500, "start": 357.0, "end": 366.0, "text": " because some, you know, some module in your code is doing something that somebody else needs for another project,", "tokens": [570, 512, 11, 291, 458, 11, 512, 10088, 294, 428, 3089, 307, 884, 746, 300, 2618, 1646, 2203, 337, 1071, 1716, 11], "temperature": 0.0, "avg_logprob": -0.20966484967400045, "compression_ratio": 1.7261904761904763, "no_speech_prob": 1.1658587027341127e-05}, {"id": 87, "seek": 34500, "start": 366.0, "end": 370.0, "text": " or they want to go look at it for reference and see how you implemented something.", "tokens": [420, 436, 528, 281, 352, 574, 412, 309, 337, 6408, 293, 536, 577, 291, 12270, 746, 13], "temperature": 0.0, "avg_logprob": -0.20966484967400045, "compression_ratio": 1.7261904761904763, "no_speech_prob": 1.1658587027341127e-05}, {"id": 88, "seek": 34500, "start": 370.0, "end": 374.0, "text": " Maybe you're using the same framework under the hood and somebody just wants to go look at the code", "tokens": [2704, 291, 434, 1228, 264, 912, 8388, 833, 264, 13376, 293, 2618, 445, 2738, 281, 352, 574, 412, 264, 3089], "temperature": 0.0, "avg_logprob": -0.20966484967400045, "compression_ratio": 1.7261904761904763, "no_speech_prob": 1.1658587027341127e-05}, {"id": 89, "seek": 37400, "start": 374.0, "end": 376.0, "text": " and see how someone else did it.", "tokens": [293, 536, 577, 1580, 1646, 630, 309, 13], "temperature": 0.0, "avg_logprob": -0.18154847103616464, "compression_ratio": 1.6009174311926606, "no_speech_prob": 5.64917572773993e-05}, {"id": 90, "seek": 37400, "start": 376.0, "end": 382.0, "text": " Yeah, there's definitely like a learning aspect to open source as well,", "tokens": [865, 11, 456, 311, 2138, 411, 257, 2539, 4171, 281, 1269, 4009, 382, 731, 11], "temperature": 0.0, "avg_logprob": -0.18154847103616464, "compression_ratio": 1.6009174311926606, "no_speech_prob": 5.64917572773993e-05}, {"id": 91, "seek": 37400, "start": 382.0, "end": 385.0, "text": " where you look at other people's code and you learn from that.", "tokens": [689, 291, 574, 412, 661, 561, 311, 3089, 293, 291, 1466, 490, 300, 13], "temperature": 0.0, "avg_logprob": -0.18154847103616464, "compression_ratio": 1.6009174311926606, "no_speech_prob": 5.64917572773993e-05}, {"id": 92, "seek": 37400, "start": 385.0, "end": 386.0, "text": " Yes. Right.", "tokens": [1079, 13, 1779, 13], "temperature": 0.0, "avg_logprob": -0.18154847103616464, "compression_ratio": 1.6009174311926606, "no_speech_prob": 5.64917572773993e-05}, {"id": 93, "seek": 37400, "start": 386.0, "end": 392.0, "text": " And I definitely feel like doing more open source has helped me reach new levels,", "tokens": [400, 286, 2138, 841, 411, 884, 544, 1269, 4009, 575, 4254, 385, 2524, 777, 4358, 11], "temperature": 0.0, "avg_logprob": -0.18154847103616464, "compression_ratio": 1.6009174311926606, "no_speech_prob": 5.64917572773993e-05}, {"id": 94, "seek": 37400, "start": 392.0, "end": 396.0, "text": " which would have been hard to reach if I only did programming at work.", "tokens": [597, 576, 362, 668, 1152, 281, 2524, 498, 286, 787, 630, 9410, 412, 589, 13], "temperature": 0.0, "avg_logprob": -0.18154847103616464, "compression_ratio": 1.6009174311926606, "no_speech_prob": 5.64917572773993e-05}, {"id": 95, "seek": 37400, "start": 396.0, "end": 398.0, "text": " Yes, absolutely.", "tokens": [1079, 11, 3122, 13], "temperature": 0.0, "avg_logprob": -0.18154847103616464, "compression_ratio": 1.6009174311926606, "no_speech_prob": 5.64917572773993e-05}, {"id": 96, "seek": 39800, "start": 398.0, "end": 404.0, "text": " And, you know, to your point of wanting to build things that help people, you want to leverage that too.", "tokens": [400, 11, 291, 458, 11, 281, 428, 935, 295, 7935, 281, 1322, 721, 300, 854, 561, 11, 291, 528, 281, 13982, 300, 886, 13], "temperature": 0.0, "avg_logprob": -0.16234306855635208, "compression_ratio": 1.9657794676806084, "no_speech_prob": 6.107969238655642e-05}, {"id": 97, "seek": 39800, "start": 404.0, "end": 408.0, "text": " So the more leverage you have, the more your thing can help people.", "tokens": [407, 264, 544, 13982, 291, 362, 11, 264, 544, 428, 551, 393, 854, 561, 13], "temperature": 0.0, "avg_logprob": -0.16234306855635208, "compression_ratio": 1.9657794676806084, "no_speech_prob": 6.107969238655642e-05}, {"id": 98, "seek": 39800, "start": 408.0, "end": 411.0, "text": " And if it's open source, it can help people in these different ways.", "tokens": [400, 498, 309, 311, 1269, 4009, 11, 309, 393, 854, 561, 294, 613, 819, 2098, 13], "temperature": 0.0, "avg_logprob": -0.16234306855635208, "compression_ratio": 1.9657794676806084, "no_speech_prob": 6.107969238655642e-05}, {"id": 99, "seek": 39800, "start": 411.0, "end": 413.0, "text": " It can help people by them looking at the source code.", "tokens": [467, 393, 854, 561, 538, 552, 1237, 412, 264, 4009, 3089, 13], "temperature": 0.0, "avg_logprob": -0.16234306855635208, "compression_ratio": 1.9657794676806084, "no_speech_prob": 6.107969238655642e-05}, {"id": 100, "seek": 39800, "start": 413.0, "end": 419.0, "text": " It can help them by them being able to use it as a dependency in another open source project,", "tokens": [467, 393, 854, 552, 538, 552, 885, 1075, 281, 764, 309, 382, 257, 33621, 294, 1071, 1269, 4009, 1716, 11], "temperature": 0.0, "avg_logprob": -0.16234306855635208, "compression_ratio": 1.9657794676806084, "no_speech_prob": 6.107969238655642e-05}, {"id": 101, "seek": 39800, "start": 419.0, "end": 421.0, "text": " because it's just an open source thing.", "tokens": [570, 309, 311, 445, 364, 1269, 4009, 551, 13], "temperature": 0.0, "avg_logprob": -0.16234306855635208, "compression_ratio": 1.9657794676806084, "no_speech_prob": 6.107969238655642e-05}, {"id": 102, "seek": 39800, "start": 421.0, "end": 422.0, "text": " They don't need licensing.", "tokens": [814, 500, 380, 643, 29759, 13], "temperature": 0.0, "avg_logprob": -0.16234306855635208, "compression_ratio": 1.9657794676806084, "no_speech_prob": 6.107969238655642e-05}, {"id": 103, "seek": 39800, "start": 422.0, "end": 425.0, "text": " They don't need to think about any of these considerations,", "tokens": [814, 500, 380, 643, 281, 519, 466, 604, 295, 613, 24070, 11], "temperature": 0.0, "avg_logprob": -0.16234306855635208, "compression_ratio": 1.9657794676806084, "no_speech_prob": 6.107969238655642e-05}, {"id": 104, "seek": 42500, "start": 425.0, "end": 430.0, "text": " but they can also use it in a proprietary project and they don't have to think about that.", "tokens": [457, 436, 393, 611, 764, 309, 294, 257, 38992, 1716, 293, 436, 500, 380, 362, 281, 519, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.15035265583102986, "compression_ratio": 1.7936507936507937, "no_speech_prob": 2.8408370781107806e-05}, {"id": 105, "seek": 42500, "start": 430.0, "end": 434.0, "text": " And, you know, for me as an open source maintainer, that gives me great joy.", "tokens": [400, 11, 291, 458, 11, 337, 385, 382, 364, 1269, 4009, 6909, 260, 11, 300, 2709, 385, 869, 6258, 13], "temperature": 0.0, "avg_logprob": -0.15035265583102986, "compression_ratio": 1.7936507936507937, "no_speech_prob": 2.8408370781107806e-05}, {"id": 106, "seek": 42500, "start": 434.0, "end": 440.0, "text": " If people use an open source tool that I built in their business, that makes me very happy.", "tokens": [759, 561, 764, 364, 1269, 4009, 2290, 300, 286, 3094, 294, 641, 1606, 11, 300, 1669, 385, 588, 2055, 13], "temperature": 0.0, "avg_logprob": -0.15035265583102986, "compression_ratio": 1.7936507936507937, "no_speech_prob": 2.8408370781107806e-05}, {"id": 107, "seek": 42500, "start": 440.0, "end": 446.0, "text": " I mean, honestly, if no businesses used the tools that I built, then I might not build them.", "tokens": [286, 914, 11, 6095, 11, 498, 572, 6011, 1143, 264, 3873, 300, 286, 3094, 11, 550, 286, 1062, 406, 1322, 552, 13], "temperature": 0.0, "avg_logprob": -0.15035265583102986, "compression_ratio": 1.7936507936507937, "no_speech_prob": 2.8408370781107806e-05}, {"id": 108, "seek": 42500, "start": 446.0, "end": 448.0, "text": " That's like one of the main motivations.", "tokens": [663, 311, 411, 472, 295, 264, 2135, 39034, 13], "temperature": 0.0, "avg_logprob": -0.15035265583102986, "compression_ratio": 1.7936507936507937, "no_speech_prob": 2.8408370781107806e-05}, {"id": 109, "seek": 42500, "start": 448.0, "end": 451.0, "text": " And it makes it a lot easier for businesses to build them.", "tokens": [400, 309, 1669, 309, 257, 688, 3571, 337, 6011, 281, 1322, 552, 13], "temperature": 0.0, "avg_logprob": -0.15035265583102986, "compression_ratio": 1.7936507936507937, "no_speech_prob": 2.8408370781107806e-05}, {"id": 110, "seek": 45100, "start": 451.0, "end": 459.0, "text": " Like these days, it's hard to imagine a business betting on a programming language that's not open source.", "tokens": [1743, 613, 1708, 11, 309, 311, 1152, 281, 3811, 257, 1606, 34246, 322, 257, 9410, 2856, 300, 311, 406, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.16268516255316334, "compression_ratio": 1.6374045801526718, "no_speech_prob": 2.0774272343260236e-05}, {"id": 111, "seek": 45100, "start": 459.0, "end": 465.0, "text": " This has not always been the case, but there's been sort of a revolution where that's the expectation,", "tokens": [639, 575, 406, 1009, 668, 264, 1389, 11, 457, 456, 311, 668, 1333, 295, 257, 8894, 689, 300, 311, 264, 14334, 11], "temperature": 0.0, "avg_logprob": -0.16268516255316334, "compression_ratio": 1.6374045801526718, "no_speech_prob": 2.0774272343260236e-05}, {"id": 112, "seek": 45100, "start": 465.0, "end": 470.0, "text": " because, you know, how are you going to feel confident about the security of a project", "tokens": [570, 11, 291, 458, 11, 577, 366, 291, 516, 281, 841, 6679, 466, 264, 3825, 295, 257, 1716], "temperature": 0.0, "avg_logprob": -0.16268516255316334, "compression_ratio": 1.6374045801526718, "no_speech_prob": 2.0774272343260236e-05}, {"id": 113, "seek": 45100, "start": 470.0, "end": 473.0, "text": " if you can't look at the code and see what it's doing?", "tokens": [498, 291, 393, 380, 574, 412, 264, 3089, 293, 536, 437, 309, 311, 884, 30], "temperature": 0.0, "avg_logprob": -0.16268516255316334, "compression_ratio": 1.6374045801526718, "no_speech_prob": 2.0774272343260236e-05}, {"id": 114, "seek": 45100, "start": 473.0, "end": 478.0, "text": " I think there used to be sort of the opposite view maybe a decade or two ago.", "tokens": [286, 519, 456, 1143, 281, 312, 1333, 295, 264, 6182, 1910, 1310, 257, 10378, 420, 732, 2057, 13], "temperature": 0.0, "avg_logprob": -0.16268516255316334, "compression_ratio": 1.6374045801526718, "no_speech_prob": 2.0774272343260236e-05}, {"id": 115, "seek": 47800, "start": 478.0, "end": 482.0, "text": " For languages or for projects or tools in general?", "tokens": [1171, 8650, 420, 337, 4455, 420, 3873, 294, 2674, 30], "temperature": 0.0, "avg_logprob": -0.25316112797434737, "compression_ratio": 1.5392670157068062, "no_speech_prob": 1.129832071455894e-05}, {"id": 116, "seek": 47800, "start": 482.0, "end": 485.0, "text": " For both, yeah.", "tokens": [1171, 1293, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.25316112797434737, "compression_ratio": 1.5392670157068062, "no_speech_prob": 1.129832071455894e-05}, {"id": 117, "seek": 47800, "start": 485.0, "end": 491.0, "text": " I mean, there's also just like the fact that it's very cheap because it's costless.", "tokens": [286, 914, 11, 456, 311, 611, 445, 411, 264, 1186, 300, 309, 311, 588, 7084, 570, 309, 311, 2063, 1832, 13], "temperature": 0.0, "avg_logprob": -0.25316112797434737, "compression_ratio": 1.5392670157068062, "no_speech_prob": 1.129832071455894e-05}, {"id": 118, "seek": 47800, "start": 491.0, "end": 498.0, "text": " Like, it doesn't cost you any penny to use it.", "tokens": [1743, 11, 309, 1177, 380, 2063, 291, 604, 24178, 281, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.25316112797434737, "compression_ratio": 1.5392670157068062, "no_speech_prob": 1.129832071455894e-05}, {"id": 119, "seek": 47800, "start": 498.0, "end": 503.0, "text": " Well, until you have to maintain it a little bit because the quality might be a little bit more,", "tokens": [1042, 11, 1826, 291, 362, 281, 6909, 309, 257, 707, 857, 570, 264, 3125, 1062, 312, 257, 707, 857, 544, 11], "temperature": 0.0, "avg_logprob": -0.25316112797434737, "compression_ratio": 1.5392670157068062, "no_speech_prob": 1.129832071455894e-05}, {"id": 120, "seek": 50300, "start": 503.0, "end": 511.0, "text": " a little bit worse than if you use a proprietary solution, which should hopefully be better.", "tokens": [257, 707, 857, 5324, 813, 498, 291, 764, 257, 38992, 3827, 11, 597, 820, 4696, 312, 1101, 13], "temperature": 0.0, "avg_logprob": -0.19808799028396606, "compression_ratio": 1.6575342465753424, "no_speech_prob": 8.749063999857754e-05}, {"id": 121, "seek": 50300, "start": 511.0, "end": 513.0, "text": " Like it can go both ways, right?", "tokens": [1743, 309, 393, 352, 1293, 2098, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.19808799028396606, "compression_ratio": 1.6575342465753424, "no_speech_prob": 8.749063999857754e-05}, {"id": 122, "seek": 50300, "start": 513.0, "end": 518.0, "text": " Right. I mean, if it's open source, then it's open to contributions.", "tokens": [1779, 13, 286, 914, 11, 498, 309, 311, 1269, 4009, 11, 550, 309, 311, 1269, 281, 15725, 13], "temperature": 0.0, "avg_logprob": -0.19808799028396606, "compression_ratio": 1.6575342465753424, "no_speech_prob": 8.749063999857754e-05}, {"id": 123, "seek": 50300, "start": 518.0, "end": 523.0, "text": " But if it's not open source, then it might be more sustainably funded.", "tokens": [583, 498, 309, 311, 406, 1269, 4009, 11, 550, 309, 1062, 312, 544, 6769, 1188, 14385, 13], "temperature": 0.0, "avg_logprob": -0.19808799028396606, "compression_ratio": 1.6575342465753424, "no_speech_prob": 8.749063999857754e-05}, {"id": 124, "seek": 50300, "start": 523.0, "end": 530.0, "text": " So that's sort of getting to the other side of what might be some of the downsides of open source", "tokens": [407, 300, 311, 1333, 295, 1242, 281, 264, 661, 1252, 295, 437, 1062, 312, 512, 295, 264, 21554, 1875, 295, 1269, 4009], "temperature": 0.0, "avg_logprob": -0.19808799028396606, "compression_ratio": 1.6575342465753424, "no_speech_prob": 8.749063999857754e-05}, {"id": 125, "seek": 53000, "start": 530.0, "end": 535.0, "text": " or perhaps not strictly downsides, but challenges that I think,", "tokens": [420, 4317, 406, 20792, 21554, 1875, 11, 457, 4759, 300, 286, 519, 11], "temperature": 0.0, "avg_logprob": -0.2061115029740007, "compression_ratio": 1.4946236559139785, "no_speech_prob": 0.00011232717224629596}, {"id": 126, "seek": 53000, "start": 535.0, "end": 541.0, "text": " I feel that we're at a pretty novel stage of open source.", "tokens": [286, 841, 300, 321, 434, 412, 257, 1238, 7613, 3233, 295, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.2061115029740007, "compression_ratio": 1.4946236559139785, "no_speech_prob": 0.00011232717224629596}, {"id": 127, "seek": 53000, "start": 541.0, "end": 547.0, "text": " And we have a lot of maturing to do as a software community in figuring out,", "tokens": [400, 321, 362, 257, 688, 295, 3803, 1345, 281, 360, 382, 257, 4722, 1768, 294, 15213, 484, 11], "temperature": 0.0, "avg_logprob": -0.2061115029740007, "compression_ratio": 1.4946236559139785, "no_speech_prob": 0.00011232717224629596}, {"id": 128, "seek": 53000, "start": 547.0, "end": 554.0, "text": " like we've kind of decided that open source is the way to go for most projects,", "tokens": [411, 321, 600, 733, 295, 3047, 300, 1269, 4009, 307, 264, 636, 281, 352, 337, 881, 4455, 11], "temperature": 0.0, "avg_logprob": -0.2061115029740007, "compression_ratio": 1.4946236559139785, "no_speech_prob": 0.00011232717224629596}, {"id": 129, "seek": 55400, "start": 554.0, "end": 562.0, "text": " for languages and frameworks and libraries for the most part, for 95, 99% of them.", "tokens": [337, 8650, 293, 29834, 293, 15148, 337, 264, 881, 644, 11, 337, 13420, 11, 11803, 4, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.2719119296354406, "compression_ratio": 1.4973262032085561, "no_speech_prob": 8.344948582816869e-05}, {"id": 130, "seek": 55400, "start": 562.0, "end": 569.0, "text": " But we haven't really figured out how to make the huge ambitious open source projects", "tokens": [583, 321, 2378, 380, 534, 8932, 484, 577, 281, 652, 264, 2603, 20239, 1269, 4009, 4455], "temperature": 0.0, "avg_logprob": -0.2719119296354406, "compression_ratio": 1.4973262032085561, "no_speech_prob": 8.344948582816869e-05}, {"id": 131, "seek": 55400, "start": 569.0, "end": 574.0, "text": " we depend on sustainable and avoid burnout for the people maintaining them.", "tokens": [321, 5672, 322, 11235, 293, 5042, 44841, 337, 264, 561, 14916, 552, 13], "temperature": 0.0, "avg_logprob": -0.2719119296354406, "compression_ratio": 1.4973262032085561, "no_speech_prob": 8.344948582816869e-05}, {"id": 132, "seek": 55400, "start": 574.0, "end": 577.0, "text": " Burnout.", "tokens": [18328, 346, 13], "temperature": 0.0, "avg_logprob": -0.2719119296354406, "compression_ratio": 1.4973262032085561, "no_speech_prob": 8.344948582816869e-05}, {"id": 133, "seek": 55400, "start": 577.0, "end": 582.0, "text": " Open source little friend.", "tokens": [7238, 4009, 707, 1277, 13], "temperature": 0.0, "avg_logprob": -0.2719119296354406, "compression_ratio": 1.4973262032085561, "no_speech_prob": 8.344948582816869e-05}, {"id": 134, "seek": 58200, "start": 582.0, "end": 585.0, "text": " Yeah. So that's another side of it.", "tokens": [865, 13, 407, 300, 311, 1071, 1252, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.24807962745127052, "compression_ratio": 1.5304347826086957, "no_speech_prob": 0.00017395180475432426}, {"id": 135, "seek": 58200, "start": 585.0, "end": 593.0, "text": " And I mean, I recently spent a year and a half working full time on the on-page V3 release.", "tokens": [400, 286, 914, 11, 286, 3938, 4418, 257, 1064, 293, 257, 1922, 1364, 1577, 565, 322, 264, 322, 12, 15161, 691, 18, 4374, 13], "temperature": 0.0, "avg_logprob": -0.24807962745127052, "compression_ratio": 1.5304347826086957, "no_speech_prob": 0.00017395180475432426}, {"id": 136, "seek": 58200, "start": 593.0, "end": 599.0, "text": " And it was very rewarding. I got to build this thing that I really cared about.", "tokens": [400, 309, 390, 588, 20063, 13, 286, 658, 281, 1322, 341, 551, 300, 286, 534, 19779, 466, 13], "temperature": 0.0, "avg_logprob": -0.24807962745127052, "compression_ratio": 1.5304347826086957, "no_speech_prob": 0.00017395180475432426}, {"id": 137, "seek": 58200, "start": 599.0, "end": 606.0, "text": " But it was, I mean, and I was fortunate enough to have a company helping to fund my work,", "tokens": [583, 309, 390, 11, 286, 914, 11, 293, 286, 390, 14096, 1547, 281, 362, 257, 2237, 4315, 281, 2374, 452, 589, 11], "temperature": 0.0, "avg_logprob": -0.24807962745127052, "compression_ratio": 1.5304347826086957, "no_speech_prob": 0.00017395180475432426}, {"id": 138, "seek": 58200, "start": 606.0, "end": 610.0, "text": " but I was still the primary sponsor of my work. Right.", "tokens": [457, 286, 390, 920, 264, 6194, 16198, 295, 452, 589, 13, 1779, 13], "temperature": 0.0, "avg_logprob": -0.24807962745127052, "compression_ratio": 1.5304347826086957, "no_speech_prob": 0.00017395180475432426}, {"id": 139, "seek": 61000, "start": 610.0, "end": 616.0, "text": " And I think a lot of people in the open source community end up doing that.", "tokens": [400, 286, 519, 257, 688, 295, 561, 294, 264, 1269, 4009, 1768, 917, 493, 884, 300, 13], "temperature": 0.0, "avg_logprob": -0.16305212264365337, "compression_ratio": 1.625531914893617, "no_speech_prob": 2.9772190828225575e-05}, {"id": 140, "seek": 61000, "start": 616.0, "end": 622.0, "text": " There are some projects that are lucky enough to have massive sustainable funding,", "tokens": [821, 366, 512, 4455, 300, 366, 6356, 1547, 281, 362, 5994, 11235, 6137, 11], "temperature": 0.0, "avg_logprob": -0.16305212264365337, "compression_ratio": 1.625531914893617, "no_speech_prob": 2.9772190828225575e-05}, {"id": 141, "seek": 61000, "start": 622.0, "end": 625.0, "text": " but the majority of open source is not that way.", "tokens": [457, 264, 6286, 295, 1269, 4009, 307, 406, 300, 636, 13], "temperature": 0.0, "avg_logprob": -0.16305212264365337, "compression_ratio": 1.625531914893617, "no_speech_prob": 2.9772190828225575e-05}, {"id": 142, "seek": 61000, "start": 625.0, "end": 629.0, "text": " I mean, when you say massive, I'm like, it's still pretty small.", "tokens": [286, 914, 11, 562, 291, 584, 5994, 11, 286, 478, 411, 11, 309, 311, 920, 1238, 1359, 13], "temperature": 0.0, "avg_logprob": -0.16305212264365337, "compression_ratio": 1.625531914893617, "no_speech_prob": 2.9772190828225575e-05}, {"id": 143, "seek": 61000, "start": 629.0, "end": 636.0, "text": " Like any project you can think of has very little backing compared to any projects that you can find at work.", "tokens": [1743, 604, 1716, 291, 393, 519, 295, 575, 588, 707, 19373, 5347, 281, 604, 4455, 300, 291, 393, 915, 412, 589, 13], "temperature": 0.0, "avg_logprob": -0.16305212264365337, "compression_ratio": 1.625531914893617, "no_speech_prob": 2.9772190828225575e-05}, {"id": 144, "seek": 63600, "start": 636.0, "end": 641.0, "text": " Yeah. I mean, like React, for example, would be one of the big ones that comes to mind", "tokens": [865, 13, 286, 914, 11, 411, 30644, 11, 337, 1365, 11, 576, 312, 472, 295, 264, 955, 2306, 300, 1487, 281, 1575], "temperature": 0.0, "avg_logprob": -0.19374025647885332, "compression_ratio": 1.5617977528089888, "no_speech_prob": 1.1842504136438947e-05}, {"id": 145, "seek": 63600, "start": 641.0, "end": 648.0, "text": " where they have enough budget to hire full time teams of people building documentation.", "tokens": [689, 436, 362, 1547, 4706, 281, 11158, 1577, 565, 5491, 295, 561, 2390, 14333, 13], "temperature": 0.0, "avg_logprob": -0.19374025647885332, "compression_ratio": 1.5617977528089888, "no_speech_prob": 1.1842504136438947e-05}, {"id": 146, "seek": 63600, "start": 648.0, "end": 652.0, "text": " But it's rare and that might not last forever either.", "tokens": [583, 309, 311, 5892, 293, 300, 1062, 406, 1036, 5680, 2139, 13], "temperature": 0.0, "avg_logprob": -0.19374025647885332, "compression_ratio": 1.5617977528089888, "no_speech_prob": 1.1842504136438947e-05}, {"id": 147, "seek": 63600, "start": 652.0, "end": 657.0, "text": " Yeah. I think actually some of them are moving towards other companies.", "tokens": [865, 13, 286, 519, 767, 512, 295, 552, 366, 2684, 3030, 661, 3431, 13], "temperature": 0.0, "avg_logprob": -0.19374025647885332, "compression_ratio": 1.5617977528089888, "no_speech_prob": 1.1842504136438947e-05}, {"id": 148, "seek": 63600, "start": 657.0, "end": 661.0, "text": " So it's diversifying in a way, which is probably good.", "tokens": [407, 309, 311, 6111, 5489, 294, 257, 636, 11, 597, 307, 1391, 665, 13], "temperature": 0.0, "avg_logprob": -0.19374025647885332, "compression_ratio": 1.5617977528089888, "no_speech_prob": 1.1842504136438947e-05}, {"id": 149, "seek": 63600, "start": 661.0, "end": 664.0, "text": " My memory might be wrong about this, but if it is, then yeah.", "tokens": [1222, 4675, 1062, 312, 2085, 466, 341, 11, 457, 498, 309, 307, 11, 550, 1338, 13], "temperature": 0.0, "avg_logprob": -0.19374025647885332, "compression_ratio": 1.5617977528089888, "no_speech_prob": 1.1842504136438947e-05}, {"id": 150, "seek": 66400, "start": 664.0, "end": 668.0, "text": " No. Yeah. I mean, Dan Abramoff recently left Meta.", "tokens": [883, 13, 865, 13, 286, 914, 11, 3394, 31717, 335, 4506, 3938, 1411, 6377, 64, 13], "temperature": 0.0, "avg_logprob": -0.2241036766453793, "compression_ratio": 1.576470588235294, "no_speech_prob": 0.00011957233800785616}, {"id": 151, "seek": 66400, "start": 668.0, "end": 672.0, "text": " So and he was one of the key people in the React team,", "tokens": [407, 293, 415, 390, 472, 295, 264, 2141, 561, 294, 264, 30644, 1469, 11], "temperature": 0.0, "avg_logprob": -0.2241036766453793, "compression_ratio": 1.576470588235294, "no_speech_prob": 0.00011957233800785616}, {"id": 152, "seek": 66400, "start": 672.0, "end": 677.0, "text": " but he's still going to be on the React core team just at a different company, I think.", "tokens": [457, 415, 311, 920, 516, 281, 312, 322, 264, 30644, 4965, 1469, 445, 412, 257, 819, 2237, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.2241036766453793, "compression_ratio": 1.576470588235294, "no_speech_prob": 0.00011957233800785616}, {"id": 153, "seek": 66400, "start": 677.0, "end": 682.0, "text": " So it's just the difference is who pays him, I guess.", "tokens": [407, 309, 311, 445, 264, 2649, 307, 567, 10604, 796, 11, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.2241036766453793, "compression_ratio": 1.576470588235294, "no_speech_prob": 0.00011957233800785616}, {"id": 154, "seek": 66400, "start": 682.0, "end": 685.0, "text": " Yeah. Yeah. And perhaps whether he'll be paid for it.", "tokens": [865, 13, 865, 13, 400, 4317, 1968, 415, 603, 312, 4835, 337, 309, 13], "temperature": 0.0, "avg_logprob": -0.2241036766453793, "compression_ratio": 1.576470588235294, "no_speech_prob": 0.00011957233800785616}, {"id": 155, "seek": 66400, "start": 685.0, "end": 693.0, "text": " I'm not sure in that particular instance, but it's definitely a challenge for the open source world.", "tokens": [286, 478, 406, 988, 294, 300, 1729, 5197, 11, 457, 309, 311, 2138, 257, 3430, 337, 264, 1269, 4009, 1002, 13], "temperature": 0.0, "avg_logprob": -0.2241036766453793, "compression_ratio": 1.576470588235294, "no_speech_prob": 0.00011957233800785616}, {"id": 156, "seek": 69300, "start": 693.0, "end": 697.0, "text": " And of course, in the Elm community, we are particularly aware of this", "tokens": [400, 295, 1164, 11, 294, 264, 2699, 76, 1768, 11, 321, 366, 4098, 3650, 295, 341], "temperature": 0.0, "avg_logprob": -0.2073243335612769, "compression_ratio": 1.6885245901639345, "no_speech_prob": 4.3999094486935064e-05}, {"id": 157, "seek": 69300, "start": 697.0, "end": 703.0, "text": " because we've seen different permutations in the life of Elm", "tokens": [570, 321, 600, 1612, 819, 4784, 325, 763, 294, 264, 993, 295, 2699, 76], "temperature": 0.0, "avg_logprob": -0.2073243335612769, "compression_ratio": 1.6885245901639345, "no_speech_prob": 4.3999094486935064e-05}, {"id": 158, "seek": 69300, "start": 703.0, "end": 707.0, "text": " with how Evan has been funding Elm's development.", "tokens": [365, 577, 22613, 575, 668, 6137, 2699, 76, 311, 3250, 13], "temperature": 0.0, "avg_logprob": -0.2073243335612769, "compression_ratio": 1.6885245901639345, "no_speech_prob": 4.3999094486935064e-05}, {"id": 159, "seek": 69300, "start": 707.0, "end": 711.0, "text": " And we had an episode about funding open source with Evan,", "tokens": [400, 321, 632, 364, 3500, 466, 6137, 1269, 4009, 365, 22613, 11], "temperature": 0.0, "avg_logprob": -0.2073243335612769, "compression_ratio": 1.6885245901639345, "no_speech_prob": 4.3999094486935064e-05}, {"id": 160, "seek": 69300, "start": 711.0, "end": 714.0, "text": " and he talked about a lot of different ideas there.", "tokens": [293, 415, 2825, 466, 257, 688, 295, 819, 3487, 456, 13], "temperature": 0.0, "avg_logprob": -0.2073243335612769, "compression_ratio": 1.6885245901639345, "no_speech_prob": 4.3999094486935064e-05}, {"id": 161, "seek": 69300, "start": 714.0, "end": 719.0, "text": " And a lot of the challenges of aligning the incentives between a business", "tokens": [400, 257, 688, 295, 264, 4759, 295, 419, 9676, 264, 23374, 1296, 257, 1606], "temperature": 0.0, "avg_logprob": -0.2073243335612769, "compression_ratio": 1.6885245901639345, "no_speech_prob": 4.3999094486935064e-05}, {"id": 162, "seek": 69300, "start": 719.0, "end": 722.0, "text": " and an open source project is very difficult.", "tokens": [293, 364, 1269, 4009, 1716, 307, 588, 2252, 13], "temperature": 0.0, "avg_logprob": -0.2073243335612769, "compression_ratio": 1.6885245901639345, "no_speech_prob": 4.3999094486935064e-05}, {"id": 163, "seek": 72200, "start": 722.0, "end": 726.0, "text": " So another thing that comes to mind for me with open source is,", "tokens": [407, 1071, 551, 300, 1487, 281, 1575, 337, 385, 365, 1269, 4009, 307, 11], "temperature": 0.0, "avg_logprob": -0.1950077215830485, "compression_ratio": 1.7202380952380953, "no_speech_prob": 9.027291525853798e-05}, {"id": 164, "seek": 72200, "start": 726.0, "end": 732.0, "text": " so what should users of an open source project expect?", "tokens": [370, 437, 820, 5022, 295, 364, 1269, 4009, 1716, 2066, 30], "temperature": 0.0, "avg_logprob": -0.1950077215830485, "compression_ratio": 1.7202380952380953, "no_speech_prob": 9.027291525853798e-05}, {"id": 165, "seek": 72200, "start": 732.0, "end": 737.0, "text": " And what should maintainers of an open source project expect from their users?", "tokens": [400, 437, 820, 6909, 433, 295, 364, 1269, 4009, 1716, 2066, 490, 641, 5022, 30], "temperature": 0.0, "avg_logprob": -0.1950077215830485, "compression_ratio": 1.7202380952380953, "no_speech_prob": 9.027291525853798e-05}, {"id": 166, "seek": 72200, "start": 737.0, "end": 739.0, "text": " Perfection.", "tokens": [10246, 313, 13], "temperature": 0.0, "avg_logprob": -0.1950077215830485, "compression_ratio": 1.7202380952380953, "no_speech_prob": 9.027291525853798e-05}, {"id": 167, "seek": 72200, "start": 739.0, "end": 747.0, "text": " I expect nothing less than perfection from anyone.", "tokens": [286, 2066, 1825, 1570, 813, 19708, 490, 2878, 13], "temperature": 0.0, "avg_logprob": -0.1950077215830485, "compression_ratio": 1.7202380952380953, "no_speech_prob": 9.027291525853798e-05}, {"id": 168, "seek": 72200, "start": 747.0, "end": 751.0, "text": " Sometimes it feels that way.", "tokens": [4803, 309, 3417, 300, 636, 13], "temperature": 0.0, "avg_logprob": -0.1950077215830485, "compression_ratio": 1.7202380952380953, "no_speech_prob": 9.027291525853798e-05}, {"id": 169, "seek": 75100, "start": 751.0, "end": 756.0, "text": " Do you mean like, for instance, if I open an issue, what should I expect?", "tokens": [1144, 291, 914, 411, 11, 337, 5197, 11, 498, 286, 1269, 364, 2734, 11, 437, 820, 286, 2066, 30], "temperature": 0.0, "avg_logprob": -0.15727070928777306, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.0002338474296266213}, {"id": 170, "seek": 75100, "start": 756.0, "end": 757.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.15727070928777306, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.0002338474296266213}, {"id": 171, "seek": 75100, "start": 757.0, "end": 762.0, "text": " Or if I'm a maintainer, what do users expect of me? What do I expect of them?", "tokens": [1610, 498, 286, 478, 257, 6909, 260, 11, 437, 360, 5022, 2066, 295, 385, 30, 708, 360, 286, 2066, 295, 552, 30], "temperature": 0.0, "avg_logprob": -0.15727070928777306, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.0002338474296266213}, {"id": 172, "seek": 75100, "start": 762.0, "end": 763.0, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.15727070928777306, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.0002338474296266213}, {"id": 173, "seek": 75100, "start": 763.0, "end": 767.0, "text": " I have a feeling you want to lean me towards someone.", "tokens": [286, 362, 257, 2633, 291, 528, 281, 11659, 385, 3030, 1580, 13], "temperature": 0.0, "avg_logprob": -0.15727070928777306, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.0002338474296266213}, {"id": 174, "seek": 75100, "start": 767.0, "end": 770.0, "text": " Well, I have opinions, but I'm curious what yours are.", "tokens": [1042, 11, 286, 362, 11819, 11, 457, 286, 478, 6369, 437, 6342, 366, 13], "temperature": 0.0, "avg_logprob": -0.15727070928777306, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.0002338474296266213}, {"id": 175, "seek": 75100, "start": 770.0, "end": 776.0, "text": " I mean, I know that one of the things that people dislike with open source", "tokens": [286, 914, 11, 286, 458, 300, 472, 295, 264, 721, 300, 561, 26006, 365, 1269, 4009], "temperature": 0.0, "avg_logprob": -0.15727070928777306, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.0002338474296266213}, {"id": 176, "seek": 77600, "start": 776.0, "end": 782.0, "text": " is when you're a maintainer and there's a user who doesn't ask for something,", "tokens": [307, 562, 291, 434, 257, 6909, 260, 293, 456, 311, 257, 4195, 567, 1177, 380, 1029, 337, 746, 11], "temperature": 0.0, "avg_logprob": -0.190621551202268, "compression_ratio": 1.7393364928909953, "no_speech_prob": 4.133064430789091e-05}, {"id": 177, "seek": 77600, "start": 782.0, "end": 786.0, "text": " who doesn't open an issue or make a pull request on something,", "tokens": [567, 1177, 380, 1269, 364, 2734, 420, 652, 257, 2235, 5308, 322, 746, 11], "temperature": 0.0, "avg_logprob": -0.190621551202268, "compression_ratio": 1.7393364928909953, "no_speech_prob": 4.133064430789091e-05}, {"id": 178, "seek": 77600, "start": 786.0, "end": 789.0, "text": " and says, could you please look at this,", "tokens": [293, 1619, 11, 727, 291, 1767, 574, 412, 341, 11], "temperature": 0.0, "avg_logprob": -0.190621551202268, "compression_ratio": 1.7393364928909953, "no_speech_prob": 4.133064430789091e-05}, {"id": 179, "seek": 77600, "start": 789.0, "end": 793.0, "text": " but who would demand that you look at something,", "tokens": [457, 567, 576, 4733, 300, 291, 574, 412, 746, 11], "temperature": 0.0, "avg_logprob": -0.190621551202268, "compression_ratio": 1.7393364928909953, "no_speech_prob": 4.133064430789091e-05}, {"id": 180, "seek": 77600, "start": 793.0, "end": 796.0, "text": " basically as if they were owed something.", "tokens": [1936, 382, 498, 436, 645, 41262, 746, 13], "temperature": 0.0, "avg_logprob": -0.190621551202268, "compression_ratio": 1.7393364928909953, "no_speech_prob": 4.133064430789091e-05}, {"id": 181, "seek": 77600, "start": 796.0, "end": 800.0, "text": " And that is obviously not a great expectation,", "tokens": [400, 300, 307, 2745, 406, 257, 869, 14334, 11], "temperature": 0.0, "avg_logprob": -0.190621551202268, "compression_ratio": 1.7393364928909953, "no_speech_prob": 4.133064430789091e-05}, {"id": 182, "seek": 77600, "start": 800.0, "end": 804.0, "text": " which if it works out for the maintainer, sure.", "tokens": [597, 498, 309, 1985, 484, 337, 264, 6909, 260, 11, 988, 13], "temperature": 0.0, "avg_logprob": -0.190621551202268, "compression_ratio": 1.7393364928909953, "no_speech_prob": 4.133064430789091e-05}, {"id": 183, "seek": 80400, "start": 804.0, "end": 808.0, "text": " If it doesn't, then refer to the license.", "tokens": [759, 309, 1177, 380, 11, 550, 2864, 281, 264, 10476, 13], "temperature": 0.0, "avg_logprob": -0.19001338958740235, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.00010886514064623043}, {"id": 184, "seek": 80400, "start": 808.0, "end": 811.0, "text": " There's no warranty.", "tokens": [821, 311, 572, 26852, 13], "temperature": 0.0, "avg_logprob": -0.19001338958740235, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.00010886514064623043}, {"id": 185, "seek": 80400, "start": 811.0, "end": 816.0, "text": " The maintainer is not getting paid for any of the work.", "tokens": [440, 6909, 260, 307, 406, 1242, 4835, 337, 604, 295, 264, 589, 13], "temperature": 0.0, "avg_logprob": -0.19001338958740235, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.00010886514064623043}, {"id": 186, "seek": 80400, "start": 816.0, "end": 820.0, "text": " They are not compensated, so you should not expect anything from them", "tokens": [814, 366, 406, 11598, 770, 11, 370, 291, 820, 406, 2066, 1340, 490, 552], "temperature": 0.0, "avg_logprob": -0.19001338958740235, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.00010886514064623043}, {"id": 187, "seek": 80400, "start": 820.0, "end": 823.0, "text": " except their benevolence, I guess, in a way,", "tokens": [3993, 641, 48567, 655, 11, 286, 2041, 11, 294, 257, 636, 11], "temperature": 0.0, "avg_logprob": -0.19001338958740235, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.00010886514064623043}, {"id": 188, "seek": 80400, "start": 823.0, "end": 827.0, "text": " like their empathy and their willingness to work for free", "tokens": [411, 641, 18701, 293, 641, 25069, 281, 589, 337, 1737], "temperature": 0.0, "avg_logprob": -0.19001338958740235, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.00010886514064623043}, {"id": 189, "seek": 80400, "start": 827.0, "end": 830.0, "text": " just to make some people happy.", "tokens": [445, 281, 652, 512, 561, 2055, 13], "temperature": 0.0, "avg_logprob": -0.19001338958740235, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.00010886514064623043}, {"id": 190, "seek": 80400, "start": 830.0, "end": 833.0, "text": " So is that where you wanted to lead me?", "tokens": [407, 307, 300, 689, 291, 1415, 281, 1477, 385, 30], "temperature": 0.0, "avg_logprob": -0.19001338958740235, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.00010886514064623043}, {"id": 191, "seek": 83300, "start": 833.0, "end": 835.0, "text": " Yeah, it kind of is.", "tokens": [865, 11, 309, 733, 295, 307, 13], "temperature": 0.0, "avg_logprob": -0.2111321414809629, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.0001685960014583543}, {"id": 192, "seek": 83300, "start": 835.0, "end": 837.0, "text": " I knew it.", "tokens": [286, 2586, 309, 13], "temperature": 0.0, "avg_logprob": -0.2111321414809629, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.0001685960014583543}, {"id": 193, "seek": 83300, "start": 837.0, "end": 840.0, "text": " I definitely feel the same way.", "tokens": [286, 2138, 841, 264, 912, 636, 13], "temperature": 0.0, "avg_logprob": -0.2111321414809629, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.0001685960014583543}, {"id": 194, "seek": 83300, "start": 840.0, "end": 845.0, "text": " So what should users expect from an open source project?", "tokens": [407, 437, 820, 5022, 2066, 490, 364, 1269, 4009, 1716, 30], "temperature": 0.0, "avg_logprob": -0.2111321414809629, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.0001685960014583543}, {"id": 195, "seek": 83300, "start": 845.0, "end": 849.0, "text": " And yeah, to me, the answer is you shouldn't expect anything.", "tokens": [400, 1338, 11, 281, 385, 11, 264, 1867, 307, 291, 4659, 380, 2066, 1340, 13], "temperature": 0.0, "avg_logprob": -0.2111321414809629, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.0001685960014583543}, {"id": 196, "seek": 83300, "start": 849.0, "end": 855.0, "text": " But that's obviously not great if you're just like, whatever,", "tokens": [583, 300, 311, 2745, 406, 869, 498, 291, 434, 445, 411, 11, 2035, 11], "temperature": 0.0, "avg_logprob": -0.2111321414809629, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.0001685960014583543}, {"id": 197, "seek": 83300, "start": 855.0, "end": 859.0, "text": " I don't care what this project needs.", "tokens": [286, 500, 380, 1127, 437, 341, 1716, 2203, 13], "temperature": 0.0, "avg_logprob": -0.2111321414809629, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.0001685960014583543}, {"id": 198, "seek": 85900, "start": 859.0, "end": 864.0, "text": " Obviously, I don't think that's the right answer either.", "tokens": [7580, 11, 286, 500, 380, 519, 300, 311, 264, 558, 1867, 2139, 13], "temperature": 0.0, "avg_logprob": -0.20896534043915418, "compression_ratio": 1.631578947368421, "no_speech_prob": 3.218626443413086e-05}, {"id": 199, "seek": 85900, "start": 864.0, "end": 870.0, "text": " But I think the question for me is what do you want out of the project?", "tokens": [583, 286, 519, 264, 1168, 337, 385, 307, 437, 360, 291, 528, 484, 295, 264, 1716, 30], "temperature": 0.0, "avg_logprob": -0.20896534043915418, "compression_ratio": 1.631578947368421, "no_speech_prob": 3.218626443413086e-05}, {"id": 200, "seek": 85900, "start": 870.0, "end": 873.0, "text": " If you put an open source project out there,", "tokens": [759, 291, 829, 364, 1269, 4009, 1716, 484, 456, 11], "temperature": 0.0, "avg_logprob": -0.20896534043915418, "compression_ratio": 1.631578947368421, "no_speech_prob": 3.218626443413086e-05}, {"id": 201, "seek": 85900, "start": 873.0, "end": 878.0, "text": " if you publish your blog as an open source project,", "tokens": [498, 291, 11374, 428, 6968, 382, 364, 1269, 4009, 1716, 11], "temperature": 0.0, "avg_logprob": -0.20896534043915418, "compression_ratio": 1.631578947368421, "no_speech_prob": 3.218626443413086e-05}, {"id": 202, "seek": 85900, "start": 878.0, "end": 882.0, "text": " what should people expect from you?", "tokens": [437, 820, 561, 2066, 490, 291, 30], "temperature": 0.0, "avg_logprob": -0.20896534043915418, "compression_ratio": 1.631578947368421, "no_speech_prob": 3.218626443413086e-05}, {"id": 203, "seek": 85900, "start": 882.0, "end": 884.0, "text": " Clearly, that's kind of it.", "tokens": [24120, 11, 300, 311, 733, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.20896534043915418, "compression_ratio": 1.631578947368421, "no_speech_prob": 3.218626443413086e-05}, {"id": 204, "seek": 85900, "start": 884.0, "end": 887.0, "text": " It's like, this is my blog, and you can look at it,", "tokens": [467, 311, 411, 11, 341, 307, 452, 6968, 11, 293, 291, 393, 574, 412, 309, 11], "temperature": 0.0, "avg_logprob": -0.20896534043915418, "compression_ratio": 1.631578947368421, "no_speech_prob": 3.218626443413086e-05}, {"id": 205, "seek": 88700, "start": 887.0, "end": 891.0, "text": " and you can copy some of the code if you, whatever,", "tokens": [293, 291, 393, 5055, 512, 295, 264, 3089, 498, 291, 11, 2035, 11], "temperature": 0.0, "avg_logprob": -0.15077418147927463, "compression_ratio": 1.6188340807174888, "no_speech_prob": 1.0451364687469322e-05}, {"id": 206, "seek": 88700, "start": 891.0, "end": 893.0, "text": " put the license in the right place.", "tokens": [829, 264, 10476, 294, 264, 558, 1081, 13], "temperature": 0.0, "avg_logprob": -0.15077418147927463, "compression_ratio": 1.6188340807174888, "no_speech_prob": 1.0451364687469322e-05}, {"id": 207, "seek": 88700, "start": 893.0, "end": 895.0, "text": " But that's it.", "tokens": [583, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.15077418147927463, "compression_ratio": 1.6188340807174888, "no_speech_prob": 1.0451364687469322e-05}, {"id": 208, "seek": 88700, "start": 895.0, "end": 897.0, "text": " People don't really expect much more.", "tokens": [3432, 500, 380, 534, 2066, 709, 544, 13], "temperature": 0.0, "avg_logprob": -0.15077418147927463, "compression_ratio": 1.6188340807174888, "no_speech_prob": 1.0451364687469322e-05}, {"id": 209, "seek": 88700, "start": 897.0, "end": 902.0, "text": " But somehow, when it's publishing a library or a framework,", "tokens": [583, 6063, 11, 562, 309, 311, 17832, 257, 6405, 420, 257, 8388, 11], "temperature": 0.0, "avg_logprob": -0.15077418147927463, "compression_ratio": 1.6188340807174888, "no_speech_prob": 1.0451364687469322e-05}, {"id": 210, "seek": 88700, "start": 902.0, "end": 907.0, "text": " people can start to expect that they can set the agenda.", "tokens": [561, 393, 722, 281, 2066, 300, 436, 393, 992, 264, 9829, 13], "temperature": 0.0, "avg_logprob": -0.15077418147927463, "compression_ratio": 1.6188340807174888, "no_speech_prob": 1.0451364687469322e-05}, {"id": 211, "seek": 88700, "start": 907.0, "end": 911.0, "text": " I don't think that doesn't feel good as a maintainer", "tokens": [286, 500, 380, 519, 300, 1177, 380, 841, 665, 382, 257, 6909, 260], "temperature": 0.0, "avg_logprob": -0.15077418147927463, "compression_ratio": 1.6188340807174888, "no_speech_prob": 1.0451364687469322e-05}, {"id": 212, "seek": 88700, "start": 911.0, "end": 914.0, "text": " when that's the vibe you're getting from somebody.", "tokens": [562, 300, 311, 264, 14606, 291, 434, 1242, 490, 2618, 13], "temperature": 0.0, "avg_logprob": -0.15077418147927463, "compression_ratio": 1.6188340807174888, "no_speech_prob": 1.0451364687469322e-05}, {"id": 213, "seek": 91400, "start": 914.0, "end": 919.0, "text": " But at the same time, if you create a project that people are depending on,", "tokens": [583, 412, 264, 912, 565, 11, 498, 291, 1884, 257, 1716, 300, 561, 366, 5413, 322, 11], "temperature": 0.0, "avg_logprob": -0.1521760155172909, "compression_ratio": 1.7348837209302326, "no_speech_prob": 1.8924913092632778e-05}, {"id": 214, "seek": 91400, "start": 919.0, "end": 925.0, "text": " then I think if you want that to be a sustainable thing", "tokens": [550, 286, 519, 498, 291, 528, 300, 281, 312, 257, 11235, 551], "temperature": 0.0, "avg_logprob": -0.1521760155172909, "compression_ratio": 1.7348837209302326, "no_speech_prob": 1.8924913092632778e-05}, {"id": 215, "seek": 91400, "start": 925.0, "end": 928.0, "text": " that people are going to continue to engage with,", "tokens": [300, 561, 366, 516, 281, 2354, 281, 4683, 365, 11], "temperature": 0.0, "avg_logprob": -0.1521760155172909, "compression_ratio": 1.7348837209302326, "no_speech_prob": 1.8924913092632778e-05}, {"id": 216, "seek": 91400, "start": 928.0, "end": 933.0, "text": " you are somehow going to need to earn the trust of users.", "tokens": [291, 366, 6063, 516, 281, 643, 281, 6012, 264, 3361, 295, 5022, 13], "temperature": 0.0, "avg_logprob": -0.1521760155172909, "compression_ratio": 1.7348837209302326, "no_speech_prob": 1.8924913092632778e-05}, {"id": 217, "seek": 91400, "start": 933.0, "end": 935.0, "text": " So that's how I look at it.", "tokens": [407, 300, 311, 577, 286, 574, 412, 309, 13], "temperature": 0.0, "avg_logprob": -0.1521760155172909, "compression_ratio": 1.7348837209302326, "no_speech_prob": 1.8924913092632778e-05}, {"id": 218, "seek": 91400, "start": 935.0, "end": 938.0, "text": " It's like, what do you want this project to be?", "tokens": [467, 311, 411, 11, 437, 360, 291, 528, 341, 1716, 281, 312, 30], "temperature": 0.0, "avg_logprob": -0.1521760155172909, "compression_ratio": 1.7348837209302326, "no_speech_prob": 1.8924913092632778e-05}, {"id": 219, "seek": 91400, "start": 938.0, "end": 942.0, "text": " And it's totally fair if somebody wants to make a project", "tokens": [400, 309, 311, 3879, 3143, 498, 2618, 2738, 281, 652, 257, 1716], "temperature": 0.0, "avg_logprob": -0.1521760155172909, "compression_ratio": 1.7348837209302326, "no_speech_prob": 1.8924913092632778e-05}, {"id": 220, "seek": 94200, "start": 942.0, "end": 945.0, "text": " and ride off into the sunset.", "tokens": [293, 5077, 766, 666, 264, 20142, 13], "temperature": 0.0, "avg_logprob": -0.1506478225483614, "compression_ratio": 1.6414473684210527, "no_speech_prob": 2.0145063899690285e-05}, {"id": 221, "seek": 94200, "start": 945.0, "end": 948.0, "text": " That's totally fine. They're allowed to do that.", "tokens": [663, 311, 3879, 2489, 13, 814, 434, 4350, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.1506478225483614, "compression_ratio": 1.6414473684210527, "no_speech_prob": 2.0145063899690285e-05}, {"id": 222, "seek": 94200, "start": 948.0, "end": 952.0, "text": " And I don't blame an open-source maintainer who does that.", "tokens": [400, 286, 500, 380, 10127, 364, 1269, 12, 41676, 6909, 260, 567, 775, 300, 13], "temperature": 0.0, "avg_logprob": -0.1506478225483614, "compression_ratio": 1.6414473684210527, "no_speech_prob": 2.0145063899690285e-05}, {"id": 223, "seek": 94200, "start": 952.0, "end": 955.0, "text": " But I think that everybody's going to have a better experience", "tokens": [583, 286, 519, 300, 2201, 311, 516, 281, 362, 257, 1101, 1752], "temperature": 0.0, "avg_logprob": -0.1506478225483614, "compression_ratio": 1.6414473684210527, "no_speech_prob": 2.0145063899690285e-05}, {"id": 224, "seek": 94200, "start": 955.0, "end": 957.0, "text": " if they can set those expectations.", "tokens": [498, 436, 393, 992, 729, 9843, 13], "temperature": 0.0, "avg_logprob": -0.1506478225483614, "compression_ratio": 1.6414473684210527, "no_speech_prob": 2.0145063899690285e-05}, {"id": 225, "seek": 94200, "start": 957.0, "end": 960.0, "text": " If that's what you're doing, then say, hey, this is it.", "tokens": [759, 300, 311, 437, 291, 434, 884, 11, 550, 584, 11, 4177, 11, 341, 307, 309, 13], "temperature": 0.0, "avg_logprob": -0.1506478225483614, "compression_ratio": 1.6414473684210527, "no_speech_prob": 2.0145063899690285e-05}, {"id": 226, "seek": 94200, "start": 960.0, "end": 963.0, "text": " This project will never have any more commits.", "tokens": [639, 1716, 486, 1128, 362, 604, 544, 48311, 13], "temperature": 0.0, "avg_logprob": -0.1506478225483614, "compression_ratio": 1.6414473684210527, "no_speech_prob": 2.0145063899690285e-05}, {"id": 227, "seek": 94200, "start": 963.0, "end": 966.0, "text": " Don't bother opening issues because I'm not going to look at them.", "tokens": [1468, 380, 8677, 5193, 2663, 570, 286, 478, 406, 516, 281, 574, 412, 552, 13], "temperature": 0.0, "avg_logprob": -0.1506478225483614, "compression_ratio": 1.6414473684210527, "no_speech_prob": 2.0145063899690285e-05}, {"id": 228, "seek": 94200, "start": 966.0, "end": 968.0, "text": " I think you should express that.", "tokens": [286, 519, 291, 820, 5109, 300, 13], "temperature": 0.0, "avg_logprob": -0.1506478225483614, "compression_ratio": 1.6414473684210527, "no_speech_prob": 2.0145063899690285e-05}, {"id": 229, "seek": 94200, "start": 968.0, "end": 971.0, "text": " Which in GitHub you can do through archiving, for instance.", "tokens": [3013, 294, 23331, 291, 393, 360, 807, 3912, 2123, 11, 337, 5197, 13], "temperature": 0.0, "avg_logprob": -0.1506478225483614, "compression_ratio": 1.6414473684210527, "no_speech_prob": 2.0145063899690285e-05}, {"id": 230, "seek": 97100, "start": 971.0, "end": 974.0, "text": " Yeah, right. Absolutely. Yeah.", "tokens": [865, 11, 558, 13, 7021, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.19184478123982748, "compression_ratio": 1.5694444444444444, "no_speech_prob": 6.92192988935858e-05}, {"id": 231, "seek": 97100, "start": 974.0, "end": 977.0, "text": " So I think there's somewhere in between those two extremes.", "tokens": [407, 286, 519, 456, 311, 4079, 294, 1296, 729, 732, 41119, 13], "temperature": 0.0, "avg_logprob": -0.19184478123982748, "compression_ratio": 1.5694444444444444, "no_speech_prob": 6.92192988935858e-05}, {"id": 232, "seek": 97100, "start": 977.0, "end": 981.0, "text": " But either way, I think setting expectations is a good thing.", "tokens": [583, 2139, 636, 11, 286, 519, 3287, 9843, 307, 257, 665, 551, 13], "temperature": 0.0, "avg_logprob": -0.19184478123982748, "compression_ratio": 1.5694444444444444, "no_speech_prob": 6.92192988935858e-05}, {"id": 233, "seek": 97100, "start": 981.0, "end": 983.0, "text": " And I think...", "tokens": [400, 286, 519, 485], "temperature": 0.0, "avg_logprob": -0.19184478123982748, "compression_ratio": 1.5694444444444444, "no_speech_prob": 6.92192988935858e-05}, {"id": 234, "seek": 97100, "start": 983.0, "end": 986.0, "text": " So for me, with my open-source projects,", "tokens": [407, 337, 385, 11, 365, 452, 1269, 12, 41676, 4455, 11], "temperature": 0.0, "avg_logprob": -0.19184478123982748, "compression_ratio": 1.5694444444444444, "no_speech_prob": 6.92192988935858e-05}, {"id": 235, "seek": 97100, "start": 986.0, "end": 989.0, "text": " I often find that things work best", "tokens": [286, 2049, 915, 300, 721, 589, 1151], "temperature": 0.0, "avg_logprob": -0.19184478123982748, "compression_ratio": 1.5694444444444444, "no_speech_prob": 6.92192988935858e-05}, {"id": 236, "seek": 97100, "start": 989.0, "end": 993.0, "text": " when the roles are operating a certain way.", "tokens": [562, 264, 9604, 366, 7447, 257, 1629, 636, 13], "temperature": 0.0, "avg_logprob": -0.19184478123982748, "compression_ratio": 1.5694444444444444, "no_speech_prob": 6.92192988935858e-05}, {"id": 237, "seek": 97100, "start": 993.0, "end": 998.0, "text": " So I don't see my role as an open-source maintainer", "tokens": [407, 286, 500, 380, 536, 452, 3090, 382, 364, 1269, 12, 41676, 6909, 260], "temperature": 0.0, "avg_logprob": -0.19184478123982748, "compression_ratio": 1.5694444444444444, "no_speech_prob": 6.92192988935858e-05}, {"id": 238, "seek": 99800, "start": 998.0, "end": 1002.0, "text": " as being to do everything that everybody wants for the project.", "tokens": [382, 885, 281, 360, 1203, 300, 2201, 2738, 337, 264, 1716, 13], "temperature": 0.0, "avg_logprob": -0.1685106731596447, "compression_ratio": 1.8584474885844748, "no_speech_prob": 1.7501439288025722e-05}, {"id": 239, "seek": 99800, "start": 1002.0, "end": 1005.0, "text": " And in fact, I couldn't if I wanted to.", "tokens": [400, 294, 1186, 11, 286, 2809, 380, 498, 286, 1415, 281, 13], "temperature": 0.0, "avg_logprob": -0.1685106731596447, "compression_ratio": 1.8584474885844748, "no_speech_prob": 1.7501439288025722e-05}, {"id": 240, "seek": 99800, "start": 1005.0, "end": 1008.0, "text": " Because if I did everything that everybody wants for a project,", "tokens": [1436, 498, 286, 630, 1203, 300, 2201, 2738, 337, 257, 1716, 11], "temperature": 0.0, "avg_logprob": -0.1685106731596447, "compression_ratio": 1.8584474885844748, "no_speech_prob": 1.7501439288025722e-05}, {"id": 241, "seek": 99800, "start": 1008.0, "end": 1011.0, "text": " then one person would want this,", "tokens": [550, 472, 954, 576, 528, 341, 11], "temperature": 0.0, "avg_logprob": -0.1685106731596447, "compression_ratio": 1.8584474885844748, "no_speech_prob": 1.7501439288025722e-05}, {"id": 242, "seek": 99800, "start": 1011.0, "end": 1014.0, "text": " and another person would want another contradictory thing.", "tokens": [293, 1071, 954, 576, 528, 1071, 49555, 551, 13], "temperature": 0.0, "avg_logprob": -0.1685106731596447, "compression_ratio": 1.8584474885844748, "no_speech_prob": 1.7501439288025722e-05}, {"id": 243, "seek": 99800, "start": 1014.0, "end": 1016.0, "text": " So it's literally impossible.", "tokens": [407, 309, 311, 3736, 6243, 13], "temperature": 0.0, "avg_logprob": -0.1685106731596447, "compression_ratio": 1.8584474885844748, "no_speech_prob": 1.7501439288025722e-05}, {"id": 244, "seek": 99800, "start": 1016.0, "end": 1020.0, "text": " And that's one thing that I, as a maintainer, really appreciate,", "tokens": [400, 300, 311, 472, 551, 300, 286, 11, 382, 257, 6909, 260, 11, 534, 4449, 11], "temperature": 0.0, "avg_logprob": -0.1685106731596447, "compression_ratio": 1.8584474885844748, "no_speech_prob": 1.7501439288025722e-05}, {"id": 245, "seek": 99800, "start": 1020.0, "end": 1025.0, "text": " is when people recognize that I am, as a maintainer,", "tokens": [307, 562, 561, 5521, 300, 286, 669, 11, 382, 257, 6909, 260, 11], "temperature": 0.0, "avg_logprob": -0.1685106731596447, "compression_ratio": 1.8584474885844748, "no_speech_prob": 1.7501439288025722e-05}, {"id": 246, "seek": 102500, "start": 1025.0, "end": 1031.0, "text": " balancing conflicting desires for a project, conflicting directions.", "tokens": [22495, 43784, 18005, 337, 257, 1716, 11, 43784, 11095, 13], "temperature": 0.0, "avg_logprob": -0.15601340462179744, "compression_ratio": 1.790794979079498, "no_speech_prob": 2.5068000468309037e-05}, {"id": 247, "seek": 102500, "start": 1031.0, "end": 1035.0, "text": " And so while somebody might have an opinion", "tokens": [400, 370, 1339, 2618, 1062, 362, 364, 4800], "temperature": 0.0, "avg_logprob": -0.15601340462179744, "compression_ratio": 1.790794979079498, "no_speech_prob": 2.5068000468309037e-05}, {"id": 248, "seek": 102500, "start": 1035.0, "end": 1037.0, "text": " that a particular direction is good,", "tokens": [300, 257, 1729, 3513, 307, 665, 11], "temperature": 0.0, "avg_logprob": -0.15601340462179744, "compression_ratio": 1.790794979079498, "no_speech_prob": 2.5068000468309037e-05}, {"id": 249, "seek": 102500, "start": 1037.0, "end": 1039.0, "text": " and I want to hear about that opinion,", "tokens": [293, 286, 528, 281, 1568, 466, 300, 4800, 11], "temperature": 0.0, "avg_logprob": -0.15601340462179744, "compression_ratio": 1.790794979079498, "no_speech_prob": 2.5068000468309037e-05}, {"id": 250, "seek": 102500, "start": 1039.0, "end": 1042.0, "text": " I really appreciate it when people recognize", "tokens": [286, 534, 4449, 309, 562, 561, 5521], "temperature": 0.0, "avg_logprob": -0.15601340462179744, "compression_ratio": 1.790794979079498, "no_speech_prob": 2.5068000468309037e-05}, {"id": 251, "seek": 102500, "start": 1042.0, "end": 1045.0, "text": " that it is one opinion that I'm going to need to balance out,", "tokens": [300, 309, 307, 472, 4800, 300, 286, 478, 516, 281, 643, 281, 4772, 484, 11], "temperature": 0.0, "avg_logprob": -0.15601340462179744, "compression_ratio": 1.790794979079498, "no_speech_prob": 2.5068000468309037e-05}, {"id": 252, "seek": 102500, "start": 1045.0, "end": 1048.0, "text": " as somebody leading an open-source project,", "tokens": [382, 2618, 5775, 364, 1269, 12, 41676, 1716, 11], "temperature": 0.0, "avg_logprob": -0.15601340462179744, "compression_ratio": 1.790794979079498, "no_speech_prob": 2.5068000468309037e-05}, {"id": 253, "seek": 102500, "start": 1048.0, "end": 1051.0, "text": " with my opinions and other people's opinions.", "tokens": [365, 452, 11819, 293, 661, 561, 311, 11819, 13], "temperature": 0.0, "avg_logprob": -0.15601340462179744, "compression_ratio": 1.790794979079498, "no_speech_prob": 2.5068000468309037e-05}, {"id": 254, "seek": 102500, "start": 1051.0, "end": 1054.0, "text": " And theirs is just one possible direction.", "tokens": [400, 22760, 307, 445, 472, 1944, 3513, 13], "temperature": 0.0, "avg_logprob": -0.15601340462179744, "compression_ratio": 1.790794979079498, "no_speech_prob": 2.5068000468309037e-05}, {"id": 255, "seek": 105400, "start": 1054.0, "end": 1056.0, "text": " So I really appreciate that sentiment,", "tokens": [407, 286, 534, 4449, 300, 16149, 11], "temperature": 0.0, "avg_logprob": -0.1732919274306879, "compression_ratio": 1.6095238095238096, "no_speech_prob": 3.16859659506008e-05}, {"id": 256, "seek": 105400, "start": 1056.0, "end": 1059.0, "text": " because if people are coming at it in that way", "tokens": [570, 498, 561, 366, 1348, 412, 309, 294, 300, 636], "temperature": 0.0, "avg_logprob": -0.1732919274306879, "compression_ratio": 1.6095238095238096, "no_speech_prob": 3.16859659506008e-05}, {"id": 257, "seek": 105400, "start": 1059.0, "end": 1065.0, "text": " where they expect their preferred direction to be executed on,", "tokens": [689, 436, 2066, 641, 16494, 3513, 281, 312, 17577, 322, 11], "temperature": 0.0, "avg_logprob": -0.1732919274306879, "compression_ratio": 1.6095238095238096, "no_speech_prob": 3.16859659506008e-05}, {"id": 258, "seek": 105400, "start": 1065.0, "end": 1071.0, "text": " then it's giving you a whole other hurdle to have to jump over,", "tokens": [550, 309, 311, 2902, 291, 257, 1379, 661, 47423, 281, 362, 281, 3012, 670, 11], "temperature": 0.0, "avg_logprob": -0.1732919274306879, "compression_ratio": 1.6095238095238096, "no_speech_prob": 3.16859659506008e-05}, {"id": 259, "seek": 105400, "start": 1071.0, "end": 1077.0, "text": " where now not only do you have to potentially work on something,", "tokens": [689, 586, 406, 787, 360, 291, 362, 281, 7263, 589, 322, 746, 11], "temperature": 0.0, "avg_logprob": -0.1732919274306879, "compression_ratio": 1.6095238095238096, "no_speech_prob": 3.16859659506008e-05}, {"id": 260, "seek": 105400, "start": 1077.0, "end": 1082.0, "text": " but you need to do all this extra effort to communicate that", "tokens": [457, 291, 643, 281, 360, 439, 341, 2857, 4630, 281, 7890, 300], "temperature": 0.0, "avg_logprob": -0.1732919274306879, "compression_ratio": 1.6095238095238096, "no_speech_prob": 3.16859659506008e-05}, {"id": 261, "seek": 108200, "start": 1082.0, "end": 1084.0, "text": " and set those expectations.", "tokens": [293, 992, 729, 9843, 13], "temperature": 0.0, "avg_logprob": -0.14608336658012577, "compression_ratio": 1.915966386554622, "no_speech_prob": 0.00014879558875691146}, {"id": 262, "seek": 108200, "start": 1084.0, "end": 1088.0, "text": " So when people make it clear that they are not expecting you", "tokens": [407, 562, 561, 652, 309, 1850, 300, 436, 366, 406, 9650, 291], "temperature": 0.0, "avg_logprob": -0.14608336658012577, "compression_ratio": 1.915966386554622, "no_speech_prob": 0.00014879558875691146}, {"id": 263, "seek": 108200, "start": 1088.0, "end": 1090.0, "text": " to do whatever they're asking for,", "tokens": [281, 360, 2035, 436, 434, 3365, 337, 11], "temperature": 0.0, "avg_logprob": -0.14608336658012577, "compression_ratio": 1.915966386554622, "no_speech_prob": 0.00014879558875691146}, {"id": 264, "seek": 108200, "start": 1090.0, "end": 1093.0, "text": " it just makes it less work for the maintainer.", "tokens": [309, 445, 1669, 309, 1570, 589, 337, 264, 6909, 260, 13], "temperature": 0.0, "avg_logprob": -0.14608336658012577, "compression_ratio": 1.915966386554622, "no_speech_prob": 0.00014879558875691146}, {"id": 265, "seek": 108200, "start": 1093.0, "end": 1096.0, "text": " So that's one thing you can do as a contributor,", "tokens": [407, 300, 311, 472, 551, 291, 393, 360, 382, 257, 42859, 11], "temperature": 0.0, "avg_logprob": -0.14608336658012577, "compression_ratio": 1.915966386554622, "no_speech_prob": 0.00014879558875691146}, {"id": 266, "seek": 108200, "start": 1096.0, "end": 1098.0, "text": " is make it clear, like,", "tokens": [307, 652, 309, 1850, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.14608336658012577, "compression_ratio": 1.915966386554622, "no_speech_prob": 0.00014879558875691146}, {"id": 267, "seek": 108200, "start": 1098.0, "end": 1102.0, "text": " I'm just making sure these options are there for your consideration.", "tokens": [286, 478, 445, 1455, 988, 613, 3956, 366, 456, 337, 428, 12381, 13], "temperature": 0.0, "avg_logprob": -0.14608336658012577, "compression_ratio": 1.915966386554622, "no_speech_prob": 0.00014879558875691146}, {"id": 268, "seek": 108200, "start": 1102.0, "end": 1105.0, "text": " I don't expect you to do this free labor.", "tokens": [286, 500, 380, 2066, 291, 281, 360, 341, 1737, 5938, 13], "temperature": 0.0, "avg_logprob": -0.14608336658012577, "compression_ratio": 1.915966386554622, "no_speech_prob": 0.00014879558875691146}, {"id": 269, "seek": 108200, "start": 1105.0, "end": 1108.0, "text": " I don't expect you to choose my direction.", "tokens": [286, 500, 380, 2066, 291, 281, 2826, 452, 3513, 13], "temperature": 0.0, "avg_logprob": -0.14608336658012577, "compression_ratio": 1.915966386554622, "no_speech_prob": 0.00014879558875691146}, {"id": 270, "seek": 108200, "start": 1108.0, "end": 1111.0, "text": " But I wanted to put this out there for your consideration.", "tokens": [583, 286, 1415, 281, 829, 341, 484, 456, 337, 428, 12381, 13], "temperature": 0.0, "avg_logprob": -0.14608336658012577, "compression_ratio": 1.915966386554622, "no_speech_prob": 0.00014879558875691146}, {"id": 271, "seek": 111100, "start": 1111.0, "end": 1115.0, "text": " So, Lint, I find it really nice when people are thinking about it", "tokens": [407, 11, 441, 686, 11, 286, 915, 309, 534, 1481, 562, 561, 366, 1953, 466, 309], "temperature": 0.0, "avg_logprob": -0.19493533883775985, "compression_ratio": 1.7302904564315353, "no_speech_prob": 8.74911856953986e-05}, {"id": 272, "seek": 111100, "start": 1115.0, "end": 1119.0, "text": " as not just, like, what should you do as a maintainer,", "tokens": [382, 406, 445, 11, 411, 11, 437, 820, 291, 360, 382, 257, 6909, 260, 11], "temperature": 0.0, "avg_logprob": -0.19493533883775985, "compression_ratio": 1.7302904564315353, "no_speech_prob": 8.74911856953986e-05}, {"id": 273, "seek": 111100, "start": 1119.0, "end": 1123.0, "text": " but how do we make this project operate smoothly?", "tokens": [457, 577, 360, 321, 652, 341, 1716, 9651, 19565, 30], "temperature": 0.0, "avg_logprob": -0.19493533883775985, "compression_ratio": 1.7302904564315353, "no_speech_prob": 8.74911856953986e-05}, {"id": 274, "seek": 111100, "start": 1123.0, "end": 1125.0, "text": " And how do we make sure that this project", "tokens": [400, 577, 360, 321, 652, 988, 300, 341, 1716], "temperature": 0.0, "avg_logprob": -0.19493533883775985, "compression_ratio": 1.7302904564315353, "no_speech_prob": 8.74911856953986e-05}, {"id": 275, "seek": 111100, "start": 1125.0, "end": 1129.0, "text": " is kind of having all these great ideas presented", "tokens": [307, 733, 295, 1419, 439, 613, 869, 3487, 8212], "temperature": 0.0, "avg_logprob": -0.19493533883775985, "compression_ratio": 1.7302904564315353, "no_speech_prob": 8.74911856953986e-05}, {"id": 276, "seek": 111100, "start": 1129.0, "end": 1131.0, "text": " so they can be considered?", "tokens": [370, 436, 393, 312, 4888, 30], "temperature": 0.0, "avg_logprob": -0.19493533883775985, "compression_ratio": 1.7302904564315353, "no_speech_prob": 8.74911856953986e-05}, {"id": 277, "seek": 111100, "start": 1131.0, "end": 1133.0, "text": " I feel like that touches on something", "tokens": [286, 841, 411, 300, 17431, 322, 746], "temperature": 0.0, "avg_logprob": -0.19493533883775985, "compression_ratio": 1.7302904564315353, "no_speech_prob": 8.74911856953986e-05}, {"id": 278, "seek": 111100, "start": 1133.0, "end": 1136.0, "text": " that I quite enjoy with my projects,", "tokens": [300, 286, 1596, 2103, 365, 452, 4455, 11], "temperature": 0.0, "avg_logprob": -0.19493533883775985, "compression_ratio": 1.7302904564315353, "no_speech_prob": 8.74911856953986e-05}, {"id": 279, "seek": 111100, "start": 1136.0, "end": 1138.0, "text": " or at least the feeling that I get with my projects.", "tokens": [420, 412, 1935, 264, 2633, 300, 286, 483, 365, 452, 4455, 13], "temperature": 0.0, "avg_logprob": -0.19493533883775985, "compression_ratio": 1.7302904564315353, "no_speech_prob": 8.74911856953986e-05}, {"id": 280, "seek": 113800, "start": 1138.0, "end": 1142.0, "text": " I feel like everyone who interacts with mine,", "tokens": [286, 841, 411, 1518, 567, 43582, 365, 3892, 11], "temperature": 0.0, "avg_logprob": -0.16591799837871662, "compression_ratio": 1.6465116279069767, "no_speech_prob": 8.663228072691709e-06}, {"id": 281, "seek": 113800, "start": 1142.0, "end": 1148.0, "text": " they all want, just like me, the best from the project.", "tokens": [436, 439, 528, 11, 445, 411, 385, 11, 264, 1151, 490, 264, 1716, 13], "temperature": 0.0, "avg_logprob": -0.16591799837871662, "compression_ratio": 1.6465116279069767, "no_speech_prob": 8.663228072691709e-06}, {"id": 282, "seek": 113800, "start": 1148.0, "end": 1152.0, "text": " And we all know that that is made of trade-offs.", "tokens": [400, 321, 439, 458, 300, 300, 307, 1027, 295, 4923, 12, 19231, 13], "temperature": 0.0, "avg_logprob": -0.16591799837871662, "compression_ratio": 1.6465116279069767, "no_speech_prob": 8.663228072691709e-06}, {"id": 283, "seek": 113800, "start": 1152.0, "end": 1154.0, "text": " So some people might say,", "tokens": [407, 512, 561, 1062, 584, 11], "temperature": 0.0, "avg_logprob": -0.16591799837871662, "compression_ratio": 1.6465116279069767, "no_speech_prob": 8.663228072691709e-06}, {"id": 284, "seek": 113800, "start": 1154.0, "end": 1156.0, "text": " I would like to have this,", "tokens": [286, 576, 411, 281, 362, 341, 11], "temperature": 0.0, "avg_logprob": -0.16591799837871662, "compression_ratio": 1.6465116279069767, "no_speech_prob": 8.663228072691709e-06}, {"id": 285, "seek": 113800, "start": 1156.0, "end": 1160.0, "text": " and then I respond, or other people respond with,", "tokens": [293, 550, 286, 4196, 11, 420, 661, 561, 4196, 365, 11], "temperature": 0.0, "avg_logprob": -0.16591799837871662, "compression_ratio": 1.6465116279069767, "no_speech_prob": 8.663228072691709e-06}, {"id": 286, "seek": 113800, "start": 1160.0, "end": 1164.0, "text": " well, if that is true, or if you want this,", "tokens": [731, 11, 498, 300, 307, 2074, 11, 420, 498, 291, 528, 341, 11], "temperature": 0.0, "avg_logprob": -0.16591799837871662, "compression_ratio": 1.6465116279069767, "no_speech_prob": 8.663228072691709e-06}, {"id": 287, "seek": 113800, "start": 1164.0, "end": 1167.0, "text": " then you're going to have a problem with this situation,", "tokens": [550, 291, 434, 516, 281, 362, 257, 1154, 365, 341, 2590, 11], "temperature": 0.0, "avg_logprob": -0.16591799837871662, "compression_ratio": 1.6465116279069767, "no_speech_prob": 8.663228072691709e-06}, {"id": 288, "seek": 116700, "start": 1167.0, "end": 1170.0, "text": " you're going to have this to handle as well.", "tokens": [291, 434, 516, 281, 362, 341, 281, 4813, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.16877501586387897, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00012143669300712645}, {"id": 289, "seek": 116700, "start": 1170.0, "end": 1173.0, "text": " Plenty of trade-offs to think about", "tokens": [2149, 4179, 295, 4923, 12, 19231, 281, 519, 466], "temperature": 0.0, "avg_logprob": -0.16877501586387897, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00012143669300712645}, {"id": 290, "seek": 116700, "start": 1173.0, "end": 1176.0, "text": " and to figure out the best solution", "tokens": [293, 281, 2573, 484, 264, 1151, 3827], "temperature": 0.0, "avg_logprob": -0.16877501586387897, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00012143669300712645}, {"id": 291, "seek": 116700, "start": 1176.0, "end": 1179.0, "text": " that works for the most people,", "tokens": [300, 1985, 337, 264, 881, 561, 11], "temperature": 0.0, "avg_logprob": -0.16877501586387897, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00012143669300712645}, {"id": 292, "seek": 116700, "start": 1179.0, "end": 1182.0, "text": " or a custom way that works for you", "tokens": [420, 257, 2375, 636, 300, 1985, 337, 291], "temperature": 0.0, "avg_logprob": -0.16877501586387897, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00012143669300712645}, {"id": 293, "seek": 116700, "start": 1182.0, "end": 1184.0, "text": " but will not work for others.", "tokens": [457, 486, 406, 589, 337, 2357, 13], "temperature": 0.0, "avg_logprob": -0.16877501586387897, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00012143669300712645}, {"id": 294, "seek": 116700, "start": 1184.0, "end": 1186.0, "text": " That might be a solution as well.", "tokens": [663, 1062, 312, 257, 3827, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.16877501586387897, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00012143669300712645}, {"id": 295, "seek": 116700, "start": 1186.0, "end": 1190.0, "text": " Yeah, I just feel like people have this understanding,", "tokens": [865, 11, 286, 445, 841, 411, 561, 362, 341, 3701, 11], "temperature": 0.0, "avg_logprob": -0.16877501586387897, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00012143669300712645}, {"id": 296, "seek": 116700, "start": 1190.0, "end": 1191.0, "text": " which I love.", "tokens": [597, 286, 959, 13], "temperature": 0.0, "avg_logprob": -0.16877501586387897, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00012143669300712645}, {"id": 297, "seek": 116700, "start": 1191.0, "end": 1194.0, "text": " If you have interacted with me on ElmReview", "tokens": [759, 291, 362, 49621, 365, 385, 322, 2699, 76, 8524, 1759], "temperature": 0.0, "avg_logprob": -0.16877501586387897, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00012143669300712645}, {"id": 298, "seek": 116700, "start": 1194.0, "end": 1196.0, "text": " in any way, shape, or form,", "tokens": [294, 604, 636, 11, 3909, 11, 420, 1254, 11], "temperature": 0.0, "avg_logprob": -0.16877501586387897, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.00012143669300712645}, {"id": 299, "seek": 119600, "start": 1196.0, "end": 1198.0, "text": " you're a part of this.", "tokens": [291, 434, 257, 644, 295, 341, 13], "temperature": 0.0, "avg_logprob": -0.20710350218273343, "compression_ratio": 1.4619289340101522, "no_speech_prob": 7.718311826465651e-05}, {"id": 300, "seek": 119600, "start": 1198.0, "end": 1201.0, "text": " And I really appreciate it.", "tokens": [400, 286, 534, 4449, 309, 13], "temperature": 0.0, "avg_logprob": -0.20710350218273343, "compression_ratio": 1.4619289340101522, "no_speech_prob": 7.718311826465651e-05}, {"id": 301, "seek": 119600, "start": 1201.0, "end": 1204.0, "text": " People are thinking of what is best.", "tokens": [3432, 366, 1953, 295, 437, 307, 1151, 13], "temperature": 0.0, "avg_logprob": -0.20710350218273343, "compression_ratio": 1.4619289340101522, "no_speech_prob": 7.718311826465651e-05}, {"id": 302, "seek": 119600, "start": 1204.0, "end": 1209.0, "text": " And me, myself, even though I'm the maintainer,", "tokens": [400, 385, 11, 2059, 11, 754, 1673, 286, 478, 264, 6909, 260, 11], "temperature": 0.0, "avg_logprob": -0.20710350218273343, "compression_ratio": 1.4619289340101522, "no_speech_prob": 7.718311826465651e-05}, {"id": 303, "seek": 119600, "start": 1209.0, "end": 1212.0, "text": " I am just someone with one opinion.", "tokens": [286, 669, 445, 1580, 365, 472, 4800, 13], "temperature": 0.0, "avg_logprob": -0.20710350218273343, "compression_ratio": 1.4619289340101522, "no_speech_prob": 7.718311826465651e-05}, {"id": 304, "seek": 119600, "start": 1212.0, "end": 1215.0, "text": " In practice, I will probably make the end decision", "tokens": [682, 3124, 11, 286, 486, 1391, 652, 264, 917, 3537], "temperature": 0.0, "avg_logprob": -0.20710350218273343, "compression_ratio": 1.4619289340101522, "no_speech_prob": 7.718311826465651e-05}, {"id": 305, "seek": 119600, "start": 1215.0, "end": 1216.0, "text": " because they're my projects,", "tokens": [570, 436, 434, 452, 4455, 11], "temperature": 0.0, "avg_logprob": -0.20710350218273343, "compression_ratio": 1.4619289340101522, "no_speech_prob": 7.718311826465651e-05}, {"id": 306, "seek": 119600, "start": 1216.0, "end": 1219.0, "text": " but people are allowed to fork them.", "tokens": [457, 561, 366, 4350, 281, 17716, 552, 13], "temperature": 0.0, "avg_logprob": -0.20710350218273343, "compression_ratio": 1.4619289340101522, "no_speech_prob": 7.718311826465651e-05}, {"id": 307, "seek": 121900, "start": 1219.0, "end": 1229.0, "text": " But I am successful at convincing people of my opinions", "tokens": [583, 286, 669, 4406, 412, 24823, 561, 295, 452, 11819], "temperature": 0.0, "avg_logprob": -0.21322470975209432, "compression_ratio": 1.6130653266331658, "no_speech_prob": 8.735743904253468e-05}, {"id": 308, "seek": 121900, "start": 1229.0, "end": 1232.0, "text": " that they're not totally wrong.", "tokens": [300, 436, 434, 406, 3879, 2085, 13], "temperature": 0.0, "avg_logprob": -0.21322470975209432, "compression_ratio": 1.6130653266331658, "no_speech_prob": 8.735743904253468e-05}, {"id": 309, "seek": 121900, "start": 1232.0, "end": 1235.0, "text": " And sometimes I'm just convinced that that can also happen.", "tokens": [400, 2171, 286, 478, 445, 12561, 300, 300, 393, 611, 1051, 13], "temperature": 0.0, "avg_logprob": -0.21322470975209432, "compression_ratio": 1.6130653266331658, "no_speech_prob": 8.735743904253468e-05}, {"id": 310, "seek": 121900, "start": 1235.0, "end": 1238.0, "text": " And I'm really happy when I get convinced as well.", "tokens": [400, 286, 478, 534, 2055, 562, 286, 483, 12561, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.21322470975209432, "compression_ratio": 1.6130653266331658, "no_speech_prob": 8.735743904253468e-05}, {"id": 311, "seek": 121900, "start": 1238.0, "end": 1239.0, "text": " So that feels good.", "tokens": [407, 300, 3417, 665, 13], "temperature": 0.0, "avg_logprob": -0.21322470975209432, "compression_ratio": 1.6130653266331658, "no_speech_prob": 8.735743904253468e-05}, {"id": 312, "seek": 121900, "start": 1239.0, "end": 1242.0, "text": " The expectations I have with people", "tokens": [440, 9843, 286, 362, 365, 561], "temperature": 0.0, "avg_logprob": -0.21322470975209432, "compression_ratio": 1.6130653266331658, "no_speech_prob": 8.735743904253468e-05}, {"id": 313, "seek": 121900, "start": 1242.0, "end": 1243.0, "text": " who interact with my projects", "tokens": [567, 4648, 365, 452, 4455], "temperature": 0.0, "avg_logprob": -0.21322470975209432, "compression_ratio": 1.6130653266331658, "no_speech_prob": 8.735743904253468e-05}, {"id": 314, "seek": 121900, "start": 1243.0, "end": 1246.0, "text": " is that we will have a conversation.", "tokens": [307, 300, 321, 486, 362, 257, 3761, 13], "temperature": 0.0, "avg_logprob": -0.21322470975209432, "compression_ratio": 1.6130653266331658, "no_speech_prob": 8.735743904253468e-05}, {"id": 315, "seek": 124600, "start": 1246.0, "end": 1250.0, "text": " You are submitting an idea, a bug report,", "tokens": [509, 366, 31836, 364, 1558, 11, 257, 7426, 2275, 11], "temperature": 0.0, "avg_logprob": -0.20669434802366957, "compression_ratio": 1.5645933014354068, "no_speech_prob": 2.0451925593079068e-05}, {"id": 316, "seek": 124600, "start": 1250.0, "end": 1254.0, "text": " and fixing or adding that feature", "tokens": [293, 19442, 420, 5127, 300, 4111], "temperature": 0.0, "avg_logprob": -0.20669434802366957, "compression_ratio": 1.5645933014354068, "no_speech_prob": 2.0451925593079068e-05}, {"id": 317, "seek": 124600, "start": 1254.0, "end": 1256.0, "text": " is not necessarily going to be simple.", "tokens": [307, 406, 4725, 516, 281, 312, 2199, 13], "temperature": 0.0, "avg_logprob": -0.20669434802366957, "compression_ratio": 1.5645933014354068, "no_speech_prob": 2.0451925593079068e-05}, {"id": 318, "seek": 124600, "start": 1256.0, "end": 1258.0, "text": " So let's talk it out.", "tokens": [407, 718, 311, 751, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.20669434802366957, "compression_ratio": 1.5645933014354068, "no_speech_prob": 2.0451925593079068e-05}, {"id": 319, "seek": 124600, "start": 1258.0, "end": 1260.0, "text": " Let's figure out a solution.", "tokens": [961, 311, 2573, 484, 257, 3827, 13], "temperature": 0.0, "avg_logprob": -0.20669434802366957, "compression_ratio": 1.5645933014354068, "no_speech_prob": 2.0451925593079068e-05}, {"id": 320, "seek": 124600, "start": 1260.0, "end": 1262.0, "text": " And let's implement it.", "tokens": [400, 718, 311, 4445, 309, 13], "temperature": 0.0, "avg_logprob": -0.20669434802366957, "compression_ratio": 1.5645933014354068, "no_speech_prob": 2.0451925593079068e-05}, {"id": 321, "seek": 124600, "start": 1262.0, "end": 1267.0, "text": " And that implementation part might be me by me, you,", "tokens": [400, 300, 11420, 644, 1062, 312, 385, 538, 385, 11, 291, 11], "temperature": 0.0, "avg_logprob": -0.20669434802366957, "compression_ratio": 1.5645933014354068, "no_speech_prob": 2.0451925593079068e-05}, {"id": 322, "seek": 124600, "start": 1267.0, "end": 1269.0, "text": " might be in a few years from now.", "tokens": [1062, 312, 294, 257, 1326, 924, 490, 586, 13], "temperature": 0.0, "avg_logprob": -0.20669434802366957, "compression_ratio": 1.5645933014354068, "no_speech_prob": 2.0451925593079068e-05}, {"id": 323, "seek": 124600, "start": 1269.0, "end": 1271.0, "text": " I am spread thin,", "tokens": [286, 669, 3974, 5862, 11], "temperature": 0.0, "avg_logprob": -0.20669434802366957, "compression_ratio": 1.5645933014354068, "no_speech_prob": 2.0451925593079068e-05}, {"id": 324, "seek": 124600, "start": 1271.0, "end": 1275.0, "text": " and I'm not doing this full-time", "tokens": [293, 286, 478, 406, 884, 341, 1577, 12, 3766], "temperature": 0.0, "avg_logprob": -0.20669434802366957, "compression_ratio": 1.5645933014354068, "no_speech_prob": 2.0451925593079068e-05}, {"id": 325, "seek": 127500, "start": 1275.0, "end": 1280.0, "text": " because Meta is not doing Elm and is not paying me.", "tokens": [570, 6377, 64, 307, 406, 884, 2699, 76, 293, 307, 406, 6229, 385, 13], "temperature": 0.0, "avg_logprob": -0.18843036227756077, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.000569381401874125}, {"id": 326, "seek": 127500, "start": 1280.0, "end": 1283.0, "text": " So I'm happy that I'm getting these interactions.", "tokens": [407, 286, 478, 2055, 300, 286, 478, 1242, 613, 13280, 13], "temperature": 0.0, "avg_logprob": -0.18843036227756077, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.000569381401874125}, {"id": 327, "seek": 127500, "start": 1283.0, "end": 1286.0, "text": " And that's why I feel like I have very good interactions", "tokens": [400, 300, 311, 983, 286, 841, 411, 286, 362, 588, 665, 13280], "temperature": 0.0, "avg_logprob": -0.18843036227756077, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.000569381401874125}, {"id": 328, "seek": 127500, "start": 1286.0, "end": 1289.0, "text": " with the Elm community, the open source.", "tokens": [365, 264, 2699, 76, 1768, 11, 264, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.18843036227756077, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.000569381401874125}, {"id": 329, "seek": 127500, "start": 1289.0, "end": 1292.0, "text": " Yeah, that resonates with me a lot.", "tokens": [865, 11, 300, 41051, 365, 385, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.18843036227756077, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.000569381401874125}, {"id": 330, "seek": 127500, "start": 1292.0, "end": 1296.0, "text": " So, you know, like the recognizing trade-offs,", "tokens": [407, 11, 291, 458, 11, 411, 264, 18538, 4923, 12, 19231, 11], "temperature": 0.0, "avg_logprob": -0.18843036227756077, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.000569381401874125}, {"id": 331, "seek": 127500, "start": 1296.0, "end": 1298.0, "text": " recognizing that the timeline,", "tokens": [18538, 300, 264, 12933, 11], "temperature": 0.0, "avg_logprob": -0.18843036227756077, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.000569381401874125}, {"id": 332, "seek": 127500, "start": 1298.0, "end": 1301.0, "text": " like users of an open source project", "tokens": [411, 5022, 295, 364, 1269, 4009, 1716], "temperature": 0.0, "avg_logprob": -0.18843036227756077, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.000569381401874125}, {"id": 333, "seek": 127500, "start": 1301.0, "end": 1303.0, "text": " don't get to dictate the timeline.", "tokens": [500, 380, 483, 281, 36071, 264, 12933, 13], "temperature": 0.0, "avg_logprob": -0.18843036227756077, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.000569381401874125}, {"id": 334, "seek": 130300, "start": 1303.0, "end": 1305.0, "text": " That's not the role of the user.", "tokens": [663, 311, 406, 264, 3090, 295, 264, 4195, 13], "temperature": 0.0, "avg_logprob": -0.17359365042993577, "compression_ratio": 1.7624521072796935, "no_speech_prob": 2.6686228011385538e-05}, {"id": 335, "seek": 130300, "start": 1305.0, "end": 1308.0, "text": " And they also don't get to dictate the agenda", "tokens": [400, 436, 611, 500, 380, 483, 281, 36071, 264, 9829], "temperature": 0.0, "avg_logprob": -0.17359365042993577, "compression_ratio": 1.7624521072796935, "no_speech_prob": 2.6686228011385538e-05}, {"id": 336, "seek": 130300, "start": 1308.0, "end": 1311.0, "text": " because, as you said, like they can present trade-offs,", "tokens": [570, 11, 382, 291, 848, 11, 411, 436, 393, 1974, 4923, 12, 19231, 11], "temperature": 0.0, "avg_logprob": -0.17359365042993577, "compression_ratio": 1.7624521072796935, "no_speech_prob": 2.6686228011385538e-05}, {"id": 337, "seek": 130300, "start": 1311.0, "end": 1315.0, "text": " but ultimately, like the person leading an open source project,", "tokens": [457, 6284, 11, 411, 264, 954, 5775, 364, 1269, 4009, 1716, 11], "temperature": 0.0, "avg_logprob": -0.17359365042993577, "compression_ratio": 1.7624521072796935, "no_speech_prob": 2.6686228011385538e-05}, {"id": 338, "seek": 130300, "start": 1315.0, "end": 1317.0, "text": " they're going to come to some conclusions", "tokens": [436, 434, 516, 281, 808, 281, 512, 22865], "temperature": 0.0, "avg_logprob": -0.17359365042993577, "compression_ratio": 1.7624521072796935, "no_speech_prob": 2.6686228011385538e-05}, {"id": 339, "seek": 130300, "start": 1317.0, "end": 1319.0, "text": " that might be different than somebody else.", "tokens": [300, 1062, 312, 819, 813, 2618, 1646, 13], "temperature": 0.0, "avg_logprob": -0.17359365042993577, "compression_ratio": 1.7624521072796935, "no_speech_prob": 2.6686228011385538e-05}, {"id": 340, "seek": 130300, "start": 1319.0, "end": 1321.0, "text": " Many times there are different ways", "tokens": [5126, 1413, 456, 366, 819, 2098], "temperature": 0.0, "avg_logprob": -0.17359365042993577, "compression_ratio": 1.7624521072796935, "no_speech_prob": 2.6686228011385538e-05}, {"id": 341, "seek": 130300, "start": 1321.0, "end": 1323.0, "text": " to approach an open source project.", "tokens": [281, 3109, 364, 1269, 4009, 1716, 13], "temperature": 0.0, "avg_logprob": -0.17359365042993577, "compression_ratio": 1.7624521072796935, "no_speech_prob": 2.6686228011385538e-05}, {"id": 342, "seek": 130300, "start": 1323.0, "end": 1326.0, "text": " And I think open source projects work best", "tokens": [400, 286, 519, 1269, 4009, 4455, 589, 1151], "temperature": 0.0, "avg_logprob": -0.17359365042993577, "compression_ratio": 1.7624521072796935, "no_speech_prob": 2.6686228011385538e-05}, {"id": 343, "seek": 130300, "start": 1326.0, "end": 1332.0, "text": " when they recognize that, to me, a project is a perspective.", "tokens": [562, 436, 5521, 300, 11, 281, 385, 11, 257, 1716, 307, 257, 4585, 13], "temperature": 0.0, "avg_logprob": -0.17359365042993577, "compression_ratio": 1.7624521072796935, "no_speech_prob": 2.6686228011385538e-05}, {"id": 344, "seek": 133200, "start": 1332.0, "end": 1336.0, "text": " You can't try to incorporate every perspective into it", "tokens": [509, 393, 380, 853, 281, 16091, 633, 4585, 666, 309], "temperature": 0.0, "avg_logprob": -0.15056833231224204, "compression_ratio": 1.7448559670781894, "no_speech_prob": 3.480444138403982e-05}, {"id": 345, "seek": 133200, "start": 1336.0, "end": 1338.0, "text": " because that's just watering it down.", "tokens": [570, 300, 311, 445, 33028, 309, 760, 13], "temperature": 0.0, "avg_logprob": -0.15056833231224204, "compression_ratio": 1.7448559670781894, "no_speech_prob": 3.480444138403982e-05}, {"id": 346, "seek": 133200, "start": 1338.0, "end": 1341.0, "text": " A project is choosing a perspective", "tokens": [316, 1716, 307, 10875, 257, 4585], "temperature": 0.0, "avg_logprob": -0.15056833231224204, "compression_ratio": 1.7448559670781894, "no_speech_prob": 3.480444138403982e-05}, {"id": 347, "seek": 133200, "start": 1341.0, "end": 1343.0, "text": " and committing to that.", "tokens": [293, 26659, 281, 300, 13], "temperature": 0.0, "avg_logprob": -0.15056833231224204, "compression_ratio": 1.7448559670781894, "no_speech_prob": 3.480444138403982e-05}, {"id": 348, "seek": 133200, "start": 1343.0, "end": 1345.0, "text": " And I think they work best when they do that.", "tokens": [400, 286, 519, 436, 589, 1151, 562, 436, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.15056833231224204, "compression_ratio": 1.7448559670781894, "no_speech_prob": 3.480444138403982e-05}, {"id": 349, "seek": 133200, "start": 1345.0, "end": 1348.0, "text": " And I think open source projects work best", "tokens": [400, 286, 519, 1269, 4009, 4455, 589, 1151], "temperature": 0.0, "avg_logprob": -0.15056833231224204, "compression_ratio": 1.7448559670781894, "no_speech_prob": 3.480444138403982e-05}, {"id": 350, "seek": 133200, "start": 1348.0, "end": 1351.0, "text": " when the communication also recognizes that.", "tokens": [562, 264, 6101, 611, 26564, 300, 13], "temperature": 0.0, "avg_logprob": -0.15056833231224204, "compression_ratio": 1.7448559670781894, "no_speech_prob": 3.480444138403982e-05}, {"id": 351, "seek": 133200, "start": 1351.0, "end": 1355.0, "text": " When you say, this project goes with this approach.", "tokens": [1133, 291, 584, 11, 341, 1716, 1709, 365, 341, 3109, 13], "temperature": 0.0, "avg_logprob": -0.15056833231224204, "compression_ratio": 1.7448559670781894, "no_speech_prob": 3.480444138403982e-05}, {"id": 352, "seek": 133200, "start": 1355.0, "end": 1357.0, "text": " The approach you're talking about here", "tokens": [440, 3109, 291, 434, 1417, 466, 510], "temperature": 0.0, "avg_logprob": -0.15056833231224204, "compression_ratio": 1.7448559670781894, "no_speech_prob": 3.480444138403982e-05}, {"id": 353, "seek": 133200, "start": 1357.0, "end": 1361.0, "text": " sounds like a totally valid set of trade-offs,", "tokens": [3263, 411, 257, 3879, 7363, 992, 295, 4923, 12, 19231, 11], "temperature": 0.0, "avg_logprob": -0.15056833231224204, "compression_ratio": 1.7448559670781894, "no_speech_prob": 3.480444138403982e-05}, {"id": 354, "seek": 136100, "start": 1361.0, "end": 1363.0, "text": " but here are the core values that", "tokens": [457, 510, 366, 264, 4965, 4190, 300], "temperature": 0.0, "avg_logprob": -0.16784080299171242, "compression_ratio": 1.7387755102040816, "no_speech_prob": 6.204021337907761e-05}, {"id": 355, "seek": 136100, "start": 1363.0, "end": 1365.0, "text": " are laid out for this project.", "tokens": [366, 9897, 484, 337, 341, 1716, 13], "temperature": 0.0, "avg_logprob": -0.16784080299171242, "compression_ratio": 1.7387755102040816, "no_speech_prob": 6.204021337907761e-05}, {"id": 356, "seek": 136100, "start": 1365.0, "end": 1367.0, "text": " Here are some examples that show that.", "tokens": [1692, 366, 512, 5110, 300, 855, 300, 13], "temperature": 0.0, "avg_logprob": -0.16784080299171242, "compression_ratio": 1.7387755102040816, "no_speech_prob": 6.204021337907761e-05}, {"id": 357, "seek": 136100, "start": 1367.0, "end": 1371.0, "text": " Here's ideally where some of these values are written down.", "tokens": [1692, 311, 22915, 689, 512, 295, 613, 4190, 366, 3720, 760, 13], "temperature": 0.0, "avg_logprob": -0.16784080299171242, "compression_ratio": 1.7387755102040816, "no_speech_prob": 6.204021337907761e-05}, {"id": 358, "seek": 136100, "start": 1371.0, "end": 1373.0, "text": " Or let's write them down now because I'm", "tokens": [1610, 718, 311, 2464, 552, 760, 586, 570, 286, 478], "temperature": 0.0, "avg_logprob": -0.16784080299171242, "compression_ratio": 1.7387755102040816, "no_speech_prob": 6.204021337907761e-05}, {"id": 359, "seek": 136100, "start": 1373.0, "end": 1375.0, "text": " realizing that we have these values for this project", "tokens": [16734, 300, 321, 362, 613, 4190, 337, 341, 1716], "temperature": 0.0, "avg_logprob": -0.16784080299171242, "compression_ratio": 1.7387755102040816, "no_speech_prob": 6.204021337907761e-05}, {"id": 360, "seek": 136100, "start": 1375.0, "end": 1378.0, "text": " now that this might not be aligned with.", "tokens": [586, 300, 341, 1062, 406, 312, 17962, 365, 13], "temperature": 0.0, "avg_logprob": -0.16784080299171242, "compression_ratio": 1.7387755102040816, "no_speech_prob": 6.204021337907761e-05}, {"id": 361, "seek": 136100, "start": 1378.0, "end": 1384.0, "text": " And I think the more somebody depends on a project,", "tokens": [400, 286, 519, 264, 544, 2618, 5946, 322, 257, 1716, 11], "temperature": 0.0, "avg_logprob": -0.16784080299171242, "compression_ratio": 1.7387755102040816, "no_speech_prob": 6.204021337907761e-05}, {"id": 362, "seek": 136100, "start": 1384.0, "end": 1386.0, "text": " the higher the stakes are.", "tokens": [264, 2946, 264, 28429, 366, 13], "temperature": 0.0, "avg_logprob": -0.16784080299171242, "compression_ratio": 1.7387755102040816, "no_speech_prob": 6.204021337907761e-05}, {"id": 363, "seek": 136100, "start": 1386.0, "end": 1390.0, "text": " So if you make it a little extras helper package", "tokens": [407, 498, 291, 652, 309, 257, 707, 40961, 36133, 7372], "temperature": 0.0, "avg_logprob": -0.16784080299171242, "compression_ratio": 1.7387755102040816, "no_speech_prob": 6.204021337907761e-05}, {"id": 364, "seek": 139000, "start": 1390.0, "end": 1393.0, "text": " in the Elm ecosystem, if somebody", "tokens": [294, 264, 2699, 76, 11311, 11, 498, 2618], "temperature": 0.0, "avg_logprob": -0.1471789488151892, "compression_ratio": 1.658703071672355, "no_speech_prob": 3.169107003486715e-05}, {"id": 365, "seek": 139000, "start": 1393.0, "end": 1396.0, "text": " has a different perspective on it, then you say, hey,", "tokens": [575, 257, 819, 4585, 322, 309, 11, 550, 291, 584, 11, 4177, 11], "temperature": 0.0, "avg_logprob": -0.1471789488151892, "compression_ratio": 1.658703071672355, "no_speech_prob": 3.169107003486715e-05}, {"id": 366, "seek": 139000, "start": 1396.0, "end": 1398.0, "text": " that sounds like a great idea.", "tokens": [300, 3263, 411, 257, 869, 1558, 13], "temperature": 0.0, "avg_logprob": -0.1471789488151892, "compression_ratio": 1.658703071672355, "no_speech_prob": 3.169107003486715e-05}, {"id": 367, "seek": 139000, "start": 1398.0, "end": 1401.0, "text": " It's just not what I see for the vision of this particular", "tokens": [467, 311, 445, 406, 437, 286, 536, 337, 264, 5201, 295, 341, 1729], "temperature": 0.0, "avg_logprob": -0.1471789488151892, "compression_ratio": 1.658703071672355, "no_speech_prob": 3.169107003486715e-05}, {"id": 368, "seek": 139000, "start": 1401.0, "end": 1403.0, "text": " extras package.", "tokens": [40961, 7372, 13], "temperature": 0.0, "avg_logprob": -0.1471789488151892, "compression_ratio": 1.658703071672355, "no_speech_prob": 3.169107003486715e-05}, {"id": 369, "seek": 139000, "start": 1403.0, "end": 1405.0, "text": " So somebody else can go and make another version of it.", "tokens": [407, 2618, 1646, 393, 352, 293, 652, 1071, 3037, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.1471789488151892, "compression_ratio": 1.658703071672355, "no_speech_prob": 3.169107003486715e-05}, {"id": 370, "seek": 139000, "start": 1405.0, "end": 1406.0, "text": " Maybe it starts as a fork.", "tokens": [2704, 309, 3719, 382, 257, 17716, 13], "temperature": 0.0, "avg_logprob": -0.1471789488151892, "compression_ratio": 1.658703071672355, "no_speech_prob": 3.169107003486715e-05}, {"id": 371, "seek": 139000, "start": 1406.0, "end": 1408.0, "text": " Maybe it's a totally different thing.", "tokens": [2704, 309, 311, 257, 3879, 819, 551, 13], "temperature": 0.0, "avg_logprob": -0.1471789488151892, "compression_ratio": 1.658703071672355, "no_speech_prob": 3.169107003486715e-05}, {"id": 372, "seek": 139000, "start": 1408.0, "end": 1409.0, "text": " The stakes are very low.", "tokens": [440, 28429, 366, 588, 2295, 13], "temperature": 0.0, "avg_logprob": -0.1471789488151892, "compression_ratio": 1.658703071672355, "no_speech_prob": 3.169107003486715e-05}, {"id": 373, "seek": 139000, "start": 1409.0, "end": 1412.0, "text": " If you're talking about the programming language itself,", "tokens": [759, 291, 434, 1417, 466, 264, 9410, 2856, 2564, 11], "temperature": 0.0, "avg_logprob": -0.1471789488151892, "compression_ratio": 1.658703071672355, "no_speech_prob": 3.169107003486715e-05}, {"id": 374, "seek": 139000, "start": 1412.0, "end": 1414.0, "text": " Elm, the stakes are very high.", "tokens": [2699, 76, 11, 264, 28429, 366, 588, 1090, 13], "temperature": 0.0, "avg_logprob": -0.1471789488151892, "compression_ratio": 1.658703071672355, "no_speech_prob": 3.169107003486715e-05}, {"id": 375, "seek": 139000, "start": 1414.0, "end": 1418.0, "text": " And I think that emotions can run high as well when people", "tokens": [400, 286, 519, 300, 8462, 393, 1190, 1090, 382, 731, 562, 561], "temperature": 0.0, "avg_logprob": -0.1471789488151892, "compression_ratio": 1.658703071672355, "no_speech_prob": 3.169107003486715e-05}, {"id": 376, "seek": 141800, "start": 1418.0, "end": 1422.0, "text": " are saying, I depend on the future of this project", "tokens": [366, 1566, 11, 286, 5672, 322, 264, 2027, 295, 341, 1716], "temperature": 0.0, "avg_logprob": -0.15601229485664658, "compression_ratio": 1.8352941176470587, "no_speech_prob": 2.392304304521531e-05}, {"id": 377, "seek": 141800, "start": 1422.0, "end": 1425.0, "text": " because this is the language I'm using.", "tokens": [570, 341, 307, 264, 2856, 286, 478, 1228, 13], "temperature": 0.0, "avg_logprob": -0.15601229485664658, "compression_ratio": 1.8352941176470587, "no_speech_prob": 2.392304304521531e-05}, {"id": 378, "seek": 141800, "start": 1425.0, "end": 1427.0, "text": " Not only is it the language I'm using,", "tokens": [1726, 787, 307, 309, 264, 2856, 286, 478, 1228, 11], "temperature": 0.0, "avg_logprob": -0.15601229485664658, "compression_ratio": 1.8352941176470587, "no_speech_prob": 2.392304304521531e-05}, {"id": 379, "seek": 141800, "start": 1427.0, "end": 1429.0, "text": " but it's a highly constrained language with the philosophy", "tokens": [457, 309, 311, 257, 5405, 38901, 2856, 365, 264, 10675], "temperature": 0.0, "avg_logprob": -0.15601229485664658, "compression_ratio": 1.8352941176470587, "no_speech_prob": 2.392304304521531e-05}, {"id": 380, "seek": 141800, "start": 1429.0, "end": 1431.0, "text": " of not providing escape patches.", "tokens": [295, 406, 6530, 7615, 26531, 13], "temperature": 0.0, "avg_logprob": -0.15601229485664658, "compression_ratio": 1.8352941176470587, "no_speech_prob": 2.392304304521531e-05}, {"id": 381, "seek": 141800, "start": 1431.0, "end": 1434.0, "text": " So if you don't provide an escape patch for me,", "tokens": [407, 498, 291, 500, 380, 2893, 364, 7615, 9972, 337, 385, 11], "temperature": 0.0, "avg_logprob": -0.15601229485664658, "compression_ratio": 1.8352941176470587, "no_speech_prob": 2.392304304521531e-05}, {"id": 382, "seek": 141800, "start": 1434.0, "end": 1436.0, "text": " or if you don't provide a path for me,", "tokens": [420, 498, 291, 500, 380, 2893, 257, 3100, 337, 385, 11], "temperature": 0.0, "avg_logprob": -0.15601229485664658, "compression_ratio": 1.8352941176470587, "no_speech_prob": 2.392304304521531e-05}, {"id": 383, "seek": 141800, "start": 1436.0, "end": 1439.0, "text": " then I'm highly dependent on that.", "tokens": [550, 286, 478, 5405, 12334, 322, 300, 13], "temperature": 0.0, "avg_logprob": -0.15601229485664658, "compression_ratio": 1.8352941176470587, "no_speech_prob": 2.392304304521531e-05}, {"id": 384, "seek": 141800, "start": 1439.0, "end": 1443.0, "text": " So it feels more emotionally charged in cases like that.", "tokens": [407, 309, 3417, 544, 17991, 11109, 294, 3331, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.15601229485664658, "compression_ratio": 1.8352941176470587, "no_speech_prob": 2.392304304521531e-05}, {"id": 385, "seek": 141800, "start": 1443.0, "end": 1446.0, "text": " Yeah, I think it's important.", "tokens": [865, 11, 286, 519, 309, 311, 1021, 13], "temperature": 0.0, "avg_logprob": -0.15601229485664658, "compression_ratio": 1.8352941176470587, "no_speech_prob": 2.392304304521531e-05}, {"id": 386, "seek": 141800, "start": 1446.0, "end": 1447.0, "text": " Well, I don't know if it's important.", "tokens": [1042, 11, 286, 500, 380, 458, 498, 309, 311, 1021, 13], "temperature": 0.0, "avg_logprob": -0.15601229485664658, "compression_ratio": 1.8352941176470587, "no_speech_prob": 2.392304304521531e-05}, {"id": 387, "seek": 144700, "start": 1447.0, "end": 1449.0, "text": " I think it's helpful, very helpful,", "tokens": [286, 519, 309, 311, 4961, 11, 588, 4961, 11], "temperature": 0.0, "avg_logprob": -0.17777183728340346, "compression_ratio": 1.722466960352423, "no_speech_prob": 4.005901064374484e-05}, {"id": 388, "seek": 144700, "start": 1449.0, "end": 1453.0, "text": " when projects convey their goals and their non-goals,", "tokens": [562, 4455, 16965, 641, 5493, 293, 641, 2107, 12, 1571, 1124, 11], "temperature": 0.0, "avg_logprob": -0.17777183728340346, "compression_ratio": 1.722466960352423, "no_speech_prob": 4.005901064374484e-05}, {"id": 389, "seek": 144700, "start": 1453.0, "end": 1456.0, "text": " which you kind of said with the perspectives.", "tokens": [597, 291, 733, 295, 848, 365, 264, 16766, 13], "temperature": 0.0, "avg_logprob": -0.17777183728340346, "compression_ratio": 1.722466960352423, "no_speech_prob": 4.005901064374484e-05}, {"id": 390, "seek": 144700, "start": 1456.0, "end": 1461.0, "text": " Like my goals with Elm Review is to have something,", "tokens": [1743, 452, 5493, 365, 2699, 76, 19954, 307, 281, 362, 746, 11], "temperature": 0.0, "avg_logprob": -0.17777183728340346, "compression_ratio": 1.722466960352423, "no_speech_prob": 4.005901064374484e-05}, {"id": 391, "seek": 144700, "start": 1461.0, "end": 1463.0, "text": " blah, blah, blah, that is blah, blah, blah.", "tokens": [12288, 11, 12288, 11, 12288, 11, 300, 307, 12288, 11, 12288, 11, 12288, 13], "temperature": 0.0, "avg_logprob": -0.17777183728340346, "compression_ratio": 1.722466960352423, "no_speech_prob": 4.005901064374484e-05}, {"id": 392, "seek": 144700, "start": 1463.0, "end": 1468.0, "text": " And for my goals, but some of what people can perceive", "tokens": [400, 337, 452, 5493, 11, 457, 512, 295, 437, 561, 393, 20281], "temperature": 0.0, "avg_logprob": -0.17777183728340346, "compression_ratio": 1.722466960352423, "no_speech_prob": 4.005901064374484e-05}, {"id": 393, "seek": 144700, "start": 1468.0, "end": 1470.0, "text": " as goals are not goals.", "tokens": [382, 5493, 366, 406, 5493, 13], "temperature": 0.0, "avg_logprob": -0.17777183728340346, "compression_ratio": 1.722466960352423, "no_speech_prob": 4.005901064374484e-05}, {"id": 394, "seek": 144700, "start": 1470.0, "end": 1475.0, "text": " Like I don't want to turn Elm Review into a language server.", "tokens": [1743, 286, 500, 380, 528, 281, 1261, 2699, 76, 19954, 666, 257, 2856, 7154, 13], "temperature": 0.0, "avg_logprob": -0.17777183728340346, "compression_ratio": 1.722466960352423, "no_speech_prob": 4.005901064374484e-05}, {"id": 395, "seek": 144700, "start": 1475.0, "end": 1476.0, "text": " That is a non-goal.", "tokens": [663, 307, 257, 2107, 12, 1571, 304, 13], "temperature": 0.0, "avg_logprob": -0.17777183728340346, "compression_ratio": 1.722466960352423, "no_speech_prob": 4.005901064374484e-05}, {"id": 396, "seek": 147600, "start": 1476.0, "end": 1478.0, "text": " Maybe that will evolve.", "tokens": [2704, 300, 486, 16693, 13], "temperature": 0.0, "avg_logprob": -0.17766861688523067, "compression_ratio": 1.6161137440758293, "no_speech_prob": 2.4677727196831256e-05}, {"id": 397, "seek": 147600, "start": 1478.0, "end": 1479.0, "text": " Who knows?", "tokens": [2102, 3255, 30], "temperature": 0.0, "avg_logprob": -0.17766861688523067, "compression_ratio": 1.6161137440758293, "no_speech_prob": 2.4677727196831256e-05}, {"id": 398, "seek": 147600, "start": 1479.0, "end": 1481.0, "text": " I don't think so.", "tokens": [286, 500, 380, 519, 370, 13], "temperature": 0.0, "avg_logprob": -0.17766861688523067, "compression_ratio": 1.6161137440758293, "no_speech_prob": 2.4677727196831256e-05}, {"id": 399, "seek": 147600, "start": 1481.0, "end": 1483.0, "text": " But at the moment, there are non-goals.", "tokens": [583, 412, 264, 1623, 11, 456, 366, 2107, 12, 1571, 1124, 13], "temperature": 0.0, "avg_logprob": -0.17766861688523067, "compression_ratio": 1.6161137440758293, "no_speech_prob": 2.4677727196831256e-05}, {"id": 400, "seek": 147600, "start": 1483.0, "end": 1487.0, "text": " And the same thing is for extra packages.", "tokens": [400, 264, 912, 551, 307, 337, 2857, 17401, 13], "temperature": 0.0, "avg_logprob": -0.17766861688523067, "compression_ratio": 1.6161137440758293, "no_speech_prob": 2.4677727196831256e-05}, {"id": 401, "seek": 147600, "start": 1487.0, "end": 1489.0, "text": " The same thing is for Elm.", "tokens": [440, 912, 551, 307, 337, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.17766861688523067, "compression_ratio": 1.6161137440758293, "no_speech_prob": 2.4677727196831256e-05}, {"id": 402, "seek": 147600, "start": 1489.0, "end": 1491.0, "text": " Like some of the goals for the Elm language", "tokens": [1743, 512, 295, 264, 5493, 337, 264, 2699, 76, 2856], "temperature": 0.0, "avg_logprob": -0.17766861688523067, "compression_ratio": 1.6161137440758293, "no_speech_prob": 2.4677727196831256e-05}, {"id": 403, "seek": 147600, "start": 1491.0, "end": 1494.0, "text": " is that we make something that is really maintainable,", "tokens": [307, 300, 321, 652, 746, 300, 307, 534, 6909, 712, 11], "temperature": 0.0, "avg_logprob": -0.17766861688523067, "compression_ratio": 1.6161137440758293, "no_speech_prob": 2.4677727196831256e-05}, {"id": 404, "seek": 147600, "start": 1494.0, "end": 1500.0, "text": " easy for beginners, and fun maybe in a way, delightful.", "tokens": [1858, 337, 26992, 11, 293, 1019, 1310, 294, 257, 636, 11, 35194, 13], "temperature": 0.0, "avg_logprob": -0.17766861688523067, "compression_ratio": 1.6161137440758293, "no_speech_prob": 2.4677727196831256e-05}, {"id": 405, "seek": 147600, "start": 1500.0, "end": 1502.0, "text": " And those are the goals.", "tokens": [400, 729, 366, 264, 5493, 13], "temperature": 0.0, "avg_logprob": -0.17766861688523067, "compression_ratio": 1.6161137440758293, "no_speech_prob": 2.4677727196831256e-05}, {"id": 406, "seek": 150200, "start": 1502.0, "end": 1506.0, "text": " If something makes those goals disappear,", "tokens": [759, 746, 1669, 729, 5493, 11596, 11], "temperature": 0.0, "avg_logprob": -0.20452742143110794, "compression_ratio": 1.6303317535545023, "no_speech_prob": 2.546157884353306e-05}, {"id": 407, "seek": 150200, "start": 1506.0, "end": 1511.0, "text": " like adding a new feature that makes error messages really", "tokens": [411, 5127, 257, 777, 4111, 300, 1669, 6713, 7897, 534], "temperature": 0.0, "avg_logprob": -0.20452742143110794, "compression_ratio": 1.6303317535545023, "no_speech_prob": 2.546157884353306e-05}, {"id": 408, "seek": 150200, "start": 1511.0, "end": 1514.0, "text": " hard to read, type classes, for instance,", "tokens": [1152, 281, 1401, 11, 2010, 5359, 11, 337, 5197, 11], "temperature": 0.0, "avg_logprob": -0.20452742143110794, "compression_ratio": 1.6303317535545023, "no_speech_prob": 2.546157884353306e-05}, {"id": 409, "seek": 150200, "start": 1514.0, "end": 1518.0, "text": " is one example that I've heard of multiple times.", "tokens": [307, 472, 1365, 300, 286, 600, 2198, 295, 3866, 1413, 13], "temperature": 0.0, "avg_logprob": -0.20452742143110794, "compression_ratio": 1.6303317535545023, "no_speech_prob": 2.546157884353306e-05}, {"id": 410, "seek": 150200, "start": 1518.0, "end": 1520.0, "text": " Well, that conflicts with the goals.", "tokens": [1042, 11, 300, 19807, 365, 264, 5493, 13], "temperature": 0.0, "avg_logprob": -0.20452742143110794, "compression_ratio": 1.6303317535545023, "no_speech_prob": 2.546157884353306e-05}, {"id": 411, "seek": 150200, "start": 1520.0, "end": 1526.0, "text": " So the trade-offs have to be, like the benefits you get", "tokens": [407, 264, 4923, 12, 19231, 362, 281, 312, 11, 411, 264, 5311, 291, 483], "temperature": 0.0, "avg_logprob": -0.20452742143110794, "compression_ratio": 1.6303317535545023, "no_speech_prob": 2.546157884353306e-05}, {"id": 412, "seek": 150200, "start": 1526.0, "end": 1530.0, "text": " from adding such a feature have to be really high in order", "tokens": [490, 5127, 1270, 257, 4111, 362, 281, 312, 534, 1090, 294, 1668], "temperature": 0.0, "avg_logprob": -0.20452742143110794, "compression_ratio": 1.6303317535545023, "no_speech_prob": 2.546157884353306e-05}, {"id": 413, "seek": 153000, "start": 1530.0, "end": 1535.0, "text": " to compensate the loss of error-friendliness.", "tokens": [281, 29458, 264, 4470, 295, 6713, 12, 69, 27378, 67, 32268, 13], "temperature": 0.0, "avg_logprob": -0.18503000070382883, "compression_ratio": 1.5446808510638297, "no_speech_prob": 2.28272911044769e-05}, {"id": 414, "seek": 153000, "start": 1535.0, "end": 1537.0, "text": " But something that is a non-goal,", "tokens": [583, 746, 300, 307, 257, 2107, 12, 1571, 304, 11], "temperature": 0.0, "avg_logprob": -0.18503000070382883, "compression_ratio": 1.5446808510638297, "no_speech_prob": 2.28272911044769e-05}, {"id": 415, "seek": 153000, "start": 1537.0, "end": 1541.0, "text": " like for instance, having direct FFI,", "tokens": [411, 337, 5197, 11, 1419, 2047, 479, 38568, 11], "temperature": 0.0, "avg_logprob": -0.18503000070382883, "compression_ratio": 1.5446808510638297, "no_speech_prob": 2.28272911044769e-05}, {"id": 416, "seek": 153000, "start": 1541.0, "end": 1543.0, "text": " direct interrupt with JavaScript,", "tokens": [2047, 12729, 365, 15778, 11], "temperature": 0.0, "avg_logprob": -0.18503000070382883, "compression_ratio": 1.5446808510638297, "no_speech_prob": 2.28272911044769e-05}, {"id": 417, "seek": 153000, "start": 1543.0, "end": 1545.0, "text": " is not a goal of Elm.", "tokens": [307, 406, 257, 3387, 295, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.18503000070382883, "compression_ratio": 1.5446808510638297, "no_speech_prob": 2.28272911044769e-05}, {"id": 418, "seek": 153000, "start": 1545.0, "end": 1549.0, "text": " You have to go through these escape hatches, ports,", "tokens": [509, 362, 281, 352, 807, 613, 7615, 17387, 279, 11, 18160, 11], "temperature": 0.0, "avg_logprob": -0.18503000070382883, "compression_ratio": 1.5446808510638297, "no_speech_prob": 2.28272911044769e-05}, {"id": 419, "seek": 153000, "start": 1549.0, "end": 1550.0, "text": " that are available.", "tokens": [300, 366, 2435, 13], "temperature": 0.0, "avg_logprob": -0.18503000070382883, "compression_ratio": 1.5446808510638297, "no_speech_prob": 2.28272911044769e-05}, {"id": 420, "seek": 153000, "start": 1550.0, "end": 1555.0, "text": " And they are a goal of Elm to set up a nice barrier", "tokens": [400, 436, 366, 257, 3387, 295, 2699, 76, 281, 992, 493, 257, 1481, 13357], "temperature": 0.0, "avg_logprob": -0.18503000070382883, "compression_ratio": 1.5446808510638297, "no_speech_prob": 2.28272911044769e-05}, {"id": 421, "seek": 153000, "start": 1555.0, "end": 1556.0, "text": " around your code.", "tokens": [926, 428, 3089, 13], "temperature": 0.0, "avg_logprob": -0.18503000070382883, "compression_ratio": 1.5446808510638297, "no_speech_prob": 2.28272911044769e-05}, {"id": 422, "seek": 153000, "start": 1556.0, "end": 1559.0, "text": " And that's the way that things were thought of.", "tokens": [400, 300, 311, 264, 636, 300, 721, 645, 1194, 295, 13], "temperature": 0.0, "avg_logprob": -0.18503000070382883, "compression_ratio": 1.5446808510638297, "no_speech_prob": 2.28272911044769e-05}, {"id": 423, "seek": 155900, "start": 1559.0, "end": 1563.0, "text": " It is not meant to provide direct FFI,", "tokens": [467, 307, 406, 4140, 281, 2893, 2047, 479, 38568, 11], "temperature": 0.0, "avg_logprob": -0.21487965715040855, "compression_ratio": 1.6521739130434783, "no_speech_prob": 1.3845770808984526e-05}, {"id": 424, "seek": 155900, "start": 1563.0, "end": 1567.0, "text": " unless that happens to be easy, nice,", "tokens": [5969, 300, 2314, 281, 312, 1858, 11, 1481, 11], "temperature": 0.0, "avg_logprob": -0.21487965715040855, "compression_ratio": 1.6521739130434783, "no_speech_prob": 1.3845770808984526e-05}, {"id": 425, "seek": 155900, "start": 1567.0, "end": 1571.0, "text": " and without any judgments to other features.", "tokens": [293, 1553, 604, 40337, 281, 661, 4122, 13], "temperature": 0.0, "avg_logprob": -0.21487965715040855, "compression_ratio": 1.6521739130434783, "no_speech_prob": 1.3845770808984526e-05}, {"id": 426, "seek": 155900, "start": 1571.0, "end": 1574.0, "text": " Right, like guarantees, which is a huge part of the language.", "tokens": [1779, 11, 411, 32567, 11, 597, 307, 257, 2603, 644, 295, 264, 2856, 13], "temperature": 0.0, "avg_logprob": -0.21487965715040855, "compression_ratio": 1.6521739130434783, "no_speech_prob": 1.3845770808984526e-05}, {"id": 427, "seek": 155900, "start": 1574.0, "end": 1575.0, "text": " Safety and guarantees.", "tokens": [21340, 293, 32567, 13], "temperature": 0.0, "avg_logprob": -0.21487965715040855, "compression_ratio": 1.6521739130434783, "no_speech_prob": 1.3845770808984526e-05}, {"id": 428, "seek": 155900, "start": 1575.0, "end": 1579.0, "text": " So I'm sure, for instance, Evan would be all for type classes", "tokens": [407, 286, 478, 988, 11, 337, 5197, 11, 22613, 576, 312, 439, 337, 2010, 5359], "temperature": 0.0, "avg_logprob": -0.21487965715040855, "compression_ratio": 1.6521739130434783, "no_speech_prob": 1.3845770808984526e-05}, {"id": 429, "seek": 155900, "start": 1579.0, "end": 1583.0, "text": " and FFI if we didn't lose the guarantees,", "tokens": [293, 479, 38568, 498, 321, 994, 380, 3624, 264, 32567, 11], "temperature": 0.0, "avg_logprob": -0.21487965715040855, "compression_ratio": 1.6521739130434783, "no_speech_prob": 1.3845770808984526e-05}, {"id": 430, "seek": 155900, "start": 1583.0, "end": 1587.0, "text": " and if we didn't lose the ease of use of the language.", "tokens": [293, 498, 321, 994, 380, 3624, 264, 12708, 295, 764, 295, 264, 2856, 13], "temperature": 0.0, "avg_logprob": -0.21487965715040855, "compression_ratio": 1.6521739130434783, "no_speech_prob": 1.3845770808984526e-05}, {"id": 431, "seek": 155900, "start": 1587.0, "end": 1588.0, "text": " Exactly, yeah.", "tokens": [7587, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.21487965715040855, "compression_ratio": 1.6521739130434783, "no_speech_prob": 1.3845770808984526e-05}, {"id": 432, "seek": 158800, "start": 1588.0, "end": 1592.0, "text": " So if someone can come up with solutions to that,", "tokens": [407, 498, 1580, 393, 808, 493, 365, 6547, 281, 300, 11], "temperature": 0.0, "avg_logprob": -0.20883075169154575, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.00011952350178034976}, {"id": 433, "seek": 158800, "start": 1592.0, "end": 1595.0, "text": " then that's probably going to happen one day.", "tokens": [550, 300, 311, 1391, 516, 281, 1051, 472, 786, 13], "temperature": 0.0, "avg_logprob": -0.20883075169154575, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.00011952350178034976}, {"id": 434, "seek": 158800, "start": 1595.0, "end": 1598.0, "text": " If they don't, or if they conflict too much in trade-offs,", "tokens": [759, 436, 500, 380, 11, 420, 498, 436, 6596, 886, 709, 294, 4923, 12, 19231, 11], "temperature": 0.0, "avg_logprob": -0.20883075169154575, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.00011952350178034976}, {"id": 435, "seek": 158800, "start": 1598.0, "end": 1600.0, "text": " it won't.", "tokens": [309, 1582, 380, 13], "temperature": 0.0, "avg_logprob": -0.20883075169154575, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.00011952350178034976}, {"id": 436, "seek": 158800, "start": 1600.0, "end": 1604.0, "text": " So yeah, defining your goals and your non-goals,", "tokens": [407, 1338, 11, 17827, 428, 5493, 293, 428, 2107, 12, 1571, 1124, 11], "temperature": 0.0, "avg_logprob": -0.20883075169154575, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.00011952350178034976}, {"id": 437, "seek": 158800, "start": 1604.0, "end": 1608.0, "text": " that can help people know whether they even have", "tokens": [300, 393, 854, 561, 458, 1968, 436, 754, 362], "temperature": 0.0, "avg_logprob": -0.20883075169154575, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.00011952350178034976}, {"id": 438, "seek": 158800, "start": 1608.0, "end": 1612.0, "text": " to suggest an idea, or how much they have to push it,", "tokens": [281, 3402, 364, 1558, 11, 420, 577, 709, 436, 362, 281, 2944, 309, 11], "temperature": 0.0, "avg_logprob": -0.20883075169154575, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.00011952350178034976}, {"id": 439, "seek": 158800, "start": 1612.0, "end": 1615.0, "text": " or if they get pushback, like understand,", "tokens": [420, 498, 436, 483, 2944, 3207, 11, 411, 1223, 11], "temperature": 0.0, "avg_logprob": -0.20883075169154575, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.00011952350178034976}, {"id": 440, "seek": 161500, "start": 1615.0, "end": 1619.0, "text": " we're not going to go with this approach because we have", "tokens": [321, 434, 406, 516, 281, 352, 365, 341, 3109, 570, 321, 362], "temperature": 0.0, "avg_logprob": -0.2057347571712801, "compression_ratio": 1.4682926829268292, "no_speech_prob": 1.1841528248623945e-05}, {"id": 441, "seek": 161500, "start": 1619.0, "end": 1620.0, "text": " these goals.", "tokens": [613, 5493, 13], "temperature": 0.0, "avg_logprob": -0.2057347571712801, "compression_ratio": 1.4682926829268292, "no_speech_prob": 1.1841528248623945e-05}, {"id": 442, "seek": 161500, "start": 1620.0, "end": 1623.0, "text": " And I think that helps explain it.", "tokens": [400, 286, 519, 300, 3665, 2903, 309, 13], "temperature": 0.0, "avg_logprob": -0.2057347571712801, "compression_ratio": 1.4682926829268292, "no_speech_prob": 1.1841528248623945e-05}, {"id": 443, "seek": 161500, "start": 1623.0, "end": 1628.0, "text": " I don't know if I make my goals clear enough with Elm Review.", "tokens": [286, 500, 380, 458, 498, 286, 652, 452, 5493, 1850, 1547, 365, 2699, 76, 19954, 13], "temperature": 0.0, "avg_logprob": -0.2057347571712801, "compression_ratio": 1.4682926829268292, "no_speech_prob": 1.1841528248623945e-05}, {"id": 444, "seek": 161500, "start": 1628.0, "end": 1633.0, "text": " I'm thinking probably not, but who knows.", "tokens": [286, 478, 1953, 1391, 406, 11, 457, 567, 3255, 13], "temperature": 0.0, "avg_logprob": -0.2057347571712801, "compression_ratio": 1.4682926829268292, "no_speech_prob": 1.1841528248623945e-05}, {"id": 445, "seek": 161500, "start": 1633.0, "end": 1635.0, "text": " What about you for your project?", "tokens": [708, 466, 291, 337, 428, 1716, 30], "temperature": 0.0, "avg_logprob": -0.2057347571712801, "compression_ratio": 1.4682926829268292, "no_speech_prob": 1.1841528248623945e-05}, {"id": 446, "seek": 161500, "start": 1635.0, "end": 1640.0, "text": " I mean, I've definitely made an effort to lay out my goals,", "tokens": [286, 914, 11, 286, 600, 2138, 1027, 364, 4630, 281, 2360, 484, 452, 5493, 11], "temperature": 0.0, "avg_logprob": -0.2057347571712801, "compression_ratio": 1.4682926829268292, "no_speech_prob": 1.1841528248623945e-05}, {"id": 447, "seek": 164000, "start": 1640.0, "end": 1646.0, "text": " and I do sometimes reference them in poll requests or issues.", "tokens": [293, 286, 360, 2171, 6408, 552, 294, 6418, 12475, 420, 2663, 13], "temperature": 0.0, "avg_logprob": -0.170983760914904, "compression_ratio": 1.570754716981132, "no_speech_prob": 6.501158350147307e-05}, {"id": 448, "seek": 164000, "start": 1646.0, "end": 1650.0, "text": " Sometimes people will say, hey, it would be really great", "tokens": [4803, 561, 486, 584, 11, 4177, 11, 309, 576, 312, 534, 869], "temperature": 0.0, "avg_logprob": -0.170983760914904, "compression_ratio": 1.570754716981132, "no_speech_prob": 6.501158350147307e-05}, {"id": 449, "seek": 164000, "start": 1650.0, "end": 1655.0, "text": " if ElmGraphQL could support aliases.", "tokens": [498, 2699, 76, 38, 2662, 13695, 727, 1406, 10198, 1957, 13], "temperature": 0.0, "avg_logprob": -0.170983760914904, "compression_ratio": 1.570754716981132, "no_speech_prob": 6.501158350147307e-05}, {"id": 450, "seek": 164000, "start": 1655.0, "end": 1661.0, "text": " And I'll say, well, if there were a way to support that,", "tokens": [400, 286, 603, 584, 11, 731, 11, 498, 456, 645, 257, 636, 281, 1406, 300, 11], "temperature": 0.0, "avg_logprob": -0.170983760914904, "compression_ratio": 1.570754716981132, "no_speech_prob": 6.501158350147307e-05}, {"id": 451, "seek": 164000, "start": 1661.0, "end": 1663.0, "text": " that was in line with these goals,", "tokens": [300, 390, 294, 1622, 365, 613, 5493, 11], "temperature": 0.0, "avg_logprob": -0.170983760914904, "compression_ratio": 1.570754716981132, "no_speech_prob": 6.501158350147307e-05}, {"id": 452, "seek": 164000, "start": 1663.0, "end": 1664.0, "text": " then that would be great.", "tokens": [550, 300, 576, 312, 869, 13], "temperature": 0.0, "avg_logprob": -0.170983760914904, "compression_ratio": 1.570754716981132, "no_speech_prob": 6.501158350147307e-05}, {"id": 453, "seek": 164000, "start": 1664.0, "end": 1667.0, "text": " But I've found that it makes it a lot easier to communicate", "tokens": [583, 286, 600, 1352, 300, 309, 1669, 309, 257, 688, 3571, 281, 7890], "temperature": 0.0, "avg_logprob": -0.170983760914904, "compression_ratio": 1.570754716981132, "no_speech_prob": 6.501158350147307e-05}, {"id": 454, "seek": 166700, "start": 1667.0, "end": 1671.0, "text": " when it's all around these goals.", "tokens": [562, 309, 311, 439, 926, 613, 5493, 13], "temperature": 0.0, "avg_logprob": -0.22455296834309896, "compression_ratio": 1.558011049723757, "no_speech_prob": 1.8922481103800237e-05}, {"id": 455, "seek": 166700, "start": 1671.0, "end": 1675.0, "text": " Like, you know, there's something called nonviolent communication.", "tokens": [1743, 11, 291, 458, 11, 456, 311, 746, 1219, 2107, 48473, 6101, 13], "temperature": 0.0, "avg_logprob": -0.22455296834309896, "compression_ratio": 1.558011049723757, "no_speech_prob": 1.8922481103800237e-05}, {"id": 456, "seek": 166700, "start": 1675.0, "end": 1677.0, "text": " Sometimes people call it compassionate communication,", "tokens": [4803, 561, 818, 309, 30531, 6101, 11], "temperature": 0.0, "avg_logprob": -0.22455296834309896, "compression_ratio": 1.558011049723757, "no_speech_prob": 1.8922481103800237e-05}, {"id": 457, "seek": 166700, "start": 1677.0, "end": 1679.0, "text": " which interests me a lot.", "tokens": [597, 8847, 385, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.22455296834309896, "compression_ratio": 1.558011049723757, "no_speech_prob": 1.8922481103800237e-05}, {"id": 458, "seek": 166700, "start": 1679.0, "end": 1680.0, "text": " What did you say?", "tokens": [708, 630, 291, 584, 30], "temperature": 0.0, "avg_logprob": -0.22455296834309896, "compression_ratio": 1.558011049723757, "no_speech_prob": 1.8922481103800237e-05}, {"id": 459, "seek": 166700, "start": 1680.0, "end": 1681.0, "text": " What did you call it?", "tokens": [708, 630, 291, 818, 309, 30], "temperature": 0.0, "avg_logprob": -0.22455296834309896, "compression_ratio": 1.558011049723757, "no_speech_prob": 1.8922481103800237e-05}, {"id": 460, "seek": 166700, "start": 1681.0, "end": 1691.0, "text": " And the basic idea of it at the core is that you're basically", "tokens": [400, 264, 3875, 1558, 295, 309, 412, 264, 4965, 307, 300, 291, 434, 1936], "temperature": 0.0, "avg_logprob": -0.22455296834309896, "compression_ratio": 1.558011049723757, "no_speech_prob": 1.8922481103800237e-05}, {"id": 461, "seek": 169100, "start": 1691.0, "end": 1698.0, "text": " recognizing that everybody universally has certain universal needs.", "tokens": [18538, 300, 2201, 43995, 575, 1629, 11455, 2203, 13], "temperature": 0.0, "avg_logprob": -0.20960139021088806, "compression_ratio": 1.7486910994764397, "no_speech_prob": 5.25502491655061e-06}, {"id": 462, "seek": 169100, "start": 1698.0, "end": 1703.0, "text": " You know, a need for entertainment and a need for ease and peace", "tokens": [509, 458, 11, 257, 643, 337, 12393, 293, 257, 643, 337, 12708, 293, 4336], "temperature": 0.0, "avg_logprob": -0.20960139021088806, "compression_ratio": 1.7486910994764397, "no_speech_prob": 5.25502491655061e-06}, {"id": 463, "seek": 169100, "start": 1703.0, "end": 1705.0, "text": " and things like that.", "tokens": [293, 721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.20960139021088806, "compression_ratio": 1.7486910994764397, "no_speech_prob": 5.25502491655061e-06}, {"id": 464, "seek": 169100, "start": 1705.0, "end": 1710.0, "text": " These are basic core human needs that we recognize in everybody,", "tokens": [1981, 366, 3875, 4965, 1952, 2203, 300, 321, 5521, 294, 2201, 11], "temperature": 0.0, "avg_logprob": -0.20960139021088806, "compression_ratio": 1.7486910994764397, "no_speech_prob": 5.25502491655061e-06}, {"id": 465, "seek": 169100, "start": 1710.0, "end": 1713.0, "text": " and it's not something we would dispute.", "tokens": [293, 309, 311, 406, 746, 321, 576, 25379, 13], "temperature": 0.0, "avg_logprob": -0.20960139021088806, "compression_ratio": 1.7486910994764397, "no_speech_prob": 5.25502491655061e-06}, {"id": 466, "seek": 169100, "start": 1713.0, "end": 1714.0, "text": " The need for rest.", "tokens": [440, 643, 337, 1472, 13], "temperature": 0.0, "avg_logprob": -0.20960139021088806, "compression_ratio": 1.7486910994764397, "no_speech_prob": 5.25502491655061e-06}, {"id": 467, "seek": 169100, "start": 1714.0, "end": 1719.0, "text": " But just because somebody has a need for entertainment", "tokens": [583, 445, 570, 2618, 575, 257, 643, 337, 12393], "temperature": 0.0, "avg_logprob": -0.20960139021088806, "compression_ratio": 1.7486910994764397, "no_speech_prob": 5.25502491655061e-06}, {"id": 468, "seek": 171900, "start": 1719.0, "end": 1724.0, "text": " doesn't mean they can say, hey, Jeroen, do a dance right now.", "tokens": [1177, 380, 914, 436, 393, 584, 11, 4177, 11, 508, 2032, 268, 11, 360, 257, 4489, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.18611818313598633, "compression_ratio": 1.690217391304348, "no_speech_prob": 3.785290118685225e-06}, {"id": 469, "seek": 171900, "start": 1724.0, "end": 1728.0, "text": " Because, well, okay, maybe you can.", "tokens": [1436, 11, 731, 11, 1392, 11, 1310, 291, 393, 13], "temperature": 0.0, "avg_logprob": -0.18611818313598633, "compression_ratio": 1.690217391304348, "no_speech_prob": 3.785290118685225e-06}, {"id": 470, "seek": 171900, "start": 1728.0, "end": 1729.0, "text": " I am doing a dance right now.", "tokens": [286, 669, 884, 257, 4489, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.18611818313598633, "compression_ratio": 1.690217391304348, "no_speech_prob": 3.785290118685225e-06}, {"id": 471, "seek": 171900, "start": 1729.0, "end": 1730.0, "text": " He's doing a dance.", "tokens": [634, 311, 884, 257, 4489, 13], "temperature": 0.0, "avg_logprob": -0.18611818313598633, "compression_ratio": 1.690217391304348, "no_speech_prob": 3.785290118685225e-06}, {"id": 472, "seek": 171900, "start": 1730.0, "end": 1732.0, "text": " Pseudo-Jeroen, do a dance right now.", "tokens": [430, 405, 6207, 12, 41, 2032, 268, 11, 360, 257, 4489, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.18611818313598633, "compression_ratio": 1.690217391304348, "no_speech_prob": 3.785290118685225e-06}, {"id": 473, "seek": 171900, "start": 1732.0, "end": 1739.0, "text": " But basically these needs, these universal needs,", "tokens": [583, 1936, 613, 2203, 11, 613, 11455, 2203, 11], "temperature": 0.0, "avg_logprob": -0.18611818313598633, "compression_ratio": 1.690217391304348, "no_speech_prob": 3.785290118685225e-06}, {"id": 474, "seek": 171900, "start": 1739.0, "end": 1746.0, "text": " don't have a specific person, place, or time for how to fulfill those needs.", "tokens": [500, 380, 362, 257, 2685, 954, 11, 1081, 11, 420, 565, 337, 577, 281, 13875, 729, 2203, 13], "temperature": 0.0, "avg_logprob": -0.18611818313598633, "compression_ratio": 1.690217391304348, "no_speech_prob": 3.785290118685225e-06}, {"id": 475, "seek": 174600, "start": 1746.0, "end": 1749.0, "text": " So you can still recognize that the need is there.", "tokens": [407, 291, 393, 920, 5521, 300, 264, 643, 307, 456, 13], "temperature": 0.0, "avg_logprob": -0.1411810971181327, "compression_ratio": 1.774468085106383, "no_speech_prob": 2.429812229820527e-05}, {"id": 476, "seek": 174600, "start": 1749.0, "end": 1755.0, "text": " I have a need to be entertained, but I can't require you.", "tokens": [286, 362, 257, 643, 281, 312, 44783, 11, 457, 286, 393, 380, 3651, 291, 13], "temperature": 0.0, "avg_logprob": -0.1411810971181327, "compression_ratio": 1.774468085106383, "no_speech_prob": 2.429812229820527e-05}, {"id": 477, "seek": 174600, "start": 1755.0, "end": 1758.0, "text": " It's no longer universal when I'm requiring you right now", "tokens": [467, 311, 572, 2854, 11455, 562, 286, 478, 24165, 291, 558, 586], "temperature": 0.0, "avg_logprob": -0.1411810971181327, "compression_ratio": 1.774468085106383, "no_speech_prob": 2.429812229820527e-05}, {"id": 478, "seek": 174600, "start": 1758.0, "end": 1760.0, "text": " to meet that need for me.", "tokens": [281, 1677, 300, 643, 337, 385, 13], "temperature": 0.0, "avg_logprob": -0.1411810971181327, "compression_ratio": 1.774468085106383, "no_speech_prob": 2.429812229820527e-05}, {"id": 479, "seek": 174600, "start": 1760.0, "end": 1763.0, "text": " So in nonviolent communication, that would be called a strategy.", "tokens": [407, 294, 2107, 48473, 6101, 11, 300, 576, 312, 1219, 257, 5206, 13], "temperature": 0.0, "avg_logprob": -0.1411810971181327, "compression_ratio": 1.774468085106383, "no_speech_prob": 2.429812229820527e-05}, {"id": 480, "seek": 174600, "start": 1763.0, "end": 1766.0, "text": " That would be one strategy to meet that need,", "tokens": [663, 576, 312, 472, 5206, 281, 1677, 300, 643, 11], "temperature": 0.0, "avg_logprob": -0.1411810971181327, "compression_ratio": 1.774468085106383, "no_speech_prob": 2.429812229820527e-05}, {"id": 481, "seek": 174600, "start": 1766.0, "end": 1770.0, "text": " but there are multiple strategies to meet the need for entertainment.", "tokens": [457, 456, 366, 3866, 9029, 281, 1677, 264, 643, 337, 12393, 13], "temperature": 0.0, "avg_logprob": -0.1411810971181327, "compression_ratio": 1.774468085106383, "no_speech_prob": 2.429812229820527e-05}, {"id": 482, "seek": 174600, "start": 1770.0, "end": 1773.0, "text": " So I see it as very similar in open source,", "tokens": [407, 286, 536, 309, 382, 588, 2531, 294, 1269, 4009, 11], "temperature": 0.0, "avg_logprob": -0.1411810971181327, "compression_ratio": 1.774468085106383, "no_speech_prob": 2.429812229820527e-05}, {"id": 483, "seek": 177300, "start": 1773.0, "end": 1778.0, "text": " and that's really helped me navigate a lot of these open source communications.", "tokens": [293, 300, 311, 534, 4254, 385, 12350, 257, 688, 295, 613, 1269, 4009, 15163, 13], "temperature": 0.0, "avg_logprob": -0.2259527108608148, "compression_ratio": 1.5260663507109005, "no_speech_prob": 1.750156116031576e-05}, {"id": 484, "seek": 177300, "start": 1778.0, "end": 1782.0, "text": " I mean, not even communication, but just receiving requests", "tokens": [286, 914, 11, 406, 754, 6101, 11, 457, 445, 10040, 12475], "temperature": 0.0, "avg_logprob": -0.2259527108608148, "compression_ratio": 1.5260663507109005, "no_speech_prob": 1.750156116031576e-05}, {"id": 485, "seek": 177300, "start": 1782.0, "end": 1786.0, "text": " in an open source project is like understanding,", "tokens": [294, 364, 1269, 4009, 1716, 307, 411, 3701, 11], "temperature": 0.0, "avg_logprob": -0.2259527108608148, "compression_ratio": 1.5260663507109005, "no_speech_prob": 1.750156116031576e-05}, {"id": 486, "seek": 177300, "start": 1786.0, "end": 1791.0, "text": " okay, I get why somebody might be dependent on this particular project.", "tokens": [1392, 11, 286, 483, 983, 2618, 1062, 312, 12334, 322, 341, 1729, 1716, 13], "temperature": 0.0, "avg_logprob": -0.2259527108608148, "compression_ratio": 1.5260663507109005, "no_speech_prob": 1.750156116031576e-05}, {"id": 487, "seek": 177300, "start": 1791.0, "end": 1794.0, "text": " And so what is their need?", "tokens": [400, 370, 437, 307, 641, 643, 30], "temperature": 0.0, "avg_logprob": -0.2259527108608148, "compression_ratio": 1.5260663507109005, "no_speech_prob": 1.750156116031576e-05}, {"id": 488, "seek": 177300, "start": 1794.0, "end": 1796.0, "text": " They're trying to solve a problem.", "tokens": [814, 434, 1382, 281, 5039, 257, 1154, 13], "temperature": 0.0, "avg_logprob": -0.2259527108608148, "compression_ratio": 1.5260663507109005, "no_speech_prob": 1.750156116031576e-05}, {"id": 489, "seek": 179600, "start": 1796.0, "end": 1803.0, "text": " But similarly, this happens a lot in communication with communicating needs.", "tokens": [583, 14138, 11, 341, 2314, 257, 688, 294, 6101, 365, 17559, 2203, 13], "temperature": 0.0, "avg_logprob": -0.24939967967845775, "compression_ratio": 1.5876288659793814, "no_speech_prob": 3.340271177876275e-06}, {"id": 490, "seek": 179600, "start": 1803.0, "end": 1809.0, "text": " Often the point of conflict in communication is when we try", "tokens": [20043, 264, 935, 295, 6596, 294, 6101, 307, 562, 321, 853], "temperature": 0.0, "avg_logprob": -0.24939967967845775, "compression_ratio": 1.5876288659793814, "no_speech_prob": 3.340271177876275e-06}, {"id": 491, "seek": 179600, "start": 1809.0, "end": 1812.0, "text": " to demand a particular strategy.", "tokens": [281, 4733, 257, 1729, 5206, 13], "temperature": 0.0, "avg_logprob": -0.24939967967845775, "compression_ratio": 1.5876288659793814, "no_speech_prob": 3.340271177876275e-06}, {"id": 492, "seek": 179600, "start": 1812.0, "end": 1815.0, "text": " I say, you're in a dance right now.", "tokens": [286, 584, 11, 291, 434, 294, 257, 4489, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.24939967967845775, "compression_ratio": 1.5876288659793814, "no_speech_prob": 3.340271177876275e-06}, {"id": 493, "seek": 179600, "start": 1815.0, "end": 1820.0, "text": " If I just instead said, like, oh, man, I could go for, like,", "tokens": [759, 286, 445, 2602, 848, 11, 411, 11, 1954, 11, 587, 11, 286, 727, 352, 337, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.24939967967845775, "compression_ratio": 1.5876288659793814, "no_speech_prob": 3.340271177876275e-06}, {"id": 494, "seek": 179600, "start": 1820.0, "end": 1822.0, "text": " something fun and entertaining right now.", "tokens": [746, 1019, 293, 20402, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.24939967967845775, "compression_ratio": 1.5876288659793814, "no_speech_prob": 3.340271177876275e-06}, {"id": 495, "seek": 182200, "start": 1822.0, "end": 1827.0, "text": " If I started with that, then we could explore different ways,", "tokens": [759, 286, 1409, 365, 300, 11, 550, 321, 727, 6839, 819, 2098, 11], "temperature": 0.0, "avg_logprob": -0.17202665494835895, "compression_ratio": 1.6531531531531531, "no_speech_prob": 5.093587333249161e-06}, {"id": 496, "seek": 182200, "start": 1827.0, "end": 1829.0, "text": " different strategies for meeting that need,", "tokens": [819, 9029, 337, 3440, 300, 643, 11], "temperature": 0.0, "avg_logprob": -0.17202665494835895, "compression_ratio": 1.6531531531531531, "no_speech_prob": 5.093587333249161e-06}, {"id": 497, "seek": 182200, "start": 1829.0, "end": 1832.0, "text": " and we would have a much easier conversation.", "tokens": [293, 321, 576, 362, 257, 709, 3571, 3761, 13], "temperature": 0.0, "avg_logprob": -0.17202665494835895, "compression_ratio": 1.6531531531531531, "no_speech_prob": 5.093587333249161e-06}, {"id": 498, "seek": 182200, "start": 1832.0, "end": 1835.0, "text": " And I feel it's much the same thing in open source.", "tokens": [400, 286, 841, 309, 311, 709, 264, 912, 551, 294, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.17202665494835895, "compression_ratio": 1.6531531531531531, "no_speech_prob": 5.093587333249161e-06}, {"id": 499, "seek": 182200, "start": 1835.0, "end": 1842.0, "text": " If we can start with the universal needs, it just reduces the conflict level", "tokens": [759, 321, 393, 722, 365, 264, 11455, 2203, 11, 309, 445, 18081, 264, 6596, 1496], "temperature": 0.0, "avg_logprob": -0.17202665494835895, "compression_ratio": 1.6531531531531531, "no_speech_prob": 5.093587333249161e-06}, {"id": 500, "seek": 182200, "start": 1842.0, "end": 1846.0, "text": " and it makes it less stressful for the open source maintainer", "tokens": [293, 309, 1669, 309, 1570, 19108, 337, 264, 1269, 4009, 6909, 260], "temperature": 0.0, "avg_logprob": -0.17202665494835895, "compression_ratio": 1.6531531531531531, "no_speech_prob": 5.093587333249161e-06}, {"id": 501, "seek": 182200, "start": 1846.0, "end": 1848.0, "text": " and the user, I believe.", "tokens": [293, 264, 4195, 11, 286, 1697, 13], "temperature": 0.0, "avg_logprob": -0.17202665494835895, "compression_ratio": 1.6531531531531531, "no_speech_prob": 5.093587333249161e-06}, {"id": 502, "seek": 184800, "start": 1848.0, "end": 1854.0, "text": " For example, I think the user, I want to hear what is their pain point,", "tokens": [1171, 1365, 11, 286, 519, 264, 4195, 11, 286, 528, 281, 1568, 437, 307, 641, 1822, 935, 11], "temperature": 0.0, "avg_logprob": -0.16748107209497567, "compression_ratio": 1.7401960784313726, "no_speech_prob": 1.2218885785841849e-05}, {"id": 503, "seek": 184800, "start": 1854.0, "end": 1858.0, "text": " what is their experience, what is the problem they're solving.", "tokens": [437, 307, 641, 1752, 11, 437, 307, 264, 1154, 436, 434, 12606, 13], "temperature": 0.0, "avg_logprob": -0.16748107209497567, "compression_ratio": 1.7401960784313726, "no_speech_prob": 1.2218885785841849e-05}, {"id": 504, "seek": 184800, "start": 1858.0, "end": 1866.0, "text": " But often a request, a GitHub issue, starts with this project needs this,", "tokens": [583, 2049, 257, 5308, 11, 257, 23331, 2734, 11, 3719, 365, 341, 1716, 2203, 341, 11], "temperature": 0.0, "avg_logprob": -0.16748107209497567, "compression_ratio": 1.7401960784313726, "no_speech_prob": 1.2218885785841849e-05}, {"id": 505, "seek": 184800, "start": 1866.0, "end": 1868.0, "text": " this project needs to do this.", "tokens": [341, 1716, 2203, 281, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.16748107209497567, "compression_ratio": 1.7401960784313726, "no_speech_prob": 1.2218885785841849e-05}, {"id": 506, "seek": 184800, "start": 1868.0, "end": 1872.0, "text": " If instead they said, context, I'm using this project,", "tokens": [759, 2602, 436, 848, 11, 4319, 11, 286, 478, 1228, 341, 1716, 11], "temperature": 0.0, "avg_logprob": -0.16748107209497567, "compression_ratio": 1.7401960784313726, "no_speech_prob": 1.2218885785841849e-05}, {"id": 507, "seek": 184800, "start": 1872.0, "end": 1875.0, "text": " I'm trying to solve this problem, I'm not sure how to do it,", "tokens": [286, 478, 1382, 281, 5039, 341, 1154, 11, 286, 478, 406, 988, 577, 281, 360, 309, 11], "temperature": 0.0, "avg_logprob": -0.16748107209497567, "compression_ratio": 1.7401960784313726, "no_speech_prob": 1.2218885785841849e-05}, {"id": 508, "seek": 187500, "start": 1875.0, "end": 1880.0, "text": " this is what I tried, this is what I ran into, possible solution.", "tokens": [341, 307, 437, 286, 3031, 11, 341, 307, 437, 286, 5872, 666, 11, 1944, 3827, 13], "temperature": 0.0, "avg_logprob": -0.175758291821961, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.668847966764588e-06}, {"id": 509, "seek": 187500, "start": 1880.0, "end": 1883.0, "text": " What if you had an API that allowed you to do this?", "tokens": [708, 498, 291, 632, 364, 9362, 300, 4350, 291, 281, 360, 341, 30], "temperature": 0.0, "avg_logprob": -0.175758291821961, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.668847966764588e-06}, {"id": 510, "seek": 187500, "start": 1883.0, "end": 1887.0, "text": " And that gives the open source maintainer or somebody else", "tokens": [400, 300, 2709, 264, 1269, 4009, 6909, 260, 420, 2618, 1646], "temperature": 0.0, "avg_logprob": -0.175758291821961, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.668847966764588e-06}, {"id": 511, "seek": 187500, "start": 1887.0, "end": 1892.0, "text": " who is looking at the issues for the project the opportunity to perhaps", "tokens": [567, 307, 1237, 412, 264, 2663, 337, 264, 1716, 264, 2650, 281, 4317], "temperature": 0.0, "avg_logprob": -0.175758291821961, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.668847966764588e-06}, {"id": 512, "seek": 187500, "start": 1892.0, "end": 1896.0, "text": " the solution takes the form of, oh, well, here's an API that maybe", "tokens": [264, 3827, 2516, 264, 1254, 295, 11, 1954, 11, 731, 11, 510, 311, 364, 9362, 300, 1310], "temperature": 0.0, "avg_logprob": -0.175758291821961, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.668847966764588e-06}, {"id": 513, "seek": 187500, "start": 1896.0, "end": 1897.0, "text": " you haven't tried.", "tokens": [291, 2378, 380, 3031, 13], "temperature": 0.0, "avg_logprob": -0.175758291821961, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.668847966764588e-06}, {"id": 514, "seek": 187500, "start": 1897.0, "end": 1899.0, "text": " Why don't you try using it this way?", "tokens": [1545, 500, 380, 291, 853, 1228, 309, 341, 636, 30], "temperature": 0.0, "avg_logprob": -0.175758291821961, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.668847966764588e-06}, {"id": 515, "seek": 187500, "start": 1899.0, "end": 1901.0, "text": " That might solve your problem.", "tokens": [663, 1062, 5039, 428, 1154, 13], "temperature": 0.0, "avg_logprob": -0.175758291821961, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.668847966764588e-06}, {"id": 516, "seek": 190100, "start": 1901.0, "end": 1905.0, "text": " Or maybe there's another API, the API could take another form.", "tokens": [1610, 1310, 456, 311, 1071, 9362, 11, 264, 9362, 727, 747, 1071, 1254, 13], "temperature": 0.0, "avg_logprob": -0.20745965100209648, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.9637670902739046e-06}, {"id": 517, "seek": 190100, "start": 1905.0, "end": 1907.0, "text": " Maybe we could explore that.", "tokens": [2704, 321, 727, 6839, 300, 13], "temperature": 0.0, "avg_logprob": -0.20745965100209648, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.9637670902739046e-06}, {"id": 518, "seek": 190100, "start": 1907.0, "end": 1911.0, "text": " So now it's an exploration and the tensions are less high because it's not", "tokens": [407, 586, 309, 311, 364, 16197, 293, 264, 28303, 366, 1570, 1090, 570, 309, 311, 406], "temperature": 0.0, "avg_logprob": -0.20745965100209648, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.9637670902739046e-06}, {"id": 519, "seek": 190100, "start": 1911.0, "end": 1913.0, "text": " like my way or the highway.", "tokens": [411, 452, 636, 420, 264, 17205, 13], "temperature": 0.0, "avg_logprob": -0.20745965100209648, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.9637670902739046e-06}, {"id": 520, "seek": 190100, "start": 1913.0, "end": 1919.0, "text": " We can explore options together without feeling like it's winner takes all,", "tokens": [492, 393, 6839, 3956, 1214, 1553, 2633, 411, 309, 311, 8507, 2516, 439, 11], "temperature": 0.0, "avg_logprob": -0.20745965100209648, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.9637670902739046e-06}, {"id": 521, "seek": 190100, "start": 1919.0, "end": 1923.0, "text": " zero-sum game, one of us is going to get our way and one of us is not.", "tokens": [4018, 12, 82, 449, 1216, 11, 472, 295, 505, 307, 516, 281, 483, 527, 636, 293, 472, 295, 505, 307, 406, 13], "temperature": 0.0, "avg_logprob": -0.20745965100209648, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.9637670902739046e-06}, {"id": 522, "seek": 190100, "start": 1923.0, "end": 1928.0, "text": " And also, even if you went with this project needs this new feature", "tokens": [400, 611, 11, 754, 498, 291, 1437, 365, 341, 1716, 2203, 341, 777, 4111], "temperature": 0.0, "avg_logprob": -0.20745965100209648, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.9637670902739046e-06}, {"id": 523, "seek": 192800, "start": 1928.0, "end": 1932.0, "text": " and the maintainer is like, okay, sure, I'll add it.", "tokens": [293, 264, 6909, 260, 307, 411, 11, 1392, 11, 988, 11, 286, 603, 909, 309, 13], "temperature": 0.0, "avg_logprob": -0.20225819519587926, "compression_ratio": 1.58203125, "no_speech_prob": 4.936951427225722e-06}, {"id": 524, "seek": 192800, "start": 1932.0, "end": 1937.0, "text": " Well, maybe the feature will not be what the person requested in the", "tokens": [1042, 11, 1310, 264, 4111, 486, 406, 312, 437, 264, 954, 16436, 294, 264], "temperature": 0.0, "avg_logprob": -0.20225819519587926, "compression_ratio": 1.58203125, "no_speech_prob": 4.936951427225722e-06}, {"id": 525, "seek": 192800, "start": 1937.0, "end": 1942.0, "text": " first place or exactly like, oh, no, I actually wanted it to return", "tokens": [700, 1081, 420, 2293, 411, 11, 1954, 11, 572, 11, 286, 767, 1415, 309, 281, 2736], "temperature": 0.0, "avg_logprob": -0.20225819519587926, "compression_ratio": 1.58203125, "no_speech_prob": 4.936951427225722e-06}, {"id": 526, "seek": 192800, "start": 1942.0, "end": 1944.0, "text": " this value when this argument is given.", "tokens": [341, 2158, 562, 341, 6770, 307, 2212, 13], "temperature": 0.0, "avg_logprob": -0.20225819519587926, "compression_ratio": 1.58203125, "no_speech_prob": 4.936951427225722e-06}, {"id": 527, "seek": 192800, "start": 1944.0, "end": 1946.0, "text": " Oh, but that's not what I understood.", "tokens": [876, 11, 457, 300, 311, 406, 437, 286, 7320, 13], "temperature": 0.0, "avg_logprob": -0.20225819519587926, "compression_ratio": 1.58203125, "no_speech_prob": 4.936951427225722e-06}, {"id": 528, "seek": 192800, "start": 1946.0, "end": 1951.0, "text": " But if you start with a problem to solve, then things become clear.", "tokens": [583, 498, 291, 722, 365, 257, 1154, 281, 5039, 11, 550, 721, 1813, 1850, 13], "temperature": 0.0, "avg_logprob": -0.20225819519587926, "compression_ratio": 1.58203125, "no_speech_prob": 4.936951427225722e-06}, {"id": 529, "seek": 192800, "start": 1951.0, "end": 1956.0, "text": " I mean, just like in an open source project, at work they tend to say", "tokens": [286, 914, 11, 445, 411, 294, 364, 1269, 4009, 1716, 11, 412, 589, 436, 3928, 281, 584], "temperature": 0.0, "avg_logprob": -0.20225819519587926, "compression_ratio": 1.58203125, "no_speech_prob": 4.936951427225722e-06}, {"id": 530, "seek": 195600, "start": 1956.0, "end": 1961.0, "text": " like, don't come up with, don't present solutions, present problems", "tokens": [411, 11, 500, 380, 808, 493, 365, 11, 500, 380, 1974, 6547, 11, 1974, 2740], "temperature": 0.0, "avg_logprob": -0.19013959511943246, "compression_ratio": 1.7172774869109948, "no_speech_prob": 2.2250035272008972e-06}, {"id": 531, "seek": 195600, "start": 1961.0, "end": 1964.0, "text": " and present ideas.", "tokens": [293, 1974, 3487, 13], "temperature": 0.0, "avg_logprob": -0.19013959511943246, "compression_ratio": 1.7172774869109948, "no_speech_prob": 2.2250035272008972e-06}, {"id": 532, "seek": 195600, "start": 1964.0, "end": 1965.0, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.19013959511943246, "compression_ratio": 1.7172774869109948, "no_speech_prob": 2.2250035272008972e-06}, {"id": 533, "seek": 195600, "start": 1965.0, "end": 1971.0, "text": " And as you mentioned earlier, there could be different ways to address", "tokens": [400, 382, 291, 2835, 3071, 11, 456, 727, 312, 819, 2098, 281, 2985], "temperature": 0.0, "avg_logprob": -0.19013959511943246, "compression_ratio": 1.7172774869109948, "no_speech_prob": 2.2250035272008972e-06}, {"id": 534, "seek": 195600, "start": 1971.0, "end": 1977.0, "text": " the underlying problem or maybe solving that problem is not in the scope", "tokens": [264, 14217, 1154, 420, 1310, 12606, 300, 1154, 307, 406, 294, 264, 11923], "temperature": 0.0, "avg_logprob": -0.19013959511943246, "compression_ratio": 1.7172774869109948, "no_speech_prob": 2.2250035272008972e-06}, {"id": 535, "seek": 195600, "start": 1977.0, "end": 1978.0, "text": " of the project.", "tokens": [295, 264, 1716, 13], "temperature": 0.0, "avg_logprob": -0.19013959511943246, "compression_ratio": 1.7172774869109948, "no_speech_prob": 2.2250035272008972e-06}, {"id": 536, "seek": 195600, "start": 1978.0, "end": 1983.0, "text": " Maybe it's a non-goal of the project or maybe it's a goal of the project", "tokens": [2704, 309, 311, 257, 2107, 12, 1571, 304, 295, 264, 1716, 420, 1310, 309, 311, 257, 3387, 295, 264, 1716], "temperature": 0.0, "avg_logprob": -0.19013959511943246, "compression_ratio": 1.7172774869109948, "no_speech_prob": 2.2250035272008972e-06}, {"id": 537, "seek": 198300, "start": 1983.0, "end": 1987.0, "text": " but it's not a goal for the maintainer or the maintainer doesn't have time", "tokens": [457, 309, 311, 406, 257, 3387, 337, 264, 6909, 260, 420, 264, 6909, 260, 1177, 380, 362, 565], "temperature": 0.0, "avg_logprob": -0.18753318786621093, "compression_ratio": 1.8429752066115703, "no_speech_prob": 3.119877146673389e-05}, {"id": 538, "seek": 198300, "start": 1987.0, "end": 1990.0, "text": " to work on that or doesn't have the motivation to work on that particular", "tokens": [281, 589, 322, 300, 420, 1177, 380, 362, 264, 12335, 281, 589, 322, 300, 1729], "temperature": 0.0, "avg_logprob": -0.18753318786621093, "compression_ratio": 1.8429752066115703, "no_speech_prob": 3.119877146673389e-05}, {"id": 539, "seek": 198300, "start": 1990.0, "end": 1991.0, "text": " thing.", "tokens": [551, 13], "temperature": 0.0, "avg_logprob": -0.18753318786621093, "compression_ratio": 1.8429752066115703, "no_speech_prob": 3.119877146673389e-05}, {"id": 540, "seek": 198300, "start": 1991.0, "end": 1992.0, "text": " And that's okay, too.", "tokens": [400, 300, 311, 1392, 11, 886, 13], "temperature": 0.0, "avg_logprob": -0.18753318786621093, "compression_ratio": 1.8429752066115703, "no_speech_prob": 3.119877146673389e-05}, {"id": 541, "seek": 198300, "start": 1992.0, "end": 1998.0, "text": " And I do think I'm not saying that maintainer, I mean, obviously I believe", "tokens": [400, 286, 360, 519, 286, 478, 406, 1566, 300, 6909, 260, 11, 286, 914, 11, 2745, 286, 1697], "temperature": 0.0, "avg_logprob": -0.18753318786621093, "compression_ratio": 1.8429752066115703, "no_speech_prob": 3.119877146673389e-05}, {"id": 542, "seek": 198300, "start": 1998.0, "end": 2005.0, "text": " you and I have put in huge amounts of our free time to trying to do things", "tokens": [291, 293, 286, 362, 829, 294, 2603, 11663, 295, 527, 1737, 565, 281, 1382, 281, 360, 721], "temperature": 0.0, "avg_logprob": -0.18753318786621093, "compression_ratio": 1.8429752066115703, "no_speech_prob": 3.119877146673389e-05}, {"id": 543, "seek": 198300, "start": 2005.0, "end": 2007.0, "text": " in response to requests people have made.", "tokens": [294, 4134, 281, 12475, 561, 362, 1027, 13], "temperature": 0.0, "avg_logprob": -0.18753318786621093, "compression_ratio": 1.8429752066115703, "no_speech_prob": 3.119877146673389e-05}, {"id": 544, "seek": 198300, "start": 2007.0, "end": 2008.0, "text": " Right?", "tokens": [1779, 30], "temperature": 0.0, "avg_logprob": -0.18753318786621093, "compression_ratio": 1.8429752066115703, "no_speech_prob": 3.119877146673389e-05}, {"id": 545, "seek": 198300, "start": 2008.0, "end": 2012.0, "text": " So we're obviously not opposed to responding to people's requests and", "tokens": [407, 321, 434, 2745, 406, 8851, 281, 16670, 281, 561, 311, 12475, 293], "temperature": 0.0, "avg_logprob": -0.18753318786621093, "compression_ratio": 1.8429752066115703, "no_speech_prob": 3.119877146673389e-05}, {"id": 546, "seek": 201200, "start": 2012.0, "end": 2014.0, "text": " building something for them.", "tokens": [2390, 746, 337, 552, 13], "temperature": 0.0, "avg_logprob": -0.1696164974799523, "compression_ratio": 1.6517857142857142, "no_speech_prob": 3.4805234463419765e-05}, {"id": 547, "seek": 201200, "start": 2014.0, "end": 2020.0, "text": " But I think it just is really healthy for a project to recognize that, hey,", "tokens": [583, 286, 519, 309, 445, 307, 534, 4627, 337, 257, 1716, 281, 5521, 300, 11, 4177, 11], "temperature": 0.0, "avg_logprob": -0.1696164974799523, "compression_ratio": 1.6517857142857142, "no_speech_prob": 3.4805234463419765e-05}, {"id": 548, "seek": 201200, "start": 2020.0, "end": 2025.0, "text": " you can request something and I can say, hey, that sounds like a great idea,", "tokens": [291, 393, 5308, 746, 293, 286, 393, 584, 11, 4177, 11, 300, 3263, 411, 257, 869, 1558, 11], "temperature": 0.0, "avg_logprob": -0.1696164974799523, "compression_ratio": 1.6517857142857142, "no_speech_prob": 3.4805234463419765e-05}, {"id": 549, "seek": 201200, "start": 2025.0, "end": 2026.0, "text": " pull requests are welcome.", "tokens": [2235, 12475, 366, 2928, 13], "temperature": 0.0, "avg_logprob": -0.1696164974799523, "compression_ratio": 1.6517857142857142, "no_speech_prob": 3.4805234463419765e-05}, {"id": 550, "seek": 201200, "start": 2026.0, "end": 2029.0, "text": " Or maybe I decide to build it.", "tokens": [1610, 1310, 286, 4536, 281, 1322, 309, 13], "temperature": 0.0, "avg_logprob": -0.1696164974799523, "compression_ratio": 1.6517857142857142, "no_speech_prob": 3.4805234463419765e-05}, {"id": 551, "seek": 201200, "start": 2029.0, "end": 2034.0, "text": " And I think for me, especially like as, I mean, I have a lot of open source", "tokens": [400, 286, 519, 337, 385, 11, 2318, 411, 382, 11, 286, 914, 11, 286, 362, 257, 688, 295, 1269, 4009], "temperature": 0.0, "avg_logprob": -0.1696164974799523, "compression_ratio": 1.6517857142857142, "no_speech_prob": 3.4805234463419765e-05}, {"id": 552, "seek": 201200, "start": 2034.0, "end": 2035.0, "text": " projects.", "tokens": [4455, 13], "temperature": 0.0, "avg_logprob": -0.1696164974799523, "compression_ratio": 1.6517857142857142, "no_speech_prob": 3.4805234463419765e-05}, {"id": 553, "seek": 201200, "start": 2035.0, "end": 2039.0, "text": " I get a lot of feature requests in my inbox.", "tokens": [286, 483, 257, 688, 295, 4111, 12475, 294, 452, 35067, 13], "temperature": 0.0, "avg_logprob": -0.1696164974799523, "compression_ratio": 1.6517857142857142, "no_speech_prob": 3.4805234463419765e-05}, {"id": 554, "seek": 203900, "start": 2039.0, "end": 2044.0, "text": " And I can't, I literally can't do every single feature request everyone puts", "tokens": [400, 286, 393, 380, 11, 286, 3736, 393, 380, 360, 633, 2167, 4111, 5308, 1518, 8137], "temperature": 0.0, "avg_logprob": -0.1785481673020583, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.368396604259033e-06}, {"id": 555, "seek": 203900, "start": 2044.0, "end": 2045.0, "text": " in my inbox.", "tokens": [294, 452, 35067, 13], "temperature": 0.0, "avg_logprob": -0.1785481673020583, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.368396604259033e-06}, {"id": 556, "seek": 203900, "start": 2045.0, "end": 2049.0, "text": " It wouldn't, if I did, I would implicitly be saying no to somebody else's", "tokens": [467, 2759, 380, 11, 498, 286, 630, 11, 286, 576, 26947, 356, 312, 1566, 572, 281, 2618, 1646, 311], "temperature": 0.0, "avg_logprob": -0.1785481673020583, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.368396604259033e-06}, {"id": 557, "seek": 203900, "start": 2049.0, "end": 2053.0, "text": " feature request because by starting to work on something, I wouldn't have time", "tokens": [4111, 5308, 570, 538, 2891, 281, 589, 322, 746, 11, 286, 2759, 380, 362, 565], "temperature": 0.0, "avg_logprob": -0.1785481673020583, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.368396604259033e-06}, {"id": 558, "seek": 203900, "start": 2053.0, "end": 2055.0, "text": " to work on the other thing.", "tokens": [281, 589, 322, 264, 661, 551, 13], "temperature": 0.0, "avg_logprob": -0.1785481673020583, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.368396604259033e-06}, {"id": 559, "seek": 203900, "start": 2055.0, "end": 2058.0, "text": " And that's even if I'm working full time, like literally, it's just not", "tokens": [400, 300, 311, 754, 498, 286, 478, 1364, 1577, 565, 11, 411, 3736, 11, 309, 311, 445, 406], "temperature": 0.0, "avg_logprob": -0.1785481673020583, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.368396604259033e-06}, {"id": 560, "seek": 203900, "start": 2058.0, "end": 2059.0, "text": " possible.", "tokens": [1944, 13], "temperature": 0.0, "avg_logprob": -0.1785481673020583, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.368396604259033e-06}, {"id": 561, "seek": 203900, "start": 2059.0, "end": 2063.0, "text": " When you say full time, do you mean only eight hours a day?", "tokens": [1133, 291, 584, 1577, 565, 11, 360, 291, 914, 787, 3180, 2496, 257, 786, 30], "temperature": 0.0, "avg_logprob": -0.1785481673020583, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.368396604259033e-06}, {"id": 562, "seek": 203900, "start": 2063.0, "end": 2064.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.1785481673020583, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.368396604259033e-06}, {"id": 563, "seek": 203900, "start": 2064.0, "end": 2065.0, "text": " Probably not.", "tokens": [9210, 406, 13], "temperature": 0.0, "avg_logprob": -0.1785481673020583, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.368396604259033e-06}, {"id": 564, "seek": 203900, "start": 2065.0, "end": 2067.0, "text": " And not on weekends?", "tokens": [400, 406, 322, 23595, 30], "temperature": 0.0, "avg_logprob": -0.1785481673020583, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.368396604259033e-06}, {"id": 565, "seek": 206700, "start": 2067.0, "end": 2069.0, "text": " Come on, put in some effort.", "tokens": [2492, 322, 11, 829, 294, 512, 4630, 13], "temperature": 0.0, "avg_logprob": -0.19720557428175403, "compression_ratio": 1.541237113402062, "no_speech_prob": 1.202794101118343e-05}, {"id": 566, "seek": 206700, "start": 2069.0, "end": 2070.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.19720557428175403, "compression_ratio": 1.541237113402062, "no_speech_prob": 1.202794101118343e-05}, {"id": 567, "seek": 206700, "start": 2070.0, "end": 2072.0, "text": " I mean, often not.", "tokens": [286, 914, 11, 2049, 406, 13], "temperature": 0.0, "avg_logprob": -0.19720557428175403, "compression_ratio": 1.541237113402062, "no_speech_prob": 1.202794101118343e-05}, {"id": 568, "seek": 206700, "start": 2072.0, "end": 2073.0, "text": " And even then.", "tokens": [400, 754, 550, 13], "temperature": 0.0, "avg_logprob": -0.19720557428175403, "compression_ratio": 1.541237113402062, "no_speech_prob": 1.202794101118343e-05}, {"id": 569, "seek": 206700, "start": 2073.0, "end": 2079.0, "text": " And, you know, so I think it's, I think it depends on the type of issue,", "tokens": [400, 11, 291, 458, 11, 370, 286, 519, 309, 311, 11, 286, 519, 309, 5946, 322, 264, 2010, 295, 2734, 11], "temperature": 0.0, "avg_logprob": -0.19720557428175403, "compression_ratio": 1.541237113402062, "no_speech_prob": 1.202794101118343e-05}, {"id": 570, "seek": 206700, "start": 2079.0, "end": 2080.0, "text": " right?", "tokens": [558, 30], "temperature": 0.0, "avg_logprob": -0.19720557428175403, "compression_ratio": 1.541237113402062, "no_speech_prob": 1.202794101118343e-05}, {"id": 571, "seek": 206700, "start": 2080.0, "end": 2084.0, "text": " If there's like a blocking issue, it's a core feature of the framework and", "tokens": [759, 456, 311, 411, 257, 17776, 2734, 11, 309, 311, 257, 4965, 4111, 295, 264, 8388, 293], "temperature": 0.0, "avg_logprob": -0.19720557428175403, "compression_ratio": 1.541237113402062, "no_speech_prob": 1.202794101118343e-05}, {"id": 572, "seek": 206700, "start": 2084.0, "end": 2092.0, "text": " it's blocking people from solving basic use cases with the tool or library.", "tokens": [309, 311, 17776, 561, 490, 12606, 3875, 764, 3331, 365, 264, 2290, 420, 6405, 13], "temperature": 0.0, "avg_logprob": -0.19720557428175403, "compression_ratio": 1.541237113402062, "no_speech_prob": 1.202794101118343e-05}, {"id": 573, "seek": 209200, "start": 2092.0, "end": 2099.0, "text": " Right. Obviously that's going to change your prioritization on it compared to", "tokens": [1779, 13, 7580, 300, 311, 516, 281, 1319, 428, 14846, 2144, 322, 309, 5347, 281], "temperature": 0.0, "avg_logprob": -0.20692992437453497, "compression_ratio": 1.6, "no_speech_prob": 1.34195652208291e-05}, {"id": 574, "seek": 209200, "start": 2099.0, "end": 2101.0, "text": " some nice to have feature.", "tokens": [512, 1481, 281, 362, 4111, 13], "temperature": 0.0, "avg_logprob": -0.20692992437453497, "compression_ratio": 1.6, "no_speech_prob": 1.34195652208291e-05}, {"id": 575, "seek": 209200, "start": 2101.0, "end": 2103.0, "text": " Hey, this would be a really handy thing to have.", "tokens": [1911, 11, 341, 576, 312, 257, 534, 13239, 551, 281, 362, 13], "temperature": 0.0, "avg_logprob": -0.20692992437453497, "compression_ratio": 1.6, "no_speech_prob": 1.34195652208291e-05}, {"id": 576, "seek": 209200, "start": 2103.0, "end": 2108.0, "text": " And in cases like that, I'm much more likely to say, hey, that sounds really", "tokens": [400, 294, 3331, 411, 300, 11, 286, 478, 709, 544, 3700, 281, 584, 11, 4177, 11, 300, 3263, 534], "temperature": 0.0, "avg_logprob": -0.20692992437453497, "compression_ratio": 1.6, "no_speech_prob": 1.34195652208291e-05}, {"id": 577, "seek": 209200, "start": 2108.0, "end": 2109.0, "text": " interesting.", "tokens": [1880, 13], "temperature": 0.0, "avg_logprob": -0.20692992437453497, "compression_ratio": 1.6, "no_speech_prob": 1.34195652208291e-05}, {"id": 578, "seek": 209200, "start": 2109.0, "end": 2115.0, "text": " I would be glad to like do the work to review a pull request and then for the", "tokens": [286, 576, 312, 5404, 281, 411, 360, 264, 589, 281, 3131, 257, 2235, 5308, 293, 550, 337, 264], "temperature": 0.0, "avg_logprob": -0.20692992437453497, "compression_ratio": 1.6, "no_speech_prob": 1.34195652208291e-05}, {"id": 579, "seek": 209200, "start": 2115.0, "end": 2121.0, "text": " rest of this project, maintain this code, which is actually a very large cost.", "tokens": [1472, 295, 341, 1716, 11, 6909, 341, 3089, 11, 597, 307, 767, 257, 588, 2416, 2063, 13], "temperature": 0.0, "avg_logprob": -0.20692992437453497, "compression_ratio": 1.6, "no_speech_prob": 1.34195652208291e-05}, {"id": 580, "seek": 212100, "start": 2121.0, "end": 2122.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.19027988433837892, "compression_ratio": 1.84037558685446, "no_speech_prob": 4.9857098929351196e-05}, {"id": 581, "seek": 212100, "start": 2122.0, "end": 2128.0, "text": " Like when you're, when somebody is, it's not free to just pull in somebody's", "tokens": [1743, 562, 291, 434, 11, 562, 2618, 307, 11, 309, 311, 406, 1737, 281, 445, 2235, 294, 2618, 311], "temperature": 0.0, "avg_logprob": -0.19027988433837892, "compression_ratio": 1.84037558685446, "no_speech_prob": 4.9857098929351196e-05}, {"id": 582, "seek": 212100, "start": 2128.0, "end": 2130.0, "text": " code because, oh, they wrote this code.", "tokens": [3089, 570, 11, 1954, 11, 436, 4114, 341, 3089, 13], "temperature": 0.0, "avg_logprob": -0.19027988433837892, "compression_ratio": 1.84037558685446, "no_speech_prob": 4.9857098929351196e-05}, {"id": 583, "seek": 212100, "start": 2130.0, "end": 2136.0, "text": " When somebody writes the code, you're now committing to continue to consider", "tokens": [1133, 2618, 13657, 264, 3089, 11, 291, 434, 586, 26659, 281, 2354, 281, 1949], "temperature": 0.0, "avg_logprob": -0.19027988433837892, "compression_ratio": 1.84037558685446, "no_speech_prob": 4.9857098929351196e-05}, {"id": 584, "seek": 212100, "start": 2136.0, "end": 2140.0, "text": " how that feature affects the project.", "tokens": [577, 300, 4111, 11807, 264, 1716, 13], "temperature": 0.0, "avg_logprob": -0.19027988433837892, "compression_ratio": 1.84037558685446, "no_speech_prob": 4.9857098929351196e-05}, {"id": 585, "seek": 212100, "start": 2140.0, "end": 2144.0, "text": " So any new features that are added, you need to consider that feature and how", "tokens": [407, 604, 777, 4122, 300, 366, 3869, 11, 291, 643, 281, 1949, 300, 4111, 293, 577], "temperature": 0.0, "avg_logprob": -0.19027988433837892, "compression_ratio": 1.84037558685446, "no_speech_prob": 4.9857098929351196e-05}, {"id": 586, "seek": 212100, "start": 2144.0, "end": 2149.0, "text": " it interacts with new features you're adding or new bug fixes you're doing.", "tokens": [309, 43582, 365, 777, 4122, 291, 434, 5127, 420, 777, 7426, 32539, 291, 434, 884, 13], "temperature": 0.0, "avg_logprob": -0.19027988433837892, "compression_ratio": 1.84037558685446, "no_speech_prob": 4.9857098929351196e-05}, {"id": 587, "seek": 214900, "start": 2149.0, "end": 2152.0, "text": " And reviewing that code is not free.", "tokens": [400, 19576, 300, 3089, 307, 406, 1737, 13], "temperature": 0.0, "avg_logprob": -0.18434785461425782, "compression_ratio": 1.7472527472527473, "no_speech_prob": 1.3419769857136998e-05}, {"id": 588, "seek": 214900, "start": 2152.0, "end": 2156.0, "text": " Somebody might make a pull request that has several subtle bugs.", "tokens": [13463, 1062, 652, 257, 2235, 5308, 300, 575, 2940, 13743, 15120, 13], "temperature": 0.0, "avg_logprob": -0.18434785461425782, "compression_ratio": 1.7472527472527473, "no_speech_prob": 1.3419769857136998e-05}, {"id": 589, "seek": 214900, "start": 2156.0, "end": 2157.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.18434785461425782, "compression_ratio": 1.7472527472527473, "no_speech_prob": 1.3419769857136998e-05}, {"id": 590, "seek": 214900, "start": 2157.0, "end": 2163.0, "text": " So it's, it's actually, you know, there's less investment needed to make a pull", "tokens": [407, 309, 311, 11, 309, 311, 767, 11, 291, 458, 11, 456, 311, 1570, 6078, 2978, 281, 652, 257, 2235], "temperature": 0.0, "avg_logprob": -0.18434785461425782, "compression_ratio": 1.7472527472527473, "no_speech_prob": 1.3419769857136998e-05}, {"id": 591, "seek": 214900, "start": 2163.0, "end": 2167.0, "text": " request because you're not taking on responsibility for the project's long", "tokens": [5308, 570, 291, 434, 406, 1940, 322, 6357, 337, 264, 1716, 311, 938], "temperature": 0.0, "avg_logprob": -0.18434785461425782, "compression_ratio": 1.7472527472527473, "no_speech_prob": 1.3419769857136998e-05}, {"id": 592, "seek": 214900, "start": 2167.0, "end": 2167.0, "text": " term.", "tokens": [1433, 13], "temperature": 0.0, "avg_logprob": -0.18434785461425782, "compression_ratio": 1.7472527472527473, "no_speech_prob": 1.3419769857136998e-05}, {"id": 593, "seek": 214900, "start": 2167.0, "end": 2171.0, "text": " Like if somebody makes a pull request and there are bugs that result from that,", "tokens": [1743, 498, 2618, 1669, 257, 2235, 5308, 293, 456, 366, 15120, 300, 1874, 490, 300, 11], "temperature": 0.0, "avg_logprob": -0.18434785461425782, "compression_ratio": 1.7472527472527473, "no_speech_prob": 1.3419769857136998e-05}, {"id": 594, "seek": 214900, "start": 2171.0, "end": 2173.0, "text": " are they then going to fix them?", "tokens": [366, 436, 550, 516, 281, 3191, 552, 30], "temperature": 0.0, "avg_logprob": -0.18434785461425782, "compression_ratio": 1.7472527472527473, "no_speech_prob": 1.3419769857136998e-05}, {"id": 595, "seek": 214900, "start": 2173.0, "end": 2176.0, "text": " Or are you going to revert the feature if you find that there were bugs with it?", "tokens": [1610, 366, 291, 516, 281, 319, 3281, 264, 4111, 498, 291, 915, 300, 456, 645, 15120, 365, 309, 30], "temperature": 0.0, "avg_logprob": -0.18434785461425782, "compression_ratio": 1.7472527472527473, "no_speech_prob": 1.3419769857136998e-05}, {"id": 596, "seek": 214900, "start": 2176.0, "end": 2177.0, "text": " Probably not.", "tokens": [9210, 406, 13], "temperature": 0.0, "avg_logprob": -0.18434785461425782, "compression_ratio": 1.7472527472527473, "no_speech_prob": 1.3419769857136998e-05}, {"id": 597, "seek": 217700, "start": 2177.0, "end": 2183.0, "text": " You might be spending some of your weekends and evenings fixing that bug,", "tokens": [509, 1062, 312, 6434, 512, 295, 428, 23595, 293, 42835, 19442, 300, 7426, 11], "temperature": 0.0, "avg_logprob": -0.20420316549447867, "compression_ratio": 1.5982532751091703, "no_speech_prob": 4.425315637490712e-06}, {"id": 598, "seek": 217700, "start": 2183.0, "end": 2186.0, "text": " which actually happens to me frequently.", "tokens": [597, 767, 2314, 281, 385, 10374, 13], "temperature": 0.0, "avg_logprob": -0.20420316549447867, "compression_ratio": 1.5982532751091703, "no_speech_prob": 4.425315637490712e-06}, {"id": 599, "seek": 217700, "start": 2186.0, "end": 2186.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.20420316549447867, "compression_ratio": 1.5982532751091703, "no_speech_prob": 4.425315637490712e-06}, {"id": 600, "seek": 217700, "start": 2186.0, "end": 2191.0, "text": " So it's, I think it's really good to recognize that open source, there is a", "tokens": [407, 309, 311, 11, 286, 519, 309, 311, 534, 665, 281, 5521, 300, 1269, 4009, 11, 456, 307, 257], "temperature": 0.0, "avg_logprob": -0.20420316549447867, "compression_ratio": 1.5982532751091703, "no_speech_prob": 4.425315637490712e-06}, {"id": 601, "seek": 217700, "start": 2191.0, "end": 2193.0, "text": " cost to, to it.", "tokens": [2063, 281, 11, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.20420316549447867, "compression_ratio": 1.5982532751091703, "no_speech_prob": 4.425315637490712e-06}, {"id": 602, "seek": 217700, "start": 2193.0, "end": 2198.0, "text": " It's not just reviewing a pull request, but to, to taking on new scope.", "tokens": [467, 311, 406, 445, 19576, 257, 2235, 5308, 11, 457, 281, 11, 281, 1940, 322, 777, 11923, 13], "temperature": 0.0, "avg_logprob": -0.20420316549447867, "compression_ratio": 1.5982532751091703, "no_speech_prob": 4.425315637490712e-06}, {"id": 603, "seek": 217700, "start": 2198.0, "end": 2202.0, "text": " So I think it just helps to recognize, to have empathy for that, you know?", "tokens": [407, 286, 519, 309, 445, 3665, 281, 5521, 11, 281, 362, 18701, 337, 300, 11, 291, 458, 30], "temperature": 0.0, "avg_logprob": -0.20420316549447867, "compression_ratio": 1.5982532751091703, "no_speech_prob": 4.425315637490712e-06}, {"id": 604, "seek": 217700, "start": 2202.0, "end": 2203.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.20420316549447867, "compression_ratio": 1.5982532751091703, "no_speech_prob": 4.425315637490712e-06}, {"id": 605, "seek": 220300, "start": 2203.0, "end": 2209.0, "text": " I feel like some of the best features that are requested and which will", "tokens": [286, 841, 411, 512, 295, 264, 1151, 4122, 300, 366, 16436, 293, 597, 486], "temperature": 0.0, "avg_logprob": -0.17795409504164997, "compression_ratio": 1.6932773109243697, "no_speech_prob": 1.8161972548114136e-06}, {"id": 606, "seek": 220300, "start": 2209.0, "end": 2213.0, "text": " motivate me the most is the ones that I want myself.", "tokens": [28497, 385, 264, 881, 307, 264, 2306, 300, 286, 528, 2059, 13], "temperature": 0.0, "avg_logprob": -0.17795409504164997, "compression_ratio": 1.6932773109243697, "no_speech_prob": 1.8161972548114136e-06}, {"id": 607, "seek": 220300, "start": 2213.0, "end": 2218.0, "text": " Like for instance, I make Elm Review and I'm a user of Elm Review.", "tokens": [1743, 337, 5197, 11, 286, 652, 2699, 76, 19954, 293, 286, 478, 257, 4195, 295, 2699, 76, 19954, 13], "temperature": 0.0, "avg_logprob": -0.17795409504164997, "compression_ratio": 1.6932773109243697, "no_speech_prob": 1.8161972548114136e-06}, {"id": 608, "seek": 220300, "start": 2218.0, "end": 2220.0, "text": " And there are some people who say, well,", "tokens": [400, 456, 366, 512, 561, 567, 584, 11, 731, 11], "temperature": 0.0, "avg_logprob": -0.17795409504164997, "compression_ratio": 1.6932773109243697, "no_speech_prob": 1.8161972548114136e-06}, {"id": 609, "seek": 220300, "start": 2220.0, "end": 2224.0, "text": " it would be nice if we could make a rule that does this,", "tokens": [309, 576, 312, 1481, 498, 321, 727, 652, 257, 4978, 300, 775, 341, 11], "temperature": 0.0, "avg_logprob": -0.17795409504164997, "compression_ratio": 1.6932773109243697, "no_speech_prob": 1.8161972548114136e-06}, {"id": 610, "seek": 220300, "start": 2224.0, "end": 2226.0, "text": " or if there was this rule.", "tokens": [420, 498, 456, 390, 341, 4978, 13], "temperature": 0.0, "avg_logprob": -0.17795409504164997, "compression_ratio": 1.6932773109243697, "no_speech_prob": 1.8161972548114136e-06}, {"id": 611, "seek": 220300, "start": 2226.0, "end": 2229.0, "text": " And I'm like, yeah, I want that as well.", "tokens": [400, 286, 478, 411, 11, 1338, 11, 286, 528, 300, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.17795409504164997, "compression_ratio": 1.6932773109243697, "no_speech_prob": 1.8161972548114136e-06}, {"id": 612, "seek": 220300, "start": 2229.0, "end": 2232.0, "text": " Like the no news record fields, for instance.", "tokens": [1743, 264, 572, 2583, 2136, 7909, 11, 337, 5197, 13], "temperature": 0.0, "avg_logprob": -0.17795409504164997, "compression_ratio": 1.6932773109243697, "no_speech_prob": 1.8161972548114136e-06}, {"id": 613, "seek": 223200, "start": 2232.0, "end": 2235.0, "text": " Doesn't exist, would be amazing to have.", "tokens": [12955, 380, 2514, 11, 576, 312, 2243, 281, 362, 13], "temperature": 0.0, "avg_logprob": -0.21626876831054687, "compression_ratio": 1.5871559633027523, "no_speech_prob": 2.355203469051048e-05}, {"id": 614, "seek": 223200, "start": 2235.0, "end": 2241.0, "text": " And it's more likely that people that that will happen if you get me on board", "tokens": [400, 309, 311, 544, 3700, 300, 561, 300, 300, 486, 1051, 498, 291, 483, 385, 322, 3150], "temperature": 0.0, "avg_logprob": -0.21626876831054687, "compression_ratio": 1.5871559633027523, "no_speech_prob": 2.355203469051048e-05}, {"id": 615, "seek": 223200, "start": 2241.0, "end": 2246.0, "text": " with the, the intent of your, with your idea.", "tokens": [365, 264, 11, 264, 8446, 295, 428, 11, 365, 428, 1558, 13], "temperature": 0.0, "avg_logprob": -0.21626876831054687, "compression_ratio": 1.5871559633027523, "no_speech_prob": 2.355203469051048e-05}, {"id": 616, "seek": 223200, "start": 2246.0, "end": 2248.0, "text": " And me as a maintainer,", "tokens": [400, 385, 382, 257, 6909, 260, 11], "temperature": 0.0, "avg_logprob": -0.21626876831054687, "compression_ratio": 1.5871559633027523, "no_speech_prob": 2.355203469051048e-05}, {"id": 617, "seek": 223200, "start": 2248.0, "end": 2253.0, "text": " I want my project to work as best as possible for my users because empathy,", "tokens": [286, 528, 452, 1716, 281, 589, 382, 1151, 382, 1944, 337, 452, 5022, 570, 18701, 11], "temperature": 0.0, "avg_logprob": -0.21626876831054687, "compression_ratio": 1.5871559633027523, "no_speech_prob": 2.355203469051048e-05}, {"id": 618, "seek": 223200, "start": 2253.0, "end": 2255.0, "text": " I guess.", "tokens": [286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.21626876831054687, "compression_ratio": 1.5871559633027523, "no_speech_prob": 2.355203469051048e-05}, {"id": 619, "seek": 223200, "start": 2255.0, "end": 2260.0, "text": " So if there are bugs that are, that I can solve, then I will solve them.", "tokens": [407, 498, 456, 366, 15120, 300, 366, 11, 300, 286, 393, 5039, 11, 550, 286, 486, 5039, 552, 13], "temperature": 0.0, "avg_logprob": -0.21626876831054687, "compression_ratio": 1.5871559633027523, "no_speech_prob": 2.355203469051048e-05}, {"id": 620, "seek": 226000, "start": 2260.0, "end": 2263.0, "text": " If there is a pull request, even better.", "tokens": [759, 456, 307, 257, 2235, 5308, 11, 754, 1101, 13], "temperature": 0.0, "avg_logprob": -0.22308650207519531, "compression_ratio": 1.7740585774058577, "no_speech_prob": 2.902270352933556e-06}, {"id": 621, "seek": 226000, "start": 2263.0, "end": 2264.0, "text": " But yeah,", "tokens": [583, 1338, 11], "temperature": 0.0, "avg_logprob": -0.22308650207519531, "compression_ratio": 1.7740585774058577, "no_speech_prob": 2.902270352933556e-06}, {"id": 622, "seek": 226000, "start": 2264.0, "end": 2269.0, "text": " if you get me on board because I want my project to be as flawless as", "tokens": [498, 291, 483, 385, 322, 3150, 570, 286, 528, 452, 1716, 281, 312, 382, 45693, 382], "temperature": 0.0, "avg_logprob": -0.22308650207519531, "compression_ratio": 1.7740585774058577, "no_speech_prob": 2.902270352933556e-06}, {"id": 623, "seek": 226000, "start": 2269.0, "end": 2271.0, "text": " possible,", "tokens": [1944, 11], "temperature": 0.0, "avg_logprob": -0.22308650207519531, "compression_ratio": 1.7740585774058577, "no_speech_prob": 2.902270352933556e-06}, {"id": 624, "seek": 226000, "start": 2271.0, "end": 2272.0, "text": " and,", "tokens": [293, 11], "temperature": 0.0, "avg_logprob": -0.22308650207519531, "compression_ratio": 1.7740585774058577, "no_speech_prob": 2.902270352933556e-06}, {"id": 625, "seek": 226000, "start": 2272.0, "end": 2275.0, "text": " or you want a new feature that I also want because I want my product to be", "tokens": [420, 291, 528, 257, 777, 4111, 300, 286, 611, 528, 570, 286, 528, 452, 1674, 281, 312], "temperature": 0.0, "avg_logprob": -0.22308650207519531, "compression_ratio": 1.7740585774058577, "no_speech_prob": 2.902270352933556e-06}, {"id": 626, "seek": 226000, "start": 2275.0, "end": 2277.0, "text": " as useful as possible,", "tokens": [382, 4420, 382, 1944, 11], "temperature": 0.0, "avg_logprob": -0.22308650207519531, "compression_ratio": 1.7740585774058577, "no_speech_prob": 2.902270352933556e-06}, {"id": 627, "seek": 226000, "start": 2277.0, "end": 2281.0, "text": " then that's going to give you the best changes to, to get your idea in.", "tokens": [550, 300, 311, 516, 281, 976, 291, 264, 1151, 2962, 281, 11, 281, 483, 428, 1558, 294, 13], "temperature": 0.0, "avg_logprob": -0.22308650207519531, "compression_ratio": 1.7740585774058577, "no_speech_prob": 2.902270352933556e-06}, {"id": 628, "seek": 226000, "start": 2281.0, "end": 2285.0, "text": " I don't know how you can affect what I want though.", "tokens": [286, 500, 380, 458, 577, 291, 393, 3345, 437, 286, 528, 1673, 13], "temperature": 0.0, "avg_logprob": -0.22308650207519531, "compression_ratio": 1.7740585774058577, "no_speech_prob": 2.902270352933556e-06}, {"id": 629, "seek": 226000, "start": 2285.0, "end": 2289.0, "text": " But yeah, I guess that's part of the goals of the project as well.", "tokens": [583, 1338, 11, 286, 2041, 300, 311, 644, 295, 264, 5493, 295, 264, 1716, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.22308650207519531, "compression_ratio": 1.7740585774058577, "no_speech_prob": 2.902270352933556e-06}, {"id": 630, "seek": 228900, "start": 2289.0, "end": 2294.0, "text": " Like you probably know where I want to go in a way where you can kind of", "tokens": [1743, 291, 1391, 458, 689, 286, 528, 281, 352, 294, 257, 636, 689, 291, 393, 733, 295], "temperature": 0.0, "avg_logprob": -0.2166541667466753, "compression_ratio": 1.505, "no_speech_prob": 1.3418589333014097e-05}, {"id": 631, "seek": 228900, "start": 2294.0, "end": 2296.0, "text": " guess. And well,", "tokens": [2041, 13, 400, 731, 11], "temperature": 0.0, "avg_logprob": -0.2166541667466753, "compression_ratio": 1.505, "no_speech_prob": 1.3418589333014097e-05}, {"id": 632, "seek": 228900, "start": 2296.0, "end": 2300.0, "text": " through discussion we will figure out whether I do or I won't.", "tokens": [807, 5017, 321, 486, 2573, 484, 1968, 286, 360, 420, 286, 1582, 380, 13], "temperature": 0.0, "avg_logprob": -0.2166541667466753, "compression_ratio": 1.505, "no_speech_prob": 1.3418589333014097e-05}, {"id": 633, "seek": 228900, "start": 2300.0, "end": 2302.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2166541667466753, "compression_ratio": 1.505, "no_speech_prob": 1.3418589333014097e-05}, {"id": 634, "seek": 228900, "start": 2302.0, "end": 2305.0, "text": " I would say for me, like one,", "tokens": [286, 576, 584, 337, 385, 11, 411, 472, 11], "temperature": 0.0, "avg_logprob": -0.2166541667466753, "compression_ratio": 1.505, "no_speech_prob": 1.3418589333014097e-05}, {"id": 635, "seek": 228900, "start": 2305.0, "end": 2311.0, "text": " one thing that makes me far more likely to either roll up my sleeves and,", "tokens": [472, 551, 300, 1669, 385, 1400, 544, 3700, 281, 2139, 3373, 493, 452, 24555, 293, 11], "temperature": 0.0, "avg_logprob": -0.2166541667466753, "compression_ratio": 1.505, "no_speech_prob": 1.3418589333014097e-05}, {"id": 636, "seek": 228900, "start": 2311.0, "end": 2313.0, "text": " and implement something myself or,", "tokens": [293, 4445, 746, 2059, 420, 11], "temperature": 0.0, "avg_logprob": -0.2166541667466753, "compression_ratio": 1.505, "no_speech_prob": 1.3418589333014097e-05}, {"id": 637, "seek": 228900, "start": 2313.0, "end": 2314.0, "text": " or,", "tokens": [420, 11], "temperature": 0.0, "avg_logprob": -0.2166541667466753, "compression_ratio": 1.505, "no_speech_prob": 1.3418589333014097e-05}, {"id": 638, "seek": 231400, "start": 2314.0, "end": 2319.0, "text": " or be interested in somebody making a pull request about a particular feature", "tokens": [420, 312, 3102, 294, 2618, 1455, 257, 2235, 5308, 466, 257, 1729, 4111], "temperature": 0.0, "avg_logprob": -0.16633782159714472, "compression_ratio": 1.6177606177606179, "no_speech_prob": 1.520553541922709e-05}, {"id": 639, "seek": 231400, "start": 2319.0, "end": 2321.0, "text": " and wanting to whatever,", "tokens": [293, 7935, 281, 2035, 11], "temperature": 0.0, "avg_logprob": -0.16633782159714472, "compression_ratio": 1.6177606177606179, "no_speech_prob": 1.520553541922709e-05}, {"id": 640, "seek": 231400, "start": 2321.0, "end": 2328.0, "text": " have Slack messages coordinating that and that sort of thing is how much are", "tokens": [362, 37211, 7897, 37824, 300, 293, 300, 1333, 295, 551, 307, 577, 709, 366], "temperature": 0.0, "avg_logprob": -0.16633782159714472, "compression_ratio": 1.6177606177606179, "no_speech_prob": 1.520553541922709e-05}, {"id": 641, "seek": 231400, "start": 2328.0, "end": 2331.0, "text": " they invested in it? Like if somebody,", "tokens": [436, 13104, 294, 309, 30, 1743, 498, 2618, 11], "temperature": 0.0, "avg_logprob": -0.16633782159714472, "compression_ratio": 1.6177606177606179, "no_speech_prob": 1.520553541922709e-05}, {"id": 642, "seek": 231400, "start": 2331.0, "end": 2334.0, "text": " if somebody opens a GitHub issue and says, Hey,", "tokens": [498, 2618, 9870, 257, 23331, 2734, 293, 1619, 11, 1911, 11], "temperature": 0.0, "avg_logprob": -0.16633782159714472, "compression_ratio": 1.6177606177606179, "no_speech_prob": 1.520553541922709e-05}, {"id": 643, "seek": 231400, "start": 2334.0, "end": 2335.0, "text": " this would be really cool.", "tokens": [341, 576, 312, 534, 1627, 13], "temperature": 0.0, "avg_logprob": -0.16633782159714472, "compression_ratio": 1.6177606177606179, "no_speech_prob": 1.520553541922709e-05}, {"id": 644, "seek": 231400, "start": 2335.0, "end": 2339.0, "text": " And there's nothing laid out of like, what problem does this solve?", "tokens": [400, 456, 311, 1825, 9897, 484, 295, 411, 11, 437, 1154, 775, 341, 5039, 30], "temperature": 0.0, "avg_logprob": -0.16633782159714472, "compression_ratio": 1.6177606177606179, "no_speech_prob": 1.520553541922709e-05}, {"id": 645, "seek": 231400, "start": 2339.0, "end": 2343.0, "text": " Why do I have this problem? What are possible trade-offs?", "tokens": [1545, 360, 286, 362, 341, 1154, 30, 708, 366, 1944, 4923, 12, 19231, 30], "temperature": 0.0, "avg_logprob": -0.16633782159714472, "compression_ratio": 1.6177606177606179, "no_speech_prob": 1.520553541922709e-05}, {"id": 646, "seek": 234300, "start": 2343.0, "end": 2347.0, "text": " What are possible downsides to this new feature?", "tokens": [708, 366, 1944, 21554, 1875, 281, 341, 777, 4111, 30], "temperature": 0.0, "avg_logprob": -0.1600669679187593, "compression_ratio": 1.6582278481012658, "no_speech_prob": 4.069268106832169e-05}, {"id": 647, "seek": 234300, "start": 2347.0, "end": 2350.0, "text": " What are possible approaches and implementations?", "tokens": [708, 366, 1944, 11587, 293, 4445, 763, 30], "temperature": 0.0, "avg_logprob": -0.1600669679187593, "compression_ratio": 1.6582278481012658, "no_speech_prob": 4.069268106832169e-05}, {"id": 648, "seek": 234300, "start": 2350.0, "end": 2355.0, "text": " Like I'm not very likely to consider a feature request if it's just a sort of", "tokens": [1743, 286, 478, 406, 588, 3700, 281, 1949, 257, 4111, 5308, 498, 309, 311, 445, 257, 1333, 295], "temperature": 0.0, "avg_logprob": -0.1600669679187593, "compression_ratio": 1.6582278481012658, "no_speech_prob": 4.069268106832169e-05}, {"id": 649, "seek": 234300, "start": 2355.0, "end": 2359.0, "text": " not, if it's not giving me that motivation of why,", "tokens": [406, 11, 498, 309, 311, 406, 2902, 385, 300, 12335, 295, 983, 11], "temperature": 0.0, "avg_logprob": -0.1600669679187593, "compression_ratio": 1.6582278481012658, "no_speech_prob": 4.069268106832169e-05}, {"id": 650, "seek": 234300, "start": 2359.0, "end": 2361.0, "text": " why is this important? It's like, well,", "tokens": [983, 307, 341, 1021, 30, 467, 311, 411, 11, 731, 11], "temperature": 0.0, "avg_logprob": -0.1600669679187593, "compression_ratio": 1.6582278481012658, "no_speech_prob": 4.069268106832169e-05}, {"id": 651, "seek": 234300, "start": 2361.0, "end": 2365.0, "text": " if you don't care enough to really lay out what problem this is solving and,", "tokens": [498, 291, 500, 380, 1127, 1547, 281, 534, 2360, 484, 437, 1154, 341, 307, 12606, 293, 11], "temperature": 0.0, "avg_logprob": -0.1600669679187593, "compression_ratio": 1.6582278481012658, "no_speech_prob": 4.069268106832169e-05}, {"id": 652, "seek": 234300, "start": 2365.0, "end": 2369.0, "text": " and really dig into like, how would you do this?", "tokens": [293, 534, 2528, 666, 411, 11, 577, 576, 291, 360, 341, 30], "temperature": 0.0, "avg_logprob": -0.1600669679187593, "compression_ratio": 1.6582278481012658, "no_speech_prob": 4.069268106832169e-05}, {"id": 653, "seek": 236900, "start": 2369.0, "end": 2373.0, "text": " Why should I be interested enough to do that for you to,", "tokens": [1545, 820, 286, 312, 3102, 1547, 281, 360, 300, 337, 291, 281, 11], "temperature": 0.0, "avg_logprob": -0.23393517871235692, "compression_ratio": 1.5598086124401913, "no_speech_prob": 9.665781362855341e-06}, {"id": 654, "seek": 236900, "start": 2373.0, "end": 2377.0, "text": " to flesh out this feature idea more deeply?", "tokens": [281, 12497, 484, 341, 4111, 1558, 544, 8760, 30], "temperature": 0.0, "avg_logprob": -0.23393517871235692, "compression_ratio": 1.5598086124401913, "no_speech_prob": 9.665781362855341e-06}, {"id": 655, "seek": 236900, "start": 2377.0, "end": 2381.0, "text": " So I'm probably not going to prioritize that over something else where someone", "tokens": [407, 286, 478, 1391, 406, 516, 281, 25164, 300, 670, 746, 1646, 689, 1580], "temperature": 0.0, "avg_logprob": -0.23393517871235692, "compression_ratio": 1.5598086124401913, "no_speech_prob": 9.665781362855341e-06}, {"id": 656, "seek": 236900, "start": 2381.0, "end": 2382.0, "text": " has done that.", "tokens": [575, 1096, 300, 13], "temperature": 0.0, "avg_logprob": -0.23393517871235692, "compression_ratio": 1.5598086124401913, "no_speech_prob": 9.665781362855341e-06}, {"id": 657, "seek": 236900, "start": 2382.0, "end": 2387.0, "text": " Are you saying that if you get a issue saying as a title,", "tokens": [2014, 291, 1566, 300, 498, 291, 483, 257, 2734, 1566, 382, 257, 4876, 11], "temperature": 0.0, "avg_logprob": -0.23393517871235692, "compression_ratio": 1.5598086124401913, "no_speech_prob": 9.665781362855341e-06}, {"id": 658, "seek": 236900, "start": 2387.0, "end": 2392.0, "text": " add feature X and that the comments of,", "tokens": [909, 4111, 1783, 293, 300, 264, 3053, 295, 11], "temperature": 0.0, "avg_logprob": -0.23393517871235692, "compression_ratio": 1.5598086124401913, "no_speech_prob": 9.665781362855341e-06}, {"id": 659, "seek": 236900, "start": 2392.0, "end": 2396.0, "text": " of the issue says no description,", "tokens": [295, 264, 2734, 1619, 572, 3855, 11], "temperature": 0.0, "avg_logprob": -0.23393517871235692, "compression_ratio": 1.5598086124401913, "no_speech_prob": 9.665781362855341e-06}, {"id": 660, "seek": 239600, "start": 2396.0, "end": 2401.0, "text": " the when it's empty, but you're not getting passionate.", "tokens": [264, 562, 309, 311, 6707, 11, 457, 291, 434, 406, 1242, 11410, 13], "temperature": 0.0, "avg_logprob": -0.2204854876496071, "compression_ratio": 1.523076923076923, "no_speech_prob": 1.3844113709637895e-05}, {"id": 661, "seek": 239600, "start": 2401.0, "end": 2406.0, "text": " Like you don't have a fire burning and causing you to roll up your", "tokens": [1743, 291, 500, 380, 362, 257, 2610, 9488, 293, 9853, 291, 281, 3373, 493, 428], "temperature": 0.0, "avg_logprob": -0.2204854876496071, "compression_ratio": 1.523076923076923, "no_speech_prob": 1.3844113709637895e-05}, {"id": 662, "seek": 239600, "start": 2406.0, "end": 2409.0, "text": " sleeves and get to work. Really?", "tokens": [24555, 293, 483, 281, 589, 13, 4083, 30], "temperature": 0.0, "avg_logprob": -0.2204854876496071, "compression_ratio": 1.523076923076923, "no_speech_prob": 1.3844113709637895e-05}, {"id": 663, "seek": 239600, "start": 2409.0, "end": 2414.0, "text": " I say that not, not just as a, like, you know, old man yells at cloud.", "tokens": [286, 584, 300, 406, 11, 406, 445, 382, 257, 11, 411, 11, 291, 458, 11, 1331, 587, 48543, 412, 4588, 13], "temperature": 0.0, "avg_logprob": -0.2204854876496071, "compression_ratio": 1.523076923076923, "no_speech_prob": 1.3844113709637895e-05}, {"id": 664, "seek": 239600, "start": 2415.0, "end": 2420.0, "text": " Although partially I also say it is that, but I also say that as like,", "tokens": [5780, 18886, 286, 611, 584, 309, 307, 300, 11, 457, 286, 611, 584, 300, 382, 411, 11], "temperature": 0.0, "avg_logprob": -0.2204854876496071, "compression_ratio": 1.523076923076923, "no_speech_prob": 1.3844113709637895e-05}, {"id": 665, "seek": 242000, "start": 2420.0, "end": 2424.0, "text": " and I actually make an attempt to,", "tokens": [293, 286, 767, 652, 364, 5217, 281, 11], "temperature": 0.0, "avg_logprob": -0.17489194033438699, "compression_ratio": 1.7601626016260163, "no_speech_prob": 8.013125807337929e-06}, {"id": 666, "seek": 242000, "start": 2424.0, "end": 2427.0, "text": " to communicate those types of things on issues and say, Hey,", "tokens": [281, 7890, 729, 3467, 295, 721, 322, 2663, 293, 584, 11, 1911, 11], "temperature": 0.0, "avg_logprob": -0.17489194033438699, "compression_ratio": 1.7601626016260163, "no_speech_prob": 8.013125807337929e-06}, {"id": 667, "seek": 242000, "start": 2427.0, "end": 2429.0, "text": " if you think this is interesting, I'm,", "tokens": [498, 291, 519, 341, 307, 1880, 11, 286, 478, 11], "temperature": 0.0, "avg_logprob": -0.17489194033438699, "compression_ratio": 1.7601626016260163, "no_speech_prob": 8.013125807337929e-06}, {"id": 668, "seek": 242000, "start": 2429.0, "end": 2432.0, "text": " I'm willing to like accept a pull requests.", "tokens": [286, 478, 4950, 281, 411, 3241, 257, 2235, 12475, 13], "temperature": 0.0, "avg_logprob": -0.17489194033438699, "compression_ratio": 1.7601626016260163, "no_speech_prob": 8.013125807337929e-06}, {"id": 669, "seek": 242000, "start": 2432.0, "end": 2436.0, "text": " If you can help me understand like what problem this would solve and how you", "tokens": [759, 291, 393, 854, 385, 1223, 411, 437, 1154, 341, 576, 5039, 293, 577, 291], "temperature": 0.0, "avg_logprob": -0.17489194033438699, "compression_ratio": 1.7601626016260163, "no_speech_prob": 8.013125807337929e-06}, {"id": 670, "seek": 242000, "start": 2436.0, "end": 2439.0, "text": " would do this and how the trade-offs are going,", "tokens": [576, 360, 341, 293, 577, 264, 4923, 12, 19231, 366, 516, 11], "temperature": 0.0, "avg_logprob": -0.17489194033438699, "compression_ratio": 1.7601626016260163, "no_speech_prob": 8.013125807337929e-06}, {"id": 671, "seek": 242000, "start": 2439.0, "end": 2443.0, "text": " going to look and how it's going to interfere or not interfere with this", "tokens": [516, 281, 574, 293, 577, 309, 311, 516, 281, 23946, 420, 406, 23946, 365, 341], "temperature": 0.0, "avg_logprob": -0.17489194033438699, "compression_ratio": 1.7601626016260163, "no_speech_prob": 8.013125807337929e-06}, {"id": 672, "seek": 242000, "start": 2443.0, "end": 2447.0, "text": " feature, you know? So I try to communicate those things.", "tokens": [4111, 11, 291, 458, 30, 407, 286, 853, 281, 7890, 729, 721, 13], "temperature": 0.0, "avg_logprob": -0.17489194033438699, "compression_ratio": 1.7601626016260163, "no_speech_prob": 8.013125807337929e-06}, {"id": 673, "seek": 244700, "start": 2447.0, "end": 2451.0, "text": " And actually pretty often people do say, okay, great. Yeah.", "tokens": [400, 767, 1238, 2049, 561, 360, 584, 11, 1392, 11, 869, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.1768931802713646, "compression_ratio": 1.649805447470817, "no_speech_prob": 1.1125054697913583e-05}, {"id": 674, "seek": 244700, "start": 2451.0, "end": 2452.0, "text": " I'd be happy to do that.", "tokens": [286, 1116, 312, 2055, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.1768931802713646, "compression_ratio": 1.649805447470817, "no_speech_prob": 1.1125054697913583e-05}, {"id": 675, "seek": 244700, "start": 2452.0, "end": 2457.0, "text": " And they write out super thoughtful comments and get some prior art and show", "tokens": [400, 436, 2464, 484, 1687, 21566, 3053, 293, 483, 512, 4059, 1523, 293, 855], "temperature": 0.0, "avg_logprob": -0.1768931802713646, "compression_ratio": 1.649805447470817, "no_speech_prob": 1.1125054697913583e-05}, {"id": 676, "seek": 244700, "start": 2458.0, "end": 2463.0, "text": " me how other projects have solved this problem and maybe make a pull request", "tokens": [385, 577, 661, 4455, 362, 13041, 341, 1154, 293, 1310, 652, 257, 2235, 5308], "temperature": 0.0, "avg_logprob": -0.1768931802713646, "compression_ratio": 1.649805447470817, "no_speech_prob": 1.1125054697913583e-05}, {"id": 677, "seek": 244700, "start": 2463.0, "end": 2467.0, "text": " or make a pull request that has some failing tests. So it,", "tokens": [420, 652, 257, 2235, 5308, 300, 575, 512, 18223, 6921, 13, 407, 309, 11], "temperature": 0.0, "avg_logprob": -0.1768931802713646, "compression_ratio": 1.649805447470817, "no_speech_prob": 1.1125054697913583e-05}, {"id": 678, "seek": 244700, "start": 2468.0, "end": 2472.0, "text": " I think giving users the opportunity to do that and communicating like what,", "tokens": [286, 519, 2902, 5022, 264, 2650, 281, 360, 300, 293, 17559, 411, 437, 11], "temperature": 0.0, "avg_logprob": -0.1768931802713646, "compression_ratio": 1.649805447470817, "no_speech_prob": 1.1125054697913583e-05}, {"id": 679, "seek": 244700, "start": 2472.0, "end": 2474.0, "text": " what you need as a maintainer is really good too,", "tokens": [437, 291, 643, 382, 257, 6909, 260, 307, 534, 665, 886, 11], "temperature": 0.0, "avg_logprob": -0.1768931802713646, "compression_ratio": 1.649805447470817, "no_speech_prob": 1.1125054697913583e-05}, {"id": 680, "seek": 247400, "start": 2474.0, "end": 2477.0, "text": " because at the end of the day, as you said, like, I mean,", "tokens": [570, 412, 264, 917, 295, 264, 786, 11, 382, 291, 848, 11, 411, 11, 286, 914, 11], "temperature": 0.0, "avg_logprob": -0.1476684840379563, "compression_ratio": 1.9260869565217391, "no_speech_prob": 9.51577749219723e-06}, {"id": 681, "seek": 247400, "start": 2477.0, "end": 2482.0, "text": " I think open source is a tool for making our projects more accessible,", "tokens": [286, 519, 1269, 4009, 307, 257, 2290, 337, 1455, 527, 4455, 544, 9515, 11], "temperature": 0.0, "avg_logprob": -0.1476684840379563, "compression_ratio": 1.9260869565217391, "no_speech_prob": 9.51577749219723e-06}, {"id": 682, "seek": 247400, "start": 2482.0, "end": 2487.0, "text": " but also like helping people more and contributions are a tool for that.", "tokens": [457, 611, 411, 4315, 561, 544, 293, 15725, 366, 257, 2290, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.1476684840379563, "compression_ratio": 1.9260869565217391, "no_speech_prob": 9.51577749219723e-06}, {"id": 683, "seek": 247400, "start": 2487.0, "end": 2490.0, "text": " And the way we build our open source projects,", "tokens": [400, 264, 636, 321, 1322, 527, 1269, 4009, 4455, 11], "temperature": 0.0, "avg_logprob": -0.1476684840379563, "compression_ratio": 1.9260869565217391, "no_speech_prob": 9.51577749219723e-06}, {"id": 684, "seek": 247400, "start": 2490.0, "end": 2493.0, "text": " the way we communicate in our open source projects are tools for that,", "tokens": [264, 636, 321, 7890, 294, 527, 1269, 4009, 4455, 366, 3873, 337, 300, 11], "temperature": 0.0, "avg_logprob": -0.1476684840379563, "compression_ratio": 1.9260869565217391, "no_speech_prob": 9.51577749219723e-06}, {"id": 685, "seek": 247400, "start": 2493.0, "end": 2495.0, "text": " because at the end of the day,", "tokens": [570, 412, 264, 917, 295, 264, 786, 11], "temperature": 0.0, "avg_logprob": -0.1476684840379563, "compression_ratio": 1.9260869565217391, "no_speech_prob": 9.51577749219723e-06}, {"id": 686, "seek": 247400, "start": 2495.0, "end": 2499.0, "text": " we're putting time into this because there's something we care about putting", "tokens": [321, 434, 3372, 565, 666, 341, 570, 456, 311, 746, 321, 1127, 466, 3372], "temperature": 0.0, "avg_logprob": -0.1476684840379563, "compression_ratio": 1.9260869565217391, "no_speech_prob": 9.51577749219723e-06}, {"id": 687, "seek": 247400, "start": 2499.0, "end": 2500.0, "text": " into the world.", "tokens": [666, 264, 1002, 13], "temperature": 0.0, "avg_logprob": -0.1476684840379563, "compression_ratio": 1.9260869565217391, "no_speech_prob": 9.51577749219723e-06}, {"id": 688, "seek": 250000, "start": 2500.0, "end": 2505.0, "text": " We care about being able to have more guarantees in an Elm project by doing", "tokens": [492, 1127, 466, 885, 1075, 281, 362, 544, 32567, 294, 364, 2699, 76, 1716, 538, 884], "temperature": 0.0, "avg_logprob": -0.201575870513916, "compression_ratio": 1.6680327868852458, "no_speech_prob": 1.0288897101418115e-05}, {"id": 689, "seek": 250000, "start": 2505.0, "end": 2508.0, "text": " more powerful static analysis. That's like,", "tokens": [544, 4005, 13437, 5215, 13, 663, 311, 411, 11], "temperature": 0.0, "avg_logprob": -0.201575870513916, "compression_ratio": 1.6680327868852458, "no_speech_prob": 1.0288897101418115e-05}, {"id": 690, "seek": 250000, "start": 2508.0, "end": 2513.0, "text": " I believe that's something that you care about at your core and managing an", "tokens": [286, 1697, 300, 311, 746, 300, 291, 1127, 466, 412, 428, 4965, 293, 11642, 364], "temperature": 0.0, "avg_logprob": -0.201575870513916, "compression_ratio": 1.6680327868852458, "no_speech_prob": 1.0288897101418115e-05}, {"id": 691, "seek": 250000, "start": 2514.0, "end": 2518.0, "text": " open source project effectively leverages you to be able to do that better,", "tokens": [1269, 4009, 1716, 8659, 12451, 1660, 291, 281, 312, 1075, 281, 360, 300, 1101, 11], "temperature": 0.0, "avg_logprob": -0.201575870513916, "compression_ratio": 1.6680327868852458, "no_speech_prob": 1.0288897101418115e-05}, {"id": 692, "seek": 250000, "start": 2518.0, "end": 2522.0, "text": " to, to put that vision into the world in a more effective way.", "tokens": [281, 11, 281, 829, 300, 5201, 666, 264, 1002, 294, 257, 544, 4942, 636, 13], "temperature": 0.0, "avg_logprob": -0.201575870513916, "compression_ratio": 1.6680327868852458, "no_speech_prob": 1.0288897101418115e-05}, {"id": 693, "seek": 250000, "start": 2522.0, "end": 2528.0, "text": " So I think communicating can help people do that. And I think also like,", "tokens": [407, 286, 519, 17559, 393, 854, 561, 360, 300, 13, 400, 286, 519, 611, 411, 11], "temperature": 0.0, "avg_logprob": -0.201575870513916, "compression_ratio": 1.6680327868852458, "no_speech_prob": 1.0288897101418115e-05}, {"id": 694, "seek": 252800, "start": 2528.0, "end": 2532.0, "text": " so I often think about like the role of a,", "tokens": [370, 286, 2049, 519, 466, 411, 264, 3090, 295, 257, 11], "temperature": 0.0, "avg_logprob": -0.18229527376136, "compression_ratio": 1.6564102564102565, "no_speech_prob": 2.6273286493960768e-05}, {"id": 695, "seek": 252800, "start": 2532.0, "end": 2537.0, "text": " an open source maintainer or lead on an open source project as kind of like a", "tokens": [364, 1269, 4009, 6909, 260, 420, 1477, 322, 364, 1269, 4009, 1716, 382, 733, 295, 411, 257], "temperature": 0.0, "avg_logprob": -0.18229527376136, "compression_ratio": 1.6564102564102565, "no_speech_prob": 2.6273286493960768e-05}, {"id": 696, "seek": 252800, "start": 2537.0, "end": 2542.0, "text": " CTO for, for a mini company. And as that company scales,", "tokens": [383, 15427, 337, 11, 337, 257, 8382, 2237, 13, 400, 382, 300, 2237, 17408, 11], "temperature": 0.0, "avg_logprob": -0.18229527376136, "compression_ratio": 1.6564102564102565, "no_speech_prob": 2.6273286493960768e-05}, {"id": 697, "seek": 252800, "start": 2542.0, "end": 2546.0, "text": " the role of the CTO also changes. So, you know,", "tokens": [264, 3090, 295, 264, 383, 15427, 611, 2962, 13, 407, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.18229527376136, "compression_ratio": 1.6564102564102565, "no_speech_prob": 2.6273286493960768e-05}, {"id": 698, "seek": 252800, "start": 2546.0, "end": 2551.0, "text": " if you're CTO in a company of two, then,", "tokens": [498, 291, 434, 383, 15427, 294, 257, 2237, 295, 732, 11, 550, 11], "temperature": 0.0, "avg_logprob": -0.18229527376136, "compression_ratio": 1.6564102564102565, "no_speech_prob": 2.6273286493960768e-05}, {"id": 699, "seek": 252800, "start": 2551.0, "end": 2553.0, "text": " then you're, you're the developer of the company, right?", "tokens": [550, 291, 434, 11, 291, 434, 264, 10754, 295, 264, 2237, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18229527376136, "compression_ratio": 1.6564102564102565, "no_speech_prob": 2.6273286493960768e-05}, {"id": 700, "seek": 255300, "start": 2553.0, "end": 2558.0, "text": " You're also making technical decisions that if that company were to take off", "tokens": [509, 434, 611, 1455, 6191, 5327, 300, 498, 300, 2237, 645, 281, 747, 766], "temperature": 0.0, "avg_logprob": -0.17490988361592197, "compression_ratio": 1.7887931034482758, "no_speech_prob": 2.5465205908403732e-05}, {"id": 701, "seek": 255300, "start": 2558.0, "end": 2561.0, "text": " and become a company with a hundred developers, a thousand developers,", "tokens": [293, 1813, 257, 2237, 365, 257, 3262, 8849, 11, 257, 4714, 8849, 11], "temperature": 0.0, "avg_logprob": -0.17490988361592197, "compression_ratio": 1.7887931034482758, "no_speech_prob": 2.5465205908403732e-05}, {"id": 702, "seek": 255300, "start": 2562.0, "end": 2567.0, "text": " those technical decisions are going to impact the long-term roadmap for the", "tokens": [729, 6191, 5327, 366, 516, 281, 2712, 264, 938, 12, 7039, 35738, 337, 264], "temperature": 0.0, "avg_logprob": -0.17490988361592197, "compression_ratio": 1.7887931034482758, "no_speech_prob": 2.5465205908403732e-05}, {"id": 703, "seek": 255300, "start": 2567.0, "end": 2571.0, "text": " company and the long-term success technically of the project.", "tokens": [2237, 293, 264, 938, 12, 7039, 2245, 12120, 295, 264, 1716, 13], "temperature": 0.0, "avg_logprob": -0.17490988361592197, "compression_ratio": 1.7887931034482758, "no_speech_prob": 2.5465205908403732e-05}, {"id": 704, "seek": 255300, "start": 2572.0, "end": 2577.0, "text": " So that's the hat I'm wearing early on in an open source project when I'm", "tokens": [407, 300, 311, 264, 2385, 286, 478, 4769, 2440, 322, 294, 364, 1269, 4009, 1716, 562, 286, 478], "temperature": 0.0, "avg_logprob": -0.17490988361592197, "compression_ratio": 1.7887931034482758, "no_speech_prob": 2.5465205908403732e-05}, {"id": 705, "seek": 255300, "start": 2578.0, "end": 2580.0, "text": " maybe not even sure it's going to be successful, right?", "tokens": [1310, 406, 754, 988, 309, 311, 516, 281, 312, 4406, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.17490988361592197, "compression_ratio": 1.7887931034482758, "no_speech_prob": 2.5465205908403732e-05}, {"id": 706, "seek": 258000, "start": 2580.0, "end": 2584.0, "text": " Maybe it'll be a failed startup. Maybe it'll be an open source project that", "tokens": [2704, 309, 603, 312, 257, 7612, 18578, 13, 2704, 309, 603, 312, 364, 1269, 4009, 1716, 300], "temperature": 0.0, "avg_logprob": -0.1605651750477082, "compression_ratio": 1.6767241379310345, "no_speech_prob": 3.591022323234938e-05}, {"id": 707, "seek": 258000, "start": 2584.0, "end": 2588.0, "text": " nobody uses and, and that can happen and that's okay. But,", "tokens": [5079, 4960, 293, 11, 293, 300, 393, 1051, 293, 300, 311, 1392, 13, 583, 11], "temperature": 0.0, "avg_logprob": -0.1605651750477082, "compression_ratio": 1.6767241379310345, "no_speech_prob": 3.591022323234938e-05}, {"id": 708, "seek": 258000, "start": 2589.0, "end": 2593.0, "text": " that's the hat I'm wearing when I'm early on in an open source project.", "tokens": [300, 311, 264, 2385, 286, 478, 4769, 562, 286, 478, 2440, 322, 294, 364, 1269, 4009, 1716, 13], "temperature": 0.0, "avg_logprob": -0.1605651750477082, "compression_ratio": 1.6767241379310345, "no_speech_prob": 3.591022323234938e-05}, {"id": 709, "seek": 258000, "start": 2593.0, "end": 2595.0, "text": " And as the project scales,", "tokens": [400, 382, 264, 1716, 17408, 11], "temperature": 0.0, "avg_logprob": -0.1605651750477082, "compression_ratio": 1.6767241379310345, "no_speech_prob": 3.591022323234938e-05}, {"id": 710, "seek": 258000, "start": 2595.0, "end": 2602.0, "text": " I tend to play a more strategic role and I'm thinking about how do I make", "tokens": [286, 3928, 281, 862, 257, 544, 10924, 3090, 293, 286, 478, 1953, 466, 577, 360, 286, 652], "temperature": 0.0, "avg_logprob": -0.1605651750477082, "compression_ratio": 1.6767241379310345, "no_speech_prob": 3.591022323234938e-05}, {"id": 711, "seek": 258000, "start": 2602.0, "end": 2606.0, "text": " technical decisions? How do I help mentor people? You know,", "tokens": [6191, 5327, 30, 1012, 360, 286, 854, 14478, 561, 30, 509, 458, 11], "temperature": 0.0, "avg_logprob": -0.1605651750477082, "compression_ratio": 1.6767241379310345, "no_speech_prob": 3.591022323234938e-05}, {"id": 712, "seek": 258000, "start": 2606.0, "end": 2607.0, "text": " how do I get on call?", "tokens": [577, 360, 286, 483, 322, 818, 30], "temperature": 0.0, "avg_logprob": -0.1605651750477082, "compression_ratio": 1.6767241379310345, "no_speech_prob": 3.591022323234938e-05}, {"id": 713, "seek": 260700, "start": 2607.0, "end": 2611.0, "text": " Like maybe I'm going to be spending more time getting on video calls with", "tokens": [1743, 1310, 286, 478, 516, 281, 312, 6434, 544, 565, 1242, 322, 960, 5498, 365], "temperature": 0.0, "avg_logprob": -0.1855521447879752, "compression_ratio": 1.6458333333333333, "no_speech_prob": 6.854130333522335e-06}, {"id": 714, "seek": 260700, "start": 2611.0, "end": 2614.0, "text": " people who want to make contributions to help them,", "tokens": [561, 567, 528, 281, 652, 15725, 281, 854, 552, 11], "temperature": 0.0, "avg_logprob": -0.1855521447879752, "compression_ratio": 1.6458333333333333, "no_speech_prob": 6.854130333522335e-06}, {"id": 715, "seek": 260700, "start": 2614.0, "end": 2620.0, "text": " to pair with them to help talk through certain trade-offs or technical", "tokens": [281, 6119, 365, 552, 281, 854, 751, 807, 1629, 4923, 12, 19231, 420, 6191], "temperature": 0.0, "avg_logprob": -0.1855521447879752, "compression_ratio": 1.6458333333333333, "no_speech_prob": 6.854130333522335e-06}, {"id": 716, "seek": 260700, "start": 2620.0, "end": 2621.0, "text": " questions.", "tokens": [1651, 13], "temperature": 0.0, "avg_logprob": -0.1855521447879752, "compression_ratio": 1.6458333333333333, "no_speech_prob": 6.854130333522335e-06}, {"id": 717, "seek": 260700, "start": 2621.0, "end": 2627.0, "text": " And I'm also like thinking really hard about high level strategic choices,", "tokens": [400, 286, 478, 611, 411, 1953, 534, 1152, 466, 1090, 1496, 10924, 7994, 11], "temperature": 0.0, "avg_logprob": -0.1855521447879752, "compression_ratio": 1.6458333333333333, "no_speech_prob": 6.854130333522335e-06}, {"id": 718, "seek": 260700, "start": 2627.0, "end": 2629.0, "text": " like what's our testing strategy going to be?", "tokens": [411, 437, 311, 527, 4997, 5206, 516, 281, 312, 30], "temperature": 0.0, "avg_logprob": -0.1855521447879752, "compression_ratio": 1.6458333333333333, "no_speech_prob": 6.854130333522335e-06}, {"id": 719, "seek": 260700, "start": 2629.0, "end": 2633.0, "text": " Are we doing some snapshot tests? Are we doing fuzz tests on this?", "tokens": [2014, 321, 884, 512, 30163, 6921, 30, 2014, 321, 884, 283, 16740, 6921, 322, 341, 30], "temperature": 0.0, "avg_logprob": -0.1855521447879752, "compression_ratio": 1.6458333333333333, "no_speech_prob": 6.854130333522335e-06}, {"id": 720, "seek": 263300, "start": 2633.0, "end": 2640.0, "text": " Like what's going to ensure quality and make that high bar for anybody", "tokens": [1743, 437, 311, 516, 281, 5586, 3125, 293, 652, 300, 1090, 2159, 337, 4472], "temperature": 0.0, "avg_logprob": -0.17301235367766524, "compression_ratio": 1.6611570247933884, "no_speech_prob": 2.7108344511361793e-05}, {"id": 721, "seek": 263300, "start": 2640.0, "end": 2643.0, "text": " contributing to it? Not just me, because if it's a,", "tokens": [19270, 281, 309, 30, 1726, 445, 385, 11, 570, 498, 309, 311, 257, 11], "temperature": 0.0, "avg_logprob": -0.17301235367766524, "compression_ratio": 1.6611570247933884, "no_speech_prob": 2.7108344511361793e-05}, {"id": 722, "seek": 263300, "start": 2643.0, "end": 2646.0, "text": " if it's a big project that a lot of people depend on,", "tokens": [498, 309, 311, 257, 955, 1716, 300, 257, 688, 295, 561, 5672, 322, 11], "temperature": 0.0, "avg_logprob": -0.17301235367766524, "compression_ratio": 1.6611570247933884, "no_speech_prob": 2.7108344511361793e-05}, {"id": 723, "seek": 263300, "start": 2646.0, "end": 2649.0, "text": " I want to make it easy for a lot of people to contribute to it.", "tokens": [286, 528, 281, 652, 309, 1858, 337, 257, 688, 295, 561, 281, 10586, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.17301235367766524, "compression_ratio": 1.6611570247933884, "no_speech_prob": 2.7108344511361793e-05}, {"id": 724, "seek": 263300, "start": 2649.0, "end": 2653.0, "text": " And so that's something I'm really focusing a lot of my time on that.", "tokens": [400, 370, 300, 311, 746, 286, 478, 534, 8416, 257, 688, 295, 452, 565, 322, 300, 13], "temperature": 0.0, "avg_logprob": -0.17301235367766524, "compression_ratio": 1.6611570247933884, "no_speech_prob": 2.7108344511361793e-05}, {"id": 725, "seek": 263300, "start": 2653.0, "end": 2659.0, "text": " I think I uniquely need to be focused on as the CTO of the open source", "tokens": [286, 519, 286, 31474, 643, 281, 312, 5178, 322, 382, 264, 383, 15427, 295, 264, 1269, 4009], "temperature": 0.0, "avg_logprob": -0.17301235367766524, "compression_ratio": 1.6611570247933884, "no_speech_prob": 2.7108344511361793e-05}, {"id": 726, "seek": 263300, "start": 2659.0, "end": 2661.0, "text": " project as it grows.", "tokens": [1716, 382, 309, 13156, 13], "temperature": 0.0, "avg_logprob": -0.17301235367766524, "compression_ratio": 1.6611570247933884, "no_speech_prob": 2.7108344511361793e-05}, {"id": 727, "seek": 266100, "start": 2661.0, "end": 2666.0, "text": " Right. So when you get someone to contribute a pull request,", "tokens": [1779, 13, 407, 562, 291, 483, 1580, 281, 10586, 257, 2235, 5308, 11], "temperature": 0.0, "avg_logprob": -0.18360712217248004, "compression_ratio": 1.674641148325359, "no_speech_prob": 3.1200364901451394e-05}, {"id": 728, "seek": 266100, "start": 2666.0, "end": 2670.0, "text": " how much do you care about like the quality of the contribution?", "tokens": [577, 709, 360, 291, 1127, 466, 411, 264, 3125, 295, 264, 13150, 30], "temperature": 0.0, "avg_logprob": -0.18360712217248004, "compression_ratio": 1.674641148325359, "no_speech_prob": 3.1200364901451394e-05}, {"id": 729, "seek": 266100, "start": 2670.0, "end": 2673.0, "text": " What are the types of things you're thinking about with quality?", "tokens": [708, 366, 264, 3467, 295, 721, 291, 434, 1953, 466, 365, 3125, 30], "temperature": 0.0, "avg_logprob": -0.18360712217248004, "compression_ratio": 1.674641148325359, "no_speech_prob": 3.1200364901451394e-05}, {"id": 730, "seek": 266100, "start": 2673.0, "end": 2674.0, "text": " I'm curious.", "tokens": [286, 478, 6369, 13], "temperature": 0.0, "avg_logprob": -0.18360712217248004, "compression_ratio": 1.674641148325359, "no_speech_prob": 3.1200364901451394e-05}, {"id": 731, "seek": 266100, "start": 2674.0, "end": 2677.0, "text": " So whenever you get a pull request,", "tokens": [407, 5699, 291, 483, 257, 2235, 5308, 11], "temperature": 0.0, "avg_logprob": -0.18360712217248004, "compression_ratio": 1.674641148325359, "no_speech_prob": 3.1200364901451394e-05}, {"id": 732, "seek": 266100, "start": 2677.0, "end": 2683.0, "text": " you will wonder a few things like is it code? Does a code look okay?", "tokens": [291, 486, 2441, 257, 1326, 721, 411, 307, 309, 3089, 30, 4402, 257, 3089, 574, 1392, 30], "temperature": 0.0, "avg_logprob": -0.18360712217248004, "compression_ratio": 1.674641148325359, "no_speech_prob": 3.1200364901451394e-05}, {"id": 733, "seek": 266100, "start": 2683.0, "end": 2686.0, "text": " Does this handle all the different cases?", "tokens": [4402, 341, 4813, 439, 264, 819, 3331, 30], "temperature": 0.0, "avg_logprob": -0.18360712217248004, "compression_ratio": 1.674641148325359, "no_speech_prob": 3.1200364901451394e-05}, {"id": 734, "seek": 268600, "start": 2686.0, "end": 2692.0, "text": " Are there any obvious bugs that can be found? Is it co-style okay?", "tokens": [2014, 456, 604, 6322, 15120, 300, 393, 312, 1352, 30, 1119, 309, 598, 12, 15014, 1392, 30], "temperature": 0.0, "avg_logprob": -0.20758433622472428, "compression_ratio": 1.6414141414141414, "no_speech_prob": 2.111081084876787e-05}, {"id": 735, "seek": 268600, "start": 2692.0, "end": 2696.0, "text": " Like all those things. Which ones do you care about?", "tokens": [1743, 439, 729, 721, 13, 3013, 2306, 360, 291, 1127, 466, 30], "temperature": 0.0, "avg_logprob": -0.20758433622472428, "compression_ratio": 1.6414141414141414, "no_speech_prob": 2.111081084876787e-05}, {"id": 736, "seek": 268600, "start": 2696.0, "end": 2698.0, "text": " Which ones do you not care about?", "tokens": [3013, 2306, 360, 291, 406, 1127, 466, 30], "temperature": 0.0, "avg_logprob": -0.20758433622472428, "compression_ratio": 1.6414141414141414, "no_speech_prob": 2.111081084876787e-05}, {"id": 737, "seek": 268600, "start": 2698.0, "end": 2704.0, "text": " Yeah. I tend to be fairly trusting about contributions.", "tokens": [865, 13, 286, 3928, 281, 312, 6457, 28235, 466, 15725, 13], "temperature": 0.0, "avg_logprob": -0.20758433622472428, "compression_ratio": 1.6414141414141414, "no_speech_prob": 2.111081084876787e-05}, {"id": 738, "seek": 268600, "start": 2704.0, "end": 2710.0, "text": " I look for ways that a contributor can show me that they're,", "tokens": [286, 574, 337, 2098, 300, 257, 42859, 393, 855, 385, 300, 436, 434, 11], "temperature": 0.0, "avg_logprob": -0.20758433622472428, "compression_ratio": 1.6414141414141414, "no_speech_prob": 2.111081084876787e-05}, {"id": 739, "seek": 268600, "start": 2710.0, "end": 2714.0, "text": " that they're taking ownership of those considerations.", "tokens": [300, 436, 434, 1940, 15279, 295, 729, 24070, 13], "temperature": 0.0, "avg_logprob": -0.20758433622472428, "compression_ratio": 1.6414141414141414, "no_speech_prob": 2.111081084876787e-05}, {"id": 740, "seek": 271400, "start": 2714.0, "end": 2719.0, "text": " And if I'm not being given signs of that,", "tokens": [400, 498, 286, 478, 406, 885, 2212, 7880, 295, 300, 11], "temperature": 0.0, "avg_logprob": -0.17203523715337118, "compression_ratio": 1.5695067264573992, "no_speech_prob": 6.921308522578329e-05}, {"id": 741, "seek": 271400, "start": 2719.0, "end": 2723.0, "text": " then I'll ask to be communicated with in a way that gives me signs of that.", "tokens": [550, 286, 603, 1029, 281, 312, 34989, 365, 294, 257, 636, 300, 2709, 385, 7880, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.17203523715337118, "compression_ratio": 1.5695067264573992, "no_speech_prob": 6.921308522578329e-05}, {"id": 742, "seek": 271400, "start": 2723.0, "end": 2726.0, "text": " Like, what are the things you're thinking through here?", "tokens": [1743, 11, 437, 366, 264, 721, 291, 434, 1953, 807, 510, 30], "temperature": 0.0, "avg_logprob": -0.17203523715337118, "compression_ratio": 1.5695067264573992, "no_speech_prob": 6.921308522578329e-05}, {"id": 743, "seek": 271400, "start": 2726.0, "end": 2728.0, "text": " Like, can you lay that out for me?", "tokens": [1743, 11, 393, 291, 2360, 300, 484, 337, 385, 30], "temperature": 0.0, "avg_logprob": -0.17203523715337118, "compression_ratio": 1.5695067264573992, "no_speech_prob": 6.921308522578329e-05}, {"id": 744, "seek": 271400, "start": 2728.0, "end": 2734.0, "text": " Because in general, I don't want to micromanage people's contributions.", "tokens": [1436, 294, 2674, 11, 286, 500, 380, 528, 281, 3123, 81, 4277, 609, 561, 311, 15725, 13], "temperature": 0.0, "avg_logprob": -0.17203523715337118, "compression_ratio": 1.5695067264573992, "no_speech_prob": 6.921308522578329e-05}, {"id": 745, "seek": 271400, "start": 2734.0, "end": 2740.0, "text": " I generally want to trust them and give them some level of ownership.", "tokens": [286, 5101, 528, 281, 3361, 552, 293, 976, 552, 512, 1496, 295, 15279, 13], "temperature": 0.0, "avg_logprob": -0.17203523715337118, "compression_ratio": 1.5695067264573992, "no_speech_prob": 6.921308522578329e-05}, {"id": 746, "seek": 274000, "start": 2740.0, "end": 2746.0, "text": " And, you know, there are certain quality standards that I have for the project", "tokens": [400, 11, 291, 458, 11, 456, 366, 1629, 3125, 7787, 300, 286, 362, 337, 264, 1716], "temperature": 0.0, "avg_logprob": -0.22271008240549187, "compression_ratio": 1.455, "no_speech_prob": 2.1781957912025973e-05}, {"id": 747, "seek": 274000, "start": 2746.0, "end": 2750.0, "text": " that are pretty superficial to check.", "tokens": [300, 366, 1238, 34622, 281, 1520, 13], "temperature": 0.0, "avg_logprob": -0.22271008240549187, "compression_ratio": 1.455, "no_speech_prob": 2.1781957912025973e-05}, {"id": 748, "seek": 274000, "start": 2750.0, "end": 2754.0, "text": " Did you write tests? Is the CI green?", "tokens": [2589, 291, 2464, 6921, 30, 1119, 264, 37777, 3092, 30], "temperature": 0.0, "avg_logprob": -0.22271008240549187, "compression_ratio": 1.455, "no_speech_prob": 2.1781957912025973e-05}, {"id": 749, "seek": 274000, "start": 2754.0, "end": 2760.0, "text": " Right. Like, but I try to automate those as much as possible.", "tokens": [1779, 13, 1743, 11, 457, 286, 853, 281, 31605, 729, 382, 709, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.22271008240549187, "compression_ratio": 1.455, "no_speech_prob": 2.1781957912025973e-05}, {"id": 750, "seek": 274000, "start": 2760.0, "end": 2764.0, "text": " Like I'm not going to go through and check code style and things like that", "tokens": [1743, 286, 478, 406, 516, 281, 352, 807, 293, 1520, 3089, 3758, 293, 721, 411, 300], "temperature": 0.0, "avg_logprob": -0.22271008240549187, "compression_ratio": 1.455, "no_speech_prob": 2.1781957912025973e-05}, {"id": 751, "seek": 276400, "start": 2764.0, "end": 2771.0, "text": " because Elm format in my CI and Elm review in my CI and my approval test suite", "tokens": [570, 2699, 76, 7877, 294, 452, 37777, 293, 2699, 76, 3131, 294, 452, 37777, 293, 452, 13317, 1500, 14205], "temperature": 0.0, "avg_logprob": -0.17290842122045055, "compression_ratio": 1.7469879518072289, "no_speech_prob": 1.6963986126938835e-05}, {"id": 752, "seek": 276400, "start": 2771.0, "end": 2773.0, "text": " and my unit test suite do that.", "tokens": [293, 452, 4985, 1500, 14205, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.17290842122045055, "compression_ratio": 1.7469879518072289, "no_speech_prob": 1.6963986126938835e-05}, {"id": 753, "seek": 276400, "start": 2773.0, "end": 2777.0, "text": " In the pull request, I am going to say, hey, I noticed this doesn't have tests.", "tokens": [682, 264, 2235, 5308, 11, 286, 669, 516, 281, 584, 11, 4177, 11, 286, 5694, 341, 1177, 380, 362, 6921, 13], "temperature": 0.0, "avg_logprob": -0.17290842122045055, "compression_ratio": 1.7469879518072289, "no_speech_prob": 1.6963986126938835e-05}, {"id": 754, "seek": 276400, "start": 2777.0, "end": 2781.0, "text": " I'm not going to merge this until it has some tests.", "tokens": [286, 478, 406, 516, 281, 22183, 341, 1826, 309, 575, 512, 6921, 13], "temperature": 0.0, "avg_logprob": -0.17290842122045055, "compression_ratio": 1.7469879518072289, "no_speech_prob": 1.6963986126938835e-05}, {"id": 755, "seek": 276400, "start": 2781.0, "end": 2784.0, "text": " But other than that, I generally like to trust people.", "tokens": [583, 661, 813, 300, 11, 286, 5101, 411, 281, 3361, 561, 13], "temperature": 0.0, "avg_logprob": -0.17290842122045055, "compression_ratio": 1.7469879518072289, "no_speech_prob": 1.6963986126938835e-05}, {"id": 756, "seek": 276400, "start": 2784.0, "end": 2789.0, "text": " But I do try to make sure that we're having the conversation where I see", "tokens": [583, 286, 360, 853, 281, 652, 988, 300, 321, 434, 1419, 264, 3761, 689, 286, 536], "temperature": 0.0, "avg_logprob": -0.17290842122045055, "compression_ratio": 1.7469879518072289, "no_speech_prob": 1.6963986126938835e-05}, {"id": 757, "seek": 276400, "start": 2789.0, "end": 2792.0, "text": " that they're taking ownership and considering all these things.", "tokens": [300, 436, 434, 1940, 15279, 293, 8079, 439, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.17290842122045055, "compression_ratio": 1.7469879518072289, "no_speech_prob": 1.6963986126938835e-05}, {"id": 758, "seek": 279200, "start": 2792.0, "end": 2794.0, "text": " Because I want to give contributors ownership.", "tokens": [1436, 286, 528, 281, 976, 45627, 15279, 13], "temperature": 0.0, "avg_logprob": -0.19086725446912978, "compression_ratio": 1.6869158878504673, "no_speech_prob": 2.2472388081951067e-05}, {"id": 759, "seek": 279200, "start": 2794.0, "end": 2797.0, "text": " Like I don't want to take that away from contributors.", "tokens": [1743, 286, 500, 380, 528, 281, 747, 300, 1314, 490, 45627, 13], "temperature": 0.0, "avg_logprob": -0.19086725446912978, "compression_ratio": 1.6869158878504673, "no_speech_prob": 2.2472388081951067e-05}, {"id": 760, "seek": 279200, "start": 2797.0, "end": 2803.0, "text": " I want to allow them to have some flexibility in how they approach something", "tokens": [286, 528, 281, 2089, 552, 281, 362, 512, 12635, 294, 577, 436, 3109, 746], "temperature": 0.0, "avg_logprob": -0.19086725446912978, "compression_ratio": 1.6869158878504673, "no_speech_prob": 2.2472388081951067e-05}, {"id": 761, "seek": 279200, "start": 2803.0, "end": 2805.0, "text": " because it's their thing.", "tokens": [570, 309, 311, 641, 551, 13], "temperature": 0.0, "avg_logprob": -0.19086725446912978, "compression_ratio": 1.6869158878504673, "no_speech_prob": 2.2472388081951067e-05}, {"id": 762, "seek": 279200, "start": 2805.0, "end": 2808.0, "text": " They are contributing it to a project I maintain.", "tokens": [814, 366, 19270, 309, 281, 257, 1716, 286, 6909, 13], "temperature": 0.0, "avg_logprob": -0.19086725446912978, "compression_ratio": 1.6869158878504673, "no_speech_prob": 2.2472388081951067e-05}, {"id": 763, "seek": 279200, "start": 2808.0, "end": 2814.0, "text": " And so that does mean that I'm committing to taking on maintenance of it.", "tokens": [400, 370, 300, 775, 914, 300, 286, 478, 26659, 281, 1940, 322, 11258, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.19086725446912978, "compression_ratio": 1.6869158878504673, "no_speech_prob": 2.2472388081951067e-05}, {"id": 764, "seek": 279200, "start": 2814.0, "end": 2816.0, "text": " But I also want to trust people.", "tokens": [583, 286, 611, 528, 281, 3361, 561, 13], "temperature": 0.0, "avg_logprob": -0.19086725446912978, "compression_ratio": 1.6869158878504673, "no_speech_prob": 2.2472388081951067e-05}, {"id": 765, "seek": 281600, "start": 2816.0, "end": 2822.0, "text": " Yeah, I haven't thought of the ownership aspect and considered it.", "tokens": [865, 11, 286, 2378, 380, 1194, 295, 264, 15279, 4171, 293, 4888, 309, 13], "temperature": 0.0, "avg_logprob": -0.19366233245186185, "compression_ratio": 1.5648148148148149, "no_speech_prob": 3.071638639084995e-05}, {"id": 766, "seek": 281600, "start": 2822.0, "end": 2825.0, "text": " But otherwise, I do pretty much the same thing.", "tokens": [583, 5911, 11, 286, 360, 1238, 709, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.19366233245186185, "compression_ratio": 1.5648148148148149, "no_speech_prob": 3.071638639084995e-05}, {"id": 767, "seek": 281600, "start": 2825.0, "end": 2830.0, "text": " Like as long as the CI is green and as long as there are tests,", "tokens": [1743, 382, 938, 382, 264, 37777, 307, 3092, 293, 382, 938, 382, 456, 366, 6921, 11], "temperature": 0.0, "avg_logprob": -0.19366233245186185, "compression_ratio": 1.5648148148148149, "no_speech_prob": 3.071638639084995e-05}, {"id": 768, "seek": 281600, "start": 2830.0, "end": 2832.0, "text": " I'm usually okay with it.", "tokens": [286, 478, 2673, 1392, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.19366233245186185, "compression_ratio": 1.5648148148148149, "no_speech_prob": 3.071638639084995e-05}, {"id": 769, "seek": 281600, "start": 2832.0, "end": 2837.0, "text": " Sometimes if I'm worried about something, I will ask them to add a few tests", "tokens": [4803, 498, 286, 478, 5804, 466, 746, 11, 286, 486, 1029, 552, 281, 909, 257, 1326, 6921], "temperature": 0.0, "avg_logprob": -0.19366233245186185, "compression_ratio": 1.5648148148148149, "no_speech_prob": 3.071638639084995e-05}, {"id": 770, "seek": 281600, "start": 2837.0, "end": 2841.0, "text": " and to fix them if needed because they need to be green.", "tokens": [293, 281, 3191, 552, 498, 2978, 570, 436, 643, 281, 312, 3092, 13], "temperature": 0.0, "avg_logprob": -0.19366233245186185, "compression_ratio": 1.5648148148148149, "no_speech_prob": 3.071638639084995e-05}, {"id": 771, "seek": 284100, "start": 2841.0, "end": 2846.0, "text": " But other than that, especially if it's like a new contributor,", "tokens": [583, 661, 813, 300, 11, 2318, 498, 309, 311, 411, 257, 777, 42859, 11], "temperature": 0.0, "avg_logprob": -0.19615872701009116, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.961840881558601e-06}, {"id": 772, "seek": 284100, "start": 2846.0, "end": 2853.0, "text": " if the code style is not to my liking for the things that Elm Review doesn't report", "tokens": [498, 264, 3089, 3758, 307, 406, 281, 452, 16933, 337, 264, 721, 300, 2699, 76, 19954, 1177, 380, 2275], "temperature": 0.0, "avg_logprob": -0.19615872701009116, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.961840881558601e-06}, {"id": 773, "seek": 284100, "start": 2853.0, "end": 2860.0, "text": " or Elm Format doesn't report, I will tend to let those pass.", "tokens": [420, 2699, 76, 10126, 267, 1177, 380, 2275, 11, 286, 486, 3928, 281, 718, 729, 1320, 13], "temperature": 0.0, "avg_logprob": -0.19615872701009116, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.961840881558601e-06}, {"id": 774, "seek": 284100, "start": 2860.0, "end": 2868.0, "text": " I will merge their pull request and then I will go fix them afterwards.", "tokens": [286, 486, 22183, 641, 2235, 5308, 293, 550, 286, 486, 352, 3191, 552, 10543, 13], "temperature": 0.0, "avg_logprob": -0.19615872701009116, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.961840881558601e-06}, {"id": 775, "seek": 286800, "start": 2868.0, "end": 2874.0, "text": " I feel like it's hard to get pull requests in sometimes", "tokens": [286, 841, 411, 309, 311, 1152, 281, 483, 2235, 12475, 294, 2171], "temperature": 0.0, "avg_logprob": -0.1824822235107422, "compression_ratio": 1.595505617977528, "no_speech_prob": 1.2217757102916948e-05}, {"id": 776, "seek": 286800, "start": 2874.0, "end": 2879.0, "text": " as someone who is like a first-time contributor.", "tokens": [382, 1580, 567, 307, 411, 257, 700, 12, 3766, 42859, 13], "temperature": 0.0, "avg_logprob": -0.1824822235107422, "compression_ratio": 1.595505617977528, "no_speech_prob": 1.2217757102916948e-05}, {"id": 777, "seek": 286800, "start": 2879.0, "end": 2884.0, "text": " So since the first time is the hardest, let's make that one easier.", "tokens": [407, 1670, 264, 700, 565, 307, 264, 13158, 11, 718, 311, 652, 300, 472, 3571, 13], "temperature": 0.0, "avg_logprob": -0.1824822235107422, "compression_ratio": 1.595505617977528, "no_speech_prob": 1.2217757102916948e-05}, {"id": 778, "seek": 286800, "start": 2884.0, "end": 2891.0, "text": " We still want something of high quality or of decent quality,", "tokens": [492, 920, 528, 746, 295, 1090, 3125, 420, 295, 8681, 3125, 11], "temperature": 0.0, "avg_logprob": -0.1824822235107422, "compression_ratio": 1.595505617977528, "no_speech_prob": 1.2217757102916948e-05}, {"id": 779, "seek": 286800, "start": 2891.0, "end": 2895.0, "text": " but I will try to make that easier on the person.", "tokens": [457, 286, 486, 853, 281, 652, 300, 3571, 322, 264, 954, 13], "temperature": 0.0, "avg_logprob": -0.1824822235107422, "compression_ratio": 1.595505617977528, "no_speech_prob": 1.2217757102916948e-05}, {"id": 780, "seek": 289500, "start": 2895.0, "end": 2899.0, "text": " And if that puts some strain on me, I'm fine with that.", "tokens": [400, 498, 300, 8137, 512, 14249, 322, 385, 11, 286, 478, 2489, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.18701788522664783, "compression_ratio": 1.6502057613168724, "no_speech_prob": 4.984008410247043e-05}, {"id": 781, "seek": 289500, "start": 2899.0, "end": 2904.0, "text": " And then if that person contributes more, then I will make more comments", "tokens": [400, 550, 498, 300, 954, 32035, 544, 11, 550, 286, 486, 652, 544, 3053], "temperature": 0.0, "avg_logprob": -0.18701788522664783, "compression_ratio": 1.6502057613168724, "no_speech_prob": 4.984008410247043e-05}, {"id": 782, "seek": 289500, "start": 2904.0, "end": 2910.0, "text": " because they will also understand how I work, how the project is written,", "tokens": [570, 436, 486, 611, 1223, 577, 286, 589, 11, 577, 264, 1716, 307, 3720, 11], "temperature": 0.0, "avg_logprob": -0.18701788522664783, "compression_ratio": 1.6502057613168724, "no_speech_prob": 4.984008410247043e-05}, {"id": 783, "seek": 289500, "start": 2910.0, "end": 2912.0, "text": " and we want things to be consistent.", "tokens": [293, 321, 528, 721, 281, 312, 8398, 13], "temperature": 0.0, "avg_logprob": -0.18701788522664783, "compression_ratio": 1.6502057613168724, "no_speech_prob": 4.984008410247043e-05}, {"id": 784, "seek": 289500, "start": 2912.0, "end": 2914.0, "text": " They will understand the various trade-offs.", "tokens": [814, 486, 1223, 264, 3683, 4923, 12, 19231, 13], "temperature": 0.0, "avg_logprob": -0.18701788522664783, "compression_ratio": 1.6502057613168724, "no_speech_prob": 4.984008410247043e-05}, {"id": 785, "seek": 289500, "start": 2914.0, "end": 2920.0, "text": " But on the first few pull requests, that's maybe not the essence of the contribution.", "tokens": [583, 322, 264, 700, 1326, 2235, 12475, 11, 300, 311, 1310, 406, 264, 12801, 295, 264, 13150, 13], "temperature": 0.0, "avg_logprob": -0.18701788522664783, "compression_ratio": 1.6502057613168724, "no_speech_prob": 4.984008410247043e-05}, {"id": 786, "seek": 289500, "start": 2920.0, "end": 2922.0, "text": " Right. Yeah, that makes sense.", "tokens": [1779, 13, 865, 11, 300, 1669, 2020, 13], "temperature": 0.0, "avg_logprob": -0.18701788522664783, "compression_ratio": 1.6502057613168724, "no_speech_prob": 4.984008410247043e-05}, {"id": 787, "seek": 292200, "start": 2922.0, "end": 2927.0, "text": " Yeah, I'll definitely help push along first-time contributors as well in that way", "tokens": [865, 11, 286, 603, 2138, 854, 2944, 2051, 700, 12, 3766, 45627, 382, 731, 294, 300, 636], "temperature": 0.0, "avg_logprob": -0.1980212498637079, "compression_ratio": 1.6023622047244095, "no_speech_prob": 4.331002492108382e-05}, {"id": 788, "seek": 292200, "start": 2927.0, "end": 2931.0, "text": " where if there's something that they just were missing, like,", "tokens": [689, 498, 456, 311, 746, 300, 436, 445, 645, 5361, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.1980212498637079, "compression_ratio": 1.6023622047244095, "no_speech_prob": 4.331002492108382e-05}, {"id": 789, "seek": 292200, "start": 2931.0, "end": 2934.0, "text": " hey, there's a module that abstracts away some of these details", "tokens": [4177, 11, 456, 311, 257, 10088, 300, 12649, 82, 1314, 512, 295, 613, 4365], "temperature": 0.0, "avg_logprob": -0.1980212498637079, "compression_ratio": 1.6023622047244095, "no_speech_prob": 4.331002492108382e-05}, {"id": 790, "seek": 292200, "start": 2934.0, "end": 2939.0, "text": " that we use in this code base, then I may make a commit on the PR", "tokens": [300, 321, 764, 294, 341, 3089, 3096, 11, 550, 286, 815, 652, 257, 5599, 322, 264, 11568], "temperature": 0.0, "avg_logprob": -0.1980212498637079, "compression_ratio": 1.6023622047244095, "no_speech_prob": 4.331002492108382e-05}, {"id": 791, "seek": 292200, "start": 2939.0, "end": 2943.0, "text": " or point them to it depending on how involved it is.", "tokens": [420, 935, 552, 281, 309, 5413, 322, 577, 3288, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.1980212498637079, "compression_ratio": 1.6023622047244095, "no_speech_prob": 4.331002492108382e-05}, {"id": 792, "seek": 292200, "start": 2943.0, "end": 2951.0, "text": " And yeah, regarding the ownership, I think the more you give somebody your trust", "tokens": [400, 1338, 11, 8595, 264, 15279, 11, 286, 519, 264, 544, 291, 976, 2618, 428, 3361], "temperature": 0.0, "avg_logprob": -0.1980212498637079, "compression_ratio": 1.6023622047244095, "no_speech_prob": 4.331002492108382e-05}, {"id": 793, "seek": 295100, "start": 2951.0, "end": 2955.0, "text": " and ownership over something, the more they step up to it.", "tokens": [293, 15279, 670, 746, 11, 264, 544, 436, 1823, 493, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.20269467613913797, "compression_ratio": 1.5972222222222223, "no_speech_prob": 1.544522456242703e-05}, {"id": 794, "seek": 295100, "start": 2955.0, "end": 2956.0, "text": " That's just something I've noticed.", "tokens": [663, 311, 445, 746, 286, 600, 5694, 13], "temperature": 0.0, "avg_logprob": -0.20269467613913797, "compression_ratio": 1.5972222222222223, "no_speech_prob": 1.544522456242703e-05}, {"id": 795, "seek": 295100, "start": 2956.0, "end": 2959.0, "text": " I definitely feel that way as well.", "tokens": [286, 2138, 841, 300, 636, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.20269467613913797, "compression_ratio": 1.5972222222222223, "no_speech_prob": 1.544522456242703e-05}, {"id": 796, "seek": 295100, "start": 2959.0, "end": 2967.0, "text": " So I think as maintainers, we can really set the tone where if we're not trusting", "tokens": [407, 286, 519, 382, 6909, 433, 11, 321, 393, 534, 992, 264, 8027, 689, 498, 321, 434, 406, 28235], "temperature": 0.0, "avg_logprob": -0.20269467613913797, "compression_ratio": 1.5972222222222223, "no_speech_prob": 1.544522456242703e-05}, {"id": 797, "seek": 295100, "start": 2967.0, "end": 2973.0, "text": " our contributors, they feel that, and they feel constrained and like,", "tokens": [527, 45627, 11, 436, 841, 300, 11, 293, 436, 841, 38901, 293, 411, 11], "temperature": 0.0, "avg_logprob": -0.20269467613913797, "compression_ratio": 1.5972222222222223, "no_speech_prob": 1.544522456242703e-05}, {"id": 798, "seek": 295100, "start": 2973.0, "end": 2977.0, "text": " we're going to check everything and basically redo their work.", "tokens": [321, 434, 516, 281, 1520, 1203, 293, 1936, 29956, 641, 589, 13], "temperature": 0.0, "avg_logprob": -0.20269467613913797, "compression_ratio": 1.5972222222222223, "no_speech_prob": 1.544522456242703e-05}, {"id": 799, "seek": 297700, "start": 2977.0, "end": 2984.0, "text": " So they don't really look at the big picture because that's not what they're being asked to do.", "tokens": [407, 436, 500, 380, 534, 574, 412, 264, 955, 3036, 570, 300, 311, 406, 437, 436, 434, 885, 2351, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.18302443533232718, "compression_ratio": 1.6123348017621146, "no_speech_prob": 1.1478335181891453e-05}, {"id": 800, "seek": 297700, "start": 2984.0, "end": 2990.0, "text": " They're being asked to just give some code, but we're going to be micromanaging it anyway.", "tokens": [814, 434, 885, 2351, 281, 445, 976, 512, 3089, 11, 457, 321, 434, 516, 281, 312, 3123, 81, 4277, 3568, 309, 4033, 13], "temperature": 0.0, "avg_logprob": -0.18302443533232718, "compression_ratio": 1.6123348017621146, "no_speech_prob": 1.1478335181891453e-05}, {"id": 801, "seek": 297700, "start": 2990.0, "end": 2996.0, "text": " So why would they be thinking about the big picture of how it fits in and everything?", "tokens": [407, 983, 576, 436, 312, 1953, 466, 264, 955, 3036, 295, 577, 309, 9001, 294, 293, 1203, 30], "temperature": 0.0, "avg_logprob": -0.18302443533232718, "compression_ratio": 1.6123348017621146, "no_speech_prob": 1.1478335181891453e-05}, {"id": 802, "seek": 297700, "start": 2996.0, "end": 3000.0, "text": " There's a TED talk I saw by this author of a book.", "tokens": [821, 311, 257, 43036, 751, 286, 1866, 538, 341, 3793, 295, 257, 1446, 13], "temperature": 0.0, "avg_logprob": -0.18302443533232718, "compression_ratio": 1.6123348017621146, "no_speech_prob": 1.1478335181891453e-05}, {"id": 803, "seek": 297700, "start": 3000.0, "end": 3001.0, "text": " I think it's called Turn This Ship Around.", "tokens": [286, 519, 309, 311, 1219, 7956, 639, 38407, 17633, 13], "temperature": 0.0, "avg_logprob": -0.18302443533232718, "compression_ratio": 1.6123348017621146, "no_speech_prob": 1.1478335181891453e-05}, {"id": 804, "seek": 300100, "start": 3001.0, "end": 3010.0, "text": " And the author was a commander or admiral or something of a nuclear submarine, I believe.", "tokens": [400, 264, 3793, 390, 257, 17885, 420, 5910, 35083, 420, 746, 295, 257, 8179, 33995, 11, 286, 1697, 13], "temperature": 0.0, "avg_logprob": -0.1991217749459403, "compression_ratio": 1.6057142857142856, "no_speech_prob": 1.5444540622411296e-05}, {"id": 805, "seek": 300100, "start": 3010.0, "end": 3019.0, "text": " And his first day on the job on this nuclear submarine, he actually was given a different type of vessel", "tokens": [400, 702, 700, 786, 322, 264, 1691, 322, 341, 8179, 33995, 11, 415, 767, 390, 2212, 257, 819, 2010, 295, 18098], "temperature": 0.0, "avg_logprob": -0.1991217749459403, "compression_ratio": 1.6057142857142856, "no_speech_prob": 1.5444540622411296e-05}, {"id": 806, "seek": 300100, "start": 3019.0, "end": 3021.0, "text": " than he thought he was going to be commanding.", "tokens": [813, 415, 1194, 415, 390, 516, 281, 312, 5622, 278, 13], "temperature": 0.0, "avg_logprob": -0.1991217749459403, "compression_ratio": 1.6057142857142856, "no_speech_prob": 1.5444540622411296e-05}, {"id": 807, "seek": 300100, "start": 3021.0, "end": 3026.0, "text": " And so he started to give these orders.", "tokens": [400, 370, 415, 1409, 281, 976, 613, 9470, 13], "temperature": 0.0, "avg_logprob": -0.1991217749459403, "compression_ratio": 1.6057142857142856, "no_speech_prob": 1.5444540622411296e-05}, {"id": 808, "seek": 302600, "start": 3026.0, "end": 3031.0, "text": " And people would look confused sometimes and he'd say, what's wrong?", "tokens": [400, 561, 576, 574, 9019, 2171, 293, 415, 1116, 584, 11, 437, 311, 2085, 30], "temperature": 0.0, "avg_logprob": -0.17322659896591963, "compression_ratio": 1.6768060836501901, "no_speech_prob": 2.2823778635938652e-05}, {"id": 809, "seek": 302600, "start": 3031.0, "end": 3032.0, "text": " Is there a problem?", "tokens": [1119, 456, 257, 1154, 30], "temperature": 0.0, "avg_logprob": -0.17322659896591963, "compression_ratio": 1.6768060836501901, "no_speech_prob": 2.2823778635938652e-05}, {"id": 810, "seek": 302600, "start": 3032.0, "end": 3036.0, "text": " And they'd say, well, we don't have that unit on this ship or something like that.", "tokens": [400, 436, 1116, 584, 11, 731, 11, 321, 500, 380, 362, 300, 4985, 322, 341, 5374, 420, 746, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.17322659896591963, "compression_ratio": 1.6768060836501901, "no_speech_prob": 2.2823778635938652e-05}, {"id": 811, "seek": 302600, "start": 3036.0, "end": 3044.0, "text": " And he would realize when he was giving orders, people would sort of shut off their thinking", "tokens": [400, 415, 576, 4325, 562, 415, 390, 2902, 9470, 11, 561, 576, 1333, 295, 5309, 766, 641, 1953], "temperature": 0.0, "avg_logprob": -0.17322659896591963, "compression_ratio": 1.6768060836501901, "no_speech_prob": 2.2823778635938652e-05}, {"id": 812, "seek": 302600, "start": 3044.0, "end": 3049.0, "text": " because they'd just be like, well, it's my duty to do what was asked of me,", "tokens": [570, 436, 1116, 445, 312, 411, 11, 731, 11, 309, 311, 452, 9776, 281, 360, 437, 390, 2351, 295, 385, 11], "temperature": 0.0, "avg_logprob": -0.17322659896591963, "compression_ratio": 1.6768060836501901, "no_speech_prob": 2.2823778635938652e-05}, {"id": 813, "seek": 302600, "start": 3049.0, "end": 3051.0, "text": " even if it doesn't really make sense.", "tokens": [754, 498, 309, 1177, 380, 534, 652, 2020, 13], "temperature": 0.0, "avg_logprob": -0.17322659896591963, "compression_ratio": 1.6768060836501901, "no_speech_prob": 2.2823778635938652e-05}, {"id": 814, "seek": 302600, "start": 3051.0, "end": 3054.0, "text": " Because you're not being asked to think about the big picture.", "tokens": [1436, 291, 434, 406, 885, 2351, 281, 519, 466, 264, 955, 3036, 13], "temperature": 0.0, "avg_logprob": -0.17322659896591963, "compression_ratio": 1.6768060836501901, "no_speech_prob": 2.2823778635938652e-05}, {"id": 815, "seek": 305400, "start": 3054.0, "end": 3059.0, "text": " And so he ended up realizing that if he was going to successfully run this vessel,", "tokens": [400, 370, 415, 4590, 493, 16734, 300, 498, 415, 390, 516, 281, 10727, 1190, 341, 18098, 11], "temperature": 0.0, "avg_logprob": -0.19184128443400064, "compression_ratio": 1.6157407407407407, "no_speech_prob": 3.32103154505603e-05}, {"id": 816, "seek": 305400, "start": 3059.0, "end": 3062.0, "text": " he would need to do things differently.", "tokens": [415, 576, 643, 281, 360, 721, 7614, 13], "temperature": 0.0, "avg_logprob": -0.19184128443400064, "compression_ratio": 1.6157407407407407, "no_speech_prob": 3.32103154505603e-05}, {"id": 817, "seek": 305400, "start": 3062.0, "end": 3067.0, "text": " So he started to say, it's my intention to submerge the vessel.", "tokens": [407, 415, 1409, 281, 584, 11, 309, 311, 452, 7789, 281, 36751, 432, 264, 18098, 13], "temperature": 0.0, "avg_logprob": -0.19184128443400064, "compression_ratio": 1.6157407407407407, "no_speech_prob": 3.32103154505603e-05}, {"id": 818, "seek": 305400, "start": 3067.0, "end": 3070.0, "text": " And what am I going to ask you?", "tokens": [400, 437, 669, 286, 516, 281, 1029, 291, 30], "temperature": 0.0, "avg_logprob": -0.19184128443400064, "compression_ratio": 1.6157407407407407, "no_speech_prob": 3.32103154505603e-05}, {"id": 819, "seek": 305400, "start": 3070.0, "end": 3073.0, "text": " And they would start thinking about his goals.", "tokens": [400, 436, 576, 722, 1953, 466, 702, 5493, 13], "temperature": 0.0, "avg_logprob": -0.19184128443400064, "compression_ratio": 1.6157407407407407, "no_speech_prob": 3.32103154505603e-05}, {"id": 820, "seek": 305400, "start": 3073.0, "end": 3077.0, "text": " So, OK, well, is everybody going to be safe?", "tokens": [407, 11, 2264, 11, 731, 11, 307, 2201, 516, 281, 312, 3273, 30], "temperature": 0.0, "avg_logprob": -0.19184128443400064, "compression_ratio": 1.6157407407407407, "no_speech_prob": 3.32103154505603e-05}, {"id": 821, "seek": 305400, "start": 3077.0, "end": 3080.0, "text": " And whatever. His checklist of things.", "tokens": [400, 2035, 13, 2812, 30357, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.19184128443400064, "compression_ratio": 1.6157407407407407, "no_speech_prob": 3.32103154505603e-05}, {"id": 822, "seek": 308000, "start": 3080.0, "end": 3084.0, "text": " So that was his way of mentoring everybody to make sure these are the,", "tokens": [407, 300, 390, 702, 636, 295, 30257, 2201, 281, 652, 988, 613, 366, 264, 11], "temperature": 0.0, "avg_logprob": -0.19569965645118995, "compression_ratio": 1.7330508474576272, "no_speech_prob": 1.3211581972427666e-05}, {"id": 823, "seek": 308000, "start": 3084.0, "end": 3088.0, "text": " this is the vision that I'm setting as the captain.", "tokens": [341, 307, 264, 5201, 300, 286, 478, 3287, 382, 264, 14871, 13], "temperature": 0.0, "avg_logprob": -0.19569965645118995, "compression_ratio": 1.7330508474576272, "no_speech_prob": 1.3211581972427666e-05}, {"id": 824, "seek": 308000, "start": 3088.0, "end": 3093.0, "text": " But I'm trusting you to execute that and take ownership over your part of it.", "tokens": [583, 286, 478, 28235, 291, 281, 14483, 300, 293, 747, 15279, 670, 428, 644, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.19569965645118995, "compression_ratio": 1.7330508474576272, "no_speech_prob": 1.3211581972427666e-05}, {"id": 825, "seek": 308000, "start": 3093.0, "end": 3095.0, "text": " And I'm setting the high level vision.", "tokens": [400, 286, 478, 3287, 264, 1090, 1496, 5201, 13], "temperature": 0.0, "avg_logprob": -0.19569965645118995, "compression_ratio": 1.7330508474576272, "no_speech_prob": 1.3211581972427666e-05}, {"id": 826, "seek": 308000, "start": 3095.0, "end": 3100.0, "text": " And I think that that's a really good way to approach an open source project as well.", "tokens": [400, 286, 519, 300, 300, 311, 257, 534, 665, 636, 281, 3109, 364, 1269, 4009, 1716, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.19569965645118995, "compression_ratio": 1.7330508474576272, "no_speech_prob": 1.3211581972427666e-05}, {"id": 827, "seek": 308000, "start": 3100.0, "end": 3103.0, "text": " Yeah. Yeah, that resonates with me as well.", "tokens": [865, 13, 865, 11, 300, 41051, 365, 385, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.19569965645118995, "compression_ratio": 1.7330508474576272, "no_speech_prob": 1.3211581972427666e-05}, {"id": 828, "seek": 308000, "start": 3103.0, "end": 3106.0, "text": " So when is an open source project done?", "tokens": [407, 562, 307, 364, 1269, 4009, 1716, 1096, 30], "temperature": 0.0, "avg_logprob": -0.19569965645118995, "compression_ratio": 1.7330508474576272, "no_speech_prob": 1.3211581972427666e-05}, {"id": 829, "seek": 310600, "start": 3106.0, "end": 3114.0, "text": " When the maintainer leaves?", "tokens": [1133, 264, 6909, 260, 5510, 30], "temperature": 0.0, "avg_logprob": -0.24084783483434608, "compression_ratio": 1.622093023255814, "no_speech_prob": 4.859219188801944e-06}, {"id": 830, "seek": 310600, "start": 3114.0, "end": 3116.0, "text": " When there's no maintainer left?", "tokens": [1133, 456, 311, 572, 6909, 260, 1411, 30], "temperature": 0.0, "avg_logprob": -0.24084783483434608, "compression_ratio": 1.622093023255814, "no_speech_prob": 4.859219188801944e-06}, {"id": 831, "seek": 310600, "start": 3116.0, "end": 3118.0, "text": " When the maintainer gets hit by a bus?", "tokens": [1133, 264, 6909, 260, 2170, 2045, 538, 257, 1255, 30], "temperature": 0.0, "avg_logprob": -0.24084783483434608, "compression_ratio": 1.622093023255814, "no_speech_prob": 4.859219188801944e-06}, {"id": 832, "seek": 310600, "start": 3118.0, "end": 3121.0, "text": " Apparently that's a thing that happens with maintainers.", "tokens": [16755, 300, 311, 257, 551, 300, 2314, 365, 6909, 433, 13], "temperature": 0.0, "avg_logprob": -0.24084783483434608, "compression_ratio": 1.622093023255814, "no_speech_prob": 4.859219188801944e-06}, {"id": 833, "seek": 310600, "start": 3121.0, "end": 3123.0, "text": " Yeah, quite often.", "tokens": [865, 11, 1596, 2049, 13], "temperature": 0.0, "avg_logprob": -0.24084783483434608, "compression_ratio": 1.622093023255814, "no_speech_prob": 4.859219188801944e-06}, {"id": 834, "seek": 310600, "start": 3123.0, "end": 3130.0, "text": " Actually, I don't know any maintainer who's been hit by a bus.", "tokens": [5135, 11, 286, 500, 380, 458, 604, 6909, 260, 567, 311, 668, 2045, 538, 257, 1255, 13], "temperature": 0.0, "avg_logprob": -0.24084783483434608, "compression_ratio": 1.622093023255814, "no_speech_prob": 4.859219188801944e-06}, {"id": 835, "seek": 310600, "start": 3130.0, "end": 3134.0, "text": " Definitely stay away from buses, though.", "tokens": [12151, 1754, 1314, 490, 20519, 11, 1673, 13], "temperature": 0.0, "avg_logprob": -0.24084783483434608, "compression_ratio": 1.622093023255814, "no_speech_prob": 4.859219188801944e-06}, {"id": 836, "seek": 313400, "start": 3134.0, "end": 3137.0, "text": " No, no, no. Use public transport. It's good. It's good.", "tokens": [883, 11, 572, 11, 572, 13, 8278, 1908, 5495, 13, 467, 311, 665, 13, 467, 311, 665, 13], "temperature": 0.0, "avg_logprob": -0.16496379176775613, "compression_ratio": 1.6373056994818653, "no_speech_prob": 3.1874501473794226e-06}, {"id": 837, "seek": 313400, "start": 3137.0, "end": 3144.0, "text": " Be on the bus. If you're on the bus, your odds of getting hit by a bus are lower. Probably.", "tokens": [879, 322, 264, 1255, 13, 759, 291, 434, 322, 264, 1255, 11, 428, 17439, 295, 1242, 2045, 538, 257, 1255, 366, 3126, 13, 9210, 13], "temperature": 0.0, "avg_logprob": -0.16496379176775613, "compression_ratio": 1.6373056994818653, "no_speech_prob": 3.1874501473794226e-06}, {"id": 838, "seek": 313400, "start": 3144.0, "end": 3149.0, "text": " I mean, if you're on the bus, then you're probably trying to flee someone with a gun", "tokens": [286, 914, 11, 498, 291, 434, 322, 264, 1255, 11, 550, 291, 434, 1391, 1382, 281, 25146, 1580, 365, 257, 3874], "temperature": 0.0, "avg_logprob": -0.16496379176775613, "compression_ratio": 1.6373056994818653, "no_speech_prob": 3.1874501473794226e-06}, {"id": 839, "seek": 313400, "start": 3149.0, "end": 3156.0, "text": " and you jumped from a bridge on top of the bus.", "tokens": [293, 291, 13864, 490, 257, 7283, 322, 1192, 295, 264, 1255, 13], "temperature": 0.0, "avg_logprob": -0.16496379176775613, "compression_ratio": 1.6373056994818653, "no_speech_prob": 3.1874501473794226e-06}, {"id": 840, "seek": 313400, "start": 3156.0, "end": 3162.0, "text": " Maintainers lead interesting lives.", "tokens": [376, 5114, 491, 433, 1477, 1880, 2909, 13], "temperature": 0.0, "avg_logprob": -0.16496379176775613, "compression_ratio": 1.6373056994818653, "no_speech_prob": 3.1874501473794226e-06}, {"id": 841, "seek": 316200, "start": 3162.0, "end": 3165.0, "text": " I guess. When is a project done?", "tokens": [286, 2041, 13, 1133, 307, 257, 1716, 1096, 30], "temperature": 0.0, "avg_logprob": -0.23019818200005426, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.00018788526358548552}, {"id": 842, "seek": 316200, "start": 3165.0, "end": 3172.0, "text": " Honestly, when it reaches its goals and when it's perfect, in the sense of", "tokens": [12348, 11, 562, 309, 14235, 1080, 5493, 293, 562, 309, 311, 2176, 11, 294, 264, 2020, 295], "temperature": 0.0, "avg_logprob": -0.23019818200005426, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.00018788526358548552}, {"id": 843, "seek": 316200, "start": 3172.0, "end": 3179.0, "text": " whichever author said perfection is attained when there's nothing more to remove.", "tokens": [24123, 3793, 848, 19708, 307, 46633, 562, 456, 311, 1825, 544, 281, 4159, 13], "temperature": 0.0, "avg_logprob": -0.23019818200005426, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.00018788526358548552}, {"id": 844, "seek": 316200, "start": 3179.0, "end": 3182.0, "text": " Something like that.", "tokens": [6595, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.23019818200005426, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.00018788526358548552}, {"id": 845, "seek": 316200, "start": 3182.0, "end": 3187.0, "text": " Which is very far from where our projects are, I think.", "tokens": [3013, 307, 588, 1400, 490, 689, 527, 4455, 366, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.23019818200005426, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.00018788526358548552}, {"id": 846, "seek": 316200, "start": 3187.0, "end": 3191.0, "text": " I mean, you have some projects that could be considered to be done or close to done.", "tokens": [286, 914, 11, 291, 362, 512, 4455, 300, 727, 312, 4888, 281, 312, 1096, 420, 1998, 281, 1096, 13], "temperature": 0.0, "avg_logprob": -0.23019818200005426, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.00018788526358548552}, {"id": 847, "seek": 319100, "start": 3191.0, "end": 3196.0, "text": " Yeah, absolutely. I mean, and I think it depends on the scope of the project, right?", "tokens": [865, 11, 3122, 13, 286, 914, 11, 293, 286, 519, 309, 5946, 322, 264, 11923, 295, 264, 1716, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.22958219191607307, "compression_ratio": 1.5568181818181819, "no_speech_prob": 0.0003797718964051455}, {"id": 848, "seek": 319100, "start": 3196.0, "end": 3210.0, "text": " If it's a project that, I don't know, if it's a project that parses a URL or parses an ISO 8601 date, right?", "tokens": [759, 309, 311, 257, 1716, 300, 11, 286, 500, 380, 458, 11, 498, 309, 311, 257, 1716, 300, 21156, 279, 257, 12905, 420, 21156, 279, 364, 25042, 1649, 4550, 16, 4002, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.22958219191607307, "compression_ratio": 1.5568181818181819, "no_speech_prob": 0.0003797718964051455}, {"id": 849, "seek": 319100, "start": 3210.0, "end": 3218.0, "text": " Like, is Richard's ISO 8601 date parser package done? I think it pretty much is.", "tokens": [1743, 11, 307, 9809, 311, 25042, 1649, 4550, 16, 4002, 21156, 260, 7372, 1096, 30, 286, 519, 309, 1238, 709, 307, 13], "temperature": 0.0, "avg_logprob": -0.22958219191607307, "compression_ratio": 1.5568181818181819, "no_speech_prob": 0.0003797718964051455}, {"id": 850, "seek": 321800, "start": 3218.0, "end": 3227.0, "text": " And I think that sometimes a project can be done when it has a particular vision.", "tokens": [400, 286, 519, 300, 2171, 257, 1716, 393, 312, 1096, 562, 309, 575, 257, 1729, 5201, 13], "temperature": 0.0, "avg_logprob": -0.21655889459558436, "compression_ratio": 1.7955801104972375, "no_speech_prob": 0.00012137683370383456}, {"id": 851, "seek": 321800, "start": 3227.0, "end": 3230.0, "text": " It sort of meets that vision.", "tokens": [467, 1333, 295, 13961, 300, 5201, 13], "temperature": 0.0, "avg_logprob": -0.21655889459558436, "compression_ratio": 1.7955801104972375, "no_speech_prob": 0.00012137683370383456}, {"id": 852, "seek": 321800, "start": 3230.0, "end": 3236.0, "text": " And then sometimes it's better, rather than trying to reinvent that project,", "tokens": [400, 550, 2171, 309, 311, 1101, 11, 2831, 813, 1382, 281, 33477, 300, 1716, 11], "temperature": 0.0, "avg_logprob": -0.21655889459558436, "compression_ratio": 1.7955801104972375, "no_speech_prob": 0.00012137683370383456}, {"id": 853, "seek": 321800, "start": 3236.0, "end": 3239.0, "text": " sometimes it's better to create a different project with different goals,", "tokens": [2171, 309, 311, 1101, 281, 1884, 257, 819, 1716, 365, 819, 5493, 11], "temperature": 0.0, "avg_logprob": -0.21655889459558436, "compression_ratio": 1.7955801104972375, "no_speech_prob": 0.00012137683370383456}, {"id": 854, "seek": 321800, "start": 3239.0, "end": 3243.0, "text": " rather than completely transforming the goals of that project.", "tokens": [2831, 813, 2584, 27210, 264, 5493, 295, 300, 1716, 13], "temperature": 0.0, "avg_logprob": -0.21655889459558436, "compression_ratio": 1.7955801104972375, "no_speech_prob": 0.00012137683370383456}, {"id": 855, "seek": 324300, "start": 3243.0, "end": 3248.0, "text": " But I think that happens quite often, and I think that's a natural part of the cycle as well.", "tokens": [583, 286, 519, 300, 2314, 1596, 2049, 11, 293, 286, 519, 300, 311, 257, 3303, 644, 295, 264, 6586, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.22493393780433968, "compression_ratio": 1.4395604395604396, "no_speech_prob": 4.5394761400530115e-05}, {"id": 856, "seek": 324300, "start": 3248.0, "end": 3260.0, "text": " But yeah, for ElmGraphQL, for example, I think it's at a phase where it kind of delivers what it promised.", "tokens": [583, 1338, 11, 337, 2699, 76, 38, 2662, 13695, 11, 337, 1365, 11, 286, 519, 309, 311, 412, 257, 5574, 689, 309, 733, 295, 24860, 437, 309, 10768, 13], "temperature": 0.0, "avg_logprob": -0.22493393780433968, "compression_ratio": 1.4395604395604396, "no_speech_prob": 4.5394761400530115e-05}, {"id": 857, "seek": 324300, "start": 3260.0, "end": 3267.0, "text": " And small improvements come up, and I do actively work on it,", "tokens": [400, 1359, 13797, 808, 493, 11, 293, 286, 360, 13022, 589, 322, 309, 11], "temperature": 0.0, "avg_logprob": -0.22493393780433968, "compression_ratio": 1.4395604395604396, "no_speech_prob": 4.5394761400530115e-05}, {"id": 858, "seek": 326700, "start": 3267.0, "end": 3273.0, "text": " and merge pull requests and small bug fixes come up.", "tokens": [293, 22183, 2235, 12475, 293, 1359, 7426, 32539, 808, 493, 13], "temperature": 0.0, "avg_logprob": -0.15961857464002527, "compression_ratio": 1.5654205607476634, "no_speech_prob": 3.8225411117309704e-05}, {"id": 859, "seek": 326700, "start": 3273.0, "end": 3282.0, "text": " But it's much less frequent, and the core features are there, and they're pretty much solid.", "tokens": [583, 309, 311, 709, 1570, 18004, 11, 293, 264, 4965, 4122, 366, 456, 11, 293, 436, 434, 1238, 709, 5100, 13], "temperature": 0.0, "avg_logprob": -0.15961857464002527, "compression_ratio": 1.5654205607476634, "no_speech_prob": 3.8225411117309704e-05}, {"id": 860, "seek": 326700, "start": 3282.0, "end": 3288.0, "text": " Not that it's... I don't think it's a perfect project, but I think it's a dependable project.", "tokens": [1726, 300, 309, 311, 485, 286, 500, 380, 519, 309, 311, 257, 2176, 1716, 11, 457, 286, 519, 309, 311, 257, 5672, 712, 1716, 13], "temperature": 0.0, "avg_logprob": -0.15961857464002527, "compression_ratio": 1.5654205607476634, "no_speech_prob": 3.8225411117309704e-05}, {"id": 861, "seek": 326700, "start": 3288.0, "end": 3292.0, "text": " You can basically use it to do what it promises.", "tokens": [509, 393, 1936, 764, 309, 281, 360, 437, 309, 16403, 13], "temperature": 0.0, "avg_logprob": -0.15961857464002527, "compression_ratio": 1.5654205607476634, "no_speech_prob": 3.8225411117309704e-05}, {"id": 862, "seek": 326700, "start": 3292.0, "end": 3296.0, "text": " So it's more in maintenance mode, I would say.", "tokens": [407, 309, 311, 544, 294, 11258, 4391, 11, 286, 576, 584, 13], "temperature": 0.0, "avg_logprob": -0.15961857464002527, "compression_ratio": 1.5654205607476634, "no_speech_prob": 3.8225411117309704e-05}, {"id": 863, "seek": 329600, "start": 3296.0, "end": 3298.0, "text": " Not that I could never ever feature.", "tokens": [1726, 300, 286, 727, 1128, 1562, 4111, 13], "temperature": 0.0, "avg_logprob": -0.21227744773582177, "compression_ratio": 1.46, "no_speech_prob": 4.9082405894296244e-05}, {"id": 864, "seek": 329600, "start": 3298.0, "end": 3302.0, "text": " Yeah, because the project is doing pretty much all that it needs to.", "tokens": [865, 11, 570, 264, 1716, 307, 884, 1238, 709, 439, 300, 309, 2203, 281, 13], "temperature": 0.0, "avg_logprob": -0.21227744773582177, "compression_ratio": 1.46, "no_speech_prob": 4.9082405894296244e-05}, {"id": 865, "seek": 329600, "start": 3302.0, "end": 3303.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.21227744773582177, "compression_ratio": 1.46, "no_speech_prob": 4.9082405894296244e-05}, {"id": 866, "seek": 329600, "start": 3303.0, "end": 3313.0, "text": " So yeah, ElmGraphQL wanted to allow you to interact with GraphQL endpoints in a specific way.", "tokens": [407, 1338, 11, 2699, 76, 38, 2662, 13695, 1415, 281, 2089, 291, 281, 4648, 365, 21884, 13695, 917, 20552, 294, 257, 2685, 636, 13], "temperature": 0.0, "avg_logprob": -0.21227744773582177, "compression_ratio": 1.46, "no_speech_prob": 4.9082405894296244e-05}, {"id": 867, "seek": 329600, "start": 3313.0, "end": 3319.0, "text": " And as long as you reach that goal, and no one finds anything that needs to be added,", "tokens": [400, 382, 938, 382, 291, 2524, 300, 3387, 11, 293, 572, 472, 10704, 1340, 300, 2203, 281, 312, 3869, 11], "temperature": 0.0, "avg_logprob": -0.21227744773582177, "compression_ratio": 1.46, "no_speech_prob": 4.9082405894296244e-05}, {"id": 868, "seek": 331900, "start": 3319.0, "end": 3327.0, "text": " like new support for ADSes maybe, I don't know if that's a new thing, then yeah, you're done.", "tokens": [411, 777, 1406, 337, 9135, 50, 279, 1310, 11, 286, 500, 380, 458, 498, 300, 311, 257, 777, 551, 11, 550, 1338, 11, 291, 434, 1096, 13], "temperature": 0.0, "avg_logprob": -0.24906818539488548, "compression_ratio": 1.471111111111111, "no_speech_prob": 3.340477860547253e-06}, {"id": 869, "seek": 331900, "start": 3327.0, "end": 3328.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.24906818539488548, "compression_ratio": 1.471111111111111, "no_speech_prob": 3.340477860547253e-06}, {"id": 870, "seek": 331900, "start": 3328.0, "end": 3329.0, "text": " Or close to done.", "tokens": [1610, 1998, 281, 1096, 13], "temperature": 0.0, "avg_logprob": -0.24906818539488548, "compression_ratio": 1.471111111111111, "no_speech_prob": 3.340477860547253e-06}, {"id": 871, "seek": 331900, "start": 3329.0, "end": 3336.0, "text": " Like, yeah, maintenance, fixed typos in the documentation that no one has seen before, that can happen.", "tokens": [1743, 11, 1338, 11, 11258, 11, 6806, 2125, 329, 294, 264, 14333, 300, 572, 472, 575, 1612, 949, 11, 300, 393, 1051, 13], "temperature": 0.0, "avg_logprob": -0.24906818539488548, "compression_ratio": 1.471111111111111, "no_speech_prob": 3.340477860547253e-06}, {"id": 872, "seek": 331900, "start": 3336.0, "end": 3338.0, "text": " Nothing really big, right?", "tokens": [6693, 534, 955, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.24906818539488548, "compression_ratio": 1.471111111111111, "no_speech_prob": 3.340477860547253e-06}, {"id": 873, "seek": 331900, "start": 3338.0, "end": 3340.0, "text": " Yeah, and I think that's...", "tokens": [865, 11, 293, 286, 519, 300, 311, 485], "temperature": 0.0, "avg_logprob": -0.24906818539488548, "compression_ratio": 1.471111111111111, "no_speech_prob": 3.340477860547253e-06}, {"id": 874, "seek": 331900, "start": 3340.0, "end": 3345.0, "text": " I mean, the scope of ElmGraphQL is definitely like...", "tokens": [286, 914, 11, 264, 11923, 295, 2699, 76, 38, 2662, 13695, 307, 2138, 411, 485], "temperature": 0.0, "avg_logprob": -0.24906818539488548, "compression_ratio": 1.471111111111111, "no_speech_prob": 3.340477860547253e-06}, {"id": 875, "seek": 334500, "start": 3345.0, "end": 3350.0, "text": " I mean, it's a non-trivial project, but it's also like a pretty clear scope.", "tokens": [286, 914, 11, 309, 311, 257, 2107, 12, 83, 470, 22640, 1716, 11, 457, 309, 311, 611, 411, 257, 1238, 1850, 11923, 13], "temperature": 0.0, "avg_logprob": -0.15688210267287034, "compression_ratio": 1.568075117370892, "no_speech_prob": 2.902247842939687e-06}, {"id": 876, "seek": 334500, "start": 3350.0, "end": 3356.0, "text": " Like frameworks like ElmPages, it would be a lot harder to ever call ElmPages done.", "tokens": [1743, 29834, 411, 2699, 76, 47, 1660, 11, 309, 576, 312, 257, 688, 6081, 281, 1562, 818, 2699, 76, 47, 1660, 1096, 13], "temperature": 0.0, "avg_logprob": -0.15688210267287034, "compression_ratio": 1.568075117370892, "no_speech_prob": 2.902247842939687e-06}, {"id": 877, "seek": 334500, "start": 3356.0, "end": 3359.0, "text": " Because it's a framework.", "tokens": [1436, 309, 311, 257, 8388, 13], "temperature": 0.0, "avg_logprob": -0.15688210267287034, "compression_ratio": 1.568075117370892, "no_speech_prob": 2.902247842939687e-06}, {"id": 878, "seek": 334500, "start": 3359.0, "end": 3361.0, "text": " Because the goal is much bigger.", "tokens": [1436, 264, 3387, 307, 709, 3801, 13], "temperature": 0.0, "avg_logprob": -0.15688210267287034, "compression_ratio": 1.568075117370892, "no_speech_prob": 2.902247842939687e-06}, {"id": 879, "seek": 334500, "start": 3361.0, "end": 3365.0, "text": " I mean, you say that, but for instance, Backbone, back in the day,", "tokens": [286, 914, 11, 291, 584, 300, 11, 457, 337, 5197, 11, 5833, 19782, 11, 646, 294, 264, 786, 11], "temperature": 0.0, "avg_logprob": -0.15688210267287034, "compression_ratio": 1.568075117370892, "no_speech_prob": 2.902247842939687e-06}, {"id": 880, "seek": 334500, "start": 3365.0, "end": 3368.0, "text": " which I've never used, but I've heard people...", "tokens": [597, 286, 600, 1128, 1143, 11, 457, 286, 600, 2198, 561, 485], "temperature": 0.0, "avg_logprob": -0.15688210267287034, "compression_ratio": 1.568075117370892, "no_speech_prob": 2.902247842939687e-06}, {"id": 881, "seek": 336800, "start": 3368.0, "end": 3375.0, "text": " I went to a Backbone meetup once in Paris, and they talked pretty much about anything else.", "tokens": [286, 1437, 281, 257, 5833, 19782, 1677, 1010, 1564, 294, 8380, 11, 293, 436, 2825, 1238, 709, 466, 1340, 1646, 13], "temperature": 0.0, "avg_logprob": -0.18340738040884746, "compression_ratio": 1.6713615023474178, "no_speech_prob": 5.421682544692885e-06}, {"id": 882, "seek": 336800, "start": 3375.0, "end": 3383.0, "text": " I didn't learn any Backbone there, because Backbone did what it had to do,", "tokens": [286, 994, 380, 1466, 604, 5833, 19782, 456, 11, 570, 5833, 19782, 630, 437, 309, 632, 281, 360, 11], "temperature": 0.0, "avg_logprob": -0.18340738040884746, "compression_ratio": 1.6713615023474178, "no_speech_prob": 5.421682544692885e-06}, {"id": 883, "seek": 336800, "start": 3383.0, "end": 3387.0, "text": " and they talked about other projects that worked well with Backbone.", "tokens": [293, 436, 2825, 466, 661, 4455, 300, 2732, 731, 365, 5833, 19782, 13], "temperature": 0.0, "avg_logprob": -0.18340738040884746, "compression_ratio": 1.6713615023474178, "no_speech_prob": 5.421682544692885e-06}, {"id": 884, "seek": 336800, "start": 3387.0, "end": 3390.0, "text": " I think, for instance, Lodash or something.", "tokens": [286, 519, 11, 337, 5197, 11, 441, 378, 1299, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.18340738040884746, "compression_ratio": 1.6713615023474178, "no_speech_prob": 5.421682544692885e-06}, {"id": 885, "seek": 336800, "start": 3390.0, "end": 3396.0, "text": " So the project was simple enough, in a way, and it did what it needed to do.", "tokens": [407, 264, 1716, 390, 2199, 1547, 11, 294, 257, 636, 11, 293, 309, 630, 437, 309, 2978, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.18340738040884746, "compression_ratio": 1.6713615023474178, "no_speech_prob": 5.421682544692885e-06}, {"id": 886, "seek": 339600, "start": 3396.0, "end": 3400.0, "text": " But it was inadequate for some use cases, and therefore died out.", "tokens": [583, 309, 390, 42107, 337, 512, 764, 3331, 11, 293, 4412, 4539, 484, 13], "temperature": 0.0, "avg_logprob": -0.2856642185956582, "compression_ratio": 1.5544554455445545, "no_speech_prob": 2.11085698538227e-05}, {"id": 887, "seek": 339600, "start": 3400.0, "end": 3404.0, "text": " That might be one of the reasons why it died out, I don't know.", "tokens": [663, 1062, 312, 472, 295, 264, 4112, 983, 309, 4539, 484, 11, 286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.2856642185956582, "compression_ratio": 1.5544554455445545, "no_speech_prob": 2.11085698538227e-05}, {"id": 888, "seek": 339600, "start": 3404.0, "end": 3413.0, "text": " But yeah, it is possible for it to finish, if you lay the right groundwork.", "tokens": [583, 1338, 11, 309, 307, 1944, 337, 309, 281, 2413, 11, 498, 291, 2360, 264, 558, 2727, 1902, 13], "temperature": 0.0, "avg_logprob": -0.2856642185956582, "compression_ratio": 1.5544554455445545, "no_speech_prob": 2.11085698538227e-05}, {"id": 889, "seek": 339600, "start": 3413.0, "end": 3415.0, "text": " Or don't know how you say that.", "tokens": [1610, 500, 380, 458, 577, 291, 584, 300, 13], "temperature": 0.0, "avg_logprob": -0.2856642185956582, "compression_ratio": 1.5544554455445545, "no_speech_prob": 2.11085698538227e-05}, {"id": 890, "seek": 339600, "start": 3415.0, "end": 3422.0, "text": " Yeah, if your vision wants to allow users to do an enormous amount of things", "tokens": [865, 11, 498, 428, 5201, 2738, 281, 2089, 5022, 281, 360, 364, 11322, 2372, 295, 721], "temperature": 0.0, "avg_logprob": -0.2856642185956582, "compression_ratio": 1.5544554455445545, "no_speech_prob": 2.11085698538227e-05}, {"id": 891, "seek": 342200, "start": 3422.0, "end": 3428.0, "text": " that you're not doing, then yeah, you're far from being done, right?", "tokens": [300, 291, 434, 406, 884, 11, 550, 1338, 11, 291, 434, 1400, 490, 885, 1096, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.21860808360425732, "compression_ratio": 1.473170731707317, "no_speech_prob": 6.807882891735062e-05}, {"id": 892, "seek": 342200, "start": 3428.0, "end": 3434.0, "text": " Yeah, I think it's extremely valuable to put a lot of thought into how you scope a project.", "tokens": [865, 11, 286, 519, 309, 311, 4664, 8263, 281, 829, 257, 688, 295, 1194, 666, 577, 291, 11923, 257, 1716, 13], "temperature": 0.0, "avg_logprob": -0.21860808360425732, "compression_ratio": 1.473170731707317, "no_speech_prob": 6.807882891735062e-05}, {"id": 893, "seek": 342200, "start": 3434.0, "end": 3442.0, "text": " Because, at the beginning of the episode, we talked about what should users expect from maintainers.", "tokens": [1436, 11, 412, 264, 2863, 295, 264, 3500, 11, 321, 2825, 466, 437, 820, 5022, 2066, 490, 6909, 433, 13], "temperature": 0.0, "avg_logprob": -0.21860808360425732, "compression_ratio": 1.473170731707317, "no_speech_prob": 6.807882891735062e-05}, {"id": 894, "seek": 342200, "start": 3442.0, "end": 3446.0, "text": " And of course, the software comes as is.", "tokens": [400, 295, 1164, 11, 264, 4722, 1487, 382, 307, 13], "temperature": 0.0, "avg_logprob": -0.21860808360425732, "compression_ratio": 1.473170731707317, "no_speech_prob": 6.807882891735062e-05}, {"id": 895, "seek": 344600, "start": 3446.0, "end": 3454.0, "text": " If you really don't want a big commitment, then don't take on a large scope of the project.", "tokens": [759, 291, 534, 500, 380, 528, 257, 955, 8371, 11, 550, 500, 380, 747, 322, 257, 2416, 11923, 295, 264, 1716, 13], "temperature": 0.0, "avg_logprob": -0.2201558963672535, "compression_ratio": 1.3769633507853403, "no_speech_prob": 2.709848376980517e-05}, {"id": 896, "seek": 344600, "start": 3454.0, "end": 3456.0, "text": " Try to narrow the scope down.", "tokens": [6526, 281, 9432, 264, 11923, 760, 13], "temperature": 0.0, "avg_logprob": -0.2201558963672535, "compression_ratio": 1.3769633507853403, "no_speech_prob": 2.709848376980517e-05}, {"id": 897, "seek": 344600, "start": 3456.0, "end": 3463.0, "text": " Or at least communicate what you plan to contribute to it over time.", "tokens": [1610, 412, 1935, 7890, 437, 291, 1393, 281, 10586, 281, 309, 670, 565, 13], "temperature": 0.0, "avg_logprob": -0.2201558963672535, "compression_ratio": 1.3769633507853403, "no_speech_prob": 2.709848376980517e-05}, {"id": 898, "seek": 344600, "start": 3463.0, "end": 3470.0, "text": " But I think, we talked to Ryan Haskell-Glatz about his approach in LMSPA", "tokens": [583, 286, 519, 11, 321, 2825, 281, 9116, 8646, 43723, 12, 38, 75, 10300, 466, 702, 3109, 294, 441, 10288, 10297], "temperature": 0.0, "avg_logprob": -0.2201558963672535, "compression_ratio": 1.3769633507853403, "no_speech_prob": 2.709848376980517e-05}, {"id": 899, "seek": 347000, "start": 3470.0, "end": 3479.0, "text": " with just trying to not make people blocked on his technical decisions by providing extension points.", "tokens": [365, 445, 1382, 281, 406, 652, 561, 15470, 322, 702, 6191, 5327, 538, 6530, 10320, 2793, 13], "temperature": 0.0, "avg_logprob": -0.20789366057424835, "compression_ratio": 1.654320987654321, "no_speech_prob": 3.809624831774272e-05}, {"id": 900, "seek": 347000, "start": 3479.0, "end": 3484.0, "text": " Where the framework isn't responsible for everything they want to do.", "tokens": [2305, 264, 8388, 1943, 380, 6250, 337, 1203, 436, 528, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.20789366057424835, "compression_ratio": 1.654320987654321, "no_speech_prob": 3.809624831774272e-05}, {"id": 901, "seek": 347000, "start": 3484.0, "end": 3490.0, "text": " And Ryan was even talking about it, he's almost afraid of taking on that responsibility of", "tokens": [400, 9116, 390, 754, 1417, 466, 309, 11, 415, 311, 1920, 4638, 295, 1940, 322, 300, 6357, 295], "temperature": 0.0, "avg_logprob": -0.20789366057424835, "compression_ratio": 1.654320987654321, "no_speech_prob": 3.809624831774272e-05}, {"id": 902, "seek": 347000, "start": 3490.0, "end": 3494.0, "text": " users don't have a way to do things unless I give it to them.", "tokens": [5022, 500, 380, 362, 257, 636, 281, 360, 721, 5969, 286, 976, 309, 281, 552, 13], "temperature": 0.0, "avg_logprob": -0.20789366057424835, "compression_ratio": 1.654320987654321, "no_speech_prob": 3.809624831774272e-05}, {"id": 903, "seek": 347000, "start": 3494.0, "end": 3496.0, "text": " And I think that's very wise.", "tokens": [400, 286, 519, 300, 311, 588, 10829, 13], "temperature": 0.0, "avg_logprob": -0.20789366057424835, "compression_ratio": 1.654320987654321, "no_speech_prob": 3.809624831774272e-05}, {"id": 904, "seek": 347000, "start": 3496.0, "end": 3498.0, "text": " And I think that's a good way to run a project.", "tokens": [400, 286, 519, 300, 311, 257, 665, 636, 281, 1190, 257, 1716, 13], "temperature": 0.0, "avg_logprob": -0.20789366057424835, "compression_ratio": 1.654320987654321, "no_speech_prob": 3.809624831774272e-05}, {"id": 905, "seek": 349800, "start": 3498.0, "end": 3502.0, "text": " You should really consider if that's what you want to do.", "tokens": [509, 820, 534, 1949, 498, 300, 311, 437, 291, 528, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.1939245146148059, "compression_ratio": 1.514018691588785, "no_speech_prob": 1.4282441043178551e-05}, {"id": 906, "seek": 349800, "start": 3502.0, "end": 3506.0, "text": " And avoid it if at all possible.", "tokens": [400, 5042, 309, 498, 412, 439, 1944, 13], "temperature": 0.0, "avg_logprob": -0.1939245146148059, "compression_ratio": 1.514018691588785, "no_speech_prob": 1.4282441043178551e-05}, {"id": 907, "seek": 349800, "start": 3506.0, "end": 3512.0, "text": " Yeah, LMSPA is one of those projects where if you limit what people can do,", "tokens": [865, 11, 441, 10288, 10297, 307, 472, 295, 729, 4455, 689, 498, 291, 4948, 437, 561, 393, 360, 11], "temperature": 0.0, "avg_logprob": -0.1939245146148059, "compression_ratio": 1.514018691588785, "no_speech_prob": 1.4282441043178551e-05}, {"id": 908, "seek": 349800, "start": 3512.0, "end": 3516.0, "text": " it's going to kill the project or it's going to frustrate users.", "tokens": [309, 311, 516, 281, 1961, 264, 1716, 420, 309, 311, 516, 281, 7454, 4404, 5022, 13], "temperature": 0.0, "avg_logprob": -0.1939245146148059, "compression_ratio": 1.514018691588785, "no_speech_prob": 1.4282441043178551e-05}, {"id": 909, "seek": 349800, "start": 3516.0, "end": 3517.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.1939245146148059, "compression_ratio": 1.514018691588785, "no_speech_prob": 1.4282441043178551e-05}, {"id": 910, "seek": 349800, "start": 3517.0, "end": 3524.0, "text": " If it's an auctioneering tool, then that's a lot more accepted, I would say.", "tokens": [759, 309, 311, 364, 1609, 882, 68, 1794, 2290, 11, 550, 300, 311, 257, 688, 544, 9035, 11, 286, 576, 584, 13], "temperature": 0.0, "avg_logprob": -0.1939245146148059, "compression_ratio": 1.514018691588785, "no_speech_prob": 1.4282441043178551e-05}, {"id": 911, "seek": 349800, "start": 3524.0, "end": 3525.0, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.1939245146148059, "compression_ratio": 1.514018691588785, "no_speech_prob": 1.4282441043178551e-05}, {"id": 912, "seek": 352500, "start": 3525.0, "end": 3531.0, "text": " For instance, for Elm Review, I feel like if I don't allow rule authors to make something,", "tokens": [1171, 5197, 11, 337, 2699, 76, 19954, 11, 286, 841, 411, 498, 286, 500, 380, 2089, 4978, 16552, 281, 652, 746, 11], "temperature": 0.0, "avg_logprob": -0.18505112041126598, "compression_ratio": 1.5743801652892562, "no_speech_prob": 3.966872100136243e-06}, {"id": 913, "seek": 352500, "start": 3531.0, "end": 3534.0, "text": " then it's a shame.", "tokens": [550, 309, 311, 257, 10069, 13], "temperature": 0.0, "avg_logprob": -0.18505112041126598, "compression_ratio": 1.5743801652892562, "no_speech_prob": 3.966872100136243e-06}, {"id": 914, "seek": 352500, "start": 3534.0, "end": 3539.0, "text": " If it's something that could have been useful, then it's a shame, but it's okay.", "tokens": [759, 309, 311, 746, 300, 727, 362, 668, 4420, 11, 550, 309, 311, 257, 10069, 11, 457, 309, 311, 1392, 13], "temperature": 0.0, "avg_logprob": -0.18505112041126598, "compression_ratio": 1.5743801652892562, "no_speech_prob": 3.966872100136243e-06}, {"id": 915, "seek": 352500, "start": 3539.0, "end": 3544.0, "text": " If you do that with Elm Pages or LMSPA, that's not going to float.", "tokens": [759, 291, 360, 300, 365, 2699, 76, 430, 1660, 420, 441, 10288, 10297, 11, 300, 311, 406, 516, 281, 15706, 13], "temperature": 0.0, "avg_logprob": -0.18505112041126598, "compression_ratio": 1.5743801652892562, "no_speech_prob": 3.966872100136243e-06}, {"id": 916, "seek": 352500, "start": 3544.0, "end": 3545.0, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.18505112041126598, "compression_ratio": 1.5743801652892562, "no_speech_prob": 3.966872100136243e-06}, {"id": 917, "seek": 352500, "start": 3545.0, "end": 3553.0, "text": " So one thing we haven't talked about yet at this point is how do you get feedback from users or from contributors?", "tokens": [407, 472, 551, 321, 2378, 380, 2825, 466, 1939, 412, 341, 935, 307, 577, 360, 291, 483, 5824, 490, 5022, 420, 490, 45627, 30], "temperature": 0.0, "avg_logprob": -0.18505112041126598, "compression_ratio": 1.5743801652892562, "no_speech_prob": 3.966872100136243e-06}, {"id": 918, "seek": 355300, "start": 3553.0, "end": 3560.0, "text": " So, I mean, we come up with plenty of tool or feature ideas,", "tokens": [407, 11, 286, 914, 11, 321, 808, 493, 365, 7140, 295, 2290, 420, 4111, 3487, 11], "temperature": 0.0, "avg_logprob": -0.22641183932622275, "compression_ratio": 1.5890410958904109, "no_speech_prob": 4.6805413148831576e-05}, {"id": 919, "seek": 355300, "start": 3560.0, "end": 3564.0, "text": " and we know we're not always perfect in our decisions.", "tokens": [293, 321, 458, 321, 434, 406, 1009, 2176, 294, 527, 5327, 13], "temperature": 0.0, "avg_logprob": -0.22641183932622275, "compression_ratio": 1.5890410958904109, "no_speech_prob": 4.6805413148831576e-05}, {"id": 920, "seek": 355300, "start": 3564.0, "end": 3568.0, "text": " And sometimes it takes us years to think of some things.", "tokens": [400, 2171, 309, 2516, 505, 924, 281, 519, 295, 512, 721, 13], "temperature": 0.0, "avg_logprob": -0.22641183932622275, "compression_ratio": 1.5890410958904109, "no_speech_prob": 4.6805413148831576e-05}, {"id": 921, "seek": 355300, "start": 3568.0, "end": 3569.0, "text": " And therefore, we need feedback.", "tokens": [400, 4412, 11, 321, 643, 5824, 13], "temperature": 0.0, "avg_logprob": -0.22641183932622275, "compression_ratio": 1.5890410958904109, "no_speech_prob": 4.6805413148831576e-05}, {"id": 922, "seek": 355300, "start": 3569.0, "end": 3573.0, "text": " We need to know what people will want to use something for,", "tokens": [492, 643, 281, 458, 437, 561, 486, 528, 281, 764, 746, 337, 11], "temperature": 0.0, "avg_logprob": -0.22641183932622275, "compression_ratio": 1.5890410958904109, "no_speech_prob": 4.6805413148831576e-05}, {"id": 923, "seek": 355300, "start": 3573.0, "end": 3576.0, "text": " and we need to ask them their opinion.", "tokens": [293, 321, 643, 281, 1029, 552, 641, 4800, 13], "temperature": 0.0, "avg_logprob": -0.22641183932622275, "compression_ratio": 1.5890410958904109, "no_speech_prob": 4.6805413148831576e-05}, {"id": 924, "seek": 355300, "start": 3576.0, "end": 3579.0, "text": " So how do you go about that and doing that?", "tokens": [407, 577, 360, 291, 352, 466, 300, 293, 884, 300, 30], "temperature": 0.0, "avg_logprob": -0.22641183932622275, "compression_ratio": 1.5890410958904109, "no_speech_prob": 4.6805413148831576e-05}, {"id": 925, "seek": 357900, "start": 3579.0, "end": 3588.0, "text": " Yeah, well, I love feedback, and I think that feedback is essential for the health of a project, in my opinion.", "tokens": [865, 11, 731, 11, 286, 959, 5824, 11, 293, 286, 519, 300, 5824, 307, 7115, 337, 264, 1585, 295, 257, 1716, 11, 294, 452, 4800, 13], "temperature": 0.0, "avg_logprob": -0.1798154219840337, "compression_ratio": 1.5622317596566524, "no_speech_prob": 1.8340580936637707e-05}, {"id": 926, "seek": 357900, "start": 3588.0, "end": 3594.0, "text": " And it's a role that users are uniquely able to play.", "tokens": [400, 309, 311, 257, 3090, 300, 5022, 366, 31474, 1075, 281, 862, 13], "temperature": 0.0, "avg_logprob": -0.1798154219840337, "compression_ratio": 1.5622317596566524, "no_speech_prob": 1.8340580936637707e-05}, {"id": 927, "seek": 357900, "start": 3594.0, "end": 3600.0, "text": " Of course, we can give ourselves feedback, but we're kind of biased in the way we perceive things.", "tokens": [2720, 1164, 11, 321, 393, 976, 4175, 5824, 11, 457, 321, 434, 733, 295, 28035, 294, 264, 636, 321, 20281, 721, 13], "temperature": 0.0, "avg_logprob": -0.1798154219840337, "compression_ratio": 1.5622317596566524, "no_speech_prob": 1.8340580936637707e-05}, {"id": 928, "seek": 357900, "start": 3600.0, "end": 3603.0, "text": " Yeah, I mean, we are still users of our own tools.", "tokens": [865, 11, 286, 914, 11, 321, 366, 920, 5022, 295, 527, 1065, 3873, 13], "temperature": 0.0, "avg_logprob": -0.1798154219840337, "compression_ratio": 1.5622317596566524, "no_speech_prob": 1.8340580936637707e-05}, {"id": 929, "seek": 357900, "start": 3603.0, "end": 3604.0, "text": " We are users.", "tokens": [492, 366, 5022, 13], "temperature": 0.0, "avg_logprob": -0.1798154219840337, "compression_ratio": 1.5622317596566524, "no_speech_prob": 1.8340580936637707e-05}, {"id": 930, "seek": 357900, "start": 3604.0, "end": 3605.0, "text": " Thankfully.", "tokens": [28344, 13], "temperature": 0.0, "avg_logprob": -0.1798154219840337, "compression_ratio": 1.5622317596566524, "no_speech_prob": 1.8340580936637707e-05}, {"id": 931, "seek": 357900, "start": 3605.0, "end": 3608.0, "text": " Otherwise, like, yeah.", "tokens": [10328, 11, 411, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.1798154219840337, "compression_ratio": 1.5622317596566524, "no_speech_prob": 1.8340580936637707e-05}, {"id": 932, "seek": 360800, "start": 3608.0, "end": 3615.0, "text": " But there's also a huge value to getting feedback from different uses of the tool.", "tokens": [583, 456, 311, 611, 257, 2603, 2158, 281, 1242, 5824, 490, 819, 4960, 295, 264, 2290, 13], "temperature": 0.0, "avg_logprob": -0.1889388390949794, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.00015116359281819314}, {"id": 933, "seek": 360800, "start": 3615.0, "end": 3618.0, "text": " And so I think it's an essential process.", "tokens": [400, 370, 286, 519, 309, 311, 364, 7115, 1399, 13], "temperature": 0.0, "avg_logprob": -0.1889388390949794, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.00015116359281819314}, {"id": 934, "seek": 360800, "start": 3618.0, "end": 3623.0, "text": " And I mean, for me, the first thing that comes to mind is just ask.", "tokens": [400, 286, 914, 11, 337, 385, 11, 264, 700, 551, 300, 1487, 281, 1575, 307, 445, 1029, 13], "temperature": 0.0, "avg_logprob": -0.1889388390949794, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.00015116359281819314}, {"id": 935, "seek": 360800, "start": 3623.0, "end": 3624.0, "text": " Ask for feedback.", "tokens": [12320, 337, 5824, 13], "temperature": 0.0, "avg_logprob": -0.1889388390949794, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.00015116359281819314}, {"id": 936, "seek": 360800, "start": 3624.0, "end": 3626.0, "text": " I try to ask for feedback all the time.", "tokens": [286, 853, 281, 1029, 337, 5824, 439, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.1889388390949794, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.00015116359281819314}, {"id": 937, "seek": 360800, "start": 3626.0, "end": 3630.0, "text": " Like, you know, I would love to hear what you think of this.", "tokens": [1743, 11, 291, 458, 11, 286, 576, 959, 281, 1568, 437, 291, 519, 295, 341, 13], "temperature": 0.0, "avg_logprob": -0.1889388390949794, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.00015116359281819314}, {"id": 938, "seek": 360800, "start": 3630.0, "end": 3635.0, "text": " And I often ask that on Slack when I release a new feature.", "tokens": [400, 286, 2049, 1029, 300, 322, 37211, 562, 286, 4374, 257, 777, 4111, 13], "temperature": 0.0, "avg_logprob": -0.1889388390949794, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.00015116359281819314}, {"id": 939, "seek": 360800, "start": 3635.0, "end": 3637.0, "text": " Also in GitHub issues.", "tokens": [2743, 294, 23331, 2663, 13], "temperature": 0.0, "avg_logprob": -0.1889388390949794, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.00015116359281819314}, {"id": 940, "seek": 363700, "start": 3637.0, "end": 3647.0, "text": " You know, that's another like if somebody opens an issue, then again, that conversation of somebody opening an issue and saying this needs to do this,", "tokens": [509, 458, 11, 300, 311, 1071, 411, 498, 2618, 9870, 364, 2734, 11, 550, 797, 11, 300, 3761, 295, 2618, 5193, 364, 2734, 293, 1566, 341, 2203, 281, 360, 341, 11], "temperature": 0.0, "avg_logprob": -0.22276629130045572, "compression_ratio": 1.6237623762376239, "no_speech_prob": 4.468440965865739e-05}, {"id": 941, "seek": 363700, "start": 3647.0, "end": 3651.0, "text": " and then peeling that back and saying, well, what problem are you trying to solve?", "tokens": [293, 550, 39926, 300, 646, 293, 1566, 11, 731, 11, 437, 1154, 366, 291, 1382, 281, 5039, 30], "temperature": 0.0, "avg_logprob": -0.22276629130045572, "compression_ratio": 1.6237623762376239, "no_speech_prob": 4.468440965865739e-05}, {"id": 942, "seek": 363700, "start": 3651.0, "end": 3658.0, "text": " Sometimes that turns into understanding the experience people are having more.", "tokens": [4803, 300, 4523, 666, 3701, 264, 1752, 561, 366, 1419, 544, 13], "temperature": 0.0, "avg_logprob": -0.22276629130045572, "compression_ratio": 1.6237623762376239, "no_speech_prob": 4.468440965865739e-05}, {"id": 943, "seek": 363700, "start": 3658.0, "end": 3659.0, "text": " What about you?", "tokens": [708, 466, 291, 30], "temperature": 0.0, "avg_logprob": -0.22276629130045572, "compression_ratio": 1.6237623762376239, "no_speech_prob": 4.468440965865739e-05}, {"id": 944, "seek": 365900, "start": 3659.0, "end": 3669.0, "text": " Yeah, I guess nowadays there's a sufficient number of people who roam the Elm Review Slack channel.", "tokens": [865, 11, 286, 2041, 13434, 456, 311, 257, 11563, 1230, 295, 561, 567, 40474, 264, 2699, 76, 19954, 37211, 2269, 13], "temperature": 0.0, "avg_logprob": -0.26089981926812067, "compression_ratio": 1.4935064935064934, "no_speech_prob": 5.771346422989154e-06}, {"id": 945, "seek": 365900, "start": 3669.0, "end": 3674.0, "text": " So there are people responding to my questions, and that feels good.", "tokens": [407, 456, 366, 561, 16670, 281, 452, 1651, 11, 293, 300, 3417, 665, 13], "temperature": 0.0, "avg_logprob": -0.26089981926812067, "compression_ratio": 1.4935064935064934, "no_speech_prob": 5.771346422989154e-06}, {"id": 946, "seek": 365900, "start": 3674.0, "end": 3676.0, "text": " Unless they're very technical.", "tokens": [16581, 436, 434, 588, 6191, 13], "temperature": 0.0, "avg_logprob": -0.26089981926812067, "compression_ratio": 1.4935064935064934, "no_speech_prob": 5.771346422989154e-06}, {"id": 947, "seek": 365900, "start": 3676.0, "end": 3681.0, "text": " My questions, I mean, and I'm the only person who cares about this thing.", "tokens": [1222, 1651, 11, 286, 914, 11, 293, 286, 478, 264, 787, 954, 567, 12310, 466, 341, 551, 13], "temperature": 0.0, "avg_logprob": -0.26089981926812067, "compression_ratio": 1.4935064935064934, "no_speech_prob": 5.771346422989154e-06}, {"id": 948, "seek": 365900, "start": 3681.0, "end": 3684.0, "text": " Then I don't always get answers.", "tokens": [1396, 286, 500, 380, 1009, 483, 6338, 13], "temperature": 0.0, "avg_logprob": -0.26089981926812067, "compression_ratio": 1.4935064935064934, "no_speech_prob": 5.771346422989154e-06}, {"id": 949, "seek": 365900, "start": 3684.0, "end": 3687.0, "text": " But usually, yeah, just ask questions.", "tokens": [583, 2673, 11, 1338, 11, 445, 1029, 1651, 13], "temperature": 0.0, "avg_logprob": -0.26089981926812067, "compression_ratio": 1.4935064935064934, "no_speech_prob": 5.771346422989154e-06}, {"id": 950, "seek": 368700, "start": 3687.0, "end": 3692.0, "text": " I do have ideas that take months to complete.", "tokens": [286, 360, 362, 3487, 300, 747, 2493, 281, 3566, 13], "temperature": 0.0, "avg_logprob": -0.20332805926983172, "compression_ratio": 1.6387665198237886, "no_speech_prob": 6.302141264313832e-05}, {"id": 951, "seek": 368700, "start": 3692.0, "end": 3700.0, "text": " And then I write an RFC or write some kind of blog post in my notes, you know, and then I make an issue of that.", "tokens": [400, 550, 286, 2464, 364, 497, 18671, 420, 2464, 512, 733, 295, 6968, 2183, 294, 452, 5570, 11, 291, 458, 11, 293, 550, 286, 652, 364, 2734, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.20332805926983172, "compression_ratio": 1.6387665198237886, "no_speech_prob": 6.302141264313832e-05}, {"id": 952, "seek": 368700, "start": 3700.0, "end": 3701.0, "text": " I don't do that nearly enough.", "tokens": [286, 500, 380, 360, 300, 6217, 1547, 13], "temperature": 0.0, "avg_logprob": -0.20332805926983172, "compression_ratio": 1.6387665198237886, "no_speech_prob": 6.302141264313832e-05}, {"id": 953, "seek": 368700, "start": 3701.0, "end": 3708.0, "text": " I have plenty of ideas that I should make available for people to comment on.", "tokens": [286, 362, 7140, 295, 3487, 300, 286, 820, 652, 2435, 337, 561, 281, 2871, 322, 13], "temperature": 0.0, "avg_logprob": -0.20332805926983172, "compression_ratio": 1.6387665198237886, "no_speech_prob": 6.302141264313832e-05}, {"id": 954, "seek": 368700, "start": 3708.0, "end": 3711.0, "text": " And maybe they would just add like one simple comment.", "tokens": [400, 1310, 436, 576, 445, 909, 411, 472, 2199, 2871, 13], "temperature": 0.0, "avg_logprob": -0.20332805926983172, "compression_ratio": 1.6387665198237886, "no_speech_prob": 6.302141264313832e-05}, {"id": 955, "seek": 368700, "start": 3711.0, "end": 3713.0, "text": " And I would be like, oh, yeah, that's a solution.", "tokens": [400, 286, 576, 312, 411, 11, 1954, 11, 1338, 11, 300, 311, 257, 3827, 13], "temperature": 0.0, "avg_logprob": -0.20332805926983172, "compression_ratio": 1.6387665198237886, "no_speech_prob": 6.302141264313832e-05}, {"id": 956, "seek": 371300, "start": 3713.0, "end": 3717.0, "text": " But that just takes a lot of time still, right?", "tokens": [583, 300, 445, 2516, 257, 688, 295, 565, 920, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18061759823658427, "compression_ratio": 1.5611814345991561, "no_speech_prob": 5.306534512783401e-05}, {"id": 957, "seek": 371300, "start": 3717.0, "end": 3720.0, "text": " Just to get it to a point where you can share it.", "tokens": [1449, 281, 483, 309, 281, 257, 935, 689, 291, 393, 2073, 309, 13], "temperature": 0.0, "avg_logprob": -0.18061759823658427, "compression_ratio": 1.5611814345991561, "no_speech_prob": 5.306534512783401e-05}, {"id": 958, "seek": 371300, "start": 3720.0, "end": 3721.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.18061759823658427, "compression_ratio": 1.5611814345991561, "no_speech_prob": 5.306534512783401e-05}, {"id": 959, "seek": 371300, "start": 3721.0, "end": 3726.0, "text": " For instance, like the other day, I was like, here's an idea.", "tokens": [1171, 5197, 11, 411, 264, 661, 786, 11, 286, 390, 411, 11, 510, 311, 364, 1558, 13], "temperature": 0.0, "avg_logprob": -0.18061759823658427, "compression_ratio": 1.5611814345991561, "no_speech_prob": 5.306534512783401e-05}, {"id": 960, "seek": 371300, "start": 3726.0, "end": 3728.0, "text": " I've thought about this for a while.", "tokens": [286, 600, 1194, 466, 341, 337, 257, 1339, 13], "temperature": 0.0, "avg_logprob": -0.18061759823658427, "compression_ratio": 1.5611814345991561, "no_speech_prob": 5.306534512783401e-05}, {"id": 961, "seek": 371300, "start": 3728.0, "end": 3729.0, "text": " I don't know if it's perfect.", "tokens": [286, 500, 380, 458, 498, 309, 311, 2176, 13], "temperature": 0.0, "avg_logprob": -0.18061759823658427, "compression_ratio": 1.5611814345991561, "no_speech_prob": 5.306534512783401e-05}, {"id": 962, "seek": 371300, "start": 3729.0, "end": 3732.0, "text": " And it's a very long thing.", "tokens": [400, 309, 311, 257, 588, 938, 551, 13], "temperature": 0.0, "avg_logprob": -0.18061759823658427, "compression_ratio": 1.5611814345991561, "no_speech_prob": 5.306534512783401e-05}, {"id": 963, "seek": 371300, "start": 3732.0, "end": 3738.0, "text": " I'm like, ah, I don't know if I'm in the mood of writing, of adding an example to this.", "tokens": [286, 478, 411, 11, 3716, 11, 286, 500, 380, 458, 498, 286, 478, 294, 264, 9268, 295, 3579, 11, 295, 5127, 364, 1365, 281, 341, 13], "temperature": 0.0, "avg_logprob": -0.18061759823658427, "compression_ratio": 1.5611814345991561, "no_speech_prob": 5.306534512783401e-05}, {"id": 964, "seek": 371300, "start": 3738.0, "end": 3740.0, "text": " Like a few use cases.", "tokens": [1743, 257, 1326, 764, 3331, 13], "temperature": 0.0, "avg_logprob": -0.18061759823658427, "compression_ratio": 1.5611814345991561, "no_speech_prob": 5.306534512783401e-05}, {"id": 965, "seek": 374000, "start": 3740.0, "end": 3743.0, "text": " Let me just get it over with and send it.", "tokens": [961, 385, 445, 483, 309, 670, 365, 293, 2845, 309, 13], "temperature": 0.0, "avg_logprob": -0.261028271276974, "compression_ratio": 1.5042735042735043, "no_speech_prob": 1.5935866031213664e-05}, {"id": 966, "seek": 374000, "start": 3743.0, "end": 3749.0, "text": " And a few minutes later, someone comes down and asks, do you have any use cases or examples for this?", "tokens": [400, 257, 1326, 2077, 1780, 11, 1580, 1487, 760, 293, 8962, 11, 360, 291, 362, 604, 764, 3331, 420, 5110, 337, 341, 30], "temperature": 0.0, "avg_logprob": -0.261028271276974, "compression_ratio": 1.5042735042735043, "no_speech_prob": 1.5935866031213664e-05}, {"id": 967, "seek": 374000, "start": 3749.0, "end": 3751.0, "text": " Like, ah.", "tokens": [1743, 11, 3716, 13], "temperature": 0.0, "avg_logprob": -0.261028271276974, "compression_ratio": 1.5042735042735043, "no_speech_prob": 1.5935866031213664e-05}, {"id": 968, "seek": 374000, "start": 3751.0, "end": 3754.0, "text": " Well, OK, well, now I'm going to add those.", "tokens": [1042, 11, 2264, 11, 731, 11, 586, 286, 478, 516, 281, 909, 729, 13], "temperature": 0.0, "avg_logprob": -0.261028271276974, "compression_ratio": 1.5042735042735043, "no_speech_prob": 1.5935866031213664e-05}, {"id": 969, "seek": 374000, "start": 3754.0, "end": 3757.0, "text": " But at least the idea will get out.", "tokens": [583, 412, 1935, 264, 1558, 486, 483, 484, 13], "temperature": 0.0, "avg_logprob": -0.261028271276974, "compression_ratio": 1.5042735042735043, "no_speech_prob": 1.5935866031213664e-05}, {"id": 970, "seek": 374000, "start": 3757.0, "end": 3767.0, "text": " So, yeah, it takes a long time, especially to present ideas in a way that's still, that are still open for discussion.", "tokens": [407, 11, 1338, 11, 309, 2516, 257, 938, 565, 11, 2318, 281, 1974, 3487, 294, 257, 636, 300, 311, 920, 11, 300, 366, 920, 1269, 337, 5017, 13], "temperature": 0.0, "avg_logprob": -0.261028271276974, "compression_ratio": 1.5042735042735043, "no_speech_prob": 1.5935866031213664e-05}, {"id": 971, "seek": 376700, "start": 3767.0, "end": 3772.0, "text": " Right, because I don't want to have a problem that I want to solve.", "tokens": [1779, 11, 570, 286, 500, 380, 528, 281, 362, 257, 1154, 300, 286, 528, 281, 5039, 13], "temperature": 0.0, "avg_logprob": -0.1969613739938447, "compression_ratio": 1.776190476190476, "no_speech_prob": 3.590601772884838e-05}, {"id": 972, "seek": 376700, "start": 3772.0, "end": 3779.0, "text": " I have some solutions I have in mind, but I don't want to close it to other solutions, which could be better.", "tokens": [286, 362, 512, 6547, 286, 362, 294, 1575, 11, 457, 286, 500, 380, 528, 281, 1998, 309, 281, 661, 6547, 11, 597, 727, 312, 1101, 13], "temperature": 0.0, "avg_logprob": -0.1969613739938447, "compression_ratio": 1.776190476190476, "no_speech_prob": 3.590601772884838e-05}, {"id": 973, "seek": 376700, "start": 3779.0, "end": 3786.0, "text": " And I hope are better because I'm not necessarily entirely satisfied with my own solutions.", "tokens": [400, 286, 1454, 366, 1101, 570, 286, 478, 406, 4725, 7696, 11239, 365, 452, 1065, 6547, 13], "temperature": 0.0, "avg_logprob": -0.1969613739938447, "compression_ratio": 1.776190476190476, "no_speech_prob": 3.590601772884838e-05}, {"id": 974, "seek": 376700, "start": 3786.0, "end": 3791.0, "text": " And sometimes the solution is like, I have an idea.", "tokens": [400, 2171, 264, 3827, 307, 411, 11, 286, 362, 364, 1558, 13], "temperature": 0.0, "avg_logprob": -0.1969613739938447, "compression_ratio": 1.776190476190476, "no_speech_prob": 3.590601772884838e-05}, {"id": 975, "seek": 376700, "start": 3791.0, "end": 3793.0, "text": " I have a problem.", "tokens": [286, 362, 257, 1154, 13], "temperature": 0.0, "avg_logprob": -0.1969613739938447, "compression_ratio": 1.776190476190476, "no_speech_prob": 3.590601772884838e-05}, {"id": 976, "seek": 376700, "start": 3793.0, "end": 3795.0, "text": " Here's a solution I'm suggesting.", "tokens": [1692, 311, 257, 3827, 286, 478, 18094, 13], "temperature": 0.0, "avg_logprob": -0.1969613739938447, "compression_ratio": 1.776190476190476, "no_speech_prob": 3.590601772884838e-05}, {"id": 977, "seek": 379500, "start": 3795.0, "end": 3799.0, "text": " And maybe the result is that is a pretty bad solution.", "tokens": [400, 1310, 264, 1874, 307, 300, 307, 257, 1238, 1578, 3827, 13], "temperature": 0.0, "avg_logprob": -0.19120641549428305, "compression_ratio": 1.4956140350877194, "no_speech_prob": 3.425010436330922e-05}, {"id": 978, "seek": 379500, "start": 3799.0, "end": 3801.0, "text": " Let's just not do it.", "tokens": [961, 311, 445, 406, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.19120641549428305, "compression_ratio": 1.4956140350877194, "no_speech_prob": 3.425010436330922e-05}, {"id": 979, "seek": 379500, "start": 3801.0, "end": 3803.0, "text": " Let's not solve this problem.", "tokens": [961, 311, 406, 5039, 341, 1154, 13], "temperature": 0.0, "avg_logprob": -0.19120641549428305, "compression_ratio": 1.4956140350877194, "no_speech_prob": 3.425010436330922e-05}, {"id": 980, "seek": 379500, "start": 3803.0, "end": 3806.0, "text": " Yeah, I'm a fan of the RFC process as well.", "tokens": [865, 11, 286, 478, 257, 3429, 295, 264, 497, 18671, 1399, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.19120641549428305, "compression_ratio": 1.4956140350877194, "no_speech_prob": 3.425010436330922e-05}, {"id": 981, "seek": 379500, "start": 3806.0, "end": 3816.0, "text": " I think like opening up a GitHub discussion thread and just saying, like, I even like it, even if nobody comments, which happens.", "tokens": [286, 519, 411, 5193, 493, 257, 23331, 5017, 7207, 293, 445, 1566, 11, 411, 11, 286, 754, 411, 309, 11, 754, 498, 5079, 3053, 11, 597, 2314, 13], "temperature": 0.0, "avg_logprob": -0.19120641549428305, "compression_ratio": 1.4956140350877194, "no_speech_prob": 3.425010436330922e-05}, {"id": 982, "seek": 379500, "start": 3816.0, "end": 3821.0, "text": " Like, I find it useful as a document to outline my thoughts.", "tokens": [1743, 11, 286, 915, 309, 4420, 382, 257, 4166, 281, 16387, 452, 4598, 13], "temperature": 0.0, "avg_logprob": -0.19120641549428305, "compression_ratio": 1.4956140350877194, "no_speech_prob": 3.425010436330922e-05}, {"id": 983, "seek": 382100, "start": 3821.0, "end": 3833.0, "text": " And as I'm writing it in a way where I'm trying to present it in a way that's easy to understand for other people and that, you know, lays out all of the possibilities.", "tokens": [400, 382, 286, 478, 3579, 309, 294, 257, 636, 689, 286, 478, 1382, 281, 1974, 309, 294, 257, 636, 300, 311, 1858, 281, 1223, 337, 661, 561, 293, 300, 11, 291, 458, 11, 32714, 484, 439, 295, 264, 12178, 13], "temperature": 0.0, "avg_logprob": -0.1794998614819019, "compression_ratio": 1.5638297872340425, "no_speech_prob": 0.00012917682761326432}, {"id": 984, "seek": 382100, "start": 3833.0, "end": 3840.0, "text": " So people can say like, hey, here are three different paths we could go down here, I think, are the tradeoffs of all of them.", "tokens": [407, 561, 393, 584, 411, 11, 4177, 11, 510, 366, 1045, 819, 14518, 321, 727, 352, 760, 510, 11, 286, 519, 11, 366, 264, 4923, 19231, 295, 439, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.1794998614819019, "compression_ratio": 1.5638297872340425, "no_speech_prob": 0.00012917682761326432}, {"id": 985, "seek": 384000, "start": 3840.0, "end": 3852.0, "text": " I might be missing some, but that process of trying to like exhaustively brainstorm all of the different approaches that are possible and all of the tradeoffs for them is valuable in itself.", "tokens": [286, 1062, 312, 5361, 512, 11, 457, 300, 1399, 295, 1382, 281, 411, 14687, 3413, 35245, 439, 295, 264, 819, 11587, 300, 366, 1944, 293, 439, 295, 264, 4923, 19231, 337, 552, 307, 8263, 294, 2564, 13], "temperature": 0.0, "avg_logprob": -0.19898309253510973, "compression_ratio": 1.6626506024096386, "no_speech_prob": 2.8388811188051477e-05}, {"id": 986, "seek": 384000, "start": 3852.0, "end": 3861.0, "text": " And it's to me, I believe it's more valuable when I believe I'm communicating it to real people, not just in my notes.", "tokens": [400, 309, 311, 281, 385, 11, 286, 1697, 309, 311, 544, 8263, 562, 286, 1697, 286, 478, 17559, 309, 281, 957, 561, 11, 406, 445, 294, 452, 5570, 13], "temperature": 0.0, "avg_logprob": -0.19898309253510973, "compression_ratio": 1.6626506024096386, "no_speech_prob": 2.8388811188051477e-05}, {"id": 987, "seek": 384000, "start": 3861.0, "end": 3864.0, "text": " Yeah, it's like when you have a duck, right?", "tokens": [865, 11, 309, 311, 411, 562, 291, 362, 257, 12482, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.19898309253510973, "compression_ratio": 1.6626506024096386, "no_speech_prob": 2.8388811188051477e-05}, {"id": 988, "seek": 384000, "start": 3864.0, "end": 3867.0, "text": " And you're explaining your problem to a duck.", "tokens": [400, 291, 434, 13468, 428, 1154, 281, 257, 12482, 13], "temperature": 0.0, "avg_logprob": -0.19898309253510973, "compression_ratio": 1.6626506024096386, "no_speech_prob": 2.8388811188051477e-05}, {"id": 989, "seek": 384000, "start": 3867.0, "end": 3868.0, "text": " Right, right.", "tokens": [1779, 11, 558, 13], "temperature": 0.0, "avg_logprob": -0.19898309253510973, "compression_ratio": 1.6626506024096386, "no_speech_prob": 2.8388811188051477e-05}, {"id": 990, "seek": 386800, "start": 3868.0, "end": 3870.0, "text": " Yeah, exactly.", "tokens": [865, 11, 2293, 13], "temperature": 0.0, "avg_logprob": -0.18132228510720388, "compression_ratio": 1.5863309352517985, "no_speech_prob": 3.4267035516677424e-05}, {"id": 991, "seek": 386800, "start": 3870.0, "end": 3874.0, "text": " It's different when you're trying to communicate it and make sure it lands.", "tokens": [467, 311, 819, 562, 291, 434, 1382, 281, 7890, 309, 293, 652, 988, 309, 5949, 13], "temperature": 0.0, "avg_logprob": -0.18132228510720388, "compression_ratio": 1.5863309352517985, "no_speech_prob": 3.4267035516677424e-05}, {"id": 992, "seek": 386800, "start": 3874.0, "end": 3879.0, "text": " And often I do get amazing discussions where people are sharing their use cases and ideas.", "tokens": [400, 2049, 286, 360, 483, 2243, 11088, 689, 561, 366, 5414, 641, 764, 3331, 293, 3487, 13], "temperature": 0.0, "avg_logprob": -0.18132228510720388, "compression_ratio": 1.5863309352517985, "no_speech_prob": 3.4267035516677424e-05}, {"id": 993, "seek": 386800, "start": 3879.0, "end": 3882.0, "text": " So yeah, RFC processes are really valuable.", "tokens": [407, 1338, 11, 497, 18671, 7555, 366, 534, 8263, 13], "temperature": 0.0, "avg_logprob": -0.18132228510720388, "compression_ratio": 1.5863309352517985, "no_speech_prob": 3.4267035516677424e-05}, {"id": 994, "seek": 386800, "start": 3882.0, "end": 3883.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.18132228510720388, "compression_ratio": 1.5863309352517985, "no_speech_prob": 3.4267035516677424e-05}, {"id": 995, "seek": 386800, "start": 3883.0, "end": 3897.0, "text": " And regardless of whether they're in your notes or on GitHub, if you've written them down and you come back to it a few weeks or months after, or a few hours maybe even, you're going to come up with new ideas.", "tokens": [400, 10060, 295, 1968, 436, 434, 294, 428, 5570, 420, 322, 23331, 11, 498, 291, 600, 3720, 552, 760, 293, 291, 808, 646, 281, 309, 257, 1326, 3259, 420, 2493, 934, 11, 420, 257, 1326, 2496, 1310, 754, 11, 291, 434, 516, 281, 808, 493, 365, 777, 3487, 13], "temperature": 0.0, "avg_logprob": -0.18132228510720388, "compression_ratio": 1.5863309352517985, "no_speech_prob": 3.4267035516677424e-05}, {"id": 996, "seek": 389700, "start": 3897.0, "end": 3905.0, "text": " So it's always quite interesting to put it in writing in a way that is well articulated.", "tokens": [407, 309, 311, 1009, 1596, 1880, 281, 829, 309, 294, 3579, 294, 257, 636, 300, 307, 731, 43322, 13], "temperature": 0.0, "avg_logprob": -0.22587365619206834, "compression_ratio": 1.4518072289156627, "no_speech_prob": 0.0001535381015855819}, {"id": 997, "seek": 389700, "start": 3905.0, "end": 3907.0, "text": " Now you can come up with new ideas.", "tokens": [823, 291, 393, 808, 493, 365, 777, 3487, 13], "temperature": 0.0, "avg_logprob": -0.22587365619206834, "compression_ratio": 1.4518072289156627, "no_speech_prob": 0.0001535381015855819}, {"id": 998, "seek": 389700, "start": 3907.0, "end": 3908.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.22587365619206834, "compression_ratio": 1.4518072289156627, "no_speech_prob": 0.0001535381015855819}, {"id": 999, "seek": 389700, "start": 3908.0, "end": 3915.0, "text": " And you might forget all the things you probably will forget, all the different possibilities you considered.", "tokens": [400, 291, 1062, 2870, 439, 264, 721, 291, 1391, 486, 2870, 11, 439, 264, 819, 12178, 291, 4888, 13], "temperature": 0.0, "avg_logprob": -0.22587365619206834, "compression_ratio": 1.4518072289156627, "no_speech_prob": 0.0001535381015855819}, {"id": 1000, "seek": 391500, "start": 3915.0, "end": 3929.0, "text": " And then down the line, a couple of years from now when somebody says, hey, why didn't we do it this way, then you dig through, you search through GitHub and you find that RFC and you're like, oh, actually I talked about the cons here.", "tokens": [400, 550, 760, 264, 1622, 11, 257, 1916, 295, 924, 490, 586, 562, 2618, 1619, 11, 4177, 11, 983, 994, 380, 321, 360, 309, 341, 636, 11, 550, 291, 2528, 807, 11, 291, 3164, 807, 23331, 293, 291, 915, 300, 497, 18671, 293, 291, 434, 411, 11, 1954, 11, 767, 286, 2825, 466, 264, 1014, 510, 13], "temperature": 0.0, "avg_logprob": -0.21082534790039062, "compression_ratio": 1.596, "no_speech_prob": 3.217429548385553e-05}, {"id": 1001, "seek": 391500, "start": 3929.0, "end": 3935.0, "text": " And maybe you missed a consideration or maybe you already thought it through and you just point to that.", "tokens": [400, 1310, 291, 6721, 257, 12381, 420, 1310, 291, 1217, 1194, 309, 807, 293, 291, 445, 935, 281, 300, 13], "temperature": 0.0, "avg_logprob": -0.21082534790039062, "compression_ratio": 1.596, "no_speech_prob": 3.217429548385553e-05}, {"id": 1002, "seek": 391500, "start": 3935.0, "end": 3939.0, "text": " So having those historical documents can be very valuable.", "tokens": [407, 1419, 729, 8584, 8512, 393, 312, 588, 8263, 13], "temperature": 0.0, "avg_logprob": -0.21082534790039062, "compression_ratio": 1.596, "no_speech_prob": 3.217429548385553e-05}, {"id": 1003, "seek": 393900, "start": 3939.0, "end": 3945.0, "text": " And now I have FOMO, I'm wondering, did I do that enough?", "tokens": [400, 586, 286, 362, 479, 5251, 46, 11, 286, 478, 6359, 11, 630, 286, 360, 300, 1547, 30], "temperature": 0.0, "avg_logprob": -0.20976614952087402, "compression_ratio": 1.5405405405405406, "no_speech_prob": 2.546363066358026e-05}, {"id": 1004, "seek": 393900, "start": 3945.0, "end": 3946.0, "text": " It's a good habit.", "tokens": [467, 311, 257, 665, 7164, 13], "temperature": 0.0, "avg_logprob": -0.20976614952087402, "compression_ratio": 1.5405405405405406, "no_speech_prob": 2.546363066358026e-05}, {"id": 1005, "seek": 393900, "start": 3946.0, "end": 3955.0, "text": " So one thing I noticed with, and I'm sure you have as well, noticed with the Elm community is that we like to tend to batch work.", "tokens": [407, 472, 551, 286, 5694, 365, 11, 293, 286, 478, 988, 291, 362, 382, 731, 11, 5694, 365, 264, 2699, 76, 1768, 307, 300, 321, 411, 281, 3928, 281, 15245, 589, 13], "temperature": 0.0, "avg_logprob": -0.20976614952087402, "compression_ratio": 1.5405405405405406, "no_speech_prob": 2.546363066358026e-05}, {"id": 1006, "seek": 393900, "start": 3955.0, "end": 3960.0, "text": " Evan made that quite explicit to talk about batching work.", "tokens": [22613, 1027, 300, 1596, 13691, 281, 751, 466, 15245, 278, 589, 13], "temperature": 0.0, "avg_logprob": -0.20976614952087402, "compression_ratio": 1.5405405405405406, "no_speech_prob": 2.546363066358026e-05}, {"id": 1007, "seek": 393900, "start": 3960.0, "end": 3962.0, "text": " And I feel like we do it too.", "tokens": [400, 286, 841, 411, 321, 360, 309, 886, 13], "temperature": 0.0, "avg_logprob": -0.20976614952087402, "compression_ratio": 1.5405405405405406, "no_speech_prob": 2.546363066358026e-05}, {"id": 1008, "seek": 393900, "start": 3962.0, "end": 3966.0, "text": " I don't know if we do it for the same reasons.", "tokens": [286, 500, 380, 458, 498, 321, 360, 309, 337, 264, 912, 4112, 13], "temperature": 0.0, "avg_logprob": -0.20976614952087402, "compression_ratio": 1.5405405405405406, "no_speech_prob": 2.546363066358026e-05}, {"id": 1009, "seek": 396600, "start": 3966.0, "end": 3973.0, "text": " And I was wondering, so one thing I really don't like is breaking versions.", "tokens": [400, 286, 390, 6359, 11, 370, 472, 551, 286, 534, 500, 380, 411, 307, 7697, 9606, 13], "temperature": 0.0, "avg_logprob": -0.21077930516210094, "compression_ratio": 1.6967213114754098, "no_speech_prob": 2.2123298549558967e-05}, {"id": 1010, "seek": 396600, "start": 3973.0, "end": 3975.0, "text": " I say I really don't like them.", "tokens": [286, 584, 286, 534, 500, 380, 411, 552, 13], "temperature": 0.0, "avg_logprob": -0.21077930516210094, "compression_ratio": 1.6967213114754098, "no_speech_prob": 2.2123298549558967e-05}, {"id": 1011, "seek": 396600, "start": 3975.0, "end": 3983.0, "text": " I just mean, I tried very hard to avoid them because, especially in the case of Elm Review, there's a lot of packages that depend on Elm Review.", "tokens": [286, 445, 914, 11, 286, 3031, 588, 1152, 281, 5042, 552, 570, 11, 2318, 294, 264, 1389, 295, 2699, 76, 19954, 11, 456, 311, 257, 688, 295, 17401, 300, 5672, 322, 2699, 76, 19954, 13], "temperature": 0.0, "avg_logprob": -0.21077930516210094, "compression_ratio": 1.6967213114754098, "no_speech_prob": 2.2123298549558967e-05}, {"id": 1012, "seek": 396600, "start": 3983.0, "end": 3988.0, "text": " So if Elm Review releases a new major version, then all of them need to be updated.", "tokens": [407, 498, 2699, 76, 19954, 16952, 257, 777, 2563, 3037, 11, 550, 439, 295, 552, 643, 281, 312, 10588, 13], "temperature": 0.0, "avg_logprob": -0.21077930516210094, "compression_ratio": 1.6967213114754098, "no_speech_prob": 2.2123298549558967e-05}, {"id": 1013, "seek": 396600, "start": 3988.0, "end": 3990.0, "text": " Some of them are mine, which I can do.", "tokens": [2188, 295, 552, 366, 3892, 11, 597, 286, 393, 360, 13], "temperature": 0.0, "avg_logprob": -0.21077930516210094, "compression_ratio": 1.6967213114754098, "no_speech_prob": 2.2123298549558967e-05}, {"id": 1014, "seek": 396600, "start": 3990.0, "end": 3993.0, "text": " It will just take me a few hours more.", "tokens": [467, 486, 445, 747, 385, 257, 1326, 2496, 544, 13], "temperature": 0.0, "avg_logprob": -0.21077930516210094, "compression_ratio": 1.6967213114754098, "no_speech_prob": 2.2123298549558967e-05}, {"id": 1015, "seek": 399300, "start": 3993.0, "end": 4002.0, "text": " But some of them are for other people, and that will take longer to, that will cause others pain to upgrade.", "tokens": [583, 512, 295, 552, 366, 337, 661, 561, 11, 293, 300, 486, 747, 2854, 281, 11, 300, 486, 3082, 2357, 1822, 281, 11484, 13], "temperature": 0.0, "avg_logprob": -0.21678952420695444, "compression_ratio": 1.4744186046511627, "no_speech_prob": 3.071320679737255e-05}, {"id": 1016, "seek": 399300, "start": 4002.0, "end": 4004.0, "text": " And I want to avoid that as much as possible.", "tokens": [400, 286, 528, 281, 5042, 300, 382, 709, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.21678952420695444, "compression_ratio": 1.4744186046511627, "no_speech_prob": 3.071320679737255e-05}, {"id": 1017, "seek": 399300, "start": 4004.0, "end": 4013.0, "text": " So Elm Review has not had a major version since April 2020, which is quite an achievement in a way.", "tokens": [407, 2699, 76, 19954, 575, 406, 632, 257, 2563, 3037, 1670, 6929, 4808, 11, 597, 307, 1596, 364, 15838, 294, 257, 636, 13], "temperature": 0.0, "avg_logprob": -0.21678952420695444, "compression_ratio": 1.4744186046511627, "no_speech_prob": 3.071320679737255e-05}, {"id": 1018, "seek": 399300, "start": 4013.0, "end": 4018.0, "text": " I know I will want a v3 at some point.", "tokens": [286, 458, 286, 486, 528, 257, 371, 18, 412, 512, 935, 13], "temperature": 0.0, "avg_logprob": -0.21678952420695444, "compression_ratio": 1.4744186046511627, "no_speech_prob": 3.071320679737255e-05}, {"id": 1019, "seek": 399300, "start": 4018.0, "end": 4020.0, "text": " I just don't know when.", "tokens": [286, 445, 500, 380, 458, 562, 13], "temperature": 0.0, "avg_logprob": -0.21678952420695444, "compression_ratio": 1.4744186046511627, "no_speech_prob": 3.071320679737255e-05}, {"id": 1020, "seek": 402000, "start": 4020.0, "end": 4027.0, "text": " I wonder whether this fear of breaking changes causes us to batch work.", "tokens": [286, 2441, 1968, 341, 4240, 295, 7697, 2962, 7700, 505, 281, 15245, 589, 13], "temperature": 0.0, "avg_logprob": -0.1927467145417866, "compression_ratio": 1.5566502463054188, "no_speech_prob": 7.690211418776016e-07}, {"id": 1021, "seek": 402000, "start": 4027.0, "end": 4038.0, "text": " Because Elm enforces semantic versioning, and that means that there are some changes that I can't do without making a new major version.", "tokens": [1436, 2699, 76, 25495, 887, 47982, 3037, 278, 11, 293, 300, 1355, 300, 456, 366, 512, 2962, 300, 286, 393, 380, 360, 1553, 1455, 257, 777, 2563, 3037, 13], "temperature": 0.0, "avg_logprob": -0.1927467145417866, "compression_ratio": 1.5566502463054188, "no_speech_prob": 7.690211418776016e-07}, {"id": 1022, "seek": 402000, "start": 4038.0, "end": 4046.0, "text": " And if I want to avoid them, I need to think really hard about how this feature will be used in the future.", "tokens": [400, 498, 286, 528, 281, 5042, 552, 11, 286, 643, 281, 519, 534, 1152, 466, 577, 341, 4111, 486, 312, 1143, 294, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.1927467145417866, "compression_ratio": 1.5566502463054188, "no_speech_prob": 7.690211418776016e-07}, {"id": 1023, "seek": 404600, "start": 4046.0, "end": 4050.0, "text": " How this feature will affect other things.", "tokens": [1012, 341, 4111, 486, 3345, 661, 721, 13], "temperature": 0.0, "avg_logprob": -0.1837052901585897, "compression_ratio": 1.439153439153439, "no_speech_prob": 8.74791294336319e-05}, {"id": 1024, "seek": 404600, "start": 4050.0, "end": 4055.0, "text": " And in that sense, I need to carefully think about things.", "tokens": [400, 294, 300, 2020, 11, 286, 643, 281, 7500, 519, 466, 721, 13], "temperature": 0.0, "avg_logprob": -0.1837052901585897, "compression_ratio": 1.439153439153439, "no_speech_prob": 8.74791294336319e-05}, {"id": 1025, "seek": 404600, "start": 4055.0, "end": 4059.0, "text": " Make RFCs, write down notes for months or years.", "tokens": [4387, 497, 18671, 82, 11, 2464, 760, 5570, 337, 2493, 420, 924, 13], "temperature": 0.0, "avg_logprob": -0.1837052901585897, "compression_ratio": 1.439153439153439, "no_speech_prob": 8.74791294336319e-05}, {"id": 1026, "seek": 404600, "start": 4059.0, "end": 4067.0, "text": " And once I feel like I have everything thought through, then I can implement it.", "tokens": [400, 1564, 286, 841, 411, 286, 362, 1203, 1194, 807, 11, 550, 286, 393, 4445, 309, 13], "temperature": 0.0, "avg_logprob": -0.1837052901585897, "compression_ratio": 1.439153439153439, "no_speech_prob": 8.74791294336319e-05}, {"id": 1027, "seek": 404600, "start": 4067.0, "end": 4071.0, "text": " And I'm sure get some discoveries still.", "tokens": [400, 286, 478, 988, 483, 512, 28400, 920, 13], "temperature": 0.0, "avg_logprob": -0.1837052901585897, "compression_ratio": 1.439153439153439, "no_speech_prob": 8.74791294336319e-05}, {"id": 1028, "seek": 407100, "start": 4071.0, "end": 4079.0, "text": " But I wonder, if you care about avoiding breaking changes, do you batch work more?", "tokens": [583, 286, 2441, 11, 498, 291, 1127, 466, 20220, 7697, 2962, 11, 360, 291, 15245, 589, 544, 30], "temperature": 0.0, "avg_logprob": -0.2020118327080449, "compression_ratio": 1.7005988023952097, "no_speech_prob": 0.00013725344615522772}, {"id": 1029, "seek": 407100, "start": 4079.0, "end": 4081.0, "text": " What do you think?", "tokens": [708, 360, 291, 519, 30], "temperature": 0.0, "avg_logprob": -0.2020118327080449, "compression_ratio": 1.7005988023952097, "no_speech_prob": 0.00013725344615522772}, {"id": 1030, "seek": 407100, "start": 4081.0, "end": 4086.0, "text": " I think you do. I think that's definitely one reason for batching work.", "tokens": [286, 519, 291, 360, 13, 286, 519, 300, 311, 2138, 472, 1778, 337, 15245, 278, 589, 13], "temperature": 0.0, "avg_logprob": -0.2020118327080449, "compression_ratio": 1.7005988023952097, "no_speech_prob": 0.00013725344615522772}, {"id": 1031, "seek": 407100, "start": 4086.0, "end": 4089.0, "text": " I don't even think it's the main reason for me though.", "tokens": [286, 500, 380, 754, 519, 309, 311, 264, 2135, 1778, 337, 385, 1673, 13], "temperature": 0.0, "avg_logprob": -0.2020118327080449, "compression_ratio": 1.7005988023952097, "no_speech_prob": 0.00013725344615522772}, {"id": 1032, "seek": 407100, "start": 4089.0, "end": 4093.0, "text": " I think the main reason that I tend to batch work is...", "tokens": [286, 519, 264, 2135, 1778, 300, 286, 3928, 281, 15245, 589, 307, 485], "temperature": 0.0, "avg_logprob": -0.2020118327080449, "compression_ratio": 1.7005988023952097, "no_speech_prob": 0.00013725344615522772}, {"id": 1033, "seek": 409300, "start": 4093.0, "end": 4102.0, "text": " First I'll say, if there's a pull request that's a typo in the docs, then I'm just going to click merge.", "tokens": [2386, 286, 603, 584, 11, 498, 456, 311, 257, 2235, 5308, 300, 311, 257, 2125, 78, 294, 264, 45623, 11, 550, 286, 478, 445, 516, 281, 2052, 22183, 13], "temperature": 0.0, "avg_logprob": -0.25762163509022107, "compression_ratio": 1.518181818181818, "no_speech_prob": 0.00029933280893601477}, {"id": 1034, "seek": 409300, "start": 4102.0, "end": 4108.0, "text": " Because I want to get that off my radar as fast as possible.", "tokens": [1436, 286, 528, 281, 483, 300, 766, 452, 16544, 382, 2370, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.25762163509022107, "compression_ratio": 1.518181818181818, "no_speech_prob": 0.00029933280893601477}, {"id": 1035, "seek": 409300, "start": 4108.0, "end": 4111.0, "text": " Because it's just like, having it sitting around...", "tokens": [1436, 309, 311, 445, 411, 11, 1419, 309, 3798, 926, 485], "temperature": 0.0, "avg_logprob": -0.25762163509022107, "compression_ratio": 1.518181818181818, "no_speech_prob": 0.00029933280893601477}, {"id": 1036, "seek": 409300, "start": 4111.0, "end": 4117.0, "text": " There's this idea in getting things done, which we talked about in our productivity episode, of the two minute rule.", "tokens": [821, 311, 341, 1558, 294, 1242, 721, 1096, 11, 597, 321, 2825, 466, 294, 527, 15604, 3500, 11, 295, 264, 732, 3456, 4978, 13], "temperature": 0.0, "avg_logprob": -0.25762163509022107, "compression_ratio": 1.518181818181818, "no_speech_prob": 0.00029933280893601477}, {"id": 1037, "seek": 411700, "start": 4117.0, "end": 4130.0, "text": " Which is that, if you can complete something in two minutes or less, then managing that in your to-do system is going to be more costly than just doing it.", "tokens": [3013, 307, 300, 11, 498, 291, 393, 3566, 746, 294, 732, 2077, 420, 1570, 11, 550, 11642, 300, 294, 428, 281, 12, 2595, 1185, 307, 516, 281, 312, 544, 28328, 813, 445, 884, 309, 13], "temperature": 0.0, "avg_logprob": -0.19971038768817853, "compression_ratio": 1.5707070707070707, "no_speech_prob": 3.9431266486644745e-05}, {"id": 1038, "seek": 411700, "start": 4130.0, "end": 4136.0, "text": " Because you accrue some sort of tax by having more things in your system.", "tokens": [1436, 291, 1317, 41729, 512, 1333, 295, 3366, 538, 1419, 544, 721, 294, 428, 1185, 13], "temperature": 0.0, "avg_logprob": -0.19971038768817853, "compression_ratio": 1.5707070707070707, "no_speech_prob": 3.9431266486644745e-05}, {"id": 1039, "seek": 411700, "start": 4136.0, "end": 4143.0, "text": " So I definitely try to push things through when there's not a lot to think about.", "tokens": [407, 286, 2138, 853, 281, 2944, 721, 807, 562, 456, 311, 406, 257, 688, 281, 519, 466, 13], "temperature": 0.0, "avg_logprob": -0.19971038768817853, "compression_ratio": 1.5707070707070707, "no_speech_prob": 3.9431266486644745e-05}, {"id": 1040, "seek": 414300, "start": 4143.0, "end": 4152.0, "text": " But when there are deep considerations that I need to go through, then sometimes those need to sit with me for a little bit.", "tokens": [583, 562, 456, 366, 2452, 24070, 300, 286, 643, 281, 352, 807, 11, 550, 2171, 729, 643, 281, 1394, 365, 385, 337, 257, 707, 857, 13], "temperature": 0.0, "avg_logprob": -0.21373920051419004, "compression_ratio": 1.7478632478632479, "no_speech_prob": 8.613795216660947e-05}, {"id": 1041, "seek": 414300, "start": 4152.0, "end": 4163.0, "text": " And I need to sleep on it, and I need to read through a bajillion RFCs that other open source projects and other language communities have made.", "tokens": [400, 286, 643, 281, 2817, 322, 309, 11, 293, 286, 643, 281, 1401, 807, 257, 23589, 11836, 497, 18671, 82, 300, 661, 1269, 4009, 4455, 293, 661, 2856, 4456, 362, 1027, 13], "temperature": 0.0, "avg_logprob": -0.21373920051419004, "compression_ratio": 1.7478632478632479, "no_speech_prob": 8.613795216660947e-05}, {"id": 1042, "seek": 414300, "start": 4163.0, "end": 4172.0, "text": " And watch some conference talks, and read some code books, and read some non-code books, and drink a Mai Tai, and think about these things.", "tokens": [400, 1159, 512, 7586, 6686, 11, 293, 1401, 512, 3089, 3642, 11, 293, 1401, 512, 2107, 12, 22332, 3642, 11, 293, 2822, 257, 24084, 9623, 11, 293, 519, 466, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.21373920051419004, "compression_ratio": 1.7478632478632479, "no_speech_prob": 8.613795216660947e-05}, {"id": 1043, "seek": 417200, "start": 4172.0, "end": 4175.0, "text": " Specifically Mai Tai?", "tokens": [26058, 24084, 9623, 30], "temperature": 0.0, "avg_logprob": -0.22183659202174136, "compression_ratio": 1.3770491803278688, "no_speech_prob": 0.00010387087240815163}, {"id": 1044, "seek": 417200, "start": 4175.0, "end": 4176.0, "text": " It couldn't hurt.", "tokens": [467, 2809, 380, 4607, 13], "temperature": 0.0, "avg_logprob": -0.22183659202174136, "compression_ratio": 1.3770491803278688, "no_speech_prob": 0.00010387087240815163}, {"id": 1045, "seek": 417200, "start": 4176.0, "end": 4179.0, "text": " I just don't know what it is, so yeah, maybe.", "tokens": [286, 445, 500, 380, 458, 437, 309, 307, 11, 370, 1338, 11, 1310, 13], "temperature": 0.0, "avg_logprob": -0.22183659202174136, "compression_ratio": 1.3770491803278688, "no_speech_prob": 0.00010387087240815163}, {"id": 1046, "seek": 417200, "start": 4179.0, "end": 4181.0, "text": " Try one out, it's good.", "tokens": [6526, 472, 484, 11, 309, 311, 665, 13], "temperature": 0.0, "avg_logprob": -0.22183659202174136, "compression_ratio": 1.3770491803278688, "no_speech_prob": 0.00010387087240815163}, {"id": 1047, "seek": 417200, "start": 4181.0, "end": 4186.0, "text": " I think there's a lot of background processing for decisions for me.", "tokens": [286, 519, 456, 311, 257, 688, 295, 3678, 9007, 337, 5327, 337, 385, 13], "temperature": 0.0, "avg_logprob": -0.22183659202174136, "compression_ratio": 1.3770491803278688, "no_speech_prob": 0.00010387087240815163}, {"id": 1048, "seek": 417200, "start": 4186.0, "end": 4194.0, "text": " Have you heard this story of the man who asked for a painting of a horse?", "tokens": [3560, 291, 2198, 341, 1657, 295, 264, 587, 567, 2351, 337, 257, 5370, 295, 257, 6832, 30], "temperature": 0.0, "avg_logprob": -0.22183659202174136, "compression_ratio": 1.3770491803278688, "no_speech_prob": 0.00010387087240815163}, {"id": 1049, "seek": 419400, "start": 4194.0, "end": 4203.0, "text": " And so he asks this painter, he says, I want to commission a painting of a horse, it's like a birthday present for someone or something.", "tokens": [400, 370, 415, 8962, 341, 26619, 11, 415, 1619, 11, 286, 528, 281, 9221, 257, 5370, 295, 257, 6832, 11, 309, 311, 411, 257, 6154, 1974, 337, 1580, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.22890630408899107, "compression_ratio": 1.9826839826839826, "no_speech_prob": 5.8109657402383164e-05}, {"id": 1050, "seek": 419400, "start": 4203.0, "end": 4208.0, "text": " And the painter says, okay, yeah sure, I'll have that for you in a month or so.", "tokens": [400, 264, 26619, 1619, 11, 1392, 11, 1338, 988, 11, 286, 603, 362, 300, 337, 291, 294, 257, 1618, 420, 370, 13], "temperature": 0.0, "avg_logprob": -0.22890630408899107, "compression_ratio": 1.9826839826839826, "no_speech_prob": 5.8109657402383164e-05}, {"id": 1051, "seek": 419400, "start": 4208.0, "end": 4213.0, "text": " And he goes back to the painter, and the painter says, are you done with the painting yet?", "tokens": [400, 415, 1709, 646, 281, 264, 26619, 11, 293, 264, 26619, 1619, 11, 366, 291, 1096, 365, 264, 5370, 1939, 30], "temperature": 0.0, "avg_logprob": -0.22890630408899107, "compression_ratio": 1.9826839826839826, "no_speech_prob": 5.8109657402383164e-05}, {"id": 1052, "seek": 419400, "start": 4213.0, "end": 4216.0, "text": " No, no, no, I'm still painting it.", "tokens": [883, 11, 572, 11, 572, 11, 286, 478, 920, 5370, 309, 13], "temperature": 0.0, "avg_logprob": -0.22890630408899107, "compression_ratio": 1.9826839826839826, "no_speech_prob": 5.8109657402383164e-05}, {"id": 1053, "seek": 419400, "start": 4216.0, "end": 4219.0, "text": " And a couple weeks go by, and the painter says, hey, are you done with it yet?", "tokens": [400, 257, 1916, 3259, 352, 538, 11, 293, 264, 26619, 1619, 11, 4177, 11, 366, 291, 1096, 365, 309, 1939, 30], "temperature": 0.0, "avg_logprob": -0.22890630408899107, "compression_ratio": 1.9826839826839826, "no_speech_prob": 5.8109657402383164e-05}, {"id": 1054, "seek": 419400, "start": 4219.0, "end": 4221.0, "text": " No, no, no, I'm still working on it.", "tokens": [883, 11, 572, 11, 572, 11, 286, 478, 920, 1364, 322, 309, 13], "temperature": 0.0, "avg_logprob": -0.22890630408899107, "compression_ratio": 1.9826839826839826, "no_speech_prob": 5.8109657402383164e-05}, {"id": 1055, "seek": 422100, "start": 4221.0, "end": 4227.0, "text": " And he keeps going back, and he's not done, and eventually he goes back, and the painter gets so frustrated, he says, okay, okay, okay.", "tokens": [400, 415, 5965, 516, 646, 11, 293, 415, 311, 406, 1096, 11, 293, 4728, 415, 1709, 646, 11, 293, 264, 26619, 2170, 370, 15751, 11, 415, 1619, 11, 1392, 11, 1392, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.19575817302121953, "compression_ratio": 1.7740585774058577, "no_speech_prob": 0.00016304988821502775}, {"id": 1056, "seek": 422100, "start": 4227.0, "end": 4231.0, "text": " And he gets out an easel and paints a horse, and then gives it to him.", "tokens": [400, 415, 2170, 484, 364, 1195, 338, 293, 28076, 257, 6832, 11, 293, 550, 2709, 309, 281, 796, 13], "temperature": 0.0, "avg_logprob": -0.19575817302121953, "compression_ratio": 1.7740585774058577, "no_speech_prob": 0.00016304988821502775}, {"id": 1057, "seek": 422100, "start": 4231.0, "end": 4236.0, "text": " And he's like, well, if you did it so quickly, why didn't you just do that before?", "tokens": [400, 415, 311, 411, 11, 731, 11, 498, 291, 630, 309, 370, 2661, 11, 983, 994, 380, 291, 445, 360, 300, 949, 30], "temperature": 0.0, "avg_logprob": -0.19575817302121953, "compression_ratio": 1.7740585774058577, "no_speech_prob": 0.00016304988821502775}, {"id": 1058, "seek": 422100, "start": 4236.0, "end": 4243.0, "text": " And he says, well, I've been, you know, observing horses, and watching how they run, and thinking about them, and dreaming about them.", "tokens": [400, 415, 1619, 11, 731, 11, 286, 600, 668, 11, 291, 458, 11, 22107, 13112, 11, 293, 1976, 577, 436, 1190, 11, 293, 1953, 466, 552, 11, 293, 21475, 466, 552, 13], "temperature": 0.0, "avg_logprob": -0.19575817302121953, "compression_ratio": 1.7740585774058577, "no_speech_prob": 0.00016304988821502775}, {"id": 1059, "seek": 424300, "start": 4243.0, "end": 4253.0, "text": " So all this time, he was working on painting the horse, even though his brush was only touching the canvas for however long, that was part of the process.", "tokens": [407, 439, 341, 565, 11, 415, 390, 1364, 322, 5370, 264, 6832, 11, 754, 1673, 702, 5287, 390, 787, 11175, 264, 16267, 337, 4461, 938, 11, 300, 390, 644, 295, 264, 1399, 13], "temperature": 0.0, "avg_logprob": -0.21510207050978536, "compression_ratio": 1.6442687747035574, "no_speech_prob": 4.905401874566451e-05}, {"id": 1060, "seek": 424300, "start": 4253.0, "end": 4264.0, "text": " And that's how I feel with coding projects, is like, it needs to sit with you, and you can't just juggle a hundred different things and really consider them.", "tokens": [400, 300, 311, 577, 286, 841, 365, 17720, 4455, 11, 307, 411, 11, 309, 2203, 281, 1394, 365, 291, 11, 293, 291, 393, 380, 445, 361, 31726, 257, 3262, 819, 721, 293, 534, 1949, 552, 13], "temperature": 0.0, "avg_logprob": -0.21510207050978536, "compression_ratio": 1.6442687747035574, "no_speech_prob": 4.905401874566451e-05}, {"id": 1061, "seek": 424300, "start": 4264.0, "end": 4272.0, "text": " Like, you have to really get that cash into your brain about all of these things you're thinking about.", "tokens": [1743, 11, 291, 362, 281, 534, 483, 300, 6388, 666, 428, 3567, 466, 439, 295, 613, 721, 291, 434, 1953, 466, 13], "temperature": 0.0, "avg_logprob": -0.21510207050978536, "compression_ratio": 1.6442687747035574, "no_speech_prob": 4.905401874566451e-05}, {"id": 1062, "seek": 427200, "start": 4272.0, "end": 4280.0, "text": " And so it's more efficient in a lot of ways to, like, think about a related group of things in a project before moving on to something else.", "tokens": [400, 370, 309, 311, 544, 7148, 294, 257, 688, 295, 2098, 281, 11, 411, 11, 519, 466, 257, 4077, 1594, 295, 721, 294, 257, 1716, 949, 2684, 322, 281, 746, 1646, 13], "temperature": 0.0, "avg_logprob": -0.1929460305434007, "compression_ratio": 1.6597510373443984, "no_speech_prob": 8.348040137207136e-05}, {"id": 1063, "seek": 427200, "start": 4280.0, "end": 4282.0, "text": " So that's how I tend to think of it.", "tokens": [407, 300, 311, 577, 286, 3928, 281, 519, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.1929460305434007, "compression_ratio": 1.6597510373443984, "no_speech_prob": 8.348040137207136e-05}, {"id": 1064, "seek": 427200, "start": 4282.0, "end": 4286.0, "text": " So is there any feature that I have to rush you about?", "tokens": [407, 307, 456, 604, 4111, 300, 286, 362, 281, 9300, 291, 466, 30], "temperature": 0.0, "avg_logprob": -0.1929460305434007, "compression_ratio": 1.6597510373443984, "no_speech_prob": 8.348040137207136e-05}, {"id": 1065, "seek": 427200, "start": 4286.0, "end": 4293.0, "text": " You know, I actually don't mind when people politely ping on something, too.", "tokens": [509, 458, 11, 286, 767, 500, 380, 1575, 562, 561, 1180, 1959, 26151, 322, 746, 11, 886, 13], "temperature": 0.0, "avg_logprob": -0.1929460305434007, "compression_ratio": 1.6597510373443984, "no_speech_prob": 8.348040137207136e-05}, {"id": 1066, "seek": 427200, "start": 4293.0, "end": 4301.0, "text": " Because for me, like, it is valuable to know that somebody actually cares about something.", "tokens": [1436, 337, 385, 11, 411, 11, 309, 307, 8263, 281, 458, 300, 2618, 767, 12310, 466, 746, 13], "temperature": 0.0, "avg_logprob": -0.1929460305434007, "compression_ratio": 1.6597510373443984, "no_speech_prob": 8.348040137207136e-05}, {"id": 1067, "seek": 430100, "start": 4301.0, "end": 4307.0, "text": " Yeah, definitely. It gives you some motivation, like, oh yeah, yeah, no, I want that too.", "tokens": [865, 11, 2138, 13, 467, 2709, 291, 512, 12335, 11, 411, 11, 1954, 1338, 11, 1338, 11, 572, 11, 286, 528, 300, 886, 13], "temperature": 0.0, "avg_logprob": -0.22321615380755924, "compression_ratio": 1.640316205533597, "no_speech_prob": 1.644009716983419e-05}, {"id": 1068, "seek": 430100, "start": 4307.0, "end": 4311.0, "text": " At least for me, because I want those things as well.", "tokens": [1711, 1935, 337, 385, 11, 570, 286, 528, 729, 721, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.22321615380755924, "compression_ratio": 1.640316205533597, "no_speech_prob": 1.644009716983419e-05}, {"id": 1069, "seek": 430100, "start": 4311.0, "end": 4316.0, "text": " Yeah. Or if somebody's blocked, I want them to be unblocked, and that's valuable information.", "tokens": [865, 13, 1610, 498, 2618, 311, 15470, 11, 286, 528, 552, 281, 312, 517, 28830, 292, 11, 293, 300, 311, 8263, 1589, 13], "temperature": 0.0, "avg_logprob": -0.22321615380755924, "compression_ratio": 1.640316205533597, "no_speech_prob": 1.644009716983419e-05}, {"id": 1070, "seek": 430100, "start": 4316.0, "end": 4324.0, "text": " So, you know, sometimes it's okay to just say, hey, just making sure you're, you know, having lost track of this in a polite way.", "tokens": [407, 11, 291, 458, 11, 2171, 309, 311, 1392, 281, 445, 584, 11, 4177, 11, 445, 1455, 988, 291, 434, 11, 291, 458, 11, 1419, 2731, 2837, 295, 341, 294, 257, 25171, 636, 13], "temperature": 0.0, "avg_logprob": -0.22321615380755924, "compression_ratio": 1.640316205533597, "no_speech_prob": 1.644009716983419e-05}, {"id": 1071, "seek": 430100, "start": 4324.0, "end": 4328.0, "text": " Yeah. Don't write a comment saying ping, but...", "tokens": [865, 13, 1468, 380, 2464, 257, 2871, 1566, 26151, 11, 457, 485], "temperature": 0.0, "avg_logprob": -0.22321615380755924, "compression_ratio": 1.640316205533597, "no_speech_prob": 1.644009716983419e-05}, {"id": 1072, "seek": 432800, "start": 4328.0, "end": 4332.0, "text": " Otherwise it's fine.", "tokens": [10328, 309, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.2070516398255254, "compression_ratio": 1.6258503401360545, "no_speech_prob": 2.976818723254837e-05}, {"id": 1073, "seek": 432800, "start": 4332.0, "end": 4334.0, "text": " Yeah. Yeah.", "tokens": [865, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.2070516398255254, "compression_ratio": 1.6258503401360545, "no_speech_prob": 2.976818723254837e-05}, {"id": 1074, "seek": 432800, "start": 4334.0, "end": 4340.0, "text": " All right. I don't know what else we can add to this conversation to maintain it.", "tokens": [1057, 558, 13, 286, 500, 380, 458, 437, 1646, 321, 393, 909, 281, 341, 3761, 281, 6909, 309, 13], "temperature": 0.0, "avg_logprob": -0.2070516398255254, "compression_ratio": 1.6258503401360545, "no_speech_prob": 2.976818723254837e-05}, {"id": 1075, "seek": 432800, "start": 4340.0, "end": 4342.0, "text": " Are you saying this conversation is done?", "tokens": [2014, 291, 1566, 341, 3761, 307, 1096, 30], "temperature": 0.0, "avg_logprob": -0.2070516398255254, "compression_ratio": 1.6258503401360545, "no_speech_prob": 2.976818723254837e-05}, {"id": 1076, "seek": 432800, "start": 4342.0, "end": 4345.0, "text": " This conversation is done.", "tokens": [639, 3761, 307, 1096, 13], "temperature": 0.0, "avg_logprob": -0.2070516398255254, "compression_ratio": 1.6258503401360545, "no_speech_prob": 2.976818723254837e-05}, {"id": 1077, "seek": 432800, "start": 4345.0, "end": 4347.0, "text": " Well, then you're in. Until next time.", "tokens": [1042, 11, 550, 291, 434, 294, 13, 9088, 958, 565, 13], "temperature": 0.0, "avg_logprob": -0.2070516398255254, "compression_ratio": 1.6258503401360545, "no_speech_prob": 2.976818723254837e-05}, {"id": 1078, "seek": 434700, "start": 4347.0, "end": 4368.0, "text": " Until next time.", "tokens": [50364, 9088, 958, 565, 13, 51414], "temperature": 0.0, "avg_logprob": -0.5601932321275983, "compression_ratio": 0.6666666666666666, "no_speech_prob": 0.00011982402065768838}], "language": "en"}