{"text": " Hello Jeroen. Hello Dillon. Well it's finally time to turn the page and start a new chapter of Elm. In fact, this might be more than a chapter, this might even be a whole new volume of Elm Pages. There are two volumes before, but by adding a third volume we've got a full stack of books about Elm Pages now. We are going to talk about Elm Pages once more. Yep, and we are not going to talk about Elm Pages Alpha, we are not going to talk about Elm Pages Beta, we are not going to talk about a soon to be released Elm Pages, we are talking about a stable release of Elm Pages V3, finally! Wooo! We've covered Elm Pages in a bunch of episodes, like our very first episode was about Elm Pages, what is Elm Pages? And that was for V1, V2 was released in between, we've done a few other episodes, including recently one about Elm Pages scripts. But that was still yet to be released, but now everything is released. Dillon is now finally done with his work, he can now retire. At the very least I can think about other things, because it really felt like there are so many pieces to Elm Pages, and I sympathize with users for the number of concepts that are available in the framework to grok. But yeah, it was quite a journey to just juggle all those concepts, and constantly try to think of better ways to simplify things, and how those pieces fit together, and then keep doing that over and over until all the pieces fit together really elegantly. Like I came up with a lot of very new techniques that I haven't seen in an Elm framework yet, so it was quite an experience. Alright, so for the few people who have not heard about Elm Pages yet, or who have not... For our one listener who doesn't know what Elm Pages is. Or who hasn't re-listened to all the episodes since the beginning, maybe tell us what Elm Pages is, and then we can afterwards talk about what is new in v3. So yeah, what is Elm Pages? Yeah, so the way I think about it, Elm Pages, number one, Elm Pages is Elm. It's an extension of Elm. So everything you understand about Elm, you can apply that understanding to Elm Pages. So it's just Elm? It's just Elm. It's just Elm. It's a single-page app in Elm. So Elm Pages is a way to build a single-page app. But it's a single-page app that extends the traditional Elm architecture. So whereas the Elm architecture gives you an initUpdateView, and it renders client-side. So you load usually sort of an empty HTML skeleton that if you turn off JavaScript, it's a blank page. If you turn on JavaScript, it's a blank page until it hydrates the client-side rendering. Hydrate isn't actually the appropriate term there. Until it executes the JavaScript. Exactly. It parses and executes the JavaScript. Elm Pages, for one thing, it pre-renders out the HTML. And it does that with a special addition to the lifecycle of the traditional Elm architecture. So the traditional Elm architecture, you have init, it can kick off some commands, and then it renders a view with your init. And it does that all on the client-side. In Elm Pages, it runs init on the server. So it actually takes the Elm app you write, and it runs it in two places. It runs it on the server, and it runs it on the client in the browser. And so, yes, it runs it twice and it creates two applications. Because the server one is running without a browser. It's running a headless application, but it runs your init, and it renders your view with your init, without running any of the commands from init. It just takes your data from init, and it renders that to an HTML string. And then that is the initial response that's sent to the client. So the client has a fully rendered HTML view before the JavaScript takes over the page. So that's one thing Elm Pages adds. The other thing that's a really big piece of what Elm Pages adds is your routes have something called data. That is an extension to the traditional Elm architecture's init update view. So data is something where you define, in Elm Pages v3, it's called a back-end task. In v2, it was called a data source. But that's a declarative way to define data, very similar to an Elm core task. So you can have an HTTP request as a task, and you can transform that all into some data type. So when that task resolves, you end up with some data. And that data is resolved fully on the server. It's resolved on the back-end, as the name back-end task implies. And then that data is available before init is called, before your view is ever called. And so, whereas with a traditional Elm app, there's no data before init, unless you pass in flags. And sometimes people do pass in flags with data from the server, to sort of bootstrap the page. Maybe it's like a Rails app or whatever server rendering framework. So actually, I think a really good way to think about the Elm Pages architecture is a sort of abstraction over that pattern. It's a way to make that pattern really easy for you to manage, where you do all of that in pure Elm, and you don't have to write all the glue code to do that. But that's essentially what it's doing. It's saying, hey, before we load this page, since we're serving up this request from a server, we may as well just resolve some data and put that in the page, basically as a flag. It actually is doing that under the hood. So you have some data that is available as flags, and it's there before init is called. That's exactly the mental model for an Elm Pages app for the route modules data. Your data is available before view is ever called, unlike the commands that you return in your init function, which are available after view is called. So you have loading spinners and intermediary states in your model to deal with. So that's really at the heart of Elm Pages. It's about getting that data before your page loads and everything that comes from that. So, for example, one thing that comes out of that pattern is you have fewer intermediary states to deal with, fewer loading spinners. The user doesn't have flashes of loading spinners coming in. Does it also resolve errors? Like if you ask for some kind of data, then you're sure to get that data, otherwise the user will get a 400 or 500 page error. Yes. Okay, so you also don't have to handle those error states. That's pretty nice. It takes those out of your happy path. So the way this works in Elm Pages v2, there was only one mode, which was rendering your pages at build time. It was a static site generator. Elm Pages v3 is a hybrid framework that supports both static site generation with something that's called pre-rendered routes, and then there are server-rendered routes. So in the pre-rendered routes, if your backend task has an error, then that results in a build failure. And you can, you know, so, oh, this API is down. Well, okay, then don't push that site live. Or if you want to, you can handle an HTTP failure with whatever logic you want, retrying the HTTP request, falling back to some data, falling back to a cached response. You can use all of these types of strategies. You can write general purpose Elm code to handle these errors. And that's actually been a big part of the v3 release of Elm Pages, partially because if you're doing server rendering, you want more fine-grained control over your error handling, because if it's just a static site, something goes wrong, fail the build, and let me play around with it and fix it. If it's server rendered, if something goes wrong, you might want more nuanced control. You know, maybe it's just that you show an error page, but you want to give really good information in that error page instead of just giving a 500 with no information. You know, maybe you want to respond like maybe an API gives you strange error codes or fails in strange ways, but it actually is just because it's a 404, this page doesn't exist for this user, or you're not authorized, or whatever it is, and you want to handle that in a more sophisticated way. But so with Elm Pages v3, there's something called a fatal error. We talked about that a little bit in our Elm Pages scripts episode. As I mentioned in that episode, I think that Elm Pages scripts are a very good way to get acquainted with these concepts around back-end tasks and fatal errors. But to summarize briefly, a back-end task has an error type, just like the Elm core task type has an error type variable and a data type variable. And in Elm Pages, the places that accept a back-end task, like your route module's data function, you return a back-end task. The error type it accepts for that back-end task is something called fatal error. And fatal error is just something that represents an error message that you can present if there's a build failure for a pre-rendered route, or if there's a 500 error. That's really all it is. But Elm Pages is able to accept something of the fatal error type. You can build your own fatal errors if you want and just say, I want to bail out, I want to just fail the build with an error message if I encounter this case. You can create your own fatal error type as well. All right. So is it, of course, there's going to be a simplification, but basically Elm Pages is a static-side generator, which in v3 now has also server-side rendered routes and something called Elm Pages scripts, which allows you to run arbitrary scripts written in Elm slash Elm Pages. Right. So that might sound like a lot of disparate concepts. The way I would frame it that makes sense to me is Elm Pages is a tool centered around this concept called a back-end task. A back-end task. Oh, so it's Elm back-end task. It kind of is. It kind of is. So that is the heart of Elm Pages, and it always has been in my heart. Deep in my heart, it's always been the heart of Elm Pages. Maybe my heart is the heart of Elm Pages. I don't know. But what it's all about is it's a way to declaratively resolve data. So the back-end task API gives you a way of resolving data on a back-end. Right. So it's a regular Elm core task. You can say scroll to this position as a task, or there are a handful of web APIs that are exposed as tasks. Those don't exist in back-end tasks because they're tasks that run on the back-end. On the other hand, an Elm core task cannot run things in Node.js. It cannot read a file. It cannot perform a glob to list out files matching a certain pattern. It cannot read environment variables. And those are often handy things to have if you're also it's not executing in a secure, trusted environment. So even if you had a way to pull in environment variables in an Elm core task, which executes in the browser, you wouldn't want to pull in secrets because suddenly you've revealed your secrets for doing admin database queries or using your open AI API token. And now you're getting slammed with requests from people who stole your token and are using that for their requests or whatever. Right. So you can't do that. With back-end tasks, you can't because it executes in a trusted, secure environment. So that is the difference between a task and a back-end task. And it has a whole suite of APIs designed for abstracting over that. For example, the glob API, back-end-task.glob, gives you a way to... I'm really pleased with the way you express this. You sort of are able to parse out parts of the file path. So you can say things matching star.md. But you don't do it as a string, so you can capture just that star part. You can capture that into an Elm type, just like if you're writing up a JSON decoder using a similar pattern. So these APIs are built in a way where you're doing that. So it's not just like a very light wrapper that lets you execute things in a back-end context, but it's like a really thought-out API for doing these types of tasks nicely in Elm and parsing them into nice Elm types. So that's the heart of it. It's this back-end-task concept. The back-end-task... yeah. So just to finish that thought, it allows you to execute things in a back-end context. It's secure, so you can use secrets, you can read files, you can pull in environment variables. You can do expensive data processing and things like that before something ever reaches the page. Whether that's at build time, where you do a lot of expensive computation, reading in a bunch of files, parsing that in some format, organizing that in some dictionary and sorting it and counting things and counting the number of occurrences of the most frequent words or phrases or whatever expensive thing. You can execute those things and then have the result of those and then that's just, if it's a static page, that's just part of your static page that's pre-computed. Or if it's server-rendered, you don't have to pay that cost on the client. And you don't even need to pull in the code in your bundle for things that only run on the back-end. So at the heart of Elm Pages is a back-end-task. Elm Pages is a framework that's centered around different ways to use a back-end task. A static route, pre-rendered routes, can use a back-end task to have the back-end task available before the view is rendered. You can render the head tags for SEO purposes that give you things like the nice social media previews for Twitter and Slack and things like that. That is there in the rendered HTML, which a lot of these tools for social previews don't execute JavaScript. So you need pre-rendered HTML in order to display those. So Elm Pages provides that, right? But how does it provide that if you don't have access to your initial page data before you do that? So back-end task is kind of a core thing around that. Back-end task is a core thing around server-rendered routes because you resolve this data, and you can run it in a secure environment in a back-end task. If you want to respond to a user clicking a Pay Now button by running something in Stripe, or if you want to respond to a Stripe webhook or whatever you want to do, back-end task is the core of how that is done. And back-end task is the core of how an Elm Pages script is done. An Elm Pages script is just a little helper that lets you easily execute a back-end task. It also lets you parse command line flags that you can use in that context of your back-end task. But again, it's all just centered around this concept of a back-end task. Yeah, that makes a lot of sense. I haven't seen it that way. But it does make things a lot more... but it does make a lot of sense. Yeah, it's more coherent when you think about it that way, right? Yeah, exactly. So basically what you did is you made this concept of back-end task, and you added a lot of primitives to get the contents of a file, to make HTTP requests ahead of time, ahead of render time, let's say, or JavaScript execution time on the client. And then you asked yourself in a way, where should this apply? And for Elm Pages v1 and v2, that was, well, this is for the front-end. Like, we're executing something at build time, and then you have some data that is sent to the front-end as plain HTML, and then there's some hydration or re-execution of the Elm code. And now with Elm Pages, you've made this apply for more things. So you have Elm Pages scripts, so it's like, well, we have all these nice things that are to get the contents of files, to write to files, to do things like that. Would be nice to just be able to run them to see, like, what is, if I run this code, do I get what I expect without having to run this whole server-side rendering machine? And then you also have this server-side rendering, because that's something that apparently the web community expects or wants and has a lot of value, which let's talk about that in a bit. But yeah, this makes a lot of sense. And I'm kind of wondering, like, if you knew that this was the core part of the package or the tool, because it's more than just a package, would you have called it differently? Because it's Elm Pages, but the Elm Pages scripts has nothing to do with Pages, and it doesn't have to be anymore. I'm guessing if you had renamed it to something else when it was still in V2, you would have called it Elm Data Source, which you would be unhappy with today, I'm guessing. Yeah, and I'm not sure Elm Backend Task really captures what you do with it either. But I don't know, maybe like... Yeah, maybe as an underlying package of Elm Pages. Maybe like Elm Backend, I don't know. But then it's like, well, Elm Backend, it's like, well, can you do things with a front end? It's like, yeah, it's about interopting between a front end and a back end. So yeah, it's hard to name. If anybody has a genius name, definitely let me know. But also, I think I mentioned this in the scripts episode we did, but the origin of Elm Pages scripts was that I was actually wanting to build more customizable scaffolding. Elm Pages V2 had an add route command, or Elm Pages add command that let you add new routes that would scaffold out the starting template for a new route. And I wanted to make that more customizable. If you want to use Elm UI or Elm CSS, Elm Tailwind modules, if you have a specific pattern that you use in all of your routes that you want to bake into it, whatever that might be. So when you say scaffolding, you mean like the tool creates a blank file or a few blank files with some predetermined data in there. Like maybe if you say, I'm just imagining something, like if I do Elm Pages add slash users slash ID, or however that's, is users dot ID or something? Yeah, you do it like an Elm module name. Okay, so if I do Elm Pages add users dot... ID underscore is a dynamic one. So ID is a dynamic thing. Then I would get a Elm module at the right position. And it would contain like, oh, a command saying this renders at slash users slash colon ID, something like that. And it actually would because it uses file-based routing. So it would create a file in the appropriate place for that route module. And then... I'm guessing an init view updates. Right, and the view would be view dot placeholder because your view might be Elm CSS or Elm HTML or Elm UI. So having a user-maintained module called view dot Elm with a type alias view being whatever type their view is, and a user-maintained function called placeholder, which renders out the placeholder. Let me scaffold out something with the view using the same pattern that Ryan came up with for Elm SPA. And that was great, but it was like, well, I want to make it more customizable than that. And I also like if you can... If you want to have... If you want to be able to pass in CLI arguments to customize how you're generating it. If you want to generate it with some GraphQL query or some HTTP request or something like... The sky's the limit. There's so many things you could do. Or maybe you want to scaffold out modules that aren't even route modules. Maybe they're helper modules for defining some backend tasks or whatever it may be. So I just wanted to make that more customizable in general. And so I knew I wanted to basically say, well, I want to have a way to make scaffolding more customizable. And I would love to do that using Elm CodeGen. So you can write Elm code to generate your Elm code for these modules. But I also want to be able to pull in HTTP data, pull in environment variables, read files if I want to read a config file, things like that. So it's like, well, OK, I want to be able to execute backend tasks in this context when I'm running the scaffolding script to generate a file. And then I'm like, you know what? Like if I just make... Like there's very little difference between a custom scaffolding script and just a script. So why don't I just make a script feature and the scaffolding script is just a special case of that. So that's what I ended up with. Nice. So for instance, I know it's like not the best use of it, but if I want to customize my scaffolding, I could create a backend task that gets the current time and then inject a comment saying this was generated on this date. Absolutely. That's pretty cool. Yeah. Terrible use, but I mean, why not? Yeah, I mean, you can read configuration from some JSON configuration file and use that to generate something and the sky's the limit. Yeah. Yeah. I'm really curious to see what people come up with or what they used it for. Me too. Yeah. I'm not going to go down a rabbit hole, but there's a new feature where you can execute an Elm pages script pointing to a GitHub gist or a link to a raw GitHub file, including a branch or just pointing to a GitHub repo and then you provide a path to a script. So I'm really excited to see what people do with scripts now that it's like much more shareable, you can just have a gist that has your scaffolding and your, you know, whatever logic for a little helper script you have. So scripts are a lot more shareable now and a lot easier to play around with. Has that last feature you talked about been released? It's released. Yeah. Okay. I haven't done an announcement post, but it's released and it's stable. Yeah. Okay. I was thinking it wasn't released yet. I'm like, we should finally talk about things that have been released. This is a bad habit. This is an intervention. Let's talk about things that have been released, but okay. It has been released. I have nothing to say. Turned over a new leaf. It's released. So we should probably talk about the big headline of ElmPages v3, which is server rendered routes. So first of all, maybe we should define server rendering and what that's in contrast to. And also you say server rendered routes. And the term that I hear from the JavaScript ecosystem is SSR, server-side rendering. Is that the same thing or the difference? It is. Yeah, it's exactly the same thing. But your name is better for some reason that you're going to explain it now. Well, in the context of an ElmPages app, you can have a pre-rendered route or a server rendered route. Pre-rendered route, the backend task is resolved at build time. It results in a pre-rendered HTML file on disk, which your hosting provider can serve up or through a CDN or however you want to do that. Like a static HTML file? Yep, you get a static file. You also get a static file called content.dat for that URL. And that contains the serialized data for your route. Now, the reason for that, so remember before I mentioned that conceptually you can use the mental model of, you know, like a Rails app that bootstraps some server data and passes them through ElmFlags. So that is actually exactly what happens if you load an initial page in your browser with HTML. But then if you click a link, it's not loading an HTML page. So if you click a link, it's actually loading just a single file. It doesn't load the HTML because it doesn't need that because it is now in single page app mode. So it's hydrated into an Elm single page app. Now it only needs that data for the page. So that's what the content.dat is for. So if you have a blog slash introducing v3 post, that has some the markdown data, the parsed markdown data and the publish date and whatever other data is resolved for that, that routes data is serialized as bytes in a byte format there. That gets downloaded by the browser. Exactly. That's in the metadata or the head tag. Exactly. So the Elm pages framework itself, when it's running in the browser, it knows when you click on a link to go fetch the corresponding data. So it can, you know, it's a single page app, but it knows before I change routes to this page, I'm going to need this data. And is that JSON in practice? In v2 it was JSON. That is then sent to the init function as flags. In, it's all binary and it uses the Lambdara wire encoders to encode that data to binary. In v3. Okay. Yeah. So Lambdara, so, and I think this is worth being explicit about. So there are two meanings of Lambdara. One is a compiler and one is a hosting platform. Elm pages v3 has nothing to do with Lambdara, the hosting platform. Lambdara, the hosting platform is awesome. You should definitely use that. If you want a Lambdara app, an app that is using WebSockets to have multiple connected clients, sending real time data and doing evergreen migrations. Awesome platform. Nothing to do with Elm pages v3. Elm pages v3 uses the Lambda compiler, which is it's exactly like the Elm compiler, but it adds a couple of things, including the ability to automatically serialize or deserialize an Elm type. And that is how in v3 Elm pages manages taking that data, which is resolved on the server and then hydrating that on the client. And this is actually a huge improvement in Elm pages v3, because in Elm pages v2, there was something called optimized decoders, which I think we talked about at length in the Elm pages v2 episode. So we're going to talk about it at length again now? Well, fortunately, you can forget about all of those concepts that you learned. And I'm sorry if you spent time learning and mastering those concepts, but fortunately, you get all of those same benefits with Elm pages v3 without having to learn any of that or without having to import a drop in replacement for JSON decoders, which is what optimized decoder was. You no longer have to worry about your data being sensitive data being used. So like Elm pages v2, there was like this design when you when you do an HTTP request, you could you had to wrap it in this secrets thing, which basically would obfuscate any secrets in the JSON data, because what it needed to do is it needed to basically mark every bit of data you depended on as you resolved your data sources and pull in the corresponding JSON. And it did like basically key value pairs with the definition of the request it was pulling from to the data for that request. So it had to scrub out sensitive data in the request in the keys of the JSON values. And it had to go and mark all the things that's what optimized decoders did is they would mark the things that were needed and only and strip out all of the data that wasn't used. It was very complicated to build, but it it allowed you to like make it an API request in the data source that pulled in some JSON data, but only used a few keys, but it wouldn't pull in all of the JSON data. But with with v3, it just resolves all of the data in your back end task that resolves to your whatever your route modules data type is, and then it it just serializes that data type. So you don't have to worry about what data you had that went into resolving that data. It's just what is the final data type that gets serialized in a binary format, and then passed in when your page is hydrated, or when you navigate to a new page, it gets downloaded. So much simpler, and much more performance. Yes, and better for security as well, which was one of the main motivations too. So I was like, if you're doing server side stuff, I don't want you to have to think about like, am I pulling in sensitive data? So yeah, because it was still possible to mess it up and to expose secrets. Yeah, even though there was a whole affordance for for working with that it, it's something that you could get wrong. So you no longer have to think about that at all. And it's more compact binary data. So it's a win win. You do need to ensure that your route modules data type, there's a type called data, usually it's a record type alias data, you do need to ensure that it does not contain any non serializable data, namely functions, functions are not serializable. And data structures that contain functions are not serializable. Some of them are surprising, like HTML, I don't know if it actually contains functions in Elm's implementation. Yeah, because you have HTML to map. Exactly. Yeah, if you have a map, right, exactly. That's right. Okay, so server side rendering, and or server rendered routes, SRR. SSR. Yeah. Should we talk about what you can do with server rendered routes? Yeah. What is it for? What can you do? Why is it better? Why is it worse? Sometimes? Let's let's first talk about what it is. Yeah. And you're right to ask, when is it better? When is it worse? Because so someone asked about this in the Elm pages, like channel recently. And my answer was, if you if you don't need fresh data, like a blog, you know, like if you if you publish, if you're running a news site, and somebody edits content, there's a typo or a correction or some emergency report with an update or something like that. And you want it to instantly be reflected when somebody loads the page, then then server side rendering is going to be a good approach. So a server rendered route would would be a good fit for that. But if it's a blog, and you're like, okay, I published something, and within within a few minutes, it's live, then I would go with a pre rendered route. And the reason is, because we've discussed this before, with a pre rendered route, you have the ability to essentially parse don't validate your initial route data with any errors being parsed out of the happy path to a build error. Whereas with a server rendered route, it gets parsed out to a 500 error. So that's one thing you have to deal with. Now, if you're building a CRUD application, or like things happen, and you can't guarantee that every service will always be up, right. So you do have to deal with that possibility. But if it's just like a little blog, or a portfolio site, or something like that, it's just like, you don't want to have to put that much thought into how you respond to those types of errors, you're just like, well, if something's wrong, then I'll just build it later or try to fix it. And you can mix and match them. For instance, if you have a news website, then you can use server rendered routes for the content. But the about page can be a pre rendered route. Yeah, exactly. Exactly. And can you also have like, plain elm pages, like the way that we currently do it without elm pages, just a blank HTML. Right. In other words, a client side rendered page, you cannot, in theory, it would be definitely possible to do that. But at the moment, elm pages does not have that. So you know, you can have a page with an empty back end task with a back end task that's just back end task to succeed, empty record or whatever. But, but yeah, there's no feature that it will still fetch that empty data before it loads your page. Also, something I've been wondering, like, ever since we started recording is like, can you have, can you mix the pre rendered routes, and the server rendered routes into one in the sense that can you have a back end task that resolves a build time, but that is then used for a server rendered routes. So like, part of the things that I need for this page are computed the build time and other things are computed at render time. Is it possible to have both? That is not possible. But I mean, you could always like have an elm pages script that pre compute some data and use a codec to deserialize it or but yeah, so the options are, there's one we haven't talked about actually pre rendered route, which is the back end task data is resolved at build time. And then of course you, you have a standard elm architecture. So you can also use your init update to perform HTTP requests and that sort of thing. There's also server rendered routes, which we've talked about. And then there is something called pre render with fallback. So pre render with fallback will pre render a set of pages for the route. But then it will dynamically execute the back end task for that route for anything that wasn't a pre computed page in there. So you basically give it a list of pages, it's actually a back end task of a list of of pages. And then it's going to go so like for example, your most popular or recent articles could be pre read pre rendered. And then your archive, which you know, maybe your archive from 1932 is not requested very frequently. So you don't want your entire build to have to build your entire archive. But if somebody requests it, then you build it. And once it's built, it will cache that. So pre render with fallback is interesting because it, it really depends on your hosting provider how it's going to be actually implemented. So with with Netlify, they have something called DPR, distributed persistent rendering, which is like a weird kind of marketing buzzword, I guess. But they basically have this idea of, of exactly that pattern. And if you use a pre rendered, if you use pre render with fallback with the Netlify adapter, then that's that's what you get. And you can define different ways to handle those types of routes with different hosting platforms through Elm pages adapters. Adapters are the way that you take you take an Elm pages app, when you run Elm pages build, it will run your adapter, which you define in the Elm pages config file, Elm pages dot config dot mjs to JavaScript file and you you can import an adapter. The default adapter in the starter is a Netlify adapter that will execute the the server rendered routes through Netlify functions. But there's a GitHub issue that I'll link to our GitHub discussion where people can share different kind of community adapters they've written. And an adapter is basically you're, you're given like a JS file that is all of the compiled Elm code for running the server rendering function. But then you generate all the surrounding files for running it in your specific framework and hosting provider. So like there's an express adapter that someone has been writing in the community and it has a way to wire it up through an express middleware. So it's just like a little bit of glue code that helps set things up for a specific provider and framework. Gotcha. And provider is a hosting platform. Right, exactly. And, and which they, you know, they have specific file structures that they expect. And, you know, where, where do serverless functions live? Or, you know, if it's express, if it's, you know, maybe you're running it in some Kubernetes context that you need a particular thing, whatever it might be, you can you can build that into your adapter scripts. But basically the contract is that you're given this bundled file that has the, the server rendering thing that handles all of the Elm pages server rendering. You give it like, here's the, here's the route. How am I responding? And it gives you the response back. And then you have to do something with that response. So if it's in express, how do you take a response and turn that into the right data that express expects for a response? And how do you take the incoming HTTP requests and turn that into the format that Elm pages expects for an HTTP request with the HTTP method and the incoming URL? So that that's what an adapter is. Okay, are these fairly simple? Or are they pretty complicated? They're pretty simple. I mean, the the the contract is pretty simple, because it's just saying, I need the incoming HTTP request in a specific format, I give you a function that you call with that specific format of data for the HTTP request. So you might have to adapt your frameworks, you know, express or Node.js or Coa or whatever it might be, you might have to turn that into a different sort of JSON object for what Elm pages expects. And then you have to turn it into a response object. And then you have to put some files in a specific place. But the part that Elm pages gives you is, here's a function to, to call the rendering and get a response back, right? And then you just need to wire that up. Yeah, the hosting provider is now a big part of web development as well, right? And this is something that we now have to face if you at least you want to do server side rendering and serverless. Yes, maybe we should talk a bit about the use cases. Yeah, I was thinking like, we still haven't said like, what is it for? What is it good for? We said where it was complicated. But that's it. Exactly. Yeah, right. So yeah, like, what would you actually do? So for example, if you have a CRUD applicant, like if you want to have an admin panel where you can manage users, manage user permissions, you know, send some forms to make a database request. And, you know, or if you have an e commerce site, and you want to manage back office things, orders, inventory, forms that do that, right, v2 would not have supported those kinds of use cases, at least it wouldn't have given you much help there, it wouldn't have been a great fit for that, right? Because if you're resolving your data, at build time, when your data is mostly dynamic, and it depends on the user session, the logged in user, it doesn't really help you there. Yeah, so you would either need to rebuild like, continuously, or you would need to do a lot of the dynamics things in on the client anyway. Right? Yeah, it just wouldn't make sense. Also, if you have a conceptually infinite number of routes, you can't even pre render all of those routes. So it just wasn't really possible. So now with v3, when you define when you define a pre rendered route, you do not have access to the request. But when you define a server rendered route, you do have access to the request. And the request allows you to get the method of the request, the URL, the query params. So you know, in a in a pre rendered route, somebody can load that page with query params, but you don't have them until the page hydrates, because the page is rendered before a request is made. So conceptually, they don't exist at that point. But for a server rendered route, they do exist. Yeah, you also have access to cookies. Right? That's right. You have access to all of the headers, including cookies. And there are some high level abstractions for accessing and setting cookies. And that's a huge part of v3 is that design and that philosophy of using the platform because I believe it really makes things easier. Like I believe that cookie based session management is way easier than JIT token, JWT token based authentication. Oh, okay. But could you use JWT tokens? If you wanted to? You could, but I mean, I don't, I don't think you'd want to. But so yeah, for security reasons to like there are some advantages to cookie based authentication. So for example, in the cookie API in on pages v3, the default strategy for cookies is HTTP only, because that's like a common best practice. And so you can opt into cookies that are visible to JS, but by default, they will only be available through HTTP. So if you have a server rendered route, and you manage the user through a session, then that cookie, you can't, if somebody injects some cross site scripting attack script in your in your page, which of course, you'd prefer not to happen, but that's one possible event attack vector, they would not have access to the HTTP only cookies. That's what an HTTP only cookie means. When you do whatever it is document cookies, it show up there. So but when you make a request to to a server at the same origin, it is accessible. Whereas if you make a third party request, the default security policy for for on pages cookies and for for regular cookies, if you don't explicitly set one, is that those cookies will not be sent to external origins only to the original origin. So that means that, you know, it's just less to think about for for for the attack vectors for people trying to take your cookies. So because if someone gets your session cookie, then they are you right, they've successfully hijacked your cookie, if they if they get that cookie, then then they're you. So you don't want that to happen. But, uh, but yeah, so with on pages v3, you have access to cookies, there's a there's a session API that even manages key value pairs of cookies. So it will serialize those key value pairs of strings for you in in the cookie. And you can give it a list of secrets. It's actually a back end task of a list of secrets because that back end task, you can do environment variables, because you might want to, you probably want to pull in an environment variable and environment variable is accessible through a back end task. So, so you can list out session secrets through these back end tasks, and you give it a list a back end task of a list of strings, and it will use those to rotate the signing. So what that means is, so first of all, signing, signing the session, what that means is it's not encrypted, it's signed, which means if you tamper with it, so there's like the raw key value data, you can you can look at the cookie and see the data that was encrypted. So you can see the data that was encoded there directly, I think it's like base 64 encoded maybe but you can basically 64 decode it and just see the what the values are. But if you change the values, this, the signature, the hash that signed it will not match. So you need the signing secret in order. So it's tamper proof. So, you know, if it says like user ID is 123 and you say, Ah ha ha user ID is 124, then the signing will will fail, it will not unsigned that session, and it will rotate through those. So if you give a list of secrets, it will use the first one in the list to sign new requests, but it will, if it fails to unsign it with the first one in the list, it will go through the rest of them to try unsigning so you can rotate through your signing secrets. So before you said that an admin page, for instance, was a good use case for the server side rendered, right? ssr. I don't know. I think that's what it is. Some combination of SS and yeah, I mean, it's better than our own pages review code gen naming. So far, so admin pages, for instance, are good for this. But is it better than a plain Elm client app? And if so, how? Right. Yeah, it's a great question. So it's a different architecture. And actually, we kind of we kind of talked about this in our writing great docs episode a little bit of being being clear and straightforward to help users make decisions about what tools to use in your documentation. And, and I talked a little bit about how I put a lot of thought with for Elm pages v3 into how do I help users make that decision between Elm land and Elm client? Elm land, which is a new version of Elm SPA, or Elm pages on pages v3. Since since now there's a lot of overlap in the kinds of use cases they can handle, right, you could do an admin panel in Elm land, you could do an admin panel and in Elm pages v3. And to me that the answer is like, it depends on what kind of architecture you want to use. And of course, like, you know, do you want to use back end tasks to get that initial data? Do you want to do you want to use the platform and use cookie based authentication and use the URL as much as possible? Because that's like a key philosophy around Elm pages. It has this philosophy of use the platform. It has an API for submitting forms. Yeah, which we did a whole episode about like two actually. Yeah, that's right. That's right. Exactly. So see those episodes for more about the form design. But basically, that's like a core philosophy of Elm pages is the web has forms. And so let's use forms because if we use things that the web has built in opinions on, we can piggyback on those to make things simpler for the developer to write and rely on these web standards to reduce the amount of boilerplate and, you know, things just line up nicely. But, you know, if you buy into that philosophy of use the platform, and you want to work that way, that's great. If you want to kind of deviate from the platform, then you might not have a great experience with it, because it sort of is like designed to work really nicely, if you buy into this architecture and this philosophy. So that's what I realized. It's about buying into an approach. Yeah, if you want to do the right things, then use Elm pages. If you want to do the wrong things, use something else. Gotcha. I mean, you know, there are, there are different, you can do very bespoke things, right. And, you know, if you're doing like a Google Docs thing with, you know, multiplayer editing, where people can see the cursors of other people and stuff, it's like, well, okay, like, use the platform is great. But what's the platform for that? Like, it doesn't really get me anything. Right. So, Yeah. Elm pages might not be a good, good choice there, right. But if it's like a, if it's an admin panel thing, so like, if you're trying to do a post, you know, hit the submit button on a form and create a new entry in an admin panel, then with Elm pages v3, like, it, there's a certain resilience because it works before the JavaScript hydrates, which might seem like nitpicking, but it's like a real thing. That, that, that can happen. So it's like one, one less thing to think about, like, you know, do I need to have the button disabled before the page is hydrated and stuff. And it's also a philosophy of, you know, it's a certain performance philosophy where it's, you know, about having your data result, you know, your initial data resolved to reduce loading spinners. But if you're not heavily optimizing, you know, for example, having your, your data center co-located with where your Elm pages app is hosted, you might not get those performance benefits. But if you do, then you, you don't have to incur the cost of making multiple round trips and incurring the latency costs between the client and your data center. Instead, you pay that very small latency cost that hopefully approaching zero latency cost of resolving data from the Elm pages backend to your data center. You do all the little round trip requests, which are very short to resolve all of your initial page data that you need. And then you serve a fully hydrated page and you do your processing of that data on the backend and you don't need to ship that code that was used to resolve that data in the backend. So like that's, but if like not everybody's going to want to architect their app that way. And, you know, and also like Elm pages gives you an architecture for reaching through and sort of directly grabbing your data. That doesn't mean that you can't hit a GraphQL API or something like that, but you can, you can make a database request from a server rendered route and directly resolve data, you know, often using like a backend test dot custom, which allows you to define a custom node JS async function to your data center. You can use a custom node JS async function to, you know, receive JSON data and return JSON data that will be resolved in that backend task. But under the hood Elm pages uses ports, but it, it wires that all up for you. You define a file called custom backend task dot TS or dot JS, and you export async functions, and then they take one argument, which is the JSON encoded value that, that you call that you pass in from Elm. And then they return a JSON value and you decode, you give a decoder for that in Elm. So yeah, you can, so again, that's like a philosophical architectural choice. Like, is that an appealing way to work? Because if you're not getting benefit from that, this architecture might, you know, it might be trying to fit a square peg in a round hole. Yeah. For the performance, just so that I get it. So the server that is, so the server that the client hits and asks, like, Hey, I want this page at this URL that will communicate that server will communicate with some database or some things, hopefully on the same server or very close to, and then it will give back a page that is filled with a lot more data that it would have fetched otherwise on the client. So the time to first paint might be slower because the server is doing more computations and more requests. So it will take longer to resolve. So you will have a blank blank page for tiny bit longer in the good use case, I guess. But once you get the data, it's all there, or almost all there. Whereas with a regular application and full front end clients, you would have time to first paint that is very short, because you just ask for a static file. But then it goes to fetch a lot of JavaScript, a lot of files, and in the init it makes an HTTP request to get a lot of data. And then once all those things are done, then you have a page that has all the data. Is that correct? Well, kind of. The time to first paint being slower is not necessarily the case, though, because consider the time to first paint for an Elm application. So when is it painting your Elm application? Basically, one question is, what's faster to paint? Some HTML that you return or some JavaScript, right? With the JavaScript, it needs to probably make a follow up request for a JavaScript file, right? So that's one more step in the waterfall that it needs to do. Which you don't in the server? The HTML is just there right away. You need to parse the JavaScript, which takes some time. And while you're parsing the JavaScript, that's a blocking operation, so it's not doing anything else. And then you can render the page. But then, of course, now that you've rendered the page and initialized the JavaScript application, you're going to need to go and trigger your HTTP requests to get your initial data, right? So yes, now you've painted it, but now you need to go ask for your initial data. You don't even have that yet. Maybe you even need to do a JIT authentication handshake or whatever first. And so all of these things are going to need to happen after the paint, right? That's not even before the paint. But getting to the first paint, it's a question of what's going to be faster, serving and rendering that HTML or serving and rendering that JavaScript, right? And it's actually not an obvious answer, which it's going to depend on a case by case basis. But there's a lot that needs to happen to initialize that JavaScript as well. So that's part of that philosophy of that architecture, right? If you can get your data resolution on your backend down to 50, 100 milliseconds or whatever, then you can have a pretty compelling story where, like, all right, I resolved the data, rendered out this HTML. Now you get a first paint. And so you can actually get a faster first paint. Of course, if it's a pre-rendered route, then you don't even need to resolve the data and you can serve it through a CDN, you could serve it at the edge. But you can also serve it at the edge, you know, with a server rendered route as well. And you can use caching, you know, you can use a Redis cache to optimize your data loading and all sorts of so it really depends on your architecture, right? But what did you mean with rendering at the edge? Like I can get for the static rendered routes or pre-rendered routes, but for server-side rendered routes? Right. So edge functions are sort of an emerging approach to serverless functions. So that's one specific technique in serverless? That's right. Yeah, that is something that some hosting providers are starting to really build out a lot of features around. But yeah, so like edge functions, as opposed to serverless functions. So a serverless function might be US East, you know, it might be an AWS Lambda in US East. So if you're You mean specifically in one location, and that's it? That's right. So there's some JavaScript code that some US East Lambda will be able to pick up and execute and somebody in Tokyo hits your server rendered route, and they go all the way to US East and they request that data. And they have to go to US East? Like there's only one copy, one server that can do this? Yeah, and maybe there are a couple or, you know, something like that. But the edge functions are this idea that let's put them at more places, you know, more, you know, serverless locations where we can do the same thing as serverless functions where you call a function as a service or whatever, but it's distributed across more locations physically. Then of course, you do need to think about your data center story, right? Because if you're calling, you know, if the server is serving it up from a closer location, but it's farther from your data center, that's not good either. And there are places that are exploring ways to do more sort of distributed edge data, you know, whether it's key value or, you know, NoSQL or SQL style databases or whatever. A lot of things are being explored there. It's a big, big world. Yeah, it sounds a little bit complicated in practice. It is. It's hard to navigate. Yeah, it sounds pretty simple, but also like how to optimize all that. Totally. Totally. But on the other hand, like you can, you know, have if you've got your data center, and you've got an express server, you can serve up some Elm pages routes too, right? So that's... And so if you want to use Elm pages with an edge architecture, would you, how would you do that? Would you just define it in Netlify or whatever your hosting platform might be? Or do you have to write an adapter for that? Yeah, you would need an adapter. The Netlify one specifically, I'm not sure that Elm pages works with Netlify edge functions right now, because they use Deno. And right now Elm pages is node based. It doesn't have like a D, it's really hard to decouple between different JS frameworks. But so that's definitely one thing on my radar. But yeah, at the moment, they use Deno and it is not, I don't think it's compatible with it. Okay, interesting. But yeah, so server rendered, it's a big world, but I think that it's easy to get lost in those details. But I would say for people thinking about building something with this, the bottom line is, you know, again, it's this pattern of bootstrapping your page with data from the server. And Elm pages v3 is an abstraction for, for being able to basically automate the glue code for that pattern. Right. So, and again, like, you, you might not want to use that pattern. And if you don't want to use that pattern, then then Elmland is probably a better fit, because it doesn't, it's not bound to that pattern. But Elm pages v3 allows you to use that pattern in a really seamless way. That's sort of its core design and philosophy. And, and it has a lot of things around that, like the session API and, and the request API for looking at request data, you can even define API routes, where you can write pure Elm functions that respond to an API route. So if you want to have an API route that doesn't have a view, it's not a page, and you want to respond to a webhook with a Stripe, you know, some sort of header that has some Stripe signing secret. So you know, it's coming from Stripe, and you can respond, you know, respond to a payment being received by Stripe through a webhook, you can you can build that in pure Elm and resolve it with back end tasks and even directly make database requests to manage things. So Did you just casually say, Oh, by the way, we can do back end in Elm pages. That's, that's the headline. Exactly. Yeah. Okay, well, that was not clear enough. Yeah, maybe we should have done a That was not clear to me. From the start. Yeah, you can, you can write back ends, you can write APIs, you can write a JSON API endpoint. I mean, it's pure, you know, it is, you can write pure Elm code that can that can respond to server requests with the incoming HTTP request payload, whether that is a route module, or an API route, which doesn't have a view, you can do that. You can do that with Elm pages v3. I didn't understand that you could do non view things or non HTML things with it. That's very cool. Yeah. And you can you can pre render your API routes to also known as files. But, but yeah, it's the you can, you don't have access to the HTTP requests. But if you you know, for example, the Elm radio podcast feed is, it's an RSS file, that is an API route. But if we wanted to make that a something that you know if we really wanted to be able to just instantly go live with an Elm radio episode at a very specific time. Which we don't really have that problem because we have, you know, like a specific time that an episode releases and we can just do that with a build step in and have it through a cron job. But if for something where you wanted to be able to like drop something at a specific time and have that update in real time, we could have it be a server rendered API route. And then the RSS feed and we could take that same route that is now pre rendered and say, okay, make it server rendered. And now I have access to the incoming request. And now, okay, here's a, here's an Elm radio pro feed, and you're going to need authentication. So you give some query parameter or some cookie or whatever it might be to get your pro Elm radio feed for your user authentication. We could do that. Pretty interesting. So I know you've taken a lot of inspiration from other frameworks that deal in the same space, mostly in the JavaScript land. Tools like Remix and Astro and, and I can't come up with any other ones. And like, so now you've opened up Elm to that space to things that are SEO performance as well. So how does Elm pages compared to those now? And also, like, are there any parts of the fact that it's written in Elm that makes it much nicer or much more performance secure? Like, why would someone who is familiar with both JavaScript and Elm choose Elm pages over the other ones? Right? Yeah. So Elm pages v3 is heavily inspired by Remix JS. So shout out to Remix and the Remix team for, I think, paving a path that is really exciting for sort of a web standards based approach to full stack front end frameworks, you know, with this idea of progressively enhancing forms and, you know, heavily relying on, you know, basically this idea of, you know, basically this idea of let's, let's make a lot of our docs just linking to MDN and saying, well, here's how cookies work, which, you know, if you're, if you've been a front end developer for the last 5-10 years, maybe you've forgotten or don't know how cookies work, or, you know, maybe you've forgotten or don't know how, how form, how forms work. Like, because you, you know, it's very lazy on their part. But you don't actually use the built in platform features for these things. And they're saying, well, maybe let's enhance what the platform gives us, but use that as a starting point. So we have this baked in set of opinions that actually works really well with the browser, and we can leverage existing functionality there. So yeah, big shout out to Remix. One thing that obviously is different between, you know, Remix and Elm pages is Elm pages is Elm. Oh, really? Remix, they use a lot of TypeScript. And there are some cool features for bridging the types between the front end and the back end, using some of these TypeScript features. But of course, you know, Elm, you get more confidence in that you get custom types and all these things we like about Elm. So that's, you know, that's, that's one obvious thing that is a difference. In addition to that, there's just a different philosophy between JavaScript and Elm. And that really shows up in these APIs. So for example, there's a lot of, I mean, if you're using Remix, one thing I noticed is you end up doing like a lot of casting. For example, you receive some form data, and you say, okay, well, I expect this to be a string, I expect this to be an int, I expect to be able to parse this, and I expect this to be a string. And I expect to parse this as an int or whatever, right. But you're still, you know, you can use things like Zod, which definitely improves things and gives you more of an Elm decoder style approach to that. But you know, just like you would choose between Elm or JavaScript in any context, it's a similar set of trade offs with TypeScript and Elm there where, yeah, you can sort of get some of the safety of Elm if you use things like Zod and stuff. But it's never like all the way there. And for, you know, for people like us, like, that's really important to us and would be a reason to use Elm in itself. So when you communicate from the client to the back end, do you get a specific type or do you just get JSON, which you then need to encode and decode in Elm pages? I mean, you get a specific type. Oh, that's nice. Yeah, yeah, yeah. So that's the whole, that's the whole game is you. So you define in your route module, you define a data function where you define a back end task. If it's a server rendered route, then you have access to the HTTP request and you can respond with a back end task based on that incoming HTTP request. And if it's pre-rendered, you don't have access to that HTTP request. And then that back end task resolves to your route modules data type. So type alias data equals record with user name, ID, product, product name, whatever, whatever your route is showing. You know, if it's a showing a product and it has inventory and it has whatever you get that, that that's your type alias data. And then you just have that in you have that in a knit. You have that in view. So you just do that. You have an app argument in your view function and you just do app dot data dot inventory count app dot data dot products name. And it's not a it's not a maybe it's not a remote data. It's not a result. You just have have that data. It's just there. Yeah. So that's the data that you get from the server when you're on the client. Right. But if the client wants to send data to the back end. Gotcha. OK. So, yes. And this is kind of a bit of a can of worms. But, yes, Elm pages V3 has something called actions in server rendered route modules as well. And that is that's heavily inspired by Remix JS. That name comes from Remix JS. I think they got the name from like a form has an action attribute in a web form. So the action function is much like the data function. The data function is a back end task that resolves on initial page load. That's your initial route data and the action. So the action is there for non get requests. So if you make a non get request such as a form submission through a post method, then that would that would come into your action function on the server. It's going to resolve your action function instead of your data function for that. And that will that will update your route. So this is like one of the core things of Elm pages V3 is there's a whole form API for for working with this where you can define a form declaratively. And also this is one of the big differences between Elm pages and Remix. At least for me, this was like an important design space was like creating a very Elm way to sort of parse form data that gives you the real time validations and all these things. So you just you know, with Elm pages V3, you declare your form, which has the parser and the view for it. And then Elm pages takes care of of showing the real time client side validation errors. And when you hit submit, it will submit the form to your action function. So you can in your action function, you can create a new item when somebody clicks submit on, you know, or you update the inventory. And then you you hit the submit button. And now you receive that in your action, you get the parsed form, which is either successfully parsed or has errors, it parses into the same value. So you can even access the value that it parsed into on the client side. And you can use that to do optimistic or pending UI, optimistic UI being assuming that it was successful and showing the UI as if it succeeded before it does while it's pending. And pending UI being less optimistic version of that where you show a spinner that something is in progress or something. So I have a demo app that people can try out a live version of or they can look at the source code of it's a modified version of Evans to do MVC Elm app. But it adds database persistence using an NPM package called Prisma with with Postgres. And it directly manages the database request through Elm pages, custom back end tasks. And, and it gives you so it gives you full database persistence uses magic link authentication. So you so Elm pages itself will send you an email with a magic link that you click on. When you click on the link, it sets a session cookie that signs you in, because you click the link. So it you've confirmed that it's you and now now you're signed in by clicking that link. That's what magic link authentication is. So it that's implemented in Elm with a couple couple of very small bindings through custom back end tasks to do to use the crypto API to do encryption and decryption. And, and then doing Prisma for the database persistence. And the rest is all in Elm pages directly and manages the cookies and all that gets the logged in users to do items. And it shows some pending UI. So as you're so if you enter a new to do item, hit hit create or whatever the button says, you will see the new item show up in your to do list with a little loading spinner next to it. And that's all done declaratively. So the same logic for parsing that form that is used to parse that that form action on the on the server to parse a an action, you know, of creating an item deleting an item editing an item, checking an item, yeah, checking an item off checking all items off. Those are these actions uses the same form parsers on the back end to respond in the action to actually handle performing those tasks on the database. But it also uses those same parsers to say what are the in flight actions that are happening. And it uses that to derive all of the pending state of all of the of your to do items. So if you delete something, you can instantly show it as deleted, because it knows there is an in flight form that is deleting this item. So I'm just going to show it as deleted and and elm pages has this is one of the really big features of on pages v3 is it has all of the in flight form submissions are managed for you. So you just run your form parsers on it, but you don't have to wire anything up to your model. So with no model or managing anything in your update, you just say, what are the currently submitting forms? Here's my form parser, what are the currently submitting form actions, and then you derive your pending UI from that state. So I recommend taking a look at that to do example, the live demo and the code. It's like, I think it's one of the coolest features of on pages v3. Like it's it's what I'm the most excited about. That does sound very, very good. Yeah, I'm very curious. I'm gonna look at it. When I can. I love that declarative approach. You're not imperatively, you know, if they click Delete on this, then add it to this list of deleting things. Or it's just like, no, there's a list of all the actions. And you kind of just have that and say, Okay, well, if I have these pending actions, then what is my UI state, and you derive it from that. So that's one less. That's one less thing that could go wrong. Like this. For me, this is like one of my big opinions about coding, I guess, is when things are more declarative, there are fewer things that you can get wrong. So on pages is very declarative. I hope I hope people will agree. Kind of has right it is Elm. And that's the way we do things. Exactly, exactly. That's right. Maybe one last thing to mention is on pages v3 has built in V integration as well. So the dev server, the dev server still has the same hot data reloading that v2 had you you know, if you if you have a page that reads from a file, and you modify that file, it automatically knows that the page you're looking at is the one that's going to be in the page that you're looking at. So it knows that the page you're looking at, dependent on the file you touched, and it will hot reload the the back end task for that for that route. In addition to that, so try out the dev server. It was a lot of work. I hope you enjoy it. It's a girl. It has a built in integration with VJS. So now you can you can read about that more in the announcement blog post. But But yeah, you can define your own custom V configuration, and the dev server will use it and the production build will will use it as well. Yeah. So that's on pages v3. Yeah, that's a lot of information. Yes. The docs are are big, because the API for the tool is big, because I mean, it's doing a lot of things in practice, like, like, oh, well, let's just add these primitives to read files. Oh, well, now we can render things to now we can make API's now we can do a lot of things. Oh, now we need cookies. Oh, now we need sessions. Now we need forms. Now we are like, it's a lot. I know it's been a very big journey for you. Like, yeah, you've been working on this for like a year and a half. Yeah. So I'm really glad that you can now focus on something else. Even though I know you're still gonna work on the own pages like that's that's you. Right? Yeah, definitely. I hope people like it. I hope people also like the all the cool stuff you you you made possible with this, including just the tiny thing you mentioned at some point saying like, oh, we can do back end. Right? Yeah, I hope people enjoy it. Working people will go if they want to learn more like you have an announcement blog post, we will add that to the show notes elm dash pages.com I'm guessing. That's exactly right. Elm dash pages.com. We've got a doc site there and a and a blog. I might might write another blog post or two in the coming weeks and join the Elm pages slack channel. I'm very active there. Happy to answer questions. Check out the discussions in the Elm pages GitHub. Yeah, like let let me know what you build with it. Let me know what questions you have. Let me know what you want to see. Let me know what docs you think could be improved. I would love to hear from people and see what they end up building with it. All right. And you're in until next time. Until next time. Transcribed by https://otter.ai", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.0, "text": " Hello Jeroen.", "tokens": [2425, 508, 2032, 268, 13], "temperature": 0.0, "avg_logprob": -0.29341695573594834, "compression_ratio": 1.53, "no_speech_prob": 0.05815580114722252}, {"id": 1, "seek": 0, "start": 2.0, "end": 4.0, "text": " Hello Dillon.", "tokens": [2425, 28160, 13], "temperature": 0.0, "avg_logprob": -0.29341695573594834, "compression_ratio": 1.53, "no_speech_prob": 0.05815580114722252}, {"id": 2, "seek": 0, "start": 4.0, "end": 9.0, "text": " Well it's finally time to turn the page and start a new chapter of Elm.", "tokens": [1042, 309, 311, 2721, 565, 281, 1261, 264, 3028, 293, 722, 257, 777, 7187, 295, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.29341695573594834, "compression_ratio": 1.53, "no_speech_prob": 0.05815580114722252}, {"id": 3, "seek": 0, "start": 9.0, "end": 15.0, "text": " In fact, this might be more than a chapter, this might even be a whole new volume of Elm Pages.", "tokens": [682, 1186, 11, 341, 1062, 312, 544, 813, 257, 7187, 11, 341, 1062, 754, 312, 257, 1379, 777, 5523, 295, 2699, 76, 430, 1660, 13], "temperature": 0.0, "avg_logprob": -0.29341695573594834, "compression_ratio": 1.53, "no_speech_prob": 0.05815580114722252}, {"id": 4, "seek": 0, "start": 15.0, "end": 23.0, "text": " There are two volumes before, but by adding a third volume we've got a full stack of books about Elm Pages now.", "tokens": [821, 366, 732, 22219, 949, 11, 457, 538, 5127, 257, 2636, 5523, 321, 600, 658, 257, 1577, 8630, 295, 3642, 466, 2699, 76, 430, 1660, 586, 13], "temperature": 0.0, "avg_logprob": -0.29341695573594834, "compression_ratio": 1.53, "no_speech_prob": 0.05815580114722252}, {"id": 5, "seek": 2300, "start": 23.0, "end": 31.0, "text": " We are going to talk about Elm Pages once more.", "tokens": [492, 366, 516, 281, 751, 466, 2699, 76, 430, 1660, 1564, 544, 13], "temperature": 0.0, "avg_logprob": -0.21860727031579177, "compression_ratio": 2.1923076923076925, "no_speech_prob": 0.0013594167539849877}, {"id": 6, "seek": 2300, "start": 31.0, "end": 39.0, "text": " Yep, and we are not going to talk about Elm Pages Alpha, we are not going to talk about Elm Pages Beta,", "tokens": [7010, 11, 293, 321, 366, 406, 516, 281, 751, 466, 2699, 76, 430, 1660, 20588, 11, 321, 366, 406, 516, 281, 751, 466, 2699, 76, 430, 1660, 33286, 11], "temperature": 0.0, "avg_logprob": -0.21860727031579177, "compression_ratio": 2.1923076923076925, "no_speech_prob": 0.0013594167539849877}, {"id": 7, "seek": 2300, "start": 39.0, "end": 48.0, "text": " we are not going to talk about a soon to be released Elm Pages, we are talking about a stable release of Elm Pages V3, finally!", "tokens": [321, 366, 406, 516, 281, 751, 466, 257, 2321, 281, 312, 4736, 2699, 76, 430, 1660, 11, 321, 366, 1417, 466, 257, 8351, 4374, 295, 2699, 76, 430, 1660, 691, 18, 11, 2721, 0], "temperature": 0.0, "avg_logprob": -0.21860727031579177, "compression_ratio": 2.1923076923076925, "no_speech_prob": 0.0013594167539849877}, {"id": 8, "seek": 2300, "start": 48.0, "end": 50.0, "text": " Wooo!", "tokens": [10468, 78, 0], "temperature": 0.0, "avg_logprob": -0.21860727031579177, "compression_ratio": 2.1923076923076925, "no_speech_prob": 0.0013594167539849877}, {"id": 9, "seek": 5000, "start": 50.0, "end": 58.0, "text": " We've covered Elm Pages in a bunch of episodes, like our very first episode was about Elm Pages, what is Elm Pages?", "tokens": [492, 600, 5343, 2699, 76, 430, 1660, 294, 257, 3840, 295, 9313, 11, 411, 527, 588, 700, 3500, 390, 466, 2699, 76, 430, 1660, 11, 437, 307, 2699, 76, 430, 1660, 30], "temperature": 0.0, "avg_logprob": -0.21173979222089395, "compression_ratio": 1.6373056994818653, "no_speech_prob": 0.00016027667152229697}, {"id": 10, "seek": 5000, "start": 58.0, "end": 67.0, "text": " And that was for V1, V2 was released in between, we've done a few other episodes, including recently one about Elm Pages scripts.", "tokens": [400, 300, 390, 337, 691, 16, 11, 691, 17, 390, 4736, 294, 1296, 11, 321, 600, 1096, 257, 1326, 661, 9313, 11, 3009, 3938, 472, 466, 2699, 76, 430, 1660, 23294, 13], "temperature": 0.0, "avg_logprob": -0.21173979222089395, "compression_ratio": 1.6373056994818653, "no_speech_prob": 0.00016027667152229697}, {"id": 11, "seek": 5000, "start": 67.0, "end": 73.0, "text": " But that was still yet to be released, but now everything is released.", "tokens": [583, 300, 390, 920, 1939, 281, 312, 4736, 11, 457, 586, 1203, 307, 4736, 13], "temperature": 0.0, "avg_logprob": -0.21173979222089395, "compression_ratio": 1.6373056994818653, "no_speech_prob": 0.00016027667152229697}, {"id": 12, "seek": 7300, "start": 73.0, "end": 82.0, "text": " Dillon is now finally done with his work, he can now retire.", "tokens": [28160, 307, 586, 2721, 1096, 365, 702, 589, 11, 415, 393, 586, 10731, 13], "temperature": 0.0, "avg_logprob": -0.20283483777727399, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.00010605982242850587}, {"id": 13, "seek": 7300, "start": 82.0, "end": 90.0, "text": " At the very least I can think about other things, because it really felt like there are so many pieces to Elm Pages,", "tokens": [1711, 264, 588, 1935, 286, 393, 519, 466, 661, 721, 11, 570, 309, 534, 2762, 411, 456, 366, 370, 867, 3755, 281, 2699, 76, 430, 1660, 11], "temperature": 0.0, "avg_logprob": -0.20283483777727399, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.00010605982242850587}, {"id": 14, "seek": 7300, "start": 90.0, "end": 99.0, "text": " and I sympathize with users for the number of concepts that are available in the framework to grok.", "tokens": [293, 286, 22276, 1125, 365, 5022, 337, 264, 1230, 295, 10392, 300, 366, 2435, 294, 264, 8388, 281, 4634, 74, 13], "temperature": 0.0, "avg_logprob": -0.20283483777727399, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.00010605982242850587}, {"id": 15, "seek": 9900, "start": 99.0, "end": 105.0, "text": " But yeah, it was quite a journey to just juggle all those concepts,", "tokens": [583, 1338, 11, 309, 390, 1596, 257, 4671, 281, 445, 361, 31726, 439, 729, 10392, 11], "temperature": 0.0, "avg_logprob": -0.2148239668025527, "compression_ratio": 1.6055045871559632, "no_speech_prob": 0.0011644808109849691}, {"id": 16, "seek": 9900, "start": 105.0, "end": 111.0, "text": " and constantly try to think of better ways to simplify things, and how those pieces fit together,", "tokens": [293, 6460, 853, 281, 519, 295, 1101, 2098, 281, 20460, 721, 11, 293, 577, 729, 3755, 3318, 1214, 11], "temperature": 0.0, "avg_logprob": -0.2148239668025527, "compression_ratio": 1.6055045871559632, "no_speech_prob": 0.0011644808109849691}, {"id": 17, "seek": 9900, "start": 111.0, "end": 116.0, "text": " and then keep doing that over and over until all the pieces fit together really elegantly.", "tokens": [293, 550, 1066, 884, 300, 670, 293, 670, 1826, 439, 264, 3755, 3318, 1214, 534, 14459, 3627, 13], "temperature": 0.0, "avg_logprob": -0.2148239668025527, "compression_ratio": 1.6055045871559632, "no_speech_prob": 0.0011644808109849691}, {"id": 18, "seek": 9900, "start": 116.0, "end": 124.0, "text": " Like I came up with a lot of very new techniques that I haven't seen in an Elm framework yet,", "tokens": [1743, 286, 1361, 493, 365, 257, 688, 295, 588, 777, 7512, 300, 286, 2378, 380, 1612, 294, 364, 2699, 76, 8388, 1939, 11], "temperature": 0.0, "avg_logprob": -0.2148239668025527, "compression_ratio": 1.6055045871559632, "no_speech_prob": 0.0011644808109849691}, {"id": 19, "seek": 12400, "start": 124.0, "end": 129.0, "text": " so it was quite an experience.", "tokens": [370, 309, 390, 1596, 364, 1752, 13], "temperature": 0.0, "avg_logprob": -0.2966549847577069, "compression_ratio": 1.4969325153374233, "no_speech_prob": 0.0001581184333190322}, {"id": 20, "seek": 12400, "start": 129.0, "end": 136.0, "text": " Alright, so for the few people who have not heard about Elm Pages yet,", "tokens": [2798, 11, 370, 337, 264, 1326, 561, 567, 362, 406, 2198, 466, 2699, 76, 430, 1660, 1939, 11], "temperature": 0.0, "avg_logprob": -0.2966549847577069, "compression_ratio": 1.4969325153374233, "no_speech_prob": 0.0001581184333190322}, {"id": 21, "seek": 12400, "start": 136.0, "end": 137.0, "text": " or who have not...", "tokens": [420, 567, 362, 406, 485], "temperature": 0.0, "avg_logprob": -0.2966549847577069, "compression_ratio": 1.4969325153374233, "no_speech_prob": 0.0001581184333190322}, {"id": 22, "seek": 12400, "start": 137.0, "end": 141.0, "text": " For our one listener who doesn't know what Elm Pages is.", "tokens": [1171, 527, 472, 31569, 567, 1177, 380, 458, 437, 2699, 76, 430, 1660, 307, 13], "temperature": 0.0, "avg_logprob": -0.2966549847577069, "compression_ratio": 1.4969325153374233, "no_speech_prob": 0.0001581184333190322}, {"id": 23, "seek": 12400, "start": 141.0, "end": 146.0, "text": " Or who hasn't re-listened to all the episodes since the beginning,", "tokens": [1610, 567, 6132, 380, 319, 12, 75, 4821, 292, 281, 439, 264, 9313, 1670, 264, 2863, 11], "temperature": 0.0, "avg_logprob": -0.2966549847577069, "compression_ratio": 1.4969325153374233, "no_speech_prob": 0.0001581184333190322}, {"id": 24, "seek": 14600, "start": 146.0, "end": 154.0, "text": " maybe tell us what Elm Pages is, and then we can afterwards talk about what is new in v3.", "tokens": [1310, 980, 505, 437, 2699, 76, 430, 1660, 307, 11, 293, 550, 321, 393, 10543, 751, 466, 437, 307, 777, 294, 371, 18, 13], "temperature": 0.0, "avg_logprob": -0.17299947431010584, "compression_ratio": 1.7524752475247525, "no_speech_prob": 5.645455530611798e-05}, {"id": 25, "seek": 14600, "start": 154.0, "end": 156.0, "text": " So yeah, what is Elm Pages?", "tokens": [407, 1338, 11, 437, 307, 2699, 76, 430, 1660, 30], "temperature": 0.0, "avg_logprob": -0.17299947431010584, "compression_ratio": 1.7524752475247525, "no_speech_prob": 5.645455530611798e-05}, {"id": 26, "seek": 14600, "start": 156.0, "end": 163.0, "text": " Yeah, so the way I think about it, Elm Pages, number one, Elm Pages is Elm.", "tokens": [865, 11, 370, 264, 636, 286, 519, 466, 309, 11, 2699, 76, 430, 1660, 11, 1230, 472, 11, 2699, 76, 430, 1660, 307, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.17299947431010584, "compression_ratio": 1.7524752475247525, "no_speech_prob": 5.645455530611798e-05}, {"id": 27, "seek": 14600, "start": 163.0, "end": 165.0, "text": " It's an extension of Elm.", "tokens": [467, 311, 364, 10320, 295, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.17299947431010584, "compression_ratio": 1.7524752475247525, "no_speech_prob": 5.645455530611798e-05}, {"id": 28, "seek": 14600, "start": 165.0, "end": 170.0, "text": " So everything you understand about Elm, you can apply that understanding to Elm Pages.", "tokens": [407, 1203, 291, 1223, 466, 2699, 76, 11, 291, 393, 3079, 300, 3701, 281, 2699, 76, 430, 1660, 13], "temperature": 0.0, "avg_logprob": -0.17299947431010584, "compression_ratio": 1.7524752475247525, "no_speech_prob": 5.645455530611798e-05}, {"id": 29, "seek": 14600, "start": 170.0, "end": 172.0, "text": " So it's just Elm?", "tokens": [407, 309, 311, 445, 2699, 76, 30], "temperature": 0.0, "avg_logprob": -0.17299947431010584, "compression_ratio": 1.7524752475247525, "no_speech_prob": 5.645455530611798e-05}, {"id": 30, "seek": 14600, "start": 172.0, "end": 173.0, "text": " It's just Elm.", "tokens": [467, 311, 445, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.17299947431010584, "compression_ratio": 1.7524752475247525, "no_speech_prob": 5.645455530611798e-05}, {"id": 31, "seek": 14600, "start": 173.0, "end": 174.0, "text": " It's just Elm.", "tokens": [467, 311, 445, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.17299947431010584, "compression_ratio": 1.7524752475247525, "no_speech_prob": 5.645455530611798e-05}, {"id": 32, "seek": 17400, "start": 174.0, "end": 177.0, "text": " It's a single-page app in Elm.", "tokens": [467, 311, 257, 2167, 12, 15161, 724, 294, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.22157154083251954, "compression_ratio": 1.6398104265402844, "no_speech_prob": 4.263329174136743e-05}, {"id": 33, "seek": 17400, "start": 177.0, "end": 181.0, "text": " So Elm Pages is a way to build a single-page app.", "tokens": [407, 2699, 76, 430, 1660, 307, 257, 636, 281, 1322, 257, 2167, 12, 15161, 724, 13], "temperature": 0.0, "avg_logprob": -0.22157154083251954, "compression_ratio": 1.6398104265402844, "no_speech_prob": 4.263329174136743e-05}, {"id": 34, "seek": 17400, "start": 181.0, "end": 186.0, "text": " But it's a single-page app that extends the traditional Elm architecture.", "tokens": [583, 309, 311, 257, 2167, 12, 15161, 724, 300, 26448, 264, 5164, 2699, 76, 9482, 13], "temperature": 0.0, "avg_logprob": -0.22157154083251954, "compression_ratio": 1.6398104265402844, "no_speech_prob": 4.263329174136743e-05}, {"id": 35, "seek": 17400, "start": 186.0, "end": 192.0, "text": " So whereas the Elm architecture gives you an initUpdateView, and it renders client-side.", "tokens": [407, 9735, 264, 2699, 76, 9482, 2709, 291, 364, 3157, 22164, 17393, 30203, 11, 293, 309, 6125, 433, 6423, 12, 1812, 13], "temperature": 0.0, "avg_logprob": -0.22157154083251954, "compression_ratio": 1.6398104265402844, "no_speech_prob": 4.263329174136743e-05}, {"id": 36, "seek": 17400, "start": 192.0, "end": 200.0, "text": " So you load usually sort of an empty HTML skeleton that if you turn off JavaScript, it's a blank page.", "tokens": [407, 291, 3677, 2673, 1333, 295, 364, 6707, 17995, 25204, 300, 498, 291, 1261, 766, 15778, 11, 309, 311, 257, 8247, 3028, 13], "temperature": 0.0, "avg_logprob": -0.22157154083251954, "compression_ratio": 1.6398104265402844, "no_speech_prob": 4.263329174136743e-05}, {"id": 37, "seek": 20000, "start": 200.0, "end": 207.0, "text": " If you turn on JavaScript, it's a blank page until it hydrates the client-side rendering.", "tokens": [759, 291, 1261, 322, 15778, 11, 309, 311, 257, 8247, 3028, 1826, 309, 5796, 12507, 264, 6423, 12, 1812, 22407, 13], "temperature": 0.0, "avg_logprob": -0.1726139145668107, "compression_ratio": 1.603448275862069, "no_speech_prob": 6.747876341250958e-06}, {"id": 38, "seek": 20000, "start": 207.0, "end": 209.0, "text": " Hydrate isn't actually the appropriate term there.", "tokens": [24231, 4404, 1943, 380, 767, 264, 6854, 1433, 456, 13], "temperature": 0.0, "avg_logprob": -0.1726139145668107, "compression_ratio": 1.603448275862069, "no_speech_prob": 6.747876341250958e-06}, {"id": 39, "seek": 20000, "start": 209.0, "end": 212.0, "text": " Until it executes the JavaScript.", "tokens": [9088, 309, 4454, 1819, 264, 15778, 13], "temperature": 0.0, "avg_logprob": -0.1726139145668107, "compression_ratio": 1.603448275862069, "no_speech_prob": 6.747876341250958e-06}, {"id": 40, "seek": 20000, "start": 212.0, "end": 215.0, "text": " Exactly. It parses and executes the JavaScript.", "tokens": [7587, 13, 467, 21156, 279, 293, 4454, 1819, 264, 15778, 13], "temperature": 0.0, "avg_logprob": -0.1726139145668107, "compression_ratio": 1.603448275862069, "no_speech_prob": 6.747876341250958e-06}, {"id": 41, "seek": 20000, "start": 215.0, "end": 221.0, "text": " Elm Pages, for one thing, it pre-renders out the HTML.", "tokens": [2699, 76, 430, 1660, 11, 337, 472, 551, 11, 309, 659, 12, 4542, 433, 484, 264, 17995, 13], "temperature": 0.0, "avg_logprob": -0.1726139145668107, "compression_ratio": 1.603448275862069, "no_speech_prob": 6.747876341250958e-06}, {"id": 42, "seek": 20000, "start": 221.0, "end": 229.0, "text": " And it does that with a special addition to the lifecycle of the traditional Elm architecture.", "tokens": [400, 309, 775, 300, 365, 257, 2121, 4500, 281, 264, 45722, 295, 264, 5164, 2699, 76, 9482, 13], "temperature": 0.0, "avg_logprob": -0.1726139145668107, "compression_ratio": 1.603448275862069, "no_speech_prob": 6.747876341250958e-06}, {"id": 43, "seek": 22900, "start": 229.0, "end": 240.0, "text": " So the traditional Elm architecture, you have init, it can kick off some commands, and then it renders a view with your init.", "tokens": [407, 264, 5164, 2699, 76, 9482, 11, 291, 362, 3157, 11, 309, 393, 4437, 766, 512, 16901, 11, 293, 550, 309, 6125, 433, 257, 1910, 365, 428, 3157, 13], "temperature": 0.0, "avg_logprob": -0.18085722829781326, "compression_ratio": 1.7135922330097086, "no_speech_prob": 1.384561892336933e-05}, {"id": 44, "seek": 22900, "start": 240.0, "end": 242.0, "text": " And it does that all on the client-side.", "tokens": [400, 309, 775, 300, 439, 322, 264, 6423, 12, 1812, 13], "temperature": 0.0, "avg_logprob": -0.18085722829781326, "compression_ratio": 1.7135922330097086, "no_speech_prob": 1.384561892336933e-05}, {"id": 45, "seek": 22900, "start": 242.0, "end": 247.0, "text": " In Elm Pages, it runs init on the server.", "tokens": [682, 2699, 76, 430, 1660, 11, 309, 6676, 3157, 322, 264, 7154, 13], "temperature": 0.0, "avg_logprob": -0.18085722829781326, "compression_ratio": 1.7135922330097086, "no_speech_prob": 1.384561892336933e-05}, {"id": 46, "seek": 22900, "start": 247.0, "end": 252.0, "text": " So it actually takes the Elm app you write, and it runs it in two places.", "tokens": [407, 309, 767, 2516, 264, 2699, 76, 724, 291, 2464, 11, 293, 309, 6676, 309, 294, 732, 3190, 13], "temperature": 0.0, "avg_logprob": -0.18085722829781326, "compression_ratio": 1.7135922330097086, "no_speech_prob": 1.384561892336933e-05}, {"id": 47, "seek": 22900, "start": 252.0, "end": 257.0, "text": " It runs it on the server, and it runs it on the client in the browser.", "tokens": [467, 6676, 309, 322, 264, 7154, 11, 293, 309, 6676, 309, 322, 264, 6423, 294, 264, 11185, 13], "temperature": 0.0, "avg_logprob": -0.18085722829781326, "compression_ratio": 1.7135922330097086, "no_speech_prob": 1.384561892336933e-05}, {"id": 48, "seek": 25700, "start": 257.0, "end": 262.0, "text": " And so, yes, it runs it twice and it creates two applications.", "tokens": [400, 370, 11, 2086, 11, 309, 6676, 309, 6091, 293, 309, 7829, 732, 5821, 13], "temperature": 0.0, "avg_logprob": -0.19622290368173637, "compression_ratio": 1.7787610619469028, "no_speech_prob": 7.88872148405062e-06}, {"id": 49, "seek": 25700, "start": 262.0, "end": 267.0, "text": " Because the server one is running without a browser.", "tokens": [1436, 264, 7154, 472, 307, 2614, 1553, 257, 11185, 13], "temperature": 0.0, "avg_logprob": -0.19622290368173637, "compression_ratio": 1.7787610619469028, "no_speech_prob": 7.88872148405062e-06}, {"id": 50, "seek": 25700, "start": 267.0, "end": 277.0, "text": " It's running a headless application, but it runs your init, and it renders your view with your init, without running any of the commands from init.", "tokens": [467, 311, 2614, 257, 1378, 1832, 3861, 11, 457, 309, 6676, 428, 3157, 11, 293, 309, 6125, 433, 428, 1910, 365, 428, 3157, 11, 1553, 2614, 604, 295, 264, 16901, 490, 3157, 13], "temperature": 0.0, "avg_logprob": -0.19622290368173637, "compression_ratio": 1.7787610619469028, "no_speech_prob": 7.88872148405062e-06}, {"id": 51, "seek": 25700, "start": 277.0, "end": 282.0, "text": " It just takes your data from init, and it renders that to an HTML string.", "tokens": [467, 445, 2516, 428, 1412, 490, 3157, 11, 293, 309, 6125, 433, 300, 281, 364, 17995, 6798, 13], "temperature": 0.0, "avg_logprob": -0.19622290368173637, "compression_ratio": 1.7787610619469028, "no_speech_prob": 7.88872148405062e-06}, {"id": 52, "seek": 25700, "start": 282.0, "end": 286.0, "text": " And then that is the initial response that's sent to the client.", "tokens": [400, 550, 300, 307, 264, 5883, 4134, 300, 311, 2279, 281, 264, 6423, 13], "temperature": 0.0, "avg_logprob": -0.19622290368173637, "compression_ratio": 1.7787610619469028, "no_speech_prob": 7.88872148405062e-06}, {"id": 53, "seek": 28600, "start": 286.0, "end": 292.0, "text": " So the client has a fully rendered HTML view before the JavaScript takes over the page.", "tokens": [407, 264, 6423, 575, 257, 4498, 28748, 17995, 1910, 949, 264, 15778, 2516, 670, 264, 3028, 13], "temperature": 0.0, "avg_logprob": -0.1598604004104416, "compression_ratio": 1.54, "no_speech_prob": 3.535500945872627e-05}, {"id": 54, "seek": 28600, "start": 292.0, "end": 295.0, "text": " So that's one thing Elm Pages adds.", "tokens": [407, 300, 311, 472, 551, 2699, 76, 430, 1660, 10860, 13], "temperature": 0.0, "avg_logprob": -0.1598604004104416, "compression_ratio": 1.54, "no_speech_prob": 3.535500945872627e-05}, {"id": 55, "seek": 28600, "start": 295.0, "end": 303.0, "text": " The other thing that's a really big piece of what Elm Pages adds is your routes have something called data.", "tokens": [440, 661, 551, 300, 311, 257, 534, 955, 2522, 295, 437, 2699, 76, 430, 1660, 10860, 307, 428, 18242, 362, 746, 1219, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1598604004104416, "compression_ratio": 1.54, "no_speech_prob": 3.535500945872627e-05}, {"id": 56, "seek": 28600, "start": 303.0, "end": 308.0, "text": " That is an extension to the traditional Elm architecture's init update view.", "tokens": [663, 307, 364, 10320, 281, 264, 5164, 2699, 76, 9482, 311, 3157, 5623, 1910, 13], "temperature": 0.0, "avg_logprob": -0.1598604004104416, "compression_ratio": 1.54, "no_speech_prob": 3.535500945872627e-05}, {"id": 57, "seek": 30800, "start": 308.0, "end": 318.0, "text": " So data is something where you define, in Elm Pages v3, it's called a back-end task. In v2, it was called a data source.", "tokens": [407, 1412, 307, 746, 689, 291, 6964, 11, 294, 2699, 76, 430, 1660, 371, 18, 11, 309, 311, 1219, 257, 646, 12, 521, 5633, 13, 682, 371, 17, 11, 309, 390, 1219, 257, 1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.18085804650949877, "compression_ratio": 1.5, "no_speech_prob": 4.4253220039536245e-06}, {"id": 58, "seek": 30800, "start": 318.0, "end": 324.0, "text": " But that's a declarative way to define data, very similar to an Elm core task.", "tokens": [583, 300, 311, 257, 16694, 1166, 636, 281, 6964, 1412, 11, 588, 2531, 281, 364, 2699, 76, 4965, 5633, 13], "temperature": 0.0, "avg_logprob": -0.18085804650949877, "compression_ratio": 1.5, "no_speech_prob": 4.4253220039536245e-06}, {"id": 59, "seek": 30800, "start": 324.0, "end": 333.0, "text": " So you can have an HTTP request as a task, and you can transform that all into some data type.", "tokens": [407, 291, 393, 362, 364, 33283, 5308, 382, 257, 5633, 11, 293, 291, 393, 4088, 300, 439, 666, 512, 1412, 2010, 13], "temperature": 0.0, "avg_logprob": -0.18085804650949877, "compression_ratio": 1.5, "no_speech_prob": 4.4253220039536245e-06}, {"id": 60, "seek": 33300, "start": 333.0, "end": 338.0, "text": " So when that task resolves, you end up with some data.", "tokens": [407, 562, 300, 5633, 7923, 977, 11, 291, 917, 493, 365, 512, 1412, 13], "temperature": 0.0, "avg_logprob": -0.20153469735003532, "compression_ratio": 1.726829268292683, "no_speech_prob": 3.7265231185301673e-06}, {"id": 61, "seek": 33300, "start": 338.0, "end": 345.0, "text": " And that data is resolved fully on the server. It's resolved on the back-end, as the name back-end task implies.", "tokens": [400, 300, 1412, 307, 20772, 4498, 322, 264, 7154, 13, 467, 311, 20772, 322, 264, 646, 12, 521, 11, 382, 264, 1315, 646, 12, 521, 5633, 18779, 13], "temperature": 0.0, "avg_logprob": -0.20153469735003532, "compression_ratio": 1.726829268292683, "no_speech_prob": 3.7265231185301673e-06}, {"id": 62, "seek": 33300, "start": 345.0, "end": 351.0, "text": " And then that data is available before init is called, before your view is ever called.", "tokens": [400, 550, 300, 1412, 307, 2435, 949, 3157, 307, 1219, 11, 949, 428, 1910, 307, 1562, 1219, 13], "temperature": 0.0, "avg_logprob": -0.20153469735003532, "compression_ratio": 1.726829268292683, "no_speech_prob": 3.7265231185301673e-06}, {"id": 63, "seek": 33300, "start": 351.0, "end": 361.0, "text": " And so, whereas with a traditional Elm app, there's no data before init, unless you pass in flags.", "tokens": [400, 370, 11, 9735, 365, 257, 5164, 2699, 76, 724, 11, 456, 311, 572, 1412, 949, 3157, 11, 5969, 291, 1320, 294, 23265, 13], "temperature": 0.0, "avg_logprob": -0.20153469735003532, "compression_ratio": 1.726829268292683, "no_speech_prob": 3.7265231185301673e-06}, {"id": 64, "seek": 36100, "start": 361.0, "end": 369.0, "text": " And sometimes people do pass in flags with data from the server, to sort of bootstrap the page.", "tokens": [400, 2171, 561, 360, 1320, 294, 23265, 365, 1412, 490, 264, 7154, 11, 281, 1333, 295, 11450, 372, 4007, 264, 3028, 13], "temperature": 0.0, "avg_logprob": -0.2057413762929488, "compression_ratio": 1.6074380165289257, "no_speech_prob": 4.756821726914495e-05}, {"id": 65, "seek": 36100, "start": 369.0, "end": 373.0, "text": " Maybe it's like a Rails app or whatever server rendering framework.", "tokens": [2704, 309, 311, 411, 257, 48526, 724, 420, 2035, 7154, 22407, 8388, 13], "temperature": 0.0, "avg_logprob": -0.2057413762929488, "compression_ratio": 1.6074380165289257, "no_speech_prob": 4.756821726914495e-05}, {"id": 66, "seek": 36100, "start": 373.0, "end": 383.0, "text": " So actually, I think a really good way to think about the Elm Pages architecture is a sort of abstraction over that pattern.", "tokens": [407, 767, 11, 286, 519, 257, 534, 665, 636, 281, 519, 466, 264, 2699, 76, 430, 1660, 9482, 307, 257, 1333, 295, 37765, 670, 300, 5102, 13], "temperature": 0.0, "avg_logprob": -0.2057413762929488, "compression_ratio": 1.6074380165289257, "no_speech_prob": 4.756821726914495e-05}, {"id": 67, "seek": 36100, "start": 383.0, "end": 390.0, "text": " It's a way to make that pattern really easy for you to manage, where you do all of that in pure Elm,", "tokens": [467, 311, 257, 636, 281, 652, 300, 5102, 534, 1858, 337, 291, 281, 3067, 11, 689, 291, 360, 439, 295, 300, 294, 6075, 2699, 76, 11], "temperature": 0.0, "avg_logprob": -0.2057413762929488, "compression_ratio": 1.6074380165289257, "no_speech_prob": 4.756821726914495e-05}, {"id": 68, "seek": 39000, "start": 390.0, "end": 393.0, "text": " and you don't have to write all the glue code to do that.", "tokens": [293, 291, 500, 380, 362, 281, 2464, 439, 264, 8998, 3089, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.14618063839999113, "compression_ratio": 1.7100840336134453, "no_speech_prob": 7.601801917189732e-05}, {"id": 69, "seek": 39000, "start": 393.0, "end": 395.0, "text": " But that's essentially what it's doing.", "tokens": [583, 300, 311, 4476, 437, 309, 311, 884, 13], "temperature": 0.0, "avg_logprob": -0.14618063839999113, "compression_ratio": 1.7100840336134453, "no_speech_prob": 7.601801917189732e-05}, {"id": 70, "seek": 39000, "start": 395.0, "end": 402.0, "text": " It's saying, hey, before we load this page, since we're serving up this request from a server,", "tokens": [467, 311, 1566, 11, 4177, 11, 949, 321, 3677, 341, 3028, 11, 1670, 321, 434, 8148, 493, 341, 5308, 490, 257, 7154, 11], "temperature": 0.0, "avg_logprob": -0.14618063839999113, "compression_ratio": 1.7100840336134453, "no_speech_prob": 7.601801917189732e-05}, {"id": 71, "seek": 39000, "start": 402.0, "end": 407.0, "text": " we may as well just resolve some data and put that in the page, basically as a flag.", "tokens": [321, 815, 382, 731, 445, 14151, 512, 1412, 293, 829, 300, 294, 264, 3028, 11, 1936, 382, 257, 7166, 13], "temperature": 0.0, "avg_logprob": -0.14618063839999113, "compression_ratio": 1.7100840336134453, "no_speech_prob": 7.601801917189732e-05}, {"id": 72, "seek": 39000, "start": 407.0, "end": 410.0, "text": " It actually is doing that under the hood.", "tokens": [467, 767, 307, 884, 300, 833, 264, 13376, 13], "temperature": 0.0, "avg_logprob": -0.14618063839999113, "compression_ratio": 1.7100840336134453, "no_speech_prob": 7.601801917189732e-05}, {"id": 73, "seek": 39000, "start": 410.0, "end": 415.0, "text": " So you have some data that is available as flags, and it's there before init is called.", "tokens": [407, 291, 362, 512, 1412, 300, 307, 2435, 382, 23265, 11, 293, 309, 311, 456, 949, 3157, 307, 1219, 13], "temperature": 0.0, "avg_logprob": -0.14618063839999113, "compression_ratio": 1.7100840336134453, "no_speech_prob": 7.601801917189732e-05}, {"id": 74, "seek": 41500, "start": 415.0, "end": 422.0, "text": " That's exactly the mental model for an Elm Pages app for the route modules data.", "tokens": [663, 311, 2293, 264, 4973, 2316, 337, 364, 2699, 76, 430, 1660, 724, 337, 264, 7955, 16679, 1412, 13], "temperature": 0.0, "avg_logprob": -0.16912179523044163, "compression_ratio": 1.6081081081081081, "no_speech_prob": 1.2411424904712476e-05}, {"id": 75, "seek": 41500, "start": 422.0, "end": 432.0, "text": " Your data is available before view is ever called, unlike the commands that you return in your init function,", "tokens": [2260, 1412, 307, 2435, 949, 1910, 307, 1562, 1219, 11, 8343, 264, 16901, 300, 291, 2736, 294, 428, 3157, 2445, 11], "temperature": 0.0, "avg_logprob": -0.16912179523044163, "compression_ratio": 1.6081081081081081, "no_speech_prob": 1.2411424904712476e-05}, {"id": 76, "seek": 41500, "start": 432.0, "end": 435.0, "text": " which are available after view is called.", "tokens": [597, 366, 2435, 934, 1910, 307, 1219, 13], "temperature": 0.0, "avg_logprob": -0.16912179523044163, "compression_ratio": 1.6081081081081081, "no_speech_prob": 1.2411424904712476e-05}, {"id": 77, "seek": 41500, "start": 435.0, "end": 440.0, "text": " So you have loading spinners and intermediary states in your model to deal with.", "tokens": [407, 291, 362, 15114, 6060, 2999, 293, 15184, 822, 4368, 294, 428, 2316, 281, 2028, 365, 13], "temperature": 0.0, "avg_logprob": -0.16912179523044163, "compression_ratio": 1.6081081081081081, "no_speech_prob": 1.2411424904712476e-05}, {"id": 78, "seek": 41500, "start": 440.0, "end": 443.0, "text": " So that's really at the heart of Elm Pages.", "tokens": [407, 300, 311, 534, 412, 264, 1917, 295, 2699, 76, 430, 1660, 13], "temperature": 0.0, "avg_logprob": -0.16912179523044163, "compression_ratio": 1.6081081081081081, "no_speech_prob": 1.2411424904712476e-05}, {"id": 79, "seek": 44300, "start": 443.0, "end": 449.0, "text": " It's about getting that data before your page loads and everything that comes from that.", "tokens": [467, 311, 466, 1242, 300, 1412, 949, 428, 3028, 12668, 293, 1203, 300, 1487, 490, 300, 13], "temperature": 0.0, "avg_logprob": -0.1670367005583528, "compression_ratio": 1.6421052631578947, "no_speech_prob": 7.888879736128729e-06}, {"id": 80, "seek": 44300, "start": 449.0, "end": 457.0, "text": " So, for example, one thing that comes out of that pattern is you have fewer intermediary states to deal with,", "tokens": [407, 11, 337, 1365, 11, 472, 551, 300, 1487, 484, 295, 300, 5102, 307, 291, 362, 13366, 15184, 822, 4368, 281, 2028, 365, 11], "temperature": 0.0, "avg_logprob": -0.1670367005583528, "compression_ratio": 1.6421052631578947, "no_speech_prob": 7.888879736128729e-06}, {"id": 81, "seek": 44300, "start": 457.0, "end": 459.0, "text": " fewer loading spinners.", "tokens": [13366, 15114, 6060, 2999, 13], "temperature": 0.0, "avg_logprob": -0.1670367005583528, "compression_ratio": 1.6421052631578947, "no_speech_prob": 7.888879736128729e-06}, {"id": 82, "seek": 44300, "start": 459.0, "end": 463.0, "text": " The user doesn't have flashes of loading spinners coming in.", "tokens": [440, 4195, 1177, 380, 362, 39665, 295, 15114, 6060, 2999, 1348, 294, 13], "temperature": 0.0, "avg_logprob": -0.1670367005583528, "compression_ratio": 1.6421052631578947, "no_speech_prob": 7.888879736128729e-06}, {"id": 83, "seek": 44300, "start": 463.0, "end": 465.0, "text": " Does it also resolve errors?", "tokens": [4402, 309, 611, 14151, 13603, 30], "temperature": 0.0, "avg_logprob": -0.1670367005583528, "compression_ratio": 1.6421052631578947, "no_speech_prob": 7.888879736128729e-06}, {"id": 84, "seek": 46500, "start": 465.0, "end": 475.0, "text": " Like if you ask for some kind of data, then you're sure to get that data, otherwise the user will get a 400 or 500 page error.", "tokens": [1743, 498, 291, 1029, 337, 512, 733, 295, 1412, 11, 550, 291, 434, 988, 281, 483, 300, 1412, 11, 5911, 264, 4195, 486, 483, 257, 8423, 420, 5923, 3028, 6713, 13], "temperature": 0.0, "avg_logprob": -0.21179391687566584, "compression_ratio": 1.5577689243027888, "no_speech_prob": 1.963770273505361e-06}, {"id": 85, "seek": 46500, "start": 475.0, "end": 476.0, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.21179391687566584, "compression_ratio": 1.5577689243027888, "no_speech_prob": 1.963770273505361e-06}, {"id": 86, "seek": 46500, "start": 476.0, "end": 480.0, "text": " Okay, so you also don't have to handle those error states. That's pretty nice.", "tokens": [1033, 11, 370, 291, 611, 500, 380, 362, 281, 4813, 729, 6713, 4368, 13, 663, 311, 1238, 1481, 13], "temperature": 0.0, "avg_logprob": -0.21179391687566584, "compression_ratio": 1.5577689243027888, "no_speech_prob": 1.963770273505361e-06}, {"id": 87, "seek": 46500, "start": 480.0, "end": 482.0, "text": " It takes those out of your happy path.", "tokens": [467, 2516, 729, 484, 295, 428, 2055, 3100, 13], "temperature": 0.0, "avg_logprob": -0.21179391687566584, "compression_ratio": 1.5577689243027888, "no_speech_prob": 1.963770273505361e-06}, {"id": 88, "seek": 46500, "start": 482.0, "end": 492.0, "text": " So the way this works in Elm Pages v2, there was only one mode, which was rendering your pages at build time.", "tokens": [407, 264, 636, 341, 1985, 294, 2699, 76, 430, 1660, 371, 17, 11, 456, 390, 787, 472, 4391, 11, 597, 390, 22407, 428, 7183, 412, 1322, 565, 13], "temperature": 0.0, "avg_logprob": -0.21179391687566584, "compression_ratio": 1.5577689243027888, "no_speech_prob": 1.963770273505361e-06}, {"id": 89, "seek": 46500, "start": 492.0, "end": 494.0, "text": " It was a static site generator.", "tokens": [467, 390, 257, 13437, 3621, 19265, 13], "temperature": 0.0, "avg_logprob": -0.21179391687566584, "compression_ratio": 1.5577689243027888, "no_speech_prob": 1.963770273505361e-06}, {"id": 90, "seek": 49400, "start": 494.0, "end": 504.0, "text": " Elm Pages v3 is a hybrid framework that supports both static site generation with something that's called pre-rendered routes,", "tokens": [2699, 76, 430, 1660, 371, 18, 307, 257, 13051, 8388, 300, 9346, 1293, 13437, 3621, 5125, 365, 746, 300, 311, 1219, 659, 12, 4542, 4073, 18242, 11], "temperature": 0.0, "avg_logprob": -0.19041880439309514, "compression_ratio": 1.5844155844155845, "no_speech_prob": 1.2029375284328125e-05}, {"id": 91, "seek": 49400, "start": 504.0, "end": 506.0, "text": " and then there are server-rendered routes.", "tokens": [293, 550, 456, 366, 7154, 12, 4542, 4073, 18242, 13], "temperature": 0.0, "avg_logprob": -0.19041880439309514, "compression_ratio": 1.5844155844155845, "no_speech_prob": 1.2029375284328125e-05}, {"id": 92, "seek": 49400, "start": 506.0, "end": 515.0, "text": " So in the pre-rendered routes, if your backend task has an error, then that results in a build failure.", "tokens": [407, 294, 264, 659, 12, 4542, 4073, 18242, 11, 498, 428, 38087, 5633, 575, 364, 6713, 11, 550, 300, 3542, 294, 257, 1322, 7763, 13], "temperature": 0.0, "avg_logprob": -0.19041880439309514, "compression_ratio": 1.5844155844155845, "no_speech_prob": 1.2029375284328125e-05}, {"id": 93, "seek": 49400, "start": 515.0, "end": 518.0, "text": " And you can, you know, so, oh, this API is down.", "tokens": [400, 291, 393, 11, 291, 458, 11, 370, 11, 1954, 11, 341, 9362, 307, 760, 13], "temperature": 0.0, "avg_logprob": -0.19041880439309514, "compression_ratio": 1.5844155844155845, "no_speech_prob": 1.2029375284328125e-05}, {"id": 94, "seek": 49400, "start": 518.0, "end": 522.0, "text": " Well, okay, then don't push that site live.", "tokens": [1042, 11, 1392, 11, 550, 500, 380, 2944, 300, 3621, 1621, 13], "temperature": 0.0, "avg_logprob": -0.19041880439309514, "compression_ratio": 1.5844155844155845, "no_speech_prob": 1.2029375284328125e-05}, {"id": 95, "seek": 52200, "start": 522.0, "end": 532.0, "text": " Or if you want to, you can handle an HTTP failure with whatever logic you want, retrying the HTTP request,", "tokens": [1610, 498, 291, 528, 281, 11, 291, 393, 4813, 364, 33283, 7763, 365, 2035, 9952, 291, 528, 11, 1533, 19076, 264, 33283, 5308, 11], "temperature": 0.0, "avg_logprob": -0.1781228492999899, "compression_ratio": 1.6962962962962962, "no_speech_prob": 7.183146863098955e-06}, {"id": 96, "seek": 52200, "start": 532.0, "end": 536.0, "text": " falling back to some data, falling back to a cached response.", "tokens": [7440, 646, 281, 512, 1412, 11, 7440, 646, 281, 257, 269, 15095, 4134, 13], "temperature": 0.0, "avg_logprob": -0.1781228492999899, "compression_ratio": 1.6962962962962962, "no_speech_prob": 7.183146863098955e-06}, {"id": 97, "seek": 52200, "start": 536.0, "end": 538.0, "text": " You can use all of these types of strategies.", "tokens": [509, 393, 764, 439, 295, 613, 3467, 295, 9029, 13], "temperature": 0.0, "avg_logprob": -0.1781228492999899, "compression_ratio": 1.6962962962962962, "no_speech_prob": 7.183146863098955e-06}, {"id": 98, "seek": 52200, "start": 538.0, "end": 541.0, "text": " You can write general purpose Elm code to handle these errors.", "tokens": [509, 393, 2464, 2674, 4334, 2699, 76, 3089, 281, 4813, 613, 13603, 13], "temperature": 0.0, "avg_logprob": -0.1781228492999899, "compression_ratio": 1.6962962962962962, "no_speech_prob": 7.183146863098955e-06}, {"id": 99, "seek": 52200, "start": 541.0, "end": 545.0, "text": " And that's actually been a big part of the v3 release of Elm Pages,", "tokens": [400, 300, 311, 767, 668, 257, 955, 644, 295, 264, 371, 18, 4374, 295, 2699, 76, 430, 1660, 11], "temperature": 0.0, "avg_logprob": -0.1781228492999899, "compression_ratio": 1.6962962962962962, "no_speech_prob": 7.183146863098955e-06}, {"id": 100, "seek": 52200, "start": 545.0, "end": 551.0, "text": " partially because if you're doing server rendering, you want more fine-grained control over your error handling,", "tokens": [18886, 570, 498, 291, 434, 884, 7154, 22407, 11, 291, 528, 544, 2489, 12, 20735, 2001, 1969, 670, 428, 6713, 13175, 11], "temperature": 0.0, "avg_logprob": -0.1781228492999899, "compression_ratio": 1.6962962962962962, "no_speech_prob": 7.183146863098955e-06}, {"id": 101, "seek": 55100, "start": 551.0, "end": 559.0, "text": " because if it's just a static site, something goes wrong, fail the build, and let me play around with it and fix it.", "tokens": [570, 498, 309, 311, 445, 257, 13437, 3621, 11, 746, 1709, 2085, 11, 3061, 264, 1322, 11, 293, 718, 385, 862, 926, 365, 309, 293, 3191, 309, 13], "temperature": 0.0, "avg_logprob": -0.15457332652548086, "compression_ratio": 1.6681614349775784, "no_speech_prob": 3.7636011256836355e-05}, {"id": 102, "seek": 55100, "start": 559.0, "end": 564.0, "text": " If it's server rendered, if something goes wrong, you might want more nuanced control.", "tokens": [759, 309, 311, 7154, 28748, 11, 498, 746, 1709, 2085, 11, 291, 1062, 528, 544, 45115, 1969, 13], "temperature": 0.0, "avg_logprob": -0.15457332652548086, "compression_ratio": 1.6681614349775784, "no_speech_prob": 3.7636011256836355e-05}, {"id": 103, "seek": 55100, "start": 564.0, "end": 571.0, "text": " You know, maybe it's just that you show an error page, but you want to give really good information in that error page", "tokens": [509, 458, 11, 1310, 309, 311, 445, 300, 291, 855, 364, 6713, 3028, 11, 457, 291, 528, 281, 976, 534, 665, 1589, 294, 300, 6713, 3028], "temperature": 0.0, "avg_logprob": -0.15457332652548086, "compression_ratio": 1.6681614349775784, "no_speech_prob": 3.7636011256836355e-05}, {"id": 104, "seek": 55100, "start": 571.0, "end": 574.0, "text": " instead of just giving a 500 with no information.", "tokens": [2602, 295, 445, 2902, 257, 5923, 365, 572, 1589, 13], "temperature": 0.0, "avg_logprob": -0.15457332652548086, "compression_ratio": 1.6681614349775784, "no_speech_prob": 3.7636011256836355e-05}, {"id": 105, "seek": 57400, "start": 574.0, "end": 583.0, "text": " You know, maybe you want to respond like maybe an API gives you strange error codes or fails in strange ways,", "tokens": [509, 458, 11, 1310, 291, 528, 281, 4196, 411, 1310, 364, 9362, 2709, 291, 5861, 6713, 14211, 420, 18199, 294, 5861, 2098, 11], "temperature": 0.0, "avg_logprob": -0.1669492299577831, "compression_ratio": 1.5793357933579335, "no_speech_prob": 4.425334736879449e-06}, {"id": 106, "seek": 57400, "start": 583.0, "end": 589.0, "text": " but it actually is just because it's a 404, this page doesn't exist for this user, or you're not authorized,", "tokens": [457, 309, 767, 307, 445, 570, 309, 311, 257, 3356, 19, 11, 341, 3028, 1177, 380, 2514, 337, 341, 4195, 11, 420, 291, 434, 406, 28312, 11], "temperature": 0.0, "avg_logprob": -0.1669492299577831, "compression_ratio": 1.5793357933579335, "no_speech_prob": 4.425334736879449e-06}, {"id": 107, "seek": 57400, "start": 589.0, "end": 593.0, "text": " or whatever it is, and you want to handle that in a more sophisticated way.", "tokens": [420, 2035, 309, 307, 11, 293, 291, 528, 281, 4813, 300, 294, 257, 544, 16950, 636, 13], "temperature": 0.0, "avg_logprob": -0.1669492299577831, "compression_ratio": 1.5793357933579335, "no_speech_prob": 4.425334736879449e-06}, {"id": 108, "seek": 57400, "start": 593.0, "end": 596.0, "text": " But so with Elm Pages v3, there's something called a fatal error.", "tokens": [583, 370, 365, 2699, 76, 430, 1660, 371, 18, 11, 456, 311, 746, 1219, 257, 24069, 6713, 13], "temperature": 0.0, "avg_logprob": -0.1669492299577831, "compression_ratio": 1.5793357933579335, "no_speech_prob": 4.425334736879449e-06}, {"id": 109, "seek": 57400, "start": 596.0, "end": 601.0, "text": " We talked about that a little bit in our Elm Pages scripts episode.", "tokens": [492, 2825, 466, 300, 257, 707, 857, 294, 527, 2699, 76, 430, 1660, 23294, 3500, 13], "temperature": 0.0, "avg_logprob": -0.1669492299577831, "compression_ratio": 1.5793357933579335, "no_speech_prob": 4.425334736879449e-06}, {"id": 110, "seek": 60100, "start": 601.0, "end": 607.0, "text": " As I mentioned in that episode, I think that Elm Pages scripts are a very good way to get acquainted with these concepts", "tokens": [1018, 286, 2835, 294, 300, 3500, 11, 286, 519, 300, 2699, 76, 430, 1660, 23294, 366, 257, 588, 665, 636, 281, 483, 50224, 365, 613, 10392], "temperature": 0.0, "avg_logprob": -0.1830594079536304, "compression_ratio": 1.7818930041152263, "no_speech_prob": 6.438915079343133e-06}, {"id": 111, "seek": 60100, "start": 607.0, "end": 609.0, "text": " around back-end tasks and fatal errors.", "tokens": [926, 646, 12, 521, 9608, 293, 24069, 13603, 13], "temperature": 0.0, "avg_logprob": -0.1830594079536304, "compression_ratio": 1.7818930041152263, "no_speech_prob": 6.438915079343133e-06}, {"id": 112, "seek": 60100, "start": 609.0, "end": 617.0, "text": " But to summarize briefly, a back-end task has an error type, just like the Elm core task type has an error type variable", "tokens": [583, 281, 20858, 10515, 11, 257, 646, 12, 521, 5633, 575, 364, 6713, 2010, 11, 445, 411, 264, 2699, 76, 4965, 5633, 2010, 575, 364, 6713, 2010, 7006], "temperature": 0.0, "avg_logprob": -0.1830594079536304, "compression_ratio": 1.7818930041152263, "no_speech_prob": 6.438915079343133e-06}, {"id": 113, "seek": 60100, "start": 617.0, "end": 619.0, "text": " and a data type variable.", "tokens": [293, 257, 1412, 2010, 7006, 13], "temperature": 0.0, "avg_logprob": -0.1830594079536304, "compression_ratio": 1.7818930041152263, "no_speech_prob": 6.438915079343133e-06}, {"id": 114, "seek": 60100, "start": 619.0, "end": 627.0, "text": " And in Elm Pages, the places that accept a back-end task, like your route module's data function, you return a back-end task.", "tokens": [400, 294, 2699, 76, 430, 1660, 11, 264, 3190, 300, 3241, 257, 646, 12, 521, 5633, 11, 411, 428, 7955, 10088, 311, 1412, 2445, 11, 291, 2736, 257, 646, 12, 521, 5633, 13], "temperature": 0.0, "avg_logprob": -0.1830594079536304, "compression_ratio": 1.7818930041152263, "no_speech_prob": 6.438915079343133e-06}, {"id": 115, "seek": 62700, "start": 627.0, "end": 632.0, "text": " The error type it accepts for that back-end task is something called fatal error.", "tokens": [440, 6713, 2010, 309, 33538, 337, 300, 646, 12, 521, 5633, 307, 746, 1219, 24069, 6713, 13], "temperature": 0.0, "avg_logprob": -0.17511983598981584, "compression_ratio": 1.7831858407079646, "no_speech_prob": 2.9479756449291017e-06}, {"id": 116, "seek": 62700, "start": 632.0, "end": 640.0, "text": " And fatal error is just something that represents an error message that you can present if there's a build failure", "tokens": [400, 24069, 6713, 307, 445, 746, 300, 8855, 364, 6713, 3636, 300, 291, 393, 1974, 498, 456, 311, 257, 1322, 7763], "temperature": 0.0, "avg_logprob": -0.17511983598981584, "compression_ratio": 1.7831858407079646, "no_speech_prob": 2.9479756449291017e-06}, {"id": 117, "seek": 62700, "start": 640.0, "end": 644.0, "text": " for a pre-rendered route, or if there's a 500 error.", "tokens": [337, 257, 659, 12, 4542, 4073, 7955, 11, 420, 498, 456, 311, 257, 5923, 6713, 13], "temperature": 0.0, "avg_logprob": -0.17511983598981584, "compression_ratio": 1.7831858407079646, "no_speech_prob": 2.9479756449291017e-06}, {"id": 118, "seek": 62700, "start": 644.0, "end": 645.0, "text": " That's really all it is.", "tokens": [663, 311, 534, 439, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.17511983598981584, "compression_ratio": 1.7831858407079646, "no_speech_prob": 2.9479756449291017e-06}, {"id": 119, "seek": 62700, "start": 645.0, "end": 651.0, "text": " But Elm Pages is able to accept something of the fatal error type.", "tokens": [583, 2699, 76, 430, 1660, 307, 1075, 281, 3241, 746, 295, 264, 24069, 6713, 2010, 13], "temperature": 0.0, "avg_logprob": -0.17511983598981584, "compression_ratio": 1.7831858407079646, "no_speech_prob": 2.9479756449291017e-06}, {"id": 120, "seek": 62700, "start": 651.0, "end": 653.0, "text": " You can build your own fatal errors if you want and just say,", "tokens": [509, 393, 1322, 428, 1065, 24069, 13603, 498, 291, 528, 293, 445, 584, 11], "temperature": 0.0, "avg_logprob": -0.17511983598981584, "compression_ratio": 1.7831858407079646, "no_speech_prob": 2.9479756449291017e-06}, {"id": 121, "seek": 65300, "start": 653.0, "end": 661.0, "text": " I want to bail out, I want to just fail the build with an error message if I encounter this case.", "tokens": [286, 528, 281, 19313, 484, 11, 286, 528, 281, 445, 3061, 264, 1322, 365, 364, 6713, 3636, 498, 286, 8593, 341, 1389, 13], "temperature": 0.0, "avg_logprob": -0.22873252329200205, "compression_ratio": 1.5210084033613445, "no_speech_prob": 5.2551840781234205e-06}, {"id": 122, "seek": 65300, "start": 661.0, "end": 663.0, "text": " You can create your own fatal error type as well.", "tokens": [509, 393, 1884, 428, 1065, 24069, 6713, 2010, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.22873252329200205, "compression_ratio": 1.5210084033613445, "no_speech_prob": 5.2551840781234205e-06}, {"id": 123, "seek": 65300, "start": 663.0, "end": 664.0, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.22873252329200205, "compression_ratio": 1.5210084033613445, "no_speech_prob": 5.2551840781234205e-06}, {"id": 124, "seek": 65300, "start": 664.0, "end": 671.0, "text": " So is it, of course, there's going to be a simplification, but basically Elm Pages is a static-side generator,", "tokens": [407, 307, 309, 11, 295, 1164, 11, 456, 311, 516, 281, 312, 257, 6883, 3774, 11, 457, 1936, 2699, 76, 430, 1660, 307, 257, 13437, 12, 1812, 19265, 11], "temperature": 0.0, "avg_logprob": -0.22873252329200205, "compression_ratio": 1.5210084033613445, "no_speech_prob": 5.2551840781234205e-06}, {"id": 125, "seek": 65300, "start": 671.0, "end": 682.0, "text": " which in v3 now has also server-side rendered routes and something called Elm Pages scripts,", "tokens": [597, 294, 371, 18, 586, 575, 611, 7154, 12, 1812, 28748, 18242, 293, 746, 1219, 2699, 76, 430, 1660, 23294, 11], "temperature": 0.0, "avg_logprob": -0.22873252329200205, "compression_ratio": 1.5210084033613445, "no_speech_prob": 5.2551840781234205e-06}, {"id": 126, "seek": 68200, "start": 682.0, "end": 687.0, "text": " which allows you to run arbitrary scripts written in Elm slash Elm Pages.", "tokens": [597, 4045, 291, 281, 1190, 23211, 23294, 3720, 294, 2699, 76, 17330, 2699, 76, 430, 1660, 13], "temperature": 0.0, "avg_logprob": -0.18780061240508178, "compression_ratio": 1.671641791044776, "no_speech_prob": 2.7532030799193308e-05}, {"id": 127, "seek": 68200, "start": 687.0, "end": 688.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.18780061240508178, "compression_ratio": 1.671641791044776, "no_speech_prob": 2.7532030799193308e-05}, {"id": 128, "seek": 68200, "start": 688.0, "end": 692.0, "text": " So that might sound like a lot of disparate concepts.", "tokens": [407, 300, 1062, 1626, 411, 257, 688, 295, 14548, 473, 10392, 13], "temperature": 0.0, "avg_logprob": -0.18780061240508178, "compression_ratio": 1.671641791044776, "no_speech_prob": 2.7532030799193308e-05}, {"id": 129, "seek": 68200, "start": 692.0, "end": 702.0, "text": " The way I would frame it that makes sense to me is Elm Pages is a tool centered around this concept called a back-end task.", "tokens": [440, 636, 286, 576, 3920, 309, 300, 1669, 2020, 281, 385, 307, 2699, 76, 430, 1660, 307, 257, 2290, 18988, 926, 341, 3410, 1219, 257, 646, 12, 521, 5633, 13], "temperature": 0.0, "avg_logprob": -0.18780061240508178, "compression_ratio": 1.671641791044776, "no_speech_prob": 2.7532030799193308e-05}, {"id": 130, "seek": 68200, "start": 702.0, "end": 703.0, "text": " A back-end task.", "tokens": [316, 646, 12, 521, 5633, 13], "temperature": 0.0, "avg_logprob": -0.18780061240508178, "compression_ratio": 1.671641791044776, "no_speech_prob": 2.7532030799193308e-05}, {"id": 131, "seek": 68200, "start": 703.0, "end": 705.0, "text": " Oh, so it's Elm back-end task.", "tokens": [876, 11, 370, 309, 311, 2699, 76, 646, 12, 521, 5633, 13], "temperature": 0.0, "avg_logprob": -0.18780061240508178, "compression_ratio": 1.671641791044776, "no_speech_prob": 2.7532030799193308e-05}, {"id": 132, "seek": 68200, "start": 705.0, "end": 706.0, "text": " It kind of is.", "tokens": [467, 733, 295, 307, 13], "temperature": 0.0, "avg_logprob": -0.18780061240508178, "compression_ratio": 1.671641791044776, "no_speech_prob": 2.7532030799193308e-05}, {"id": 133, "seek": 68200, "start": 706.0, "end": 707.0, "text": " It kind of is.", "tokens": [467, 733, 295, 307, 13], "temperature": 0.0, "avg_logprob": -0.18780061240508178, "compression_ratio": 1.671641791044776, "no_speech_prob": 2.7532030799193308e-05}, {"id": 134, "seek": 70700, "start": 707.0, "end": 712.0, "text": " So that is the heart of Elm Pages, and it always has been in my heart.", "tokens": [407, 300, 307, 264, 1917, 295, 2699, 76, 430, 1660, 11, 293, 309, 1009, 575, 668, 294, 452, 1917, 13], "temperature": 0.0, "avg_logprob": -0.1483499019517811, "compression_ratio": 1.7724867724867726, "no_speech_prob": 7.296027433767449e-06}, {"id": 135, "seek": 70700, "start": 712.0, "end": 715.0, "text": " Deep in my heart, it's always been the heart of Elm Pages.", "tokens": [14895, 294, 452, 1917, 11, 309, 311, 1009, 668, 264, 1917, 295, 2699, 76, 430, 1660, 13], "temperature": 0.0, "avg_logprob": -0.1483499019517811, "compression_ratio": 1.7724867724867726, "no_speech_prob": 7.296027433767449e-06}, {"id": 136, "seek": 70700, "start": 715.0, "end": 716.0, "text": " Maybe my heart is the heart of Elm Pages.", "tokens": [2704, 452, 1917, 307, 264, 1917, 295, 2699, 76, 430, 1660, 13], "temperature": 0.0, "avg_logprob": -0.1483499019517811, "compression_ratio": 1.7724867724867726, "no_speech_prob": 7.296027433767449e-06}, {"id": 137, "seek": 70700, "start": 716.0, "end": 717.0, "text": " I don't know.", "tokens": [286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.1483499019517811, "compression_ratio": 1.7724867724867726, "no_speech_prob": 7.296027433767449e-06}, {"id": 138, "seek": 70700, "start": 717.0, "end": 723.0, "text": " But what it's all about is it's a way to declaratively resolve data.", "tokens": [583, 437, 309, 311, 439, 466, 307, 309, 311, 257, 636, 281, 16694, 19020, 14151, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1483499019517811, "compression_ratio": 1.7724867724867726, "no_speech_prob": 7.296027433767449e-06}, {"id": 139, "seek": 70700, "start": 723.0, "end": 730.0, "text": " So the back-end task API gives you a way of resolving data on a back-end.", "tokens": [407, 264, 646, 12, 521, 5633, 9362, 2709, 291, 257, 636, 295, 49940, 1412, 322, 257, 646, 12, 521, 13], "temperature": 0.0, "avg_logprob": -0.1483499019517811, "compression_ratio": 1.7724867724867726, "no_speech_prob": 7.296027433767449e-06}, {"id": 140, "seek": 70700, "start": 730.0, "end": 731.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.1483499019517811, "compression_ratio": 1.7724867724867726, "no_speech_prob": 7.296027433767449e-06}, {"id": 141, "seek": 73100, "start": 731.0, "end": 737.0, "text": " So it's a regular Elm core task.", "tokens": [407, 309, 311, 257, 3890, 2699, 76, 4965, 5633, 13], "temperature": 0.0, "avg_logprob": -0.1710735611293627, "compression_ratio": 1.57, "no_speech_prob": 1.8738636526904884e-06}, {"id": 142, "seek": 73100, "start": 737.0, "end": 746.0, "text": " You can say scroll to this position as a task, or there are a handful of web APIs that are exposed as tasks.", "tokens": [509, 393, 584, 11369, 281, 341, 2535, 382, 257, 5633, 11, 420, 456, 366, 257, 16458, 295, 3670, 21445, 300, 366, 9495, 382, 9608, 13], "temperature": 0.0, "avg_logprob": -0.1710735611293627, "compression_ratio": 1.57, "no_speech_prob": 1.8738636526904884e-06}, {"id": 143, "seek": 73100, "start": 746.0, "end": 750.0, "text": " Those don't exist in back-end tasks because they're tasks that run on the back-end.", "tokens": [3950, 500, 380, 2514, 294, 646, 12, 521, 9608, 570, 436, 434, 9608, 300, 1190, 322, 264, 646, 12, 521, 13], "temperature": 0.0, "avg_logprob": -0.1710735611293627, "compression_ratio": 1.57, "no_speech_prob": 1.8738636526904884e-06}, {"id": 144, "seek": 73100, "start": 750.0, "end": 755.0, "text": " On the other hand, an Elm core task cannot run things in Node.js.", "tokens": [1282, 264, 661, 1011, 11, 364, 2699, 76, 4965, 5633, 2644, 1190, 721, 294, 38640, 13, 25530, 13], "temperature": 0.0, "avg_logprob": -0.1710735611293627, "compression_ratio": 1.57, "no_speech_prob": 1.8738636526904884e-06}, {"id": 145, "seek": 73100, "start": 755.0, "end": 756.0, "text": " It cannot read a file.", "tokens": [467, 2644, 1401, 257, 3991, 13], "temperature": 0.0, "avg_logprob": -0.1710735611293627, "compression_ratio": 1.57, "no_speech_prob": 1.8738636526904884e-06}, {"id": 146, "seek": 75600, "start": 756.0, "end": 762.0, "text": " It cannot perform a glob to list out files matching a certain pattern.", "tokens": [467, 2644, 2042, 257, 16125, 281, 1329, 484, 7098, 14324, 257, 1629, 5102, 13], "temperature": 0.0, "avg_logprob": -0.19496224801751633, "compression_ratio": 1.6108374384236452, "no_speech_prob": 3.5559667139750673e-06}, {"id": 147, "seek": 75600, "start": 762.0, "end": 764.0, "text": " It cannot read environment variables.", "tokens": [467, 2644, 1401, 2823, 9102, 13], "temperature": 0.0, "avg_logprob": -0.19496224801751633, "compression_ratio": 1.6108374384236452, "no_speech_prob": 3.5559667139750673e-06}, {"id": 148, "seek": 75600, "start": 764.0, "end": 773.0, "text": " And those are often handy things to have if you're also it's not executing in a secure, trusted environment.", "tokens": [400, 729, 366, 2049, 13239, 721, 281, 362, 498, 291, 434, 611, 309, 311, 406, 32368, 294, 257, 7144, 11, 16034, 2823, 13], "temperature": 0.0, "avg_logprob": -0.19496224801751633, "compression_ratio": 1.6108374384236452, "no_speech_prob": 3.5559667139750673e-06}, {"id": 149, "seek": 75600, "start": 773.0, "end": 782.0, "text": " So even if you had a way to pull in environment variables in an Elm core task, which executes in the browser,", "tokens": [407, 754, 498, 291, 632, 257, 636, 281, 2235, 294, 2823, 9102, 294, 364, 2699, 76, 4965, 5633, 11, 597, 4454, 1819, 294, 264, 11185, 11], "temperature": 0.0, "avg_logprob": -0.19496224801751633, "compression_ratio": 1.6108374384236452, "no_speech_prob": 3.5559667139750673e-06}, {"id": 150, "seek": 78200, "start": 782.0, "end": 792.0, "text": " you wouldn't want to pull in secrets because suddenly you've revealed your secrets for doing admin database queries", "tokens": [291, 2759, 380, 528, 281, 2235, 294, 14093, 570, 5800, 291, 600, 9599, 428, 14093, 337, 884, 24236, 8149, 24109], "temperature": 0.0, "avg_logprob": -0.217464868645919, "compression_ratio": 1.5959183673469388, "no_speech_prob": 2.11110836971784e-05}, {"id": 151, "seek": 78200, "start": 792.0, "end": 796.0, "text": " or using your open AI API token.", "tokens": [420, 1228, 428, 1269, 7318, 9362, 14862, 13], "temperature": 0.0, "avg_logprob": -0.217464868645919, "compression_ratio": 1.5959183673469388, "no_speech_prob": 2.11110836971784e-05}, {"id": 152, "seek": 78200, "start": 796.0, "end": 804.0, "text": " And now you're getting slammed with requests from people who stole your token and are using that for their requests or whatever.", "tokens": [400, 586, 291, 434, 1242, 50196, 365, 12475, 490, 561, 567, 16326, 428, 14862, 293, 366, 1228, 300, 337, 641, 12475, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.217464868645919, "compression_ratio": 1.5959183673469388, "no_speech_prob": 2.11110836971784e-05}, {"id": 153, "seek": 78200, "start": 804.0, "end": 805.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.217464868645919, "compression_ratio": 1.5959183673469388, "no_speech_prob": 2.11110836971784e-05}, {"id": 154, "seek": 78200, "start": 804.0, "end": 806.0, "text": " So you can't do that.", "tokens": [407, 291, 393, 380, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.217464868645919, "compression_ratio": 1.5959183673469388, "no_speech_prob": 2.11110836971784e-05}, {"id": 155, "seek": 78200, "start": 806.0, "end": 810.0, "text": " With back-end tasks, you can't because it executes in a trusted, secure environment.", "tokens": [2022, 646, 12, 521, 9608, 11, 291, 393, 380, 570, 309, 4454, 1819, 294, 257, 16034, 11, 7144, 2823, 13], "temperature": 0.0, "avg_logprob": -0.217464868645919, "compression_ratio": 1.5959183673469388, "no_speech_prob": 2.11110836971784e-05}, {"id": 156, "seek": 81000, "start": 810.0, "end": 814.0, "text": " So that is the difference between a task and a back-end task.", "tokens": [407, 300, 307, 264, 2649, 1296, 257, 5633, 293, 257, 646, 12, 521, 5633, 13], "temperature": 0.0, "avg_logprob": -0.20565502460186297, "compression_ratio": 1.5422222222222222, "no_speech_prob": 2.1444220692501403e-05}, {"id": 157, "seek": 81000, "start": 814.0, "end": 820.0, "text": " And it has a whole suite of APIs designed for abstracting over that.", "tokens": [400, 309, 575, 257, 1379, 14205, 295, 21445, 4761, 337, 12649, 278, 670, 300, 13], "temperature": 0.0, "avg_logprob": -0.20565502460186297, "compression_ratio": 1.5422222222222222, "no_speech_prob": 2.1444220692501403e-05}, {"id": 158, "seek": 81000, "start": 820.0, "end": 825.0, "text": " For example, the glob API, back-end-task.glob, gives you a way to...", "tokens": [1171, 1365, 11, 264, 16125, 9362, 11, 646, 12, 521, 12, 83, 3863, 13, 70, 752, 65, 11, 2709, 291, 257, 636, 281, 485], "temperature": 0.0, "avg_logprob": -0.20565502460186297, "compression_ratio": 1.5422222222222222, "no_speech_prob": 2.1444220692501403e-05}, {"id": 159, "seek": 81000, "start": 825.0, "end": 828.0, "text": " I'm really pleased with the way you express this.", "tokens": [286, 478, 534, 10587, 365, 264, 636, 291, 5109, 341, 13], "temperature": 0.0, "avg_logprob": -0.20565502460186297, "compression_ratio": 1.5422222222222222, "no_speech_prob": 2.1444220692501403e-05}, {"id": 160, "seek": 81000, "start": 828.0, "end": 833.0, "text": " You sort of are able to parse out parts of the file path.", "tokens": [509, 1333, 295, 366, 1075, 281, 48377, 484, 3166, 295, 264, 3991, 3100, 13], "temperature": 0.0, "avg_logprob": -0.20565502460186297, "compression_ratio": 1.5422222222222222, "no_speech_prob": 2.1444220692501403e-05}, {"id": 161, "seek": 81000, "start": 833.0, "end": 837.0, "text": " So you can say things matching star.md.", "tokens": [407, 291, 393, 584, 721, 14324, 3543, 13, 76, 67, 13], "temperature": 0.0, "avg_logprob": -0.20565502460186297, "compression_ratio": 1.5422222222222222, "no_speech_prob": 2.1444220692501403e-05}, {"id": 162, "seek": 83700, "start": 837.0, "end": 841.0, "text": " But you don't do it as a string, so you can capture just that star part.", "tokens": [583, 291, 500, 380, 360, 309, 382, 257, 6798, 11, 370, 291, 393, 7983, 445, 300, 3543, 644, 13], "temperature": 0.0, "avg_logprob": -0.1689755354470354, "compression_ratio": 1.6863468634686347, "no_speech_prob": 4.495075245358748e-06}, {"id": 163, "seek": 83700, "start": 841.0, "end": 849.0, "text": " You can capture that into an Elm type, just like if you're writing up a JSON decoder using a similar pattern.", "tokens": [509, 393, 7983, 300, 666, 364, 2699, 76, 2010, 11, 445, 411, 498, 291, 434, 3579, 493, 257, 31828, 979, 19866, 1228, 257, 2531, 5102, 13], "temperature": 0.0, "avg_logprob": -0.1689755354470354, "compression_ratio": 1.6863468634686347, "no_speech_prob": 4.495075245358748e-06}, {"id": 164, "seek": 83700, "start": 849.0, "end": 852.0, "text": " So these APIs are built in a way where you're doing that.", "tokens": [407, 613, 21445, 366, 3094, 294, 257, 636, 689, 291, 434, 884, 300, 13], "temperature": 0.0, "avg_logprob": -0.1689755354470354, "compression_ratio": 1.6863468634686347, "no_speech_prob": 4.495075245358748e-06}, {"id": 165, "seek": 83700, "start": 852.0, "end": 857.0, "text": " So it's not just like a very light wrapper that lets you execute things in a back-end context,", "tokens": [407, 309, 311, 406, 445, 411, 257, 588, 1442, 46906, 300, 6653, 291, 14483, 721, 294, 257, 646, 12, 521, 4319, 11], "temperature": 0.0, "avg_logprob": -0.1689755354470354, "compression_ratio": 1.6863468634686347, "no_speech_prob": 4.495075245358748e-06}, {"id": 166, "seek": 83700, "start": 857.0, "end": 866.0, "text": " but it's like a really thought-out API for doing these types of tasks nicely in Elm and parsing them into nice Elm types.", "tokens": [457, 309, 311, 411, 257, 534, 1194, 12, 346, 9362, 337, 884, 613, 3467, 295, 9608, 9594, 294, 2699, 76, 293, 21156, 278, 552, 666, 1481, 2699, 76, 3467, 13], "temperature": 0.0, "avg_logprob": -0.1689755354470354, "compression_ratio": 1.6863468634686347, "no_speech_prob": 4.495075245358748e-06}, {"id": 167, "seek": 86600, "start": 866.0, "end": 870.0, "text": " So that's the heart of it. It's this back-end-task concept.", "tokens": [407, 300, 311, 264, 1917, 295, 309, 13, 467, 311, 341, 646, 12, 521, 12, 83, 3863, 3410, 13], "temperature": 0.0, "avg_logprob": -0.1919373893737793, "compression_ratio": 1.660633484162896, "no_speech_prob": 2.8409176593413576e-05}, {"id": 168, "seek": 86600, "start": 870.0, "end": 872.0, "text": " The back-end-task... yeah.", "tokens": [440, 646, 12, 521, 12, 83, 3863, 485, 1338, 13], "temperature": 0.0, "avg_logprob": -0.1919373893737793, "compression_ratio": 1.660633484162896, "no_speech_prob": 2.8409176593413576e-05}, {"id": 169, "seek": 86600, "start": 872.0, "end": 878.0, "text": " So just to finish that thought, it allows you to execute things in a back-end context.", "tokens": [407, 445, 281, 2413, 300, 1194, 11, 309, 4045, 291, 281, 14483, 721, 294, 257, 646, 12, 521, 4319, 13], "temperature": 0.0, "avg_logprob": -0.1919373893737793, "compression_ratio": 1.660633484162896, "no_speech_prob": 2.8409176593413576e-05}, {"id": 170, "seek": 86600, "start": 878.0, "end": 885.0, "text": " It's secure, so you can use secrets, you can read files, you can pull in environment variables.", "tokens": [467, 311, 7144, 11, 370, 291, 393, 764, 14093, 11, 291, 393, 1401, 7098, 11, 291, 393, 2235, 294, 2823, 9102, 13], "temperature": 0.0, "avg_logprob": -0.1919373893737793, "compression_ratio": 1.660633484162896, "no_speech_prob": 2.8409176593413576e-05}, {"id": 171, "seek": 86600, "start": 885.0, "end": 894.0, "text": " You can do expensive data processing and things like that before something ever reaches the page.", "tokens": [509, 393, 360, 5124, 1412, 9007, 293, 721, 411, 300, 949, 746, 1562, 14235, 264, 3028, 13], "temperature": 0.0, "avg_logprob": -0.1919373893737793, "compression_ratio": 1.660633484162896, "no_speech_prob": 2.8409176593413576e-05}, {"id": 172, "seek": 89400, "start": 894.0, "end": 902.0, "text": " Whether that's at build time, where you do a lot of expensive computation, reading in a bunch of files,", "tokens": [8503, 300, 311, 412, 1322, 565, 11, 689, 291, 360, 257, 688, 295, 5124, 24903, 11, 3760, 294, 257, 3840, 295, 7098, 11], "temperature": 0.0, "avg_logprob": -0.19410340926226446, "compression_ratio": 1.6382978723404256, "no_speech_prob": 7.25179779692553e-05}, {"id": 173, "seek": 89400, "start": 902.0, "end": 910.0, "text": " parsing that in some format, organizing that in some dictionary and sorting it and counting things", "tokens": [21156, 278, 300, 294, 512, 7877, 11, 17608, 300, 294, 512, 25890, 293, 32411, 309, 293, 13251, 721], "temperature": 0.0, "avg_logprob": -0.19410340926226446, "compression_ratio": 1.6382978723404256, "no_speech_prob": 7.25179779692553e-05}, {"id": 174, "seek": 89400, "start": 910.0, "end": 917.0, "text": " and counting the number of occurrences of the most frequent words or phrases or whatever expensive thing.", "tokens": [293, 13251, 264, 1230, 295, 5160, 38983, 295, 264, 881, 18004, 2283, 420, 20312, 420, 2035, 5124, 551, 13], "temperature": 0.0, "avg_logprob": -0.19410340926226446, "compression_ratio": 1.6382978723404256, "no_speech_prob": 7.25179779692553e-05}, {"id": 175, "seek": 91700, "start": 917.0, "end": 928.0, "text": " You can execute those things and then have the result of those and then that's just, if it's a static page,", "tokens": [509, 393, 14483, 729, 721, 293, 550, 362, 264, 1874, 295, 729, 293, 550, 300, 311, 445, 11, 498, 309, 311, 257, 13437, 3028, 11], "temperature": 0.0, "avg_logprob": -0.17950059613610944, "compression_ratio": 1.748878923766816, "no_speech_prob": 6.143856353446608e-06}, {"id": 176, "seek": 91700, "start": 928.0, "end": 931.0, "text": " that's just part of your static page that's pre-computed.", "tokens": [300, 311, 445, 644, 295, 428, 13437, 3028, 300, 311, 659, 12, 1112, 2582, 292, 13], "temperature": 0.0, "avg_logprob": -0.17950059613610944, "compression_ratio": 1.748878923766816, "no_speech_prob": 6.143856353446608e-06}, {"id": 177, "seek": 91700, "start": 931.0, "end": 936.0, "text": " Or if it's server-rendered, you don't have to pay that cost on the client.", "tokens": [1610, 498, 309, 311, 7154, 12, 4542, 4073, 11, 291, 500, 380, 362, 281, 1689, 300, 2063, 322, 264, 6423, 13], "temperature": 0.0, "avg_logprob": -0.17950059613610944, "compression_ratio": 1.748878923766816, "no_speech_prob": 6.143856353446608e-06}, {"id": 178, "seek": 91700, "start": 936.0, "end": 943.0, "text": " And you don't even need to pull in the code in your bundle for things that only run on the back-end.", "tokens": [400, 291, 500, 380, 754, 643, 281, 2235, 294, 264, 3089, 294, 428, 24438, 337, 721, 300, 787, 1190, 322, 264, 646, 12, 521, 13], "temperature": 0.0, "avg_logprob": -0.17950059613610944, "compression_ratio": 1.748878923766816, "no_speech_prob": 6.143856353446608e-06}, {"id": 179, "seek": 91700, "start": 943.0, "end": 946.0, "text": " So at the heart of Elm Pages is a back-end-task.", "tokens": [407, 412, 264, 1917, 295, 2699, 76, 430, 1660, 307, 257, 646, 12, 521, 12, 83, 3863, 13], "temperature": 0.0, "avg_logprob": -0.17950059613610944, "compression_ratio": 1.748878923766816, "no_speech_prob": 6.143856353446608e-06}, {"id": 180, "seek": 94600, "start": 946.0, "end": 952.0, "text": " Elm Pages is a framework that's centered around different ways to use a back-end task.", "tokens": [2699, 76, 430, 1660, 307, 257, 8388, 300, 311, 18988, 926, 819, 2098, 281, 764, 257, 646, 12, 521, 5633, 13], "temperature": 0.0, "avg_logprob": -0.1928798340179108, "compression_ratio": 1.669767441860465, "no_speech_prob": 1.8342387193115428e-05}, {"id": 181, "seek": 94600, "start": 952.0, "end": 961.0, "text": " A static route, pre-rendered routes, can use a back-end task to have the back-end task available before the view is rendered.", "tokens": [316, 13437, 7955, 11, 659, 12, 4542, 4073, 18242, 11, 393, 764, 257, 646, 12, 521, 5633, 281, 362, 264, 646, 12, 521, 5633, 2435, 949, 264, 1910, 307, 28748, 13], "temperature": 0.0, "avg_logprob": -0.1928798340179108, "compression_ratio": 1.669767441860465, "no_speech_prob": 1.8342387193115428e-05}, {"id": 182, "seek": 94600, "start": 961.0, "end": 967.0, "text": " You can render the head tags for SEO purposes that give you things like the nice social media previews", "tokens": [509, 393, 15529, 264, 1378, 18632, 337, 22964, 9932, 300, 976, 291, 721, 411, 264, 1481, 2093, 3021, 14281, 82], "temperature": 0.0, "avg_logprob": -0.1928798340179108, "compression_ratio": 1.669767441860465, "no_speech_prob": 1.8342387193115428e-05}, {"id": 183, "seek": 94600, "start": 967.0, "end": 970.0, "text": " for Twitter and Slack and things like that.", "tokens": [337, 5794, 293, 37211, 293, 721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.1928798340179108, "compression_ratio": 1.669767441860465, "no_speech_prob": 1.8342387193115428e-05}, {"id": 184, "seek": 97000, "start": 970.0, "end": 978.0, "text": " That is there in the rendered HTML, which a lot of these tools for social previews don't execute JavaScript.", "tokens": [663, 307, 456, 294, 264, 28748, 17995, 11, 597, 257, 688, 295, 613, 3873, 337, 2093, 14281, 82, 500, 380, 14483, 15778, 13], "temperature": 0.0, "avg_logprob": -0.16911094209067842, "compression_ratio": 1.7049808429118773, "no_speech_prob": 7.646443918929435e-06}, {"id": 185, "seek": 97000, "start": 978.0, "end": 982.0, "text": " So you need pre-rendered HTML in order to display those.", "tokens": [407, 291, 643, 659, 12, 4542, 4073, 17995, 294, 1668, 281, 4674, 729, 13], "temperature": 0.0, "avg_logprob": -0.16911094209067842, "compression_ratio": 1.7049808429118773, "no_speech_prob": 7.646443918929435e-06}, {"id": 186, "seek": 97000, "start": 982.0, "end": 984.0, "text": " So Elm Pages provides that, right?", "tokens": [407, 2699, 76, 430, 1660, 6417, 300, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.16911094209067842, "compression_ratio": 1.7049808429118773, "no_speech_prob": 7.646443918929435e-06}, {"id": 187, "seek": 97000, "start": 984.0, "end": 991.0, "text": " But how does it provide that if you don't have access to your initial page data before you do that?", "tokens": [583, 577, 775, 309, 2893, 300, 498, 291, 500, 380, 362, 2105, 281, 428, 5883, 3028, 1412, 949, 291, 360, 300, 30], "temperature": 0.0, "avg_logprob": -0.16911094209067842, "compression_ratio": 1.7049808429118773, "no_speech_prob": 7.646443918929435e-06}, {"id": 188, "seek": 97000, "start": 991.0, "end": 994.0, "text": " So back-end task is kind of a core thing around that.", "tokens": [407, 646, 12, 521, 5633, 307, 733, 295, 257, 4965, 551, 926, 300, 13], "temperature": 0.0, "avg_logprob": -0.16911094209067842, "compression_ratio": 1.7049808429118773, "no_speech_prob": 7.646443918929435e-06}, {"id": 189, "seek": 97000, "start": 994.0, "end": 999.0, "text": " Back-end task is a core thing around server-rendered routes because you resolve this data,", "tokens": [5833, 12, 521, 5633, 307, 257, 4965, 551, 926, 7154, 12, 4542, 4073, 18242, 570, 291, 14151, 341, 1412, 11], "temperature": 0.0, "avg_logprob": -0.16911094209067842, "compression_ratio": 1.7049808429118773, "no_speech_prob": 7.646443918929435e-06}, {"id": 190, "seek": 99900, "start": 999.0, "end": 1002.0, "text": " and you can run it in a secure environment in a back-end task.", "tokens": [293, 291, 393, 1190, 309, 294, 257, 7144, 2823, 294, 257, 646, 12, 521, 5633, 13], "temperature": 0.0, "avg_logprob": -0.18839729985883158, "compression_ratio": 1.9457013574660633, "no_speech_prob": 8.887585863703862e-05}, {"id": 191, "seek": 99900, "start": 1002.0, "end": 1009.0, "text": " If you want to respond to a user clicking a Pay Now button by running something in Stripe,", "tokens": [759, 291, 528, 281, 4196, 281, 257, 4195, 9697, 257, 11431, 823, 2960, 538, 2614, 746, 294, 20390, 494, 11], "temperature": 0.0, "avg_logprob": -0.18839729985883158, "compression_ratio": 1.9457013574660633, "no_speech_prob": 8.887585863703862e-05}, {"id": 192, "seek": 99900, "start": 1009.0, "end": 1013.0, "text": " or if you want to respond to a Stripe webhook or whatever you want to do,", "tokens": [420, 498, 291, 528, 281, 4196, 281, 257, 20390, 494, 3670, 71, 1212, 420, 2035, 291, 528, 281, 360, 11], "temperature": 0.0, "avg_logprob": -0.18839729985883158, "compression_ratio": 1.9457013574660633, "no_speech_prob": 8.887585863703862e-05}, {"id": 193, "seek": 99900, "start": 1013.0, "end": 1016.0, "text": " back-end task is the core of how that is done.", "tokens": [646, 12, 521, 5633, 307, 264, 4965, 295, 577, 300, 307, 1096, 13], "temperature": 0.0, "avg_logprob": -0.18839729985883158, "compression_ratio": 1.9457013574660633, "no_speech_prob": 8.887585863703862e-05}, {"id": 194, "seek": 99900, "start": 1016.0, "end": 1019.0, "text": " And back-end task is the core of how an Elm Pages script is done.", "tokens": [400, 646, 12, 521, 5633, 307, 264, 4965, 295, 577, 364, 2699, 76, 430, 1660, 5755, 307, 1096, 13], "temperature": 0.0, "avg_logprob": -0.18839729985883158, "compression_ratio": 1.9457013574660633, "no_speech_prob": 8.887585863703862e-05}, {"id": 195, "seek": 99900, "start": 1019.0, "end": 1026.0, "text": " An Elm Pages script is just a little helper that lets you easily execute a back-end task.", "tokens": [1107, 2699, 76, 430, 1660, 5755, 307, 445, 257, 707, 36133, 300, 6653, 291, 3612, 14483, 257, 646, 12, 521, 5633, 13], "temperature": 0.0, "avg_logprob": -0.18839729985883158, "compression_ratio": 1.9457013574660633, "no_speech_prob": 8.887585863703862e-05}, {"id": 196, "seek": 102600, "start": 1026.0, "end": 1031.0, "text": " It also lets you parse command line flags that you can use in that context of your back-end task.", "tokens": [467, 611, 6653, 291, 48377, 5622, 1622, 23265, 300, 291, 393, 764, 294, 300, 4319, 295, 428, 646, 12, 521, 5633, 13], "temperature": 0.0, "avg_logprob": -0.18570224131186178, "compression_ratio": 1.8489795918367347, "no_speech_prob": 2.247354314022232e-05}, {"id": 197, "seek": 102600, "start": 1031.0, "end": 1035.0, "text": " But again, it's all just centered around this concept of a back-end task.", "tokens": [583, 797, 11, 309, 311, 439, 445, 18988, 926, 341, 3410, 295, 257, 646, 12, 521, 5633, 13], "temperature": 0.0, "avg_logprob": -0.18570224131186178, "compression_ratio": 1.8489795918367347, "no_speech_prob": 2.247354314022232e-05}, {"id": 198, "seek": 102600, "start": 1035.0, "end": 1039.0, "text": " Yeah, that makes a lot of sense. I haven't seen it that way.", "tokens": [865, 11, 300, 1669, 257, 688, 295, 2020, 13, 286, 2378, 380, 1612, 309, 300, 636, 13], "temperature": 0.0, "avg_logprob": -0.18570224131186178, "compression_ratio": 1.8489795918367347, "no_speech_prob": 2.247354314022232e-05}, {"id": 199, "seek": 102600, "start": 1039.0, "end": 1044.0, "text": " But it does make things a lot more... but it does make a lot of sense.", "tokens": [583, 309, 775, 652, 721, 257, 688, 544, 485, 457, 309, 775, 652, 257, 688, 295, 2020, 13], "temperature": 0.0, "avg_logprob": -0.18570224131186178, "compression_ratio": 1.8489795918367347, "no_speech_prob": 2.247354314022232e-05}, {"id": 200, "seek": 102600, "start": 1044.0, "end": 1047.0, "text": " Yeah, it's more coherent when you think about it that way, right?", "tokens": [865, 11, 309, 311, 544, 36239, 562, 291, 519, 466, 309, 300, 636, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18570224131186178, "compression_ratio": 1.8489795918367347, "no_speech_prob": 2.247354314022232e-05}, {"id": 201, "seek": 102600, "start": 1047.0, "end": 1048.0, "text": " Yeah, exactly.", "tokens": [865, 11, 2293, 13], "temperature": 0.0, "avg_logprob": -0.18570224131186178, "compression_ratio": 1.8489795918367347, "no_speech_prob": 2.247354314022232e-05}, {"id": 202, "seek": 102600, "start": 1048.0, "end": 1053.0, "text": " So basically what you did is you made this concept of back-end task,", "tokens": [407, 1936, 437, 291, 630, 307, 291, 1027, 341, 3410, 295, 646, 12, 521, 5633, 11], "temperature": 0.0, "avg_logprob": -0.18570224131186178, "compression_ratio": 1.8489795918367347, "no_speech_prob": 2.247354314022232e-05}, {"id": 203, "seek": 105300, "start": 1053.0, "end": 1059.0, "text": " and you added a lot of primitives to get the contents of a file,", "tokens": [293, 291, 3869, 257, 688, 295, 2886, 38970, 281, 483, 264, 15768, 295, 257, 3991, 11], "temperature": 0.0, "avg_logprob": -0.1878609035326087, "compression_ratio": 1.455813953488372, "no_speech_prob": 1.4963782632548828e-05}, {"id": 204, "seek": 105300, "start": 1059.0, "end": 1066.0, "text": " to make HTTP requests ahead of time, ahead of render time, let's say,", "tokens": [281, 652, 33283, 12475, 2286, 295, 565, 11, 2286, 295, 15529, 565, 11, 718, 311, 584, 11], "temperature": 0.0, "avg_logprob": -0.1878609035326087, "compression_ratio": 1.455813953488372, "no_speech_prob": 1.4963782632548828e-05}, {"id": 205, "seek": 105300, "start": 1066.0, "end": 1070.0, "text": " or JavaScript execution time on the client.", "tokens": [420, 15778, 15058, 565, 322, 264, 6423, 13], "temperature": 0.0, "avg_logprob": -0.1878609035326087, "compression_ratio": 1.455813953488372, "no_speech_prob": 1.4963782632548828e-05}, {"id": 206, "seek": 105300, "start": 1070.0, "end": 1076.0, "text": " And then you asked yourself in a way, where should this apply?", "tokens": [400, 550, 291, 2351, 1803, 294, 257, 636, 11, 689, 820, 341, 3079, 30], "temperature": 0.0, "avg_logprob": -0.1878609035326087, "compression_ratio": 1.455813953488372, "no_speech_prob": 1.4963782632548828e-05}, {"id": 207, "seek": 105300, "start": 1076.0, "end": 1082.0, "text": " And for Elm Pages v1 and v2, that was, well, this is for the front-end.", "tokens": [400, 337, 2699, 76, 430, 1660, 371, 16, 293, 371, 17, 11, 300, 390, 11, 731, 11, 341, 307, 337, 264, 1868, 12, 521, 13], "temperature": 0.0, "avg_logprob": -0.1878609035326087, "compression_ratio": 1.455813953488372, "no_speech_prob": 1.4963782632548828e-05}, {"id": 208, "seek": 108200, "start": 1082.0, "end": 1085.0, "text": " Like, we're executing something at build time,", "tokens": [1743, 11, 321, 434, 32368, 746, 412, 1322, 565, 11], "temperature": 0.0, "avg_logprob": -0.17813139846644452, "compression_ratio": 1.5666666666666667, "no_speech_prob": 3.705071867443621e-05}, {"id": 209, "seek": 108200, "start": 1085.0, "end": 1091.0, "text": " and then you have some data that is sent to the front-end as plain HTML,", "tokens": [293, 550, 291, 362, 512, 1412, 300, 307, 2279, 281, 264, 1868, 12, 521, 382, 11121, 17995, 11], "temperature": 0.0, "avg_logprob": -0.17813139846644452, "compression_ratio": 1.5666666666666667, "no_speech_prob": 3.705071867443621e-05}, {"id": 210, "seek": 108200, "start": 1091.0, "end": 1096.0, "text": " and then there's some hydration or re-execution of the Elm code.", "tokens": [293, 550, 456, 311, 512, 43631, 420, 319, 12, 3121, 3045, 1448, 295, 264, 2699, 76, 3089, 13], "temperature": 0.0, "avg_logprob": -0.17813139846644452, "compression_ratio": 1.5666666666666667, "no_speech_prob": 3.705071867443621e-05}, {"id": 211, "seek": 108200, "start": 1096.0, "end": 1101.0, "text": " And now with Elm Pages, you've made this apply for more things.", "tokens": [400, 586, 365, 2699, 76, 430, 1660, 11, 291, 600, 1027, 341, 3079, 337, 544, 721, 13], "temperature": 0.0, "avg_logprob": -0.17813139846644452, "compression_ratio": 1.5666666666666667, "no_speech_prob": 3.705071867443621e-05}, {"id": 212, "seek": 108200, "start": 1101.0, "end": 1106.0, "text": " So you have Elm Pages scripts, so it's like, well, we have all these nice things", "tokens": [407, 291, 362, 2699, 76, 430, 1660, 23294, 11, 370, 309, 311, 411, 11, 731, 11, 321, 362, 439, 613, 1481, 721], "temperature": 0.0, "avg_logprob": -0.17813139846644452, "compression_ratio": 1.5666666666666667, "no_speech_prob": 3.705071867443621e-05}, {"id": 213, "seek": 110600, "start": 1106.0, "end": 1112.0, "text": " that are to get the contents of files, to write to files, to do things like that.", "tokens": [300, 366, 281, 483, 264, 15768, 295, 7098, 11, 281, 2464, 281, 7098, 11, 281, 360, 721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.1904984193689683, "compression_ratio": 1.6612021857923498, "no_speech_prob": 2.9310367608559318e-05}, {"id": 214, "seek": 110600, "start": 1112.0, "end": 1117.0, "text": " Would be nice to just be able to run them to see, like, what is,", "tokens": [6068, 312, 1481, 281, 445, 312, 1075, 281, 1190, 552, 281, 536, 11, 411, 11, 437, 307, 11], "temperature": 0.0, "avg_logprob": -0.1904984193689683, "compression_ratio": 1.6612021857923498, "no_speech_prob": 2.9310367608559318e-05}, {"id": 215, "seek": 110600, "start": 1117.0, "end": 1122.0, "text": " if I run this code, do I get what I expect", "tokens": [498, 286, 1190, 341, 3089, 11, 360, 286, 483, 437, 286, 2066], "temperature": 0.0, "avg_logprob": -0.1904984193689683, "compression_ratio": 1.6612021857923498, "no_speech_prob": 2.9310367608559318e-05}, {"id": 216, "seek": 110600, "start": 1122.0, "end": 1127.0, "text": " without having to run this whole server-side rendering machine?", "tokens": [1553, 1419, 281, 1190, 341, 1379, 7154, 12, 1812, 22407, 3479, 30], "temperature": 0.0, "avg_logprob": -0.1904984193689683, "compression_ratio": 1.6612021857923498, "no_speech_prob": 2.9310367608559318e-05}, {"id": 217, "seek": 110600, "start": 1127.0, "end": 1130.0, "text": " And then you also have this server-side rendering,", "tokens": [400, 550, 291, 611, 362, 341, 7154, 12, 1812, 22407, 11], "temperature": 0.0, "avg_logprob": -0.1904984193689683, "compression_ratio": 1.6612021857923498, "no_speech_prob": 2.9310367608559318e-05}, {"id": 218, "seek": 113000, "start": 1130.0, "end": 1136.0, "text": " because that's something that apparently the web community expects or wants", "tokens": [570, 300, 311, 746, 300, 7970, 264, 3670, 1768, 33280, 420, 2738], "temperature": 0.0, "avg_logprob": -0.17168383878820082, "compression_ratio": 1.5544554455445545, "no_speech_prob": 5.141802103025839e-05}, {"id": 219, "seek": 113000, "start": 1136.0, "end": 1143.0, "text": " and has a lot of value, which let's talk about that in a bit.", "tokens": [293, 575, 257, 688, 295, 2158, 11, 597, 718, 311, 751, 466, 300, 294, 257, 857, 13], "temperature": 0.0, "avg_logprob": -0.17168383878820082, "compression_ratio": 1.5544554455445545, "no_speech_prob": 5.141802103025839e-05}, {"id": 220, "seek": 113000, "start": 1143.0, "end": 1146.0, "text": " But yeah, this makes a lot of sense.", "tokens": [583, 1338, 11, 341, 1669, 257, 688, 295, 2020, 13], "temperature": 0.0, "avg_logprob": -0.17168383878820082, "compression_ratio": 1.5544554455445545, "no_speech_prob": 5.141802103025839e-05}, {"id": 221, "seek": 113000, "start": 1146.0, "end": 1152.0, "text": " And I'm kind of wondering, like, if you knew that this was the core part", "tokens": [400, 286, 478, 733, 295, 6359, 11, 411, 11, 498, 291, 2586, 300, 341, 390, 264, 4965, 644], "temperature": 0.0, "avg_logprob": -0.17168383878820082, "compression_ratio": 1.5544554455445545, "no_speech_prob": 5.141802103025839e-05}, {"id": 222, "seek": 113000, "start": 1152.0, "end": 1157.0, "text": " of the package or the tool, because it's more than just a package,", "tokens": [295, 264, 7372, 420, 264, 2290, 11, 570, 309, 311, 544, 813, 445, 257, 7372, 11], "temperature": 0.0, "avg_logprob": -0.17168383878820082, "compression_ratio": 1.5544554455445545, "no_speech_prob": 5.141802103025839e-05}, {"id": 223, "seek": 115700, "start": 1157.0, "end": 1160.0, "text": " would you have called it differently?", "tokens": [576, 291, 362, 1219, 309, 7614, 30], "temperature": 0.0, "avg_logprob": -0.19360604245438534, "compression_ratio": 1.6626016260162602, "no_speech_prob": 1.8341641407459974e-05}, {"id": 224, "seek": 115700, "start": 1160.0, "end": 1165.0, "text": " Because it's Elm Pages, but the Elm Pages scripts has nothing to do with Pages,", "tokens": [1436, 309, 311, 2699, 76, 430, 1660, 11, 457, 264, 2699, 76, 430, 1660, 23294, 575, 1825, 281, 360, 365, 430, 1660, 11], "temperature": 0.0, "avg_logprob": -0.19360604245438534, "compression_ratio": 1.6626016260162602, "no_speech_prob": 1.8341641407459974e-05}, {"id": 225, "seek": 115700, "start": 1165.0, "end": 1167.0, "text": " and it doesn't have to be anymore.", "tokens": [293, 309, 1177, 380, 362, 281, 312, 3602, 13], "temperature": 0.0, "avg_logprob": -0.19360604245438534, "compression_ratio": 1.6626016260162602, "no_speech_prob": 1.8341641407459974e-05}, {"id": 226, "seek": 115700, "start": 1167.0, "end": 1172.0, "text": " I'm guessing if you had renamed it to something else when it was still in V2,", "tokens": [286, 478, 17939, 498, 291, 632, 40949, 309, 281, 746, 1646, 562, 309, 390, 920, 294, 691, 17, 11], "temperature": 0.0, "avg_logprob": -0.19360604245438534, "compression_ratio": 1.6626016260162602, "no_speech_prob": 1.8341641407459974e-05}, {"id": 227, "seek": 115700, "start": 1172.0, "end": 1175.0, "text": " you would have called it Elm Data Source,", "tokens": [291, 576, 362, 1219, 309, 2699, 76, 11888, 29629, 11], "temperature": 0.0, "avg_logprob": -0.19360604245438534, "compression_ratio": 1.6626016260162602, "no_speech_prob": 1.8341641407459974e-05}, {"id": 228, "seek": 115700, "start": 1175.0, "end": 1178.0, "text": " which you would be unhappy with today, I'm guessing.", "tokens": [597, 291, 576, 312, 22172, 365, 965, 11, 286, 478, 17939, 13], "temperature": 0.0, "avg_logprob": -0.19360604245438534, "compression_ratio": 1.6626016260162602, "no_speech_prob": 1.8341641407459974e-05}, {"id": 229, "seek": 115700, "start": 1178.0, "end": 1185.0, "text": " Yeah, and I'm not sure Elm Backend Task really captures what you do with it either.", "tokens": [865, 11, 293, 286, 478, 406, 988, 2699, 76, 5833, 521, 30428, 534, 27986, 437, 291, 360, 365, 309, 2139, 13], "temperature": 0.0, "avg_logprob": -0.19360604245438534, "compression_ratio": 1.6626016260162602, "no_speech_prob": 1.8341641407459974e-05}, {"id": 230, "seek": 118500, "start": 1185.0, "end": 1188.0, "text": " But I don't know, maybe like...", "tokens": [583, 286, 500, 380, 458, 11, 1310, 411, 485], "temperature": 0.0, "avg_logprob": -0.19954347610473633, "compression_ratio": 1.7209302325581395, "no_speech_prob": 4.1977185901487246e-05}, {"id": 231, "seek": 118500, "start": 1188.0, "end": 1192.0, "text": " Yeah, maybe as an underlying package of Elm Pages.", "tokens": [865, 11, 1310, 382, 364, 14217, 7372, 295, 2699, 76, 430, 1660, 13], "temperature": 0.0, "avg_logprob": -0.19954347610473633, "compression_ratio": 1.7209302325581395, "no_speech_prob": 4.1977185901487246e-05}, {"id": 232, "seek": 118500, "start": 1192.0, "end": 1194.0, "text": " Maybe like Elm Backend, I don't know.", "tokens": [2704, 411, 2699, 76, 5833, 521, 11, 286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.19954347610473633, "compression_ratio": 1.7209302325581395, "no_speech_prob": 4.1977185901487246e-05}, {"id": 233, "seek": 118500, "start": 1194.0, "end": 1199.0, "text": " But then it's like, well, Elm Backend, it's like, well, can you do things with a front end?", "tokens": [583, 550, 309, 311, 411, 11, 731, 11, 2699, 76, 5833, 521, 11, 309, 311, 411, 11, 731, 11, 393, 291, 360, 721, 365, 257, 1868, 917, 30], "temperature": 0.0, "avg_logprob": -0.19954347610473633, "compression_ratio": 1.7209302325581395, "no_speech_prob": 4.1977185901487246e-05}, {"id": 234, "seek": 118500, "start": 1199.0, "end": 1204.0, "text": " It's like, yeah, it's about interopting between a front end and a back end.", "tokens": [467, 311, 411, 11, 1338, 11, 309, 311, 466, 728, 404, 783, 1296, 257, 1868, 917, 293, 257, 646, 917, 13], "temperature": 0.0, "avg_logprob": -0.19954347610473633, "compression_ratio": 1.7209302325581395, "no_speech_prob": 4.1977185901487246e-05}, {"id": 235, "seek": 118500, "start": 1204.0, "end": 1206.0, "text": " So yeah, it's hard to name.", "tokens": [407, 1338, 11, 309, 311, 1152, 281, 1315, 13], "temperature": 0.0, "avg_logprob": -0.19954347610473633, "compression_ratio": 1.7209302325581395, "no_speech_prob": 4.1977185901487246e-05}, {"id": 236, "seek": 118500, "start": 1206.0, "end": 1212.0, "text": " If anybody has a genius name, definitely let me know.", "tokens": [759, 4472, 575, 257, 14017, 1315, 11, 2138, 718, 385, 458, 13], "temperature": 0.0, "avg_logprob": -0.19954347610473633, "compression_ratio": 1.7209302325581395, "no_speech_prob": 4.1977185901487246e-05}, {"id": 237, "seek": 121200, "start": 1212.0, "end": 1216.0, "text": " But also, I think I mentioned this in the scripts episode we did,", "tokens": [583, 611, 11, 286, 519, 286, 2835, 341, 294, 264, 23294, 3500, 321, 630, 11], "temperature": 0.0, "avg_logprob": -0.19886755692331415, "compression_ratio": 1.7268518518518519, "no_speech_prob": 5.8625987549021374e-06}, {"id": 238, "seek": 121200, "start": 1216.0, "end": 1225.0, "text": " but the origin of Elm Pages scripts was that I was actually wanting to build more customizable scaffolding.", "tokens": [457, 264, 4957, 295, 2699, 76, 430, 1660, 23294, 390, 300, 286, 390, 767, 7935, 281, 1322, 544, 47922, 44094, 278, 13], "temperature": 0.0, "avg_logprob": -0.19886755692331415, "compression_ratio": 1.7268518518518519, "no_speech_prob": 5.8625987549021374e-06}, {"id": 239, "seek": 121200, "start": 1225.0, "end": 1233.0, "text": " Elm Pages V2 had an add route command, or Elm Pages add command that let you add new routes", "tokens": [2699, 76, 430, 1660, 691, 17, 632, 364, 909, 7955, 5622, 11, 420, 2699, 76, 430, 1660, 909, 5622, 300, 718, 291, 909, 777, 18242], "temperature": 0.0, "avg_logprob": -0.19886755692331415, "compression_ratio": 1.7268518518518519, "no_speech_prob": 5.8625987549021374e-06}, {"id": 240, "seek": 121200, "start": 1233.0, "end": 1236.0, "text": " that would scaffold out the starting template for a new route.", "tokens": [300, 576, 44094, 484, 264, 2891, 12379, 337, 257, 777, 7955, 13], "temperature": 0.0, "avg_logprob": -0.19886755692331415, "compression_ratio": 1.7268518518518519, "no_speech_prob": 5.8625987549021374e-06}, {"id": 241, "seek": 121200, "start": 1236.0, "end": 1239.0, "text": " And I wanted to make that more customizable.", "tokens": [400, 286, 1415, 281, 652, 300, 544, 47922, 13], "temperature": 0.0, "avg_logprob": -0.19886755692331415, "compression_ratio": 1.7268518518518519, "no_speech_prob": 5.8625987549021374e-06}, {"id": 242, "seek": 123900, "start": 1239.0, "end": 1247.0, "text": " If you want to use Elm UI or Elm CSS, Elm Tailwind modules,", "tokens": [759, 291, 528, 281, 764, 2699, 76, 15682, 420, 2699, 76, 24387, 11, 2699, 76, 46074, 12199, 16679, 11], "temperature": 0.0, "avg_logprob": -0.19748713753440164, "compression_ratio": 1.5808080808080809, "no_speech_prob": 3.0894093470124062e-06}, {"id": 243, "seek": 123900, "start": 1247.0, "end": 1255.0, "text": " if you have a specific pattern that you use in all of your routes that you want to bake into it,", "tokens": [498, 291, 362, 257, 2685, 5102, 300, 291, 764, 294, 439, 295, 428, 18242, 300, 291, 528, 281, 16562, 666, 309, 11], "temperature": 0.0, "avg_logprob": -0.19748713753440164, "compression_ratio": 1.5808080808080809, "no_speech_prob": 3.0894093470124062e-06}, {"id": 244, "seek": 123900, "start": 1255.0, "end": 1256.0, "text": " whatever that might be.", "tokens": [2035, 300, 1062, 312, 13], "temperature": 0.0, "avg_logprob": -0.19748713753440164, "compression_ratio": 1.5808080808080809, "no_speech_prob": 3.0894093470124062e-06}, {"id": 245, "seek": 123900, "start": 1256.0, "end": 1264.0, "text": " So when you say scaffolding, you mean like the tool creates a blank file or a few blank files", "tokens": [407, 562, 291, 584, 44094, 278, 11, 291, 914, 411, 264, 2290, 7829, 257, 8247, 3991, 420, 257, 1326, 8247, 7098], "temperature": 0.0, "avg_logprob": -0.19748713753440164, "compression_ratio": 1.5808080808080809, "no_speech_prob": 3.0894093470124062e-06}, {"id": 246, "seek": 123900, "start": 1264.0, "end": 1268.0, "text": " with some predetermined data in there.", "tokens": [365, 512, 3852, 35344, 2001, 1412, 294, 456, 13], "temperature": 0.0, "avg_logprob": -0.19748713753440164, "compression_ratio": 1.5808080808080809, "no_speech_prob": 3.0894093470124062e-06}, {"id": 247, "seek": 126800, "start": 1268.0, "end": 1272.0, "text": " Like maybe if you say, I'm just imagining something,", "tokens": [1743, 1310, 498, 291, 584, 11, 286, 478, 445, 27798, 746, 11], "temperature": 0.0, "avg_logprob": -0.28992368819865777, "compression_ratio": 1.6187845303867403, "no_speech_prob": 8.664174856676254e-06}, {"id": 248, "seek": 126800, "start": 1272.0, "end": 1280.0, "text": " like if I do Elm Pages add slash users slash ID, or however that's,", "tokens": [411, 498, 286, 360, 2699, 76, 430, 1660, 909, 17330, 5022, 17330, 7348, 11, 420, 4461, 300, 311, 11], "temperature": 0.0, "avg_logprob": -0.28992368819865777, "compression_ratio": 1.6187845303867403, "no_speech_prob": 8.664174856676254e-06}, {"id": 249, "seek": 126800, "start": 1280.0, "end": 1282.0, "text": " is users dot ID or something?", "tokens": [307, 5022, 5893, 7348, 420, 746, 30], "temperature": 0.0, "avg_logprob": -0.28992368819865777, "compression_ratio": 1.6187845303867403, "no_speech_prob": 8.664174856676254e-06}, {"id": 250, "seek": 126800, "start": 1282.0, "end": 1285.0, "text": " Yeah, you do it like an Elm module name.", "tokens": [865, 11, 291, 360, 309, 411, 364, 2699, 76, 10088, 1315, 13], "temperature": 0.0, "avg_logprob": -0.28992368819865777, "compression_ratio": 1.6187845303867403, "no_speech_prob": 8.664174856676254e-06}, {"id": 251, "seek": 126800, "start": 1285.0, "end": 1290.0, "text": " Okay, so if I do Elm Pages add users dot...", "tokens": [1033, 11, 370, 498, 286, 360, 2699, 76, 430, 1660, 909, 5022, 5893, 485], "temperature": 0.0, "avg_logprob": -0.28992368819865777, "compression_ratio": 1.6187845303867403, "no_speech_prob": 8.664174856676254e-06}, {"id": 252, "seek": 126800, "start": 1290.0, "end": 1294.0, "text": " ID underscore is a dynamic one.", "tokens": [7348, 37556, 307, 257, 8546, 472, 13], "temperature": 0.0, "avg_logprob": -0.28992368819865777, "compression_ratio": 1.6187845303867403, "no_speech_prob": 8.664174856676254e-06}, {"id": 253, "seek": 126800, "start": 1294.0, "end": 1297.0, "text": " So ID is a dynamic thing.", "tokens": [407, 7348, 307, 257, 8546, 551, 13], "temperature": 0.0, "avg_logprob": -0.28992368819865777, "compression_ratio": 1.6187845303867403, "no_speech_prob": 8.664174856676254e-06}, {"id": 254, "seek": 129700, "start": 1297.0, "end": 1302.0, "text": " Then I would get a Elm module at the right position.", "tokens": [1396, 286, 576, 483, 257, 2699, 76, 10088, 412, 264, 558, 2535, 13], "temperature": 0.0, "avg_logprob": -0.2450709342956543, "compression_ratio": 1.5707762557077625, "no_speech_prob": 5.594260983343702e-06}, {"id": 255, "seek": 129700, "start": 1302.0, "end": 1310.0, "text": " And it would contain like, oh, a command saying this renders at slash users slash colon ID,", "tokens": [400, 309, 576, 5304, 411, 11, 1954, 11, 257, 5622, 1566, 341, 6125, 433, 412, 17330, 5022, 17330, 8255, 7348, 11], "temperature": 0.0, "avg_logprob": -0.2450709342956543, "compression_ratio": 1.5707762557077625, "no_speech_prob": 5.594260983343702e-06}, {"id": 256, "seek": 129700, "start": 1310.0, "end": 1311.0, "text": " something like that.", "tokens": [746, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.2450709342956543, "compression_ratio": 1.5707762557077625, "no_speech_prob": 5.594260983343702e-06}, {"id": 257, "seek": 129700, "start": 1311.0, "end": 1314.0, "text": " And it actually would because it uses file-based routing.", "tokens": [400, 309, 767, 576, 570, 309, 4960, 3991, 12, 6032, 32722, 13], "temperature": 0.0, "avg_logprob": -0.2450709342956543, "compression_ratio": 1.5707762557077625, "no_speech_prob": 5.594260983343702e-06}, {"id": 258, "seek": 129700, "start": 1314.0, "end": 1319.0, "text": " So it would create a file in the appropriate place for that route module.", "tokens": [407, 309, 576, 1884, 257, 3991, 294, 264, 6854, 1081, 337, 300, 7955, 10088, 13], "temperature": 0.0, "avg_logprob": -0.2450709342956543, "compression_ratio": 1.5707762557077625, "no_speech_prob": 5.594260983343702e-06}, {"id": 259, "seek": 129700, "start": 1319.0, "end": 1320.0, "text": " And then...", "tokens": [400, 550, 485], "temperature": 0.0, "avg_logprob": -0.2450709342956543, "compression_ratio": 1.5707762557077625, "no_speech_prob": 5.594260983343702e-06}, {"id": 260, "seek": 129700, "start": 1320.0, "end": 1322.0, "text": " I'm guessing an init view updates.", "tokens": [286, 478, 17939, 364, 3157, 1910, 9205, 13], "temperature": 0.0, "avg_logprob": -0.2450709342956543, "compression_ratio": 1.5707762557077625, "no_speech_prob": 5.594260983343702e-06}, {"id": 261, "seek": 132200, "start": 1322.0, "end": 1332.0, "text": " Right, and the view would be view dot placeholder because your view might be Elm CSS or Elm HTML or Elm UI.", "tokens": [1779, 11, 293, 264, 1910, 576, 312, 1910, 5893, 1081, 20480, 570, 428, 1910, 1062, 312, 2699, 76, 24387, 420, 2699, 76, 17995, 420, 2699, 76, 15682, 13], "temperature": 0.0, "avg_logprob": -0.21148932123758707, "compression_ratio": 1.6363636363636365, "no_speech_prob": 2.2125514078652486e-05}, {"id": 262, "seek": 132200, "start": 1332.0, "end": 1341.0, "text": " So having a user-maintained module called view dot Elm with a type alias view being whatever type their view is,", "tokens": [407, 1419, 257, 4195, 12, 76, 5114, 3563, 10088, 1219, 1910, 5893, 2699, 76, 365, 257, 2010, 419, 4609, 1910, 885, 2035, 2010, 641, 1910, 307, 11], "temperature": 0.0, "avg_logprob": -0.21148932123758707, "compression_ratio": 1.6363636363636365, "no_speech_prob": 2.2125514078652486e-05}, {"id": 263, "seek": 132200, "start": 1341.0, "end": 1346.0, "text": " and a user-maintained function called placeholder, which renders out the placeholder.", "tokens": [293, 257, 4195, 12, 76, 5114, 3563, 2445, 1219, 1081, 20480, 11, 597, 6125, 433, 484, 264, 1081, 20480, 13], "temperature": 0.0, "avg_logprob": -0.21148932123758707, "compression_ratio": 1.6363636363636365, "no_speech_prob": 2.2125514078652486e-05}, {"id": 264, "seek": 134600, "start": 1346.0, "end": 1355.0, "text": " Let me scaffold out something with the view using the same pattern that Ryan came up with for Elm SPA.", "tokens": [961, 385, 44094, 484, 746, 365, 264, 1910, 1228, 264, 912, 5102, 300, 9116, 1361, 493, 365, 337, 2699, 76, 8420, 32, 13], "temperature": 0.0, "avg_logprob": -0.1937999515743046, "compression_ratio": 1.5961538461538463, "no_speech_prob": 3.763447602977976e-05}, {"id": 265, "seek": 134600, "start": 1355.0, "end": 1360.0, "text": " And that was great, but it was like, well, I want to make it more customizable than that.", "tokens": [400, 300, 390, 869, 11, 457, 309, 390, 411, 11, 731, 11, 286, 528, 281, 652, 309, 544, 47922, 813, 300, 13], "temperature": 0.0, "avg_logprob": -0.1937999515743046, "compression_ratio": 1.5961538461538463, "no_speech_prob": 3.763447602977976e-05}, {"id": 266, "seek": 134600, "start": 1360.0, "end": 1363.0, "text": " And I also like if you can...", "tokens": [400, 286, 611, 411, 498, 291, 393, 485], "temperature": 0.0, "avg_logprob": -0.1937999515743046, "compression_ratio": 1.5961538461538463, "no_speech_prob": 3.763447602977976e-05}, {"id": 267, "seek": 134600, "start": 1363.0, "end": 1365.0, "text": " If you want to have...", "tokens": [759, 291, 528, 281, 362, 485], "temperature": 0.0, "avg_logprob": -0.1937999515743046, "compression_ratio": 1.5961538461538463, "no_speech_prob": 3.763447602977976e-05}, {"id": 268, "seek": 134600, "start": 1365.0, "end": 1370.0, "text": " If you want to be able to pass in CLI arguments to customize how you're generating it.", "tokens": [759, 291, 528, 281, 312, 1075, 281, 1320, 294, 12855, 40, 12869, 281, 19734, 577, 291, 434, 17746, 309, 13], "temperature": 0.0, "avg_logprob": -0.1937999515743046, "compression_ratio": 1.5961538461538463, "no_speech_prob": 3.763447602977976e-05}, {"id": 269, "seek": 137000, "start": 1370.0, "end": 1377.0, "text": " If you want to generate it with some GraphQL query or some HTTP request or something like...", "tokens": [759, 291, 528, 281, 8460, 309, 365, 512, 21884, 13695, 14581, 420, 512, 33283, 5308, 420, 746, 411, 485], "temperature": 0.0, "avg_logprob": -0.19236899994231843, "compression_ratio": 1.5726495726495726, "no_speech_prob": 1.6700905689503998e-05}, {"id": 270, "seek": 137000, "start": 1377.0, "end": 1378.0, "text": " The sky's the limit.", "tokens": [440, 5443, 311, 264, 4948, 13], "temperature": 0.0, "avg_logprob": -0.19236899994231843, "compression_ratio": 1.5726495726495726, "no_speech_prob": 1.6700905689503998e-05}, {"id": 271, "seek": 137000, "start": 1378.0, "end": 1379.0, "text": " There's so many things you could do.", "tokens": [821, 311, 370, 867, 721, 291, 727, 360, 13], "temperature": 0.0, "avg_logprob": -0.19236899994231843, "compression_ratio": 1.5726495726495726, "no_speech_prob": 1.6700905689503998e-05}, {"id": 272, "seek": 137000, "start": 1379.0, "end": 1383.0, "text": " Or maybe you want to scaffold out modules that aren't even route modules.", "tokens": [1610, 1310, 291, 528, 281, 44094, 484, 16679, 300, 3212, 380, 754, 7955, 16679, 13], "temperature": 0.0, "avg_logprob": -0.19236899994231843, "compression_ratio": 1.5726495726495726, "no_speech_prob": 1.6700905689503998e-05}, {"id": 273, "seek": 137000, "start": 1383.0, "end": 1388.0, "text": " Maybe they're helper modules for defining some backend tasks or whatever it may be.", "tokens": [2704, 436, 434, 36133, 16679, 337, 17827, 512, 38087, 9608, 420, 2035, 309, 815, 312, 13], "temperature": 0.0, "avg_logprob": -0.19236899994231843, "compression_ratio": 1.5726495726495726, "no_speech_prob": 1.6700905689503998e-05}, {"id": 274, "seek": 137000, "start": 1388.0, "end": 1392.0, "text": " So I just wanted to make that more customizable in general.", "tokens": [407, 286, 445, 1415, 281, 652, 300, 544, 47922, 294, 2674, 13], "temperature": 0.0, "avg_logprob": -0.19236899994231843, "compression_ratio": 1.5726495726495726, "no_speech_prob": 1.6700905689503998e-05}, {"id": 275, "seek": 139200, "start": 1392.0, "end": 1400.0, "text": " And so I knew I wanted to basically say, well, I want to have a way to make scaffolding more customizable.", "tokens": [400, 370, 286, 2586, 286, 1415, 281, 1936, 584, 11, 731, 11, 286, 528, 281, 362, 257, 636, 281, 652, 44094, 278, 544, 47922, 13], "temperature": 0.0, "avg_logprob": -0.17139504880321269, "compression_ratio": 1.5708154506437768, "no_speech_prob": 5.862725629413035e-06}, {"id": 276, "seek": 139200, "start": 1400.0, "end": 1402.0, "text": " And I would love to do that using Elm CodeGen.", "tokens": [400, 286, 576, 959, 281, 360, 300, 1228, 2699, 76, 15549, 26647, 13], "temperature": 0.0, "avg_logprob": -0.17139504880321269, "compression_ratio": 1.5708154506437768, "no_speech_prob": 5.862725629413035e-06}, {"id": 277, "seek": 139200, "start": 1402.0, "end": 1406.0, "text": " So you can write Elm code to generate your Elm code for these modules.", "tokens": [407, 291, 393, 2464, 2699, 76, 3089, 281, 8460, 428, 2699, 76, 3089, 337, 613, 16679, 13], "temperature": 0.0, "avg_logprob": -0.17139504880321269, "compression_ratio": 1.5708154506437768, "no_speech_prob": 5.862725629413035e-06}, {"id": 278, "seek": 139200, "start": 1406.0, "end": 1416.0, "text": " But I also want to be able to pull in HTTP data, pull in environment variables, read files if I want to read a config file, things like that.", "tokens": [583, 286, 611, 528, 281, 312, 1075, 281, 2235, 294, 33283, 1412, 11, 2235, 294, 2823, 9102, 11, 1401, 7098, 498, 286, 528, 281, 1401, 257, 6662, 3991, 11, 721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.17139504880321269, "compression_ratio": 1.5708154506437768, "no_speech_prob": 5.862725629413035e-06}, {"id": 279, "seek": 141600, "start": 1416.0, "end": 1424.0, "text": " So it's like, well, OK, I want to be able to execute backend tasks in this context when I'm running the scaffolding script to generate a file.", "tokens": [407, 309, 311, 411, 11, 731, 11, 2264, 11, 286, 528, 281, 312, 1075, 281, 14483, 38087, 9608, 294, 341, 4319, 562, 286, 478, 2614, 264, 44094, 278, 5755, 281, 8460, 257, 3991, 13], "temperature": 0.0, "avg_logprob": -0.1861699911264273, "compression_ratio": 1.716, "no_speech_prob": 3.137930434604641e-06}, {"id": 280, "seek": 141600, "start": 1424.0, "end": 1425.0, "text": " And then I'm like, you know what?", "tokens": [400, 550, 286, 478, 411, 11, 291, 458, 437, 30], "temperature": 0.0, "avg_logprob": -0.1861699911264273, "compression_ratio": 1.716, "no_speech_prob": 3.137930434604641e-06}, {"id": 281, "seek": 141600, "start": 1425.0, "end": 1426.0, "text": " Like if I just make...", "tokens": [1743, 498, 286, 445, 652, 485], "temperature": 0.0, "avg_logprob": -0.1861699911264273, "compression_ratio": 1.716, "no_speech_prob": 3.137930434604641e-06}, {"id": 282, "seek": 141600, "start": 1426.0, "end": 1433.0, "text": " Like there's very little difference between a custom scaffolding script and just a script.", "tokens": [1743, 456, 311, 588, 707, 2649, 1296, 257, 2375, 44094, 278, 5755, 293, 445, 257, 5755, 13], "temperature": 0.0, "avg_logprob": -0.1861699911264273, "compression_ratio": 1.716, "no_speech_prob": 3.137930434604641e-06}, {"id": 283, "seek": 141600, "start": 1433.0, "end": 1438.0, "text": " So why don't I just make a script feature and the scaffolding script is just a special case of that.", "tokens": [407, 983, 500, 380, 286, 445, 652, 257, 5755, 4111, 293, 264, 44094, 278, 5755, 307, 445, 257, 2121, 1389, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.1861699911264273, "compression_ratio": 1.716, "no_speech_prob": 3.137930434604641e-06}, {"id": 284, "seek": 141600, "start": 1438.0, "end": 1440.0, "text": " So that's what I ended up with.", "tokens": [407, 300, 311, 437, 286, 4590, 493, 365, 13], "temperature": 0.0, "avg_logprob": -0.1861699911264273, "compression_ratio": 1.716, "no_speech_prob": 3.137930434604641e-06}, {"id": 285, "seek": 141600, "start": 1440.0, "end": 1441.0, "text": " Nice.", "tokens": [5490, 13], "temperature": 0.0, "avg_logprob": -0.1861699911264273, "compression_ratio": 1.716, "no_speech_prob": 3.137930434604641e-06}, {"id": 286, "seek": 144100, "start": 1441.0, "end": 1461.0, "text": " So for instance, I know it's like not the best use of it, but if I want to customize my scaffolding, I could create a backend task that gets the current time and then inject a comment saying this was generated on this date.", "tokens": [407, 337, 5197, 11, 286, 458, 309, 311, 411, 406, 264, 1151, 764, 295, 309, 11, 457, 498, 286, 528, 281, 19734, 452, 44094, 278, 11, 286, 727, 1884, 257, 38087, 5633, 300, 2170, 264, 2190, 565, 293, 550, 10711, 257, 2871, 1566, 341, 390, 10833, 322, 341, 4002, 13], "temperature": 0.0, "avg_logprob": -0.21183786159608423, "compression_ratio": 1.4439024390243902, "no_speech_prob": 3.555793682608055e-06}, {"id": 287, "seek": 144100, "start": 1461.0, "end": 1462.0, "text": " Absolutely.", "tokens": [7021, 13], "temperature": 0.0, "avg_logprob": -0.21183786159608423, "compression_ratio": 1.4439024390243902, "no_speech_prob": 3.555793682608055e-06}, {"id": 288, "seek": 144100, "start": 1462.0, "end": 1463.0, "text": " That's pretty cool.", "tokens": [663, 311, 1238, 1627, 13], "temperature": 0.0, "avg_logprob": -0.21183786159608423, "compression_ratio": 1.4439024390243902, "no_speech_prob": 3.555793682608055e-06}, {"id": 289, "seek": 144100, "start": 1463.0, "end": 1464.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.21183786159608423, "compression_ratio": 1.4439024390243902, "no_speech_prob": 3.555793682608055e-06}, {"id": 290, "seek": 144100, "start": 1464.0, "end": 1468.0, "text": " Terrible use, but I mean, why not?", "tokens": [6564, 4457, 764, 11, 457, 286, 914, 11, 983, 406, 30], "temperature": 0.0, "avg_logprob": -0.21183786159608423, "compression_ratio": 1.4439024390243902, "no_speech_prob": 3.555793682608055e-06}, {"id": 291, "seek": 146800, "start": 1468.0, "end": 1479.0, "text": " Yeah, I mean, you can read configuration from some JSON configuration file and use that to generate something and the sky's the limit.", "tokens": [865, 11, 286, 914, 11, 291, 393, 1401, 11694, 490, 512, 31828, 11694, 3991, 293, 764, 300, 281, 8460, 746, 293, 264, 5443, 311, 264, 4948, 13], "temperature": 0.0, "avg_logprob": -0.22127936868106618, "compression_ratio": 1.4720496894409938, "no_speech_prob": 4.4253742998989765e-06}, {"id": 292, "seek": 146800, "start": 1479.0, "end": 1480.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.22127936868106618, "compression_ratio": 1.4720496894409938, "no_speech_prob": 4.4253742998989765e-06}, {"id": 293, "seek": 146800, "start": 1480.0, "end": 1481.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.22127936868106618, "compression_ratio": 1.4720496894409938, "no_speech_prob": 4.4253742998989765e-06}, {"id": 294, "seek": 146800, "start": 1481.0, "end": 1485.0, "text": " I'm really curious to see what people come up with or what they used it for.", "tokens": [286, 478, 534, 6369, 281, 536, 437, 561, 808, 493, 365, 420, 437, 436, 1143, 309, 337, 13], "temperature": 0.0, "avg_logprob": -0.22127936868106618, "compression_ratio": 1.4720496894409938, "no_speech_prob": 4.4253742998989765e-06}, {"id": 295, "seek": 146800, "start": 1485.0, "end": 1486.0, "text": " Me too.", "tokens": [1923, 886, 13], "temperature": 0.0, "avg_logprob": -0.22127936868106618, "compression_ratio": 1.4720496894409938, "no_speech_prob": 4.4253742998989765e-06}, {"id": 296, "seek": 146800, "start": 1486.0, "end": 1487.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.22127936868106618, "compression_ratio": 1.4720496894409938, "no_speech_prob": 4.4253742998989765e-06}, {"id": 297, "seek": 148700, "start": 1487.0, "end": 1506.0, "text": " I'm not going to go down a rabbit hole, but there's a new feature where you can execute an Elm pages script pointing to a GitHub gist or a link to a raw GitHub file, including a branch or just pointing to a GitHub repo and then you provide a path to a script.", "tokens": [286, 478, 406, 516, 281, 352, 760, 257, 19509, 5458, 11, 457, 456, 311, 257, 777, 4111, 689, 291, 393, 14483, 364, 2699, 76, 7183, 5755, 12166, 281, 257, 23331, 290, 468, 420, 257, 2113, 281, 257, 8936, 23331, 3991, 11, 3009, 257, 9819, 420, 445, 12166, 281, 257, 23331, 49040, 293, 550, 291, 2893, 257, 3100, 281, 257, 5755, 13], "temperature": 0.0, "avg_logprob": -0.22971663841834436, "compression_ratio": 1.579268292682927, "no_speech_prob": 3.5007644783036085e-06}, {"id": 298, "seek": 150600, "start": 1506.0, "end": 1521.0, "text": " So I'm really excited to see what people do with scripts now that it's like much more shareable, you can just have a gist that has your scaffolding and your, you know, whatever logic for a little helper script you have.", "tokens": [407, 286, 478, 534, 2919, 281, 536, 437, 561, 360, 365, 23294, 586, 300, 309, 311, 411, 709, 544, 2073, 712, 11, 291, 393, 445, 362, 257, 290, 468, 300, 575, 428, 44094, 278, 293, 428, 11, 291, 458, 11, 2035, 9952, 337, 257, 707, 36133, 5755, 291, 362, 13], "temperature": 0.0, "avg_logprob": -0.1633256431517562, "compression_ratio": 1.6826568265682658, "no_speech_prob": 3.5007158203370636e-06}, {"id": 299, "seek": 150600, "start": 1521.0, "end": 1524.0, "text": " So scripts are a lot more shareable now and a lot easier to play around with.", "tokens": [407, 23294, 366, 257, 688, 544, 2073, 712, 586, 293, 257, 688, 3571, 281, 862, 926, 365, 13], "temperature": 0.0, "avg_logprob": -0.1633256431517562, "compression_ratio": 1.6826568265682658, "no_speech_prob": 3.5007158203370636e-06}, {"id": 300, "seek": 150600, "start": 1524.0, "end": 1527.0, "text": " Has that last feature you talked about been released?", "tokens": [8646, 300, 1036, 4111, 291, 2825, 466, 668, 4736, 30], "temperature": 0.0, "avg_logprob": -0.1633256431517562, "compression_ratio": 1.6826568265682658, "no_speech_prob": 3.5007158203370636e-06}, {"id": 301, "seek": 150600, "start": 1527.0, "end": 1528.0, "text": " It's released.", "tokens": [467, 311, 4736, 13], "temperature": 0.0, "avg_logprob": -0.1633256431517562, "compression_ratio": 1.6826568265682658, "no_speech_prob": 3.5007158203370636e-06}, {"id": 302, "seek": 150600, "start": 1528.0, "end": 1529.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.1633256431517562, "compression_ratio": 1.6826568265682658, "no_speech_prob": 3.5007158203370636e-06}, {"id": 303, "seek": 150600, "start": 1529.0, "end": 1530.0, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.1633256431517562, "compression_ratio": 1.6826568265682658, "no_speech_prob": 3.5007158203370636e-06}, {"id": 304, "seek": 150600, "start": 1530.0, "end": 1533.0, "text": " I haven't done an announcement post, but it's released and it's stable.", "tokens": [286, 2378, 380, 1096, 364, 12847, 2183, 11, 457, 309, 311, 4736, 293, 309, 311, 8351, 13], "temperature": 0.0, "avg_logprob": -0.1633256431517562, "compression_ratio": 1.6826568265682658, "no_speech_prob": 3.5007158203370636e-06}, {"id": 305, "seek": 150600, "start": 1533.0, "end": 1534.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.1633256431517562, "compression_ratio": 1.6826568265682658, "no_speech_prob": 3.5007158203370636e-06}, {"id": 306, "seek": 153400, "start": 1534.0, "end": 1537.0, "text": " Okay. I was thinking it wasn't released yet.", "tokens": [1033, 13, 286, 390, 1953, 309, 2067, 380, 4736, 1939, 13], "temperature": 0.0, "avg_logprob": -0.21160656472911005, "compression_ratio": 1.7988165680473374, "no_speech_prob": 3.500814955259557e-06}, {"id": 307, "seek": 153400, "start": 1537.0, "end": 1543.0, "text": " I'm like, we should finally talk about things that have been released.", "tokens": [286, 478, 411, 11, 321, 820, 2721, 751, 466, 721, 300, 362, 668, 4736, 13], "temperature": 0.0, "avg_logprob": -0.21160656472911005, "compression_ratio": 1.7988165680473374, "no_speech_prob": 3.500814955259557e-06}, {"id": 308, "seek": 153400, "start": 1543.0, "end": 1545.0, "text": " This is a bad habit.", "tokens": [639, 307, 257, 1578, 7164, 13], "temperature": 0.0, "avg_logprob": -0.21160656472911005, "compression_ratio": 1.7988165680473374, "no_speech_prob": 3.500814955259557e-06}, {"id": 309, "seek": 153400, "start": 1545.0, "end": 1548.0, "text": " This is an intervention.", "tokens": [639, 307, 364, 13176, 13], "temperature": 0.0, "avg_logprob": -0.21160656472911005, "compression_ratio": 1.7988165680473374, "no_speech_prob": 3.500814955259557e-06}, {"id": 310, "seek": 153400, "start": 1548.0, "end": 1551.0, "text": " Let's talk about things that have been released, but okay.", "tokens": [961, 311, 751, 466, 721, 300, 362, 668, 4736, 11, 457, 1392, 13], "temperature": 0.0, "avg_logprob": -0.21160656472911005, "compression_ratio": 1.7988165680473374, "no_speech_prob": 3.500814955259557e-06}, {"id": 311, "seek": 153400, "start": 1551.0, "end": 1552.0, "text": " It has been released.", "tokens": [467, 575, 668, 4736, 13], "temperature": 0.0, "avg_logprob": -0.21160656472911005, "compression_ratio": 1.7988165680473374, "no_speech_prob": 3.500814955259557e-06}, {"id": 312, "seek": 153400, "start": 1552.0, "end": 1553.0, "text": " I have nothing to say.", "tokens": [286, 362, 1825, 281, 584, 13], "temperature": 0.0, "avg_logprob": -0.21160656472911005, "compression_ratio": 1.7988165680473374, "no_speech_prob": 3.500814955259557e-06}, {"id": 313, "seek": 153400, "start": 1553.0, "end": 1554.0, "text": " Turned over a new leaf.", "tokens": [7956, 292, 670, 257, 777, 10871, 13], "temperature": 0.0, "avg_logprob": -0.21160656472911005, "compression_ratio": 1.7988165680473374, "no_speech_prob": 3.500814955259557e-06}, {"id": 314, "seek": 153400, "start": 1554.0, "end": 1555.0, "text": " It's released.", "tokens": [467, 311, 4736, 13], "temperature": 0.0, "avg_logprob": -0.21160656472911005, "compression_ratio": 1.7988165680473374, "no_speech_prob": 3.500814955259557e-06}, {"id": 315, "seek": 155500, "start": 1555.0, "end": 1564.0, "text": " So we should probably talk about the big headline of ElmPages v3, which is server rendered routes.", "tokens": [407, 321, 820, 1391, 751, 466, 264, 955, 28380, 295, 2699, 76, 47, 1660, 371, 18, 11, 597, 307, 7154, 28748, 18242, 13], "temperature": 0.0, "avg_logprob": -0.23291698890396312, "compression_ratio": 1.5939086294416243, "no_speech_prob": 1.8924747564597055e-05}, {"id": 316, "seek": 155500, "start": 1564.0, "end": 1572.0, "text": " So first of all, maybe we should define server rendering and what that's in contrast to.", "tokens": [407, 700, 295, 439, 11, 1310, 321, 820, 6964, 7154, 22407, 293, 437, 300, 311, 294, 8712, 281, 13], "temperature": 0.0, "avg_logprob": -0.23291698890396312, "compression_ratio": 1.5939086294416243, "no_speech_prob": 1.8924747564597055e-05}, {"id": 317, "seek": 155500, "start": 1572.0, "end": 1576.0, "text": " And also you say server rendered routes.", "tokens": [400, 611, 291, 584, 7154, 28748, 18242, 13], "temperature": 0.0, "avg_logprob": -0.23291698890396312, "compression_ratio": 1.5939086294416243, "no_speech_prob": 1.8924747564597055e-05}, {"id": 318, "seek": 155500, "start": 1576.0, "end": 1584.0, "text": " And the term that I hear from the JavaScript ecosystem is SSR, server-side rendering.", "tokens": [400, 264, 1433, 300, 286, 1568, 490, 264, 15778, 11311, 307, 12238, 49, 11, 7154, 12, 1812, 22407, 13], "temperature": 0.0, "avg_logprob": -0.23291698890396312, "compression_ratio": 1.5939086294416243, "no_speech_prob": 1.8924747564597055e-05}, {"id": 319, "seek": 158400, "start": 1584.0, "end": 1587.0, "text": " Is that the same thing or the difference?", "tokens": [1119, 300, 264, 912, 551, 420, 264, 2649, 30], "temperature": 0.0, "avg_logprob": -0.21247905931974712, "compression_ratio": 1.5721153846153846, "no_speech_prob": 1.1478622582217213e-05}, {"id": 320, "seek": 158400, "start": 1587.0, "end": 1588.0, "text": " It is.", "tokens": [467, 307, 13], "temperature": 0.0, "avg_logprob": -0.21247905931974712, "compression_ratio": 1.5721153846153846, "no_speech_prob": 1.1478622582217213e-05}, {"id": 321, "seek": 158400, "start": 1588.0, "end": 1589.0, "text": " Yeah, it's exactly the same thing.", "tokens": [865, 11, 309, 311, 2293, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.21247905931974712, "compression_ratio": 1.5721153846153846, "no_speech_prob": 1.1478622582217213e-05}, {"id": 322, "seek": 158400, "start": 1589.0, "end": 1595.0, "text": " But your name is better for some reason that you're going to explain it now.", "tokens": [583, 428, 1315, 307, 1101, 337, 512, 1778, 300, 291, 434, 516, 281, 2903, 309, 586, 13], "temperature": 0.0, "avg_logprob": -0.21247905931974712, "compression_ratio": 1.5721153846153846, "no_speech_prob": 1.1478622582217213e-05}, {"id": 323, "seek": 158400, "start": 1595.0, "end": 1601.0, "text": " Well, in the context of an ElmPages app, you can have a pre-rendered route or a server rendered route.", "tokens": [1042, 11, 294, 264, 4319, 295, 364, 2699, 76, 47, 1660, 724, 11, 291, 393, 362, 257, 659, 12, 4542, 4073, 7955, 420, 257, 7154, 28748, 7955, 13], "temperature": 0.0, "avg_logprob": -0.21247905931974712, "compression_ratio": 1.5721153846153846, "no_speech_prob": 1.1478622582217213e-05}, {"id": 324, "seek": 158400, "start": 1601.0, "end": 1605.0, "text": " Pre-rendered route, the backend task is resolved at build time.", "tokens": [6001, 12, 4542, 4073, 7955, 11, 264, 38087, 5633, 307, 20772, 412, 1322, 565, 13], "temperature": 0.0, "avg_logprob": -0.21247905931974712, "compression_ratio": 1.5721153846153846, "no_speech_prob": 1.1478622582217213e-05}, {"id": 325, "seek": 160500, "start": 1605.0, "end": 1616.0, "text": " It results in a pre-rendered HTML file on disk, which your hosting provider can serve up or through a CDN or however you want to do that.", "tokens": [467, 3542, 294, 257, 659, 12, 4542, 4073, 17995, 3991, 322, 12355, 11, 597, 428, 16058, 12398, 393, 4596, 493, 420, 807, 257, 6743, 45, 420, 4461, 291, 528, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.1601396742321196, "compression_ratio": 1.52, "no_speech_prob": 4.637605798052391e-06}, {"id": 326, "seek": 160500, "start": 1616.0, "end": 1618.0, "text": " Like a static HTML file?", "tokens": [1743, 257, 13437, 17995, 3991, 30], "temperature": 0.0, "avg_logprob": -0.1601396742321196, "compression_ratio": 1.52, "no_speech_prob": 4.637605798052391e-06}, {"id": 327, "seek": 160500, "start": 1618.0, "end": 1620.0, "text": " Yep, you get a static file.", "tokens": [7010, 11, 291, 483, 257, 13437, 3991, 13], "temperature": 0.0, "avg_logprob": -0.1601396742321196, "compression_ratio": 1.52, "no_speech_prob": 4.637605798052391e-06}, {"id": 328, "seek": 160500, "start": 1620.0, "end": 1626.0, "text": " You also get a static file called content.dat for that URL.", "tokens": [509, 611, 483, 257, 13437, 3991, 1219, 2701, 13, 20367, 337, 300, 12905, 13], "temperature": 0.0, "avg_logprob": -0.1601396742321196, "compression_ratio": 1.52, "no_speech_prob": 4.637605798052391e-06}, {"id": 329, "seek": 160500, "start": 1626.0, "end": 1631.0, "text": " And that contains the serialized data for your route.", "tokens": [400, 300, 8306, 264, 17436, 1602, 1412, 337, 428, 7955, 13], "temperature": 0.0, "avg_logprob": -0.1601396742321196, "compression_ratio": 1.52, "no_speech_prob": 4.637605798052391e-06}, {"id": 330, "seek": 163100, "start": 1631.0, "end": 1646.0, "text": " Now, the reason for that, so remember before I mentioned that conceptually you can use the mental model of, you know, like a Rails app that bootstraps some server data and passes them through ElmFlags.", "tokens": [823, 11, 264, 1778, 337, 300, 11, 370, 1604, 949, 286, 2835, 300, 3410, 671, 291, 393, 764, 264, 4973, 2316, 295, 11, 291, 458, 11, 411, 257, 48526, 724, 300, 11450, 19639, 1878, 512, 7154, 1412, 293, 11335, 552, 807, 2699, 76, 25680, 12109, 13], "temperature": 0.0, "avg_logprob": -0.21699376052685, "compression_ratio": 1.5299145299145298, "no_speech_prob": 8.267627890745644e-06}, {"id": 331, "seek": 163100, "start": 1646.0, "end": 1656.0, "text": " So that is actually exactly what happens if you load an initial page in your browser with HTML.", "tokens": [407, 300, 307, 767, 2293, 437, 2314, 498, 291, 3677, 364, 5883, 3028, 294, 428, 11185, 365, 17995, 13], "temperature": 0.0, "avg_logprob": -0.21699376052685, "compression_ratio": 1.5299145299145298, "no_speech_prob": 8.267627890745644e-06}, {"id": 332, "seek": 163100, "start": 1656.0, "end": 1660.0, "text": " But then if you click a link, it's not loading an HTML page.", "tokens": [583, 550, 498, 291, 2052, 257, 2113, 11, 309, 311, 406, 15114, 364, 17995, 3028, 13], "temperature": 0.0, "avg_logprob": -0.21699376052685, "compression_ratio": 1.5299145299145298, "no_speech_prob": 8.267627890745644e-06}, {"id": 333, "seek": 166000, "start": 1660.0, "end": 1665.0, "text": " So if you click a link, it's actually loading just a single file.", "tokens": [407, 498, 291, 2052, 257, 2113, 11, 309, 311, 767, 15114, 445, 257, 2167, 3991, 13], "temperature": 0.0, "avg_logprob": -0.15172928499888225, "compression_ratio": 1.6145251396648044, "no_speech_prob": 0.00011591394286369905}, {"id": 334, "seek": 166000, "start": 1665.0, "end": 1670.0, "text": " It doesn't load the HTML because it doesn't need that because it is now in single page app mode.", "tokens": [467, 1177, 380, 3677, 264, 17995, 570, 309, 1177, 380, 643, 300, 570, 309, 307, 586, 294, 2167, 3028, 724, 4391, 13], "temperature": 0.0, "avg_logprob": -0.15172928499888225, "compression_ratio": 1.6145251396648044, "no_speech_prob": 0.00011591394286369905}, {"id": 335, "seek": 166000, "start": 1670.0, "end": 1673.0, "text": " So it's hydrated into an Elm single page app.", "tokens": [407, 309, 311, 44960, 666, 364, 2699, 76, 2167, 3028, 724, 13], "temperature": 0.0, "avg_logprob": -0.15172928499888225, "compression_ratio": 1.6145251396648044, "no_speech_prob": 0.00011591394286369905}, {"id": 336, "seek": 166000, "start": 1673.0, "end": 1676.0, "text": " Now it only needs that data for the page.", "tokens": [823, 309, 787, 2203, 300, 1412, 337, 264, 3028, 13], "temperature": 0.0, "avg_logprob": -0.15172928499888225, "compression_ratio": 1.6145251396648044, "no_speech_prob": 0.00011591394286369905}, {"id": 337, "seek": 166000, "start": 1676.0, "end": 1678.0, "text": " So that's what the content.dat is for.", "tokens": [407, 300, 311, 437, 264, 2701, 13, 20367, 307, 337, 13], "temperature": 0.0, "avg_logprob": -0.15172928499888225, "compression_ratio": 1.6145251396648044, "no_speech_prob": 0.00011591394286369905}, {"id": 338, "seek": 167800, "start": 1678.0, "end": 1700.0, "text": " So if you have a blog slash introducing v3 post, that has some the markdown data, the parsed markdown data and the publish date and whatever other data is resolved for that, that routes data is serialized as bytes in a byte format there.", "tokens": [407, 498, 291, 362, 257, 6968, 17330, 15424, 371, 18, 2183, 11, 300, 575, 512, 264, 1491, 5093, 1412, 11, 264, 21156, 292, 1491, 5093, 1412, 293, 264, 11374, 4002, 293, 2035, 661, 1412, 307, 20772, 337, 300, 11, 300, 18242, 1412, 307, 17436, 1602, 382, 36088, 294, 257, 40846, 7877, 456, 13], "temperature": 0.0, "avg_logprob": -0.2611191679791706, "compression_ratio": 1.6313131313131313, "no_speech_prob": 8.013149454200175e-06}, {"id": 339, "seek": 167800, "start": 1700.0, "end": 1703.0, "text": " That gets downloaded by the browser.", "tokens": [663, 2170, 21748, 538, 264, 11185, 13], "temperature": 0.0, "avg_logprob": -0.2611191679791706, "compression_ratio": 1.6313131313131313, "no_speech_prob": 8.013149454200175e-06}, {"id": 340, "seek": 167800, "start": 1703.0, "end": 1704.0, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.2611191679791706, "compression_ratio": 1.6313131313131313, "no_speech_prob": 8.013149454200175e-06}, {"id": 341, "seek": 167800, "start": 1704.0, "end": 1707.0, "text": " That's in the metadata or the head tag.", "tokens": [663, 311, 294, 264, 26603, 420, 264, 1378, 6162, 13], "temperature": 0.0, "avg_logprob": -0.2611191679791706, "compression_ratio": 1.6313131313131313, "no_speech_prob": 8.013149454200175e-06}, {"id": 342, "seek": 170700, "start": 1707.0, "end": 1708.0, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.2052909124465216, "compression_ratio": 1.5635593220338984, "no_speech_prob": 2.627203502925113e-05}, {"id": 343, "seek": 170700, "start": 1708.0, "end": 1717.0, "text": " So the Elm pages framework itself, when it's running in the browser, it knows when you click on a link to go fetch the corresponding data.", "tokens": [407, 264, 2699, 76, 7183, 8388, 2564, 11, 562, 309, 311, 2614, 294, 264, 11185, 11, 309, 3255, 562, 291, 2052, 322, 257, 2113, 281, 352, 23673, 264, 11760, 1412, 13], "temperature": 0.0, "avg_logprob": -0.2052909124465216, "compression_ratio": 1.5635593220338984, "no_speech_prob": 2.627203502925113e-05}, {"id": 344, "seek": 170700, "start": 1717.0, "end": 1725.0, "text": " So it can, you know, it's a single page app, but it knows before I change routes to this page, I'm going to need this data.", "tokens": [407, 309, 393, 11, 291, 458, 11, 309, 311, 257, 2167, 3028, 724, 11, 457, 309, 3255, 949, 286, 1319, 18242, 281, 341, 3028, 11, 286, 478, 516, 281, 643, 341, 1412, 13], "temperature": 0.0, "avg_logprob": -0.2052909124465216, "compression_ratio": 1.5635593220338984, "no_speech_prob": 2.627203502925113e-05}, {"id": 345, "seek": 170700, "start": 1725.0, "end": 1728.0, "text": " And is that JSON in practice?", "tokens": [400, 307, 300, 31828, 294, 3124, 30], "temperature": 0.0, "avg_logprob": -0.2052909124465216, "compression_ratio": 1.5635593220338984, "no_speech_prob": 2.627203502925113e-05}, {"id": 346, "seek": 170700, "start": 1728.0, "end": 1730.0, "text": " In v2 it was JSON.", "tokens": [682, 371, 17, 309, 390, 31828, 13], "temperature": 0.0, "avg_logprob": -0.2052909124465216, "compression_ratio": 1.5635593220338984, "no_speech_prob": 2.627203502925113e-05}, {"id": 347, "seek": 170700, "start": 1730.0, "end": 1734.0, "text": " That is then sent to the init function as flags.", "tokens": [663, 307, 550, 2279, 281, 264, 3157, 2445, 382, 23265, 13], "temperature": 0.0, "avg_logprob": -0.2052909124465216, "compression_ratio": 1.5635593220338984, "no_speech_prob": 2.627203502925113e-05}, {"id": 348, "seek": 173400, "start": 1734.0, "end": 1744.0, "text": " In, it's all binary and it uses the Lambdara wire encoders to encode that data to binary.", "tokens": [682, 11, 309, 311, 439, 17434, 293, 309, 4960, 264, 45691, 424, 6234, 2058, 378, 433, 281, 2058, 1429, 300, 1412, 281, 17434, 13], "temperature": 0.0, "avg_logprob": -0.2879332065582275, "compression_ratio": 1.4914285714285713, "no_speech_prob": 2.8854508855147287e-05}, {"id": 349, "seek": 173400, "start": 1744.0, "end": 1746.0, "text": " In v3. Okay.", "tokens": [682, 371, 18, 13, 1033, 13], "temperature": 0.0, "avg_logprob": -0.2879332065582275, "compression_ratio": 1.4914285714285713, "no_speech_prob": 2.8854508855147287e-05}, {"id": 350, "seek": 173400, "start": 1746.0, "end": 1751.0, "text": " Yeah. So Lambdara, so, and I think this is worth being explicit about.", "tokens": [865, 13, 407, 45691, 424, 11, 370, 11, 293, 286, 519, 341, 307, 3163, 885, 13691, 466, 13], "temperature": 0.0, "avg_logprob": -0.2879332065582275, "compression_ratio": 1.4914285714285713, "no_speech_prob": 2.8854508855147287e-05}, {"id": 351, "seek": 173400, "start": 1751.0, "end": 1755.0, "text": " So there are two meanings of Lambdara.", "tokens": [407, 456, 366, 732, 28138, 295, 45691, 424, 13], "temperature": 0.0, "avg_logprob": -0.2879332065582275, "compression_ratio": 1.4914285714285713, "no_speech_prob": 2.8854508855147287e-05}, {"id": 352, "seek": 173400, "start": 1755.0, "end": 1760.0, "text": " One is a compiler and one is a hosting platform.", "tokens": [1485, 307, 257, 31958, 293, 472, 307, 257, 16058, 3663, 13], "temperature": 0.0, "avg_logprob": -0.2879332065582275, "compression_ratio": 1.4914285714285713, "no_speech_prob": 2.8854508855147287e-05}, {"id": 353, "seek": 176000, "start": 1760.0, "end": 1764.0, "text": " Elm pages v3 has nothing to do with Lambdara, the hosting platform.", "tokens": [2699, 76, 7183, 371, 18, 575, 1825, 281, 360, 365, 45691, 424, 11, 264, 16058, 3663, 13], "temperature": 0.0, "avg_logprob": -0.22380383809407553, "compression_ratio": 1.6618357487922706, "no_speech_prob": 8.139538294926751e-06}, {"id": 354, "seek": 176000, "start": 1764.0, "end": 1766.0, "text": " Lambdara, the hosting platform is awesome.", "tokens": [45691, 424, 11, 264, 16058, 3663, 307, 3476, 13], "temperature": 0.0, "avg_logprob": -0.22380383809407553, "compression_ratio": 1.6618357487922706, "no_speech_prob": 8.139538294926751e-06}, {"id": 355, "seek": 176000, "start": 1766.0, "end": 1767.0, "text": " You should definitely use that.", "tokens": [509, 820, 2138, 764, 300, 13], "temperature": 0.0, "avg_logprob": -0.22380383809407553, "compression_ratio": 1.6618357487922706, "no_speech_prob": 8.139538294926751e-06}, {"id": 356, "seek": 176000, "start": 1767.0, "end": 1777.0, "text": " If you want a Lambdara app, an app that is using WebSockets to have multiple connected clients, sending real time data and doing evergreen migrations.", "tokens": [759, 291, 528, 257, 45691, 424, 724, 11, 364, 724, 300, 307, 1228, 9573, 50, 1560, 1385, 281, 362, 3866, 4582, 6982, 11, 7750, 957, 565, 1412, 293, 884, 1562, 27399, 6186, 12154, 13], "temperature": 0.0, "avg_logprob": -0.22380383809407553, "compression_ratio": 1.6618357487922706, "no_speech_prob": 8.139538294926751e-06}, {"id": 357, "seek": 176000, "start": 1777.0, "end": 1779.0, "text": " Awesome platform.", "tokens": [10391, 3663, 13], "temperature": 0.0, "avg_logprob": -0.22380383809407553, "compression_ratio": 1.6618357487922706, "no_speech_prob": 8.139538294926751e-06}, {"id": 358, "seek": 176000, "start": 1779.0, "end": 1781.0, "text": " Nothing to do with Elm pages v3.", "tokens": [6693, 281, 360, 365, 2699, 76, 7183, 371, 18, 13], "temperature": 0.0, "avg_logprob": -0.22380383809407553, "compression_ratio": 1.6618357487922706, "no_speech_prob": 8.139538294926751e-06}, {"id": 359, "seek": 178100, "start": 1781.0, "end": 1795.0, "text": " Elm pages v3 uses the Lambda compiler, which is it's exactly like the Elm compiler, but it adds a couple of things, including the ability to automatically serialize or deserialize an Elm type.", "tokens": [2699, 76, 7183, 371, 18, 4960, 264, 45691, 31958, 11, 597, 307, 309, 311, 2293, 411, 264, 2699, 76, 31958, 11, 457, 309, 10860, 257, 1916, 295, 721, 11, 3009, 264, 3485, 281, 6772, 17436, 1125, 420, 730, 260, 831, 1125, 364, 2699, 76, 2010, 13], "temperature": 0.0, "avg_logprob": -0.1708307731442335, "compression_ratio": 1.605, "no_speech_prob": 3.1380661766888807e-06}, {"id": 360, "seek": 178100, "start": 1795.0, "end": 1805.0, "text": " And that is how in v3 Elm pages manages taking that data, which is resolved on the server and then hydrating that on the client.", "tokens": [400, 300, 307, 577, 294, 371, 18, 2699, 76, 7183, 22489, 1940, 300, 1412, 11, 597, 307, 20772, 322, 264, 7154, 293, 550, 5796, 8754, 300, 322, 264, 6423, 13], "temperature": 0.0, "avg_logprob": -0.1708307731442335, "compression_ratio": 1.605, "no_speech_prob": 3.1380661766888807e-06}, {"id": 361, "seek": 180500, "start": 1805.0, "end": 1818.0, "text": " And this is actually a huge improvement in Elm pages v3, because in Elm pages v2, there was something called optimized decoders, which I think we talked about at length in the Elm pages v2 episode.", "tokens": [400, 341, 307, 767, 257, 2603, 10444, 294, 2699, 76, 7183, 371, 18, 11, 570, 294, 2699, 76, 7183, 371, 17, 11, 456, 390, 746, 1219, 26941, 979, 378, 433, 11, 597, 286, 519, 321, 2825, 466, 412, 4641, 294, 264, 2699, 76, 7183, 371, 17, 3500, 13], "temperature": 0.0, "avg_logprob": -0.1876035129322725, "compression_ratio": 1.5492957746478873, "no_speech_prob": 4.425126462592743e-06}, {"id": 362, "seek": 180500, "start": 1818.0, "end": 1823.0, "text": " So we're going to talk about it at length again now?", "tokens": [407, 321, 434, 516, 281, 751, 466, 309, 412, 4641, 797, 586, 30], "temperature": 0.0, "avg_logprob": -0.1876035129322725, "compression_ratio": 1.5492957746478873, "no_speech_prob": 4.425126462592743e-06}, {"id": 363, "seek": 180500, "start": 1823.0, "end": 1829.0, "text": " Well, fortunately, you can forget about all of those concepts that you learned.", "tokens": [1042, 11, 25511, 11, 291, 393, 2870, 466, 439, 295, 729, 10392, 300, 291, 3264, 13], "temperature": 0.0, "avg_logprob": -0.1876035129322725, "compression_ratio": 1.5492957746478873, "no_speech_prob": 4.425126462592743e-06}, {"id": 364, "seek": 182900, "start": 1829.0, "end": 1846.0, "text": " And I'm sorry if you spent time learning and mastering those concepts, but fortunately, you get all of those same benefits with Elm pages v3 without having to learn any of that or without having to import a drop in replacement for JSON decoders, which is what optimized decoder was.", "tokens": [400, 286, 478, 2597, 498, 291, 4418, 565, 2539, 293, 49382, 729, 10392, 11, 457, 25511, 11, 291, 483, 439, 295, 729, 912, 5311, 365, 2699, 76, 7183, 371, 18, 1553, 1419, 281, 1466, 604, 295, 300, 420, 1553, 1419, 281, 974, 257, 3270, 294, 14419, 337, 31828, 979, 378, 433, 11, 597, 307, 437, 26941, 979, 19866, 390, 13], "temperature": 0.0, "avg_logprob": -0.16967079963213133, "compression_ratio": 1.5814977973568283, "no_speech_prob": 2.7965434128418565e-05}, {"id": 365, "seek": 182900, "start": 1846.0, "end": 1851.0, "text": " You no longer have to worry about your data being sensitive data being used.", "tokens": [509, 572, 2854, 362, 281, 3292, 466, 428, 1412, 885, 9477, 1412, 885, 1143, 13], "temperature": 0.0, "avg_logprob": -0.16967079963213133, "compression_ratio": 1.5814977973568283, "no_speech_prob": 2.7965434128418565e-05}, {"id": 366, "seek": 185100, "start": 1851.0, "end": 1878.0, "text": " So like Elm pages v2, there was like this design when you when you do an HTTP request, you could you had to wrap it in this secrets thing, which basically would obfuscate any secrets in the JSON data, because what it needed to do is it needed to basically mark every bit of data you depended on as you resolved your data sources and pull in the corresponding JSON.", "tokens": [407, 411, 2699, 76, 7183, 371, 17, 11, 456, 390, 411, 341, 1715, 562, 291, 562, 291, 360, 364, 33283, 5308, 11, 291, 727, 291, 632, 281, 7019, 309, 294, 341, 14093, 551, 11, 597, 1936, 576, 1111, 69, 32601, 473, 604, 14093, 294, 264, 31828, 1412, 11, 570, 437, 309, 2978, 281, 360, 307, 309, 2978, 281, 1936, 1491, 633, 857, 295, 1412, 291, 1367, 3502, 322, 382, 291, 20772, 428, 1412, 7139, 293, 2235, 294, 264, 11760, 31828, 13], "temperature": 0.0, "avg_logprob": -0.20357571770163144, "compression_ratio": 1.6322869955156951, "no_speech_prob": 2.6687153876991943e-05}, {"id": 367, "seek": 187800, "start": 1878.0, "end": 1887.0, "text": " And it did like basically key value pairs with the definition of the request it was pulling from to the data for that request.", "tokens": [400, 309, 630, 411, 1936, 2141, 2158, 15494, 365, 264, 7123, 295, 264, 5308, 309, 390, 8407, 490, 281, 264, 1412, 337, 300, 5308, 13], "temperature": 0.0, "avg_logprob": -0.18511530148085728, "compression_ratio": 1.7300884955752212, "no_speech_prob": 0.0001795136195141822}, {"id": 368, "seek": 187800, "start": 1887.0, "end": 1892.0, "text": " So it had to scrub out sensitive data in the request in the keys of the JSON values.", "tokens": [407, 309, 632, 281, 24163, 484, 9477, 1412, 294, 264, 5308, 294, 264, 9317, 295, 264, 31828, 4190, 13], "temperature": 0.0, "avg_logprob": -0.18511530148085728, "compression_ratio": 1.7300884955752212, "no_speech_prob": 0.0001795136195141822}, {"id": 369, "seek": 187800, "start": 1892.0, "end": 1902.0, "text": " And it had to go and mark all the things that's what optimized decoders did is they would mark the things that were needed and only and strip out all of the data that wasn't used.", "tokens": [400, 309, 632, 281, 352, 293, 1491, 439, 264, 721, 300, 311, 437, 26941, 979, 378, 433, 630, 307, 436, 576, 1491, 264, 721, 300, 645, 2978, 293, 787, 293, 12828, 484, 439, 295, 264, 1412, 300, 2067, 380, 1143, 13], "temperature": 0.0, "avg_logprob": -0.18511530148085728, "compression_ratio": 1.7300884955752212, "no_speech_prob": 0.0001795136195141822}, {"id": 370, "seek": 190200, "start": 1902.0, "end": 1917.0, "text": " It was very complicated to build, but it it allowed you to like make it an API request in the data source that pulled in some JSON data, but only used a few keys, but it wouldn't pull in all of the JSON data.", "tokens": [467, 390, 588, 6179, 281, 1322, 11, 457, 309, 309, 4350, 291, 281, 411, 652, 309, 364, 9362, 5308, 294, 264, 1412, 4009, 300, 7373, 294, 512, 31828, 1412, 11, 457, 787, 1143, 257, 1326, 9317, 11, 457, 309, 2759, 380, 2235, 294, 439, 295, 264, 31828, 1412, 13], "temperature": 0.0, "avg_logprob": -0.21397954113078568, "compression_ratio": 1.4149659863945578, "no_speech_prob": 0.00010070951975649223}, {"id": 371, "seek": 191700, "start": 1917.0, "end": 1932.0, "text": " But with with v3, it just resolves all of the data in your back end task that resolves to your whatever your route modules data type is, and then it it just serializes that data type.", "tokens": [583, 365, 365, 371, 18, 11, 309, 445, 7923, 977, 439, 295, 264, 1412, 294, 428, 646, 917, 5633, 300, 7923, 977, 281, 428, 2035, 428, 7955, 16679, 1412, 2010, 307, 11, 293, 550, 309, 309, 445, 17436, 5660, 300, 1412, 2010, 13], "temperature": 0.0, "avg_logprob": -0.2181782418109001, "compression_ratio": 1.464, "no_speech_prob": 2.2124733732198365e-05}, {"id": 372, "seek": 193200, "start": 1932.0, "end": 1947.0, "text": " So you don't have to worry about what data you had that went into resolving that data. It's just what is the final data type that gets serialized in a binary format, and then passed in when your page is hydrated, or when you navigate to a new page, it gets downloaded.", "tokens": [407, 291, 500, 380, 362, 281, 3292, 466, 437, 1412, 291, 632, 300, 1437, 666, 49940, 300, 1412, 13, 467, 311, 445, 437, 307, 264, 2572, 1412, 2010, 300, 2170, 17436, 1602, 294, 257, 17434, 7877, 11, 293, 550, 4678, 294, 562, 428, 3028, 307, 44960, 11, 420, 562, 291, 12350, 281, 257, 777, 3028, 11, 309, 2170, 21748, 13], "temperature": 0.0, "avg_logprob": -0.2152226765950521, "compression_ratio": 1.6082474226804124, "no_speech_prob": 9.221385880664457e-06}, {"id": 373, "seek": 193200, "start": 1947.0, "end": 1950.0, "text": " So much simpler, and much more performance.", "tokens": [407, 709, 18587, 11, 293, 709, 544, 3389, 13], "temperature": 0.0, "avg_logprob": -0.2152226765950521, "compression_ratio": 1.6082474226804124, "no_speech_prob": 9.221385880664457e-06}, {"id": 374, "seek": 195000, "start": 1950.0, "end": 1962.0, "text": " Yes, and better for security as well, which was one of the main motivations too. So I was like, if you're doing server side stuff, I don't want you to have to think about like, am I pulling in sensitive data?", "tokens": [1079, 11, 293, 1101, 337, 3825, 382, 731, 11, 597, 390, 472, 295, 264, 2135, 39034, 886, 13, 407, 286, 390, 411, 11, 498, 291, 434, 884, 7154, 1252, 1507, 11, 286, 500, 380, 528, 291, 281, 362, 281, 519, 466, 411, 11, 669, 286, 8407, 294, 9477, 1412, 30], "temperature": 0.0, "avg_logprob": -0.18351011406885434, "compression_ratio": 1.4564102564102563, "no_speech_prob": 1.3006527296965942e-05}, {"id": 375, "seek": 195000, "start": 1962.0, "end": 1968.0, "text": " So yeah, because it was still possible to mess it up and to expose secrets.", "tokens": [407, 1338, 11, 570, 309, 390, 920, 1944, 281, 2082, 309, 493, 293, 281, 19219, 14093, 13], "temperature": 0.0, "avg_logprob": -0.18351011406885434, "compression_ratio": 1.4564102564102563, "no_speech_prob": 1.3006527296965942e-05}, {"id": 376, "seek": 196800, "start": 1968.0, "end": 1982.0, "text": " Yeah, even though there was a whole affordance for for working with that it, it's something that you could get wrong. So you no longer have to think about that at all. And it's more compact binary data. So it's a win win.", "tokens": [865, 11, 754, 1673, 456, 390, 257, 1379, 6157, 719, 337, 337, 1364, 365, 300, 309, 11, 309, 311, 746, 300, 291, 727, 483, 2085, 13, 407, 291, 572, 2854, 362, 281, 519, 466, 300, 412, 439, 13, 400, 309, 311, 544, 14679, 17434, 1412, 13, 407, 309, 311, 257, 1942, 1942, 13], "temperature": 0.0, "avg_logprob": -0.17677026045949837, "compression_ratio": 1.4635761589403973, "no_speech_prob": 6.24071481070132e-06}, {"id": 377, "seek": 198200, "start": 1982.0, "end": 1998.0, "text": " You do need to ensure that your route modules data type, there's a type called data, usually it's a record type alias data, you do need to ensure that it does not contain any non serializable data, namely functions, functions are not serializable.", "tokens": [509, 360, 643, 281, 5586, 300, 428, 7955, 16679, 1412, 2010, 11, 456, 311, 257, 2010, 1219, 1412, 11, 2673, 309, 311, 257, 2136, 2010, 419, 4609, 1412, 11, 291, 360, 643, 281, 5586, 300, 309, 775, 406, 5304, 604, 2107, 17436, 22395, 1412, 11, 20926, 6828, 11, 6828, 366, 406, 17436, 22395, 13], "temperature": 0.0, "avg_logprob": -0.22545456436445127, "compression_ratio": 1.8548387096774193, "no_speech_prob": 6.2044826336205e-05}, {"id": 378, "seek": 198200, "start": 1998.0, "end": 2007.0, "text": " And data structures that contain functions are not serializable. Some of them are surprising, like HTML, I don't know if it actually contains functions in Elm's implementation.", "tokens": [400, 1412, 9227, 300, 5304, 6828, 366, 406, 17436, 22395, 13, 2188, 295, 552, 366, 8830, 11, 411, 17995, 11, 286, 500, 380, 458, 498, 309, 767, 8306, 6828, 294, 2699, 76, 311, 11420, 13], "temperature": 0.0, "avg_logprob": -0.22545456436445127, "compression_ratio": 1.8548387096774193, "no_speech_prob": 6.2044826336205e-05}, {"id": 379, "seek": 198200, "start": 2007.0, "end": 2010.0, "text": " Yeah, because you have HTML to map.", "tokens": [865, 11, 570, 291, 362, 17995, 281, 4471, 13], "temperature": 0.0, "avg_logprob": -0.22545456436445127, "compression_ratio": 1.8548387096774193, "no_speech_prob": 6.2044826336205e-05}, {"id": 380, "seek": 201000, "start": 2010.0, "end": 2015.0, "text": " Exactly. Yeah, if you have a map, right, exactly. That's right.", "tokens": [7587, 13, 865, 11, 498, 291, 362, 257, 4471, 11, 558, 11, 2293, 13, 663, 311, 558, 13], "temperature": 0.0, "avg_logprob": -0.22201721114341658, "compression_ratio": 1.7085427135678393, "no_speech_prob": 4.133374386583455e-05}, {"id": 381, "seek": 201000, "start": 2015.0, "end": 2022.0, "text": " Okay, so server side rendering, and or server rendered routes, SRR.", "tokens": [1033, 11, 370, 7154, 1252, 22407, 11, 293, 420, 7154, 28748, 18242, 11, 20840, 49, 13], "temperature": 0.0, "avg_logprob": -0.22201721114341658, "compression_ratio": 1.7085427135678393, "no_speech_prob": 4.133374386583455e-05}, {"id": 382, "seek": 201000, "start": 2022.0, "end": 2028.0, "text": " SSR. Yeah. Should we talk about what you can do with server rendered routes?", "tokens": [12238, 49, 13, 865, 13, 6454, 321, 751, 466, 437, 291, 393, 360, 365, 7154, 28748, 18242, 30], "temperature": 0.0, "avg_logprob": -0.22201721114341658, "compression_ratio": 1.7085427135678393, "no_speech_prob": 4.133374386583455e-05}, {"id": 383, "seek": 201000, "start": 2028.0, "end": 2037.0, "text": " Yeah. What is it for? What can you do? Why is it better? Why is it worse? Sometimes? Let's let's first talk about what it is. Yeah.", "tokens": [865, 13, 708, 307, 309, 337, 30, 708, 393, 291, 360, 30, 1545, 307, 309, 1101, 30, 1545, 307, 309, 5324, 30, 4803, 30, 961, 311, 718, 311, 700, 751, 466, 437, 309, 307, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.22201721114341658, "compression_ratio": 1.7085427135678393, "no_speech_prob": 4.133374386583455e-05}, {"id": 384, "seek": 203700, "start": 2037.0, "end": 2066.0, "text": " And you're right to ask, when is it better? When is it worse? Because so someone asked about this in the Elm pages, like channel recently. And my answer was, if you if you don't need fresh data, like a blog, you know, like if you if you publish, if you're running a news site, and somebody edits content, there's a typo or a correction or some emergency report with an update or something like that.", "tokens": [400, 291, 434, 558, 281, 1029, 11, 562, 307, 309, 1101, 30, 1133, 307, 309, 5324, 30, 1436, 370, 1580, 2351, 466, 341, 294, 264, 2699, 76, 7183, 11, 411, 2269, 3938, 13, 400, 452, 1867, 390, 11, 498, 291, 498, 291, 500, 380, 643, 4451, 1412, 11, 411, 257, 6968, 11, 291, 458, 11, 411, 498, 291, 498, 291, 11374, 11, 498, 291, 434, 2614, 257, 2583, 3621, 11, 293, 2618, 41752, 2701, 11, 456, 311, 257, 2125, 78, 420, 257, 19984, 420, 512, 7473, 2275, 365, 364, 5623, 420, 746, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.1900762500184955, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.000282391527434811}, {"id": 385, "seek": 206600, "start": 2066.0, "end": 2078.0, "text": " And you want it to instantly be reflected when somebody loads the page, then then server side rendering is going to be a good approach. So a server rendered route would would be a good fit for that.", "tokens": [400, 291, 528, 309, 281, 13518, 312, 15502, 562, 2618, 12668, 264, 3028, 11, 550, 550, 7154, 1252, 22407, 307, 516, 281, 312, 257, 665, 3109, 13, 407, 257, 7154, 28748, 7955, 576, 576, 312, 257, 665, 3318, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.1963897705078125, "compression_ratio": 1.4558823529411764, "no_speech_prob": 8.887809235602617e-05}, {"id": 386, "seek": 207800, "start": 2078.0, "end": 2105.0, "text": " But if it's a blog, and you're like, okay, I published something, and within within a few minutes, it's live, then I would go with a pre rendered route. And the reason is, because we've discussed this before, with a pre rendered route, you have the ability to essentially parse don't validate your initial route data with any errors being parsed out of the happy path to a build error.", "tokens": [583, 498, 309, 311, 257, 6968, 11, 293, 291, 434, 411, 11, 1392, 11, 286, 6572, 746, 11, 293, 1951, 1951, 257, 1326, 2077, 11, 309, 311, 1621, 11, 550, 286, 576, 352, 365, 257, 659, 28748, 7955, 13, 400, 264, 1778, 307, 11, 570, 321, 600, 7152, 341, 949, 11, 365, 257, 659, 28748, 7955, 11, 291, 362, 264, 3485, 281, 4476, 48377, 500, 380, 29562, 428, 5883, 7955, 1412, 365, 604, 13603, 885, 21156, 292, 484, 295, 264, 2055, 3100, 281, 257, 1322, 6713, 13], "temperature": 0.0, "avg_logprob": -0.20443828289325422, "compression_ratio": 1.6885964912280702, "no_speech_prob": 1.0451242815179285e-05}, {"id": 387, "seek": 210500, "start": 2105.0, "end": 2126.0, "text": " Whereas with a server rendered route, it gets parsed out to a 500 error. So that's one thing you have to deal with. Now, if you're building a CRUD application, or like things happen, and you can't guarantee that every service will always be up, right. So you do have to deal with that possibility.", "tokens": [13813, 365, 257, 7154, 28748, 7955, 11, 309, 2170, 21156, 292, 484, 281, 257, 5923, 6713, 13, 407, 300, 311, 472, 551, 291, 362, 281, 2028, 365, 13, 823, 11, 498, 291, 434, 2390, 257, 14123, 9438, 3861, 11, 420, 411, 721, 1051, 11, 293, 291, 393, 380, 10815, 300, 633, 2643, 486, 1009, 312, 493, 11, 558, 13, 407, 291, 360, 362, 281, 2028, 365, 300, 7959, 13], "temperature": 0.0, "avg_logprob": -0.14840145633645255, "compression_ratio": 1.5076142131979695, "no_speech_prob": 0.00011412047751946375}, {"id": 388, "seek": 212600, "start": 2126.0, "end": 2141.0, "text": " But if it's just like a little blog, or a portfolio site, or something like that, it's just like, you don't want to have to put that much thought into how you respond to those types of errors, you're just like, well, if something's wrong, then I'll just build it later or try to fix it.", "tokens": [583, 498, 309, 311, 445, 411, 257, 707, 6968, 11, 420, 257, 12583, 3621, 11, 420, 746, 411, 300, 11, 309, 311, 445, 411, 11, 291, 500, 380, 528, 281, 362, 281, 829, 300, 709, 1194, 666, 577, 291, 4196, 281, 729, 3467, 295, 13603, 11, 291, 434, 445, 411, 11, 731, 11, 498, 746, 311, 2085, 11, 550, 286, 603, 445, 1322, 309, 1780, 420, 853, 281, 3191, 309, 13], "temperature": 0.0, "avg_logprob": -0.14848302205403646, "compression_ratio": 1.5888888888888888, "no_speech_prob": 0.00026946913567371666}, {"id": 389, "seek": 214100, "start": 2141.0, "end": 2156.0, "text": " And you can mix and match them. For instance, if you have a news website, then you can use server rendered routes for the content. But the about page can be a pre rendered route.", "tokens": [400, 291, 393, 2890, 293, 2995, 552, 13, 1171, 5197, 11, 498, 291, 362, 257, 2583, 3144, 11, 550, 291, 393, 764, 7154, 28748, 18242, 337, 264, 2701, 13, 583, 264, 466, 3028, 393, 312, 257, 659, 28748, 7955, 13], "temperature": 0.0, "avg_logprob": -0.2421279407682873, "compression_ratio": 1.5555555555555556, "no_speech_prob": 2.6271598471794277e-05}, {"id": 390, "seek": 214100, "start": 2156.0, "end": 2158.0, "text": " Yeah, exactly. Exactly.", "tokens": [865, 11, 2293, 13, 7587, 13], "temperature": 0.0, "avg_logprob": -0.2421279407682873, "compression_ratio": 1.5555555555555556, "no_speech_prob": 2.6271598471794277e-05}, {"id": 391, "seek": 214100, "start": 2158.0, "end": 2167.0, "text": " And can you also have like, plain elm pages, like the way that we currently do it without elm pages, just a blank HTML.", "tokens": [400, 393, 291, 611, 362, 411, 11, 11121, 806, 76, 7183, 11, 411, 264, 636, 300, 321, 4362, 360, 309, 1553, 806, 76, 7183, 11, 445, 257, 8247, 17995, 13], "temperature": 0.0, "avg_logprob": -0.2421279407682873, "compression_ratio": 1.5555555555555556, "no_speech_prob": 2.6271598471794277e-05}, {"id": 392, "seek": 216700, "start": 2167.0, "end": 2194.0, "text": " Right. In other words, a client side rendered page, you cannot, in theory, it would be definitely possible to do that. But at the moment, elm pages does not have that. So you know, you can have a page with an empty back end task with a back end task that's just back end task to succeed, empty record or whatever. But, but yeah, there's no feature that it will still fetch that empty data before it loads your page.", "tokens": [1779, 13, 682, 661, 2283, 11, 257, 6423, 1252, 28748, 3028, 11, 291, 2644, 11, 294, 5261, 11, 309, 576, 312, 2138, 1944, 281, 360, 300, 13, 583, 412, 264, 1623, 11, 806, 76, 7183, 775, 406, 362, 300, 13, 407, 291, 458, 11, 291, 393, 362, 257, 3028, 365, 364, 6707, 646, 917, 5633, 365, 257, 646, 917, 5633, 300, 311, 445, 646, 917, 5633, 281, 7754, 11, 6707, 2136, 420, 2035, 13, 583, 11, 457, 1338, 11, 456, 311, 572, 4111, 300, 309, 486, 920, 23673, 300, 6707, 1412, 949, 309, 12668, 428, 3028, 13], "temperature": 0.0, "avg_logprob": -0.2538109581069191, "compression_ratio": 1.7219917012448134, "no_speech_prob": 0.00015597768651787192}, {"id": 393, "seek": 219400, "start": 2194.0, "end": 2219.0, "text": " Also, something I've been wondering, like, ever since we started recording is like, can you have, can you mix the pre rendered routes, and the server rendered routes into one in the sense that can you have a back end task that resolves a build time, but that is then used for a server rendered routes.", "tokens": [2743, 11, 746, 286, 600, 668, 6359, 11, 411, 11, 1562, 1670, 321, 1409, 6613, 307, 411, 11, 393, 291, 362, 11, 393, 291, 2890, 264, 659, 28748, 18242, 11, 293, 264, 7154, 28748, 18242, 666, 472, 294, 264, 2020, 300, 393, 291, 362, 257, 646, 917, 5633, 300, 7923, 977, 257, 1322, 565, 11, 457, 300, 307, 550, 1143, 337, 257, 7154, 28748, 18242, 13], "temperature": 0.0, "avg_logprob": -0.24187562125069753, "compression_ratio": 1.7705882352941176, "no_speech_prob": 0.0004238463588990271}, {"id": 394, "seek": 221900, "start": 2219.0, "end": 2230.0, "text": " So like, part of the things that I need for this page are computed the build time and other things are computed at render time. Is it possible to have both?", "tokens": [407, 411, 11, 644, 295, 264, 721, 300, 286, 643, 337, 341, 3028, 366, 40610, 264, 1322, 565, 293, 661, 721, 366, 40610, 412, 15529, 565, 13, 1119, 309, 1944, 281, 362, 1293, 30], "temperature": 0.0, "avg_logprob": -0.2619386974133943, "compression_ratio": 1.3565217391304347, "no_speech_prob": 0.0002652878174558282}, {"id": 395, "seek": 223000, "start": 2230.0, "end": 2252.0, "text": " That is not possible. But I mean, you could always like have an elm pages script that pre compute some data and use a codec to deserialize it or but yeah, so the options are, there's one we haven't talked about actually pre rendered route, which is the back end task data is resolved at build time.", "tokens": [663, 307, 406, 1944, 13, 583, 286, 914, 11, 291, 727, 1009, 411, 362, 364, 806, 76, 7183, 5755, 300, 659, 14722, 512, 1412, 293, 764, 257, 3089, 66, 281, 730, 260, 831, 1125, 309, 420, 457, 1338, 11, 370, 264, 3956, 366, 11, 456, 311, 472, 321, 2378, 380, 2825, 466, 767, 659, 28748, 7955, 11, 597, 307, 264, 646, 917, 5633, 1412, 307, 20772, 412, 1322, 565, 13], "temperature": 0.0, "avg_logprob": -0.21588035531946131, "compression_ratio": 1.49, "no_speech_prob": 1.3006186236452777e-05}, {"id": 396, "seek": 225200, "start": 2252.0, "end": 2263.0, "text": " And then of course you, you have a standard elm architecture. So you can also use your init update to perform HTTP requests and that sort of thing.", "tokens": [400, 550, 295, 1164, 291, 11, 291, 362, 257, 3832, 806, 76, 9482, 13, 407, 291, 393, 611, 764, 428, 3157, 5623, 281, 2042, 33283, 12475, 293, 300, 1333, 295, 551, 13], "temperature": 0.0, "avg_logprob": -0.22754303614298502, "compression_ratio": 1.2457627118644068, "no_speech_prob": 7.889127118687611e-06}, {"id": 397, "seek": 226300, "start": 2263.0, "end": 2289.0, "text": " There's also server rendered routes, which we've talked about. And then there is something called pre render with fallback. So pre render with fallback will pre render a set of pages for the route. But then it will dynamically execute the back end task for that route for anything that wasn't a pre computed page in there.", "tokens": [821, 311, 611, 7154, 28748, 18242, 11, 597, 321, 600, 2825, 466, 13, 400, 550, 456, 307, 746, 1219, 659, 15529, 365, 2100, 3207, 13, 407, 659, 15529, 365, 2100, 3207, 486, 659, 15529, 257, 992, 295, 7183, 337, 264, 7955, 13, 583, 550, 309, 486, 43492, 14483, 264, 646, 917, 5633, 337, 300, 7955, 337, 1340, 300, 2067, 380, 257, 659, 40610, 3028, 294, 456, 13], "temperature": 0.0, "avg_logprob": -0.20848610031772669, "compression_ratio": 1.7037037037037037, "no_speech_prob": 4.222598363412544e-06}, {"id": 398, "seek": 228900, "start": 2289.0, "end": 2305.0, "text": " So you basically give it a list of pages, it's actually a back end task of a list of of pages. And then it's going to go so like for example, your most popular or recent articles could be pre read pre rendered.", "tokens": [407, 291, 1936, 976, 309, 257, 1329, 295, 7183, 11, 309, 311, 767, 257, 646, 917, 5633, 295, 257, 1329, 295, 295, 7183, 13, 400, 550, 309, 311, 516, 281, 352, 370, 411, 337, 1365, 11, 428, 881, 3743, 420, 5162, 11290, 727, 312, 659, 1401, 659, 28748, 13], "temperature": 0.0, "avg_logprob": -0.19811689628745024, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.00014424987602978945}, {"id": 399, "seek": 230500, "start": 2305.0, "end": 2322.0, "text": " And then your archive, which you know, maybe your archive from 1932 is not requested very frequently. So you don't want your entire build to have to build your entire archive. But if somebody requests it, then you build it.", "tokens": [400, 550, 428, 23507, 11, 597, 291, 458, 11, 1310, 428, 23507, 490, 1294, 11440, 307, 406, 16436, 588, 10374, 13, 407, 291, 500, 380, 528, 428, 2302, 1322, 281, 362, 281, 1322, 428, 2302, 23507, 13, 583, 498, 2618, 12475, 309, 11, 550, 291, 1322, 309, 13], "temperature": 0.0, "avg_logprob": -0.17080006232628456, "compression_ratio": 1.5067567567567568, "no_speech_prob": 5.307358878781088e-05}, {"id": 400, "seek": 232200, "start": 2322.0, "end": 2336.0, "text": " And once it's built, it will cache that. So pre render with fallback is interesting because it, it really depends on your hosting provider how it's going to be actually implemented.", "tokens": [400, 1564, 309, 311, 3094, 11, 309, 486, 19459, 300, 13, 407, 659, 15529, 365, 2100, 3207, 307, 1880, 570, 309, 11, 309, 534, 5946, 322, 428, 16058, 12398, 577, 309, 311, 516, 281, 312, 767, 12270, 13], "temperature": 0.0, "avg_logprob": -0.20881057920910062, "compression_ratio": 1.3407407407407408, "no_speech_prob": 0.00015355728100985289}, {"id": 401, "seek": 233600, "start": 2336.0, "end": 2357.0, "text": " So with with Netlify, they have something called DPR, distributed persistent rendering, which is like a weird kind of marketing buzzword, I guess. But they basically have this idea of, of exactly that pattern. And if you use a pre rendered, if you use pre render with fallback with the Netlify adapter, then that's that's what you get.", "tokens": [407, 365, 365, 6188, 75, 2505, 11, 436, 362, 746, 1219, 413, 15958, 11, 12631, 24315, 22407, 11, 597, 307, 411, 257, 3657, 733, 295, 6370, 13036, 7462, 11, 286, 2041, 13, 583, 436, 1936, 362, 341, 1558, 295, 11, 295, 2293, 300, 5102, 13, 400, 498, 291, 764, 257, 659, 28748, 11, 498, 291, 764, 659, 15529, 365, 2100, 3207, 365, 264, 6188, 75, 2505, 22860, 11, 550, 300, 311, 300, 311, 437, 291, 483, 13], "temperature": 0.0, "avg_logprob": -0.19556656590214483, "compression_ratio": 1.5654205607476634, "no_speech_prob": 5.390908336266875e-05}, {"id": 402, "seek": 235700, "start": 2357.0, "end": 2386.0, "text": " And you can define different ways to handle those types of routes with different hosting platforms through Elm pages adapters. Adapters are the way that you take you take an Elm pages app, when you run Elm pages build, it will run your adapter, which you define in the Elm pages config file, Elm pages dot config dot mjs to JavaScript file and you you can import an adapter.", "tokens": [400, 291, 393, 6964, 819, 2098, 281, 4813, 729, 3467, 295, 18242, 365, 819, 16058, 9473, 807, 2699, 76, 7183, 23169, 1559, 13, 1999, 569, 1559, 366, 264, 636, 300, 291, 747, 291, 747, 364, 2699, 76, 7183, 724, 11, 562, 291, 1190, 2699, 76, 7183, 1322, 11, 309, 486, 1190, 428, 22860, 11, 597, 291, 6964, 294, 264, 2699, 76, 7183, 6662, 3991, 11, 2699, 76, 7183, 5893, 6662, 5893, 275, 25530, 281, 15778, 3991, 293, 291, 291, 393, 974, 364, 22860, 13], "temperature": 0.0, "avg_logprob": -0.27368578043850983, "compression_ratio": 1.8067632850241546, "no_speech_prob": 2.668760316737462e-05}, {"id": 403, "seek": 238600, "start": 2386.0, "end": 2403.0, "text": " The default adapter in the starter is a Netlify adapter that will execute the the server rendered routes through Netlify functions. But there's a GitHub issue that I'll link to our GitHub discussion where people can share different kind of community adapters they've written.", "tokens": [440, 7576, 22860, 294, 264, 22465, 307, 257, 6188, 75, 2505, 22860, 300, 486, 14483, 264, 264, 7154, 28748, 18242, 807, 6188, 75, 2505, 6828, 13, 583, 456, 311, 257, 23331, 2734, 300, 286, 603, 2113, 281, 527, 23331, 5017, 689, 561, 393, 2073, 819, 733, 295, 1768, 23169, 1559, 436, 600, 3720, 13], "temperature": 0.0, "avg_logprob": -0.1736471077491497, "compression_ratio": 1.5363128491620113, "no_speech_prob": 0.0002913606585934758}, {"id": 404, "seek": 240300, "start": 2403.0, "end": 2422.0, "text": " And an adapter is basically you're, you're given like a JS file that is all of the compiled Elm code for running the server rendering function. But then you generate all the surrounding files for running it in your specific framework and hosting provider.", "tokens": [400, 364, 22860, 307, 1936, 291, 434, 11, 291, 434, 2212, 411, 257, 33063, 3991, 300, 307, 439, 295, 264, 36548, 2699, 76, 3089, 337, 2614, 264, 7154, 22407, 2445, 13, 583, 550, 291, 8460, 439, 264, 11498, 7098, 337, 2614, 309, 294, 428, 2685, 8388, 293, 16058, 12398, 13], "temperature": 0.0, "avg_logprob": -0.18055682712131077, "compression_ratio": 1.4739884393063585, "no_speech_prob": 9.314160706708208e-05}, {"id": 405, "seek": 242200, "start": 2422.0, "end": 2438.0, "text": " So like there's an express adapter that someone has been writing in the community and it has a way to wire it up through an express middleware. So it's just like a little bit of glue code that helps set things up for a specific provider and framework.", "tokens": [407, 411, 456, 311, 364, 5109, 22860, 300, 1580, 575, 668, 3579, 294, 264, 1768, 293, 309, 575, 257, 636, 281, 6234, 309, 493, 807, 364, 5109, 2808, 3039, 13, 407, 309, 311, 445, 411, 257, 707, 857, 295, 8998, 3089, 300, 3665, 992, 721, 493, 337, 257, 2685, 12398, 293, 8388, 13], "temperature": 0.0, "avg_logprob": -0.18010518130134134, "compression_ratio": 1.5128205128205128, "no_speech_prob": 7.030813139863312e-05}, {"id": 406, "seek": 242200, "start": 2438.0, "end": 2442.0, "text": " Gotcha. And provider is a hosting platform.", "tokens": [42109, 13, 400, 12398, 307, 257, 16058, 3663, 13], "temperature": 0.0, "avg_logprob": -0.18010518130134134, "compression_ratio": 1.5128205128205128, "no_speech_prob": 7.030813139863312e-05}, {"id": 407, "seek": 244200, "start": 2442.0, "end": 2465.0, "text": " Right, exactly. And, and which they, you know, they have specific file structures that they expect. And, you know, where, where do serverless functions live? Or, you know, if it's express, if it's, you know, maybe you're running it in some Kubernetes context that you need a particular thing, whatever it might be, you can you can build that into your adapter scripts.", "tokens": [1779, 11, 2293, 13, 400, 11, 293, 597, 436, 11, 291, 458, 11, 436, 362, 2685, 3991, 9227, 300, 436, 2066, 13, 400, 11, 291, 458, 11, 689, 11, 689, 360, 7154, 1832, 6828, 1621, 30, 1610, 11, 291, 458, 11, 498, 309, 311, 5109, 11, 498, 309, 311, 11, 291, 458, 11, 1310, 291, 434, 2614, 309, 294, 512, 23145, 4319, 300, 291, 643, 257, 1729, 551, 11, 2035, 309, 1062, 312, 11, 291, 393, 291, 393, 1322, 300, 666, 428, 22860, 23294, 13], "temperature": 0.0, "avg_logprob": -0.22393927413426087, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.0002453416818752885}, {"id": 408, "seek": 246500, "start": 2465.0, "end": 2480.0, "text": " But basically the contract is that you're given this bundled file that has the, the server rendering thing that handles all of the Elm pages server rendering. You give it like, here's the, here's the route. How am I responding?", "tokens": [583, 1936, 264, 4364, 307, 300, 291, 434, 2212, 341, 13882, 1493, 3991, 300, 575, 264, 11, 264, 7154, 22407, 551, 300, 18722, 439, 295, 264, 2699, 76, 7183, 7154, 22407, 13, 509, 976, 309, 411, 11, 510, 311, 264, 11, 510, 311, 264, 7955, 13, 1012, 669, 286, 16670, 30], "temperature": 0.0, "avg_logprob": -0.19439745412289516, "compression_ratio": 1.7732793522267207, "no_speech_prob": 0.00034595519537106156}, {"id": 409, "seek": 246500, "start": 2480.0, "end": 2493.0, "text": " And it gives you the response back. And then you have to do something with that response. So if it's in express, how do you take a response and turn that into the right data that express expects for a response?", "tokens": [400, 309, 2709, 291, 264, 4134, 646, 13, 400, 550, 291, 362, 281, 360, 746, 365, 300, 4134, 13, 407, 498, 309, 311, 294, 5109, 11, 577, 360, 291, 747, 257, 4134, 293, 1261, 300, 666, 264, 558, 1412, 300, 5109, 33280, 337, 257, 4134, 30], "temperature": 0.0, "avg_logprob": -0.19439745412289516, "compression_ratio": 1.7732793522267207, "no_speech_prob": 0.00034595519537106156}, {"id": 410, "seek": 249300, "start": 2493.0, "end": 2506.0, "text": " And how do you take the incoming HTTP requests and turn that into the format that Elm pages expects for an HTTP request with the HTTP method and the incoming URL? So that that's what an adapter is.", "tokens": [400, 577, 360, 291, 747, 264, 22341, 33283, 12475, 293, 1261, 300, 666, 264, 7877, 300, 2699, 76, 7183, 33280, 337, 364, 33283, 5308, 365, 264, 33283, 3170, 293, 264, 22341, 12905, 30, 407, 300, 300, 311, 437, 364, 22860, 307, 13], "temperature": 0.0, "avg_logprob": -0.23219194568571497, "compression_ratio": 1.4942528735632183, "no_speech_prob": 5.561970829148777e-05}, {"id": 411, "seek": 249300, "start": 2506.0, "end": 2510.0, "text": " Okay, are these fairly simple? Or are they pretty complicated?", "tokens": [1033, 11, 366, 613, 6457, 2199, 30, 1610, 366, 436, 1238, 6179, 30], "temperature": 0.0, "avg_logprob": -0.23219194568571497, "compression_ratio": 1.4942528735632183, "no_speech_prob": 5.561970829148777e-05}, {"id": 412, "seek": 251000, "start": 2510.0, "end": 2525.0, "text": " They're pretty simple. I mean, the the the contract is pretty simple, because it's just saying, I need the incoming HTTP request in a specific format, I give you a function that you call with that specific format of data for the HTTP request.", "tokens": [814, 434, 1238, 2199, 13, 286, 914, 11, 264, 264, 264, 4364, 307, 1238, 2199, 11, 570, 309, 311, 445, 1566, 11, 286, 643, 264, 22341, 33283, 5308, 294, 257, 2685, 7877, 11, 286, 976, 291, 257, 2445, 300, 291, 818, 365, 300, 2685, 7877, 295, 1412, 337, 264, 33283, 5308, 13], "temperature": 0.0, "avg_logprob": -0.18396929332188197, "compression_ratio": 1.5612903225806452, "no_speech_prob": 0.000511227932292968}, {"id": 413, "seek": 252500, "start": 2525.0, "end": 2540.0, "text": " So you might have to adapt your frameworks, you know, express or Node.js or Coa or whatever it might be, you might have to turn that into a different sort of JSON object for what Elm pages expects. And then you have to turn it into a response object.", "tokens": [407, 291, 1062, 362, 281, 6231, 428, 29834, 11, 291, 458, 11, 5109, 420, 38640, 13, 25530, 420, 3066, 64, 420, 2035, 309, 1062, 312, 11, 291, 1062, 362, 281, 1261, 300, 666, 257, 819, 1333, 295, 31828, 2657, 337, 437, 2699, 76, 7183, 33280, 13, 400, 550, 291, 362, 281, 1261, 309, 666, 257, 4134, 2657, 13], "temperature": 0.0, "avg_logprob": -0.21445481530551253, "compression_ratio": 1.7816091954022988, "no_speech_prob": 1.788055897122831e-06}, {"id": 414, "seek": 252500, "start": 2540.0, "end": 2550.0, "text": " And then you have to put some files in a specific place. But the part that Elm pages gives you is, here's a function to, to call the rendering and get a response back, right? And then you just need to wire that up.", "tokens": [400, 550, 291, 362, 281, 829, 512, 7098, 294, 257, 2685, 1081, 13, 583, 264, 644, 300, 2699, 76, 7183, 2709, 291, 307, 11, 510, 311, 257, 2445, 281, 11, 281, 818, 264, 22407, 293, 483, 257, 4134, 646, 11, 558, 30, 400, 550, 291, 445, 643, 281, 6234, 300, 493, 13], "temperature": 0.0, "avg_logprob": -0.21445481530551253, "compression_ratio": 1.7816091954022988, "no_speech_prob": 1.788055897122831e-06}, {"id": 415, "seek": 255000, "start": 2550.0, "end": 2563.0, "text": " Yeah, the hosting provider is now a big part of web development as well, right? And this is something that we now have to face if you at least you want to do server side rendering and serverless.", "tokens": [865, 11, 264, 16058, 12398, 307, 586, 257, 955, 644, 295, 3670, 3250, 382, 731, 11, 558, 30, 400, 341, 307, 746, 300, 321, 586, 362, 281, 1851, 498, 291, 412, 1935, 291, 528, 281, 360, 7154, 1252, 22407, 293, 7154, 1832, 13], "temperature": 0.0, "avg_logprob": -0.21788217525671025, "compression_ratio": 1.6141078838174274, "no_speech_prob": 1.2606696145667229e-05}, {"id": 416, "seek": 255000, "start": 2563.0, "end": 2567.0, "text": " Yes, maybe we should talk a bit about the use cases.", "tokens": [1079, 11, 1310, 321, 820, 751, 257, 857, 466, 264, 764, 3331, 13], "temperature": 0.0, "avg_logprob": -0.21788217525671025, "compression_ratio": 1.6141078838174274, "no_speech_prob": 1.2606696145667229e-05}, {"id": 417, "seek": 255000, "start": 2567.0, "end": 2575.0, "text": " Yeah, I was thinking like, we still haven't said like, what is it for? What is it good for? We said where it was complicated. But that's it.", "tokens": [865, 11, 286, 390, 1953, 411, 11, 321, 920, 2378, 380, 848, 411, 11, 437, 307, 309, 337, 30, 708, 307, 309, 665, 337, 30, 492, 848, 689, 309, 390, 6179, 13, 583, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.21788217525671025, "compression_ratio": 1.6141078838174274, "no_speech_prob": 1.2606696145667229e-05}, {"id": 418, "seek": 257500, "start": 2575.0, "end": 2592.0, "text": " Exactly. Yeah, right. So yeah, like, what would you actually do? So for example, if you have a CRUD applicant, like if you want to have an admin panel where you can manage users, manage user permissions, you know, send some forms to make a database request.", "tokens": [7587, 13, 865, 11, 558, 13, 407, 1338, 11, 411, 11, 437, 576, 291, 767, 360, 30, 407, 337, 1365, 11, 498, 291, 362, 257, 14123, 9438, 4988, 299, 394, 11, 411, 498, 291, 528, 281, 362, 364, 24236, 4831, 689, 291, 393, 3067, 5022, 11, 3067, 4195, 32723, 11, 291, 458, 11, 2845, 512, 6422, 281, 652, 257, 8149, 5308, 13], "temperature": 0.0, "avg_logprob": -0.19489960236982865, "compression_ratio": 1.4519774011299436, "no_speech_prob": 0.0002531370846554637}, {"id": 419, "seek": 259200, "start": 2592.0, "end": 2610.0, "text": " And, you know, or if you have an e commerce site, and you want to manage back office things, orders, inventory, forms that do that, right, v2 would not have supported those kinds of use cases, at least it wouldn't have given you much help there, it wouldn't have been a great fit for that, right?", "tokens": [400, 11, 291, 458, 11, 420, 498, 291, 362, 364, 308, 26320, 3621, 11, 293, 291, 528, 281, 3067, 646, 3398, 721, 11, 9470, 11, 14228, 11, 6422, 300, 360, 300, 11, 558, 11, 371, 17, 576, 406, 362, 8104, 729, 3685, 295, 764, 3331, 11, 412, 1935, 309, 2759, 380, 362, 2212, 291, 709, 854, 456, 11, 309, 2759, 380, 362, 668, 257, 869, 3318, 337, 300, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.20889916737874348, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.0009696061606518924}, {"id": 420, "seek": 261000, "start": 2610.0, "end": 2622.0, "text": " Because if you're resolving your data, at build time, when your data is mostly dynamic, and it depends on the user session, the logged in user, it doesn't really help you there.", "tokens": [1436, 498, 291, 434, 49940, 428, 1412, 11, 412, 1322, 565, 11, 562, 428, 1412, 307, 5240, 8546, 11, 293, 309, 5946, 322, 264, 4195, 5481, 11, 264, 27231, 294, 4195, 11, 309, 1177, 380, 534, 854, 291, 456, 13], "temperature": 0.0, "avg_logprob": -0.18988222890085987, "compression_ratio": 1.6173469387755102, "no_speech_prob": 0.00010554219625191763}, {"id": 421, "seek": 261000, "start": 2622.0, "end": 2633.0, "text": " Yeah, so you would either need to rebuild like, continuously, or you would need to do a lot of the dynamics things in on the client anyway.", "tokens": [865, 11, 370, 291, 576, 2139, 643, 281, 16877, 411, 11, 15684, 11, 420, 291, 576, 643, 281, 360, 257, 688, 295, 264, 15679, 721, 294, 322, 264, 6423, 4033, 13], "temperature": 0.0, "avg_logprob": -0.18988222890085987, "compression_ratio": 1.6173469387755102, "no_speech_prob": 0.00010554219625191763}, {"id": 422, "seek": 263300, "start": 2633.0, "end": 2652.0, "text": " Right? Yeah, it just wouldn't make sense. Also, if you have a conceptually infinite number of routes, you can't even pre render all of those routes. So it just wasn't really possible. So now with v3, when you define when you define a pre rendered route, you do not have access to the request.", "tokens": [1779, 30, 865, 11, 309, 445, 2759, 380, 652, 2020, 13, 2743, 11, 498, 291, 362, 257, 3410, 671, 13785, 1230, 295, 18242, 11, 291, 393, 380, 754, 659, 15529, 439, 295, 729, 18242, 13, 407, 309, 445, 2067, 380, 534, 1944, 13, 407, 586, 365, 371, 18, 11, 562, 291, 6964, 562, 291, 6964, 257, 659, 28748, 7955, 11, 291, 360, 406, 362, 2105, 281, 264, 5308, 13], "temperature": 0.0, "avg_logprob": -0.1571269884501418, "compression_ratio": 1.5783783783783785, "no_speech_prob": 6.605175440199673e-05}, {"id": 423, "seek": 265200, "start": 2652.0, "end": 2679.0, "text": " But when you define a server rendered route, you do have access to the request. And the request allows you to get the method of the request, the URL, the query params. So you know, in a in a pre rendered route, somebody can load that page with query params, but you don't have them until the page hydrates, because the page is rendered before a request is made. So conceptually, they don't exist at that point. But for a server rendered route, they do exist.", "tokens": [583, 562, 291, 6964, 257, 7154, 28748, 7955, 11, 291, 360, 362, 2105, 281, 264, 5308, 13, 400, 264, 5308, 4045, 291, 281, 483, 264, 3170, 295, 264, 5308, 11, 264, 12905, 11, 264, 14581, 971, 4070, 13, 407, 291, 458, 11, 294, 257, 294, 257, 659, 28748, 7955, 11, 2618, 393, 3677, 300, 3028, 365, 14581, 971, 4070, 11, 457, 291, 500, 380, 362, 552, 1826, 264, 3028, 5796, 12507, 11, 570, 264, 3028, 307, 28748, 949, 257, 5308, 307, 1027, 13, 407, 3410, 671, 11, 436, 500, 380, 2514, 412, 300, 935, 13, 583, 337, 257, 7154, 28748, 7955, 11, 436, 360, 2514, 13], "temperature": 0.0, "avg_logprob": -0.1810938228260387, "compression_ratio": 1.8925619834710743, "no_speech_prob": 5.144104943610728e-05}, {"id": 424, "seek": 267900, "start": 2679.0, "end": 2682.0, "text": " Yeah, you also have access to cookies. Right?", "tokens": [865, 11, 291, 611, 362, 2105, 281, 13670, 13, 1779, 30], "temperature": 0.0, "avg_logprob": -0.18990139125548688, "compression_ratio": 1.7076923076923076, "no_speech_prob": 0.0010321561712771654}, {"id": 425, "seek": 267900, "start": 2682.0, "end": 2708.0, "text": " That's right. You have access to all of the headers, including cookies. And there are some high level abstractions for accessing and setting cookies. And that's a huge part of v3 is that design and that philosophy of using the platform because I believe it really makes things easier. Like I believe that cookie based session management is way easier than JIT token, JWT token based authentication.", "tokens": [663, 311, 558, 13, 509, 362, 2105, 281, 439, 295, 264, 45101, 11, 3009, 13670, 13, 400, 456, 366, 512, 1090, 1496, 12649, 626, 337, 26440, 293, 3287, 13670, 13, 400, 300, 311, 257, 2603, 644, 295, 371, 18, 307, 300, 1715, 293, 300, 10675, 295, 1228, 264, 3663, 570, 286, 1697, 309, 534, 1669, 721, 3571, 13, 1743, 286, 1697, 300, 14417, 2361, 5481, 4592, 307, 636, 3571, 813, 508, 3927, 14862, 11, 49885, 51, 14862, 2361, 26643, 13], "temperature": 0.0, "avg_logprob": -0.18990139125548688, "compression_ratio": 1.7076923076923076, "no_speech_prob": 0.0010321561712771654}, {"id": 426, "seek": 270800, "start": 2708.0, "end": 2713.0, "text": " Oh, okay. But could you use JWT tokens? If you wanted to?", "tokens": [876, 11, 1392, 13, 583, 727, 291, 764, 49885, 51, 22667, 30, 759, 291, 1415, 281, 30], "temperature": 0.0, "avg_logprob": -0.2510341689700172, "compression_ratio": 0.95, "no_speech_prob": 0.001032173866406083}, {"id": 427, "seek": 271300, "start": 2713.0, "end": 2741.0, "text": " You could, but I mean, I don't, I don't think you'd want to. But so yeah, for security reasons to like there are some advantages to cookie based authentication. So for example, in the cookie API in on pages v3, the default strategy for cookies is HTTP only, because that's like a common best practice. And so you can opt into cookies that are visible to JS, but by default, they will only be available through HTTP.", "tokens": [509, 727, 11, 457, 286, 914, 11, 286, 500, 380, 11, 286, 500, 380, 519, 291, 1116, 528, 281, 13, 583, 370, 1338, 11, 337, 3825, 4112, 281, 411, 456, 366, 512, 14906, 281, 14417, 2361, 26643, 13, 407, 337, 1365, 11, 294, 264, 14417, 9362, 294, 322, 7183, 371, 18, 11, 264, 7576, 5206, 337, 13670, 307, 33283, 787, 11, 570, 300, 311, 411, 257, 2689, 1151, 3124, 13, 400, 370, 291, 393, 2427, 666, 13670, 300, 366, 8974, 281, 33063, 11, 457, 538, 7576, 11, 436, 486, 787, 312, 2435, 807, 33283, 13], "temperature": 0.0, "avg_logprob": -0.2050671432957505, "compression_ratio": 1.5961538461538463, "no_speech_prob": 0.00015117062139324844}, {"id": 428, "seek": 274100, "start": 2741.0, "end": 2767.0, "text": " So if you have a server rendered route, and you manage the user through a session, then that cookie, you can't, if somebody injects some cross site scripting attack script in your in your page, which of course, you'd prefer not to happen, but that's one possible event attack vector, they would not have access to the HTTP only cookies. That's what an HTTP only cookie means.", "tokens": [407, 498, 291, 362, 257, 7154, 28748, 7955, 11, 293, 291, 3067, 264, 4195, 807, 257, 5481, 11, 550, 300, 14417, 11, 291, 393, 380, 11, 498, 2618, 10711, 82, 512, 3278, 3621, 5755, 278, 2690, 5755, 294, 428, 294, 428, 3028, 11, 597, 295, 1164, 11, 291, 1116, 4382, 406, 281, 1051, 11, 457, 300, 311, 472, 1944, 2280, 2690, 8062, 11, 436, 576, 406, 362, 2105, 281, 264, 33283, 787, 13670, 13, 663, 311, 437, 364, 33283, 787, 14417, 1355, 13], "temperature": 0.0, "avg_logprob": -0.18698622166425333, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.001098706852644682}, {"id": 429, "seek": 276700, "start": 2767.0, "end": 2796.0, "text": " When you do whatever it is document cookies, it show up there. So but when you make a request to to a server at the same origin, it is accessible. Whereas if you make a third party request, the default security policy for for on pages cookies and for for regular cookies, if you don't explicitly set one, is that those cookies will not be sent to external origins only to the original origin.", "tokens": [1133, 291, 360, 2035, 309, 307, 4166, 13670, 11, 309, 855, 493, 456, 13, 407, 457, 562, 291, 652, 257, 5308, 281, 281, 257, 7154, 412, 264, 912, 4957, 11, 309, 307, 9515, 13, 13813, 498, 291, 652, 257, 2636, 3595, 5308, 11, 264, 7576, 3825, 3897, 337, 337, 322, 7183, 13670, 293, 337, 337, 3890, 13670, 11, 498, 291, 500, 380, 20803, 992, 472, 11, 307, 300, 729, 13670, 486, 406, 312, 2279, 281, 8320, 22721, 787, 281, 264, 3380, 4957, 13], "temperature": 0.0, "avg_logprob": -0.19973682535105738, "compression_ratio": 1.7657657657657657, "no_speech_prob": 0.015423525124788284}, {"id": 430, "seek": 279600, "start": 2796.0, "end": 2825.0, "text": " So that means that, you know, it's just less to think about for for for the attack vectors for people trying to take your cookies. So because if someone gets your session cookie, then they are you right, they've successfully hijacked your cookie, if they if they get that cookie, then then they're you. So you don't want that to happen. But, uh, but yeah, so with on pages v3, you have access to cookies, there's a there's a session API that even manages key value pairs of cookies.", "tokens": [407, 300, 1355, 300, 11, 291, 458, 11, 309, 311, 445, 1570, 281, 519, 466, 337, 337, 337, 264, 2690, 18875, 337, 561, 1382, 281, 747, 428, 13670, 13, 407, 570, 498, 1580, 2170, 428, 5481, 14417, 11, 550, 436, 366, 291, 558, 11, 436, 600, 10727, 10625, 25949, 428, 14417, 11, 498, 436, 498, 436, 483, 300, 14417, 11, 550, 550, 436, 434, 291, 13, 407, 291, 500, 380, 528, 300, 281, 1051, 13, 583, 11, 2232, 11, 457, 1338, 11, 370, 365, 322, 7183, 371, 18, 11, 291, 362, 2105, 281, 13670, 11, 456, 311, 257, 456, 311, 257, 5481, 9362, 300, 754, 22489, 2141, 2158, 15494, 295, 13670, 13], "temperature": 0.0, "avg_logprob": -0.22460429421786604, "compression_ratio": 1.79182156133829, "no_speech_prob": 0.0006361713167279959}, {"id": 431, "seek": 282500, "start": 2825.0, "end": 2850.0, "text": " So it will serialize those key value pairs of strings for you in in the cookie. And you can give it a list of secrets. It's actually a back end task of a list of secrets because that back end task, you can do environment variables, because you might want to, you probably want to pull in an environment variable and environment variable is accessible through a back end task.", "tokens": [407, 309, 486, 17436, 1125, 729, 2141, 2158, 15494, 295, 13985, 337, 291, 294, 294, 264, 14417, 13, 400, 291, 393, 976, 309, 257, 1329, 295, 14093, 13, 467, 311, 767, 257, 646, 917, 5633, 295, 257, 1329, 295, 14093, 570, 300, 646, 917, 5633, 11, 291, 393, 360, 2823, 9102, 11, 570, 291, 1062, 528, 281, 11, 291, 1391, 528, 281, 2235, 294, 364, 2823, 7006, 293, 2823, 7006, 307, 9515, 807, 257, 646, 917, 5633, 13], "temperature": 0.0, "avg_logprob": -0.21874623182343272, "compression_ratio": 1.8472906403940887, "no_speech_prob": 0.00027802676777355373}, {"id": 432, "seek": 285000, "start": 2850.0, "end": 2879.0, "text": " So, so you can list out session secrets through these back end tasks, and you give it a list a back end task of a list of strings, and it will use those to rotate the signing. So what that means is, so first of all, signing, signing the session, what that means is it's not encrypted, it's signed, which means if you tamper with it, so there's like the raw key value data, you can you can look at the cookie and see the data that was encrypted.", "tokens": [407, 11, 370, 291, 393, 1329, 484, 5481, 14093, 807, 613, 646, 917, 9608, 11, 293, 291, 976, 309, 257, 1329, 257, 646, 917, 5633, 295, 257, 1329, 295, 13985, 11, 293, 309, 486, 764, 729, 281, 13121, 264, 13393, 13, 407, 437, 300, 1355, 307, 11, 370, 700, 295, 439, 11, 13393, 11, 13393, 264, 5481, 11, 437, 300, 1355, 307, 309, 311, 406, 36663, 11, 309, 311, 8175, 11, 597, 1355, 498, 291, 7677, 610, 365, 309, 11, 370, 456, 311, 411, 264, 8936, 2141, 2158, 1412, 11, 291, 393, 291, 393, 574, 412, 264, 14417, 293, 536, 264, 1412, 300, 390, 36663, 13], "temperature": 0.0, "avg_logprob": -0.2190251263705167, "compression_ratio": 1.9137931034482758, "no_speech_prob": 0.0023966319859027863}, {"id": 433, "seek": 287900, "start": 2879.0, "end": 2890.0, "text": " So you can see the data that was encoded there directly, I think it's like base 64 encoded maybe but you can basically 64 decode it and just see the what the values are.", "tokens": [407, 291, 393, 536, 264, 1412, 300, 390, 2058, 12340, 456, 3838, 11, 286, 519, 309, 311, 411, 3096, 12145, 2058, 12340, 1310, 457, 291, 393, 1936, 12145, 979, 1429, 309, 293, 445, 536, 264, 437, 264, 4190, 366, 13], "temperature": 0.0, "avg_logprob": -0.29336370121348987, "compression_ratio": 1.396694214876033, "no_speech_prob": 0.0014778749318793416}, {"id": 434, "seek": 289000, "start": 2890.0, "end": 2915.0, "text": " But if you change the values, this, the signature, the hash that signed it will not match. So you need the signing secret in order. So it's tamper proof. So, you know, if it says like user ID is 123 and you say, Ah ha ha user ID is 124, then the signing will will fail, it will not unsigned that session, and it will rotate through those.", "tokens": [583, 498, 291, 1319, 264, 4190, 11, 341, 11, 264, 13397, 11, 264, 22019, 300, 8175, 309, 486, 406, 2995, 13, 407, 291, 643, 264, 13393, 4054, 294, 1668, 13, 407, 309, 311, 7677, 610, 8177, 13, 407, 11, 291, 458, 11, 498, 309, 1619, 411, 4195, 7348, 307, 34466, 293, 291, 584, 11, 2438, 324, 324, 4195, 7348, 307, 2272, 19, 11, 550, 264, 13393, 486, 486, 3061, 11, 309, 486, 406, 2693, 16690, 300, 5481, 11, 293, 309, 486, 13121, 807, 729, 13], "temperature": 0.0, "avg_logprob": -0.26644801021961684, "compression_ratio": 1.6732673267326732, "no_speech_prob": 2.4299597498611547e-05}, {"id": 435, "seek": 291500, "start": 2915.0, "end": 2931.0, "text": " So if you give a list of secrets, it will use the first one in the list to sign new requests, but it will, if it fails to unsign it with the first one in the list, it will go through the rest of them to try unsigning so you can rotate through your signing secrets.", "tokens": [407, 498, 291, 976, 257, 1329, 295, 14093, 11, 309, 486, 764, 264, 700, 472, 294, 264, 1329, 281, 1465, 777, 12475, 11, 457, 309, 486, 11, 498, 309, 18199, 281, 2693, 788, 309, 365, 264, 700, 472, 294, 264, 1329, 11, 309, 486, 352, 807, 264, 1472, 295, 552, 281, 853, 2693, 9676, 370, 291, 393, 13121, 807, 428, 13393, 14093, 13], "temperature": 0.0, "avg_logprob": -0.2117059337559031, "compression_ratio": 1.8333333333333333, "no_speech_prob": 9.761293767951429e-05}, {"id": 436, "seek": 293100, "start": 2931.0, "end": 2955.0, "text": " So before you said that an admin page, for instance, was a good use case for the server side rendered, right? ssr. I don't know. I think that's what it is. Some combination of SS and yeah, I mean, it's better than our own pages review code gen naming. So far, so admin pages, for instance, are good for this.", "tokens": [407, 949, 291, 848, 300, 364, 24236, 3028, 11, 337, 5197, 11, 390, 257, 665, 764, 1389, 337, 264, 7154, 1252, 28748, 11, 558, 30, 262, 82, 81, 13, 286, 500, 380, 458, 13, 286, 519, 300, 311, 437, 309, 307, 13, 2188, 6562, 295, 12238, 293, 1338, 11, 286, 914, 11, 309, 311, 1101, 813, 527, 1065, 7183, 3131, 3089, 1049, 25290, 13, 407, 1400, 11, 370, 24236, 7183, 11, 337, 5197, 11, 366, 665, 337, 341, 13], "temperature": 0.0, "avg_logprob": -0.36463234223515156, "compression_ratio": 1.5634517766497462, "no_speech_prob": 4.539424480753951e-05}, {"id": 437, "seek": 295500, "start": 2955.0, "end": 2961.0, "text": " But is it better than a plain Elm client app? And if so, how?", "tokens": [583, 307, 309, 1101, 813, 257, 11121, 2699, 76, 6423, 724, 30, 400, 498, 370, 11, 577, 30], "temperature": 0.0, "avg_logprob": -0.20106356794183905, "compression_ratio": 0.9384615384615385, "no_speech_prob": 0.0011878048535436392}, {"id": 438, "seek": 296100, "start": 2961.0, "end": 2990.0, "text": " Right. Yeah, it's a great question. So it's a different architecture. And actually, we kind of we kind of talked about this in our writing great docs episode a little bit of being being clear and straightforward to help users make decisions about what tools to use in your documentation. And, and I talked a little bit about how I put a lot of thought with for Elm pages v3 into how do I help users make that decision between Elm land and Elm client?", "tokens": [1779, 13, 865, 11, 309, 311, 257, 869, 1168, 13, 407, 309, 311, 257, 819, 9482, 13, 400, 767, 11, 321, 733, 295, 321, 733, 295, 2825, 466, 341, 294, 527, 3579, 869, 45623, 3500, 257, 707, 857, 295, 885, 885, 1850, 293, 15325, 281, 854, 5022, 652, 5327, 466, 437, 3873, 281, 764, 294, 428, 14333, 13, 400, 11, 293, 286, 2825, 257, 707, 857, 466, 577, 286, 829, 257, 688, 295, 1194, 365, 337, 2699, 76, 7183, 371, 18, 666, 577, 360, 286, 854, 5022, 652, 300, 3537, 1296, 2699, 76, 2117, 293, 2699, 76, 6423, 30], "temperature": 0.0, "avg_logprob": -0.24015887732644683, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.00047279836144298315}, {"id": 439, "seek": 299000, "start": 2990.0, "end": 3013.0, "text": " Elm land, which is a new version of Elm SPA, or Elm pages on pages v3. Since since now there's a lot of overlap in the kinds of use cases they can handle, right, you could do an admin panel in Elm land, you could do an admin panel and in Elm pages v3. And to me that the answer is like, it depends on what kind of architecture you want to use.", "tokens": [2699, 76, 2117, 11, 597, 307, 257, 777, 3037, 295, 2699, 76, 8420, 32, 11, 420, 2699, 76, 7183, 322, 7183, 371, 18, 13, 4162, 1670, 586, 456, 311, 257, 688, 295, 19959, 294, 264, 3685, 295, 764, 3331, 436, 393, 4813, 11, 558, 11, 291, 727, 360, 364, 24236, 4831, 294, 2699, 76, 2117, 11, 291, 727, 360, 364, 24236, 4831, 293, 294, 2699, 76, 7183, 371, 18, 13, 400, 281, 385, 300, 264, 1867, 307, 411, 11, 309, 5946, 322, 437, 733, 295, 9482, 291, 528, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.2155990199038857, "compression_ratio": 1.6570048309178744, "no_speech_prob": 0.0007793414406478405}, {"id": 440, "seek": 301300, "start": 3013.0, "end": 3039.0, "text": " And of course, like, you know, do you want to use back end tasks to get that initial data? Do you want to do you want to use the platform and use cookie based authentication and use the URL as much as possible? Because that's like a key philosophy around Elm pages. It has this philosophy of use the platform. It has an API for submitting forms.", "tokens": [400, 295, 1164, 11, 411, 11, 291, 458, 11, 360, 291, 528, 281, 764, 646, 917, 9608, 281, 483, 300, 5883, 1412, 30, 1144, 291, 528, 281, 360, 291, 528, 281, 764, 264, 3663, 293, 764, 14417, 2361, 26643, 293, 764, 264, 12905, 382, 709, 382, 1944, 30, 1436, 300, 311, 411, 257, 2141, 10675, 926, 2699, 76, 7183, 13, 467, 575, 341, 10675, 295, 764, 264, 3663, 13, 467, 575, 364, 9362, 337, 31836, 6422, 13], "temperature": 0.0, "avg_logprob": -0.18298255072699654, "compression_ratio": 1.6507177033492824, "no_speech_prob": 0.0016228279564529657}, {"id": 441, "seek": 303900, "start": 3039.0, "end": 3044.0, "text": " Yeah, which we did a whole episode about like two actually.", "tokens": [865, 11, 597, 321, 630, 257, 1379, 3500, 466, 411, 732, 767, 13], "temperature": 0.0, "avg_logprob": -0.3608856762156767, "compression_ratio": 0.921875, "no_speech_prob": 0.0019265433074906468}, {"id": 442, "seek": 304400, "start": 3044.0, "end": 3073.0, "text": " Yeah, that's right. That's right. Exactly. So see those episodes for more about the form design. But basically, that's like a core philosophy of Elm pages is the web has forms. And so let's use forms because if we use things that the web has built in opinions on, we can piggyback on those to make things simpler for the developer to write and rely on these web standards to reduce the amount of boilerplate and, you know,", "tokens": [865, 11, 300, 311, 558, 13, 663, 311, 558, 13, 7587, 13, 407, 536, 729, 9313, 337, 544, 466, 264, 1254, 1715, 13, 583, 1936, 11, 300, 311, 411, 257, 4965, 10675, 295, 2699, 76, 7183, 307, 264, 3670, 575, 6422, 13, 400, 370, 718, 311, 764, 6422, 570, 498, 321, 764, 721, 300, 264, 3670, 575, 3094, 294, 11819, 322, 11, 321, 393, 39349, 3207, 322, 729, 281, 652, 721, 18587, 337, 264, 10754, 281, 2464, 293, 10687, 322, 613, 3670, 7787, 281, 5407, 264, 2372, 295, 39228, 37008, 293, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.1988597253356317, "compression_ratio": 1.6812749003984064, "no_speech_prob": 0.0004238380352035165}, {"id": 443, "seek": 307300, "start": 3073.0, "end": 3102.0, "text": " things just line up nicely. But, you know, if you buy into that philosophy of use the platform, and you want to work that way, that's great. If you want to kind of deviate from the platform, then you might not have a great experience with it, because it sort of is like designed to work really nicely, if you buy into this architecture and this philosophy. So that's what I realized. It's about buying into an approach.", "tokens": [721, 445, 1622, 493, 9594, 13, 583, 11, 291, 458, 11, 498, 291, 2256, 666, 300, 10675, 295, 764, 264, 3663, 11, 293, 291, 528, 281, 589, 300, 636, 11, 300, 311, 869, 13, 759, 291, 528, 281, 733, 295, 1905, 13024, 490, 264, 3663, 11, 550, 291, 1062, 406, 362, 257, 869, 1752, 365, 309, 11, 570, 309, 1333, 295, 307, 411, 4761, 281, 589, 534, 9594, 11, 498, 291, 2256, 666, 341, 9482, 293, 341, 10675, 13, 407, 300, 311, 437, 286, 5334, 13, 467, 311, 466, 6382, 666, 364, 3109, 13], "temperature": 0.0, "avg_logprob": -0.17611083205865355, "compression_ratio": 1.7314049586776858, "no_speech_prob": 0.0010003304341807961}, {"id": 444, "seek": 310200, "start": 3102.0, "end": 3108.0, "text": " Yeah, if you want to do the right things, then use Elm pages. If you want to do the wrong things, use something else. Gotcha.", "tokens": [865, 11, 498, 291, 528, 281, 360, 264, 558, 721, 11, 550, 764, 2699, 76, 7183, 13, 759, 291, 528, 281, 360, 264, 2085, 721, 11, 764, 746, 1646, 13, 42109, 13], "temperature": 0.0, "avg_logprob": -0.20208215713500977, "compression_ratio": 1.3440860215053763, "no_speech_prob": 0.001115955994464457}, {"id": 445, "seek": 310800, "start": 3108.0, "end": 3134.0, "text": " I mean, you know, there are, there are different, you can do very bespoke things, right. And, you know, if you're doing like a Google Docs thing with, you know, multiplayer editing, where people can see the cursors of other people and stuff, it's like, well, okay, like, use the platform is great. But what's the platform for that? Like, it doesn't really get me anything. Right. So,", "tokens": [286, 914, 11, 291, 458, 11, 456, 366, 11, 456, 366, 819, 11, 291, 393, 360, 588, 4097, 48776, 721, 11, 558, 13, 400, 11, 291, 458, 11, 498, 291, 434, 884, 411, 257, 3329, 16024, 82, 551, 365, 11, 291, 458, 11, 27325, 10000, 11, 689, 561, 393, 536, 264, 13946, 830, 295, 661, 561, 293, 1507, 11, 309, 311, 411, 11, 731, 11, 1392, 11, 411, 11, 764, 264, 3663, 307, 869, 13, 583, 437, 311, 264, 3663, 337, 300, 30, 1743, 11, 309, 1177, 380, 534, 483, 385, 1340, 13, 1779, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.21970100402832032, "compression_ratio": 1.6695278969957081, "no_speech_prob": 0.00016344721370842308}, {"id": 446, "seek": 310800, "start": 3134.0, "end": 3135.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.21970100402832032, "compression_ratio": 1.6695278969957081, "no_speech_prob": 0.00016344721370842308}, {"id": 447, "seek": 313500, "start": 3135.0, "end": 3164.0, "text": " Elm pages might not be a good, good choice there, right. But if it's like a, if it's an admin panel thing, so like, if you're trying to do a post, you know, hit the submit button on a form and create a new entry in an admin panel, then with Elm pages v3, like, it, there's a certain resilience because it works before the JavaScript hydrates, which might seem like nitpicking, but it's like a real thing.", "tokens": [2699, 76, 7183, 1062, 406, 312, 257, 665, 11, 665, 3922, 456, 11, 558, 13, 583, 498, 309, 311, 411, 257, 11, 498, 309, 311, 364, 24236, 4831, 551, 11, 370, 411, 11, 498, 291, 434, 1382, 281, 360, 257, 2183, 11, 291, 458, 11, 2045, 264, 10315, 2960, 322, 257, 1254, 293, 1884, 257, 777, 8729, 294, 364, 24236, 4831, 11, 550, 365, 2699, 76, 7183, 371, 18, 11, 411, 11, 309, 11, 456, 311, 257, 1629, 19980, 570, 309, 1985, 949, 264, 15778, 5796, 12507, 11, 597, 1062, 1643, 411, 10900, 79, 10401, 11, 457, 309, 311, 411, 257, 957, 551, 13], "temperature": 0.0, "avg_logprob": -0.1944882074991862, "compression_ratio": 1.6489795918367347, "no_speech_prob": 0.0005792632582597435}, {"id": 448, "seek": 316400, "start": 3164.0, "end": 3187.0, "text": " That, that, that can happen. So it's like one, one less thing to think about, like, you know, do I need to have the button disabled before the page is hydrated and stuff. And it's also a philosophy of, you know, it's a certain performance philosophy where it's, you know, about having your data result, you know, your initial data resolved to reduce loading spinners.", "tokens": [663, 11, 300, 11, 300, 393, 1051, 13, 407, 309, 311, 411, 472, 11, 472, 1570, 551, 281, 519, 466, 11, 411, 11, 291, 458, 11, 360, 286, 643, 281, 362, 264, 2960, 15191, 949, 264, 3028, 307, 44960, 293, 1507, 13, 400, 309, 311, 611, 257, 10675, 295, 11, 291, 458, 11, 309, 311, 257, 1629, 3389, 10675, 689, 309, 311, 11, 291, 458, 11, 466, 1419, 428, 1412, 1874, 11, 291, 458, 11, 428, 5883, 1412, 20772, 281, 5407, 15114, 6060, 2999, 13], "temperature": 0.0, "avg_logprob": -0.20781182707025764, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.0013884550426155329}, {"id": 449, "seek": 318700, "start": 3187.0, "end": 3209.0, "text": " But if you're not heavily optimizing, you know, for example, having your, your data center co-located with where your Elm pages app is hosted, you might not get those performance benefits. But if you do, then you, you don't have to incur the cost of making multiple round trips and incurring the latency costs between the client and your data center.", "tokens": [583, 498, 291, 434, 406, 10950, 40425, 11, 291, 458, 11, 337, 1365, 11, 1419, 428, 11, 428, 1412, 3056, 598, 12, 5842, 770, 365, 689, 428, 2699, 76, 7183, 724, 307, 19204, 11, 291, 1062, 406, 483, 729, 3389, 5311, 13, 583, 498, 291, 360, 11, 550, 291, 11, 291, 500, 380, 362, 281, 35774, 264, 2063, 295, 1455, 3866, 3098, 16051, 293, 35774, 2937, 264, 27043, 5497, 1296, 264, 6423, 293, 428, 1412, 3056, 13], "temperature": 0.0, "avg_logprob": -0.1784481707914376, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.00011774269660236314}, {"id": 450, "seek": 320900, "start": 3209.0, "end": 3229.0, "text": " Instead, you pay that very small latency cost that hopefully approaching zero latency cost of resolving data from the Elm pages backend to your data center. You do all the little round trip requests, which are very short to resolve all of your initial page data that you need.", "tokens": [7156, 11, 291, 1689, 300, 588, 1359, 27043, 2063, 300, 4696, 14908, 4018, 27043, 2063, 295, 49940, 1412, 490, 264, 2699, 76, 7183, 38087, 281, 428, 1412, 3056, 13, 509, 360, 439, 264, 707, 3098, 4931, 12475, 11, 597, 366, 588, 2099, 281, 14151, 439, 295, 428, 5883, 3028, 1412, 300, 291, 643, 13], "temperature": 0.0, "avg_logprob": -0.20236340884504647, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.00010390816896688193}, {"id": 451, "seek": 322900, "start": 3229.0, "end": 3245.0, "text": " And then you serve a fully hydrated page and you do your processing of that data on the backend and you don't need to ship that code that was used to resolve that data in the backend. So like that's, but if like not everybody's going to want to architect their app that way.", "tokens": [400, 550, 291, 4596, 257, 4498, 44960, 3028, 293, 291, 360, 428, 9007, 295, 300, 1412, 322, 264, 38087, 293, 291, 500, 380, 643, 281, 5374, 300, 3089, 300, 390, 1143, 281, 14151, 300, 1412, 294, 264, 38087, 13, 407, 411, 300, 311, 11, 457, 498, 411, 406, 2201, 311, 516, 281, 528, 281, 6331, 641, 724, 300, 636, 13], "temperature": 0.0, "avg_logprob": -0.2276177853345871, "compression_ratio": 1.630952380952381, "no_speech_prob": 4.683727820520289e-05}, {"id": 452, "seek": 324500, "start": 3245.0, "end": 3274.0, "text": " And, you know, and also like Elm pages gives you an architecture for reaching through and sort of directly grabbing your data. That doesn't mean that you can't hit a GraphQL API or something like that, but you can, you can make a database request from a server rendered route and directly resolve data, you know, often using like a backend test dot custom, which allows you to define a custom node JS async function to your data center.", "tokens": [400, 11, 291, 458, 11, 293, 611, 411, 2699, 76, 7183, 2709, 291, 364, 9482, 337, 9906, 807, 293, 1333, 295, 3838, 23771, 428, 1412, 13, 663, 1177, 380, 914, 300, 291, 393, 380, 2045, 257, 21884, 13695, 9362, 420, 746, 411, 300, 11, 457, 291, 393, 11, 291, 393, 652, 257, 8149, 5308, 490, 257, 7154, 28748, 7955, 293, 3838, 14151, 1412, 11, 291, 458, 11, 2049, 1228, 411, 257, 38087, 1500, 5893, 2375, 11, 597, 4045, 291, 281, 6964, 257, 2375, 9984, 33063, 382, 34015, 2445, 281, 428, 1412, 3056, 13], "temperature": 0.0, "avg_logprob": -0.2513640688866684, "compression_ratio": 1.6452830188679246, "no_speech_prob": 2.9310884201549925e-05}, {"id": 453, "seek": 327400, "start": 3274.0, "end": 3289.0, "text": " You can use a custom node JS async function to, you know, receive JSON data and return JSON data that will be resolved in that backend task. But under the hood Elm pages uses ports, but it, it wires that all up for you.", "tokens": [509, 393, 764, 257, 2375, 9984, 33063, 382, 34015, 2445, 281, 11, 291, 458, 11, 4774, 31828, 1412, 293, 2736, 31828, 1412, 300, 486, 312, 20772, 294, 300, 38087, 5633, 13, 583, 833, 264, 13376, 2699, 76, 7183, 4960, 18160, 11, 457, 309, 11, 309, 15537, 300, 439, 493, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.40333632060459684, "compression_ratio": 1.3773584905660377, "no_speech_prob": 0.0001713025412755087}, {"id": 454, "seek": 328900, "start": 3289.0, "end": 3306.0, "text": " You define a file called custom backend task dot TS or dot JS, and you export async functions, and then they take one argument, which is the JSON encoded value that, that you call that you pass in from Elm.", "tokens": [509, 6964, 257, 3991, 1219, 2375, 38087, 5633, 5893, 37645, 420, 5893, 33063, 11, 293, 291, 10725, 382, 34015, 6828, 11, 293, 550, 436, 747, 472, 6770, 11, 597, 307, 264, 31828, 2058, 12340, 2158, 300, 11, 300, 291, 818, 300, 291, 1320, 294, 490, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.2504281447483943, "compression_ratio": 1.3733333333333333, "no_speech_prob": 8.013036676857155e-06}, {"id": 455, "seek": 330600, "start": 3306.0, "end": 3330.0, "text": " And then they return a JSON value and you decode, you give a decoder for that in Elm. So yeah, you can, so again, that's like a philosophical architectural choice. Like, is that an appealing way to work? Because if you're not getting benefit from that, this architecture might, you know, it might be trying to fit a square peg in a round hole.", "tokens": [400, 550, 436, 2736, 257, 31828, 2158, 293, 291, 979, 1429, 11, 291, 976, 257, 979, 19866, 337, 300, 294, 2699, 76, 13, 407, 1338, 11, 291, 393, 11, 370, 797, 11, 300, 311, 411, 257, 25066, 26621, 3922, 13, 1743, 11, 307, 300, 364, 23842, 636, 281, 589, 30, 1436, 498, 291, 434, 406, 1242, 5121, 490, 300, 11, 341, 9482, 1062, 11, 291, 458, 11, 309, 1062, 312, 1382, 281, 3318, 257, 3732, 17199, 294, 257, 3098, 5458, 13], "temperature": 0.0, "avg_logprob": -0.17214822208180147, "compression_ratio": 1.53125, "no_speech_prob": 4.39924442616757e-05}, {"id": 456, "seek": 333000, "start": 3330.0, "end": 3359.0, "text": " Yeah. For the performance, just so that I get it. So the server that is, so the server that the client hits and asks, like, Hey, I want this page at this URL that will communicate that server will communicate with some database or some things, hopefully on the same server or very close to, and then it will give back a page that is filled with a lot more data that it would have fetched otherwise on the client.", "tokens": [865, 13, 1171, 264, 3389, 11, 445, 370, 300, 286, 483, 309, 13, 407, 264, 7154, 300, 307, 11, 370, 264, 7154, 300, 264, 6423, 8664, 293, 8962, 11, 411, 11, 1911, 11, 286, 528, 341, 3028, 412, 341, 12905, 300, 486, 7890, 300, 7154, 486, 7890, 365, 512, 8149, 420, 512, 721, 11, 4696, 322, 264, 912, 7154, 420, 588, 1998, 281, 11, 293, 550, 309, 486, 976, 646, 257, 3028, 300, 307, 6412, 365, 257, 688, 544, 1412, 300, 309, 576, 362, 23673, 292, 5911, 322, 264, 6423, 13], "temperature": 0.0, "avg_logprob": -0.24221900136847246, "compression_ratio": 1.7606837606837606, "no_speech_prob": 0.00013341213343665004}, {"id": 457, "seek": 335900, "start": 3359.0, "end": 3377.0, "text": " So the time to first paint might be slower because the server is doing more computations and more requests. So it will take longer to resolve. So you will have a blank blank page for tiny bit longer in the good use case, I guess.", "tokens": [407, 264, 565, 281, 700, 4225, 1062, 312, 14009, 570, 264, 7154, 307, 884, 544, 2807, 763, 293, 544, 12475, 13, 407, 309, 486, 747, 2854, 281, 14151, 13, 407, 291, 486, 362, 257, 8247, 8247, 3028, 337, 5870, 857, 2854, 294, 264, 665, 764, 1389, 11, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.20572067190099647, "compression_ratio": 1.4774193548387098, "no_speech_prob": 0.0004238392866682261}, {"id": 458, "seek": 337700, "start": 3377.0, "end": 3397.0, "text": " But once you get the data, it's all there, or almost all there. Whereas with a regular application and full front end clients, you would have time to first paint that is very short, because you just ask for a static file.", "tokens": [583, 1564, 291, 483, 264, 1412, 11, 309, 311, 439, 456, 11, 420, 1920, 439, 456, 13, 13813, 365, 257, 3890, 3861, 293, 1577, 1868, 917, 6982, 11, 291, 576, 362, 565, 281, 700, 4225, 300, 307, 588, 2099, 11, 570, 291, 445, 1029, 337, 257, 13437, 3991, 13], "temperature": 0.0, "avg_logprob": -0.27056836182216426, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.00012531864922493696}, {"id": 459, "seek": 339700, "start": 3397.0, "end": 3414.0, "text": " But then it goes to fetch a lot of JavaScript, a lot of files, and in the init it makes an HTTP request to get a lot of data. And then once all those things are done, then you have a page that has all the data. Is that correct?", "tokens": [583, 550, 309, 1709, 281, 23673, 257, 688, 295, 15778, 11, 257, 688, 295, 7098, 11, 293, 294, 264, 3157, 309, 1669, 364, 33283, 5308, 281, 483, 257, 688, 295, 1412, 13, 400, 550, 1564, 439, 729, 721, 366, 1096, 11, 550, 291, 362, 257, 3028, 300, 575, 439, 264, 1412, 13, 1119, 300, 3006, 30], "temperature": 0.0, "avg_logprob": -0.19318745930989584, "compression_ratio": 1.4836601307189543, "no_speech_prob": 0.000588330440223217}, {"id": 460, "seek": 341400, "start": 3414.0, "end": 3433.0, "text": " Well, kind of. The time to first paint being slower is not necessarily the case, though, because consider the time to first paint for an Elm application. So when is it painting your Elm application? Basically, one question is, what's faster to paint?", "tokens": [1042, 11, 733, 295, 13, 440, 565, 281, 700, 4225, 885, 14009, 307, 406, 4725, 264, 1389, 11, 1673, 11, 570, 1949, 264, 565, 281, 700, 4225, 337, 364, 2699, 76, 3861, 13, 407, 562, 307, 309, 5370, 428, 2699, 76, 3861, 30, 8537, 11, 472, 1168, 307, 11, 437, 311, 4663, 281, 4225, 30], "temperature": 0.0, "avg_logprob": -0.23749985129146253, "compression_ratio": 1.5432098765432098, "no_speech_prob": 6.604564259760082e-05}, {"id": 461, "seek": 343300, "start": 3433.0, "end": 3450.0, "text": " Some HTML that you return or some JavaScript, right? With the JavaScript, it needs to probably make a follow up request for a JavaScript file, right? So that's one more step in the waterfall that it needs to do.", "tokens": [2188, 17995, 300, 291, 2736, 420, 512, 15778, 11, 558, 30, 2022, 264, 15778, 11, 309, 2203, 281, 1391, 652, 257, 1524, 493, 5308, 337, 257, 15778, 3991, 11, 558, 30, 407, 300, 311, 472, 544, 1823, 294, 264, 27848, 300, 309, 2203, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.2317924658457438, "compression_ratio": 1.5125, "no_speech_prob": 0.0007436378509737551}, {"id": 462, "seek": 343300, "start": 3450.0, "end": 3452.0, "text": " Which you don't in the server?", "tokens": [3013, 291, 500, 380, 294, 264, 7154, 30], "temperature": 0.0, "avg_logprob": -0.2317924658457438, "compression_ratio": 1.5125, "no_speech_prob": 0.0007436378509737551}, {"id": 463, "seek": 345200, "start": 3452.0, "end": 3467.0, "text": " The HTML is just there right away. You need to parse the JavaScript, which takes some time. And while you're parsing the JavaScript, that's a blocking operation, so it's not doing anything else. And then you can render the page.", "tokens": [440, 17995, 307, 445, 456, 558, 1314, 13, 509, 643, 281, 48377, 264, 15778, 11, 597, 2516, 512, 565, 13, 400, 1339, 291, 434, 21156, 278, 264, 15778, 11, 300, 311, 257, 17776, 6916, 11, 370, 309, 311, 406, 884, 1340, 1646, 13, 400, 550, 291, 393, 15529, 264, 3028, 13], "temperature": 0.0, "avg_logprob": -0.1940095381303267, "compression_ratio": 1.4339622641509433, "no_speech_prob": 0.00012533309927675873}, {"id": 464, "seek": 346700, "start": 3467.0, "end": 3489.0, "text": " But then, of course, now that you've rendered the page and initialized the JavaScript application, you're going to need to go and trigger your HTTP requests to get your initial data, right? So yes, now you've painted it, but now you need to go ask for your initial data.", "tokens": [583, 550, 11, 295, 1164, 11, 586, 300, 291, 600, 28748, 264, 3028, 293, 5883, 1602, 264, 15778, 3861, 11, 291, 434, 516, 281, 643, 281, 352, 293, 7875, 428, 33283, 12475, 281, 483, 428, 5883, 1412, 11, 558, 30, 407, 2086, 11, 586, 291, 600, 11797, 309, 11, 457, 586, 291, 643, 281, 352, 1029, 337, 428, 5883, 1412, 13], "temperature": 0.0, "avg_logprob": -0.18470259446364182, "compression_ratio": 1.588235294117647, "no_speech_prob": 2.4298997232108377e-05}, {"id": 465, "seek": 348900, "start": 3489.0, "end": 3504.0, "text": " You don't even have that yet. Maybe you even need to do a JIT authentication handshake or whatever first. And so all of these things are going to need to happen after the paint, right? That's not even before the paint.", "tokens": [509, 500, 380, 754, 362, 300, 1939, 13, 2704, 291, 754, 643, 281, 360, 257, 508, 3927, 26643, 2377, 34593, 420, 2035, 700, 13, 400, 370, 439, 295, 613, 721, 366, 516, 281, 643, 281, 1051, 934, 264, 4225, 11, 558, 30, 663, 311, 406, 754, 949, 264, 4225, 13], "temperature": 0.0, "avg_logprob": -0.2085010740492079, "compression_ratio": 1.4064516129032258, "no_speech_prob": 2.1781639588880353e-05}, {"id": 466, "seek": 350400, "start": 3504.0, "end": 3521.0, "text": " But getting to the first paint, it's a question of what's going to be faster, serving and rendering that HTML or serving and rendering that JavaScript, right? And it's actually not an obvious answer, which it's going to depend on a case by case basis.", "tokens": [583, 1242, 281, 264, 700, 4225, 11, 309, 311, 257, 1168, 295, 437, 311, 516, 281, 312, 4663, 11, 8148, 293, 22407, 300, 17995, 420, 8148, 293, 22407, 300, 15778, 11, 558, 30, 400, 309, 311, 767, 406, 364, 6322, 1867, 11, 597, 309, 311, 516, 281, 5672, 322, 257, 1389, 538, 1389, 5143, 13], "temperature": 0.0, "avg_logprob": -0.19443376185530323, "compression_ratio": 1.5493827160493827, "no_speech_prob": 7.888775144238025e-06}, {"id": 467, "seek": 352100, "start": 3521.0, "end": 3547.0, "text": " But there's a lot that needs to happen to initialize that JavaScript as well. So that's part of that philosophy of that architecture, right? If you can get your data resolution on your backend down to 50, 100 milliseconds or whatever, then you can have a pretty compelling story where, like,", "tokens": [583, 456, 311, 257, 688, 300, 2203, 281, 1051, 281, 5883, 1125, 300, 15778, 382, 731, 13, 407, 300, 311, 644, 295, 300, 10675, 295, 300, 9482, 11, 558, 30, 759, 291, 393, 483, 428, 1412, 8669, 322, 428, 38087, 760, 281, 2625, 11, 2319, 34184, 420, 2035, 11, 550, 291, 393, 362, 257, 1238, 20050, 1657, 689, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.23221036470853365, "compression_ratio": 1.4623115577889447, "no_speech_prob": 5.4757631005486473e-05}, {"id": 468, "seek": 354700, "start": 3547.0, "end": 3564.0, "text": " all right, I resolved the data, rendered out this HTML. Now you get a first paint. And so you can actually get a faster first paint. Of course, if it's a pre-rendered route, then you don't even need to resolve the data and you can serve it through a CDN, you could serve it at the edge.", "tokens": [439, 558, 11, 286, 20772, 264, 1412, 11, 28748, 484, 341, 17995, 13, 823, 291, 483, 257, 700, 4225, 13, 400, 370, 291, 393, 767, 483, 257, 4663, 700, 4225, 13, 2720, 1164, 11, 498, 309, 311, 257, 659, 12, 4542, 4073, 7955, 11, 550, 291, 500, 380, 754, 643, 281, 14151, 264, 1412, 293, 291, 393, 4596, 309, 807, 257, 6743, 45, 11, 291, 727, 4596, 309, 412, 264, 4691, 13], "temperature": 0.0, "avg_logprob": -0.22415008042988024, "compression_ratio": 1.5888888888888888, "no_speech_prob": 9.314386988990009e-05}, {"id": 469, "seek": 356400, "start": 3564.0, "end": 3582.0, "text": " But you can also serve it at the edge, you know, with a server rendered route as well. And you can use caching, you know, you can use a Redis cache to optimize your data loading and all sorts of so it really depends on your architecture, right?", "tokens": [583, 291, 393, 611, 4596, 309, 412, 264, 4691, 11, 291, 458, 11, 365, 257, 7154, 28748, 7955, 382, 731, 13, 400, 291, 393, 764, 269, 2834, 11, 291, 458, 11, 291, 393, 764, 257, 4477, 271, 19459, 281, 19719, 428, 1412, 15114, 293, 439, 7527, 295, 370, 309, 534, 5946, 322, 428, 9482, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1977709942176694, "compression_ratio": 1.5443037974683544, "no_speech_prob": 7.721908332314342e-05}, {"id": 470, "seek": 358200, "start": 3582.0, "end": 3595.0, "text": " But what did you mean with rendering at the edge? Like I can get for the static rendered routes or pre-rendered routes, but for server-side rendered routes?", "tokens": [583, 437, 630, 291, 914, 365, 22407, 412, 264, 4691, 30, 1743, 286, 393, 483, 337, 264, 13437, 28748, 18242, 420, 659, 12, 4542, 4073, 18242, 11, 457, 337, 7154, 12, 1812, 28748, 18242, 30], "temperature": 0.0, "avg_logprob": -0.26704829672108527, "compression_ratio": 1.6214689265536724, "no_speech_prob": 6.81394012644887e-05}, {"id": 471, "seek": 358200, "start": 3595.0, "end": 3603.0, "text": " Right. So edge functions are sort of an emerging approach to serverless functions.", "tokens": [1779, 13, 407, 4691, 6828, 366, 1333, 295, 364, 14989, 3109, 281, 7154, 1832, 6828, 13], "temperature": 0.0, "avg_logprob": -0.26704829672108527, "compression_ratio": 1.6214689265536724, "no_speech_prob": 6.81394012644887e-05}, {"id": 472, "seek": 358200, "start": 3603.0, "end": 3609.0, "text": " So that's one specific technique in serverless?", "tokens": [407, 300, 311, 472, 2685, 6532, 294, 7154, 1832, 30], "temperature": 0.0, "avg_logprob": -0.26704829672108527, "compression_ratio": 1.6214689265536724, "no_speech_prob": 6.81394012644887e-05}, {"id": 473, "seek": 360900, "start": 3609.0, "end": 3632.0, "text": " That's right. Yeah, that is something that some hosting providers are starting to really build out a lot of features around. But yeah, so like edge functions, as opposed to serverless functions. So a serverless function might be US East, you know, it might be an AWS Lambda in US East. So if you're", "tokens": [663, 311, 558, 13, 865, 11, 300, 307, 746, 300, 512, 16058, 11330, 366, 2891, 281, 534, 1322, 484, 257, 688, 295, 4122, 926, 13, 583, 1338, 11, 370, 411, 4691, 6828, 11, 382, 8851, 281, 7154, 1832, 6828, 13, 407, 257, 7154, 1832, 2445, 1062, 312, 2546, 6747, 11, 291, 458, 11, 309, 1062, 312, 364, 17650, 45691, 294, 2546, 6747, 13, 407, 498, 291, 434], "temperature": 0.0, "avg_logprob": -0.2244832431568819, "compression_ratio": 1.592760180995475, "no_speech_prob": 6.204778765095398e-05}, {"id": 474, "seek": 360900, "start": 3632.0, "end": 3636.0, "text": " You mean specifically in one location, and that's it?", "tokens": [509, 914, 4682, 294, 472, 4914, 11, 293, 300, 311, 309, 30], "temperature": 0.0, "avg_logprob": -0.2244832431568819, "compression_ratio": 1.592760180995475, "no_speech_prob": 6.204778765095398e-05}, {"id": 475, "seek": 363600, "start": 3636.0, "end": 3655.0, "text": " That's right. So there's some JavaScript code that some US East Lambda will be able to pick up and execute and somebody in Tokyo hits your server rendered route, and they go all the way to US East and they request that data.", "tokens": [663, 311, 558, 13, 407, 456, 311, 512, 15778, 3089, 300, 512, 2546, 6747, 45691, 486, 312, 1075, 281, 1888, 493, 293, 14483, 293, 2618, 294, 15147, 8664, 428, 7154, 28748, 7955, 11, 293, 436, 352, 439, 264, 636, 281, 2546, 6747, 293, 436, 5308, 300, 1412, 13], "temperature": 0.0, "avg_logprob": -0.21390129683853745, "compression_ratio": 1.5495049504950495, "no_speech_prob": 3.822790313279256e-05}, {"id": 476, "seek": 363600, "start": 3655.0, "end": 3662.0, "text": " And they have to go to US East? Like there's only one copy, one server that can do this?", "tokens": [400, 436, 362, 281, 352, 281, 2546, 6747, 30, 1743, 456, 311, 787, 472, 5055, 11, 472, 7154, 300, 393, 360, 341, 30], "temperature": 0.0, "avg_logprob": -0.21390129683853745, "compression_ratio": 1.5495049504950495, "no_speech_prob": 3.822790313279256e-05}, {"id": 477, "seek": 366200, "start": 3662.0, "end": 3688.0, "text": " Yeah, and maybe there are a couple or, you know, something like that. But the edge functions are this idea that let's put them at more places, you know, more, you know, serverless locations where we can do the same thing as serverless functions where you call a function as a service or whatever, but it's distributed across more locations physically.", "tokens": [865, 11, 293, 1310, 456, 366, 257, 1916, 420, 11, 291, 458, 11, 746, 411, 300, 13, 583, 264, 4691, 6828, 366, 341, 1558, 300, 718, 311, 829, 552, 412, 544, 3190, 11, 291, 458, 11, 544, 11, 291, 458, 11, 7154, 1832, 9253, 689, 321, 393, 360, 264, 912, 551, 382, 7154, 1832, 6828, 689, 291, 818, 257, 2445, 382, 257, 2643, 420, 2035, 11, 457, 309, 311, 12631, 2108, 544, 9253, 9762, 13], "temperature": 0.0, "avg_logprob": -0.18839925452123715, "compression_ratio": 1.763819095477387, "no_speech_prob": 0.006002926267683506}, {"id": 478, "seek": 368800, "start": 3688.0, "end": 3704.0, "text": " Then of course, you do need to think about your data center story, right? Because if you're calling, you know, if the server is serving it up from a closer location, but it's farther from your data center, that's not good either.", "tokens": [1396, 295, 1164, 11, 291, 360, 643, 281, 519, 466, 428, 1412, 3056, 1657, 11, 558, 30, 1436, 498, 291, 434, 5141, 11, 291, 458, 11, 498, 264, 7154, 307, 8148, 309, 493, 490, 257, 4966, 4914, 11, 457, 309, 311, 20344, 490, 428, 1412, 3056, 11, 300, 311, 406, 665, 2139, 13], "temperature": 0.0, "avg_logprob": -0.1492360934876559, "compression_ratio": 1.4774193548387098, "no_speech_prob": 0.0013044445076957345}, {"id": 479, "seek": 370400, "start": 3704.0, "end": 3725.0, "text": " And there are places that are exploring ways to do more sort of distributed edge data, you know, whether it's key value or, you know, NoSQL or SQL style databases or whatever. A lot of things are being explored there. It's a big, big world.", "tokens": [400, 456, 366, 3190, 300, 366, 12736, 2098, 281, 360, 544, 1333, 295, 12631, 4691, 1412, 11, 291, 458, 11, 1968, 309, 311, 2141, 2158, 420, 11, 291, 458, 11, 883, 39934, 420, 19200, 3758, 22380, 420, 2035, 13, 316, 688, 295, 721, 366, 885, 24016, 456, 13, 467, 311, 257, 955, 11, 955, 1002, 13], "temperature": 0.0, "avg_logprob": -0.18010146277291433, "compression_ratio": 1.514018691588785, "no_speech_prob": 0.00010229687904939055}, {"id": 480, "seek": 370400, "start": 3725.0, "end": 3729.0, "text": " Yeah, it sounds a little bit complicated in practice.", "tokens": [865, 11, 309, 3263, 257, 707, 857, 6179, 294, 3124, 13], "temperature": 0.0, "avg_logprob": -0.18010146277291433, "compression_ratio": 1.514018691588785, "no_speech_prob": 0.00010229687904939055}, {"id": 481, "seek": 370400, "start": 3729.0, "end": 3731.0, "text": " It is. It's hard to navigate.", "tokens": [467, 307, 13, 467, 311, 1152, 281, 12350, 13], "temperature": 0.0, "avg_logprob": -0.18010146277291433, "compression_ratio": 1.514018691588785, "no_speech_prob": 0.00010229687904939055}, {"id": 482, "seek": 373100, "start": 3731.0, "end": 3736.0, "text": " Yeah, it sounds pretty simple, but also like how to optimize all that.", "tokens": [865, 11, 309, 3263, 1238, 2199, 11, 457, 611, 411, 577, 281, 19719, 439, 300, 13], "temperature": 0.0, "avg_logprob": -0.24033588252655447, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.0001293106033699587}, {"id": 483, "seek": 373100, "start": 3736.0, "end": 3750.0, "text": " Totally. Totally. But on the other hand, like you can, you know, have if you've got your data center, and you've got an express server, you can serve up some Elm pages routes too, right? So that's...", "tokens": [22837, 13, 22837, 13, 583, 322, 264, 661, 1011, 11, 411, 291, 393, 11, 291, 458, 11, 362, 498, 291, 600, 658, 428, 1412, 3056, 11, 293, 291, 600, 658, 364, 5109, 7154, 11, 291, 393, 4596, 493, 512, 2699, 76, 7183, 18242, 886, 11, 558, 30, 407, 300, 311, 485], "temperature": 0.0, "avg_logprob": -0.24033588252655447, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.0001293106033699587}, {"id": 484, "seek": 375000, "start": 3750.0, "end": 3767.0, "text": " And so if you want to use Elm pages with an edge architecture, would you, how would you do that? Would you just define it in Netlify or whatever your hosting platform might be? Or do you have to write an adapter for that?", "tokens": [400, 370, 498, 291, 528, 281, 764, 2699, 76, 7183, 365, 364, 4691, 9482, 11, 576, 291, 11, 577, 576, 291, 360, 300, 30, 6068, 291, 445, 6964, 309, 294, 6188, 75, 2505, 420, 2035, 428, 16058, 3663, 1062, 312, 30, 1610, 360, 291, 362, 281, 2464, 364, 22860, 337, 300, 30], "temperature": 0.0, "avg_logprob": -0.2075268030166626, "compression_ratio": 1.4258064516129032, "no_speech_prob": 6.01398860453628e-05}, {"id": 485, "seek": 376700, "start": 3767.0, "end": 3789.0, "text": " Yeah, you would need an adapter. The Netlify one specifically, I'm not sure that Elm pages works with Netlify edge functions right now, because they use Deno. And right now Elm pages is node based. It doesn't have like a D, it's really hard to decouple between different JS frameworks.", "tokens": [865, 11, 291, 576, 643, 364, 22860, 13, 440, 6188, 75, 2505, 472, 4682, 11, 286, 478, 406, 988, 300, 2699, 76, 7183, 1985, 365, 6188, 75, 2505, 4691, 6828, 558, 586, 11, 570, 436, 764, 413, 5808, 13, 400, 558, 586, 2699, 76, 7183, 307, 9984, 2361, 13, 467, 1177, 380, 362, 411, 257, 413, 11, 309, 311, 534, 1152, 281, 979, 263, 781, 1296, 819, 33063, 29834, 13], "temperature": 0.0, "avg_logprob": -0.22303480715365023, "compression_ratio": 1.4393939393939394, "no_speech_prob": 2.7108500944450498e-05}, {"id": 486, "seek": 378900, "start": 3789.0, "end": 3797.0, "text": " But so that's definitely one thing on my radar. But yeah, at the moment, they use Deno and it is not, I don't think it's compatible with it.", "tokens": [583, 370, 300, 311, 2138, 472, 551, 322, 452, 16544, 13, 583, 1338, 11, 412, 264, 1623, 11, 436, 764, 413, 5808, 293, 309, 307, 406, 11, 286, 500, 380, 519, 309, 311, 18218, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.21942563264266304, "compression_ratio": 1.679245283018868, "no_speech_prob": 1.9525703464751132e-05}, {"id": 487, "seek": 378900, "start": 3797.0, "end": 3799.0, "text": " Okay, interesting.", "tokens": [1033, 11, 1880, 13], "temperature": 0.0, "avg_logprob": -0.21942563264266304, "compression_ratio": 1.679245283018868, "no_speech_prob": 1.9525703464751132e-05}, {"id": 488, "seek": 378900, "start": 3799.0, "end": 3818.0, "text": " But yeah, so server rendered, it's a big world, but I think that it's easy to get lost in those details. But I would say for people thinking about building something with this, the bottom line is, you know, again, it's this pattern of bootstrapping your page with data from the server.", "tokens": [583, 1338, 11, 370, 7154, 28748, 11, 309, 311, 257, 955, 1002, 11, 457, 286, 519, 300, 309, 311, 1858, 281, 483, 2731, 294, 729, 4365, 13, 583, 286, 576, 584, 337, 561, 1953, 466, 2390, 746, 365, 341, 11, 264, 2767, 1622, 307, 11, 291, 458, 11, 797, 11, 309, 311, 341, 5102, 295, 11450, 19639, 3759, 428, 3028, 365, 1412, 490, 264, 7154, 13], "temperature": 0.0, "avg_logprob": -0.21942563264266304, "compression_ratio": 1.679245283018868, "no_speech_prob": 1.9525703464751132e-05}, {"id": 489, "seek": 381800, "start": 3818.0, "end": 3839.0, "text": " And Elm pages v3 is an abstraction for, for being able to basically automate the glue code for that pattern. Right. So, and again, like, you, you might not want to use that pattern. And if you don't want to use that pattern, then then Elmland is probably a better fit, because it doesn't, it's not bound to that pattern.", "tokens": [400, 2699, 76, 7183, 371, 18, 307, 364, 37765, 337, 11, 337, 885, 1075, 281, 1936, 31605, 264, 8998, 3089, 337, 300, 5102, 13, 1779, 13, 407, 11, 293, 797, 11, 411, 11, 291, 11, 291, 1062, 406, 528, 281, 764, 300, 5102, 13, 400, 498, 291, 500, 380, 528, 281, 764, 300, 5102, 11, 550, 550, 2699, 76, 1661, 307, 1391, 257, 1101, 3318, 11, 570, 309, 1177, 380, 11, 309, 311, 406, 5472, 281, 300, 5102, 13], "temperature": 0.0, "avg_logprob": -0.22868689571518497, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.264672679710202e-05}, {"id": 490, "seek": 383900, "start": 3839.0, "end": 3866.0, "text": " But Elm pages v3 allows you to use that pattern in a really seamless way. That's sort of its core design and philosophy. And, and it has a lot of things around that, like the session API and, and the request API for looking at request data, you can even define API routes, where you can write pure Elm functions that respond to an API route.", "tokens": [583, 2699, 76, 7183, 371, 18, 4045, 291, 281, 764, 300, 5102, 294, 257, 534, 28677, 636, 13, 663, 311, 1333, 295, 1080, 4965, 1715, 293, 10675, 13, 400, 11, 293, 309, 575, 257, 688, 295, 721, 926, 300, 11, 411, 264, 5481, 9362, 293, 11, 293, 264, 5308, 9362, 337, 1237, 412, 5308, 1412, 11, 291, 393, 754, 6964, 9362, 18242, 11, 689, 291, 393, 2464, 6075, 2699, 76, 6828, 300, 4196, 281, 364, 9362, 7955, 13], "temperature": 0.0, "avg_logprob": -0.1954295228167278, "compression_ratio": 1.5714285714285714, "no_speech_prob": 6.921843305462971e-05}, {"id": 491, "seek": 386600, "start": 3866.0, "end": 3881.0, "text": " So if you want to have an API route that doesn't have a view, it's not a page, and you want to respond to a webhook with a Stripe, you know, some sort of header that has some Stripe signing secret.", "tokens": [407, 498, 291, 528, 281, 362, 364, 9362, 7955, 300, 1177, 380, 362, 257, 1910, 11, 309, 311, 406, 257, 3028, 11, 293, 291, 528, 281, 4196, 281, 257, 3670, 71, 1212, 365, 257, 20390, 494, 11, 291, 458, 11, 512, 1333, 295, 23117, 300, 575, 512, 20390, 494, 13393, 4054, 13], "temperature": 0.0, "avg_logprob": -0.18165194988250732, "compression_ratio": 1.4172661870503598, "no_speech_prob": 0.0008692839764989913}, {"id": 492, "seek": 388100, "start": 3881.0, "end": 3900.0, "text": " So you know, it's coming from Stripe, and you can respond, you know, respond to a payment being received by Stripe through a webhook, you can you can build that in pure Elm and resolve it with back end tasks and even directly make database requests to manage things. So", "tokens": [407, 291, 458, 11, 309, 311, 1348, 490, 20390, 494, 11, 293, 291, 393, 4196, 11, 291, 458, 11, 4196, 281, 257, 10224, 885, 4613, 538, 20390, 494, 807, 257, 3670, 71, 1212, 11, 291, 393, 291, 393, 1322, 300, 294, 6075, 2699, 76, 293, 14151, 309, 365, 646, 917, 9608, 293, 754, 3838, 652, 8149, 12475, 281, 3067, 721, 13, 407], "temperature": 0.0, "avg_logprob": -0.20903457128084624, "compression_ratio": 1.6008230452674896, "no_speech_prob": 3.7851830256840913e-06}, {"id": 493, "seek": 388100, "start": 3900.0, "end": 3906.0, "text": " Did you just casually say, Oh, by the way, we can do back end in Elm pages.", "tokens": [2589, 291, 445, 34872, 584, 11, 876, 11, 538, 264, 636, 11, 321, 393, 360, 646, 917, 294, 2699, 76, 7183, 13], "temperature": 0.0, "avg_logprob": -0.20903457128084624, "compression_ratio": 1.6008230452674896, "no_speech_prob": 3.7851830256840913e-06}, {"id": 494, "seek": 388100, "start": 3906.0, "end": 3909.0, "text": " That's, that's the headline. Exactly. Yeah.", "tokens": [663, 311, 11, 300, 311, 264, 28380, 13, 7587, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.20903457128084624, "compression_ratio": 1.6008230452674896, "no_speech_prob": 3.7851830256840913e-06}, {"id": 495, "seek": 390900, "start": 3909.0, "end": 3912.0, "text": " Okay, well, that was not clear enough.", "tokens": [1033, 11, 731, 11, 300, 390, 406, 1850, 1547, 13], "temperature": 0.0, "avg_logprob": -0.28353318301114167, "compression_ratio": 1.2098765432098766, "no_speech_prob": 3.763542554224841e-05}, {"id": 496, "seek": 390900, "start": 3912.0, "end": 3915.0, "text": " Yeah, maybe we should have done a", "tokens": [865, 11, 1310, 321, 820, 362, 1096, 257], "temperature": 0.0, "avg_logprob": -0.28353318301114167, "compression_ratio": 1.2098765432098766, "no_speech_prob": 3.763542554224841e-05}, {"id": 497, "seek": 390900, "start": 3915.0, "end": 3917.0, "text": " That was not clear to me.", "tokens": [663, 390, 406, 1850, 281, 385, 13], "temperature": 0.0, "avg_logprob": -0.28353318301114167, "compression_ratio": 1.2098765432098766, "no_speech_prob": 3.763542554224841e-05}, {"id": 498, "seek": 391700, "start": 3917.0, "end": 3946.0, "text": " From the start. Yeah, you can, you can write back ends, you can write APIs, you can write a JSON API endpoint. I mean, it's pure, you know, it is, you can write pure Elm code that can that can respond to server requests with the incoming HTTP request payload, whether that is a route module, or an API route, which doesn't have a view, you can do that. You can do that with Elm pages v3.", "tokens": [3358, 264, 722, 13, 865, 11, 291, 393, 11, 291, 393, 2464, 646, 5314, 11, 291, 393, 2464, 21445, 11, 291, 393, 2464, 257, 31828, 9362, 35795, 13, 286, 914, 11, 309, 311, 6075, 11, 291, 458, 11, 309, 307, 11, 291, 393, 2464, 6075, 2699, 76, 3089, 300, 393, 300, 393, 4196, 281, 7154, 12475, 365, 264, 22341, 33283, 5308, 30918, 11, 1968, 300, 307, 257, 7955, 10088, 11, 420, 364, 9362, 7955, 11, 597, 1177, 380, 362, 257, 1910, 11, 291, 393, 360, 300, 13, 509, 393, 360, 300, 365, 2699, 76, 7183, 371, 18, 13], "temperature": 0.0, "avg_logprob": -0.23125863542743758, "compression_ratio": 1.751131221719457, "no_speech_prob": 1.2218823030707426e-05}, {"id": 499, "seek": 394600, "start": 3946.0, "end": 3953.0, "text": " I didn't understand that you could do non view things or non HTML things with it. That's very cool.", "tokens": [286, 994, 380, 1223, 300, 291, 727, 360, 2107, 1910, 721, 420, 2107, 17995, 721, 365, 309, 13, 663, 311, 588, 1627, 13], "temperature": 0.0, "avg_logprob": -0.21425591682901188, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.00017129865591414273}, {"id": 500, "seek": 394600, "start": 3953.0, "end": 3975.0, "text": " Yeah. And you can you can pre render your API routes to also known as files. But, but yeah, it's the you can, you don't have access to the HTTP requests. But if you you know, for example, the Elm radio podcast feed is, it's an RSS file, that is an API route.", "tokens": [865, 13, 400, 291, 393, 291, 393, 659, 15529, 428, 9362, 18242, 281, 611, 2570, 382, 7098, 13, 583, 11, 457, 1338, 11, 309, 311, 264, 291, 393, 11, 291, 500, 380, 362, 2105, 281, 264, 33283, 12475, 13, 583, 498, 291, 291, 458, 11, 337, 1365, 11, 264, 2699, 76, 6477, 7367, 3154, 307, 11, 309, 311, 364, 497, 21929, 3991, 11, 300, 307, 364, 9362, 7955, 13], "temperature": 0.0, "avg_logprob": -0.21425591682901188, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.00017129865591414273}, {"id": 501, "seek": 397500, "start": 3975.0, "end": 3990.0, "text": " But if we wanted to make that a something that you know if we really wanted to be able to just instantly go live with an Elm radio episode at a very specific time.", "tokens": [583, 498, 321, 1415, 281, 652, 300, 257, 746, 300, 291, 458, 498, 321, 534, 1415, 281, 312, 1075, 281, 445, 13518, 352, 1621, 365, 364, 2699, 76, 6477, 3500, 412, 257, 588, 2685, 565, 13], "temperature": 0.0, "avg_logprob": -0.21273691654205323, "compression_ratio": 1.3471074380165289, "no_speech_prob": 5.649584636557847e-05}, {"id": 502, "seek": 399000, "start": 3990.0, "end": 4012.0, "text": " Which we don't really have that problem because we have, you know, like a specific time that an episode releases and we can just do that with a build step in and have it through a cron job. But if for something where you wanted to be able to like drop something at a specific time and have that update in real time, we could have it be a server rendered API route.", "tokens": [3013, 321, 500, 380, 534, 362, 300, 1154, 570, 321, 362, 11, 291, 458, 11, 411, 257, 2685, 565, 300, 364, 3500, 16952, 293, 321, 393, 445, 360, 300, 365, 257, 1322, 1823, 294, 293, 362, 309, 807, 257, 941, 266, 1691, 13, 583, 498, 337, 746, 689, 291, 1415, 281, 312, 1075, 281, 411, 3270, 746, 412, 257, 2685, 565, 293, 362, 300, 5623, 294, 957, 565, 11, 321, 727, 362, 309, 312, 257, 7154, 28748, 9362, 7955, 13], "temperature": 0.0, "avg_logprob": -0.21684346880231584, "compression_ratio": 1.6545454545454545, "no_speech_prob": 1.9525032257661223e-05}, {"id": 503, "seek": 401200, "start": 4012.0, "end": 4029.0, "text": " And then the RSS feed and we could take that same route that is now pre rendered and say, okay, make it server rendered. And now I have access to the incoming request. And now, okay, here's a, here's an Elm radio pro feed, and you're going to need authentication.", "tokens": [400, 550, 264, 497, 21929, 3154, 293, 321, 727, 747, 300, 912, 7955, 300, 307, 586, 659, 28748, 293, 584, 11, 1392, 11, 652, 309, 7154, 28748, 13, 400, 586, 286, 362, 2105, 281, 264, 22341, 5308, 13, 400, 586, 11, 1392, 11, 510, 311, 257, 11, 510, 311, 364, 2699, 76, 6477, 447, 3154, 11, 293, 291, 434, 516, 281, 643, 26643, 13], "temperature": 0.0, "avg_logprob": -0.21162216803606818, "compression_ratio": 1.5748502994011977, "no_speech_prob": 3.2191826903726906e-05}, {"id": 504, "seek": 402900, "start": 4029.0, "end": 4043.0, "text": " So you give some query parameter or some cookie or whatever it might be to get your pro Elm radio feed for your user authentication. We could do that. Pretty interesting.", "tokens": [407, 291, 976, 512, 14581, 13075, 420, 512, 14417, 420, 2035, 309, 1062, 312, 281, 483, 428, 447, 2699, 76, 6477, 3154, 337, 428, 4195, 26643, 13, 492, 727, 360, 300, 13, 10693, 1880, 13], "temperature": 0.0, "avg_logprob": -0.21939578423133263, "compression_ratio": 1.317829457364341, "no_speech_prob": 0.00016602706455159932}, {"id": 505, "seek": 404300, "start": 4043.0, "end": 4069.0, "text": " So I know you've taken a lot of inspiration from other frameworks that deal in the same space, mostly in the JavaScript land. Tools like Remix and Astro and, and I can't come up with any other ones. And like, so now you've opened up Elm to that space to things that are SEO performance as well.", "tokens": [407, 286, 458, 291, 600, 2726, 257, 688, 295, 10249, 490, 661, 29834, 300, 2028, 294, 264, 912, 1901, 11, 5240, 294, 264, 15778, 2117, 13, 30302, 411, 4080, 970, 293, 12884, 340, 293, 11, 293, 286, 393, 380, 808, 493, 365, 604, 661, 2306, 13, 400, 411, 11, 370, 586, 291, 600, 5625, 493, 2699, 76, 281, 300, 1901, 281, 721, 300, 366, 22964, 3389, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.22750441668784782, "compression_ratio": 1.5, "no_speech_prob": 9.458480053581297e-05}, {"id": 506, "seek": 406900, "start": 4069.0, "end": 4091.0, "text": " So how does Elm pages compared to those now? And also, like, are there any parts of the fact that it's written in Elm that makes it much nicer or much more performance secure? Like, why would someone who is familiar with both JavaScript and Elm choose Elm pages over the other ones?", "tokens": [407, 577, 775, 2699, 76, 7183, 5347, 281, 729, 586, 30, 400, 611, 11, 411, 11, 366, 456, 604, 3166, 295, 264, 1186, 300, 309, 311, 3720, 294, 2699, 76, 300, 1669, 309, 709, 22842, 420, 709, 544, 3389, 7144, 30, 1743, 11, 983, 576, 1580, 567, 307, 4963, 365, 1293, 15778, 293, 2699, 76, 2826, 2699, 76, 7183, 670, 264, 661, 2306, 30], "temperature": 0.0, "avg_logprob": -0.2170424741857192, "compression_ratio": 1.4764397905759161, "no_speech_prob": 0.00016603388939984143}, {"id": 507, "seek": 409100, "start": 4091.0, "end": 4120.0, "text": " Right? Yeah. So Elm pages v3 is heavily inspired by Remix JS. So shout out to Remix and the Remix team for, I think, paving a path that is really exciting for sort of a web standards based approach to full stack front end frameworks, you know, with this idea of progressively enhancing forms and, you know, heavily relying on, you know, basically this idea of, you know,", "tokens": [1779, 30, 865, 13, 407, 2699, 76, 7183, 371, 18, 307, 10950, 7547, 538, 4080, 970, 33063, 13, 407, 8043, 484, 281, 4080, 970, 293, 264, 4080, 970, 1469, 337, 11, 286, 519, 11, 280, 6152, 257, 3100, 300, 307, 534, 4670, 337, 1333, 295, 257, 3670, 7787, 2361, 3109, 281, 1577, 8630, 1868, 917, 29834, 11, 291, 458, 11, 365, 341, 1558, 295, 46667, 36579, 6422, 293, 11, 291, 458, 11, 10950, 24140, 322, 11, 291, 458, 11, 1936, 341, 1558, 295, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.27088727007855423, "compression_ratio": 1.6371681415929205, "no_speech_prob": 0.0004878259205725044}, {"id": 508, "seek": 412000, "start": 4120.0, "end": 4146.0, "text": " basically this idea of let's, let's make a lot of our docs just linking to MDN and saying, well, here's how cookies work, which, you know, if you're, if you've been a front end developer for the last 5-10 years, maybe you've forgotten or don't know how cookies work, or, you know, maybe you've forgotten or don't know how, how form, how forms work. Like, because you, you know,", "tokens": [1936, 341, 1558, 295, 718, 311, 11, 718, 311, 652, 257, 688, 295, 527, 45623, 445, 25775, 281, 22521, 45, 293, 1566, 11, 731, 11, 510, 311, 577, 13670, 589, 11, 597, 11, 291, 458, 11, 498, 291, 434, 11, 498, 291, 600, 668, 257, 1868, 917, 10754, 337, 264, 1036, 1025, 12, 3279, 924, 11, 1310, 291, 600, 11832, 420, 500, 380, 458, 577, 13670, 589, 11, 420, 11, 291, 458, 11, 1310, 291, 600, 11832, 420, 500, 380, 458, 577, 11, 577, 1254, 11, 577, 6422, 589, 13, 1743, 11, 570, 291, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.20547975278368183, "compression_ratio": 1.7952380952380953, "no_speech_prob": 0.0009544100612401962}, {"id": 509, "seek": 414600, "start": 4146.0, "end": 4153.0, "text": " it's very lazy on their part.", "tokens": [309, 311, 588, 14847, 322, 641, 644, 13], "temperature": 0.0, "avg_logprob": -0.6370024681091309, "compression_ratio": 0.7837837837837838, "no_speech_prob": 0.0005975825479254127}, {"id": 510, "seek": 415300, "start": 4153.0, "end": 4182.0, "text": " But you don't actually use the built in platform features for these things. And they're saying, well, maybe let's enhance what the platform gives us, but use that as a starting point. So we have this baked in set of opinions that actually works really well with the browser, and we can leverage existing functionality there. So yeah, big shout out to Remix. One thing that obviously is different between, you know, Remix and Elm pages is Elm pages is Elm.", "tokens": [583, 291, 500, 380, 767, 764, 264, 3094, 294, 3663, 4122, 337, 613, 721, 13, 400, 436, 434, 1566, 11, 731, 11, 1310, 718, 311, 11985, 437, 264, 3663, 2709, 505, 11, 457, 764, 300, 382, 257, 2891, 935, 13, 407, 321, 362, 341, 19453, 294, 992, 295, 11819, 300, 767, 1985, 534, 731, 365, 264, 11185, 11, 293, 321, 393, 13982, 6741, 14980, 456, 13, 407, 1338, 11, 955, 8043, 484, 281, 4080, 970, 13, 1485, 551, 300, 2745, 307, 819, 1296, 11, 291, 458, 11, 4080, 970, 293, 2699, 76, 7183, 307, 2699, 76, 7183, 307, 2699, 76, 13], "temperature": 0.0, "avg_logprob": -0.20772567022414434, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.682432336267084e-05}, {"id": 511, "seek": 418200, "start": 4182.0, "end": 4185.0, "text": " Oh, really?", "tokens": [876, 11, 534, 30], "temperature": 0.0, "avg_logprob": -0.2018948949948706, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.00014201606973074377}, {"id": 512, "seek": 418200, "start": 4185.0, "end": 4209.0, "text": " Remix, they use a lot of TypeScript. And there are some cool features for bridging the types between the front end and the back end, using some of these TypeScript features. But of course, you know, Elm, you get more confidence in that you get custom types and all these things we like about Elm. So that's, you know, that's, that's one obvious thing that is a difference.", "tokens": [4080, 970, 11, 436, 764, 257, 688, 295, 15576, 14237, 13, 400, 456, 366, 512, 1627, 4122, 337, 16362, 3249, 264, 3467, 1296, 264, 1868, 917, 293, 264, 646, 917, 11, 1228, 512, 295, 613, 15576, 14237, 4122, 13, 583, 295, 1164, 11, 291, 458, 11, 2699, 76, 11, 291, 483, 544, 6687, 294, 300, 291, 483, 2375, 3467, 293, 439, 613, 721, 321, 411, 466, 2699, 76, 13, 407, 300, 311, 11, 291, 458, 11, 300, 311, 11, 300, 311, 472, 6322, 551, 300, 307, 257, 2649, 13], "temperature": 0.0, "avg_logprob": -0.2018948949948706, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.00014201606973074377}, {"id": 513, "seek": 420900, "start": 4209.0, "end": 4238.0, "text": " In addition to that, there's just a different philosophy between JavaScript and Elm. And that really shows up in these APIs. So for example, there's a lot of, I mean, if you're using Remix, one thing I noticed is you end up doing like a lot of casting. For example, you receive some form data, and you say, okay, well, I expect this to be a string, I expect this to be an int, I expect to be able to parse this, and I expect this to be a string.", "tokens": [682, 4500, 281, 300, 11, 456, 311, 445, 257, 819, 10675, 1296, 15778, 293, 2699, 76, 13, 400, 300, 534, 3110, 493, 294, 613, 21445, 13, 407, 337, 1365, 11, 456, 311, 257, 688, 295, 11, 286, 914, 11, 498, 291, 434, 1228, 4080, 970, 11, 472, 551, 286, 5694, 307, 291, 917, 493, 884, 411, 257, 688, 295, 17301, 13, 1171, 1365, 11, 291, 4774, 512, 1254, 1412, 11, 293, 291, 584, 11, 1392, 11, 731, 11, 286, 2066, 341, 281, 312, 257, 6798, 11, 286, 2066, 341, 281, 312, 364, 560, 11, 286, 2066, 281, 312, 1075, 281, 48377, 341, 11, 293, 286, 2066, 341, 281, 312, 257, 6798, 13], "temperature": 0.0, "avg_logprob": -0.27242320159385947, "compression_ratio": 1.7729083665338645, "no_speech_prob": 0.002287127310410142}, {"id": 514, "seek": 423800, "start": 4238.0, "end": 4266.0, "text": " And I expect to parse this as an int or whatever, right. But you're still, you know, you can use things like Zod, which definitely improves things and gives you more of an Elm decoder style approach to that. But you know, just like you would choose between Elm or JavaScript in any context, it's a similar set of trade offs with TypeScript and Elm there where, yeah, you can sort of get some of the safety of Elm if you use things like Zod and stuff.", "tokens": [400, 286, 2066, 281, 48377, 341, 382, 364, 560, 420, 2035, 11, 558, 13, 583, 291, 434, 920, 11, 291, 458, 11, 291, 393, 764, 721, 411, 1176, 378, 11, 597, 2138, 24771, 721, 293, 2709, 291, 544, 295, 364, 2699, 76, 979, 19866, 3758, 3109, 281, 300, 13, 583, 291, 458, 11, 445, 411, 291, 576, 2826, 1296, 2699, 76, 420, 15778, 294, 604, 4319, 11, 309, 311, 257, 2531, 992, 295, 4923, 39457, 365, 15576, 14237, 293, 2699, 76, 456, 689, 11, 1338, 11, 291, 393, 1333, 295, 483, 512, 295, 264, 4514, 295, 2699, 76, 498, 291, 764, 721, 411, 1176, 378, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.22636214324406215, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0025113478768616915}, {"id": 515, "seek": 426600, "start": 4266.0, "end": 4277.0, "text": " But it's never like all the way there. And for, you know, for people like us, like, that's really important to us and would be a reason to use Elm in itself.", "tokens": [583, 309, 311, 1128, 411, 439, 264, 636, 456, 13, 400, 337, 11, 291, 458, 11, 337, 561, 411, 505, 11, 411, 11, 300, 311, 534, 1021, 281, 505, 293, 576, 312, 257, 1778, 281, 764, 2699, 76, 294, 2564, 13], "temperature": 0.0, "avg_logprob": -0.20146674030231979, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.00020986443269066513}, {"id": 516, "seek": 426600, "start": 4277.0, "end": 4288.0, "text": " So when you communicate from the client to the back end, do you get a specific type or do you just get JSON, which you then need to encode and decode in Elm pages?", "tokens": [407, 562, 291, 7890, 490, 264, 6423, 281, 264, 646, 917, 11, 360, 291, 483, 257, 2685, 2010, 420, 360, 291, 445, 483, 31828, 11, 597, 291, 550, 643, 281, 2058, 1429, 293, 979, 1429, 294, 2699, 76, 7183, 30], "temperature": 0.0, "avg_logprob": -0.20146674030231979, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.00020986443269066513}, {"id": 517, "seek": 426600, "start": 4288.0, "end": 4290.0, "text": " I mean, you get a specific type.", "tokens": [286, 914, 11, 291, 483, 257, 2685, 2010, 13], "temperature": 0.0, "avg_logprob": -0.20146674030231979, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.00020986443269066513}, {"id": 518, "seek": 426600, "start": 4290.0, "end": 4291.0, "text": " Oh, that's nice.", "tokens": [876, 11, 300, 311, 1481, 13], "temperature": 0.0, "avg_logprob": -0.20146674030231979, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.00020986443269066513}, {"id": 519, "seek": 429100, "start": 4291.0, "end": 4299.0, "text": " Yeah, yeah, yeah. So that's the whole, that's the whole game is you. So you define in your route module, you define a data function where you define a back end task.", "tokens": [865, 11, 1338, 11, 1338, 13, 407, 300, 311, 264, 1379, 11, 300, 311, 264, 1379, 1216, 307, 291, 13, 407, 291, 6964, 294, 428, 7955, 10088, 11, 291, 6964, 257, 1412, 2445, 689, 291, 6964, 257, 646, 917, 5633, 13], "temperature": 0.0, "avg_logprob": -0.23452244529241248, "compression_ratio": 1.761111111111111, "no_speech_prob": 0.00015843118308112025}, {"id": 520, "seek": 429100, "start": 4299.0, "end": 4311.0, "text": " If it's a server rendered route, then you have access to the HTTP request and you can respond with a back end task based on that incoming HTTP request.", "tokens": [759, 309, 311, 257, 7154, 28748, 7955, 11, 550, 291, 362, 2105, 281, 264, 33283, 5308, 293, 291, 393, 4196, 365, 257, 646, 917, 5633, 2361, 322, 300, 22341, 33283, 5308, 13], "temperature": 0.0, "avg_logprob": -0.23452244529241248, "compression_ratio": 1.761111111111111, "no_speech_prob": 0.00015843118308112025}, {"id": 521, "seek": 431100, "start": 4311.0, "end": 4321.0, "text": " And if it's pre-rendered, you don't have access to that HTTP request. And then that back end task resolves to your route modules data type.", "tokens": [400, 498, 309, 311, 659, 12, 4542, 4073, 11, 291, 500, 380, 362, 2105, 281, 300, 33283, 5308, 13, 400, 550, 300, 646, 917, 5633, 7923, 977, 281, 428, 7955, 16679, 1412, 2010, 13], "temperature": 0.0, "avg_logprob": -0.23327893921823212, "compression_ratio": 1.4770114942528736, "no_speech_prob": 5.173832505533937e-06}, {"id": 522, "seek": 431100, "start": 4321.0, "end": 4332.0, "text": " So type alias data equals record with user name, ID, product, product name, whatever, whatever your route is showing.", "tokens": [407, 2010, 419, 4609, 1412, 6915, 2136, 365, 4195, 1315, 11, 7348, 11, 1674, 11, 1674, 1315, 11, 2035, 11, 2035, 428, 7955, 307, 4099, 13], "temperature": 0.0, "avg_logprob": -0.23327893921823212, "compression_ratio": 1.4770114942528736, "no_speech_prob": 5.173832505533937e-06}, {"id": 523, "seek": 433200, "start": 4332.0, "end": 4341.0, "text": " You know, if it's a showing a product and it has inventory and it has whatever you get that, that that's your type alias data.", "tokens": [509, 458, 11, 498, 309, 311, 257, 4099, 257, 1674, 293, 309, 575, 14228, 293, 309, 575, 2035, 291, 483, 300, 11, 300, 300, 311, 428, 2010, 419, 4609, 1412, 13], "temperature": 0.0, "avg_logprob": -0.25697791969383155, "compression_ratio": 1.903225806451613, "no_speech_prob": 1.3630380635731854e-05}, {"id": 524, "seek": 433200, "start": 4341.0, "end": 4345.0, "text": " And then you just have that in you have that in a knit. You have that in view.", "tokens": [400, 550, 291, 445, 362, 300, 294, 291, 362, 300, 294, 257, 15594, 13, 509, 362, 300, 294, 1910, 13], "temperature": 0.0, "avg_logprob": -0.25697791969383155, "compression_ratio": 1.903225806451613, "no_speech_prob": 1.3630380635731854e-05}, {"id": 525, "seek": 433200, "start": 4345.0, "end": 4356.0, "text": " So you just do that. You have an app argument in your view function and you just do app dot data dot inventory count app dot data dot products name.", "tokens": [407, 291, 445, 360, 300, 13, 509, 362, 364, 724, 6770, 294, 428, 1910, 2445, 293, 291, 445, 360, 724, 5893, 1412, 5893, 14228, 1207, 724, 5893, 1412, 5893, 3383, 1315, 13], "temperature": 0.0, "avg_logprob": -0.25697791969383155, "compression_ratio": 1.903225806451613, "no_speech_prob": 1.3630380635731854e-05}, {"id": 526, "seek": 435600, "start": 4356.0, "end": 4363.0, "text": " And it's not a it's not a maybe it's not a remote data. It's not a result. You just have have that data. It's just there.", "tokens": [400, 309, 311, 406, 257, 309, 311, 406, 257, 1310, 309, 311, 406, 257, 8607, 1412, 13, 467, 311, 406, 257, 1874, 13, 509, 445, 362, 362, 300, 1412, 13, 467, 311, 445, 456, 13], "temperature": 0.0, "avg_logprob": -0.18449668128891747, "compression_ratio": 1.7046632124352332, "no_speech_prob": 3.500822231217171e-06}, {"id": 527, "seek": 435600, "start": 4363.0, "end": 4368.0, "text": " Yeah. So that's the data that you get from the server when you're on the client. Right.", "tokens": [865, 13, 407, 300, 311, 264, 1412, 300, 291, 483, 490, 264, 7154, 562, 291, 434, 322, 264, 6423, 13, 1779, 13], "temperature": 0.0, "avg_logprob": -0.18449668128891747, "compression_ratio": 1.7046632124352332, "no_speech_prob": 3.500822231217171e-06}, {"id": 528, "seek": 435600, "start": 4368.0, "end": 4373.0, "text": " But if the client wants to send data to the back end.", "tokens": [583, 498, 264, 6423, 2738, 281, 2845, 1412, 281, 264, 646, 917, 13], "temperature": 0.0, "avg_logprob": -0.18449668128891747, "compression_ratio": 1.7046632124352332, "no_speech_prob": 3.500822231217171e-06}, {"id": 529, "seek": 435600, "start": 4373.0, "end": 4377.0, "text": " Gotcha. OK. So, yes. And this is kind of a bit of a can of worms.", "tokens": [42109, 13, 2264, 13, 407, 11, 2086, 13, 400, 341, 307, 733, 295, 257, 857, 295, 257, 393, 295, 28271, 13], "temperature": 0.0, "avg_logprob": -0.18449668128891747, "compression_ratio": 1.7046632124352332, "no_speech_prob": 3.500822231217171e-06}, {"id": 530, "seek": 437700, "start": 4377.0, "end": 4388.0, "text": " But, yes, Elm pages V3 has something called actions in server rendered route modules as well. And that is that's heavily inspired by Remix JS.", "tokens": [583, 11, 2086, 11, 2699, 76, 7183, 691, 18, 575, 746, 1219, 5909, 294, 7154, 28748, 7955, 16679, 382, 731, 13, 400, 300, 307, 300, 311, 10950, 7547, 538, 4080, 970, 33063, 13], "temperature": 0.0, "avg_logprob": -0.22988434993859494, "compression_ratio": 1.4245810055865922, "no_speech_prob": 7.889156222518068e-06}, {"id": 531, "seek": 437700, "start": 4388.0, "end": 4398.0, "text": " That name comes from Remix JS. I think they got the name from like a form has an action attribute in a web form.", "tokens": [663, 1315, 1487, 490, 4080, 970, 33063, 13, 286, 519, 436, 658, 264, 1315, 490, 411, 257, 1254, 575, 364, 3069, 19667, 294, 257, 3670, 1254, 13], "temperature": 0.0, "avg_logprob": -0.22988434993859494, "compression_ratio": 1.4245810055865922, "no_speech_prob": 7.889156222518068e-06}, {"id": 532, "seek": 439800, "start": 4398.0, "end": 4408.0, "text": " So the action function is much like the data function. The data function is a back end task that resolves on initial page load.", "tokens": [407, 264, 3069, 2445, 307, 709, 411, 264, 1412, 2445, 13, 440, 1412, 2445, 307, 257, 646, 917, 5633, 300, 7923, 977, 322, 5883, 3028, 3677, 13], "temperature": 0.0, "avg_logprob": -0.22520158875663326, "compression_ratio": 1.6846153846153846, "no_speech_prob": 4.860318313149037e-06}, {"id": 533, "seek": 439800, "start": 4408.0, "end": 4416.0, "text": " That's your initial route data and the action. So the action is there for non get requests.", "tokens": [663, 311, 428, 5883, 7955, 1412, 293, 264, 3069, 13, 407, 264, 3069, 307, 456, 337, 2107, 483, 12475, 13], "temperature": 0.0, "avg_logprob": -0.22520158875663326, "compression_ratio": 1.6846153846153846, "no_speech_prob": 4.860318313149037e-06}, {"id": 534, "seek": 441600, "start": 4416.0, "end": 4428.0, "text": " So if you make a non get request such as a form submission through a post method, then that would that would come into your action function on the server.", "tokens": [407, 498, 291, 652, 257, 2107, 483, 5308, 1270, 382, 257, 1254, 23689, 807, 257, 2183, 3170, 11, 550, 300, 576, 300, 576, 808, 666, 428, 3069, 2445, 322, 264, 7154, 13], "temperature": 0.0, "avg_logprob": -0.1863758753216456, "compression_ratio": 1.6867469879518073, "no_speech_prob": 1.805666215659585e-05}, {"id": 535, "seek": 441600, "start": 4428.0, "end": 4436.0, "text": " It's going to resolve your action function instead of your data function for that. And that will that will update your route.", "tokens": [467, 311, 516, 281, 14151, 428, 3069, 2445, 2602, 295, 428, 1412, 2445, 337, 300, 13, 400, 300, 486, 300, 486, 5623, 428, 7955, 13], "temperature": 0.0, "avg_logprob": -0.1863758753216456, "compression_ratio": 1.6867469879518073, "no_speech_prob": 1.805666215659585e-05}, {"id": 536, "seek": 443600, "start": 4436.0, "end": 4450.0, "text": " So this is like one of the core things of Elm pages V3 is there's a whole form API for for working with this where you can define a form declaratively.", "tokens": [407, 341, 307, 411, 472, 295, 264, 4965, 721, 295, 2699, 76, 7183, 691, 18, 307, 456, 311, 257, 1379, 1254, 9362, 337, 337, 1364, 365, 341, 689, 291, 393, 6964, 257, 1254, 16694, 19020, 13], "temperature": 0.0, "avg_logprob": -0.19917515576896022, "compression_ratio": 1.4545454545454546, "no_speech_prob": 2.0780647901119664e-05}, {"id": 537, "seek": 443600, "start": 4450.0, "end": 4455.0, "text": " And also this is one of the big differences between Elm pages and Remix.", "tokens": [400, 611, 341, 307, 472, 295, 264, 955, 7300, 1296, 2699, 76, 7183, 293, 4080, 970, 13], "temperature": 0.0, "avg_logprob": -0.19917515576896022, "compression_ratio": 1.4545454545454546, "no_speech_prob": 2.0780647901119664e-05}, {"id": 538, "seek": 445500, "start": 4455.0, "end": 4466.0, "text": " At least for me, this was like an important design space was like creating a very Elm way to sort of parse form data that gives you the real time validations and all these things.", "tokens": [1711, 1935, 337, 385, 11, 341, 390, 411, 364, 1021, 1715, 1901, 390, 411, 4084, 257, 588, 2699, 76, 636, 281, 1333, 295, 48377, 1254, 1412, 300, 2709, 291, 264, 957, 565, 7363, 763, 293, 439, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.23357535697318413, "compression_ratio": 1.5159574468085106, "no_speech_prob": 3.02373828162672e-05}, {"id": 539, "seek": 445500, "start": 4466.0, "end": 4473.0, "text": " So you just you know, with Elm pages V3, you declare your form, which has the parser and the view for it.", "tokens": [407, 291, 445, 291, 458, 11, 365, 2699, 76, 7183, 691, 18, 11, 291, 19710, 428, 1254, 11, 597, 575, 264, 21156, 260, 293, 264, 1910, 337, 309, 13], "temperature": 0.0, "avg_logprob": -0.23357535697318413, "compression_ratio": 1.5159574468085106, "no_speech_prob": 3.02373828162672e-05}, {"id": 540, "seek": 447300, "start": 4473.0, "end": 4486.0, "text": " And then Elm pages takes care of of showing the real time client side validation errors. And when you hit submit, it will submit the form to your action function.", "tokens": [400, 550, 2699, 76, 7183, 2516, 1127, 295, 295, 4099, 264, 957, 565, 6423, 1252, 24071, 13603, 13, 400, 562, 291, 2045, 10315, 11, 309, 486, 10315, 264, 1254, 281, 428, 3069, 2445, 13], "temperature": 0.0, "avg_logprob": -0.21014409825421762, "compression_ratio": 1.6388888888888888, "no_speech_prob": 1.0782449862745125e-05}, {"id": 541, "seek": 447300, "start": 4486.0, "end": 4496.0, "text": " So you can in your action function, you can create a new item when somebody clicks submit on, you know, or you update the inventory.", "tokens": [407, 291, 393, 294, 428, 3069, 2445, 11, 291, 393, 1884, 257, 777, 3174, 562, 2618, 18521, 10315, 322, 11, 291, 458, 11, 420, 291, 5623, 264, 14228, 13], "temperature": 0.0, "avg_logprob": -0.21014409825421762, "compression_ratio": 1.6388888888888888, "no_speech_prob": 1.0782449862745125e-05}, {"id": 542, "seek": 449600, "start": 4496.0, "end": 4509.0, "text": " And then you you hit the submit button. And now you receive that in your action, you get the parsed form, which is either successfully parsed or has errors, it parses into the same value.", "tokens": [400, 550, 291, 291, 2045, 264, 10315, 2960, 13, 400, 586, 291, 4774, 300, 294, 428, 3069, 11, 291, 483, 264, 21156, 292, 1254, 11, 597, 307, 2139, 10727, 21156, 292, 420, 575, 13603, 11, 309, 21156, 279, 666, 264, 912, 2158, 13], "temperature": 0.0, "avg_logprob": -0.2099790947110045, "compression_ratio": 1.8099173553719008, "no_speech_prob": 6.204667442943901e-05}, {"id": 543, "seek": 449600, "start": 4509.0, "end": 4525.0, "text": " So you can even access the value that it parsed into on the client side. And you can use that to do optimistic or pending UI, optimistic UI being assuming that it was successful and showing the UI as if it succeeded before it does while it's pending.", "tokens": [407, 291, 393, 754, 2105, 264, 2158, 300, 309, 21156, 292, 666, 322, 264, 6423, 1252, 13, 400, 291, 393, 764, 300, 281, 360, 19397, 420, 32110, 15682, 11, 19397, 15682, 885, 11926, 300, 309, 390, 4406, 293, 4099, 264, 15682, 382, 498, 309, 20263, 949, 309, 775, 1339, 309, 311, 32110, 13], "temperature": 0.0, "avg_logprob": -0.2099790947110045, "compression_ratio": 1.8099173553719008, "no_speech_prob": 6.204667442943901e-05}, {"id": 544, "seek": 452500, "start": 4525.0, "end": 4533.0, "text": " And pending UI being less optimistic version of that where you show a spinner that something is in progress or something.", "tokens": [400, 32110, 15682, 885, 1570, 19397, 3037, 295, 300, 689, 291, 855, 257, 44849, 300, 746, 307, 294, 4205, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.18413761480530697, "compression_ratio": 1.5277777777777777, "no_speech_prob": 9.759990643942729e-05}, {"id": 545, "seek": 452500, "start": 4533.0, "end": 4547.0, "text": " So I have a demo app that people can try out a live version of or they can look at the source code of it's a modified version of Evans to do MVC Elm app.", "tokens": [407, 286, 362, 257, 10723, 724, 300, 561, 393, 853, 484, 257, 1621, 3037, 295, 420, 436, 393, 574, 412, 264, 4009, 3089, 295, 309, 311, 257, 15873, 3037, 295, 30055, 281, 360, 17663, 34, 2699, 76, 724, 13], "temperature": 0.0, "avg_logprob": -0.18413761480530697, "compression_ratio": 1.5277777777777777, "no_speech_prob": 9.759990643942729e-05}, {"id": 546, "seek": 454700, "start": 4547.0, "end": 4562.0, "text": " But it adds database persistence using an NPM package called Prisma with with Postgres. And it directly manages the database request through Elm pages, custom back end tasks.", "tokens": [583, 309, 10860, 8149, 37617, 1228, 364, 426, 18819, 7372, 1219, 2114, 14795, 365, 365, 10223, 45189, 13, 400, 309, 3838, 22489, 264, 8149, 5308, 807, 2699, 76, 7183, 11, 2375, 646, 917, 9608, 13], "temperature": 0.0, "avg_logprob": -0.25437767222776253, "compression_ratio": 1.560693641618497, "no_speech_prob": 0.00014423737593460828}, {"id": 547, "seek": 454700, "start": 4562.0, "end": 4568.0, "text": " And, and it gives you so it gives you full database persistence uses magic link authentication.", "tokens": [400, 11, 293, 309, 2709, 291, 370, 309, 2709, 291, 1577, 8149, 37617, 4960, 5585, 2113, 26643, 13], "temperature": 0.0, "avg_logprob": -0.25437767222776253, "compression_ratio": 1.560693641618497, "no_speech_prob": 0.00014423737593460828}, {"id": 548, "seek": 456800, "start": 4568.0, "end": 4581.0, "text": " So you so Elm pages itself will send you an email with a magic link that you click on. When you click on the link, it sets a session cookie that signs you in, because you click the link.", "tokens": [407, 291, 370, 2699, 76, 7183, 2564, 486, 2845, 291, 364, 3796, 365, 257, 5585, 2113, 300, 291, 2052, 322, 13, 1133, 291, 2052, 322, 264, 2113, 11, 309, 6352, 257, 5481, 14417, 300, 7880, 291, 294, 11, 570, 291, 2052, 264, 2113, 13], "temperature": 0.0, "avg_logprob": -0.18465989752660825, "compression_ratio": 1.7043010752688172, "no_speech_prob": 0.00015112943947315216}, {"id": 549, "seek": 456800, "start": 4581.0, "end": 4587.0, "text": " So it you've confirmed that it's you and now now you're signed in by clicking that link. That's what magic link authentication is.", "tokens": [407, 309, 291, 600, 11341, 300, 309, 311, 291, 293, 586, 586, 291, 434, 8175, 294, 538, 9697, 300, 2113, 13, 663, 311, 437, 5585, 2113, 26643, 307, 13], "temperature": 0.0, "avg_logprob": -0.18465989752660825, "compression_ratio": 1.7043010752688172, "no_speech_prob": 0.00015112943947315216}, {"id": 550, "seek": 458700, "start": 4587.0, "end": 4598.0, "text": " So it that's implemented in Elm with a couple couple of very small bindings through custom back end tasks to do to use the crypto API to do encryption and decryption.", "tokens": [407, 309, 300, 311, 12270, 294, 2699, 76, 365, 257, 1916, 1916, 295, 588, 1359, 14786, 1109, 807, 2375, 646, 917, 9608, 281, 360, 281, 764, 264, 17240, 9362, 281, 360, 29575, 293, 979, 627, 1695, 13], "temperature": 0.0, "avg_logprob": -0.2214247856611087, "compression_ratio": 1.619047619047619, "no_speech_prob": 7.481680222554132e-05}, {"id": 551, "seek": 458700, "start": 4598.0, "end": 4611.0, "text": " And, and then doing Prisma for the database persistence. And the rest is all in Elm pages directly and manages the cookies and all that gets the logged in users to do items.", "tokens": [400, 11, 293, 550, 884, 2114, 14795, 337, 264, 8149, 37617, 13, 400, 264, 1472, 307, 439, 294, 2699, 76, 7183, 3838, 293, 22489, 264, 13670, 293, 439, 300, 2170, 264, 27231, 294, 5022, 281, 360, 4754, 13], "temperature": 0.0, "avg_logprob": -0.2214247856611087, "compression_ratio": 1.619047619047619, "no_speech_prob": 7.481680222554132e-05}, {"id": 552, "seek": 461100, "start": 4611.0, "end": 4626.0, "text": " And it shows some pending UI. So as you're so if you enter a new to do item, hit hit create or whatever the button says, you will see the new item show up in your to do list with a little loading spinner next to it.", "tokens": [400, 309, 3110, 512, 32110, 15682, 13, 407, 382, 291, 434, 370, 498, 291, 3242, 257, 777, 281, 360, 3174, 11, 2045, 2045, 1884, 420, 2035, 264, 2960, 1619, 11, 291, 486, 536, 264, 777, 3174, 855, 493, 294, 428, 281, 360, 1329, 365, 257, 707, 15114, 44849, 958, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.2021346092224121, "compression_ratio": 1.423841059602649, "no_speech_prob": 7.842940249247476e-05}, {"id": 553, "seek": 462600, "start": 4626.0, "end": 4647.0, "text": " And that's all done declaratively. So the same logic for parsing that form that is used to parse that that form action on the on the server to parse a an action, you know, of creating an item deleting an item editing an item, checking an item,", "tokens": [400, 300, 311, 439, 1096, 16694, 19020, 13, 407, 264, 912, 9952, 337, 21156, 278, 300, 1254, 300, 307, 1143, 281, 48377, 300, 300, 1254, 3069, 322, 264, 322, 264, 7154, 281, 48377, 257, 364, 3069, 11, 291, 458, 11, 295, 4084, 364, 3174, 48946, 364, 3174, 10000, 364, 3174, 11, 8568, 364, 3174, 11], "temperature": 0.0, "avg_logprob": -0.22571125677076437, "compression_ratio": 1.6758620689655173, "no_speech_prob": 1.618646456336137e-05}, {"id": 554, "seek": 464700, "start": 4647.0, "end": 4662.0, "text": " yeah, checking an item off checking all items off. Those are these actions uses the same form parsers on the back end to respond in the action to actually handle performing those tasks on the database.", "tokens": [1338, 11, 8568, 364, 3174, 766, 8568, 439, 4754, 766, 13, 3950, 366, 613, 5909, 4960, 264, 912, 1254, 21156, 433, 322, 264, 646, 917, 281, 4196, 294, 264, 3069, 281, 767, 4813, 10205, 729, 9608, 322, 264, 8149, 13], "temperature": 0.0, "avg_logprob": -0.2380720485340465, "compression_ratio": 1.534351145038168, "no_speech_prob": 1.0782983736135066e-05}, {"id": 555, "seek": 466200, "start": 4662.0, "end": 4685.0, "text": " But it also uses those same parsers to say what are the in flight actions that are happening. And it uses that to derive all of the pending state of all of the of your to do items. So if you delete something, you can instantly show it as deleted, because it knows there is an in flight form that is deleting this item.", "tokens": [583, 309, 611, 4960, 729, 912, 21156, 433, 281, 584, 437, 366, 264, 294, 7018, 5909, 300, 366, 2737, 13, 400, 309, 4960, 300, 281, 28446, 439, 295, 264, 32110, 1785, 295, 439, 295, 264, 295, 428, 281, 360, 4754, 13, 407, 498, 291, 12097, 746, 11, 291, 393, 13518, 855, 309, 382, 22981, 11, 570, 309, 3255, 456, 307, 364, 294, 7018, 1254, 300, 307, 48946, 341, 3174, 13], "temperature": 0.0, "avg_logprob": -0.21168786126214104, "compression_ratio": 1.6914893617021276, "no_speech_prob": 1.406351657351479e-05}, {"id": 556, "seek": 468500, "start": 4685.0, "end": 4703.0, "text": " So I'm just going to show it as deleted and and elm pages has this is one of the really big features of on pages v3 is it has all of the in flight form submissions are managed for you. So you just run your form parsers on it, but you don't have to wire anything up to your model.", "tokens": [407, 286, 478, 445, 516, 281, 855, 309, 382, 22981, 293, 293, 806, 76, 7183, 575, 341, 307, 472, 295, 264, 534, 955, 4122, 295, 322, 7183, 371, 18, 307, 309, 575, 439, 295, 264, 294, 7018, 1254, 40429, 366, 6453, 337, 291, 13, 407, 291, 445, 1190, 428, 1254, 21156, 433, 322, 309, 11, 457, 291, 500, 380, 362, 281, 6234, 1340, 493, 281, 428, 2316, 13], "temperature": 0.0, "avg_logprob": -0.2183254294925266, "compression_ratio": 1.5414364640883977, "no_speech_prob": 3.88299667974934e-05}, {"id": 557, "seek": 470300, "start": 4703.0, "end": 4718.0, "text": " So with no model or managing anything in your update, you just say, what are the currently submitting forms? Here's my form parser, what are the currently submitting form actions, and then you derive your pending UI from that state.", "tokens": [407, 365, 572, 2316, 420, 11642, 1340, 294, 428, 5623, 11, 291, 445, 584, 11, 437, 366, 264, 4362, 31836, 6422, 30, 1692, 311, 452, 1254, 21156, 260, 11, 437, 366, 264, 4362, 31836, 1254, 5909, 11, 293, 550, 291, 28446, 428, 32110, 15682, 490, 300, 1785, 13], "temperature": 0.0, "avg_logprob": -0.18903556097121466, "compression_ratio": 1.691699604743083, "no_speech_prob": 1.4970582014939282e-05}, {"id": 558, "seek": 470300, "start": 4718.0, "end": 4728.0, "text": " So I recommend taking a look at that to do example, the live demo and the code. It's like, I think it's one of the coolest features of on pages v3. Like it's it's what I'm the most excited about.", "tokens": [407, 286, 2748, 1940, 257, 574, 412, 300, 281, 360, 1365, 11, 264, 1621, 10723, 293, 264, 3089, 13, 467, 311, 411, 11, 286, 519, 309, 311, 472, 295, 264, 22013, 4122, 295, 322, 7183, 371, 18, 13, 1743, 309, 311, 309, 311, 437, 286, 478, 264, 881, 2919, 466, 13], "temperature": 0.0, "avg_logprob": -0.18903556097121466, "compression_ratio": 1.691699604743083, "no_speech_prob": 1.4970582014939282e-05}, {"id": 559, "seek": 472800, "start": 4728.0, "end": 4733.0, "text": " That does sound very, very good. Yeah, I'm very curious. I'm gonna look at it. When I can.", "tokens": [663, 775, 1626, 588, 11, 588, 665, 13, 865, 11, 286, 478, 588, 6369, 13, 286, 478, 799, 574, 412, 309, 13, 1133, 286, 393, 13], "temperature": 0.0, "avg_logprob": -0.19942994403024006, "compression_ratio": 1.6488549618320612, "no_speech_prob": 3.883001409121789e-05}, {"id": 560, "seek": 472800, "start": 4733.0, "end": 4755.0, "text": " I love that declarative approach. You're not imperatively, you know, if they click Delete on this, then add it to this list of deleting things. Or it's just like, no, there's a list of all the actions. And you kind of just have that and say, Okay, well, if I have these pending actions, then what is my UI state, and you derive it from that.", "tokens": [286, 959, 300, 16694, 1166, 3109, 13, 509, 434, 406, 10100, 19020, 11, 291, 458, 11, 498, 436, 2052, 49452, 322, 341, 11, 550, 909, 309, 281, 341, 1329, 295, 48946, 721, 13, 1610, 309, 311, 445, 411, 11, 572, 11, 456, 311, 257, 1329, 295, 439, 264, 5909, 13, 400, 291, 733, 295, 445, 362, 300, 293, 584, 11, 1033, 11, 731, 11, 498, 286, 362, 613, 32110, 5909, 11, 550, 437, 307, 452, 15682, 1785, 11, 293, 291, 28446, 309, 490, 300, 13], "temperature": 0.0, "avg_logprob": -0.19942994403024006, "compression_ratio": 1.6488549618320612, "no_speech_prob": 3.883001409121789e-05}, {"id": 561, "seek": 475500, "start": 4755.0, "end": 4773.0, "text": " So that's one less. That's one less thing that could go wrong. Like this. For me, this is like one of my big opinions about coding, I guess, is when things are more declarative, there are fewer things that you can get wrong. So on pages is very declarative. I hope I hope people will agree.", "tokens": [407, 300, 311, 472, 1570, 13, 663, 311, 472, 1570, 551, 300, 727, 352, 2085, 13, 1743, 341, 13, 1171, 385, 11, 341, 307, 411, 472, 295, 452, 955, 11819, 466, 17720, 11, 286, 2041, 11, 307, 562, 721, 366, 544, 16694, 1166, 11, 456, 366, 13366, 721, 300, 291, 393, 483, 2085, 13, 407, 322, 7183, 307, 588, 16694, 1166, 13, 286, 1454, 286, 1454, 561, 486, 3986, 13], "temperature": 0.0, "avg_logprob": -0.2173876633515229, "compression_ratio": 1.6201117318435754, "no_speech_prob": 0.00019410844834055752}, {"id": 562, "seek": 477300, "start": 4773.0, "end": 4802.0, "text": " Kind of has right it is Elm. And that's the way we do things. Exactly, exactly. That's right. Maybe one last thing to mention is on pages v3 has built in V integration as well. So the dev server, the dev server still has the same hot data reloading that v2 had you you know, if you if you have a page that reads from a file, and you modify that file, it automatically knows that the page you're looking at is the one that's going to be in the page that you're looking at.", "tokens": [9242, 295, 575, 558, 309, 307, 2699, 76, 13, 400, 300, 311, 264, 636, 321, 360, 721, 13, 7587, 11, 2293, 13, 663, 311, 558, 13, 2704, 472, 1036, 551, 281, 2152, 307, 322, 7183, 371, 18, 575, 3094, 294, 691, 10980, 382, 731, 13, 407, 264, 1905, 7154, 11, 264, 1905, 7154, 920, 575, 264, 912, 2368, 1412, 25628, 278, 300, 371, 17, 632, 291, 291, 458, 11, 498, 291, 498, 291, 362, 257, 3028, 300, 15700, 490, 257, 3991, 11, 293, 291, 16927, 300, 3991, 11, 309, 6772, 3255, 300, 264, 3028, 291, 434, 1237, 412, 307, 264, 472, 300, 311, 516, 281, 312, 294, 264, 3028, 300, 291, 434, 1237, 412, 13], "temperature": 0.0, "avg_logprob": -0.3757577142795595, "compression_ratio": 1.7706766917293233, "no_speech_prob": 0.00013134720211382955}, {"id": 563, "seek": 480200, "start": 4802.0, "end": 4816.0, "text": " So it knows that the page you're looking at, dependent on the file you touched, and it will hot reload the the back end task for that for that route. In addition to that, so try out the dev server. It was a lot of work. I hope you enjoy it.", "tokens": [407, 309, 3255, 300, 264, 3028, 291, 434, 1237, 412, 11, 12334, 322, 264, 3991, 291, 9828, 11, 293, 309, 486, 2368, 25628, 264, 264, 646, 917, 5633, 337, 300, 337, 300, 7955, 13, 682, 4500, 281, 300, 11, 370, 853, 484, 264, 1905, 7154, 13, 467, 390, 257, 688, 295, 589, 13, 286, 1454, 291, 2103, 309, 13], "temperature": 0.0, "avg_logprob": -0.28413545517694383, "compression_ratio": 1.5, "no_speech_prob": 0.0010004296200349927}, {"id": 564, "seek": 481600, "start": 4816.0, "end": 4836.0, "text": " It's a girl. It has a built in integration with VJS. So now you can you can read about that more in the announcement blog post. But But yeah, you can define your own custom V configuration, and the dev server will use it and the production build will will use it as well. Yeah. So that's on pages v3.", "tokens": [467, 311, 257, 2013, 13, 467, 575, 257, 3094, 294, 10980, 365, 691, 41, 50, 13, 407, 586, 291, 393, 291, 393, 1401, 466, 300, 544, 294, 264, 12847, 6968, 2183, 13, 583, 583, 1338, 11, 291, 393, 6964, 428, 1065, 2375, 691, 11694, 11, 293, 264, 1905, 7154, 486, 764, 309, 293, 264, 4265, 1322, 486, 486, 764, 309, 382, 731, 13, 865, 13, 407, 300, 311, 322, 7183, 371, 18, 13], "temperature": 0.0, "avg_logprob": -0.27933375866382154, "compression_ratio": 1.530612244897959, "no_speech_prob": 4.198332680971362e-05}, {"id": 565, "seek": 483600, "start": 4836.0, "end": 4857.0, "text": " Yeah, that's a lot of information. Yes. The docs are are big, because the API for the tool is big, because I mean, it's doing a lot of things in practice, like, like, oh, well, let's just add these primitives to read files. Oh, well, now we can render things to", "tokens": [865, 11, 300, 311, 257, 688, 295, 1589, 13, 1079, 13, 440, 45623, 366, 366, 955, 11, 570, 264, 9362, 337, 264, 2290, 307, 955, 11, 570, 286, 914, 11, 309, 311, 884, 257, 688, 295, 721, 294, 3124, 11, 411, 11, 411, 11, 1954, 11, 731, 11, 718, 311, 445, 909, 613, 2886, 38970, 281, 1401, 7098, 13, 876, 11, 731, 11, 586, 321, 393, 15529, 721, 281], "temperature": 0.0, "avg_logprob": -0.1961405244592118, "compression_ratio": 1.5535714285714286, "no_speech_prob": 7.141540118027478e-05}, {"id": 566, "seek": 485700, "start": 4857.0, "end": 4886.0, "text": " now we can make API's now we can do a lot of things. Oh, now we need cookies. Oh, now we need sessions. Now we need forms. Now we are like, it's a lot. I know it's been a very big journey for you. Like, yeah, you've been working on this for like a year and a half. Yeah. So I'm really glad that you can now focus on something else. Even though I know you're still gonna work on the own pages like that's that's you.", "tokens": [586, 321, 393, 652, 9362, 311, 586, 321, 393, 360, 257, 688, 295, 721, 13, 876, 11, 586, 321, 643, 13670, 13, 876, 11, 586, 321, 643, 11081, 13, 823, 321, 643, 6422, 13, 823, 321, 366, 411, 11, 309, 311, 257, 688, 13, 286, 458, 309, 311, 668, 257, 588, 955, 4671, 337, 291, 13, 1743, 11, 1338, 11, 291, 600, 668, 1364, 322, 341, 337, 411, 257, 1064, 293, 257, 1922, 13, 865, 13, 407, 286, 478, 534, 5404, 300, 291, 393, 586, 1879, 322, 746, 1646, 13, 2754, 1673, 286, 458, 291, 434, 920, 799, 589, 322, 264, 1065, 7183, 411, 300, 311, 300, 311, 291, 13], "temperature": 0.0, "avg_logprob": -0.2929585105494449, "compression_ratio": 1.7078189300411524, "no_speech_prob": 8.092320058494806e-05}, {"id": 567, "seek": 488600, "start": 4886.0, "end": 4915.0, "text": " Right? Yeah, definitely. I hope people like it. I hope people also like the all the cool stuff you you you made possible with this, including just the tiny thing you mentioned at some point saying like, oh, we can do back end. Right? Yeah, I hope people enjoy it. Working people will go if they want to learn more like you have an announcement blog post, we will add that to the show notes elm dash pages.com I'm guessing.", "tokens": [1779, 30, 865, 11, 2138, 13, 286, 1454, 561, 411, 309, 13, 286, 1454, 561, 611, 411, 264, 439, 264, 1627, 1507, 291, 291, 291, 1027, 1944, 365, 341, 11, 3009, 445, 264, 5870, 551, 291, 2835, 412, 512, 935, 1566, 411, 11, 1954, 11, 321, 393, 360, 646, 917, 13, 1779, 30, 865, 11, 286, 1454, 561, 2103, 309, 13, 18337, 561, 486, 352, 498, 436, 528, 281, 1466, 544, 411, 291, 362, 364, 12847, 6968, 2183, 11, 321, 486, 909, 300, 281, 264, 855, 5570, 806, 76, 8240, 7183, 13, 1112, 286, 478, 17939, 13], "temperature": 0.0, "avg_logprob": -0.299205213490099, "compression_ratio": 1.6812749003984064, "no_speech_prob": 0.0003458603750914335}, {"id": 568, "seek": 491500, "start": 4915.0, "end": 4944.0, "text": " That's exactly right. Elm dash pages.com. We've got a doc site there and a and a blog. I might might write another blog post or two in the coming weeks and join the Elm pages slack channel. I'm very active there. Happy to answer questions. Check out the discussions in the Elm pages GitHub. Yeah, like let let me know what you build with it. Let me know what questions you have. Let me know what you want to see.", "tokens": [663, 311, 2293, 558, 13, 2699, 76, 8240, 7183, 13, 1112, 13, 492, 600, 658, 257, 3211, 3621, 456, 293, 257, 293, 257, 6968, 13, 286, 1062, 1062, 2464, 1071, 6968, 2183, 420, 732, 294, 264, 1348, 3259, 293, 3917, 264, 2699, 76, 7183, 29767, 2269, 13, 286, 478, 588, 4967, 456, 13, 8277, 281, 1867, 1651, 13, 6881, 484, 264, 11088, 294, 264, 2699, 76, 7183, 23331, 13, 865, 11, 411, 718, 718, 385, 458, 437, 291, 1322, 365, 309, 13, 961, 385, 458, 437, 1651, 291, 362, 13, 961, 385, 458, 437, 291, 528, 281, 536, 13], "temperature": 0.0, "avg_logprob": -0.3048803088734451, "compression_ratio": 1.7095435684647302, "no_speech_prob": 0.0004043028748128563}, {"id": 569, "seek": 494400, "start": 4944.0, "end": 4955.0, "text": " Let me know what docs you think could be improved. I would love to hear from people and see what they end up building with it. All right. And you're in until next time. Until next time.", "tokens": [50364, 961, 385, 458, 437, 45623, 291, 519, 727, 312, 9689, 13, 286, 576, 959, 281, 1568, 490, 561, 293, 536, 437, 436, 917, 493, 2390, 365, 309, 13, 1057, 558, 13, 400, 291, 434, 294, 1826, 958, 565, 13, 9088, 958, 565, 13, 50914], "temperature": 0.0, "avg_logprob": -0.23371379271797513, "compression_ratio": 1.3703703703703705, "no_speech_prob": 4.3309308239258826e-05}, {"id": 570, "seek": 497400, "start": 4974.0, "end": 4988.0, "text": " Transcribed by https://otter.ai", "tokens": [50414, 6531, 18732, 538, 34426, 21492, 310, 391, 13, 1301, 51064], "temperature": 0.0, "avg_logprob": -0.3893229166666667, "compression_ratio": 0.7948717948717948, "no_speech_prob": 0.99896240234375}], "language": "en"}