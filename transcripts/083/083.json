{"text": " Hello Jeroen. Hello Dillon. Well, I've been playing around with a fun feature in Elm Review that we haven't really talked about before. Wait a second. Where's the pun? I've got to keep you on your toes Jeroen. The pun might spring out at any point. We started the recording and I was like, oh no, I forgot he was going to do a pun and I'm not prepared. The one time you were mentally preparing. Kind of on the late side and now you're like, there's no pun? What? I thought I could extract a reaction from you. Okay, that's fine then. We have standards, man. That's why we have linters. We need standards. We got to deliver. So today, we haven't really talked about this on the podcast, but there's this whole feature that's kind of like pretty powerful in Elm Review. The extractors. So do you want to tell us what Elm Review extractors are? Yeah, sure. So Elm Review has this new feature, which is extractors, which allows you to gain insight into your code base. So you run an Elm Review rule and it's going to gather a lot of information. And then it's going to be able to give you that information as a JSON output. And you can read that JSON and you can figure out whatever information you wanted. So what kinds of information can you get? Well, that entirely depends on you and on the rules that you've enabled or written. So one very small example that I made is making an import graph of your modules. So what Elm Review is going to do is it's going to look at your whole Elm project. And it's going to notice, okay, well, this module is importing this thing, this other module, this other module is importing that module, and so on and so on. And it's going to internally make a graph of the imports. And at the end, it just says, well, I've made those into a graph or a list of arrows. And this is now like it's going to format it as a mermaid diagram or a dot graph diagram. And you can now use that to generate an image using the dot specification, the mermaid specification, whatever. So but this information is just like one rule is saying, well, I'm going to gather this information and then present it as a graph. It's not something that is built into Elm Review. It's just whatever you configure your rule to do. Right. Yeah, it's really it's like allowing the context that you have that you build up in Elm Review to escape from the bounds of Elm Review to the outside world. So you can use it in external tools however you want. So it's yeah, it's really like so you've got like, you know, if for anyone who's familiar with writing Elm Review rules and, you know, using visitors to update the context, which we've talked about in previous episodes, that would be akin to your update function updating your model. You know, you have in the Elm architecture, this tuple you return from update of the model and commands. And in Elm Review, visitors can change the context, which would be like updating the model. And they can return errors or fixes, which would be like running a command. But extractors, instead of resulting in fixes and reporting errors, you can you're given the context at the end of running the rule, and then you can turn that into JSON. Right. That's all it that's all it really is. Absolutely. Yeah. But the what you can do with that is it's anything anything that you can do by visiting an Elm project, extracting context from that and turning that into JSON. Now you have access to that in any external tool. So we said it's JSON, but in practice, it's whatever can be encoded as JSON. So if you if you just want it to be YAML, then you just make a string that is YAML format in practice. The way to use this feature is to call the Elm Review CLI with a dash dash extract and also dash dash reports equals JSON. Otherwise, you won't get the extracts and then we'll give you a JSON. But that contains arbitrary JSON. So if you want it to be a string that contains the YAML, whereas in YAML format, that's fine. That's kind of what I do with the imports graph, because that's just dots, specification strings. Right. Right. So you can Yeah, it's it's JSON at the top level. But inside of those JSON values, it might just be a single JSON string, which is actually a different data format. Yeah, I've I think there are a few different ways that you could approach. I mean, it depends on what you're trying to do with it. You could directly encode some format if you need some mermaid format or some markdown format or whatever you want to encode to. You could just directly encode to those data formats if you're consuming it from another Elm app. Then you could use something like Elm codec to share your codec to encode the JSON data and then decode using code sharing between the code bases. If you're consuming it and extracting from from Elm code. So, well, this might be a good opportunity. You're in this might be a bit of an intervention. Actually, it turns out I I've spoken to you about my idea of Elm code Elm pages code gen review. So pages code gen review. OK, sure. Yeah. Are you sure it's not Elm review pages code gen? We can we can negotiate. Which which comes first? Absolutely. I'm open to that. But the the main point. So, well, I recently kind of brought my my Elm pages code gen idea to fruition. And I'm quite happy with it. I kind of joked about that in our code gen episode with Matt Griffith. But the challenge there being what was your idea again? Right. So, OK, so there are Elm pages scripts. Elm pages v3 has this thing called a back end task, which, you know, it's like a pretty full featured API for reading files from the file system and doing globs to list out files and reading environment variables and handling failures. If something if there's a fatal error, you can pass that up at the top level of the script and it will report that with rich information. Or you can handle fatal errors and make sure that you've handled every possible failure. So now Elm code gen, we did an episode on that. It's an amazing tool that lets you write Elm code to generate Elm code. And it, you know, to me, its main superpower is giving you like these sort of type safe ways to to put together bits of code and make sure that you're passing them the data that they need, because it creates these little stubs for different packet like bindings for different packages that helps you make sure you're generating valid code for those APIs. It also has a little CLI tool that helps you generate code. But then the challenge becomes, OK, well, but now I want to pass in some data to it. So, OK, the CLI that Elm code gen provides gives you this little hook that lets you pass in some JSON data. And then, well, what if you want to read an environment variable? OK, well, encode that into JSON and pass that in as a flag when you call the Elm code gen CLI. And then, well, what if you want to read, you know, you want to read an environment variable, you want to read a file and pass in that context. You kind of have to hack something together. Yeah, it feels like you need to do a bash script to gather the information and then call Elm code gen. Exactly. And and then like, well, should Elm code gen give you access to environment variables? Should it give you a first class way to do that? Should it give you a first class way to read files? Should it give you a nice way to do error handling and report that something went wrong? Which it does. But at a certain point, it's like becoming a more general purpose sort of scripting thing. So and that's sort of like back end task is a pretty general purpose way of doing that sort of thing. Elm pages scripts. I've like put a lot of polish into making it like you just do Elm pages run path to your own pages script, which is in a script project folder. And it figures out how to compile and run it. And you can even do, you know, Elm pages bundle script and it will compile and minify that down to a single executable JS file. So you can just chmod it, make it executable and run it. And if you have node installed, it'll just run as a single file with all the dependencies in line. So like should Elm like Elm code gen if it tries to is going to creep too far towards that. And we're going to end up like reinventing the wheel over and over. And then like, well, what about Elm review? Like, should it? Because there are certain things you might want to do. You might want to write some of that context to a file. You might. So at a certain point you run into a similar thing. And so I was I was recently hacking on some of these ideas that we talked about in our Elm and AI episode. And I was making an Elm pages script that calls the GPT for API and super fun. And I essentially wanted to take like the the in scope type annotations, kind of like we talked about, like what, what values are in scope? Like what are the direct dependencies that are available to me? And what are the like values that are in scope, the let values, the parameters that are in scope, right? Elm review knows. So that you can feed all of that information to GPT. Exactly. I can seed the prompt with that context. So like Elm review isn't, you know, you're not going to make Elm review something that can like make HTTP requests and like do scripting tasks and write something to a file or print arbitrary things to the console. Like at a certain point, you run into the same problem, right? Yeah. So Elm review pages code gen. dash GPT. Because essentially, like, I want to bridge the gap between like, I essentially want to make an Elm review rule that is like a context gatherer. Yeah. Which is good, because that's exactly what the Elm review rule does. It gathers context. It got, yeah, it gathers context. And then instead of saying, like defining a data extract, like with data extractor, that turns it into JSON, I want to say, like, here's my Elm pages script. And here is my Elm review rule that gathers context, pass that in as an argument to my Elm pages script. And then given that context, I can now execute a script, which calls Elm code gen. Yes, exactly. So the Elm code gen thing I already, I mean, it's actually fairly straightforward. You just in your Elm pages script project folder. So just like Elm review has a project folder, a review folder, that's just a regular Elm project. Elm pages scripts also have, you know, by convention, you can call it a script folder, but it's just any Elm project, which has Elm pages installed as a dependency. By the way, I really like that we've kind of started using this pattern that I think I introduced. I believe so. That's definitely what clued me into it. I mean, it's like, oh, it's a folder for configuration, but it's like, yeah, but it works really well. So because, yeah, because you can think of it just like a regular Elm project. You can use your editor tooling and it understands what an Elm project is. So yeah, it's amazing. So in that script project folder, you just have an Elm code gen project, like the generated source as a source directories. Yeah. And then you're good to go. So then you generate the Elm code gen bindings there. That's all you really need. Right. So there's not that much to that, you know, sort of combining those two tools together. It's actually a pretty loose coupling, but it works well. So, yeah, I've definitely thought about like how this could be done with Elm review and Elm pages. Yeah. So you were mentioning it was an intervention. What do you mean with an intervention? The intervention is... Where's my family? Can I pressure you? We're worried about you, Jeroen. And we really think that you need to make Elm review pages code gen. Yeah. I mean, I think it would be an interesting thing to explore. It's sort of this question of like, so like potentially if Elm review had a way to call it through like some Node.js dependency, so you could like import some Node.js version of Elm review and run it. That could be interesting. Okay. You mean calling Elm review programmatically instead of... Exactly. Right. Because basically, I mean, so you can certainly use, you can certainly like build up project context and use like a codec to share your encoders and decoders. And that works pretty well. Actually, the Lambda compiler also has this sort of undocumented way to create encoders, decoders of bytes, encoders. And so I've definitely considered like just hacking together a little prototype that I think I could do this, assuming that they're serializable values, things like functions are not. That's one benefit to doing it this other way where you can programmatically call Elm review because then it can execute this Elm code for you. So it's interesting. But I mean, at the end of the day, it's, I guess the point I'm trying to make is that like, this is a really powerful feature. And I think we should like build more cool stuff with it. I'm not gonna convince you otherwise. I have announced it, I think in November, even though the feature was released probably a little bit earlier than that. No, I announced it in December, but it was released in November. Yeah, it's a running blog post is a pain sometimes. Yeah. Have you heard of any cool things people have built with it? No, in practice, or at least people have not told me. They haven't shared it. Well, listener, if you have built something cool with it, tell your own because he's interested. Maintainers like to know those things. Yeah, they like feedback. Yes, good ones. Yeah, absolutely. Well, I had a really good time building with it, like just being able to like do a direct dependency visitor and extract the information is so nice. You know, I mean, you've built these API's for going and extracting information for for use with reporting rules and fixes. So why not break it outside of the box? Yeah, I did add extractors to a few of the rules that I made. Yeah, some of them published and some of them I haven't yet, at least. So for instance, I have this rule for licenses, which is called no approved license, which is basically going to forbid you from using licenses that your project has not cleared or have not accepted. Like, for instance, yeah, our company is not allowed to use license XYZ. GPL licenses and things. Yeah. Yeah, it's something that doesn't allow proprietary licenses, whatever, I'm not that familiar. And this rule is going to tell you, well, this dependency is using a license that you can't use, or this dependency is using a license that you have not mentioned as being okay or not okay. So you need to ask your legal team what you think should be done. And at my company, we are a security firm. So we need things to be good legally and security wise. And one of the requirements that we have is that we need to know the licenses of the things that we use. And I think we need to make it available publicly. I think I've never seen it before, actually. Right. So every now and then, or actually, every time we update our dependencies, we need to inform some legal entity in our company, which licenses we're using and which dependencies we're using. And so what I've made for this rule, I've changed it so that it has a data extractor that gives you the licenses that you're using for each dependency. So dependency elm slash core is using MIT or something like that. So that's now the process of listing the license that we have is automated, which previously we had to do manually. It's not a big deal in the case of our dependency, because we don't have 50 of them. It's a lot more painful for our JavaScript dependencies or NPM dependencies. But it's a nice thing to automate. Another one that I've worked on, which I have not published yet, because I forgot about it. Was the no deprecated one. Yes. Are you familiar with that rule? Yeah, I think so. Does it look for like an at deprecated annotation or something in the doc comments? Yeah, exactly. So everything that you annotate as deprecated, either through that at deprecated in the function or the modules documentation, or something that has deprecated in their name, which you can easily do in application code, like, oh, this thing is deprecated. So let's rename it. That makes it obvious everywhere. This rule is really meant to be used with ElmReview suppress, so that all the things that you have deprecated, you will be able to continue using, but you should not add more usages of those. So ElmReview suppress is really working very well with that rule, in my opinion. The problem, though, is that it doesn't tell you what to tackle next. Suppressions are meant to be resolved. They're meant to be tackled at some point. You should get rid of those. And the suppression files are meant to be readable by human and even edited, potentially. So you can see which files have the most usages of deprecated things. So file A has 47 issues, file B has 23. And regardless how you want to tackle those, you can say, okay, well, I'm going to try to remove all the ones from file A or file B or whatever. But that only gives you like one aspect of what to tackle, like which files you should look at. But it doesn't tell you what deprecated things are used most. That is something that you're going to have to look at yourself, right? And that can be a bit painful if you really want to get that information. So what I made is I added a data extractor, big surprise here, where that is exactly the information that you're getting out of, is which things are deprecated. And are they deprecated because the module is deprecated? Or are they deprecated because they have been tagged as deprecated? And then in how many places are they used? And then you can see, okay, well, this function, this deprecated function is used two times. So it will be pretty easy to fix. And this function is used 230 times, which is like, okay, well, that's going to be harder. Maybe it's more interesting to tackle that one now. So now you have the information of where the deprecations are in which files. You have the information of which deprecated things are used and how often. And now you have more information to tackle those issues, which I've found to be pretty interesting. So I should just focus on releasing that one. If it's not released by the time that you listen to this, and you're interested, let me know. Like, kick my butt, something. Very cool. I like that idea a lot of kind of bundling an extractor directly into these rules. That seems really cool. So like, do you think that that is a good general practice? Are there specific contexts where that works better? Like where a rule has context that's meaningful on its own, as opposed to like, like imports, they don't really necessarily tell you anything. Whereas like licenses, you just list out the licenses. I don't know. I haven't made any, I haven't uncovered any specific rules about rules and data extractors. It's like, it's more like, I need some insight to do some task, and I need to, in order to do something. And if there happens to be a rule that's that relates to that, then maybe it's interesting for that rule to do it. In the instance of no deprecated, the issue is how do I fix those application issues? So that's really related to the rule. So I think it makes sense to have the data extractor bundled along with it. Will it? I guess there's probably not much of a performance cost because the no deprecated is going to collect that information regardless. So then it's just like, do you encode that context to JSON or not? But does it basically skip executing the JSON encoding part if you don't use the extract flag in the CLI? Exactly. I don't know if people are going to make things that are very expensive to compute, but I'm assuming it will be. So yes, I'm skipping work. If I notice that people that were not reporting in JSON format, and we're not asking to extract something. So we will still need to collect all the information. There's no special case like, oh, if we're trying to extract, then we will collect things differently, which could be nice in practice, but would also make the rule a lot more complex. But we will skip calling the data extractor if it's not requested. So yeah, for the licenses, I think it makes sense to have a list of licenses that go with that rule. For instance, what rules could you have with no unused variables? Like, could you make a graph of what other functions could be removed if we removed it? Maybe. Would it be worthwhile? I don't know. I don't think so, so far. I mean, I think it's a rule of thumb. If it's like a clear cut set of data to extract, then maybe bundle it with it. But you could potentially even make that configurable since ElmReview is configured through plain Elm code. You could pass in options for an extractor. But I mean, at that point, I mean... You could have a data extractor enabled or disabled based on configurations. It really depends on what you want, right? Right. What is the purpose of preventExtract? There's something in the ElmReview API to prevent an extractor. So the use case I had for this was like something for detecting unused CSS or something like that. You could imagine that you have a rule that tries to find all the CSS classes that are used in your application and returns a list of these CSS classes. This is not even about unused. It's just like this rule will try to find all the CSS classes that are referenced in your Elm code. And then you can pass that into a tool that prunes your CSS files by removing all the CSS classes that are not mentioned and so on. So for this rule to work, all the places where you would reference a CSS class, it would have to be in known position. So for instance, if you pass a CSS class to HTML.attributes.class, then it's known. It's extractable and it's easy to see what this value is used to be a class or this value is a class. But if you pass a variable to that function, to the class function, then it's a lot harder to figure out what the CSS class was. And in that case, you could have the rule say, hey, I encountered something that is unknown to me and I prefer reporting an error and you will have to fix it. And this is something that we have at our codebase at Crystallize. And so the user will see that there's an error, but potentially you would also want to say, well, given this problem, I don't want to give you the extract. I'm going to prevent this extract or this issue. If you ask me to do an extract and there is this kind of issue, I'm just going to give you something that is incorrect. So let me just stop the extraction. So that's what this function is for. So whenever you create an error, you can annotate it as preventing the extract. Right. So just to make that explicit, it's a prevent extract is a function that you call on an Elm review error. So in the course of your rule, whether it's your no unused CSS classes rule or whatever it might be called, you can give an error. And then you can pass that error to prevent extract. And that error will now have that special behavior that when you call it the CLI with the extract flag, that error will propagate through and prevent it from giving the final JSON for extract. That's very cool. So whenever you will run Elm review extract and report JSON and don't like the UX so far, because it will give you like null or undefined for the extract where you expected it. And you basically have to run Elm review again without those flags in order to find out which errors have popped up. It's not great, but I see. Yeah, it's good enough so far, at least until someone brings it. It lets me know if I get an idea. Right. I guess you could like have a special error format and you could provide like an error decoder. I mean, this is assuming that people are consuming it in Elm, but even if they're not consuming it in Elm, you could make it a fairly lightweight format where you give an easy to consume error message. Yeah, but the problem is that that could be like you would write an arbitrary JSON value to say, hey, this didn't work out. Right. But that could also be in a valid value for that rule. Right. Totally. I actually don't remember what I do exactly. Maybe I do something like show an error in the JSON. But in practice, when you run it with JQ to extract the exact information you want, you get a null. You get a null. Yeah. Yeah. So it's a bit annoying. That makes sense. Yep. But if you consume this through a Node.js script, then you could do more checks like, oh, if rule name dot error equals something, then exactly something bad happens or something. Yeah, it totally depends on how you're using it. I would like to think maybe you're using it from Elm review code gen pages, but one page is now at the end. I'm using it as a bargaining chip to try to build consensus. The only part that I thought should not be at the beginning is code gen. And that's what you just did. So let's at least call it ElmU something or Elm pages something. But Elm code gen is not appropriate here, I'd say. Matt would have to come on this show and tell us otherwise. But yeah, that's true. In the meantime. Okay, you can have code gen first or review first. So why don't we talk about like a couple of other possible use cases? I mean, again, really, it's really just taking these cool features in Elm review, which are, you know, giving you the ability to have visitors that look at expressions, which let you look at the abstract syntax tree of an entire project and walking through looking at what imports for a particular module are there. What are the direct dependencies, indirect dependencies of project, looking at the readme, looking at doc comments, and gathering up context to connect these things together. So, you know, of course, like, you can imagine the kinds of context, you would have to build up for marking certain values as unused or things like that. So building up like pretty sophisticated context about where how things connect together and things like that. So given that, actually, on that topic, like, Elm review is not necessarily super easy tool to use, right? Like, writing a rule takes a lot of code in practice. Like if you have to do something really quick, I would not use Elm review rule for to extract something out of the code base, like I would use something like grep, or combi or tree grappler, which Brian Hicks made a few years ago. Which are like, you just say, like, which patterns you're interested in, and you can then extract that information. The thing where Elm review is very powerful is it gives you a little more semantic analysis, like, you know, it's easy to figure out, well, this, this function is that from a local is defined in this in this module, or is it from a, an important module or from a dependency? And if so, which one? Like the module lookup table? Exactly. Would that be what you're talking about there? Yeah. Potentially type inference, potentially other kinds of information. And we were Elm review shines is because it's not just a specification on how you can extract certain AST notes or specific information from ASTs. But it's a, it's like, it's literally code, you can put all those contexts into, you can find all those things. You can find connections between those contexts. So for instance, if you want to detect unused variables, you need to connect all the declarations of variables with usages of the variables. If you just try to pattern match on a nodes individually, you're not going to be able to do that, you're going to have to write an external system, internal external things to be able to deduct that, to deduce that. So that's, I think where Elm review is really powerful is it allows you to put those things into context. Right. It sounds kind of like, you know, should I use a reg X or a parser for this? Yeah. And if you're trying to like extract semantic information from HTML, then reg X, you're going to have a bad time with because, you know. Yeah. But in some cases, like, especially if it's for a quick and dirty thing, grep will be very good. Combi will be very good as well. TreeGrepper, I'm guessing as well. It's probably the same thing, the syntax I'm just not familiar with. But if you need something that will need to be correct or something that needs to be used a lot of times, something where you need less false positives or less false negatives, then Elm review will be very good. That said, in a lot of cases, like depending on what information you want to get, you will not be able to get it. Like a static analysis tool is sometimes limited, right? Right. Dynamic values. There are certain things that Elm review makes very high level that would be a ton of work to gather manually. For example, like extracting information about the direct dependencies of a project, which I was trying to do for my particular use case with this kind of AI prompting context builder. You provide like a fairly high level API where that information exists somewhere on the file system. You might even have to like run Elm make on something to like make that come into existence somewhere. I actually download everything manually. I look at the Elm home and if it's there, I use that. Otherwise I download things. Right. So if you're building a quick and dirty script, it's not going to be quick, but it will be dirty if you try to get that information yourself. Whereas if you use Elm review, you just get like a nice Elm type that describes the direct dependencies and all of the types and values it exposes. So that's pretty powerful. Like the one thing I see that's definitely a little tricky is like Elm review rules are not super composable. Like visitors, it's hard to like bundle up visitors together. You sort of have to say like, okay, this visitor is going to go and update the context by looking at imports and this visitor is going to update it. But you can't really have a self-contained like, all right, here's my Elm review thing that does like five different types of visitors. And it gives you, you can't have like nested T, nested Elm architecture, review visitors. That's like a combined visitor that somebody published as a helper. Actually, you can. Can you really? Yeah. Oh, I had no idea. Not in the shape that you think. The thing that is possible is you can add multiple visitors of the same type. So you can have multiple with expression visitor, multiple with declaration visitors. Right. The module name lookup table, which you mentioned before is a basically Elm review pre-computes for every node in your AST where something was defined. So if you have a function, is it defined in an import, in a module? And if so, which one or is it defined locally? That was not in Elm review to start with. That was actually in a package that I purposefully did not publish for maintenance reasons. But you could basically copy paste that code and just add a function that says add visitors for scope. I think it was scope dots, add visitors, something. And that added all the visitors that that sub rule, sub information gathering thing needed to modify your context. Like it was specifically modifying one field in your context. And then that was available to all the other rules, to all the other visitors. So it is possible. It's just not in the way you want to. And in practice, it's not done very often. Like I've basically only use it for that purpose and I quite liked it. So it's still feature that is not very well documented. And also like I'm thinking about removing it because like things are slightly faster if they're not a list of visitors. Like maybe visitor under the hood, but it is possible and it is a nice feature when it's necessary. Would that allow you to, you probably wouldn't have access to that, like prepared finished context by the time your visitors run? Or could you, could you make sure that those visitors all run before your visitors subsequently run so they have access to that context? Yeah, yeah. Okay. Yeah. And that's very powerful. Interesting. Yeah. It's depends on what you want to do, but yeah, potentially all those, those rules can do whatever they want to. Those, sorry, those helpers can gather all the information you need. But depending on the information, that will be more or less easy, but usually it's pretty easy. Hmm. Interesting. Because they're running in a specific order, which makes that easy. That's pretty cool. I would love to see like people sharing the cool stuff that they build with this. And like, I don't know, maybe we should host a, an ElmReview extractor hackathon Jeroen to get, because there's so much cool stuff you could build with this functionality. Yeah. So the main thing that I was thinking about, like that could be pretty, that is pretty generic and it could be useful is like extracting metrics out of your code base. So lines of code is the easy one, which there are many powerful tools for that. There's just simple, the WC command line tool, there's clock and there's plenty of others, I'm sure. So maybe that's not the best metric, but that's the kind of idea that you could do. At the moment, one of my colleagues is I think working on computing the complexity of the code base. So there's the cognitive complexity, which I made a rule for. I think he will probably try that first, which by the way, there's now a data extractor, I think. Cool. Somewhere, maybe in a branch of mine, maybe it's just on my computer. I think, at least it would be very easy to make it. That's for sure. Because it's just extracting the context to JSON. But yeah, there's also cyclomatic complexity, which is basically a measure of how many unit tests would you need to cover all the branches for a given function. And that's a reasonable metric, not to tell you how to refactor your code. Cognitive complexity is better for that. But cyclomatic does tell you, well, this code is pretty complex, or this project is pretty complex, because there's a lot of edge cases that it needs to handle. And you could make a graph out of that. So at LogScale, we're a log product, we just send all of our logs to LogScale, and then we can make dashboards with it. And when we run Elm Review in our CI, well, we have those metrics available. Well, we can run Elm Review with dash dash extracts, dash dash report JSON. And that gives us metrics. And then we can extract those and try to make dashboards out of it. And yeah, then whatever metrics you think are useful to you. Like, this is an area where I'm not all that familiar with, like what metrics are interesting to gather for a technical depth finding platform or something. There's a tool called CodeScene, where they basically gather a lot of this information, like notably the complexity, but also like the get information from your code base. And they say, well, the files that are most that are touched the most often are usually the ones with bugs. And we can try to combine the information of how often is something touched and how complex is the the file in terms of cyclomatic complexity. And you could say, well, this is probably where we need to address technical debt, or this is where it'd be useful to to put our eyes on. Yeah, exactly. I mean, you could even just extract the length of certain functions. Yeah, as a for instance, yeah. So Elm Review does not have access to get information. But it does have access to a lot of other information. And I think at some point, you will, I will just make it available to you to extract information from arbitrary files in your project. Yeah, cool. Like just trying to be able to read CSS files, and figure out which CSS files or which CSS classes are available or unused, even. That'd be useful, I think. So that's, that's the idea behind that thing. Yeah, it's super powerful. Yeah, I mean, and you can start piecing these ideas together, you know, you start gathering metrics. I mean, you know, what metrics can you gather from a code base number of lines number of number of non opaque types, perhaps? Potentially, yeah. Like, I don't know if there are metrics for noticing like how coupled something is, a couple of one module to another is to another. But if there's those things, and potentially that there's a thing that you could put it on a dashboard and try to follow and try to reduce or try to increase, I don't know. Test coverage, but yeah, that's not Elm Review. There's a different tool for that. Yeah, yeah. And yeah, and there is Elm coverage, which actually works pretty darn well. But, but yeah, like, look for things like, you know, checking if something is not an opaque type, like, as much as we would like for that to be a rule that just reports an error, error, non opaque type found, there are use cases where you want an exposed custom type. And so it's, it's not a problem. It's a, it's a thing to be aware of. And so metrics, and visualizations and things like that are are useful. So that's the kind of area where extracting information rather than reporting an error is what you want. Yeah, like if your company or if your project has a specific use case of something that they'd like to increase or decrease or collect somehow, then you can make a rule for that. And you can extract the information and display it somewhere. But yeah, like this is really something that I have not looked into. And clearly, like, I don't know what metrics are useful. So if people want to play with that and know like, what could be useful, try it out and let me know. Yeah, I mean, you could really build like, a suite of Elm code quality tools and visualizations for it with this, you know, like, yeah, all the pieces are there. You could look at the number of maybes in a code base to write like, that's an interesting piece of information, like maybes aren't bad, but where are there more of them? Yeah, or the number of primitives, you know, primitive obsession, that kind of thing. But yeah, metrics are always kind of scaring that thing like, like, do we want to decrease this number even further? Like, sometimes yes, but like, it's not, it's not a fixed rule. That's, that's also like an area where this can get useful. It's like Elm Review has, like, it's really hard to say well, this, this rule does not apply everywhere. Elm Review basically, all the rules have to be 100% correct, in the sense that they don't report false positives, they can report false negatives, they can have false negatives, you can't report false negatives. But if you make that into, if you add an extractor to that, then you can extract that information without enforcing it on your project, if that makes sense. That's a possibility. I don't know if that will work out. But it's, it's something you could do. I think it's really good. It's a good workflow to just like, have this information, and then say, like, all right, what could use some refactoring. And then, especially if you like cross reference that with like, like, if you take, like you said, like, Elm Review doesn't currently have access to get information. But if you're building an extractor, you just extract what you need using Elm Review extractors, and then extract some information from the command line from Elm Review. And then you extract some information from the command line from Git of how frequently files are changed, you know, the churn rate of certain modules. And then you can just sort of cross reference those pieces of data in a in a script. And so you say like, okay, well, this file has a lot of churn, it has a lot of non opaque types, it has a lot of deeply nested conditional statements, it has a lot of maybes and primitive types. And it's churning a lot, we change, we touch it a lot, or maybe like bug fix commits touch this file a lot. So maybe that's a place to that that's just something to be aware of that it might be a hotspot. It doesn't mean the numbers need to go to zero, because they're bad inherently, it just is something to focus your attention on when you're looking for areas to refactor. So if you're missing some information in Elm Review, then yes, exactly. As you say, you can combine it with other information in a scripts. You can also do the opposite way of you can provide more information to Elm Review by adding it to the configuration or by you could generate that information into Elm code. For instance, that's what this what we do for detecting unused CSS classes in the workplace. We take the CSS files, and we generate an Elm file that the Elm Review configuration then fetches through simple imports. So you could again use Elm Code Gen for that. We chose to have something simpler, but right, especially because it's older than Elm Code Gen. Or Elm Review Code Gen pages. Yeah, exactly. Problem solved. Elm Review Code Gen pages, Code Gen Review. Yeah. You know, that's maybe one of those pitfalls that we have with the Elm community where we call everything based on what it does, like Elm Code Gen. Okay, it does Code Gen. Elm Review, it reviews. Whereas you have something like React. Oh, that's a cool name. It's not like it reacts to something. Right. Yeah, maybe here, like, it would be interesting to have a cool name, like, Elm, I don't know how to make cool names. Elm Linguini. Exactly. Yeah. Elm Spaghetti. I mean, if it's to find problems in your code base, like Spaghetti Code. Spaghetti Code. Yeah. To Spicy Meatball. Exactly. I mean, plenty of projects that are named that way for some reason. So yeah, if you're missing some information, you can try to combine it in one way or another. I like your idea a lot to, like you said, either Code Gen a file which is imported into your Elm Review rule, or you could like Code Gen something into your Elm Review configuration file and then pass that data in. Yeah. Or you could use Elm Review pages Code Gen. I think we should add CM at the end of that now. Just to make it longer. And I'm sure such a complex project would need a manager or a factory or something, you know. Absolutely. Absolutely. Yeah. So another, so actually, if we go down the route of what Elm Review can give you as information, it can go pretty far. Like one experiment that I tried was generating the docs.json file for packages or for any kind of projects. But yeah, mostly packages, which is like, basically the summary of the packages documentation. And that is what the Elm Packages website uses to show the documentation of a package. Right. And if you use Elm Duck Preview, that's also what it uses. Right. So I figured like, well, as a proof of concept, and this is kind of what I played around with to test things, I can generate that docs.json file, which is what the compiler does. Right. What does the Elm compiler also generate? Well, it generates JavaScript code based on the dependencies. Crazy. Yes, yes. Based on the Elm code. And like, technically, maybe with the limitation of how much JSON you can really output. Right. Potentially, you can write an Elm compiler using Elm Review. Whoa. Interesting. Yeah. So the Elm in Elm compiler could be made in Elm Review. That's a cool concept. Very interesting. Whether it will work in practice, I don't know. But that said, like, if I ever want to make Elm compile to something else than JavaScript, like, this could be a pretty easy way to get started. Like, you don't have to read files. You don't have to do all those things. Just take all the information from the Elm code and make an output. And maybe you'll be pretty far off. Yeah. And I mean, if you want to bridge the gap between Elm and other contexts, it's a pretty good start for that, too. I'm not sure if it would, like, help you. I don't think Elm Review would help you resolve. Maybe it would be fine. Like, if you wanted to do some code generation tasks, for example, like, for my old Elm TypeScript Interrupt project, I extracted information with the help of Elmite to JSON, which extracts information from the sort of binary stuff in the Elm stuff folder. And I used that to get the types of all of the ports for the project. But then I also had to do some static analysis to resolve which aliases pointed to which types so that I could turn them into actual primitives that I could send through ports and then build decoders based on that. Yeah, that's exactly one of the use cases where I could see Elm Review being used instead of a custom tool or custom script. Whether it will do better than another tool, probably not. It's like Elm Review is not that fast, unfortunately, but maybe I'm self-deprecating here. Yeah. Well, you'll have to suppress your self-deprecations, Jeroen. I will try to do so. But it's like trying to impose rules on myself is really hard, you know. Yeah, I think that's a pretty powerful use case, though. And I guess you totally could build that lookup table that resolves a type alias to what it actually points to. You could totally do that with Elm Review visitors. Yeah, I think that's a really cool use case. And I think that's really cool because you can have certain constraints where you say, this rule requires, for example, type annotations for these things. Yeah, exactly. I didn't mention it explicitly, but when you're saying that Elm Review has the ability to generate the docs.json, which is what generates the package documentation for Elm Packages, Elm Review doesn't currently have the ability to do type inference, but it doesn't need that because Elm Packages, in order to be publishable, must have type annotations for all of their top-level functions. Yeah, for everything that is exposed, at least. Everything exposed. So you can have constraints like that, and you can say, hey, I'm only able to operate on things that you have given explicit type annotations for. But you can do all sorts of cogeneration tasks for this, like, kind of bridging, you know, types without borders stuff to kind of connect different paradigms to each other. So that's pretty cool. Actually, I haven't mentioned why I made this feature in the first place. So I had a project idea that is not Elm Review, where I would use Elm Review, which I've kind of put a lid on at this moment or put to pause. I actually bought the domain name, and it expired this week. So I'm not sure I'm going to get to it soon. But basically, I wanted to show how secure the Elm Package ecosystem was. I might have mentioned this during the Christmas episode, where we did mention Elm Review's extracts feature. So the idea is that, like, there's not a lot of security issues. There's a few that I fixed a year ago with regards to virtual DOM and XSS or cross-site scripting issues. And I wanted to know, like, where do we have any packages in the Elm ecosystem that are making that are abusing this feature or this security hole? So what I did is I went through the packages, and I figured, well, which ones are depending on Elm slash HTML or Elm slash virtual DOM, which could be using these problematic functions, which have these security issues? And I will notice, well, most of them are not, but a lot of them are transitioning the problem. So the problem was if the one of the problems was using virtual DOM dot node NS. And NS stands for namespace. So it's a regular, like, HTML dot node, which takes three arguments, which is the tag name, so like div or span or button, then a list of attributes and a list of children. And the functions that are that have this NS in their name, they also take a namespace, which is like a specification URL. I actually didn't get what that was. Some XML schema URL thing. Yeah, yeah. Yeah. And there was a problem where these were not checked correctly. One of the arguments was not checked correctly. So what I noticed was a lot of these packages that were using these functions, they were taking, they were passing as arguments, things that were themselves taken as arguments. So the first argument that I needed to check for node NS was itself an argument to this function. So if I wanted to see whether a function was using the security issue, then I needed to check which ones were using this function. But that was potentially in a different package. So what I did was I started working on this data extractor behind the scenes in a branch of the project on my computer. And I extracted the information of which functions are using these functions that are vulnerable and making a list of those. And then whenever I visited another package, I took all the vulnerable functions that they depend on. They have virtual DOM as a dependency or this other intermediate package that have these dependency issues. So these vulnerabilities and so on and so on. And the idea was, well, I'm just going to extract everything. And at some point, I'm going to be able to find out whether they are, one of them is misusing something. I never completed the research. Well, so far, I haven't been able to find any problematic use, at least. So that's very positive. And now these issues are fixed anyway. So yeah, my idea was to make something that showed how many vulnerabilities there were in Elm and in its package ecosystem. And the highlight would have been, oh, there are zero issues. Just make a website that says zero. Yeah. And now, I don't know, like companies pay me to have a certification that says, hey, I'm using Elm and we are aware of all the security issues in the package ecosystem. Like basically, I was trying to do an audit of the ecosystem and trying to monetize that somehow, maybe. Yeah, yeah. Turns out I lost interest in that. I don't know if it would be interesting financially. If your company thinks it would be interesting, let me know. But otherwise, yeah, I prefer working on ElmReview directly, I guess. Yeah. So yeah, that was why I started making it. Like I needed to extract information from a package to give to other packages, to the review of other packages, and so on and so on. That's very cool. Yeah, it does open up so many doors. Like the security vulnerability checking is like, I mean, there are some interesting projects in the JS ecosystem these days checking for security vulnerabilities. But it's just so much easier to get assurances around things like that with Elm and with ElmReview and ElmReview Extractors. It's a really cool space. And code quality, like, I mean, we don't really have much by way of code quality tools in the Elm community. We have ElmReview. Right. I mean, those are tools that help ensure code quality, but not code quality tools in the sense of like giving you a code quality report to try to, you know, I mean, of course, like unused functions and things like that are a code quality metric. But it's sort of like stops being a code quality metric when the tool just fixes it for you. And then like, it's just a static analysis tool. Yeah, the metric is always zero because it fixed everything. Exactly. But that would be really cool to have like a suite of code quality tools to look at where to refactor. Yeah. So I remember talking to the author of Elm Analyze, Mats. He was really liking the direction of ElmReview and he thought it was a great project. So that made me happy. And he was thinking, well, potentially, I could now make Elm Analyze use ElmReview under the hood and make things like dashboards or code quality metrics. So exactly this idea. So yeah, I think it's possible. Yeah. What needs to be shown, what is interesting, that remains to be investigated. Yeah, so many interesting things to explore here. One thing we would be remiss if we did not mention unit testing. There's really not too much to say on this point other than you can do it. You can write unit tests for your data extractors. If you have tests, then ElmReview's testing framework will force you to explain how the data extract will look like. Really? Yeah. Basically, ElmReview's testing framework is like, if there's anything that we can check, we will check it. Whoa, I did not know this. I'm proud to say I did not know it because I have not encountered this situation before, because I really like writing tests for my ElmReview rules. But wow, that's cool. Yeah. I mean, if your rule provides a fix, then you will have to say how it's fixed. If you say, well, there's an error, it will say, well, what are the message and details and where is that error? Basically, everything that we can check, we check. I think sometimes it's annoying because you'd have to write a lot of things, especially for data extracts. Maybe it's a bit too much. I could imagine adding a feature that says, please don't force me to write a data extractor. But so far in general, the idea holds very well. I personally see it as a positive. It has worked for my rules, at least. Yeah, you could potentially have something that allows you to assert on the data extractor or something. If you want to look at a subset of the values or something like that, I don't know. It's an interesting point. But yeah, currently what it does is you say, review.test.expectDataExtract, and then you give a JSON string that you expect it to return for your extractor. I could imagine if you have very rich information, that could become tedious, but it's a great feature. Yeah, in general, the test cases you use your rules on are pretty small, so I think it's manageable. But yeah, I can absolutely imagine it will be a bit too much. So if you're hitting that and genuinely it's annoying, open an issue. Very interesting. So another use case, I can really see this being used, but I think it might also be, or this data extract idea, but I think it might be a bit too... It will not work perfectly, but I would like to see an investigation in this, is for explaining things. For instance, one of the things where people can get confused is when you have update functions, where you have one message that triggers a command, that triggers another message, which in turn triggers another command, and so on and so on. So for instance, if you need to process a payment, there's a lot of steps to that, and it can be hard to figure out in which order these messages come in. And I would love to see a diagram that shows in which order these things are applied. And I'm thinking that using static analysis, we could make this diagram. We're using ElmReview data extractors. You get all the information and you now make it a diagram. And I think you can do diagrams for a lot of things, like even, for instance, as I mentioned, the import modules before. Well, if you group them nicely, if you format them nicely, if you remove all the unnecessary details, this can now become an overview of your project that you can show to newcomers to your projects. It can become documentation that you can force to always be up to date. So this is something that I would like to see some exploration as well in. For the example, for the update, it's a lot more local, right? It's like, well, once you get information for this module, for this function, maybe it could even be like explaining how the HTML will look like and how it interacts with, or which buttons, for instance, will trigger what messages. I don't know. But the part where I'm like, this might not work very well is because you're probably going to have to compute that for your entire project, which sounds like a lot when you're only interested in a specific part. You're only interested in the diagram for this one module or this one function. So maybe the data extract should take an argument. Yes. Something like ElmCogen takes information in, which gets very tricky in terms of trying to cache the results, but it could be doable in practice. Like just if we don't care about ElmReview being slower, this could be done. Definitely. So this is something I think could be pretty cool. I think Richard Feldman also talked about this for Rock, where they want people to be able to build tools for their packages. And then whenever you install a package, you also get like editor integrations that help explain things. Like I don't remember if this was an example, a possible example, but you could imagine you're adding in Rock slash HTML package, and now you can have a preview of the HTML in your editor, or you have a color package and you can have a color picker in your editor. I don't know. Things like that. And yeah, I think I could see the same thing with ElmReview, but like performance wise, this will not work. And I know you've talked about like having language server like... Yes, yes. Intents or actions using ElmReview. And yeah, it would be nice to go that way, I think. But like maybe we should have an intervention like that. ElmReview is doing too much right now. But these would be interesting explorations, I think. Yeah, it does make... I mean, the extract functionality makes ElmReview feel more like a platform, which I think is a great thing. My sort of AI experiment where I'm trying to build like a type solver that replaces certain debug.todos. That's one of the things I'm doing is I'm actually like extracting the range of a debug.todo and then the relevant context around it of which things are in scope there. So that the type solver can go and do its thing and then pass that back to ElmReview and give it the range that it's solved for. And that gives guardrails to the GPT prompt. So it's not just going and modifying your entire code base. It's only modifying the part you gave it permission to build an implementation for. And it ran the Elm compiler on it to make sure type checks and all that. But so it's actually going back and forth to ElmReview where it extracts from ElmReview, runs a script and then sends the results of that back to ElmReview to perform a replace rule. A fix. Pretty interesting possibilities there. Or we could just give the entire code base to an AI and then it would do the same thing that ElmReview would do. A lot easier. That's true. Give it five years. We'll see where we are then. Oh, you pessimist. I think there's a collaboration to be had between our traditional static analysis and our more modern artificial intelligence approaches. I've mentioned this idea before of for a phantom builder extracting a diagram that shows you as a state machine, what are the possible states that this builder API can go through. Yeah, exactly. State machines are a perfect example. It's very easy to draw. There are tools for that. So you just need to output to this good format. Like dots or mermaid I'm sure do that. Exactly. You just need to figure out what information you want a state diagram for and extract it and you're good to go. Yeah. Sky's the limit. I mean, there's so much cool stuff we could build. So, yeah, again, if you build some cool stuff, let us know. Tweet at us. Yeah. If you want to get started with this feature, we will link the article that I put on my blog, which is called Gaining Insight into your Codebase with Elm Review. So read that and otherwise read the documentation for with data extractor in Elm Review's package documentation. Yeah. And let us know what you come up with. Yeah. Great stuff. Well, thanks again for the great feature and Jeroen, until next time. Until next time.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.0, "text": " Hello Jeroen.", "tokens": [2425, 508, 2032, 268, 13], "temperature": 0.0, "avg_logprob": -0.29974761376014125, "compression_ratio": 1.5129310344827587, "no_speech_prob": 0.2221362441778183}, {"id": 1, "seek": 0, "start": 2.0, "end": 4.0, "text": " Hello Dillon.", "tokens": [2425, 28160, 13], "temperature": 0.0, "avg_logprob": -0.29974761376014125, "compression_ratio": 1.5129310344827587, "no_speech_prob": 0.2221362441778183}, {"id": 2, "seek": 0, "start": 4.0, "end": 11.0, "text": " Well, I've been playing around with a fun feature in Elm Review that we haven't really talked about before.", "tokens": [1042, 11, 286, 600, 668, 2433, 926, 365, 257, 1019, 4111, 294, 2699, 76, 19954, 300, 321, 2378, 380, 534, 2825, 466, 949, 13], "temperature": 0.0, "avg_logprob": -0.29974761376014125, "compression_ratio": 1.5129310344827587, "no_speech_prob": 0.2221362441778183}, {"id": 3, "seek": 0, "start": 11.0, "end": 14.0, "text": " Wait a second. Where's the pun?", "tokens": [3802, 257, 1150, 13, 2305, 311, 264, 4468, 30], "temperature": 0.0, "avg_logprob": -0.29974761376014125, "compression_ratio": 1.5129310344827587, "no_speech_prob": 0.2221362441778183}, {"id": 4, "seek": 0, "start": 14.0, "end": 22.0, "text": " I've got to keep you on your toes Jeroen. The pun might spring out at any point.", "tokens": [286, 600, 658, 281, 1066, 291, 322, 428, 14681, 508, 2032, 268, 13, 440, 4468, 1062, 5587, 484, 412, 604, 935, 13], "temperature": 0.0, "avg_logprob": -0.29974761376014125, "compression_ratio": 1.5129310344827587, "no_speech_prob": 0.2221362441778183}, {"id": 5, "seek": 0, "start": 22.0, "end": 29.0, "text": " We started the recording and I was like, oh no, I forgot he was going to do a pun and I'm not prepared.", "tokens": [492, 1409, 264, 6613, 293, 286, 390, 411, 11, 1954, 572, 11, 286, 5298, 415, 390, 516, 281, 360, 257, 4468, 293, 286, 478, 406, 4927, 13], "temperature": 0.0, "avg_logprob": -0.29974761376014125, "compression_ratio": 1.5129310344827587, "no_speech_prob": 0.2221362441778183}, {"id": 6, "seek": 2900, "start": 29.0, "end": 32.0, "text": " The one time you were mentally preparing.", "tokens": [440, 472, 565, 291, 645, 17072, 10075, 13], "temperature": 0.0, "avg_logprob": -0.2550659421124036, "compression_ratio": 1.4438502673796791, "no_speech_prob": 0.0003793727664742619}, {"id": 7, "seek": 2900, "start": 32.0, "end": 37.0, "text": " Kind of on the late side and now you're like, there's no pun? What?", "tokens": [9242, 295, 322, 264, 3469, 1252, 293, 586, 291, 434, 411, 11, 456, 311, 572, 4468, 30, 708, 30], "temperature": 0.0, "avg_logprob": -0.2550659421124036, "compression_ratio": 1.4438502673796791, "no_speech_prob": 0.0003793727664742619}, {"id": 8, "seek": 2900, "start": 37.0, "end": 41.0, "text": " I thought I could extract a reaction from you.", "tokens": [286, 1194, 286, 727, 8947, 257, 5480, 490, 291, 13], "temperature": 0.0, "avg_logprob": -0.2550659421124036, "compression_ratio": 1.4438502673796791, "no_speech_prob": 0.0003793727664742619}, {"id": 9, "seek": 2900, "start": 41.0, "end": 49.0, "text": " Okay, that's fine then. We have standards, man. That's why we have linters. We need standards.", "tokens": [1033, 11, 300, 311, 2489, 550, 13, 492, 362, 7787, 11, 587, 13, 663, 311, 983, 321, 362, 22896, 1559, 13, 492, 643, 7787, 13], "temperature": 0.0, "avg_logprob": -0.2550659421124036, "compression_ratio": 1.4438502673796791, "no_speech_prob": 0.0003793727664742619}, {"id": 10, "seek": 2900, "start": 49.0, "end": 51.0, "text": " We got to deliver.", "tokens": [492, 658, 281, 4239, 13], "temperature": 0.0, "avg_logprob": -0.2550659421124036, "compression_ratio": 1.4438502673796791, "no_speech_prob": 0.0003793727664742619}, {"id": 11, "seek": 5100, "start": 51.0, "end": 63.0, "text": " So today, we haven't really talked about this on the podcast, but there's this whole feature that's kind of like pretty powerful in Elm Review.", "tokens": [407, 965, 11, 321, 2378, 380, 534, 2825, 466, 341, 322, 264, 7367, 11, 457, 456, 311, 341, 1379, 4111, 300, 311, 733, 295, 411, 1238, 4005, 294, 2699, 76, 19954, 13], "temperature": 0.0, "avg_logprob": -0.20571554790843616, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0003195698664058}, {"id": 12, "seek": 5100, "start": 63.0, "end": 68.0, "text": " The extractors. So do you want to tell us what Elm Review extractors are?", "tokens": [440, 8947, 830, 13, 407, 360, 291, 528, 281, 980, 505, 437, 2699, 76, 19954, 8947, 830, 366, 30], "temperature": 0.0, "avg_logprob": -0.20571554790843616, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0003195698664058}, {"id": 13, "seek": 5100, "start": 68.0, "end": 76.0, "text": " Yeah, sure. So Elm Review has this new feature, which is extractors, which allows you to gain insight into your code base.", "tokens": [865, 11, 988, 13, 407, 2699, 76, 19954, 575, 341, 777, 4111, 11, 597, 307, 8947, 830, 11, 597, 4045, 291, 281, 6052, 11269, 666, 428, 3089, 3096, 13], "temperature": 0.0, "avg_logprob": -0.20571554790843616, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0003195698664058}, {"id": 14, "seek": 7600, "start": 76.0, "end": 83.0, "text": " So you run an Elm Review rule and it's going to gather a lot of information.", "tokens": [407, 291, 1190, 364, 2699, 76, 19954, 4978, 293, 309, 311, 516, 281, 5448, 257, 688, 295, 1589, 13], "temperature": 0.0, "avg_logprob": -0.18475074768066407, "compression_ratio": 1.736842105263158, "no_speech_prob": 2.7954220058745705e-05}, {"id": 15, "seek": 7600, "start": 83.0, "end": 88.0, "text": " And then it's going to be able to give you that information as a JSON output.", "tokens": [400, 550, 309, 311, 516, 281, 312, 1075, 281, 976, 291, 300, 1589, 382, 257, 31828, 5598, 13], "temperature": 0.0, "avg_logprob": -0.18475074768066407, "compression_ratio": 1.736842105263158, "no_speech_prob": 2.7954220058745705e-05}, {"id": 16, "seek": 7600, "start": 88.0, "end": 93.0, "text": " And you can read that JSON and you can figure out whatever information you wanted.", "tokens": [400, 291, 393, 1401, 300, 31828, 293, 291, 393, 2573, 484, 2035, 1589, 291, 1415, 13], "temperature": 0.0, "avg_logprob": -0.18475074768066407, "compression_ratio": 1.736842105263158, "no_speech_prob": 2.7954220058745705e-05}, {"id": 17, "seek": 7600, "start": 93.0, "end": 100.0, "text": " So what kinds of information can you get? Well, that entirely depends on you and on the rules that you've enabled or written.", "tokens": [407, 437, 3685, 295, 1589, 393, 291, 483, 30, 1042, 11, 300, 7696, 5946, 322, 291, 293, 322, 264, 4474, 300, 291, 600, 15172, 420, 3720, 13], "temperature": 0.0, "avg_logprob": -0.18475074768066407, "compression_ratio": 1.736842105263158, "no_speech_prob": 2.7954220058745705e-05}, {"id": 18, "seek": 10000, "start": 100.0, "end": 108.0, "text": " So one very small example that I made is making an import graph of your modules.", "tokens": [407, 472, 588, 1359, 1365, 300, 286, 1027, 307, 1455, 364, 974, 4295, 295, 428, 16679, 13], "temperature": 0.0, "avg_logprob": -0.1956387474423363, "compression_ratio": 1.7692307692307692, "no_speech_prob": 3.218860365450382e-05}, {"id": 19, "seek": 10000, "start": 108.0, "end": 117.0, "text": " So what Elm Review is going to do is it's going to look at your whole Elm project.", "tokens": [407, 437, 2699, 76, 19954, 307, 516, 281, 360, 307, 309, 311, 516, 281, 574, 412, 428, 1379, 2699, 76, 1716, 13], "temperature": 0.0, "avg_logprob": -0.1956387474423363, "compression_ratio": 1.7692307692307692, "no_speech_prob": 3.218860365450382e-05}, {"id": 20, "seek": 10000, "start": 117.0, "end": 127.0, "text": " And it's going to notice, okay, well, this module is importing this thing, this other module, this other module is importing that module, and so on and so on.", "tokens": [400, 309, 311, 516, 281, 3449, 11, 1392, 11, 731, 11, 341, 10088, 307, 43866, 341, 551, 11, 341, 661, 10088, 11, 341, 661, 10088, 307, 43866, 300, 10088, 11, 293, 370, 322, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.1956387474423363, "compression_ratio": 1.7692307692307692, "no_speech_prob": 3.218860365450382e-05}, {"id": 21, "seek": 12700, "start": 127.0, "end": 132.0, "text": " And it's going to internally make a graph of the imports.", "tokens": [400, 309, 311, 516, 281, 19501, 652, 257, 4295, 295, 264, 41596, 13], "temperature": 0.0, "avg_logprob": -0.20573071683390756, "compression_ratio": 1.6995073891625616, "no_speech_prob": 1.5444802556885406e-05}, {"id": 22, "seek": 12700, "start": 132.0, "end": 140.0, "text": " And at the end, it just says, well, I've made those into a graph or a list of arrows.", "tokens": [400, 412, 264, 917, 11, 309, 445, 1619, 11, 731, 11, 286, 600, 1027, 729, 666, 257, 4295, 420, 257, 1329, 295, 19669, 13], "temperature": 0.0, "avg_logprob": -0.20573071683390756, "compression_ratio": 1.6995073891625616, "no_speech_prob": 1.5444802556885406e-05}, {"id": 23, "seek": 12700, "start": 140.0, "end": 148.0, "text": " And this is now like it's going to format it as a mermaid diagram or a dot graph diagram.", "tokens": [400, 341, 307, 586, 411, 309, 311, 516, 281, 7877, 309, 382, 257, 43146, 10686, 420, 257, 5893, 4295, 10686, 13], "temperature": 0.0, "avg_logprob": -0.20573071683390756, "compression_ratio": 1.6995073891625616, "no_speech_prob": 1.5444802556885406e-05}, {"id": 24, "seek": 12700, "start": 148.0, "end": 155.0, "text": " And you can now use that to generate an image using the dot specification, the mermaid specification, whatever.", "tokens": [400, 291, 393, 586, 764, 300, 281, 8460, 364, 3256, 1228, 264, 5893, 31256, 11, 264, 43146, 31256, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.20573071683390756, "compression_ratio": 1.6995073891625616, "no_speech_prob": 1.5444802556885406e-05}, {"id": 25, "seek": 15500, "start": 155.0, "end": 165.0, "text": " So but this information is just like one rule is saying, well, I'm going to gather this information and then present it as a graph.", "tokens": [407, 457, 341, 1589, 307, 445, 411, 472, 4978, 307, 1566, 11, 731, 11, 286, 478, 516, 281, 5448, 341, 1589, 293, 550, 1974, 309, 382, 257, 4295, 13], "temperature": 0.0, "avg_logprob": -0.21421539540193518, "compression_ratio": 1.6952789699570816, "no_speech_prob": 1.670103483775165e-05}, {"id": 26, "seek": 15500, "start": 165.0, "end": 171.0, "text": " It's not something that is built into Elm Review. It's just whatever you configure your rule to do.", "tokens": [467, 311, 406, 746, 300, 307, 3094, 666, 2699, 76, 19954, 13, 467, 311, 445, 2035, 291, 22162, 428, 4978, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.21421539540193518, "compression_ratio": 1.6952789699570816, "no_speech_prob": 1.670103483775165e-05}, {"id": 27, "seek": 15500, "start": 171.0, "end": 182.0, "text": " Right. Yeah, it's really it's like allowing the context that you have that you build up in Elm Review to escape from the bounds of Elm Review to the outside world.", "tokens": [1779, 13, 865, 11, 309, 311, 534, 309, 311, 411, 8293, 264, 4319, 300, 291, 362, 300, 291, 1322, 493, 294, 2699, 76, 19954, 281, 7615, 490, 264, 29905, 295, 2699, 76, 19954, 281, 264, 2380, 1002, 13], "temperature": 0.0, "avg_logprob": -0.21421539540193518, "compression_ratio": 1.6952789699570816, "no_speech_prob": 1.670103483775165e-05}, {"id": 28, "seek": 18200, "start": 182.0, "end": 186.0, "text": " So you can use it in external tools however you want.", "tokens": [407, 291, 393, 764, 309, 294, 8320, 3873, 4461, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.21054020634403936, "compression_ratio": 1.5674418604651164, "no_speech_prob": 5.828649955219589e-05}, {"id": 29, "seek": 18200, "start": 186.0, "end": 206.0, "text": " So it's yeah, it's really like so you've got like, you know, if for anyone who's familiar with writing Elm Review rules and, you know, using visitors to update the context, which we've talked about in previous episodes, that would be akin to your update function updating your model.", "tokens": [407, 309, 311, 1338, 11, 309, 311, 534, 411, 370, 291, 600, 658, 411, 11, 291, 458, 11, 498, 337, 2878, 567, 311, 4963, 365, 3579, 2699, 76, 19954, 4474, 293, 11, 291, 458, 11, 1228, 14315, 281, 5623, 264, 4319, 11, 597, 321, 600, 2825, 466, 294, 3894, 9313, 11, 300, 576, 312, 47540, 281, 428, 5623, 2445, 25113, 428, 2316, 13], "temperature": 0.0, "avg_logprob": -0.21054020634403936, "compression_ratio": 1.5674418604651164, "no_speech_prob": 5.828649955219589e-05}, {"id": 30, "seek": 20600, "start": 206.0, "end": 215.0, "text": " You know, you have in the Elm architecture, this tuple you return from update of the model and commands.", "tokens": [509, 458, 11, 291, 362, 294, 264, 2699, 76, 9482, 11, 341, 2604, 781, 291, 2736, 490, 5623, 295, 264, 2316, 293, 16901, 13], "temperature": 0.0, "avg_logprob": -0.19313405541812673, "compression_ratio": 1.590643274853801, "no_speech_prob": 8.397731107834261e-06}, {"id": 31, "seek": 20600, "start": 215.0, "end": 222.0, "text": " And in Elm Review, visitors can change the context, which would be like updating the model.", "tokens": [400, 294, 2699, 76, 19954, 11, 14315, 393, 1319, 264, 4319, 11, 597, 576, 312, 411, 25113, 264, 2316, 13], "temperature": 0.0, "avg_logprob": -0.19313405541812673, "compression_ratio": 1.590643274853801, "no_speech_prob": 8.397731107834261e-06}, {"id": 32, "seek": 20600, "start": 222.0, "end": 228.0, "text": " And they can return errors or fixes, which would be like running a command.", "tokens": [400, 436, 393, 2736, 13603, 420, 32539, 11, 597, 576, 312, 411, 2614, 257, 5622, 13], "temperature": 0.0, "avg_logprob": -0.19313405541812673, "compression_ratio": 1.590643274853801, "no_speech_prob": 8.397731107834261e-06}, {"id": 33, "seek": 22800, "start": 228.0, "end": 242.0, "text": " But extractors, instead of resulting in fixes and reporting errors, you can you're given the context at the end of running the rule, and then you can turn that into JSON.", "tokens": [583, 8947, 830, 11, 2602, 295, 16505, 294, 32539, 293, 10031, 13603, 11, 291, 393, 291, 434, 2212, 264, 4319, 412, 264, 917, 295, 2614, 264, 4978, 11, 293, 550, 291, 393, 1261, 300, 666, 31828, 13], "temperature": 0.0, "avg_logprob": -0.22691803593789378, "compression_ratio": 1.471698113207547, "no_speech_prob": 3.321272015455179e-05}, {"id": 34, "seek": 22800, "start": 242.0, "end": 244.0, "text": " Right. That's all it that's all it really is.", "tokens": [1779, 13, 663, 311, 439, 309, 300, 311, 439, 309, 534, 307, 13], "temperature": 0.0, "avg_logprob": -0.22691803593789378, "compression_ratio": 1.471698113207547, "no_speech_prob": 3.321272015455179e-05}, {"id": 35, "seek": 22800, "start": 244.0, "end": 246.0, "text": " Absolutely. Yeah.", "tokens": [7021, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.22691803593789378, "compression_ratio": 1.471698113207547, "no_speech_prob": 3.321272015455179e-05}, {"id": 36, "seek": 24600, "start": 246.0, "end": 258.0, "text": " But the what you can do with that is it's anything anything that you can do by visiting an Elm project, extracting context from that and turning that into JSON.", "tokens": [583, 264, 437, 291, 393, 360, 365, 300, 307, 309, 311, 1340, 1340, 300, 291, 393, 360, 538, 11700, 364, 2699, 76, 1716, 11, 49844, 4319, 490, 300, 293, 6246, 300, 666, 31828, 13], "temperature": 0.0, "avg_logprob": -0.1721134004138765, "compression_ratio": 1.7256637168141593, "no_speech_prob": 6.143948667158838e-06}, {"id": 37, "seek": 24600, "start": 258.0, "end": 260.0, "text": " Now you have access to that in any external tool.", "tokens": [823, 291, 362, 2105, 281, 300, 294, 604, 8320, 2290, 13], "temperature": 0.0, "avg_logprob": -0.1721134004138765, "compression_ratio": 1.7256637168141593, "no_speech_prob": 6.143948667158838e-06}, {"id": 38, "seek": 24600, "start": 260.0, "end": 265.0, "text": " So we said it's JSON, but in practice, it's whatever can be encoded as JSON.", "tokens": [407, 321, 848, 309, 311, 31828, 11, 457, 294, 3124, 11, 309, 311, 2035, 393, 312, 2058, 12340, 382, 31828, 13], "temperature": 0.0, "avg_logprob": -0.1721134004138765, "compression_ratio": 1.7256637168141593, "no_speech_prob": 6.143948667158838e-06}, {"id": 39, "seek": 24600, "start": 265.0, "end": 274.0, "text": " So if you if you just want it to be YAML, then you just make a string that is YAML format in practice.", "tokens": [407, 498, 291, 498, 291, 445, 528, 309, 281, 312, 398, 2865, 43, 11, 550, 291, 445, 652, 257, 6798, 300, 307, 398, 2865, 43, 7877, 294, 3124, 13], "temperature": 0.0, "avg_logprob": -0.1721134004138765, "compression_ratio": 1.7256637168141593, "no_speech_prob": 6.143948667158838e-06}, {"id": 40, "seek": 27400, "start": 274.0, "end": 286.0, "text": " The way to use this feature is to call the Elm Review CLI with a dash dash extract and also dash dash reports equals JSON.", "tokens": [440, 636, 281, 764, 341, 4111, 307, 281, 818, 264, 2699, 76, 19954, 12855, 40, 365, 257, 8240, 8240, 8947, 293, 611, 8240, 8240, 7122, 6915, 31828, 13], "temperature": 0.0, "avg_logprob": -0.23649603597233804, "compression_ratio": 1.5238095238095237, "no_speech_prob": 4.1985404095612466e-05}, {"id": 41, "seek": 27400, "start": 286.0, "end": 290.0, "text": " Otherwise, you won't get the extracts and then we'll give you a JSON.", "tokens": [10328, 11, 291, 1582, 380, 483, 264, 8947, 82, 293, 550, 321, 603, 976, 291, 257, 31828, 13], "temperature": 0.0, "avg_logprob": -0.23649603597233804, "compression_ratio": 1.5238095238095237, "no_speech_prob": 4.1985404095612466e-05}, {"id": 42, "seek": 27400, "start": 290.0, "end": 292.0, "text": " But that contains arbitrary JSON.", "tokens": [583, 300, 8306, 23211, 31828, 13], "temperature": 0.0, "avg_logprob": -0.23649603597233804, "compression_ratio": 1.5238095238095237, "no_speech_prob": 4.1985404095612466e-05}, {"id": 43, "seek": 27400, "start": 292.0, "end": 297.0, "text": " So if you want it to be a string that contains the YAML, whereas in YAML format, that's fine.", "tokens": [407, 498, 291, 528, 309, 281, 312, 257, 6798, 300, 8306, 264, 398, 2865, 43, 11, 9735, 294, 398, 2865, 43, 7877, 11, 300, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.23649603597233804, "compression_ratio": 1.5238095238095237, "no_speech_prob": 4.1985404095612466e-05}, {"id": 44, "seek": 29700, "start": 297.0, "end": 304.0, "text": " That's kind of what I do with the imports graph, because that's just dots, specification strings.", "tokens": [663, 311, 733, 295, 437, 286, 360, 365, 264, 41596, 4295, 11, 570, 300, 311, 445, 15026, 11, 31256, 13985, 13], "temperature": 0.0, "avg_logprob": -0.20047325558132595, "compression_ratio": 1.58984375, "no_speech_prob": 2.5063316570594907e-05}, {"id": 45, "seek": 29700, "start": 304.0, "end": 309.0, "text": " Right. Right. So you can Yeah, it's it's JSON at the top level.", "tokens": [1779, 13, 1779, 13, 407, 291, 393, 865, 11, 309, 311, 309, 311, 31828, 412, 264, 1192, 1496, 13], "temperature": 0.0, "avg_logprob": -0.20047325558132595, "compression_ratio": 1.58984375, "no_speech_prob": 2.5063316570594907e-05}, {"id": 46, "seek": 29700, "start": 309.0, "end": 317.0, "text": " But inside of those JSON values, it might just be a single JSON string, which is actually a different data format.", "tokens": [583, 1854, 295, 729, 31828, 4190, 11, 309, 1062, 445, 312, 257, 2167, 31828, 6798, 11, 597, 307, 767, 257, 819, 1412, 7877, 13], "temperature": 0.0, "avg_logprob": -0.20047325558132595, "compression_ratio": 1.58984375, "no_speech_prob": 2.5063316570594907e-05}, {"id": 47, "seek": 29700, "start": 317.0, "end": 322.0, "text": " Yeah, I've I think there are a few different ways that you could approach.", "tokens": [865, 11, 286, 600, 286, 519, 456, 366, 257, 1326, 819, 2098, 300, 291, 727, 3109, 13], "temperature": 0.0, "avg_logprob": -0.20047325558132595, "compression_ratio": 1.58984375, "no_speech_prob": 2.5063316570594907e-05}, {"id": 48, "seek": 29700, "start": 322.0, "end": 325.0, "text": " I mean, it depends on what you're trying to do with it.", "tokens": [286, 914, 11, 309, 5946, 322, 437, 291, 434, 1382, 281, 360, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.20047325558132595, "compression_ratio": 1.58984375, "no_speech_prob": 2.5063316570594907e-05}, {"id": 49, "seek": 32500, "start": 325.0, "end": 335.0, "text": " You could directly encode some format if you need some mermaid format or some markdown format or whatever you want to encode to.", "tokens": [509, 727, 3838, 2058, 1429, 512, 7877, 498, 291, 643, 512, 43146, 7877, 420, 512, 1491, 5093, 7877, 420, 2035, 291, 528, 281, 2058, 1429, 281, 13], "temperature": 0.0, "avg_logprob": -0.20736038550901947, "compression_ratio": 1.8019323671497585, "no_speech_prob": 3.9441962144337595e-05}, {"id": 50, "seek": 32500, "start": 335.0, "end": 342.0, "text": " You could just directly encode to those data formats if you're consuming it from another Elm app.", "tokens": [509, 727, 445, 3838, 2058, 1429, 281, 729, 1412, 25879, 498, 291, 434, 19867, 309, 490, 1071, 2699, 76, 724, 13], "temperature": 0.0, "avg_logprob": -0.20736038550901947, "compression_ratio": 1.8019323671497585, "no_speech_prob": 3.9441962144337595e-05}, {"id": 51, "seek": 32500, "start": 342.0, "end": 353.0, "text": " Then you could use something like Elm codec to share your codec to encode the JSON data and then decode using code sharing between the code bases.", "tokens": [1396, 291, 727, 764, 746, 411, 2699, 76, 3089, 66, 281, 2073, 428, 3089, 66, 281, 2058, 1429, 264, 31828, 1412, 293, 550, 979, 1429, 1228, 3089, 5414, 1296, 264, 3089, 17949, 13], "temperature": 0.0, "avg_logprob": -0.20736038550901947, "compression_ratio": 1.8019323671497585, "no_speech_prob": 3.9441962144337595e-05}, {"id": 52, "seek": 35300, "start": 353.0, "end": 357.0, "text": " If you're consuming it and extracting from from Elm code.", "tokens": [759, 291, 434, 19867, 309, 293, 49844, 490, 490, 2699, 76, 3089, 13], "temperature": 0.0, "avg_logprob": -0.26548098135685577, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.00011771551362471655}, {"id": 53, "seek": 35300, "start": 357.0, "end": 364.0, "text": " So, well, this might be a good opportunity. You're in this might be a bit of an intervention.", "tokens": [407, 11, 731, 11, 341, 1062, 312, 257, 665, 2650, 13, 509, 434, 294, 341, 1062, 312, 257, 857, 295, 364, 13176, 13], "temperature": 0.0, "avg_logprob": -0.26548098135685577, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.00011771551362471655}, {"id": 54, "seek": 35300, "start": 364.0, "end": 377.0, "text": " Actually, it turns out I I've spoken to you about my idea of Elm code Elm pages code gen review.", "tokens": [5135, 11, 309, 4523, 484, 286, 286, 600, 10759, 281, 291, 466, 452, 1558, 295, 2699, 76, 3089, 2699, 76, 7183, 3089, 1049, 3131, 13], "temperature": 0.0, "avg_logprob": -0.26548098135685577, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.00011771551362471655}, {"id": 55, "seek": 37700, "start": 377.0, "end": 386.0, "text": " So pages code gen review. OK, sure. Yeah. Are you sure it's not Elm review pages code gen?", "tokens": [407, 7183, 3089, 1049, 3131, 13, 2264, 11, 988, 13, 865, 13, 2014, 291, 988, 309, 311, 406, 2699, 76, 3131, 7183, 3089, 1049, 30], "temperature": 0.0, "avg_logprob": -0.2997578840989333, "compression_ratio": 1.46524064171123, "no_speech_prob": 4.1326504288008437e-05}, {"id": 56, "seek": 37700, "start": 386.0, "end": 394.0, "text": " We can we can negotiate. Which which comes first? Absolutely. I'm open to that.", "tokens": [492, 393, 321, 393, 21713, 13, 3013, 597, 1487, 700, 30, 7021, 13, 286, 478, 1269, 281, 300, 13], "temperature": 0.0, "avg_logprob": -0.2997578840989333, "compression_ratio": 1.46524064171123, "no_speech_prob": 4.1326504288008437e-05}, {"id": 57, "seek": 37700, "start": 394.0, "end": 404.0, "text": " But the the main point. So, well, I recently kind of brought my my Elm pages code gen idea to fruition.", "tokens": [583, 264, 264, 2135, 935, 13, 407, 11, 731, 11, 286, 3938, 733, 295, 3038, 452, 452, 2699, 76, 7183, 3089, 1049, 1558, 281, 48738, 13], "temperature": 0.0, "avg_logprob": -0.2997578840989333, "compression_ratio": 1.46524064171123, "no_speech_prob": 4.1326504288008437e-05}, {"id": 58, "seek": 40400, "start": 404.0, "end": 411.0, "text": " And I'm quite happy with it. I kind of joked about that in our code gen episode with Matt Griffith.", "tokens": [400, 286, 478, 1596, 2055, 365, 309, 13, 286, 733, 295, 361, 9511, 466, 300, 294, 527, 3089, 1049, 3500, 365, 7397, 23765, 355, 13], "temperature": 0.0, "avg_logprob": -0.23687820929985542, "compression_ratio": 1.3897435897435897, "no_speech_prob": 3.5354256397113204e-05}, {"id": 59, "seek": 40400, "start": 411.0, "end": 415.0, "text": " But the challenge there being what was your idea again? Right.", "tokens": [583, 264, 3430, 456, 885, 437, 390, 428, 1558, 797, 30, 1779, 13], "temperature": 0.0, "avg_logprob": -0.23687820929985542, "compression_ratio": 1.3897435897435897, "no_speech_prob": 3.5354256397113204e-05}, {"id": 60, "seek": 40400, "start": 415.0, "end": 424.0, "text": " So, OK, so there are Elm pages scripts. Elm pages v3 has this thing called a back end task, which, you know,", "tokens": [407, 11, 2264, 11, 370, 456, 366, 2699, 76, 7183, 23294, 13, 2699, 76, 7183, 371, 18, 575, 341, 551, 1219, 257, 646, 917, 5633, 11, 597, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.23687820929985542, "compression_ratio": 1.3897435897435897, "no_speech_prob": 3.5354256397113204e-05}, {"id": 61, "seek": 42400, "start": 424.0, "end": 437.0, "text": " it's like a pretty full featured API for reading files from the file system and doing globs to list out files and reading environment variables and handling failures.", "tokens": [309, 311, 411, 257, 1238, 1577, 13822, 9362, 337, 3760, 7098, 490, 264, 3991, 1185, 293, 884, 3114, 929, 281, 1329, 484, 7098, 293, 3760, 2823, 9102, 293, 13175, 20774, 13], "temperature": 0.0, "avg_logprob": -0.18118723048720248, "compression_ratio": 1.6794871794871795, "no_speech_prob": 1.0614108759909868e-05}, {"id": 62, "seek": 42400, "start": 437.0, "end": 445.0, "text": " If something if there's a fatal error, you can pass that up at the top level of the script and it will report that with rich information.", "tokens": [759, 746, 498, 456, 311, 257, 24069, 6713, 11, 291, 393, 1320, 300, 493, 412, 264, 1192, 1496, 295, 264, 5755, 293, 309, 486, 2275, 300, 365, 4593, 1589, 13], "temperature": 0.0, "avg_logprob": -0.18118723048720248, "compression_ratio": 1.6794871794871795, "no_speech_prob": 1.0614108759909868e-05}, {"id": 63, "seek": 42400, "start": 445.0, "end": 451.0, "text": " Or you can handle fatal errors and make sure that you've handled every possible failure.", "tokens": [1610, 291, 393, 4813, 24069, 13603, 293, 652, 988, 300, 291, 600, 18033, 633, 1944, 7763, 13], "temperature": 0.0, "avg_logprob": -0.18118723048720248, "compression_ratio": 1.6794871794871795, "no_speech_prob": 1.0614108759909868e-05}, {"id": 64, "seek": 45100, "start": 451.0, "end": 456.0, "text": " So now Elm code gen, we did an episode on that.", "tokens": [407, 586, 2699, 76, 3089, 1049, 11, 321, 630, 364, 3500, 322, 300, 13], "temperature": 0.0, "avg_logprob": -0.19438412677810854, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.0615549399517477e-05}, {"id": 65, "seek": 45100, "start": 456.0, "end": 461.0, "text": " It's an amazing tool that lets you write Elm code to generate Elm code.", "tokens": [467, 311, 364, 2243, 2290, 300, 6653, 291, 2464, 2699, 76, 3089, 281, 8460, 2699, 76, 3089, 13], "temperature": 0.0, "avg_logprob": -0.19438412677810854, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.0615549399517477e-05}, {"id": 66, "seek": 45100, "start": 461.0, "end": 475.0, "text": " And it, you know, to me, its main superpower is giving you like these sort of type safe ways to to put together bits of code and make sure that you're passing them the data that they need,", "tokens": [400, 309, 11, 291, 458, 11, 281, 385, 11, 1080, 2135, 45765, 307, 2902, 291, 411, 613, 1333, 295, 2010, 3273, 2098, 281, 281, 829, 1214, 9239, 295, 3089, 293, 652, 988, 300, 291, 434, 8437, 552, 264, 1412, 300, 436, 643, 11], "temperature": 0.0, "avg_logprob": -0.19438412677810854, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.0615549399517477e-05}, {"id": 67, "seek": 47500, "start": 475.0, "end": 484.0, "text": " because it creates these little stubs for different packet like bindings for different packages that helps you make sure you're generating valid code for those APIs.", "tokens": [570, 309, 7829, 613, 707, 342, 5432, 337, 819, 20300, 411, 14786, 1109, 337, 819, 17401, 300, 3665, 291, 652, 988, 291, 434, 17746, 7363, 3089, 337, 729, 21445, 13], "temperature": 0.0, "avg_logprob": -0.18772283760277, "compression_ratio": 1.5656565656565657, "no_speech_prob": 1.5206298485281877e-05}, {"id": 68, "seek": 47500, "start": 484.0, "end": 489.0, "text": " It also has a little CLI tool that helps you generate code.", "tokens": [467, 611, 575, 257, 707, 12855, 40, 2290, 300, 3665, 291, 8460, 3089, 13], "temperature": 0.0, "avg_logprob": -0.18772283760277, "compression_ratio": 1.5656565656565657, "no_speech_prob": 1.5206298485281877e-05}, {"id": 69, "seek": 47500, "start": 489.0, "end": 494.0, "text": " But then the challenge becomes, OK, well, but now I want to pass in some data to it.", "tokens": [583, 550, 264, 3430, 3643, 11, 2264, 11, 731, 11, 457, 586, 286, 528, 281, 1320, 294, 512, 1412, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.18772283760277, "compression_ratio": 1.5656565656565657, "no_speech_prob": 1.5206298485281877e-05}, {"id": 70, "seek": 49400, "start": 494.0, "end": 505.0, "text": " So, OK, the CLI that Elm code gen provides gives you this little hook that lets you pass in some JSON data.", "tokens": [407, 11, 2264, 11, 264, 12855, 40, 300, 2699, 76, 3089, 1049, 6417, 2709, 291, 341, 707, 6328, 300, 6653, 291, 1320, 294, 512, 31828, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1776943817138672, "compression_ratio": 1.952991452991453, "no_speech_prob": 2.3922784748720005e-05}, {"id": 71, "seek": 49400, "start": 505.0, "end": 507.0, "text": " And then, well, what if you want to read an environment variable?", "tokens": [400, 550, 11, 731, 11, 437, 498, 291, 528, 281, 1401, 364, 2823, 7006, 30], "temperature": 0.0, "avg_logprob": -0.1776943817138672, "compression_ratio": 1.952991452991453, "no_speech_prob": 2.3922784748720005e-05}, {"id": 72, "seek": 49400, "start": 507.0, "end": 513.0, "text": " OK, well, encode that into JSON and pass that in as a flag when you call the Elm code gen CLI.", "tokens": [2264, 11, 731, 11, 2058, 1429, 300, 666, 31828, 293, 1320, 300, 294, 382, 257, 7166, 562, 291, 818, 264, 2699, 76, 3089, 1049, 12855, 40, 13], "temperature": 0.0, "avg_logprob": -0.1776943817138672, "compression_ratio": 1.952991452991453, "no_speech_prob": 2.3922784748720005e-05}, {"id": 73, "seek": 49400, "start": 513.0, "end": 520.0, "text": " And then, well, what if you want to read, you know, you want to read an environment variable, you want to read a file and pass in that context.", "tokens": [400, 550, 11, 731, 11, 437, 498, 291, 528, 281, 1401, 11, 291, 458, 11, 291, 528, 281, 1401, 364, 2823, 7006, 11, 291, 528, 281, 1401, 257, 3991, 293, 1320, 294, 300, 4319, 13], "temperature": 0.0, "avg_logprob": -0.1776943817138672, "compression_ratio": 1.952991452991453, "no_speech_prob": 2.3922784748720005e-05}, {"id": 74, "seek": 49400, "start": 520.0, "end": 522.0, "text": " You kind of have to hack something together.", "tokens": [509, 733, 295, 362, 281, 10339, 746, 1214, 13], "temperature": 0.0, "avg_logprob": -0.1776943817138672, "compression_ratio": 1.952991452991453, "no_speech_prob": 2.3922784748720005e-05}, {"id": 75, "seek": 52200, "start": 522.0, "end": 528.0, "text": " Yeah, it feels like you need to do a bash script to gather the information and then call Elm code gen.", "tokens": [865, 11, 309, 3417, 411, 291, 643, 281, 360, 257, 46183, 5755, 281, 5448, 264, 1589, 293, 550, 818, 2699, 76, 3089, 1049, 13], "temperature": 0.0, "avg_logprob": -0.18814769217638466, "compression_ratio": 1.8571428571428572, "no_speech_prob": 1.241135487362044e-05}, {"id": 76, "seek": 52200, "start": 528.0, "end": 536.0, "text": " Exactly. And and then like, well, should Elm code gen give you access to environment variables?", "tokens": [7587, 13, 400, 293, 550, 411, 11, 731, 11, 820, 2699, 76, 3089, 1049, 976, 291, 2105, 281, 2823, 9102, 30], "temperature": 0.0, "avg_logprob": -0.18814769217638466, "compression_ratio": 1.8571428571428572, "no_speech_prob": 1.241135487362044e-05}, {"id": 77, "seek": 52200, "start": 536.0, "end": 539.0, "text": " Should it give you a first class way to do that? Should it give you a first class way to read files?", "tokens": [6454, 309, 976, 291, 257, 700, 1508, 636, 281, 360, 300, 30, 6454, 309, 976, 291, 257, 700, 1508, 636, 281, 1401, 7098, 30], "temperature": 0.0, "avg_logprob": -0.18814769217638466, "compression_ratio": 1.8571428571428572, "no_speech_prob": 1.241135487362044e-05}, {"id": 78, "seek": 52200, "start": 539.0, "end": 545.0, "text": " Should it give you a nice way to do error handling and report that something went wrong?", "tokens": [6454, 309, 976, 291, 257, 1481, 636, 281, 360, 6713, 13175, 293, 2275, 300, 746, 1437, 2085, 30], "temperature": 0.0, "avg_logprob": -0.18814769217638466, "compression_ratio": 1.8571428571428572, "no_speech_prob": 1.241135487362044e-05}, {"id": 79, "seek": 52200, "start": 545.0, "end": 551.0, "text": " Which it does. But at a certain point, it's like becoming a more general purpose sort of scripting thing.", "tokens": [3013, 309, 775, 13, 583, 412, 257, 1629, 935, 11, 309, 311, 411, 5617, 257, 544, 2674, 4334, 1333, 295, 5755, 278, 551, 13], "temperature": 0.0, "avg_logprob": -0.18814769217638466, "compression_ratio": 1.8571428571428572, "no_speech_prob": 1.241135487362044e-05}, {"id": 80, "seek": 55100, "start": 551.0, "end": 558.0, "text": " So and that's sort of like back end task is a pretty general purpose way of doing that sort of thing.", "tokens": [407, 293, 300, 311, 1333, 295, 411, 646, 917, 5633, 307, 257, 1238, 2674, 4334, 636, 295, 884, 300, 1333, 295, 551, 13], "temperature": 0.0, "avg_logprob": -0.23278264438404755, "compression_ratio": 1.543859649122807, "no_speech_prob": 8.74989345902577e-05}, {"id": 81, "seek": 55100, "start": 558.0, "end": 571.0, "text": " Elm pages scripts. I've like put a lot of polish into making it like you just do Elm pages run path to your own pages script, which is in a script project folder.", "tokens": [2699, 76, 7183, 23294, 13, 286, 600, 411, 829, 257, 688, 295, 20452, 666, 1455, 309, 411, 291, 445, 360, 2699, 76, 7183, 1190, 3100, 281, 428, 1065, 7183, 5755, 11, 597, 307, 294, 257, 5755, 1716, 10820, 13], "temperature": 0.0, "avg_logprob": -0.23278264438404755, "compression_ratio": 1.543859649122807, "no_speech_prob": 8.74989345902577e-05}, {"id": 82, "seek": 57100, "start": 571.0, "end": 583.0, "text": " And it figures out how to compile and run it. And you can even do, you know, Elm pages bundle script and it will compile and minify that down to a single executable JS file.", "tokens": [400, 309, 9624, 484, 577, 281, 31413, 293, 1190, 309, 13, 400, 291, 393, 754, 360, 11, 291, 458, 11, 2699, 76, 7183, 24438, 5755, 293, 309, 486, 31413, 293, 923, 2505, 300, 760, 281, 257, 2167, 7568, 712, 33063, 3991, 13], "temperature": 0.0, "avg_logprob": -0.19240900527599247, "compression_ratio": 1.6287128712871286, "no_speech_prob": 2.2472875571111217e-05}, {"id": 83, "seek": 57100, "start": 583.0, "end": 593.0, "text": " So you can just chmod it, make it executable and run it. And if you have node installed, it'll just run as a single file with all the dependencies in line.", "tokens": [407, 291, 393, 445, 417, 8014, 309, 11, 652, 309, 7568, 712, 293, 1190, 309, 13, 400, 498, 291, 362, 9984, 8899, 11, 309, 603, 445, 1190, 382, 257, 2167, 3991, 365, 439, 264, 36606, 294, 1622, 13], "temperature": 0.0, "avg_logprob": -0.19240900527599247, "compression_ratio": 1.6287128712871286, "no_speech_prob": 2.2472875571111217e-05}, {"id": 84, "seek": 59300, "start": 593.0, "end": 601.0, "text": " So like should Elm like Elm code gen if it tries to is going to creep too far towards that.", "tokens": [407, 411, 820, 2699, 76, 411, 2699, 76, 3089, 1049, 498, 309, 9898, 281, 307, 516, 281, 9626, 886, 1400, 3030, 300, 13], "temperature": 0.0, "avg_logprob": -0.24418104778636585, "compression_ratio": 1.6067961165048543, "no_speech_prob": 3.4806322219083086e-05}, {"id": 85, "seek": 59300, "start": 601.0, "end": 608.0, "text": " And we're going to end up like reinventing the wheel over and over. And then like, well, what about Elm review?", "tokens": [400, 321, 434, 516, 281, 917, 493, 411, 33477, 278, 264, 5589, 670, 293, 670, 13, 400, 550, 411, 11, 731, 11, 437, 466, 2699, 76, 3131, 30], "temperature": 0.0, "avg_logprob": -0.24418104778636585, "compression_ratio": 1.6067961165048543, "no_speech_prob": 3.4806322219083086e-05}, {"id": 86, "seek": 59300, "start": 608.0, "end": 615.0, "text": " Like, should it? Because there are certain things you might want to do. You might want to write some of that context to a file.", "tokens": [1743, 11, 820, 309, 30, 1436, 456, 366, 1629, 721, 291, 1062, 528, 281, 360, 13, 509, 1062, 528, 281, 2464, 512, 295, 300, 4319, 281, 257, 3991, 13], "temperature": 0.0, "avg_logprob": -0.24418104778636585, "compression_ratio": 1.6067961165048543, "no_speech_prob": 3.4806322219083086e-05}, {"id": 87, "seek": 61500, "start": 615.0, "end": 628.0, "text": " You might. So at a certain point you run into a similar thing. And so I was I was recently hacking on some of these ideas that we talked about in our Elm and AI episode.", "tokens": [509, 1062, 13, 407, 412, 257, 1629, 935, 291, 1190, 666, 257, 2531, 551, 13, 400, 370, 286, 390, 286, 390, 3938, 31422, 322, 512, 295, 613, 3487, 300, 321, 2825, 466, 294, 527, 2699, 76, 293, 7318, 3500, 13], "temperature": 0.0, "avg_logprob": -0.2411504008553245, "compression_ratio": 1.2900763358778626, "no_speech_prob": 3.0715651519130915e-05}, {"id": 88, "seek": 62800, "start": 628.0, "end": 648.0, "text": " And I was making an Elm pages script that calls the GPT for API and super fun. And I essentially wanted to take like the the in scope type annotations, kind of like we talked about, like what, what values are in scope?", "tokens": [400, 286, 390, 1455, 364, 2699, 76, 7183, 5755, 300, 5498, 264, 26039, 51, 337, 9362, 293, 1687, 1019, 13, 400, 286, 4476, 1415, 281, 747, 411, 264, 264, 294, 11923, 2010, 25339, 763, 11, 733, 295, 411, 321, 2825, 466, 11, 411, 437, 11, 437, 4190, 366, 294, 11923, 30], "temperature": 0.0, "avg_logprob": -0.2602759447964755, "compression_ratio": 1.3885350318471337, "no_speech_prob": 3.882631062879227e-05}, {"id": 89, "seek": 64800, "start": 648.0, "end": 660.0, "text": " Like what are the direct dependencies that are available to me? And what are the like values that are in scope, the let values, the parameters that are in scope, right? Elm review knows.", "tokens": [1743, 437, 366, 264, 2047, 36606, 300, 366, 2435, 281, 385, 30, 400, 437, 366, 264, 411, 4190, 300, 366, 294, 11923, 11, 264, 718, 4190, 11, 264, 9834, 300, 366, 294, 11923, 11, 558, 30, 2699, 76, 3131, 3255, 13], "temperature": 0.0, "avg_logprob": -0.23712304433186848, "compression_ratio": 1.5827814569536425, "no_speech_prob": 1.5446026736753993e-05}, {"id": 90, "seek": 64800, "start": 660.0, "end": 664.0, "text": " So that you can feed all of that information to GPT.", "tokens": [407, 300, 291, 393, 3154, 439, 295, 300, 1589, 281, 26039, 51, 13], "temperature": 0.0, "avg_logprob": -0.23712304433186848, "compression_ratio": 1.5827814569536425, "no_speech_prob": 1.5446026736753993e-05}, {"id": 91, "seek": 66400, "start": 664.0, "end": 684.0, "text": " Exactly. I can seed the prompt with that context. So like Elm review isn't, you know, you're not going to make Elm review something that can like make HTTP requests and like do scripting tasks and write something to a file or print arbitrary things to the console.", "tokens": [7587, 13, 286, 393, 8871, 264, 12391, 365, 300, 4319, 13, 407, 411, 2699, 76, 3131, 1943, 380, 11, 291, 458, 11, 291, 434, 406, 516, 281, 652, 2699, 76, 3131, 746, 300, 393, 411, 652, 33283, 12475, 293, 411, 360, 5755, 278, 9608, 293, 2464, 746, 281, 257, 3991, 420, 4482, 23211, 721, 281, 264, 11076, 13], "temperature": 0.0, "avg_logprob": -0.24102803935175357, "compression_ratio": 1.6133333333333333, "no_speech_prob": 1.6442181731690653e-05}, {"id": 92, "seek": 66400, "start": 684.0, "end": 687.0, "text": " Like at a certain point, you run into the same problem, right?", "tokens": [1743, 412, 257, 1629, 935, 11, 291, 1190, 666, 264, 912, 1154, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.24102803935175357, "compression_ratio": 1.6133333333333333, "no_speech_prob": 1.6442181731690653e-05}, {"id": 93, "seek": 66400, "start": 687.0, "end": 688.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.24102803935175357, "compression_ratio": 1.6133333333333333, "no_speech_prob": 1.6442181731690653e-05}, {"id": 94, "seek": 68800, "start": 688.0, "end": 695.0, "text": " So Elm review pages code gen.", "tokens": [407, 2699, 76, 3131, 7183, 3089, 1049, 13], "temperature": 0.0, "avg_logprob": -0.27251458168029785, "compression_ratio": 1.4153846153846155, "no_speech_prob": 2.9944246762170224e-06}, {"id": 95, "seek": 68800, "start": 695.0, "end": 699.0, "text": " dash GPT.", "tokens": [8240, 26039, 51, 13], "temperature": 0.0, "avg_logprob": -0.27251458168029785, "compression_ratio": 1.4153846153846155, "no_speech_prob": 2.9944246762170224e-06}, {"id": 96, "seek": 68800, "start": 699.0, "end": 712.0, "text": " Because essentially, like, I want to bridge the gap between like, I essentially want to make an Elm review rule that is like a context gatherer.", "tokens": [1436, 4476, 11, 411, 11, 286, 528, 281, 7283, 264, 7417, 1296, 411, 11, 286, 4476, 528, 281, 652, 364, 2699, 76, 3131, 4978, 300, 307, 411, 257, 4319, 5448, 260, 13], "temperature": 0.0, "avg_logprob": -0.27251458168029785, "compression_ratio": 1.4153846153846155, "no_speech_prob": 2.9944246762170224e-06}, {"id": 97, "seek": 71200, "start": 712.0, "end": 718.0, "text": " Yeah. Which is good, because that's exactly what the Elm review rule does. It gathers context.", "tokens": [865, 13, 3013, 307, 665, 11, 570, 300, 311, 2293, 437, 264, 2699, 76, 3131, 4978, 775, 13, 467, 290, 11850, 4319, 13], "temperature": 0.0, "avg_logprob": -0.28073884822704176, "compression_ratio": 1.0561797752808988, "no_speech_prob": 1.6442425476270728e-05}, {"id": 98, "seek": 71800, "start": 718.0, "end": 744.0, "text": " It got, yeah, it gathers context. And then instead of saying, like defining a data extract, like with data extractor, that turns it into JSON, I want to say, like, here's my Elm pages script. And here is my Elm review rule that gathers context, pass that in as an argument to my Elm pages script.", "tokens": [467, 658, 11, 1338, 11, 309, 290, 11850, 4319, 13, 400, 550, 2602, 295, 1566, 11, 411, 17827, 257, 1412, 8947, 11, 411, 365, 1412, 8947, 284, 11, 300, 4523, 309, 666, 31828, 11, 286, 528, 281, 584, 11, 411, 11, 510, 311, 452, 2699, 76, 7183, 5755, 13, 400, 510, 307, 452, 2699, 76, 3131, 4978, 300, 290, 11850, 4319, 11, 1320, 300, 294, 382, 364, 6770, 281, 452, 2699, 76, 7183, 5755, 13], "temperature": 0.0, "avg_logprob": -0.18367803549464745, "compression_ratio": 1.6723163841807909, "no_speech_prob": 5.144158785697073e-05}, {"id": 99, "seek": 74400, "start": 744.0, "end": 749.0, "text": " And then given that context, I can now execute a script, which calls Elm code gen.", "tokens": [400, 550, 2212, 300, 4319, 11, 286, 393, 586, 14483, 257, 5755, 11, 597, 5498, 2699, 76, 3089, 1049, 13], "temperature": 0.0, "avg_logprob": -0.22414727438063847, "compression_ratio": 1.6108374384236452, "no_speech_prob": 4.908591654384509e-05}, {"id": 100, "seek": 74400, "start": 749.0, "end": 768.0, "text": " Yes, exactly. So the Elm code gen thing I already, I mean, it's actually fairly straightforward. You just in your Elm pages script project folder. So just like Elm review has a project folder, a review folder, that's just a regular Elm project.", "tokens": [1079, 11, 2293, 13, 407, 264, 2699, 76, 3089, 1049, 551, 286, 1217, 11, 286, 914, 11, 309, 311, 767, 6457, 15325, 13, 509, 445, 294, 428, 2699, 76, 7183, 5755, 1716, 10820, 13, 407, 445, 411, 2699, 76, 3131, 575, 257, 1716, 10820, 11, 257, 3131, 10820, 11, 300, 311, 445, 257, 3890, 2699, 76, 1716, 13], "temperature": 0.0, "avg_logprob": -0.22414727438063847, "compression_ratio": 1.6108374384236452, "no_speech_prob": 4.908591654384509e-05}, {"id": 101, "seek": 76800, "start": 768.0, "end": 778.0, "text": " Elm pages scripts also have, you know, by convention, you can call it a script folder, but it's just any Elm project, which has Elm pages installed as a dependency.", "tokens": [2699, 76, 7183, 23294, 611, 362, 11, 291, 458, 11, 538, 10286, 11, 291, 393, 818, 309, 257, 5755, 10820, 11, 457, 309, 311, 445, 604, 2699, 76, 1716, 11, 597, 575, 2699, 76, 7183, 8899, 382, 257, 33621, 13], "temperature": 0.0, "avg_logprob": -0.2076157113780146, "compression_ratio": 1.64453125, "no_speech_prob": 2.796898115775548e-05}, {"id": 102, "seek": 76800, "start": 778.0, "end": 785.0, "text": " By the way, I really like that we've kind of started using this pattern that I think I introduced.", "tokens": [3146, 264, 636, 11, 286, 534, 411, 300, 321, 600, 733, 295, 1409, 1228, 341, 5102, 300, 286, 519, 286, 7268, 13], "temperature": 0.0, "avg_logprob": -0.2076157113780146, "compression_ratio": 1.64453125, "no_speech_prob": 2.796898115775548e-05}, {"id": 103, "seek": 76800, "start": 785.0, "end": 789.0, "text": " I believe so. That's definitely what clued me into it.", "tokens": [286, 1697, 370, 13, 663, 311, 2138, 437, 596, 5827, 385, 666, 309, 13], "temperature": 0.0, "avg_logprob": -0.2076157113780146, "compression_ratio": 1.64453125, "no_speech_prob": 2.796898115775548e-05}, {"id": 104, "seek": 76800, "start": 789.0, "end": 795.0, "text": " I mean, it's like, oh, it's a folder for configuration, but it's like, yeah, but it works really well.", "tokens": [286, 914, 11, 309, 311, 411, 11, 1954, 11, 309, 311, 257, 10820, 337, 11694, 11, 457, 309, 311, 411, 11, 1338, 11, 457, 309, 1985, 534, 731, 13], "temperature": 0.0, "avg_logprob": -0.2076157113780146, "compression_ratio": 1.64453125, "no_speech_prob": 2.796898115775548e-05}, {"id": 105, "seek": 79500, "start": 795.0, "end": 805.0, "text": " So because, yeah, because you can think of it just like a regular Elm project. You can use your editor tooling and it understands what an Elm project is. So yeah, it's amazing.", "tokens": [407, 570, 11, 1338, 11, 570, 291, 393, 519, 295, 309, 445, 411, 257, 3890, 2699, 76, 1716, 13, 509, 393, 764, 428, 9839, 46593, 293, 309, 15146, 437, 364, 2699, 76, 1716, 307, 13, 407, 1338, 11, 309, 311, 2243, 13], "temperature": 0.0, "avg_logprob": -0.20752764351760286, "compression_ratio": 1.654054054054054, "no_speech_prob": 7.721719157416373e-05}, {"id": 106, "seek": 79500, "start": 805.0, "end": 817.0, "text": " So in that script project folder, you just have an Elm code gen project, like the generated source as a source directories.", "tokens": [407, 294, 300, 5755, 1716, 10820, 11, 291, 445, 362, 364, 2699, 76, 3089, 1049, 1716, 11, 411, 264, 10833, 4009, 382, 257, 4009, 5391, 530, 13], "temperature": 0.0, "avg_logprob": -0.20752764351760286, "compression_ratio": 1.654054054054054, "no_speech_prob": 7.721719157416373e-05}, {"id": 107, "seek": 79500, "start": 817.0, "end": 818.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.20752764351760286, "compression_ratio": 1.654054054054054, "no_speech_prob": 7.721719157416373e-05}, {"id": 108, "seek": 81800, "start": 818.0, "end": 829.0, "text": " And then you're good to go. So then you generate the Elm code gen bindings there. That's all you really need. Right. So there's not that much to that, you know, sort of combining those two tools together.", "tokens": [400, 550, 291, 434, 665, 281, 352, 13, 407, 550, 291, 8460, 264, 2699, 76, 3089, 1049, 14786, 1109, 456, 13, 663, 311, 439, 291, 534, 643, 13, 1779, 13, 407, 456, 311, 406, 300, 709, 281, 300, 11, 291, 458, 11, 1333, 295, 21928, 729, 732, 3873, 1214, 13], "temperature": 0.0, "avg_logprob": -0.18810889595433286, "compression_ratio": 1.6472727272727272, "no_speech_prob": 9.817759746511001e-06}, {"id": 109, "seek": 81800, "start": 829.0, "end": 840.0, "text": " It's actually a pretty loose coupling, but it works well. So, yeah, I've definitely thought about like how this could be done with Elm review and Elm pages.", "tokens": [467, 311, 767, 257, 1238, 9612, 37447, 11, 457, 309, 1985, 731, 13, 407, 11, 1338, 11, 286, 600, 2138, 1194, 466, 411, 577, 341, 727, 312, 1096, 365, 2699, 76, 3131, 293, 2699, 76, 7183, 13], "temperature": 0.0, "avg_logprob": -0.18810889595433286, "compression_ratio": 1.6472727272727272, "no_speech_prob": 9.817759746511001e-06}, {"id": 110, "seek": 81800, "start": 840.0, "end": 845.0, "text": " Yeah. So you were mentioning it was an intervention. What do you mean with an intervention?", "tokens": [865, 13, 407, 291, 645, 18315, 309, 390, 364, 13176, 13, 708, 360, 291, 914, 365, 364, 13176, 30], "temperature": 0.0, "avg_logprob": -0.18810889595433286, "compression_ratio": 1.6472727272727272, "no_speech_prob": 9.817759746511001e-06}, {"id": 111, "seek": 84500, "start": 845.0, "end": 848.0, "text": " The intervention is...", "tokens": [440, 13176, 307, 485], "temperature": 0.0, "avg_logprob": -0.23976961771647134, "compression_ratio": 1.2164179104477613, "no_speech_prob": 0.0003053199325222522}, {"id": 112, "seek": 84500, "start": 848.0, "end": 849.0, "text": " Where's my family?", "tokens": [2305, 311, 452, 1605, 30], "temperature": 0.0, "avg_logprob": -0.23976961771647134, "compression_ratio": 1.2164179104477613, "no_speech_prob": 0.0003053199325222522}, {"id": 113, "seek": 84500, "start": 849.0, "end": 860.0, "text": " Can I pressure you? We're worried about you, Jeroen. And we really think that you need to make Elm review pages code gen.", "tokens": [1664, 286, 3321, 291, 30, 492, 434, 5804, 466, 291, 11, 508, 2032, 268, 13, 400, 321, 534, 519, 300, 291, 643, 281, 652, 2699, 76, 3131, 7183, 3089, 1049, 13], "temperature": 0.0, "avg_logprob": -0.23976961771647134, "compression_ratio": 1.2164179104477613, "no_speech_prob": 0.0003053199325222522}, {"id": 114, "seek": 86000, "start": 860.0, "end": 881.0, "text": " Yeah. I mean, I think it would be an interesting thing to explore. It's sort of this question of like, so like potentially if Elm review had a way to call it through like some Node.js dependency, so you could like import some Node.js version of Elm review and run it.", "tokens": [865, 13, 286, 914, 11, 286, 519, 309, 576, 312, 364, 1880, 551, 281, 6839, 13, 467, 311, 1333, 295, 341, 1168, 295, 411, 11, 370, 411, 7263, 498, 2699, 76, 3131, 632, 257, 636, 281, 818, 309, 807, 411, 512, 38640, 13, 25530, 33621, 11, 370, 291, 727, 411, 974, 512, 38640, 13, 25530, 3037, 295, 2699, 76, 3131, 293, 1190, 309, 13], "temperature": 0.0, "avg_logprob": -0.2451527065700955, "compression_ratio": 1.639269406392694, "no_speech_prob": 3.267883221269585e-05}, {"id": 115, "seek": 86000, "start": 881.0, "end": 884.0, "text": " That could be interesting.", "tokens": [663, 727, 312, 1880, 13], "temperature": 0.0, "avg_logprob": -0.2451527065700955, "compression_ratio": 1.639269406392694, "no_speech_prob": 3.267883221269585e-05}, {"id": 116, "seek": 86000, "start": 884.0, "end": 888.0, "text": " Okay. You mean calling Elm review programmatically instead of...", "tokens": [1033, 13, 509, 914, 5141, 2699, 76, 3131, 37648, 5030, 2602, 295, 485], "temperature": 0.0, "avg_logprob": -0.2451527065700955, "compression_ratio": 1.639269406392694, "no_speech_prob": 3.267883221269585e-05}, {"id": 117, "seek": 88800, "start": 888.0, "end": 907.0, "text": " Exactly. Right. Because basically, I mean, so you can certainly use, you can certainly like build up project context and use like a codec to share your encoders and decoders. And that works pretty well.", "tokens": [7587, 13, 1779, 13, 1436, 1936, 11, 286, 914, 11, 370, 291, 393, 3297, 764, 11, 291, 393, 3297, 411, 1322, 493, 1716, 4319, 293, 764, 411, 257, 3089, 66, 281, 2073, 428, 2058, 378, 433, 293, 979, 378, 433, 13, 400, 300, 1985, 1238, 731, 13], "temperature": 0.0, "avg_logprob": -0.2010350694843367, "compression_ratio": 1.4428571428571428, "no_speech_prob": 0.00013760746514890343}, {"id": 118, "seek": 90700, "start": 907.0, "end": 930.0, "text": " Actually, the Lambda compiler also has this sort of undocumented way to create encoders, decoders of bytes, encoders. And so I've definitely considered like just hacking together a little prototype that I think I could do this, assuming that they're serializable values, things like functions are not.", "tokens": [5135, 11, 264, 45691, 31958, 611, 575, 341, 1333, 295, 40472, 636, 281, 1884, 2058, 378, 433, 11, 979, 378, 433, 295, 36088, 11, 2058, 378, 433, 13, 400, 370, 286, 600, 2138, 4888, 411, 445, 31422, 1214, 257, 707, 19475, 300, 286, 519, 286, 727, 360, 341, 11, 11926, 300, 436, 434, 17436, 22395, 4190, 11, 721, 411, 6828, 366, 406, 13], "temperature": 0.0, "avg_logprob": -0.2499203753115526, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.00010694229422369972}, {"id": 119, "seek": 93000, "start": 930.0, "end": 951.0, "text": " That's one benefit to doing it this other way where you can programmatically call Elm review because then it can execute this Elm code for you. So it's interesting. But I mean, at the end of the day, it's, I guess the point I'm trying to make is that like, this is a really powerful feature. And I think we should like build more cool stuff with it.", "tokens": [663, 311, 472, 5121, 281, 884, 309, 341, 661, 636, 689, 291, 393, 37648, 5030, 818, 2699, 76, 3131, 570, 550, 309, 393, 14483, 341, 2699, 76, 3089, 337, 291, 13, 407, 309, 311, 1880, 13, 583, 286, 914, 11, 412, 264, 917, 295, 264, 786, 11, 309, 311, 11, 286, 2041, 264, 935, 286, 478, 1382, 281, 652, 307, 300, 411, 11, 341, 307, 257, 534, 4005, 4111, 13, 400, 286, 519, 321, 820, 411, 1322, 544, 1627, 1507, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.19352889306766471, "compression_ratio": 1.560483870967742, "no_speech_prob": 7.718780398136005e-05}, {"id": 120, "seek": 93000, "start": 951.0, "end": 954.0, "text": " I'm not gonna convince you otherwise.", "tokens": [286, 478, 406, 799, 13447, 291, 5911, 13], "temperature": 0.0, "avg_logprob": -0.19352889306766471, "compression_ratio": 1.560483870967742, "no_speech_prob": 7.718780398136005e-05}, {"id": 121, "seek": 95400, "start": 954.0, "end": 971.0, "text": " I have announced it, I think in November, even though the feature was released probably a little bit earlier than that. No, I announced it in December, but it was released in November. Yeah, it's a running blog post is a pain sometimes.", "tokens": [286, 362, 7548, 309, 11, 286, 519, 294, 7674, 11, 754, 1673, 264, 4111, 390, 4736, 1391, 257, 707, 857, 3071, 813, 300, 13, 883, 11, 286, 7548, 309, 294, 7687, 11, 457, 309, 390, 4736, 294, 7674, 13, 865, 11, 309, 311, 257, 2614, 6968, 2183, 307, 257, 1822, 2171, 13], "temperature": 0.0, "avg_logprob": -0.19976828071508515, "compression_ratio": 1.63013698630137, "no_speech_prob": 0.00023048932780511677}, {"id": 122, "seek": 95400, "start": 971.0, "end": 975.0, "text": " Yeah. Have you heard of any cool things people have built with it?", "tokens": [865, 13, 3560, 291, 2198, 295, 604, 1627, 721, 561, 362, 3094, 365, 309, 30], "temperature": 0.0, "avg_logprob": -0.19976828071508515, "compression_ratio": 1.63013698630137, "no_speech_prob": 0.00023048932780511677}, {"id": 123, "seek": 95400, "start": 975.0, "end": 979.0, "text": " No, in practice, or at least people have not told me.", "tokens": [883, 11, 294, 3124, 11, 420, 412, 1935, 561, 362, 406, 1907, 385, 13], "temperature": 0.0, "avg_logprob": -0.19976828071508515, "compression_ratio": 1.63013698630137, "no_speech_prob": 0.00023048932780511677}, {"id": 124, "seek": 97900, "start": 979.0, "end": 988.0, "text": " They haven't shared it. Well, listener, if you have built something cool with it, tell your own because he's interested. Maintainers like to know those things.", "tokens": [814, 2378, 380, 5507, 309, 13, 1042, 11, 31569, 11, 498, 291, 362, 3094, 746, 1627, 365, 309, 11, 980, 428, 1065, 570, 415, 311, 3102, 13, 12383, 15209, 433, 411, 281, 458, 729, 721, 13], "temperature": 0.0, "avg_logprob": -0.35484092018821023, "compression_ratio": 1.3673469387755102, "no_speech_prob": 0.0004728252242784947}, {"id": 125, "seek": 97900, "start": 988.0, "end": 990.0, "text": " Yeah, they like feedback.", "tokens": [865, 11, 436, 411, 5824, 13], "temperature": 0.0, "avg_logprob": -0.35484092018821023, "compression_ratio": 1.3673469387755102, "no_speech_prob": 0.0004728252242784947}, {"id": 126, "seek": 97900, "start": 990.0, "end": 992.0, "text": " Yes, good ones.", "tokens": [1079, 11, 665, 2306, 13], "temperature": 0.0, "avg_logprob": -0.35484092018821023, "compression_ratio": 1.3673469387755102, "no_speech_prob": 0.0004728252242784947}, {"id": 127, "seek": 99200, "start": 992.0, "end": 1015.0, "text": " Yeah, absolutely. Well, I had a really good time building with it, like just being able to like do a direct dependency visitor and extract the information is so nice. You know, I mean, you've built these API's for going and extracting information for for use with reporting rules and fixes. So why not break it outside of the box?", "tokens": [865, 11, 3122, 13, 1042, 11, 286, 632, 257, 534, 665, 565, 2390, 365, 309, 11, 411, 445, 885, 1075, 281, 411, 360, 257, 2047, 33621, 28222, 293, 8947, 264, 1589, 307, 370, 1481, 13, 509, 458, 11, 286, 914, 11, 291, 600, 3094, 613, 9362, 311, 337, 516, 293, 49844, 1589, 337, 337, 764, 365, 10031, 4474, 293, 32539, 13, 407, 983, 406, 1821, 309, 2380, 295, 264, 2424, 30], "temperature": 0.0, "avg_logprob": -0.22272056579589844, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.00013131924788467586}, {"id": 128, "seek": 101500, "start": 1015.0, "end": 1042.0, "text": " Yeah, I did add extractors to a few of the rules that I made. Yeah, some of them published and some of them I haven't yet, at least. So for instance, I have this rule for licenses, which is called no approved license, which is basically going to forbid you from using licenses that your project has not cleared or have not accepted.", "tokens": [865, 11, 286, 630, 909, 8947, 830, 281, 257, 1326, 295, 264, 4474, 300, 286, 1027, 13, 865, 11, 512, 295, 552, 6572, 293, 512, 295, 552, 286, 2378, 380, 1939, 11, 412, 1935, 13, 407, 337, 5197, 11, 286, 362, 341, 4978, 337, 32821, 11, 597, 307, 1219, 572, 10826, 10476, 11, 597, 307, 1936, 516, 281, 34117, 291, 490, 1228, 32821, 300, 428, 1716, 575, 406, 19725, 420, 362, 406, 9035, 13], "temperature": 0.0, "avg_logprob": -0.23624275892208785, "compression_ratio": 1.6274509803921569, "no_speech_prob": 0.0003038444265257567}, {"id": 129, "seek": 104200, "start": 1042.0, "end": 1048.0, "text": " Like, for instance, yeah, our company is not allowed to use license XYZ.", "tokens": [1743, 11, 337, 5197, 11, 1338, 11, 527, 2237, 307, 406, 4350, 281, 764, 10476, 48826, 57, 13], "temperature": 0.0, "avg_logprob": -0.31254467368125916, "compression_ratio": 1.0957446808510638, "no_speech_prob": 0.00016602697724010795}, {"id": 130, "seek": 104200, "start": 1048.0, "end": 1051.0, "text": " GPL licenses and things. Yeah.", "tokens": [460, 21593, 32821, 293, 721, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.31254467368125916, "compression_ratio": 1.0957446808510638, "no_speech_prob": 0.00016602697724010795}, {"id": 131, "seek": 105100, "start": 1051.0, "end": 1075.0, "text": " Yeah, it's something that doesn't allow proprietary licenses, whatever, I'm not that familiar. And this rule is going to tell you, well, this dependency is using a license that you can't use, or this dependency is using a license that you have not mentioned as being okay or not okay. So you need to ask your legal team what you think should be done.", "tokens": [865, 11, 309, 311, 746, 300, 1177, 380, 2089, 38992, 32821, 11, 2035, 11, 286, 478, 406, 300, 4963, 13, 400, 341, 4978, 307, 516, 281, 980, 291, 11, 731, 11, 341, 33621, 307, 1228, 257, 10476, 300, 291, 393, 380, 764, 11, 420, 341, 33621, 307, 1228, 257, 10476, 300, 291, 362, 406, 2835, 382, 885, 1392, 420, 406, 1392, 13, 407, 291, 643, 281, 1029, 428, 5089, 1469, 437, 291, 519, 820, 312, 1096, 13], "temperature": 0.0, "avg_logprob": -0.20837720235188803, "compression_ratio": 1.7241379310344827, "no_speech_prob": 5.8280176745029166e-05}, {"id": 132, "seek": 107500, "start": 1075.0, "end": 1098.0, "text": " And at my company, we are a security firm. So we need things to be good legally and security wise. And one of the requirements that we have is that we need to know the licenses of the things that we use. And I think we need to make it available publicly. I think I've never seen it before, actually.", "tokens": [400, 412, 452, 2237, 11, 321, 366, 257, 3825, 6174, 13, 407, 321, 643, 721, 281, 312, 665, 21106, 293, 3825, 10829, 13, 400, 472, 295, 264, 7728, 300, 321, 362, 307, 300, 321, 643, 281, 458, 264, 32821, 295, 264, 721, 300, 321, 764, 13, 400, 286, 519, 321, 643, 281, 652, 309, 2435, 14843, 13, 286, 519, 286, 600, 1128, 1612, 309, 949, 11, 767, 13], "temperature": 0.0, "avg_logprob": -0.24319455498143247, "compression_ratio": 1.6105263157894736, "no_speech_prob": 0.00021993977134115994}, {"id": 133, "seek": 107500, "start": 1098.0, "end": 1099.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.24319455498143247, "compression_ratio": 1.6105263157894736, "no_speech_prob": 0.00021993977134115994}, {"id": 134, "seek": 109900, "start": 1099.0, "end": 1116.0, "text": " So every now and then, or actually, every time we update our dependencies, we need to inform some legal entity in our company, which licenses we're using and which dependencies we're using.", "tokens": [407, 633, 586, 293, 550, 11, 420, 767, 11, 633, 565, 321, 5623, 527, 36606, 11, 321, 643, 281, 1356, 512, 5089, 13977, 294, 527, 2237, 11, 597, 32821, 321, 434, 1228, 293, 597, 36606, 321, 434, 1228, 13], "temperature": 0.0, "avg_logprob": -0.226898193359375, "compression_ratio": 1.4765625, "no_speech_prob": 0.0013880961341783404}, {"id": 135, "seek": 111600, "start": 1116.0, "end": 1131.0, "text": " And so what I've made for this rule, I've changed it so that it has a data extractor that gives you the licenses that you're using for each dependency. So dependency elm slash core is using MIT or something like that.", "tokens": [400, 370, 437, 286, 600, 1027, 337, 341, 4978, 11, 286, 600, 3105, 309, 370, 300, 309, 575, 257, 1412, 8947, 284, 300, 2709, 291, 264, 32821, 300, 291, 434, 1228, 337, 1184, 33621, 13, 407, 33621, 806, 76, 17330, 4965, 307, 1228, 13100, 420, 746, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.22259971330750664, "compression_ratio": 1.4466666666666668, "no_speech_prob": 5.3072402806719765e-05}, {"id": 136, "seek": 113100, "start": 1131.0, "end": 1154.0, "text": " So that's now the process of listing the license that we have is automated, which previously we had to do manually. It's not a big deal in the case of our dependency, because we don't have 50 of them. It's a lot more painful for our JavaScript dependencies or NPM dependencies. But it's a nice thing to automate.", "tokens": [407, 300, 311, 586, 264, 1399, 295, 22161, 264, 10476, 300, 321, 362, 307, 18473, 11, 597, 8046, 321, 632, 281, 360, 16945, 13, 467, 311, 406, 257, 955, 2028, 294, 264, 1389, 295, 527, 33621, 11, 570, 321, 500, 380, 362, 2625, 295, 552, 13, 467, 311, 257, 688, 544, 11697, 337, 527, 15778, 36606, 420, 426, 18819, 36606, 13, 583, 309, 311, 257, 1481, 551, 281, 31605, 13], "temperature": 0.0, "avg_logprob": -0.246369439202386, "compression_ratio": 1.5522388059701493, "no_speech_prob": 2.2825386622571386e-05}, {"id": 137, "seek": 115400, "start": 1154.0, "end": 1161.0, "text": " Another one that I've worked on, which I have not published yet, because I forgot about it.", "tokens": [3996, 472, 300, 286, 600, 2732, 322, 11, 597, 286, 362, 406, 6572, 1939, 11, 570, 286, 5298, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.2383762565818993, "compression_ratio": 1.4333333333333333, "no_speech_prob": 6.60440418869257e-05}, {"id": 138, "seek": 115400, "start": 1161.0, "end": 1165.0, "text": " Was the no deprecated one.", "tokens": [3027, 264, 572, 1367, 13867, 770, 472, 13], "temperature": 0.0, "avg_logprob": -0.2383762565818993, "compression_ratio": 1.4333333333333333, "no_speech_prob": 6.60440418869257e-05}, {"id": 139, "seek": 115400, "start": 1165.0, "end": 1166.0, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.2383762565818993, "compression_ratio": 1.4333333333333333, "no_speech_prob": 6.60440418869257e-05}, {"id": 140, "seek": 115400, "start": 1166.0, "end": 1168.0, "text": " Are you familiar with that rule?", "tokens": [2014, 291, 4963, 365, 300, 4978, 30], "temperature": 0.0, "avg_logprob": -0.2383762565818993, "compression_ratio": 1.4333333333333333, "no_speech_prob": 6.60440418869257e-05}, {"id": 141, "seek": 115400, "start": 1168.0, "end": 1175.0, "text": " Yeah, I think so. Does it look for like an at deprecated annotation or something in the doc comments?", "tokens": [865, 11, 286, 519, 370, 13, 4402, 309, 574, 337, 411, 364, 412, 1367, 13867, 770, 48654, 420, 746, 294, 264, 3211, 3053, 30], "temperature": 0.0, "avg_logprob": -0.2383762565818993, "compression_ratio": 1.4333333333333333, "no_speech_prob": 6.60440418869257e-05}, {"id": 142, "seek": 117500, "start": 1175.0, "end": 1196.0, "text": " Yeah, exactly. So everything that you annotate as deprecated, either through that at deprecated in the function or the modules documentation, or something that has deprecated in their name, which you can easily do in application code, like, oh, this thing is deprecated. So let's rename it. That makes it obvious everywhere.", "tokens": [865, 11, 2293, 13, 407, 1203, 300, 291, 25339, 473, 382, 1367, 13867, 770, 11, 2139, 807, 300, 412, 1367, 13867, 770, 294, 264, 2445, 420, 264, 16679, 14333, 11, 420, 746, 300, 575, 1367, 13867, 770, 294, 641, 1315, 11, 597, 291, 393, 3612, 360, 294, 3861, 3089, 11, 411, 11, 1954, 11, 341, 551, 307, 1367, 13867, 770, 13, 407, 718, 311, 36741, 309, 13, 663, 1669, 309, 6322, 5315, 13], "temperature": 0.0, "avg_logprob": -0.21498585985852525, "compression_ratio": 1.6446700507614214, "no_speech_prob": 4.0062397602014244e-05}, {"id": 143, "seek": 119600, "start": 1196.0, "end": 1217.0, "text": " This rule is really meant to be used with ElmReview suppress, so that all the things that you have deprecated, you will be able to continue using, but you should not add more usages of those. So ElmReview suppress is really working very well with that rule, in my opinion.", "tokens": [639, 4978, 307, 534, 4140, 281, 312, 1143, 365, 2699, 76, 8524, 1759, 26835, 11, 370, 300, 439, 264, 721, 300, 291, 362, 1367, 13867, 770, 11, 291, 486, 312, 1075, 281, 2354, 1228, 11, 457, 291, 820, 406, 909, 544, 505, 1660, 295, 729, 13, 407, 2699, 76, 8524, 1759, 26835, 307, 534, 1364, 588, 731, 365, 300, 4978, 11, 294, 452, 4800, 13], "temperature": 0.0, "avg_logprob": -0.19897036621536035, "compression_ratio": 1.5632183908045978, "no_speech_prob": 8.614020043751225e-05}, {"id": 144, "seek": 121700, "start": 1217.0, "end": 1233.0, "text": " The problem, though, is that it doesn't tell you what to tackle next. Suppressions are meant to be resolved. They're meant to be tackled at some point. You should get rid of those.", "tokens": [440, 1154, 11, 1673, 11, 307, 300, 309, 1177, 380, 980, 291, 437, 281, 14896, 958, 13, 9391, 735, 626, 366, 4140, 281, 312, 20772, 13, 814, 434, 4140, 281, 312, 9426, 1493, 412, 512, 935, 13, 509, 820, 483, 3973, 295, 729, 13], "temperature": 0.0, "avg_logprob": -0.19403566916783652, "compression_ratio": 1.3740458015267176, "no_speech_prob": 2.2826243366580456e-05}, {"id": 145, "seek": 123300, "start": 1233.0, "end": 1252.0, "text": " And the suppression files are meant to be readable by human and even edited, potentially. So you can see which files have the most usages of deprecated things. So file A has 47 issues, file B has 23.", "tokens": [400, 264, 36807, 7098, 366, 4140, 281, 312, 49857, 538, 1952, 293, 754, 23016, 11, 7263, 13, 407, 291, 393, 536, 597, 7098, 362, 264, 881, 505, 1660, 295, 1367, 13867, 770, 721, 13, 407, 3991, 316, 575, 16953, 2663, 11, 3991, 363, 575, 6673, 13], "temperature": 0.0, "avg_logprob": -0.21558563232421876, "compression_ratio": 1.3630136986301369, "no_speech_prob": 4.757458737003617e-05}, {"id": 146, "seek": 125200, "start": 1252.0, "end": 1270.0, "text": " And regardless how you want to tackle those, you can say, okay, well, I'm going to try to remove all the ones from file A or file B or whatever. But that only gives you like one aspect of what to tackle, like which files you should look at.", "tokens": [400, 10060, 577, 291, 528, 281, 14896, 729, 11, 291, 393, 584, 11, 1392, 11, 731, 11, 286, 478, 516, 281, 853, 281, 4159, 439, 264, 2306, 490, 3991, 316, 420, 3991, 363, 420, 2035, 13, 583, 300, 787, 2709, 291, 411, 472, 4171, 295, 437, 281, 14896, 11, 411, 597, 7098, 291, 820, 574, 412, 13], "temperature": 0.0, "avg_logprob": -0.20881552774398054, "compression_ratio": 1.5, "no_speech_prob": 0.00012532644905149937}, {"id": 147, "seek": 127000, "start": 1270.0, "end": 1284.0, "text": " But it doesn't tell you what deprecated things are used most. That is something that you're going to have to look at yourself, right? And that can be a bit painful if you really want to get that information.", "tokens": [583, 309, 1177, 380, 980, 291, 437, 1367, 13867, 770, 721, 366, 1143, 881, 13, 663, 307, 746, 300, 291, 434, 516, 281, 362, 281, 574, 412, 1803, 11, 558, 30, 400, 300, 393, 312, 257, 857, 11697, 498, 291, 534, 528, 281, 483, 300, 1589, 13], "temperature": 0.0, "avg_logprob": -0.18545143277037376, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.00010887850658036768}, {"id": 148, "seek": 128400, "start": 1284.0, "end": 1300.0, "text": " So what I made is I added a data extractor, big surprise here, where that is exactly the information that you're getting out of, is which things are deprecated. And are they deprecated because the module is deprecated?", "tokens": [407, 437, 286, 1027, 307, 286, 3869, 257, 1412, 8947, 284, 11, 955, 6365, 510, 11, 689, 300, 307, 2293, 264, 1589, 300, 291, 434, 1242, 484, 295, 11, 307, 597, 721, 366, 1367, 13867, 770, 13, 400, 366, 436, 1367, 13867, 770, 570, 264, 10088, 307, 1367, 13867, 770, 30], "temperature": 0.0, "avg_logprob": -0.232412390275435, "compression_ratio": 1.4630872483221478, "no_speech_prob": 0.00011589853966142982}, {"id": 149, "seek": 130000, "start": 1300.0, "end": 1314.0, "text": " Or are they deprecated because they have been tagged as deprecated? And then in how many places are they used? And then you can see, okay, well, this function, this deprecated function is used two times.", "tokens": [1610, 366, 436, 1367, 13867, 770, 570, 436, 362, 668, 40239, 382, 1367, 13867, 770, 30, 400, 550, 294, 577, 867, 3190, 366, 436, 1143, 30, 400, 550, 291, 393, 536, 11, 1392, 11, 731, 11, 341, 2445, 11, 341, 1367, 13867, 770, 2445, 307, 1143, 732, 1413, 13], "temperature": 0.0, "avg_logprob": -0.19803448443142874, "compression_ratio": 1.573643410852713, "no_speech_prob": 4.3998756154906005e-05}, {"id": 150, "seek": 131400, "start": 1314.0, "end": 1331.0, "text": " So it will be pretty easy to fix. And this function is used 230 times, which is like, okay, well, that's going to be harder. Maybe it's more interesting to tackle that one now. So now you have the information of where the deprecations are in which files.", "tokens": [407, 309, 486, 312, 1238, 1858, 281, 3191, 13, 400, 341, 2445, 307, 1143, 35311, 1413, 11, 597, 307, 411, 11, 1392, 11, 731, 11, 300, 311, 516, 281, 312, 6081, 13, 2704, 309, 311, 544, 1880, 281, 14896, 300, 472, 586, 13, 407, 586, 291, 362, 264, 1589, 295, 689, 264, 1367, 13867, 763, 366, 294, 597, 7098, 13], "temperature": 0.0, "avg_logprob": -0.24421074986457825, "compression_ratio": 1.4514285714285715, "no_speech_prob": 7.888858817750588e-06}, {"id": 151, "seek": 133100, "start": 1331.0, "end": 1345.0, "text": " You have the information of which deprecated things are used and how often. And now you have more information to tackle those issues, which I've found to be pretty interesting. So I should just focus on releasing that one.", "tokens": [509, 362, 264, 1589, 295, 597, 1367, 13867, 770, 721, 366, 1143, 293, 577, 2049, 13, 400, 586, 291, 362, 544, 1589, 281, 14896, 729, 2663, 11, 597, 286, 600, 1352, 281, 312, 1238, 1880, 13, 407, 286, 820, 445, 1879, 322, 16327, 300, 472, 13], "temperature": 0.0, "avg_logprob": -0.21349723080554642, "compression_ratio": 1.5844748858447488, "no_speech_prob": 3.024042052857112e-05}, {"id": 152, "seek": 133100, "start": 1345.0, "end": 1355.0, "text": " If it's not released by the time that you listen to this, and you're interested, let me know. Like, kick my butt, something.", "tokens": [759, 309, 311, 406, 4736, 538, 264, 565, 300, 291, 2140, 281, 341, 11, 293, 291, 434, 3102, 11, 718, 385, 458, 13, 1743, 11, 4437, 452, 6660, 11, 746, 13], "temperature": 0.0, "avg_logprob": -0.21349723080554642, "compression_ratio": 1.5844748858447488, "no_speech_prob": 3.024042052857112e-05}, {"id": 153, "seek": 135500, "start": 1355.0, "end": 1369.0, "text": " Very cool. I like that idea a lot of kind of bundling an extractor directly into these rules. That seems really cool. So like, do you think that that is a good general practice?", "tokens": [4372, 1627, 13, 286, 411, 300, 1558, 257, 688, 295, 733, 295, 13882, 1688, 364, 8947, 284, 3838, 666, 613, 4474, 13, 663, 2544, 534, 1627, 13, 407, 411, 11, 360, 291, 519, 300, 300, 307, 257, 665, 2674, 3124, 30], "temperature": 0.0, "avg_logprob": -0.1953432083129883, "compression_ratio": 1.3615384615384616, "no_speech_prob": 0.00048025071737356484}, {"id": 154, "seek": 136900, "start": 1369.0, "end": 1387.0, "text": " Are there specific contexts where that works better? Like where a rule has context that's meaningful on its own, as opposed to like, like imports, they don't really necessarily tell you anything. Whereas like licenses, you just list out the licenses. I don't know.", "tokens": [2014, 456, 2685, 30628, 689, 300, 1985, 1101, 30, 1743, 689, 257, 4978, 575, 4319, 300, 311, 10995, 322, 1080, 1065, 11, 382, 8851, 281, 411, 11, 411, 41596, 11, 436, 500, 380, 534, 4725, 980, 291, 1340, 13, 13813, 411, 32821, 11, 291, 445, 1329, 484, 264, 32821, 13, 286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.22509088354595638, "compression_ratio": 1.5, "no_speech_prob": 1.983166475838516e-05}, {"id": 155, "seek": 138700, "start": 1387.0, "end": 1406.0, "text": " I haven't made any, I haven't uncovered any specific rules about rules and data extractors. It's like, it's more like, I need some insight to do some task, and I need to, in order to do something.", "tokens": [286, 2378, 380, 1027, 604, 11, 286, 2378, 380, 37729, 604, 2685, 4474, 466, 4474, 293, 1412, 8947, 830, 13, 467, 311, 411, 11, 309, 311, 544, 411, 11, 286, 643, 512, 11269, 281, 360, 512, 5633, 11, 293, 286, 643, 281, 11, 294, 1668, 281, 360, 746, 13], "temperature": 0.0, "avg_logprob": -0.20384423237926555, "compression_ratio": 1.5076923076923077, "no_speech_prob": 7.141181413317099e-05}, {"id": 156, "seek": 140600, "start": 1406.0, "end": 1424.0, "text": " And if there happens to be a rule that's that relates to that, then maybe it's interesting for that rule to do it. In the instance of no deprecated, the issue is how do I fix those application issues? So that's really related to the rule.", "tokens": [400, 498, 456, 2314, 281, 312, 257, 4978, 300, 311, 300, 16155, 281, 300, 11, 550, 1310, 309, 311, 1880, 337, 300, 4978, 281, 360, 309, 13, 682, 264, 5197, 295, 572, 1367, 13867, 770, 11, 264, 2734, 307, 577, 360, 286, 3191, 729, 3861, 2663, 30, 407, 300, 311, 534, 4077, 281, 264, 4978, 13], "temperature": 0.0, "avg_logprob": -0.24906250635782878, "compression_ratio": 1.5454545454545454, "no_speech_prob": 3.2191928767133504e-05}, {"id": 157, "seek": 142400, "start": 1424.0, "end": 1438.0, "text": " So I think it makes sense to have the data extractor bundled along with it. Will it? I guess there's probably not much of a performance cost because the no deprecated is going to collect that information regardless.", "tokens": [407, 286, 519, 309, 1669, 2020, 281, 362, 264, 1412, 8947, 284, 13882, 1493, 2051, 365, 309, 13, 3099, 309, 30, 286, 2041, 456, 311, 1391, 406, 709, 295, 257, 3389, 2063, 570, 264, 572, 1367, 13867, 770, 307, 516, 281, 2500, 300, 1589, 10060, 13], "temperature": 0.0, "avg_logprob": -0.1832732128840621, "compression_ratio": 1.5215686274509803, "no_speech_prob": 4.6109911636449397e-05}, {"id": 158, "seek": 142400, "start": 1438.0, "end": 1451.0, "text": " So then it's just like, do you encode that context to JSON or not? But does it basically skip executing the JSON encoding part if you don't use the extract flag in the CLI?", "tokens": [407, 550, 309, 311, 445, 411, 11, 360, 291, 2058, 1429, 300, 4319, 281, 31828, 420, 406, 30, 583, 775, 309, 1936, 10023, 32368, 264, 31828, 43430, 644, 498, 291, 500, 380, 764, 264, 8947, 7166, 294, 264, 12855, 40, 30], "temperature": 0.0, "avg_logprob": -0.1832732128840621, "compression_ratio": 1.5215686274509803, "no_speech_prob": 4.6109911636449397e-05}, {"id": 159, "seek": 145100, "start": 1451.0, "end": 1469.0, "text": " Exactly. I don't know if people are going to make things that are very expensive to compute, but I'm assuming it will be. So yes, I'm skipping work. If I notice that people that were not reporting in JSON format, and we're not asking to extract something.", "tokens": [7587, 13, 286, 500, 380, 458, 498, 561, 366, 516, 281, 652, 721, 300, 366, 588, 5124, 281, 14722, 11, 457, 286, 478, 11926, 309, 486, 312, 13, 407, 2086, 11, 286, 478, 31533, 589, 13, 759, 286, 3449, 300, 561, 300, 645, 406, 10031, 294, 31828, 7877, 11, 293, 321, 434, 406, 3365, 281, 8947, 746, 13], "temperature": 0.0, "avg_logprob": -0.2147489978421119, "compression_ratio": 1.4488636363636365, "no_speech_prob": 0.00014410295989364386}, {"id": 160, "seek": 146900, "start": 1469.0, "end": 1484.0, "text": " So we will still need to collect all the information. There's no special case like, oh, if we're trying to extract, then we will collect things differently, which could be nice in practice, but would also make the rule a lot more complex.", "tokens": [407, 321, 486, 920, 643, 281, 2500, 439, 264, 1589, 13, 821, 311, 572, 2121, 1389, 411, 11, 1954, 11, 498, 321, 434, 1382, 281, 8947, 11, 550, 321, 486, 2500, 721, 7614, 11, 597, 727, 312, 1481, 294, 3124, 11, 457, 576, 611, 652, 264, 4978, 257, 688, 544, 3997, 13], "temperature": 0.0, "avg_logprob": -0.2229245560509818, "compression_ratio": 1.460122699386503, "no_speech_prob": 1.9521057765814476e-05}, {"id": 161, "seek": 148400, "start": 1484.0, "end": 1500.0, "text": " But we will skip calling the data extractor if it's not requested. So yeah, for the licenses, I think it makes sense to have a list of licenses that go with that rule. For instance, what rules could you have with no unused variables?", "tokens": [583, 321, 486, 10023, 5141, 264, 1412, 8947, 284, 498, 309, 311, 406, 16436, 13, 407, 1338, 11, 337, 264, 32821, 11, 286, 519, 309, 1669, 2020, 281, 362, 257, 1329, 295, 32821, 300, 352, 365, 300, 4978, 13, 1171, 5197, 11, 437, 4474, 727, 291, 362, 365, 572, 44383, 9102, 30], "temperature": 0.0, "avg_logprob": -0.23165270260402135, "compression_ratio": 1.4382716049382716, "no_speech_prob": 1.497013454354601e-05}, {"id": 162, "seek": 150000, "start": 1500.0, "end": 1514.0, "text": " Like, could you make a graph of what other functions could be removed if we removed it? Maybe. Would it be worthwhile? I don't know. I don't think so, so far.", "tokens": [1743, 11, 727, 291, 652, 257, 4295, 295, 437, 661, 6828, 727, 312, 7261, 498, 321, 7261, 309, 30, 2704, 13, 6068, 309, 312, 28159, 30, 286, 500, 380, 458, 13, 286, 500, 380, 519, 370, 11, 370, 1400, 13], "temperature": 0.0, "avg_logprob": -0.25255309451710095, "compression_ratio": 1.3057851239669422, "no_speech_prob": 2.7534793844097294e-05}, {"id": 163, "seek": 151400, "start": 1514.0, "end": 1535.0, "text": " I mean, I think it's a rule of thumb. If it's like a clear cut set of data to extract, then maybe bundle it with it. But you could potentially even make that configurable since ElmReview is configured through plain Elm code. You could pass in options for an extractor. But I mean, at that point, I mean...", "tokens": [286, 914, 11, 286, 519, 309, 311, 257, 4978, 295, 9298, 13, 759, 309, 311, 411, 257, 1850, 1723, 992, 295, 1412, 281, 8947, 11, 550, 1310, 24438, 309, 365, 309, 13, 583, 291, 727, 7263, 754, 652, 300, 22192, 712, 1670, 2699, 76, 8524, 1759, 307, 30538, 807, 11121, 2699, 76, 3089, 13, 509, 727, 1320, 294, 3956, 337, 364, 8947, 284, 13, 583, 286, 914, 11, 412, 300, 935, 11, 286, 914, 485], "temperature": 0.0, "avg_logprob": -0.3622664922400366, "compression_ratio": 1.525, "no_speech_prob": 6.380600098054856e-05}, {"id": 164, "seek": 153500, "start": 1535.0, "end": 1544.0, "text": " You could have a data extractor enabled or disabled based on configurations. It really depends on what you want, right?", "tokens": [509, 727, 362, 257, 1412, 8947, 284, 15172, 420, 15191, 2361, 322, 31493, 13, 467, 534, 5946, 322, 437, 291, 528, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.19540326348666487, "compression_ratio": 1.3712574850299402, "no_speech_prob": 9.07975118025206e-06}, {"id": 165, "seek": 153500, "start": 1544.0, "end": 1551.0, "text": " Right. What is the purpose of preventExtract? There's something in the ElmReview API to prevent an extractor.", "tokens": [1779, 13, 708, 307, 264, 4334, 295, 4871, 36, 734, 1897, 30, 821, 311, 746, 294, 264, 2699, 76, 8524, 1759, 9362, 281, 4871, 364, 8947, 284, 13], "temperature": 0.0, "avg_logprob": -0.19540326348666487, "compression_ratio": 1.3712574850299402, "no_speech_prob": 9.07975118025206e-06}, {"id": 166, "seek": 155100, "start": 1551.0, "end": 1573.0, "text": " So the use case I had for this was like something for detecting unused CSS or something like that. You could imagine that you have a rule that tries to find all the CSS classes that are used in your application and returns a list of these CSS classes.", "tokens": [407, 264, 764, 1389, 286, 632, 337, 341, 390, 411, 746, 337, 40237, 44383, 24387, 420, 746, 411, 300, 13, 509, 727, 3811, 300, 291, 362, 257, 4978, 300, 9898, 281, 915, 439, 264, 24387, 5359, 300, 366, 1143, 294, 428, 3861, 293, 11247, 257, 1329, 295, 613, 24387, 5359, 13], "temperature": 0.0, "avg_logprob": -0.23233503861860796, "compression_ratio": 1.578616352201258, "no_speech_prob": 1.321139916399261e-05}, {"id": 167, "seek": 157300, "start": 1573.0, "end": 1591.0, "text": " This is not even about unused. It's just like this rule will try to find all the CSS classes that are referenced in your Elm code. And then you can pass that into a tool that prunes your CSS files by removing all the CSS classes that are not mentioned and so on.", "tokens": [639, 307, 406, 754, 466, 44383, 13, 467, 311, 445, 411, 341, 4978, 486, 853, 281, 915, 439, 264, 24387, 5359, 300, 366, 32734, 294, 428, 2699, 76, 3089, 13, 400, 550, 291, 393, 1320, 300, 666, 257, 2290, 300, 582, 15001, 428, 24387, 7098, 538, 12720, 439, 264, 24387, 5359, 300, 366, 406, 2835, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.20495036291697669, "compression_ratio": 1.5595238095238095, "no_speech_prob": 3.1692343327449635e-05}, {"id": 168, "seek": 159100, "start": 1591.0, "end": 1607.0, "text": " So for this rule to work, all the places where you would reference a CSS class, it would have to be in known position. So for instance, if you pass a CSS class to HTML.attributes.class, then it's known.", "tokens": [407, 337, 341, 4978, 281, 589, 11, 439, 264, 3190, 689, 291, 576, 6408, 257, 24387, 1508, 11, 309, 576, 362, 281, 312, 294, 2570, 2535, 13, 407, 337, 5197, 11, 498, 291, 1320, 257, 24387, 1508, 281, 17995, 13, 1591, 2024, 1819, 13, 11665, 11, 550, 309, 311, 2570, 13], "temperature": 0.0, "avg_logprob": -0.22259377566250887, "compression_ratio": 1.4125874125874125, "no_speech_prob": 5.8627388170862105e-06}, {"id": 169, "seek": 160700, "start": 1607.0, "end": 1627.0, "text": " It's extractable and it's easy to see what this value is used to be a class or this value is a class. But if you pass a variable to that function, to the class function, then it's a lot harder to figure out what the CSS class was.", "tokens": [467, 311, 8947, 712, 293, 309, 311, 1858, 281, 536, 437, 341, 2158, 307, 1143, 281, 312, 257, 1508, 420, 341, 2158, 307, 257, 1508, 13, 583, 498, 291, 1320, 257, 7006, 281, 300, 2445, 11, 281, 264, 1508, 2445, 11, 550, 309, 311, 257, 688, 6081, 281, 2573, 484, 437, 264, 24387, 1508, 390, 13], "temperature": 0.0, "avg_logprob": -0.16406189600626628, "compression_ratio": 1.5862068965517242, "no_speech_prob": 1.1125413948320784e-05}, {"id": 170, "seek": 162700, "start": 1627.0, "end": 1641.0, "text": " And in that case, you could have the rule say, hey, I encountered something that is unknown to me and I prefer reporting an error and you will have to fix it. And this is something that we have at our codebase at Crystallize.", "tokens": [400, 294, 300, 1389, 11, 291, 727, 362, 264, 4978, 584, 11, 4177, 11, 286, 20381, 746, 300, 307, 9841, 281, 385, 293, 286, 4382, 10031, 364, 6713, 293, 291, 486, 362, 281, 3191, 309, 13, 400, 341, 307, 746, 300, 321, 362, 412, 527, 3089, 17429, 412, 383, 627, 372, 304, 75, 1125, 13], "temperature": 0.0, "avg_logprob": -0.3220981339276847, "compression_ratio": 1.4705882352941178, "no_speech_prob": 1.0783205652842298e-05}, {"id": 171, "seek": 164100, "start": 1641.0, "end": 1657.0, "text": " And so the user will see that there's an error, but potentially you would also want to say, well, given this problem, I don't want to give you the extract. I'm going to prevent this extract or this issue.", "tokens": [400, 370, 264, 4195, 486, 536, 300, 456, 311, 364, 6713, 11, 457, 7263, 291, 576, 611, 528, 281, 584, 11, 731, 11, 2212, 341, 1154, 11, 286, 500, 380, 528, 281, 976, 291, 264, 8947, 13, 286, 478, 516, 281, 4871, 341, 8947, 420, 341, 2734, 13], "temperature": 0.0, "avg_logprob": -0.18561547597249348, "compression_ratio": 1.7142857142857142, "no_speech_prob": 7.411181286443025e-06}, {"id": 172, "seek": 164100, "start": 1657.0, "end": 1665.0, "text": " If you ask me to do an extract and there is this kind of issue, I'm just going to give you something that is incorrect. So let me just stop the extraction.", "tokens": [759, 291, 1029, 385, 281, 360, 364, 8947, 293, 456, 307, 341, 733, 295, 2734, 11, 286, 478, 445, 516, 281, 976, 291, 746, 300, 307, 18424, 13, 407, 718, 385, 445, 1590, 264, 30197, 13], "temperature": 0.0, "avg_logprob": -0.18561547597249348, "compression_ratio": 1.7142857142857142, "no_speech_prob": 7.411181286443025e-06}, {"id": 173, "seek": 166500, "start": 1665.0, "end": 1673.0, "text": " So that's what this function is for. So whenever you create an error, you can annotate it as preventing the extract.", "tokens": [407, 300, 311, 437, 341, 2445, 307, 337, 13, 407, 5699, 291, 1884, 364, 6713, 11, 291, 393, 25339, 473, 309, 382, 19965, 264, 8947, 13], "temperature": 0.0, "avg_logprob": -0.19165724118550617, "compression_ratio": 1.2473118279569892, "no_speech_prob": 5.2553159548551776e-06}, {"id": 174, "seek": 167300, "start": 1673.0, "end": 1695.0, "text": " Right. So just to make that explicit, it's a prevent extract is a function that you call on an Elm review error. So in the course of your rule, whether it's your no unused CSS classes rule or whatever it might be called, you can give an error.", "tokens": [1779, 13, 407, 445, 281, 652, 300, 13691, 11, 309, 311, 257, 4871, 8947, 307, 257, 2445, 300, 291, 818, 322, 364, 2699, 76, 3131, 6713, 13, 407, 294, 264, 1164, 295, 428, 4978, 11, 1968, 309, 311, 428, 572, 44383, 24387, 5359, 4978, 420, 2035, 309, 1062, 312, 1219, 11, 291, 393, 976, 364, 6713, 13], "temperature": 0.0, "avg_logprob": -0.23291636295005924, "compression_ratio": 1.5, "no_speech_prob": 9.817827049118932e-06}, {"id": 175, "seek": 169500, "start": 1695.0, "end": 1711.0, "text": " And then you can pass that error to prevent extract. And that error will now have that special behavior that when you call it the CLI with the extract flag, that error will propagate through and prevent it from giving the final JSON for extract.", "tokens": [400, 550, 291, 393, 1320, 300, 6713, 281, 4871, 8947, 13, 400, 300, 6713, 486, 586, 362, 300, 2121, 5223, 300, 562, 291, 818, 309, 264, 12855, 40, 365, 264, 8947, 7166, 11, 300, 6713, 486, 48256, 807, 293, 4871, 309, 490, 2902, 264, 2572, 31828, 337, 8947, 13], "temperature": 0.0, "avg_logprob": -0.2058633048579378, "compression_ratio": 1.5705128205128205, "no_speech_prob": 8.663831067678984e-06}, {"id": 176, "seek": 171100, "start": 1711.0, "end": 1727.0, "text": " That's very cool. So whenever you will run Elm review extract and report JSON and don't like the UX so far, because it will give you like null or undefined for the extract where you expected it.", "tokens": [663, 311, 588, 1627, 13, 407, 5699, 291, 486, 1190, 2699, 76, 3131, 8947, 293, 2275, 31828, 293, 500, 380, 411, 264, 40176, 370, 1400, 11, 570, 309, 486, 976, 291, 411, 18184, 420, 674, 5666, 2001, 337, 264, 8947, 689, 291, 5176, 309, 13], "temperature": 0.0, "avg_logprob": -0.26986353737967356, "compression_ratio": 1.3472222222222223, "no_speech_prob": 1.8630276827025227e-05}, {"id": 177, "seek": 172700, "start": 1727.0, "end": 1743.0, "text": " And you basically have to run Elm review again without those flags in order to find out which errors have popped up. It's not great, but I see. Yeah, it's good enough so far, at least until someone brings it.", "tokens": [400, 291, 1936, 362, 281, 1190, 2699, 76, 3131, 797, 1553, 729, 23265, 294, 1668, 281, 915, 484, 597, 13603, 362, 21545, 493, 13, 467, 311, 406, 869, 11, 457, 286, 536, 13, 865, 11, 309, 311, 665, 1547, 370, 1400, 11, 412, 1935, 1826, 1580, 5607, 309, 13], "temperature": 0.0, "avg_logprob": -0.24261105735346955, "compression_ratio": 1.3419354838709678, "no_speech_prob": 6.240832135517849e-06}, {"id": 178, "seek": 174300, "start": 1743.0, "end": 1764.0, "text": " It lets me know if I get an idea. Right. I guess you could like have a special error format and you could provide like an error decoder. I mean, this is assuming that people are consuming it in Elm, but even if they're not consuming it in Elm, you could make it a fairly lightweight format where you give an easy to consume error message.", "tokens": [467, 6653, 385, 458, 498, 286, 483, 364, 1558, 13, 1779, 13, 286, 2041, 291, 727, 411, 362, 257, 2121, 6713, 7877, 293, 291, 727, 2893, 411, 364, 6713, 979, 19866, 13, 286, 914, 11, 341, 307, 11926, 300, 561, 366, 19867, 309, 294, 2699, 76, 11, 457, 754, 498, 436, 434, 406, 19867, 309, 294, 2699, 76, 11, 291, 727, 652, 309, 257, 6457, 22052, 7877, 689, 291, 976, 364, 1858, 281, 14732, 6713, 3636, 13], "temperature": 0.0, "avg_logprob": -0.23910710841049382, "compression_ratio": 1.6732673267326732, "no_speech_prob": 2.4299735741806217e-05}, {"id": 179, "seek": 176400, "start": 1764.0, "end": 1781.0, "text": " Yeah, but the problem is that that could be like you would write an arbitrary JSON value to say, hey, this didn't work out. Right. But that could also be in a valid value for that rule. Right. Totally.", "tokens": [865, 11, 457, 264, 1154, 307, 300, 300, 727, 312, 411, 291, 576, 2464, 364, 23211, 31828, 2158, 281, 584, 11, 4177, 11, 341, 994, 380, 589, 484, 13, 1779, 13, 583, 300, 727, 611, 312, 294, 257, 7363, 2158, 337, 300, 4978, 13, 1779, 13, 22837, 13], "temperature": 0.0, "avg_logprob": -0.2760954453394963, "compression_ratio": 1.4055944055944056, "no_speech_prob": 2.2124699171399698e-05}, {"id": 180, "seek": 178100, "start": 1781.0, "end": 1797.0, "text": " I actually don't remember what I do exactly. Maybe I do something like show an error in the JSON. But in practice, when you run it with JQ to extract the exact information you want, you get a null. You get a null. Yeah. Yeah. So it's a bit annoying.", "tokens": [286, 767, 500, 380, 1604, 437, 286, 360, 2293, 13, 2704, 286, 360, 746, 411, 855, 364, 6713, 294, 264, 31828, 13, 583, 294, 3124, 11, 562, 291, 1190, 309, 365, 508, 48, 281, 8947, 264, 1900, 1589, 291, 528, 11, 291, 483, 257, 18184, 13, 509, 483, 257, 18184, 13, 865, 13, 865, 13, 407, 309, 311, 257, 857, 11304, 13], "temperature": 0.0, "avg_logprob": -0.24496815421364523, "compression_ratio": 1.464705882352941, "no_speech_prob": 3.269820808782242e-05}, {"id": 181, "seek": 179700, "start": 1797.0, "end": 1811.0, "text": " That makes sense. Yep. But if you consume this through a Node.js script, then you could do more checks like, oh, if rule name dot error equals something, then exactly something bad happens or something.", "tokens": [663, 1669, 2020, 13, 7010, 13, 583, 498, 291, 14732, 341, 807, 257, 38640, 13, 25530, 5755, 11, 550, 291, 727, 360, 544, 13834, 411, 11, 1954, 11, 498, 4978, 1315, 5893, 6713, 6915, 746, 11, 550, 2293, 746, 1578, 2314, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.31230988663234066, "compression_ratio": 1.5608695652173914, "no_speech_prob": 8.397979399887845e-06}, {"id": 182, "seek": 179700, "start": 1811.0, "end": 1825.0, "text": " Yeah, it totally depends on how you're using it. I would like to think maybe you're using it from Elm review code gen pages, but one page is now at the end.", "tokens": [865, 11, 309, 3879, 5946, 322, 577, 291, 434, 1228, 309, 13, 286, 576, 411, 281, 519, 1310, 291, 434, 1228, 309, 490, 2699, 76, 3131, 3089, 1049, 7183, 11, 457, 472, 3028, 307, 586, 412, 264, 917, 13], "temperature": 0.0, "avg_logprob": -0.31230988663234066, "compression_ratio": 1.5608695652173914, "no_speech_prob": 8.397979399887845e-06}, {"id": 183, "seek": 182500, "start": 1825.0, "end": 1831.0, "text": " I'm using it as a bargaining chip to try to build consensus.", "tokens": [286, 478, 1228, 309, 382, 257, 42108, 11409, 281, 853, 281, 1322, 19115, 13], "temperature": 0.0, "avg_logprob": -0.2642853800455729, "compression_ratio": 1.5245901639344261, "no_speech_prob": 5.4758929763920605e-05}, {"id": 184, "seek": 182500, "start": 1831.0, "end": 1846.0, "text": " The only part that I thought should not be at the beginning is code gen. And that's what you just did. So let's at least call it ElmU something or Elm pages something. But Elm code gen is not appropriate here, I'd say.", "tokens": [440, 787, 644, 300, 286, 1194, 820, 406, 312, 412, 264, 2863, 307, 3089, 1049, 13, 400, 300, 311, 437, 291, 445, 630, 13, 407, 718, 311, 412, 1935, 818, 309, 2699, 76, 52, 746, 420, 2699, 76, 7183, 746, 13, 583, 2699, 76, 3089, 1049, 307, 406, 6854, 510, 11, 286, 1116, 584, 13], "temperature": 0.0, "avg_logprob": -0.2642853800455729, "compression_ratio": 1.5245901639344261, "no_speech_prob": 5.4758929763920605e-05}, {"id": 185, "seek": 184600, "start": 1846.0, "end": 1858.0, "text": " Matt would have to come on this show and tell us otherwise. But yeah, that's true. In the meantime. Okay, you can have code gen first or review first.", "tokens": [7397, 576, 362, 281, 808, 322, 341, 855, 293, 980, 505, 5911, 13, 583, 1338, 11, 300, 311, 2074, 13, 682, 264, 14991, 13, 1033, 11, 291, 393, 362, 3089, 1049, 700, 420, 3131, 700, 13], "temperature": 0.0, "avg_logprob": -0.2820596694946289, "compression_ratio": 1.25, "no_speech_prob": 1.52060538312071e-05}, {"id": 186, "seek": 185800, "start": 1858.0, "end": 1887.0, "text": " So why don't we talk about like a couple of other possible use cases? I mean, again, really, it's really just taking these cool features in Elm review, which are, you know, giving you the ability to have visitors that look at expressions, which let you look at the abstract syntax tree of an entire project and walking through looking at what imports for a particular module are there.", "tokens": [407, 983, 500, 380, 321, 751, 466, 411, 257, 1916, 295, 661, 1944, 764, 3331, 30, 286, 914, 11, 797, 11, 534, 11, 309, 311, 534, 445, 1940, 613, 1627, 4122, 294, 2699, 76, 3131, 11, 597, 366, 11, 291, 458, 11, 2902, 291, 264, 3485, 281, 362, 14315, 300, 574, 412, 15277, 11, 597, 718, 291, 574, 412, 264, 12649, 28431, 4230, 295, 364, 2302, 1716, 293, 4494, 807, 1237, 412, 437, 41596, 337, 257, 1729, 10088, 366, 456, 13], "temperature": 0.0, "avg_logprob": -0.22675063189338235, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.368062506429851e-05}, {"id": 187, "seek": 188700, "start": 1887.0, "end": 1899.0, "text": " What are the direct dependencies, indirect dependencies of project, looking at the readme, looking at doc comments, and gathering up context to connect these things together.", "tokens": [708, 366, 264, 2047, 36606, 11, 19523, 36606, 295, 1716, 11, 1237, 412, 264, 1401, 1398, 11, 1237, 412, 3211, 3053, 11, 293, 13519, 493, 4319, 281, 1745, 613, 721, 1214, 13], "temperature": 0.0, "avg_logprob": -0.22228850258721244, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0002652923867572099}, {"id": 188, "seek": 189900, "start": 1899.0, "end": 1920.0, "text": " So, you know, of course, like, you can imagine the kinds of context, you would have to build up for marking certain values as unused or things like that. So building up like pretty sophisticated context about where how things connect together and things like that.", "tokens": [407, 11, 291, 458, 11, 295, 1164, 11, 411, 11, 291, 393, 3811, 264, 3685, 295, 4319, 11, 291, 576, 362, 281, 1322, 493, 337, 25482, 1629, 4190, 382, 44383, 420, 721, 411, 300, 13, 407, 2390, 493, 411, 1238, 16950, 4319, 466, 689, 577, 721, 1745, 1214, 293, 721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.21088908011453195, "compression_ratio": 1.6196319018404908, "no_speech_prob": 1.6963780581136234e-05}, {"id": 189, "seek": 192000, "start": 1920.0, "end": 1949.0, "text": " So given that, actually, on that topic, like, Elm review is not necessarily super easy tool to use, right? Like, writing a rule takes a lot of code in practice. Like if you have to do something really quick, I would not use Elm review rule for to extract something out of the code base, like I would use something like grep, or combi or tree grappler, which Brian Hicks made a few years ago.", "tokens": [407, 2212, 300, 11, 767, 11, 322, 300, 4829, 11, 411, 11, 2699, 76, 3131, 307, 406, 4725, 1687, 1858, 2290, 281, 764, 11, 558, 30, 1743, 11, 3579, 257, 4978, 2516, 257, 688, 295, 3089, 294, 3124, 13, 1743, 498, 291, 362, 281, 360, 746, 534, 1702, 11, 286, 576, 406, 764, 2699, 76, 3131, 4978, 337, 281, 8947, 746, 484, 295, 264, 3089, 3096, 11, 411, 286, 576, 764, 746, 411, 6066, 79, 11, 420, 2512, 72, 420, 4230, 290, 424, 427, 1918, 11, 597, 10765, 389, 7663, 1027, 257, 1326, 924, 2057, 13], "temperature": 0.0, "avg_logprob": -0.3115962028503418, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.00011060792894568294}, {"id": 190, "seek": 194900, "start": 1949.0, "end": 1978.0, "text": " Which are like, you just say, like, which patterns you're interested in, and you can then extract that information. The thing where Elm review is very powerful is it gives you a little more semantic analysis, like, you know, it's easy to figure out, well, this, this function is that from a local is defined in this in this module, or is it from a, an important module or from a dependency? And if so, which one?", "tokens": [3013, 366, 411, 11, 291, 445, 584, 11, 411, 11, 597, 8294, 291, 434, 3102, 294, 11, 293, 291, 393, 550, 8947, 300, 1589, 13, 440, 551, 689, 2699, 76, 3131, 307, 588, 4005, 307, 309, 2709, 291, 257, 707, 544, 47982, 5215, 11, 411, 11, 291, 458, 11, 309, 311, 1858, 281, 2573, 484, 11, 731, 11, 341, 11, 341, 2445, 307, 300, 490, 257, 2654, 307, 7642, 294, 341, 294, 341, 10088, 11, 420, 307, 309, 490, 257, 11, 364, 1021, 10088, 420, 490, 257, 33621, 30, 400, 498, 370, 11, 597, 472, 30], "temperature": 0.0, "avg_logprob": -0.25329973220825197, "compression_ratio": 1.648, "no_speech_prob": 5.390947262640111e-05}, {"id": 191, "seek": 197800, "start": 1978.0, "end": 1980.0, "text": " Like the module lookup table?", "tokens": [1743, 264, 10088, 574, 1010, 3199, 30], "temperature": 0.0, "avg_logprob": -0.24175831367229594, "compression_ratio": 1.0459770114942528, "no_speech_prob": 8.887791045708582e-05}, {"id": 192, "seek": 197800, "start": 1980.0, "end": 1981.0, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.24175831367229594, "compression_ratio": 1.0459770114942528, "no_speech_prob": 8.887791045708582e-05}, {"id": 193, "seek": 197800, "start": 1981.0, "end": 1982.0, "text": " Would that be what you're talking about there? Yeah.", "tokens": [6068, 300, 312, 437, 291, 434, 1417, 466, 456, 30, 865, 13], "temperature": 0.0, "avg_logprob": -0.24175831367229594, "compression_ratio": 1.0459770114942528, "no_speech_prob": 8.887791045708582e-05}, {"id": 194, "seek": 198200, "start": 1982.0, "end": 2011.0, "text": " Potentially type inference, potentially other kinds of information. And we were Elm review shines is because it's not just a specification on how you can extract certain AST notes or specific information from ASTs. But it's a, it's like, it's literally code, you can put all those contexts into, you can find all those things.", "tokens": [9145, 3137, 2010, 38253, 11, 7263, 661, 3685, 295, 1589, 13, 400, 321, 645, 2699, 76, 3131, 28056, 307, 570, 309, 311, 406, 445, 257, 31256, 322, 577, 291, 393, 8947, 1629, 316, 6840, 5570, 420, 2685, 1589, 490, 316, 6840, 82, 13, 583, 309, 311, 257, 11, 309, 311, 411, 11, 309, 311, 3736, 3089, 11, 291, 393, 829, 439, 729, 30628, 666, 11, 291, 393, 915, 439, 729, 721, 13], "temperature": 0.0, "avg_logprob": -0.37223630202443975, "compression_ratio": 1.6464646464646464, "no_speech_prob": 3.2696978450985625e-05}, {"id": 195, "seek": 201100, "start": 2011.0, "end": 2039.0, "text": " You can find connections between those contexts. So for instance, if you want to detect unused variables, you need to connect all the declarations of variables with usages of the variables. If you just try to pattern match on a nodes individually, you're not going to be able to do that, you're going to have to write an external system, internal external things to be able to deduct that, to deduce that.", "tokens": [509, 393, 915, 9271, 1296, 729, 30628, 13, 407, 337, 5197, 11, 498, 291, 528, 281, 5531, 44383, 9102, 11, 291, 643, 281, 1745, 439, 264, 16694, 763, 295, 9102, 365, 505, 1660, 295, 264, 9102, 13, 759, 291, 445, 853, 281, 5102, 2995, 322, 257, 13891, 16652, 11, 291, 434, 406, 516, 281, 312, 1075, 281, 360, 300, 11, 291, 434, 516, 281, 362, 281, 2464, 364, 8320, 1185, 11, 6920, 8320, 721, 281, 312, 1075, 281, 31513, 300, 11, 281, 4172, 4176, 300, 13], "temperature": 0.0, "avg_logprob": -0.24033448961046006, "compression_ratio": 1.8, "no_speech_prob": 0.0001253355439985171}, {"id": 196, "seek": 203900, "start": 2039.0, "end": 2046.0, "text": " So that's, I think where Elm review is really powerful is it allows you to put those things into context.", "tokens": [407, 300, 311, 11, 286, 519, 689, 2699, 76, 3131, 307, 534, 4005, 307, 309, 4045, 291, 281, 829, 729, 721, 666, 4319, 13], "temperature": 0.0, "avg_logprob": -0.23557709075592376, "compression_ratio": 1.4755555555555555, "no_speech_prob": 7.602246478199959e-05}, {"id": 197, "seek": 203900, "start": 2046.0, "end": 2052.0, "text": " Right. It sounds kind of like, you know, should I use a reg X or a parser for this?", "tokens": [1779, 13, 467, 3263, 733, 295, 411, 11, 291, 458, 11, 820, 286, 764, 257, 1121, 1783, 420, 257, 21156, 260, 337, 341, 30], "temperature": 0.0, "avg_logprob": -0.23557709075592376, "compression_ratio": 1.4755555555555555, "no_speech_prob": 7.602246478199959e-05}, {"id": 198, "seek": 203900, "start": 2052.0, "end": 2053.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.23557709075592376, "compression_ratio": 1.4755555555555555, "no_speech_prob": 7.602246478199959e-05}, {"id": 199, "seek": 203900, "start": 2053.0, "end": 2062.0, "text": " And if you're trying to like extract semantic information from HTML, then reg X, you're going to have a bad time with because, you know.", "tokens": [400, 498, 291, 434, 1382, 281, 411, 8947, 47982, 1589, 490, 17995, 11, 550, 1121, 1783, 11, 291, 434, 516, 281, 362, 257, 1578, 565, 365, 570, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.23557709075592376, "compression_ratio": 1.4755555555555555, "no_speech_prob": 7.602246478199959e-05}, {"id": 200, "seek": 206200, "start": 2062.0, "end": 2077.0, "text": " Yeah. But in some cases, like, especially if it's for a quick and dirty thing, grep will be very good. Combi will be very good as well. TreeGrepper, I'm guessing as well. It's probably the same thing, the syntax I'm just not familiar with.", "tokens": [865, 13, 583, 294, 512, 3331, 11, 411, 11, 2318, 498, 309, 311, 337, 257, 1702, 293, 9360, 551, 11, 6066, 79, 486, 312, 588, 665, 13, 2432, 5614, 486, 312, 588, 665, 382, 731, 13, 22291, 38, 265, 3717, 11, 286, 478, 17939, 382, 731, 13, 467, 311, 1391, 264, 912, 551, 11, 264, 28431, 286, 478, 445, 406, 4963, 365, 13], "temperature": 0.0, "avg_logprob": -0.24973562122446247, "compression_ratio": 1.804, "no_speech_prob": 2.0144936570432037e-05}, {"id": 201, "seek": 206200, "start": 2077.0, "end": 2090.0, "text": " But if you need something that will need to be correct or something that needs to be used a lot of times, something where you need less false positives or less false negatives, then Elm review will be very good.", "tokens": [583, 498, 291, 643, 746, 300, 486, 643, 281, 312, 3006, 420, 746, 300, 2203, 281, 312, 1143, 257, 688, 295, 1413, 11, 746, 689, 291, 643, 1570, 7908, 35127, 420, 1570, 7908, 40019, 11, 550, 2699, 76, 3131, 486, 312, 588, 665, 13], "temperature": 0.0, "avg_logprob": -0.24973562122446247, "compression_ratio": 1.804, "no_speech_prob": 2.0144936570432037e-05}, {"id": 202, "seek": 209000, "start": 2090.0, "end": 2100.0, "text": " That said, in a lot of cases, like depending on what information you want to get, you will not be able to get it. Like a static analysis tool is sometimes limited, right?", "tokens": [663, 848, 11, 294, 257, 688, 295, 3331, 11, 411, 5413, 322, 437, 1589, 291, 528, 281, 483, 11, 291, 486, 406, 312, 1075, 281, 483, 309, 13, 1743, 257, 13437, 5215, 2290, 307, 2171, 5567, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.21246422254122221, "compression_ratio": 1.3785714285714286, "no_speech_prob": 1.2411143870849628e-05}, {"id": 203, "seek": 209000, "start": 2100.0, "end": 2101.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.21246422254122221, "compression_ratio": 1.3785714285714286, "no_speech_prob": 1.2411143870849628e-05}, {"id": 204, "seek": 209000, "start": 2101.0, "end": 2103.0, "text": " Dynamic values.", "tokens": [45440, 4190, 13], "temperature": 0.0, "avg_logprob": -0.21246422254122221, "compression_ratio": 1.3785714285714286, "no_speech_prob": 1.2411143870849628e-05}, {"id": 205, "seek": 210300, "start": 2103.0, "end": 2123.0, "text": " There are certain things that Elm review makes very high level that would be a ton of work to gather manually. For example, like extracting information about the direct dependencies of a project, which I was trying to do for my particular use case with this kind of AI prompting context builder.", "tokens": [821, 366, 1629, 721, 300, 2699, 76, 3131, 1669, 588, 1090, 1496, 300, 576, 312, 257, 2952, 295, 589, 281, 5448, 16945, 13, 1171, 1365, 11, 411, 49844, 1589, 466, 264, 2047, 36606, 295, 257, 1716, 11, 597, 286, 390, 1382, 281, 360, 337, 452, 1729, 764, 1389, 365, 341, 733, 295, 7318, 12391, 278, 4319, 27377, 13], "temperature": 0.0, "avg_logprob": -0.19074284645818895, "compression_ratio": 1.4390243902439024, "no_speech_prob": 7.368182559730485e-05}, {"id": 206, "seek": 212300, "start": 2123.0, "end": 2139.0, "text": " You provide like a fairly high level API where that information exists somewhere on the file system. You might even have to like run Elm make on something to like make that come into existence somewhere.", "tokens": [509, 2893, 411, 257, 6457, 1090, 1496, 9362, 689, 300, 1589, 8198, 4079, 322, 264, 3991, 1185, 13, 509, 1062, 754, 362, 281, 411, 1190, 2699, 76, 652, 322, 746, 281, 411, 652, 300, 808, 666, 9123, 4079, 13], "temperature": 0.0, "avg_logprob": -0.19675671564389582, "compression_ratio": 1.635, "no_speech_prob": 3.071630635531619e-05}, {"id": 207, "seek": 212300, "start": 2139.0, "end": 2148.0, "text": " I actually download everything manually. I look at the Elm home and if it's there, I use that. Otherwise I download things.", "tokens": [286, 767, 5484, 1203, 16945, 13, 286, 574, 412, 264, 2699, 76, 1280, 293, 498, 309, 311, 456, 11, 286, 764, 300, 13, 10328, 286, 5484, 721, 13], "temperature": 0.0, "avg_logprob": -0.19675671564389582, "compression_ratio": 1.635, "no_speech_prob": 3.071630635531619e-05}, {"id": 208, "seek": 214800, "start": 2148.0, "end": 2168.0, "text": " Right. So if you're building a quick and dirty script, it's not going to be quick, but it will be dirty if you try to get that information yourself. Whereas if you use Elm review, you just get like a nice Elm type that describes the direct dependencies and all of the types and values it exposes.", "tokens": [1779, 13, 407, 498, 291, 434, 2390, 257, 1702, 293, 9360, 5755, 11, 309, 311, 406, 516, 281, 312, 1702, 11, 457, 309, 486, 312, 9360, 498, 291, 853, 281, 483, 300, 1589, 1803, 13, 13813, 498, 291, 764, 2699, 76, 3131, 11, 291, 445, 483, 411, 257, 1481, 2699, 76, 2010, 300, 15626, 264, 2047, 36606, 293, 439, 295, 264, 3467, 293, 4190, 309, 1278, 4201, 13], "temperature": 0.0, "avg_logprob": -0.15821186701456705, "compression_ratio": 1.549738219895288, "no_speech_prob": 7.966876728460193e-05}, {"id": 209, "seek": 216800, "start": 2168.0, "end": 2183.0, "text": " So that's pretty powerful. Like the one thing I see that's definitely a little tricky is like Elm review rules are not super composable. Like visitors, it's hard to like bundle up visitors together.", "tokens": [407, 300, 311, 1238, 4005, 13, 1743, 264, 472, 551, 286, 536, 300, 311, 2138, 257, 707, 12414, 307, 411, 2699, 76, 3131, 4474, 366, 406, 1687, 10199, 712, 13, 1743, 14315, 11, 309, 311, 1152, 281, 411, 24438, 493, 14315, 1214, 13], "temperature": 0.0, "avg_logprob": -0.20645756417132438, "compression_ratio": 1.375, "no_speech_prob": 7.601924880873412e-05}, {"id": 210, "seek": 218300, "start": 2183.0, "end": 2203.0, "text": " You sort of have to say like, okay, this visitor is going to go and update the context by looking at imports and this visitor is going to update it. But you can't really have a self-contained like, all right, here's my Elm review thing that does like five different types of visitors.", "tokens": [509, 1333, 295, 362, 281, 584, 411, 11, 1392, 11, 341, 28222, 307, 516, 281, 352, 293, 5623, 264, 4319, 538, 1237, 412, 41596, 293, 341, 28222, 307, 516, 281, 5623, 309, 13, 583, 291, 393, 380, 534, 362, 257, 2698, 12, 9000, 3563, 411, 11, 439, 558, 11, 510, 311, 452, 2699, 76, 3131, 551, 300, 775, 411, 1732, 819, 3467, 295, 14315, 13], "temperature": 0.0, "avg_logprob": -0.18393184827721637, "compression_ratio": 1.5777777777777777, "no_speech_prob": 1.3630940884468146e-05}, {"id": 211, "seek": 220300, "start": 2203.0, "end": 2217.0, "text": " And it gives you, you can't have like nested T, nested Elm architecture, review visitors. That's like a combined visitor that somebody published as a helper.", "tokens": [400, 309, 2709, 291, 11, 291, 393, 380, 362, 411, 15646, 292, 314, 11, 15646, 292, 2699, 76, 9482, 11, 3131, 14315, 13, 663, 311, 411, 257, 9354, 28222, 300, 2618, 6572, 382, 257, 36133, 13], "temperature": 0.0, "avg_logprob": -0.18040664268262457, "compression_ratio": 1.3647798742138364, "no_speech_prob": 4.860376975557301e-06}, {"id": 212, "seek": 220300, "start": 2217.0, "end": 2219.0, "text": " Actually, you can.", "tokens": [5135, 11, 291, 393, 13], "temperature": 0.0, "avg_logprob": -0.18040664268262457, "compression_ratio": 1.3647798742138364, "no_speech_prob": 4.860376975557301e-06}, {"id": 213, "seek": 220300, "start": 2219.0, "end": 2220.0, "text": " Can you really?", "tokens": [1664, 291, 534, 30], "temperature": 0.0, "avg_logprob": -0.18040664268262457, "compression_ratio": 1.3647798742138364, "no_speech_prob": 4.860376975557301e-06}, {"id": 214, "seek": 220300, "start": 2220.0, "end": 2221.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.18040664268262457, "compression_ratio": 1.3647798742138364, "no_speech_prob": 4.860376975557301e-06}, {"id": 215, "seek": 220300, "start": 2221.0, "end": 2223.0, "text": " Oh, I had no idea.", "tokens": [876, 11, 286, 632, 572, 1558, 13], "temperature": 0.0, "avg_logprob": -0.18040664268262457, "compression_ratio": 1.3647798742138364, "no_speech_prob": 4.860376975557301e-06}, {"id": 216, "seek": 222300, "start": 2223.0, "end": 2237.0, "text": " Not in the shape that you think. The thing that is possible is you can add multiple visitors of the same type. So you can have multiple with expression visitor, multiple with declaration visitors.", "tokens": [1726, 294, 264, 3909, 300, 291, 519, 13, 440, 551, 300, 307, 1944, 307, 291, 393, 909, 3866, 14315, 295, 264, 912, 2010, 13, 407, 291, 393, 362, 3866, 365, 6114, 28222, 11, 3866, 365, 27606, 14315, 13], "temperature": 0.0, "avg_logprob": -0.2534253286278766, "compression_ratio": 1.573643410852713, "no_speech_prob": 8.664591405249666e-06}, {"id": 217, "seek": 222300, "start": 2237.0, "end": 2238.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.2534253286278766, "compression_ratio": 1.573643410852713, "no_speech_prob": 8.664591405249666e-06}, {"id": 218, "seek": 223800, "start": 2238.0, "end": 2253.0, "text": " The module name lookup table, which you mentioned before is a basically Elm review pre-computes for every node in your AST where something was defined.", "tokens": [440, 10088, 1315, 574, 1010, 3199, 11, 597, 291, 2835, 949, 307, 257, 1936, 2699, 76, 3131, 659, 12, 21541, 1819, 337, 633, 9984, 294, 428, 316, 6840, 689, 746, 390, 7642, 13], "temperature": 0.0, "avg_logprob": -0.30115563160664327, "compression_ratio": 1.2276422764227641, "no_speech_prob": 5.0146122703154106e-06}, {"id": 219, "seek": 225300, "start": 2253.0, "end": 2273.0, "text": " So if you have a function, is it defined in an import, in a module? And if so, which one or is it defined locally? That was not in Elm review to start with. That was actually in a package that I purposefully did not publish for maintenance reasons.", "tokens": [407, 498, 291, 362, 257, 2445, 11, 307, 309, 7642, 294, 364, 974, 11, 294, 257, 10088, 30, 400, 498, 370, 11, 597, 472, 420, 307, 309, 7642, 16143, 30, 663, 390, 406, 294, 2699, 76, 3131, 281, 722, 365, 13, 663, 390, 767, 294, 257, 7372, 300, 286, 4334, 2277, 630, 406, 11374, 337, 11258, 4112, 13], "temperature": 0.0, "avg_logprob": -0.2276716539936681, "compression_ratio": 1.4588235294117646, "no_speech_prob": 1.4367175253937603e-06}, {"id": 220, "seek": 227300, "start": 2273.0, "end": 2286.0, "text": " But you could basically copy paste that code and just add a function that says add visitors for scope. I think it was scope dots, add visitors, something.", "tokens": [583, 291, 727, 1936, 5055, 9163, 300, 3089, 293, 445, 909, 257, 2445, 300, 1619, 909, 14315, 337, 11923, 13, 286, 519, 309, 390, 11923, 15026, 11, 909, 14315, 11, 746, 13], "temperature": 0.0, "avg_logprob": -0.28882837295532227, "compression_ratio": 1.3628318584070795, "no_speech_prob": 2.2252381768339546e-06}, {"id": 221, "seek": 228600, "start": 2286.0, "end": 2303.0, "text": " And that added all the visitors that that sub rule, sub information gathering thing needed to modify your context. Like it was specifically modifying one field in your context.", "tokens": [400, 300, 3869, 439, 264, 14315, 300, 300, 1422, 4978, 11, 1422, 1589, 13519, 551, 2978, 281, 16927, 428, 4319, 13, 1743, 309, 390, 4682, 42626, 472, 2519, 294, 428, 4319, 13], "temperature": 0.0, "avg_logprob": -0.3133321338229709, "compression_ratio": 1.4308943089430894, "no_speech_prob": 3.844773345917929e-06}, {"id": 222, "seek": 230300, "start": 2303.0, "end": 2316.0, "text": " And then that was available to all the other rules, to all the other visitors. So it is possible. It's just not in the way you want to. And in practice, it's not done very often.", "tokens": [400, 550, 300, 390, 2435, 281, 439, 264, 661, 4474, 11, 281, 439, 264, 661, 14315, 13, 407, 309, 307, 1944, 13, 467, 311, 445, 406, 294, 264, 636, 291, 528, 281, 13, 400, 294, 3124, 11, 309, 311, 406, 1096, 588, 2049, 13], "temperature": 0.0, "avg_logprob": -0.22717287143071493, "compression_ratio": 1.390625, "no_speech_prob": 1.5205964700726327e-05}, {"id": 223, "seek": 231600, "start": 2316.0, "end": 2333.0, "text": " Like I've basically only use it for that purpose and I quite liked it. So it's still feature that is not very well documented. And also like I'm thinking about removing it because like things are slightly faster if they're not a list of visitors.", "tokens": [1743, 286, 600, 1936, 787, 764, 309, 337, 300, 4334, 293, 286, 1596, 4501, 309, 13, 407, 309, 311, 920, 4111, 300, 307, 406, 588, 731, 23007, 13, 400, 611, 411, 286, 478, 1953, 466, 12720, 309, 570, 411, 721, 366, 4748, 4663, 498, 436, 434, 406, 257, 1329, 295, 14315, 13], "temperature": 0.0, "avg_logprob": -0.26382514408656527, "compression_ratio": 1.4470588235294117, "no_speech_prob": 8.0125464592129e-06}, {"id": 224, "seek": 233300, "start": 2333.0, "end": 2353.0, "text": " Like maybe visitor under the hood, but it is possible and it is a nice feature when it's necessary. Would that allow you to, you probably wouldn't have access to that, like prepared finished context by the time your visitors run?", "tokens": [1743, 1310, 28222, 833, 264, 13376, 11, 457, 309, 307, 1944, 293, 309, 307, 257, 1481, 4111, 562, 309, 311, 4818, 13, 6068, 300, 2089, 291, 281, 11, 291, 1391, 2759, 380, 362, 2105, 281, 300, 11, 411, 4927, 4335, 4319, 538, 264, 565, 428, 14315, 1190, 30], "temperature": 0.0, "avg_logprob": -0.2870159332568829, "compression_ratio": 1.4135802469135803, "no_speech_prob": 1.2029159734083805e-05}, {"id": 225, "seek": 235300, "start": 2353.0, "end": 2363.0, "text": " Or could you, could you make sure that those visitors all run before your visitors subsequently run so they have access to that context?", "tokens": [1610, 727, 291, 11, 727, 291, 652, 988, 300, 729, 14315, 439, 1190, 949, 428, 14315, 26514, 1190, 370, 436, 362, 2105, 281, 300, 4319, 30], "temperature": 0.0, "avg_logprob": -0.28117731094360354, "compression_ratio": 1.3916083916083917, "no_speech_prob": 2.0460118321352638e-05}, {"id": 226, "seek": 235300, "start": 2363.0, "end": 2365.0, "text": " Yeah, yeah.", "tokens": [865, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.28117731094360354, "compression_ratio": 1.3916083916083917, "no_speech_prob": 2.0460118321352638e-05}, {"id": 227, "seek": 235300, "start": 2365.0, "end": 2370.0, "text": " Okay. Yeah. And that's very powerful. Interesting.", "tokens": [1033, 13, 865, 13, 400, 300, 311, 588, 4005, 13, 14711, 13], "temperature": 0.0, "avg_logprob": -0.28117731094360354, "compression_ratio": 1.3916083916083917, "no_speech_prob": 2.0460118321352638e-05}, {"id": 228, "seek": 237000, "start": 2370.0, "end": 2386.0, "text": " Yeah. It's depends on what you want to do, but yeah, potentially all those, those rules can do whatever they want to. Those, sorry, those helpers can gather all the information you need. But depending on the information, that will be more or less easy, but usually it's pretty easy.", "tokens": [865, 13, 467, 311, 5946, 322, 437, 291, 528, 281, 360, 11, 457, 1338, 11, 7263, 439, 729, 11, 729, 4474, 393, 360, 2035, 436, 528, 281, 13, 3950, 11, 2597, 11, 729, 854, 433, 393, 5448, 439, 264, 1589, 291, 643, 13, 583, 5413, 322, 264, 1589, 11, 300, 486, 312, 544, 420, 1570, 1858, 11, 457, 2673, 309, 311, 1238, 1858, 13], "temperature": 0.0, "avg_logprob": -0.2743571599324544, "compression_ratio": 1.6355555555555557, "no_speech_prob": 3.3930384688574122e-06}, {"id": 229, "seek": 237000, "start": 2386.0, "end": 2388.0, "text": " Hmm. Interesting.", "tokens": [8239, 13, 14711, 13], "temperature": 0.0, "avg_logprob": -0.2743571599324544, "compression_ratio": 1.6355555555555557, "no_speech_prob": 3.3930384688574122e-06}, {"id": 230, "seek": 237000, "start": 2388.0, "end": 2391.0, "text": " Because they're running in a specific order, which makes that easy.", "tokens": [1436, 436, 434, 2614, 294, 257, 2685, 1668, 11, 597, 1669, 300, 1858, 13], "temperature": 0.0, "avg_logprob": -0.2743571599324544, "compression_ratio": 1.6355555555555557, "no_speech_prob": 3.3930384688574122e-06}, {"id": 231, "seek": 239100, "start": 2391.0, "end": 2409.0, "text": " That's pretty cool. I would love to see like people sharing the cool stuff that they build with this. And like, I don't know, maybe we should host a, an ElmReview extractor hackathon Jeroen to get, because there's so much cool stuff you could build with this functionality.", "tokens": [663, 311, 1238, 1627, 13, 286, 576, 959, 281, 536, 411, 561, 5414, 264, 1627, 1507, 300, 436, 1322, 365, 341, 13, 400, 411, 11, 286, 500, 380, 458, 11, 1310, 321, 820, 3975, 257, 11, 364, 2699, 76, 8524, 1759, 8947, 284, 10339, 18660, 508, 2032, 268, 281, 483, 11, 570, 456, 311, 370, 709, 1627, 1507, 291, 727, 1322, 365, 341, 14980, 13], "temperature": 0.0, "avg_logprob": -0.20588818149290222, "compression_ratio": 1.4756756756756757, "no_speech_prob": 1.5205168892862275e-05}, {"id": 232, "seek": 240900, "start": 2409.0, "end": 2425.0, "text": " Yeah. So the main thing that I was thinking about, like that could be pretty, that is pretty generic and it could be useful is like extracting metrics out of your code base. So lines of code is the easy one, which there are many powerful tools for that.", "tokens": [865, 13, 407, 264, 2135, 551, 300, 286, 390, 1953, 466, 11, 411, 300, 727, 312, 1238, 11, 300, 307, 1238, 19577, 293, 309, 727, 312, 4420, 307, 411, 49844, 16367, 484, 295, 428, 3089, 3096, 13, 407, 3876, 295, 3089, 307, 264, 1858, 472, 11, 597, 456, 366, 867, 4005, 3873, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.2531309612726761, "compression_ratio": 1.5333333333333334, "no_speech_prob": 2.4679173293407075e-05}, {"id": 233, "seek": 242500, "start": 2425.0, "end": 2440.0, "text": " There's just simple, the WC command line tool, there's clock and there's plenty of others, I'm sure. So maybe that's not the best metric, but that's the kind of idea that you could do.", "tokens": [821, 311, 445, 2199, 11, 264, 343, 34, 5622, 1622, 2290, 11, 456, 311, 7830, 293, 456, 311, 7140, 295, 2357, 11, 286, 478, 988, 13, 407, 1310, 300, 311, 406, 264, 1151, 20678, 11, 457, 300, 311, 264, 733, 295, 1558, 300, 291, 727, 360, 13], "temperature": 0.0, "avg_logprob": -0.1998761681949391, "compression_ratio": 1.3834586466165413, "no_speech_prob": 2.2826165150036104e-05}, {"id": 234, "seek": 244000, "start": 2440.0, "end": 2458.0, "text": " At the moment, one of my colleagues is I think working on computing the complexity of the code base. So there's the cognitive complexity, which I made a rule for. I think he will probably try that first, which by the way, there's now a data extractor, I think.", "tokens": [1711, 264, 1623, 11, 472, 295, 452, 7734, 307, 286, 519, 1364, 322, 15866, 264, 14024, 295, 264, 3089, 3096, 13, 407, 456, 311, 264, 15605, 14024, 11, 597, 286, 1027, 257, 4978, 337, 13, 286, 519, 415, 486, 1391, 853, 300, 700, 11, 597, 538, 264, 636, 11, 456, 311, 586, 257, 1412, 8947, 284, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.2110256728004007, "compression_ratio": 1.5375722543352601, "no_speech_prob": 5.86078931519296e-06}, {"id": 235, "seek": 244000, "start": 2458.0, "end": 2459.0, "text": " Cool.", "tokens": [8561, 13], "temperature": 0.0, "avg_logprob": -0.2110256728004007, "compression_ratio": 1.5375722543352601, "no_speech_prob": 5.86078931519296e-06}, {"id": 236, "seek": 245900, "start": 2459.0, "end": 2474.0, "text": " Somewhere, maybe in a branch of mine, maybe it's just on my computer. I think, at least it would be very easy to make it. That's for sure. Because it's just extracting the context to JSON.", "tokens": [34500, 11, 1310, 294, 257, 9819, 295, 3892, 11, 1310, 309, 311, 445, 322, 452, 3820, 13, 286, 519, 11, 412, 1935, 309, 576, 312, 588, 1858, 281, 652, 309, 13, 663, 311, 337, 988, 13, 1436, 309, 311, 445, 49844, 264, 4319, 281, 31828, 13], "temperature": 0.0, "avg_logprob": -0.23556646347045898, "compression_ratio": 1.3428571428571427, "no_speech_prob": 5.560376666835509e-05}, {"id": 237, "seek": 247400, "start": 2474.0, "end": 2496.0, "text": " But yeah, there's also cyclomatic complexity, which is basically a measure of how many unit tests would you need to cover all the branches for a given function. And that's a reasonable metric, not to tell you how to refactor your code.", "tokens": [583, 1338, 11, 456, 311, 611, 19474, 13143, 14024, 11, 597, 307, 1936, 257, 3481, 295, 577, 867, 4985, 6921, 576, 291, 643, 281, 2060, 439, 264, 14770, 337, 257, 2212, 2445, 13, 400, 300, 311, 257, 10585, 20678, 11, 406, 281, 980, 291, 577, 281, 1895, 15104, 428, 3089, 13], "temperature": 0.0, "avg_logprob": -0.19797883467240768, "compression_ratio": 1.4242424242424243, "no_speech_prob": 3.120067412965e-05}, {"id": 238, "seek": 249600, "start": 2496.0, "end": 2511.0, "text": " Cognitive complexity is better for that. But cyclomatic does tell you, well, this code is pretty complex, or this project is pretty complex, because there's a lot of edge cases that it needs to handle.", "tokens": [383, 2912, 2187, 14024, 307, 1101, 337, 300, 13, 583, 19474, 13143, 775, 980, 291, 11, 731, 11, 341, 3089, 307, 1238, 3997, 11, 420, 341, 1716, 307, 1238, 3997, 11, 570, 456, 311, 257, 688, 295, 4691, 3331, 300, 309, 2203, 281, 4813, 13], "temperature": 0.0, "avg_logprob": -0.2142895679084622, "compression_ratio": 1.467153284671533, "no_speech_prob": 4.133288166485727e-05}, {"id": 239, "seek": 251100, "start": 2511.0, "end": 2532.0, "text": " And you could make a graph out of that. So at LogScale, we're a log product, we just send all of our logs to LogScale, and then we can make dashboards with it. And when we run Elm Review in our CI, well, we have those metrics available.", "tokens": [400, 291, 727, 652, 257, 4295, 484, 295, 300, 13, 407, 412, 10824, 16806, 1220, 11, 321, 434, 257, 3565, 1674, 11, 321, 445, 2845, 439, 295, 527, 20820, 281, 10824, 16806, 1220, 11, 293, 550, 321, 393, 652, 8240, 17228, 365, 309, 13, 400, 562, 321, 1190, 2699, 76, 19954, 294, 527, 37777, 11, 731, 11, 321, 362, 729, 16367, 2435, 13], "temperature": 0.0, "avg_logprob": -0.2552341631988981, "compression_ratio": 1.4390243902439024, "no_speech_prob": 1.2411148418323137e-05}, {"id": 240, "seek": 253200, "start": 2532.0, "end": 2544.0, "text": " Well, we can run Elm Review with dash dash extracts, dash dash report JSON. And that gives us metrics. And then we can extract those and try to make dashboards out of it.", "tokens": [1042, 11, 321, 393, 1190, 2699, 76, 19954, 365, 8240, 8240, 8947, 82, 11, 8240, 8240, 2275, 31828, 13, 400, 300, 2709, 505, 16367, 13, 400, 550, 321, 393, 8947, 729, 293, 853, 281, 652, 8240, 17228, 484, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.22289729648166232, "compression_ratio": 1.3492063492063493, "no_speech_prob": 4.83240291941911e-05}, {"id": 241, "seek": 254400, "start": 2544.0, "end": 2563.0, "text": " And yeah, then whatever metrics you think are useful to you. Like, this is an area where I'm not all that familiar with, like what metrics are interesting to gather for a technical depth finding platform or something.", "tokens": [400, 1338, 11, 550, 2035, 16367, 291, 519, 366, 4420, 281, 291, 13, 1743, 11, 341, 307, 364, 1859, 689, 286, 478, 406, 439, 300, 4963, 365, 11, 411, 437, 16367, 366, 1880, 281, 5448, 337, 257, 6191, 7161, 5006, 3663, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.2226322889328003, "compression_ratio": 1.4276315789473684, "no_speech_prob": 2.35514289670391e-05}, {"id": 242, "seek": 256300, "start": 2563.0, "end": 2576.0, "text": " There's a tool called CodeScene, where they basically gather a lot of this information, like notably the complexity, but also like the get information from your code base.", "tokens": [821, 311, 257, 2290, 1219, 15549, 16806, 1450, 11, 689, 436, 1936, 5448, 257, 688, 295, 341, 1589, 11, 411, 31357, 264, 14024, 11, 457, 611, 411, 264, 483, 1589, 490, 428, 3089, 3096, 13], "temperature": 0.0, "avg_logprob": -0.2444617687127529, "compression_ratio": 1.3571428571428572, "no_speech_prob": 7.254107913468033e-05}, {"id": 243, "seek": 257600, "start": 2576.0, "end": 2596.0, "text": " And they say, well, the files that are most that are touched the most often are usually the ones with bugs. And we can try to combine the information of how often is something touched and how complex is the the file in terms of cyclomatic complexity.", "tokens": [400, 436, 584, 11, 731, 11, 264, 7098, 300, 366, 881, 300, 366, 9828, 264, 881, 2049, 366, 2673, 264, 2306, 365, 15120, 13, 400, 321, 393, 853, 281, 10432, 264, 1589, 295, 577, 2049, 307, 746, 9828, 293, 577, 3997, 307, 264, 264, 3991, 294, 2115, 295, 19474, 13143, 14024, 13], "temperature": 0.0, "avg_logprob": -0.21913585034045543, "compression_ratio": 1.7244444444444444, "no_speech_prob": 1.4738462596142199e-05}, {"id": 244, "seek": 257600, "start": 2596.0, "end": 2605.0, "text": " And you could say, well, this is probably where we need to address technical debt, or this is where it'd be useful to to put our eyes on.", "tokens": [400, 291, 727, 584, 11, 731, 11, 341, 307, 1391, 689, 321, 643, 281, 2985, 6191, 7831, 11, 420, 341, 307, 689, 309, 1116, 312, 4420, 281, 281, 829, 527, 2575, 322, 13], "temperature": 0.0, "avg_logprob": -0.21913585034045543, "compression_ratio": 1.7244444444444444, "no_speech_prob": 1.4738462596142199e-05}, {"id": 245, "seek": 260500, "start": 2605.0, "end": 2611.0, "text": " Yeah, exactly. I mean, you could even just extract the length of certain functions.", "tokens": [865, 11, 2293, 13, 286, 914, 11, 291, 727, 754, 445, 8947, 264, 4641, 295, 1629, 6828, 13], "temperature": 0.0, "avg_logprob": -0.2215364477136633, "compression_ratio": 1.6343612334801763, "no_speech_prob": 2.4299753931700252e-05}, {"id": 246, "seek": 260500, "start": 2611.0, "end": 2629.0, "text": " Yeah, as a for instance, yeah. So Elm Review does not have access to get information. But it does have access to a lot of other information. And I think at some point, you will, I will just make it available to you to extract information from arbitrary files in your project.", "tokens": [865, 11, 382, 257, 337, 5197, 11, 1338, 13, 407, 2699, 76, 19954, 775, 406, 362, 2105, 281, 483, 1589, 13, 583, 309, 775, 362, 2105, 281, 257, 688, 295, 661, 1589, 13, 400, 286, 519, 412, 512, 935, 11, 291, 486, 11, 286, 486, 445, 652, 309, 2435, 281, 291, 281, 8947, 1589, 490, 23211, 7098, 294, 428, 1716, 13], "temperature": 0.0, "avg_logprob": -0.2215364477136633, "compression_ratio": 1.6343612334801763, "no_speech_prob": 2.4299753931700252e-05}, {"id": 247, "seek": 260500, "start": 2629.0, "end": 2631.0, "text": " Yeah, cool.", "tokens": [865, 11, 1627, 13], "temperature": 0.0, "avg_logprob": -0.2215364477136633, "compression_ratio": 1.6343612334801763, "no_speech_prob": 2.4299753931700252e-05}, {"id": 248, "seek": 263100, "start": 2631.0, "end": 2646.0, "text": " Like just trying to be able to read CSS files, and figure out which CSS files or which CSS classes are available or unused, even. That'd be useful, I think. So that's, that's the idea behind that thing.", "tokens": [1743, 445, 1382, 281, 312, 1075, 281, 1401, 24387, 7098, 11, 293, 2573, 484, 597, 24387, 7098, 420, 597, 24387, 5359, 366, 2435, 420, 44383, 11, 754, 13, 663, 1116, 312, 4420, 11, 286, 519, 13, 407, 300, 311, 11, 300, 311, 264, 1558, 2261, 300, 551, 13], "temperature": 0.0, "avg_logprob": -0.25523701080909145, "compression_ratio": 1.4326241134751774, "no_speech_prob": 9.914644033415243e-05}, {"id": 249, "seek": 264600, "start": 2646.0, "end": 2663.0, "text": " Yeah, it's super powerful. Yeah, I mean, and you can start piecing these ideas together, you know, you start gathering metrics. I mean, you know, what metrics can you gather from a code base number of lines number of number of non opaque types, perhaps?", "tokens": [865, 11, 309, 311, 1687, 4005, 13, 865, 11, 286, 914, 11, 293, 291, 393, 722, 1730, 2175, 613, 3487, 1214, 11, 291, 458, 11, 291, 722, 13519, 16367, 13, 286, 914, 11, 291, 458, 11, 437, 16367, 393, 291, 5448, 490, 257, 3089, 3096, 1230, 295, 3876, 1230, 295, 1230, 295, 2107, 42687, 3467, 11, 4317, 30], "temperature": 0.0, "avg_logprob": -0.2210888708791425, "compression_ratio": 1.6012658227848102, "no_speech_prob": 4.6377122089324985e-06}, {"id": 250, "seek": 266300, "start": 2663.0, "end": 2685.0, "text": " Potentially, yeah. Like, I don't know if there are metrics for noticing like how coupled something is, a couple of one module to another is to another. But if there's those things, and potentially that there's a thing that you could put it on a dashboard and try to follow and try to reduce or try to increase, I don't know.", "tokens": [9145, 3137, 11, 1338, 13, 1743, 11, 286, 500, 380, 458, 498, 456, 366, 16367, 337, 21814, 411, 577, 29482, 746, 307, 11, 257, 1916, 295, 472, 10088, 281, 1071, 307, 281, 1071, 13, 583, 498, 456, 311, 729, 721, 11, 293, 7263, 300, 456, 311, 257, 551, 300, 291, 727, 829, 309, 322, 257, 18342, 293, 853, 281, 1524, 293, 853, 281, 5407, 420, 853, 281, 3488, 11, 286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.26732771467454364, "compression_ratio": 1.7245762711864407, "no_speech_prob": 1.9525383322616108e-05}, {"id": 251, "seek": 266300, "start": 2685.0, "end": 2689.0, "text": " Test coverage, but yeah, that's not Elm Review. There's a different tool for that.", "tokens": [9279, 9645, 11, 457, 1338, 11, 300, 311, 406, 2699, 76, 19954, 13, 821, 311, 257, 819, 2290, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.26732771467454364, "compression_ratio": 1.7245762711864407, "no_speech_prob": 1.9525383322616108e-05}, {"id": 252, "seek": 268900, "start": 2689.0, "end": 2714.0, "text": " Yeah, yeah. And yeah, and there is Elm coverage, which actually works pretty darn well. But, but yeah, like, look for things like, you know, checking if something is not an opaque type, like, as much as we would like for that to be a rule that just reports an error, error, non opaque type found, there are use cases where you want an exposed custom type.", "tokens": [865, 11, 1338, 13, 400, 1338, 11, 293, 456, 307, 2699, 76, 9645, 11, 597, 767, 1985, 1238, 29063, 731, 13, 583, 11, 457, 1338, 11, 411, 11, 574, 337, 721, 411, 11, 291, 458, 11, 8568, 498, 746, 307, 406, 364, 42687, 2010, 11, 411, 11, 382, 709, 382, 321, 576, 411, 337, 300, 281, 312, 257, 4978, 300, 445, 7122, 364, 6713, 11, 6713, 11, 2107, 42687, 2010, 1352, 11, 456, 366, 764, 3331, 689, 291, 528, 364, 9495, 2375, 2010, 13], "temperature": 0.0, "avg_logprob": -0.21191677180203525, "compression_ratio": 1.6359447004608294, "no_speech_prob": 0.0006070606759749353}, {"id": 253, "seek": 271400, "start": 2714.0, "end": 2733.0, "text": " And so it's, it's not a problem. It's a, it's a thing to be aware of. And so metrics, and visualizations and things like that are are useful. So that's the kind of area where extracting information rather than reporting an error is what you want.", "tokens": [400, 370, 309, 311, 11, 309, 311, 406, 257, 1154, 13, 467, 311, 257, 11, 309, 311, 257, 551, 281, 312, 3650, 295, 13, 400, 370, 16367, 11, 293, 5056, 14455, 293, 721, 411, 300, 366, 366, 4420, 13, 407, 300, 311, 264, 733, 295, 1859, 689, 49844, 1589, 2831, 813, 10031, 364, 6713, 307, 437, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.1750218224903894, "compression_ratio": 1.5, "no_speech_prob": 0.0003625722893048078}, {"id": 254, "seek": 273300, "start": 2733.0, "end": 2762.0, "text": " Yeah, like if your company or if your project has a specific use case of something that they'd like to increase or decrease or collect somehow, then you can make a rule for that. And you can extract the information and display it somewhere. But yeah, like this is really something that I have not looked into. And clearly, like, I don't know what metrics are useful. So if people want to play with that and know like, what could be useful, try it out and let me know.", "tokens": [865, 11, 411, 498, 428, 2237, 420, 498, 428, 1716, 575, 257, 2685, 764, 1389, 295, 746, 300, 436, 1116, 411, 281, 3488, 420, 11514, 420, 2500, 6063, 11, 550, 291, 393, 652, 257, 4978, 337, 300, 13, 400, 291, 393, 8947, 264, 1589, 293, 4674, 309, 4079, 13, 583, 1338, 11, 411, 341, 307, 534, 746, 300, 286, 362, 406, 2956, 666, 13, 400, 4448, 11, 411, 11, 286, 500, 380, 458, 437, 16367, 366, 4420, 13, 407, 498, 561, 528, 281, 862, 365, 300, 293, 458, 411, 11, 437, 727, 312, 4420, 11, 853, 309, 484, 293, 718, 385, 458, 13], "temperature": 0.0, "avg_logprob": -0.1971991886602384, "compression_ratio": 1.755639097744361, "no_speech_prob": 0.0006563163478858769}, {"id": 255, "seek": 276200, "start": 2762.0, "end": 2783.0, "text": " Yeah, I mean, you could really build like, a suite of Elm code quality tools and visualizations for it with this, you know, like, yeah, all the pieces are there. You could look at the number of maybes in a code base to write like, that's an interesting piece of information, like maybes aren't bad, but where are there more of them?", "tokens": [865, 11, 286, 914, 11, 291, 727, 534, 1322, 411, 11, 257, 14205, 295, 2699, 76, 3089, 3125, 3873, 293, 5056, 14455, 337, 309, 365, 341, 11, 291, 458, 11, 411, 11, 1338, 11, 439, 264, 3755, 366, 456, 13, 509, 727, 574, 412, 264, 1230, 295, 815, 6446, 294, 257, 3089, 3096, 281, 2464, 411, 11, 300, 311, 364, 1880, 2522, 295, 1589, 11, 411, 815, 6446, 3212, 380, 1578, 11, 457, 689, 366, 456, 544, 295, 552, 30], "temperature": 0.0, "avg_logprob": -0.19841232753935314, "compression_ratio": 1.6116504854368932, "no_speech_prob": 0.0002453512279316783}, {"id": 256, "seek": 278300, "start": 2783.0, "end": 2812.0, "text": " Yeah, or the number of primitives, you know, primitive obsession, that kind of thing. But yeah, metrics are always kind of scaring that thing like, like, do we want to decrease this number even further? Like, sometimes yes, but like, it's not, it's not a fixed rule. That's, that's also like an area where this can get useful. It's like Elm Review has, like, it's really hard to say", "tokens": [865, 11, 420, 264, 1230, 295, 2886, 38970, 11, 291, 458, 11, 28540, 30521, 11, 300, 733, 295, 551, 13, 583, 1338, 11, 16367, 366, 1009, 733, 295, 795, 1921, 300, 551, 411, 11, 411, 11, 360, 321, 528, 281, 11514, 341, 1230, 754, 3052, 30, 1743, 11, 2171, 2086, 11, 457, 411, 11, 309, 311, 406, 11, 309, 311, 406, 257, 6806, 4978, 13, 663, 311, 11, 300, 311, 611, 411, 364, 1859, 689, 341, 393, 483, 4420, 13, 467, 311, 411, 2699, 76, 19954, 575, 11, 411, 11, 309, 311, 534, 1152, 281, 584], "temperature": 0.0, "avg_logprob": -0.24571128845214843, "compression_ratio": 1.6394849785407726, "no_speech_prob": 0.0001007057071547024}, {"id": 257, "seek": 281200, "start": 2812.0, "end": 2841.0, "text": " well, this, this rule does not apply everywhere. Elm Review basically, all the rules have to be 100% correct, in the sense that they don't report false positives, they can report false negatives, they can have false negatives, you can't report false negatives. But if you make that into, if you add an extractor to that, then you can extract that information without enforcing it on your project, if that makes sense. That's a possibility.", "tokens": [731, 11, 341, 11, 341, 4978, 775, 406, 3079, 5315, 13, 2699, 76, 19954, 1936, 11, 439, 264, 4474, 362, 281, 312, 2319, 4, 3006, 11, 294, 264, 2020, 300, 436, 500, 380, 2275, 7908, 35127, 11, 436, 393, 2275, 7908, 40019, 11, 436, 393, 362, 7908, 40019, 11, 291, 393, 380, 2275, 7908, 40019, 13, 583, 498, 291, 652, 300, 666, 11, 498, 291, 909, 364, 8947, 284, 281, 300, 11, 550, 291, 393, 8947, 300, 1589, 1553, 25495, 2175, 309, 322, 428, 1716, 11, 498, 300, 1669, 2020, 13, 663, 311, 257, 7959, 13], "temperature": 0.0, "avg_logprob": -0.21154838562011719, "compression_ratio": 1.8291666666666666, "no_speech_prob": 0.0003053354157600552}, {"id": 258, "seek": 284100, "start": 2841.0, "end": 2845.0, "text": " I don't know if that will work out. But it's, it's something you could do.", "tokens": [286, 500, 380, 458, 498, 300, 486, 589, 484, 13, 583, 309, 311, 11, 309, 311, 746, 291, 727, 360, 13], "temperature": 0.0, "avg_logprob": -0.15141855239868163, "compression_ratio": 0.9866666666666667, "no_speech_prob": 0.0002823946124408394}, {"id": 259, "seek": 284500, "start": 2845.0, "end": 2874.0, "text": " I think it's really good. It's a good workflow to just like, have this information, and then say, like, all right, what could use some refactoring. And then, especially if you like cross reference that with like, like, if you take, like you said, like, Elm Review doesn't currently have access to get information. But if you're building an extractor, you just extract what you need using Elm Review extractors, and then extract some information from the command line from Elm Review.", "tokens": [286, 519, 309, 311, 534, 665, 13, 467, 311, 257, 665, 20993, 281, 445, 411, 11, 362, 341, 1589, 11, 293, 550, 584, 11, 411, 11, 439, 558, 11, 437, 727, 764, 512, 1895, 578, 3662, 13, 400, 550, 11, 2318, 498, 291, 411, 3278, 6408, 300, 365, 411, 11, 411, 11, 498, 291, 747, 11, 411, 291, 848, 11, 411, 11, 2699, 76, 19954, 1177, 380, 4362, 362, 2105, 281, 483, 1589, 13, 583, 498, 291, 434, 2390, 364, 8947, 284, 11, 291, 445, 8947, 437, 291, 643, 1228, 2699, 76, 19954, 8947, 830, 11, 293, 550, 8947, 512, 1589, 490, 264, 5622, 1622, 490, 2699, 76, 19954, 13], "temperature": 0.0, "avg_logprob": -0.20723854868035568, "compression_ratio": 1.872093023255814, "no_speech_prob": 0.00022340851137414575}, {"id": 260, "seek": 287400, "start": 2874.0, "end": 2902.0, "text": " And then you extract some information from the command line from Git of how frequently files are changed, you know, the churn rate of certain modules. And then you can just sort of cross reference those pieces of data in a in a script. And so you say like, okay, well, this file has a lot of churn, it has a lot of non opaque types, it has a lot of deeply nested conditional statements, it has a lot of maybes and primitive types.", "tokens": [400, 550, 291, 8947, 512, 1589, 490, 264, 5622, 1622, 490, 16939, 295, 577, 10374, 7098, 366, 3105, 11, 291, 458, 11, 264, 417, 925, 3314, 295, 1629, 16679, 13, 400, 550, 291, 393, 445, 1333, 295, 3278, 6408, 729, 3755, 295, 1412, 294, 257, 294, 257, 5755, 13, 400, 370, 291, 584, 411, 11, 1392, 11, 731, 11, 341, 3991, 575, 257, 688, 295, 417, 925, 11, 309, 575, 257, 688, 295, 2107, 42687, 3467, 11, 309, 575, 257, 688, 295, 8760, 15646, 292, 27708, 12363, 11, 309, 575, 257, 688, 295, 815, 6446, 293, 28540, 3467, 13], "temperature": 0.0, "avg_logprob": -0.24659390125459837, "compression_ratio": 1.7622950819672132, "no_speech_prob": 0.004829240031540394}, {"id": 261, "seek": 290200, "start": 2902.0, "end": 2927.0, "text": " And it's churning a lot, we change, we touch it a lot, or maybe like bug fix commits touch this file a lot. So maybe that's a place to that that's just something to be aware of that it might be a hotspot. It doesn't mean the numbers need to go to zero, because they're bad inherently, it just is something to focus your attention on when you're looking for areas to refactor.", "tokens": [400, 309, 311, 417, 10656, 257, 688, 11, 321, 1319, 11, 321, 2557, 309, 257, 688, 11, 420, 1310, 411, 7426, 3191, 48311, 2557, 341, 3991, 257, 688, 13, 407, 1310, 300, 311, 257, 1081, 281, 300, 300, 311, 445, 746, 281, 312, 3650, 295, 300, 309, 1062, 312, 257, 36121, 17698, 13, 467, 1177, 380, 914, 264, 3547, 643, 281, 352, 281, 4018, 11, 570, 436, 434, 1578, 27993, 11, 309, 445, 307, 746, 281, 1879, 428, 3202, 322, 562, 291, 434, 1237, 337, 3179, 281, 1895, 15104, 13], "temperature": 0.0, "avg_logprob": -0.22086721785525057, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.006487752310931683}, {"id": 262, "seek": 292700, "start": 2927.0, "end": 2951.0, "text": " So if you're missing some information in Elm Review, then yes, exactly. As you say, you can combine it with other information in a scripts. You can also do the opposite way of you can provide more information to Elm Review by adding it to the configuration or by you could generate that information into Elm code.", "tokens": [407, 498, 291, 434, 5361, 512, 1589, 294, 2699, 76, 19954, 11, 550, 2086, 11, 2293, 13, 1018, 291, 584, 11, 291, 393, 10432, 309, 365, 661, 1589, 294, 257, 23294, 13, 509, 393, 611, 360, 264, 6182, 636, 295, 291, 393, 2893, 544, 1589, 281, 2699, 76, 19954, 538, 5127, 309, 281, 264, 11694, 420, 538, 291, 727, 8460, 300, 1589, 666, 2699, 76, 3089, 13], "temperature": 0.0, "avg_logprob": -0.26182475560148, "compression_ratio": 1.6737967914438503, "no_speech_prob": 0.00013550750736612827}, {"id": 263, "seek": 295100, "start": 2951.0, "end": 2977.0, "text": " For instance, that's what this what we do for detecting unused CSS classes in the workplace. We take the CSS files, and we generate an Elm file that the Elm Review configuration then fetches through simple imports. So you could again use Elm Code Gen for that. We chose to have something simpler, but right, especially because it's older than Elm Code Gen.", "tokens": [1171, 5197, 11, 300, 311, 437, 341, 437, 321, 360, 337, 40237, 44383, 24387, 5359, 294, 264, 15328, 13, 492, 747, 264, 24387, 7098, 11, 293, 321, 8460, 364, 2699, 76, 3991, 300, 264, 2699, 76, 19954, 11694, 550, 15136, 3781, 807, 2199, 41596, 13, 407, 291, 727, 797, 764, 2699, 76, 15549, 3632, 337, 300, 13, 492, 5111, 281, 362, 746, 18587, 11, 457, 558, 11, 2318, 570, 309, 311, 4906, 813, 2699, 76, 15549, 3632, 13], "temperature": 0.0, "avg_logprob": -0.28069916549994023, "compression_ratio": 1.6104417670682731, "no_speech_prob": 0.00016864525969140232}, {"id": 264, "seek": 295100, "start": 2977.0, "end": 2979.0, "text": " Or Elm Review Code Gen pages.", "tokens": [1610, 2699, 76, 19954, 15549, 3632, 7183, 13], "temperature": 0.0, "avg_logprob": -0.28069916549994023, "compression_ratio": 1.6104417670682731, "no_speech_prob": 0.00016864525969140232}, {"id": 265, "seek": 295100, "start": 2979.0, "end": 2980.0, "text": " Yeah, exactly.", "tokens": [865, 11, 2293, 13], "temperature": 0.0, "avg_logprob": -0.28069916549994023, "compression_ratio": 1.6104417670682731, "no_speech_prob": 0.00016864525969140232}, {"id": 266, "seek": 298000, "start": 2980.0, "end": 2981.0, "text": " Problem solved.", "tokens": [11676, 13041, 13], "temperature": 0.0, "avg_logprob": -0.3766748905181885, "compression_ratio": 1.0833333333333333, "no_speech_prob": 0.00020024244440719485}, {"id": 267, "seek": 298000, "start": 2981.0, "end": 2985.0, "text": " Elm Review Code Gen pages, Code Gen Review.", "tokens": [2699, 76, 19954, 15549, 3632, 7183, 11, 15549, 3632, 19954, 13], "temperature": 0.0, "avg_logprob": -0.3766748905181885, "compression_ratio": 1.0833333333333333, "no_speech_prob": 0.00020024244440719485}, {"id": 268, "seek": 298000, "start": 2985.0, "end": 2989.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.3766748905181885, "compression_ratio": 1.0833333333333333, "no_speech_prob": 0.00020024244440719485}, {"id": 269, "seek": 298900, "start": 2989.0, "end": 3009.0, "text": " You know, that's maybe one of those pitfalls that we have with the Elm community where we call everything based on what it does, like Elm Code Gen. Okay, it does Code Gen. Elm Review, it reviews. Whereas you have something like React. Oh, that's a cool name. It's not like it reacts to something.", "tokens": [509, 458, 11, 300, 311, 1310, 472, 295, 729, 10147, 18542, 300, 321, 362, 365, 264, 2699, 76, 1768, 689, 321, 818, 1203, 2361, 322, 437, 309, 775, 11, 411, 2699, 76, 15549, 3632, 13, 1033, 11, 309, 775, 15549, 3632, 13, 2699, 76, 19954, 11, 309, 10229, 13, 13813, 291, 362, 746, 411, 30644, 13, 876, 11, 300, 311, 257, 1627, 1315, 13, 467, 311, 406, 411, 309, 33305, 281, 746, 13], "temperature": 0.0, "avg_logprob": -0.19429343423725645, "compression_ratio": 1.5618556701030928, "no_speech_prob": 9.368357495986857e-06}, {"id": 270, "seek": 298900, "start": 3009.0, "end": 3010.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.19429343423725645, "compression_ratio": 1.5618556701030928, "no_speech_prob": 9.368357495986857e-06}, {"id": 271, "seek": 301000, "start": 3010.0, "end": 3020.0, "text": " Yeah, maybe here, like, it would be interesting to have a cool name, like, Elm, I don't know how to make cool names.", "tokens": [865, 11, 1310, 510, 11, 411, 11, 309, 576, 312, 1880, 281, 362, 257, 1627, 1315, 11, 411, 11, 2699, 76, 11, 286, 500, 380, 458, 577, 281, 652, 1627, 5288, 13], "temperature": 0.0, "avg_logprob": -0.2493428031166831, "compression_ratio": 1.5307262569832403, "no_speech_prob": 8.939480721892323e-06}, {"id": 272, "seek": 301000, "start": 3020.0, "end": 3021.0, "text": " Elm Linguini.", "tokens": [2699, 76, 441, 7050, 3812, 13], "temperature": 0.0, "avg_logprob": -0.2493428031166831, "compression_ratio": 1.5307262569832403, "no_speech_prob": 8.939480721892323e-06}, {"id": 273, "seek": 301000, "start": 3021.0, "end": 3031.0, "text": " Exactly. Yeah. Elm Spaghetti. I mean, if it's to find problems in your code base, like Spaghetti Code.", "tokens": [7587, 13, 865, 13, 2699, 76, 1738, 24402, 13, 286, 914, 11, 498, 309, 311, 281, 915, 2740, 294, 428, 3089, 3096, 11, 411, 1738, 24402, 15549, 13], "temperature": 0.0, "avg_logprob": -0.2493428031166831, "compression_ratio": 1.5307262569832403, "no_speech_prob": 8.939480721892323e-06}, {"id": 274, "seek": 301000, "start": 3031.0, "end": 3032.0, "text": " Spaghetti Code.", "tokens": [1738, 24402, 15549, 13], "temperature": 0.0, "avg_logprob": -0.2493428031166831, "compression_ratio": 1.5307262569832403, "no_speech_prob": 8.939480721892323e-06}, {"id": 275, "seek": 301000, "start": 3032.0, "end": 3033.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2493428031166831, "compression_ratio": 1.5307262569832403, "no_speech_prob": 8.939480721892323e-06}, {"id": 276, "seek": 301000, "start": 3033.0, "end": 3034.0, "text": " To Spicy Meatball.", "tokens": [1407, 35999, 30502, 3129, 13], "temperature": 0.0, "avg_logprob": -0.2493428031166831, "compression_ratio": 1.5307262569832403, "no_speech_prob": 8.939480721892323e-06}, {"id": 277, "seek": 303400, "start": 3034.0, "end": 3049.0, "text": " Exactly. I mean, plenty of projects that are named that way for some reason. So yeah, if you're missing some information, you can try to combine it in one way or another.", "tokens": [7587, 13, 286, 914, 11, 7140, 295, 4455, 300, 366, 4926, 300, 636, 337, 512, 1778, 13, 407, 1338, 11, 498, 291, 434, 5361, 512, 1589, 11, 291, 393, 853, 281, 10432, 309, 294, 472, 636, 420, 1071, 13], "temperature": 0.0, "avg_logprob": -0.17358593608057776, "compression_ratio": 1.317829457364341, "no_speech_prob": 7.296312560356455e-06}, {"id": 278, "seek": 304900, "start": 3049.0, "end": 3067.0, "text": " I like your idea a lot to, like you said, either Code Gen a file which is imported into your Elm Review rule, or you could like Code Gen something into your Elm Review configuration file and then pass that data in.", "tokens": [286, 411, 428, 1558, 257, 688, 281, 11, 411, 291, 848, 11, 2139, 15549, 3632, 257, 3991, 597, 307, 25524, 666, 428, 2699, 76, 19954, 4978, 11, 420, 291, 727, 411, 15549, 3632, 746, 666, 428, 2699, 76, 19954, 11694, 3991, 293, 550, 1320, 300, 1412, 294, 13], "temperature": 0.0, "avg_logprob": -0.22653188567230667, "compression_ratio": 1.6603773584905661, "no_speech_prob": 7.889165317465086e-06}, {"id": 279, "seek": 304900, "start": 3067.0, "end": 3069.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.22653188567230667, "compression_ratio": 1.6603773584905661, "no_speech_prob": 7.889165317465086e-06}, {"id": 280, "seek": 304900, "start": 3069.0, "end": 3075.0, "text": " Or you could use Elm Review pages Code Gen.", "tokens": [1610, 291, 727, 764, 2699, 76, 19954, 7183, 15549, 3632, 13], "temperature": 0.0, "avg_logprob": -0.22653188567230667, "compression_ratio": 1.6603773584905661, "no_speech_prob": 7.889165317465086e-06}, {"id": 281, "seek": 307500, "start": 3075.0, "end": 3088.0, "text": " I think we should add CM at the end of that now. Just to make it longer. And I'm sure such a complex project would need a manager or a factory or something, you know.", "tokens": [286, 519, 321, 820, 909, 20424, 412, 264, 917, 295, 300, 586, 13, 1449, 281, 652, 309, 2854, 13, 400, 286, 478, 988, 1270, 257, 3997, 1716, 576, 643, 257, 6598, 420, 257, 9265, 420, 746, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.22672803878784178, "compression_ratio": 1.3475177304964538, "no_speech_prob": 4.757480201078579e-05}, {"id": 282, "seek": 307500, "start": 3088.0, "end": 3091.0, "text": " Absolutely. Absolutely.", "tokens": [7021, 13, 7021, 13], "temperature": 0.0, "avg_logprob": -0.22672803878784178, "compression_ratio": 1.3475177304964538, "no_speech_prob": 4.757480201078579e-05}, {"id": 283, "seek": 309100, "start": 3091.0, "end": 3113.0, "text": " Yeah. So another, so actually, if we go down the route of what Elm Review can give you as information, it can go pretty far. Like one experiment that I tried was generating the docs.json file for packages or for any kind of projects.", "tokens": [865, 13, 407, 1071, 11, 370, 767, 11, 498, 321, 352, 760, 264, 7955, 295, 437, 2699, 76, 19954, 393, 976, 291, 382, 1589, 11, 309, 393, 352, 1238, 1400, 13, 1743, 472, 5120, 300, 286, 3031, 390, 17746, 264, 45623, 13, 73, 3015, 3991, 337, 17401, 420, 337, 604, 733, 295, 4455, 13], "temperature": 0.0, "avg_logprob": -0.2448404410789753, "compression_ratio": 1.3625730994152048, "no_speech_prob": 0.00018231727881357074}, {"id": 284, "seek": 311300, "start": 3113.0, "end": 3129.0, "text": " But yeah, mostly packages, which is like, basically the summary of the packages documentation. And that is what the Elm Packages website uses to show the documentation of a package.", "tokens": [583, 1338, 11, 5240, 17401, 11, 597, 307, 411, 11, 1936, 264, 12691, 295, 264, 17401, 14333, 13, 400, 300, 307, 437, 264, 2699, 76, 18466, 1660, 3144, 4960, 281, 855, 264, 14333, 295, 257, 7372, 13], "temperature": 0.0, "avg_logprob": -0.2246540574466481, "compression_ratio": 1.5875, "no_speech_prob": 2.7967584173893556e-05}, {"id": 285, "seek": 311300, "start": 3129.0, "end": 3130.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.2246540574466481, "compression_ratio": 1.5875, "no_speech_prob": 2.7967584173893556e-05}, {"id": 286, "seek": 311300, "start": 3130.0, "end": 3135.0, "text": " And if you use Elm Duck Preview, that's also what it uses.", "tokens": [400, 498, 291, 764, 2699, 76, 29266, 6001, 1759, 11, 300, 311, 611, 437, 309, 4960, 13], "temperature": 0.0, "avg_logprob": -0.2246540574466481, "compression_ratio": 1.5875, "no_speech_prob": 2.7967584173893556e-05}, {"id": 287, "seek": 311300, "start": 3135.0, "end": 3137.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.2246540574466481, "compression_ratio": 1.5875, "no_speech_prob": 2.7967584173893556e-05}, {"id": 288, "seek": 313700, "start": 3137.0, "end": 3149.0, "text": " So I figured like, well, as a proof of concept, and this is kind of what I played around with to test things, I can generate that docs.json file, which is what the compiler does.", "tokens": [407, 286, 8932, 411, 11, 731, 11, 382, 257, 8177, 295, 3410, 11, 293, 341, 307, 733, 295, 437, 286, 3737, 926, 365, 281, 1500, 721, 11, 286, 393, 8460, 300, 45623, 13, 73, 3015, 3991, 11, 597, 307, 437, 264, 31958, 775, 13], "temperature": 0.0, "avg_logprob": -0.20253669924852324, "compression_ratio": 1.5073891625615763, "no_speech_prob": 3.535347423166968e-05}, {"id": 289, "seek": 313700, "start": 3149.0, "end": 3150.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.20253669924852324, "compression_ratio": 1.5073891625615763, "no_speech_prob": 3.535347423166968e-05}, {"id": 290, "seek": 313700, "start": 3150.0, "end": 3161.0, "text": " What does the Elm compiler also generate? Well, it generates JavaScript code based on the dependencies.", "tokens": [708, 775, 264, 2699, 76, 31958, 611, 8460, 30, 1042, 11, 309, 23815, 15778, 3089, 2361, 322, 264, 36606, 13], "temperature": 0.0, "avg_logprob": -0.20253669924852324, "compression_ratio": 1.5073891625615763, "no_speech_prob": 3.535347423166968e-05}, {"id": 291, "seek": 313700, "start": 3161.0, "end": 3162.0, "text": " Crazy. Yes, yes.", "tokens": [22509, 13, 1079, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.20253669924852324, "compression_ratio": 1.5073891625615763, "no_speech_prob": 3.535347423166968e-05}, {"id": 292, "seek": 316200, "start": 3162.0, "end": 3171.0, "text": " Based on the Elm code. And like, technically, maybe with the limitation of how much JSON you can really output.", "tokens": [18785, 322, 264, 2699, 76, 3089, 13, 400, 411, 11, 12120, 11, 1310, 365, 264, 27432, 295, 577, 709, 31828, 291, 393, 534, 5598, 13], "temperature": 0.0, "avg_logprob": -0.21894240105289153, "compression_ratio": 1.5279187817258884, "no_speech_prob": 1.4063613889447879e-05}, {"id": 293, "seek": 316200, "start": 3171.0, "end": 3172.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.21894240105289153, "compression_ratio": 1.5279187817258884, "no_speech_prob": 1.4063613889447879e-05}, {"id": 294, "seek": 316200, "start": 3172.0, "end": 3177.0, "text": " Potentially, you can write an Elm compiler using Elm Review.", "tokens": [9145, 3137, 11, 291, 393, 2464, 364, 2699, 76, 31958, 1228, 2699, 76, 19954, 13], "temperature": 0.0, "avg_logprob": -0.21894240105289153, "compression_ratio": 1.5279187817258884, "no_speech_prob": 1.4063613889447879e-05}, {"id": 295, "seek": 316200, "start": 3177.0, "end": 3179.0, "text": " Whoa. Interesting. Yeah.", "tokens": [7521, 13, 14711, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.21894240105289153, "compression_ratio": 1.5279187817258884, "no_speech_prob": 1.4063613889447879e-05}, {"id": 296, "seek": 316200, "start": 3179.0, "end": 3182.0, "text": " So the Elm in Elm compiler could be made in Elm Review.", "tokens": [407, 264, 2699, 76, 294, 2699, 76, 31958, 727, 312, 1027, 294, 2699, 76, 19954, 13], "temperature": 0.0, "avg_logprob": -0.21894240105289153, "compression_ratio": 1.5279187817258884, "no_speech_prob": 1.4063613889447879e-05}, {"id": 297, "seek": 316200, "start": 3182.0, "end": 3186.0, "text": " That's a cool concept. Very interesting.", "tokens": [663, 311, 257, 1627, 3410, 13, 4372, 1880, 13], "temperature": 0.0, "avg_logprob": -0.21894240105289153, "compression_ratio": 1.5279187817258884, "no_speech_prob": 1.4063613889447879e-05}, {"id": 298, "seek": 318600, "start": 3186.0, "end": 3204.0, "text": " Whether it will work in practice, I don't know. But that said, like, if I ever want to make Elm compile to something else than JavaScript, like, this could be a pretty easy way to get started.", "tokens": [8503, 309, 486, 589, 294, 3124, 11, 286, 500, 380, 458, 13, 583, 300, 848, 11, 411, 11, 498, 286, 1562, 528, 281, 652, 2699, 76, 31413, 281, 746, 1646, 813, 15778, 11, 411, 11, 341, 727, 312, 257, 1238, 1858, 636, 281, 483, 1409, 13], "temperature": 0.0, "avg_logprob": -0.2096412314309014, "compression_ratio": 1.4751381215469612, "no_speech_prob": 6.143978680483997e-06}, {"id": 299, "seek": 318600, "start": 3204.0, "end": 3208.0, "text": " Like, you don't have to read files. You don't have to do all those things.", "tokens": [1743, 11, 291, 500, 380, 362, 281, 1401, 7098, 13, 509, 500, 380, 362, 281, 360, 439, 729, 721, 13], "temperature": 0.0, "avg_logprob": -0.2096412314309014, "compression_ratio": 1.4751381215469612, "no_speech_prob": 6.143978680483997e-06}, {"id": 300, "seek": 320800, "start": 3208.0, "end": 3216.0, "text": " Just take all the information from the Elm code and make an output. And maybe you'll be pretty far off.", "tokens": [1449, 747, 439, 264, 1589, 490, 264, 2699, 76, 3089, 293, 652, 364, 5598, 13, 400, 1310, 291, 603, 312, 1238, 1400, 766, 13], "temperature": 0.0, "avg_logprob": -0.17055239460685037, "compression_ratio": 1.5242718446601942, "no_speech_prob": 1.0450760782987345e-05}, {"id": 301, "seek": 320800, "start": 3216.0, "end": 3227.0, "text": " Yeah. And I mean, if you want to bridge the gap between Elm and other contexts, it's a pretty good start for that, too.", "tokens": [865, 13, 400, 286, 914, 11, 498, 291, 528, 281, 7283, 264, 7417, 1296, 2699, 76, 293, 661, 30628, 11, 309, 311, 257, 1238, 665, 722, 337, 300, 11, 886, 13], "temperature": 0.0, "avg_logprob": -0.17055239460685037, "compression_ratio": 1.5242718446601942, "no_speech_prob": 1.0450760782987345e-05}, {"id": 302, "seek": 320800, "start": 3227.0, "end": 3234.0, "text": " I'm not sure if it would, like, help you. I don't think Elm Review would help you resolve.", "tokens": [286, 478, 406, 988, 498, 309, 576, 11, 411, 11, 854, 291, 13, 286, 500, 380, 519, 2699, 76, 19954, 576, 854, 291, 14151, 13], "temperature": 0.0, "avg_logprob": -0.17055239460685037, "compression_ratio": 1.5242718446601942, "no_speech_prob": 1.0450760782987345e-05}, {"id": 303, "seek": 323400, "start": 3234.0, "end": 3256.0, "text": " Maybe it would be fine. Like, if you wanted to do some code generation tasks, for example, like, for my old Elm TypeScript Interrupt project, I extracted information with the help of Elmite to JSON, which extracts information from the sort of binary stuff in the Elm stuff folder.", "tokens": [2704, 309, 576, 312, 2489, 13, 1743, 11, 498, 291, 1415, 281, 360, 512, 3089, 5125, 9608, 11, 337, 1365, 11, 411, 11, 337, 452, 1331, 2699, 76, 15576, 14237, 5751, 5428, 1716, 11, 286, 34086, 1589, 365, 264, 854, 295, 2699, 76, 642, 281, 31828, 11, 597, 8947, 82, 1589, 490, 264, 1333, 295, 17434, 1507, 294, 264, 2699, 76, 1507, 10820, 13], "temperature": 0.0, "avg_logprob": -0.26154187146355123, "compression_ratio": 1.4814814814814814, "no_speech_prob": 7.484386151190847e-05}, {"id": 304, "seek": 325600, "start": 3256.0, "end": 3278.0, "text": " And I used that to get the types of all of the ports for the project. But then I also had to do some static analysis to resolve which aliases pointed to which types so that I could turn them into actual primitives that I could send through ports and then build decoders based on that.", "tokens": [400, 286, 1143, 300, 281, 483, 264, 3467, 295, 439, 295, 264, 18160, 337, 264, 1716, 13, 583, 550, 286, 611, 632, 281, 360, 512, 13437, 5215, 281, 14151, 597, 10198, 1957, 10932, 281, 597, 3467, 370, 300, 286, 727, 1261, 552, 666, 3539, 2886, 38970, 300, 286, 727, 2845, 807, 18160, 293, 550, 1322, 979, 378, 433, 2361, 322, 300, 13], "temperature": 0.0, "avg_logprob": -0.16665835814042526, "compression_ratio": 1.6228571428571428, "no_speech_prob": 0.00011411676678108051}, {"id": 305, "seek": 327800, "start": 3278.0, "end": 3293.0, "text": " Yeah, that's exactly one of the use cases where I could see Elm Review being used instead of a custom tool or custom script. Whether it will do better than another tool, probably not.", "tokens": [865, 11, 300, 311, 2293, 472, 295, 264, 764, 3331, 689, 286, 727, 536, 2699, 76, 19954, 885, 1143, 2602, 295, 257, 2375, 2290, 420, 2375, 5755, 13, 8503, 309, 486, 360, 1101, 813, 1071, 2290, 11, 1391, 406, 13], "temperature": 0.0, "avg_logprob": -0.20632117727528448, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.0001511060690972954}, {"id": 306, "seek": 327800, "start": 3293.0, "end": 3299.0, "text": " It's like Elm Review is not that fast, unfortunately, but maybe I'm self-deprecating here.", "tokens": [467, 311, 411, 2699, 76, 19954, 307, 406, 300, 2370, 11, 7015, 11, 457, 1310, 286, 478, 2698, 12, 19929, 13867, 990, 510, 13], "temperature": 0.0, "avg_logprob": -0.20632117727528448, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.0001511060690972954}, {"id": 307, "seek": 327800, "start": 3299.0, "end": 3304.0, "text": " Yeah. Well, you'll have to suppress your self-deprecations, Jeroen.", "tokens": [865, 13, 1042, 11, 291, 603, 362, 281, 26835, 428, 2698, 12, 19929, 13867, 763, 11, 508, 2032, 268, 13], "temperature": 0.0, "avg_logprob": -0.20632117727528448, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.0001511060690972954}, {"id": 308, "seek": 330400, "start": 3304.0, "end": 3314.0, "text": " I will try to do so. But it's like trying to impose rules on myself is really hard, you know.", "tokens": [286, 486, 853, 281, 360, 370, 13, 583, 309, 311, 411, 1382, 281, 26952, 4474, 322, 2059, 307, 534, 1152, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.2718686546598162, "compression_ratio": 1.0941176470588236, "no_speech_prob": 0.000519008026458323}, {"id": 309, "seek": 331400, "start": 3314.0, "end": 3334.0, "text": " Yeah, I think that's a pretty powerful use case, though. And I guess you totally could build that lookup table that resolves a type alias to what it actually points to. You could totally do that with Elm Review visitors.", "tokens": [865, 11, 286, 519, 300, 311, 257, 1238, 4005, 764, 1389, 11, 1673, 13, 400, 286, 2041, 291, 3879, 727, 1322, 300, 574, 1010, 3199, 300, 7923, 977, 257, 2010, 419, 4609, 281, 437, 309, 767, 2793, 281, 13, 509, 727, 3879, 360, 300, 365, 2699, 76, 19954, 14315, 13], "temperature": 0.0, "avg_logprob": -0.1802798553749367, "compression_ratio": 1.4193548387096775, "no_speech_prob": 0.0003453633398748934}, {"id": 310, "seek": 333400, "start": 3334.0, "end": 3350.0, "text": " Yeah, I think that's a really cool use case. And I think that's really cool because you can have certain constraints where you say, this rule requires, for example, type annotations for these things.", "tokens": [865, 11, 286, 519, 300, 311, 257, 534, 1627, 764, 1389, 13, 400, 286, 519, 300, 311, 534, 1627, 570, 291, 393, 362, 1629, 18491, 689, 291, 584, 11, 341, 4978, 7029, 11, 337, 1365, 11, 2010, 25339, 763, 337, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.5933180395162331, "compression_ratio": 1.4758620689655173, "no_speech_prob": 0.0028839618898928165}, {"id": 311, "seek": 333400, "start": 3350.0, "end": 3352.0, "text": " Yeah, exactly.", "tokens": [865, 11, 2293, 13], "temperature": 0.0, "avg_logprob": -0.5933180395162331, "compression_ratio": 1.4758620689655173, "no_speech_prob": 0.0028839618898928165}, {"id": 312, "seek": 335200, "start": 3352.0, "end": 3376.0, "text": " I didn't mention it explicitly, but when you're saying that Elm Review has the ability to generate the docs.json, which is what generates the package documentation for Elm Packages, Elm Review doesn't currently have the ability to do type inference, but it doesn't need that because Elm Packages, in order to be publishable, must have type annotations for all of their top-level functions.", "tokens": [286, 994, 380, 2152, 309, 20803, 11, 457, 562, 291, 434, 1566, 300, 2699, 76, 19954, 575, 264, 3485, 281, 8460, 264, 45623, 13, 73, 3015, 11, 597, 307, 437, 23815, 264, 7372, 14333, 337, 2699, 76, 18466, 1660, 11, 2699, 76, 19954, 1177, 380, 4362, 362, 264, 3485, 281, 360, 2010, 38253, 11, 457, 309, 1177, 380, 643, 300, 570, 2699, 76, 18466, 1660, 11, 294, 1668, 281, 312, 11374, 712, 11, 1633, 362, 2010, 25339, 763, 337, 439, 295, 641, 1192, 12, 12418, 6828, 13], "temperature": 0.0, "avg_logprob": -0.18570914635291466, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.000543752801604569}, {"id": 313, "seek": 335200, "start": 3376.0, "end": 3378.0, "text": " Yeah, for everything that is exposed, at least.", "tokens": [865, 11, 337, 1203, 300, 307, 9495, 11, 412, 1935, 13], "temperature": 0.0, "avg_logprob": -0.18570914635291466, "compression_ratio": 1.720472440944882, "no_speech_prob": 0.000543752801604569}, {"id": 314, "seek": 337800, "start": 3378.0, "end": 3399.0, "text": " Everything exposed. So you can have constraints like that, and you can say, hey, I'm only able to operate on things that you have given explicit type annotations for. But you can do all sorts of cogeneration tasks for this, like, kind of bridging, you know, types without borders stuff to kind of connect different paradigms to each other. So that's pretty cool.", "tokens": [5471, 9495, 13, 407, 291, 393, 362, 18491, 411, 300, 11, 293, 291, 393, 584, 11, 4177, 11, 286, 478, 787, 1075, 281, 9651, 322, 721, 300, 291, 362, 2212, 13691, 2010, 25339, 763, 337, 13, 583, 291, 393, 360, 439, 7527, 295, 598, 30372, 9608, 337, 341, 11, 411, 11, 733, 295, 16362, 3249, 11, 291, 458, 11, 3467, 1553, 16287, 1507, 281, 733, 295, 1745, 819, 13480, 328, 2592, 281, 1184, 661, 13, 407, 300, 311, 1238, 1627, 13], "temperature": 0.0, "avg_logprob": -0.1964473948759191, "compression_ratio": 1.5807860262008733, "no_speech_prob": 0.00043054166599176824}, {"id": 315, "seek": 339900, "start": 3399.0, "end": 3416.0, "text": " Actually, I haven't mentioned why I made this feature in the first place. So I had a project idea that is not Elm Review, where I would use Elm Review, which I've kind of put a lid on at this moment or put to pause.", "tokens": [5135, 11, 286, 2378, 380, 2835, 983, 286, 1027, 341, 4111, 294, 264, 700, 1081, 13, 407, 286, 632, 257, 1716, 1558, 300, 307, 406, 2699, 76, 19954, 11, 689, 286, 576, 764, 2699, 76, 19954, 11, 597, 286, 600, 733, 295, 829, 257, 10252, 322, 412, 341, 1623, 420, 829, 281, 10465, 13], "temperature": 0.0, "avg_logprob": -0.16974730327211576, "compression_ratio": 1.4052287581699345, "no_speech_prob": 3.8445550671895035e-06}, {"id": 316, "seek": 341600, "start": 3416.0, "end": 3432.0, "text": " I actually bought the domain name, and it expired this week. So I'm not sure I'm going to get to it soon. But basically, I wanted to show how secure the Elm Package ecosystem was.", "tokens": [286, 767, 4243, 264, 9274, 1315, 11, 293, 309, 36587, 341, 1243, 13, 407, 286, 478, 406, 988, 286, 478, 516, 281, 483, 281, 309, 2321, 13, 583, 1936, 11, 286, 1415, 281, 855, 577, 7144, 264, 2699, 76, 18466, 609, 11311, 390, 13], "temperature": 0.0, "avg_logprob": -0.21609548727671304, "compression_ratio": 1.2971014492753623, "no_speech_prob": 2.5465236831223592e-05}, {"id": 317, "seek": 343200, "start": 3432.0, "end": 3454.0, "text": " I might have mentioned this during the Christmas episode, where we did mention Elm Review's extracts feature. So the idea is that, like, there's not a lot of security issues. There's a few that I fixed a year ago with regards to virtual DOM and XSS or cross-site scripting issues.", "tokens": [286, 1062, 362, 2835, 341, 1830, 264, 5272, 3500, 11, 689, 321, 630, 2152, 2699, 76, 19954, 311, 8947, 82, 4111, 13, 407, 264, 1558, 307, 300, 11, 411, 11, 456, 311, 406, 257, 688, 295, 3825, 2663, 13, 821, 311, 257, 1326, 300, 286, 6806, 257, 1064, 2057, 365, 14258, 281, 6374, 35727, 293, 1783, 21929, 420, 3278, 12, 30417, 5755, 278, 2663, 13], "temperature": 0.0, "avg_logprob": -0.19246088940164316, "compression_ratio": 1.4213197969543148, "no_speech_prob": 0.00012730646994896233}, {"id": 318, "seek": 345400, "start": 3454.0, "end": 3466.0, "text": " And I wanted to know, like, where do we have any packages in the Elm ecosystem that are making that are abusing this feature or this security hole?", "tokens": [400, 286, 1415, 281, 458, 11, 411, 11, 689, 360, 321, 362, 604, 17401, 294, 264, 2699, 76, 11311, 300, 366, 1455, 300, 366, 410, 7981, 341, 4111, 420, 341, 3825, 5458, 30], "temperature": 0.0, "avg_logprob": -0.2890497671591269, "compression_ratio": 1.2894736842105263, "no_speech_prob": 0.00010554485197644681}, {"id": 319, "seek": 346600, "start": 3466.0, "end": 3485.0, "text": " So what I did is I went through the packages, and I figured, well, which ones are depending on Elm slash HTML or Elm slash virtual DOM, which could be using these problematic functions, which have these security issues?", "tokens": [407, 437, 286, 630, 307, 286, 1437, 807, 264, 17401, 11, 293, 286, 8932, 11, 731, 11, 597, 2306, 366, 5413, 322, 2699, 76, 17330, 17995, 420, 2699, 76, 17330, 6374, 35727, 11, 597, 727, 312, 1228, 613, 19011, 6828, 11, 597, 362, 613, 3825, 2663, 30], "temperature": 0.0, "avg_logprob": -0.21775286805395985, "compression_ratio": 1.3773584905660377, "no_speech_prob": 1.4823376659478527e-06}, {"id": 320, "seek": 348500, "start": 3485.0, "end": 3500.0, "text": " And I will notice, well, most of them are not, but a lot of them are transitioning the problem. So the problem was if the one of the problems was using virtual DOM dot node NS.", "tokens": [400, 286, 486, 3449, 11, 731, 11, 881, 295, 552, 366, 406, 11, 457, 257, 688, 295, 552, 366, 33777, 264, 1154, 13, 407, 264, 1154, 390, 498, 264, 472, 295, 264, 2740, 390, 1228, 6374, 35727, 5893, 9984, 15943, 13], "temperature": 0.0, "avg_logprob": -0.2508339564005534, "compression_ratio": 1.4426229508196722, "no_speech_prob": 3.426785769988783e-05}, {"id": 321, "seek": 350000, "start": 3500.0, "end": 3517.0, "text": " And NS stands for namespace. So it's a regular, like, HTML dot node, which takes three arguments, which is the tag name, so like div or span or button, then a list of attributes and a list of children.", "tokens": [400, 15943, 7382, 337, 5288, 17940, 13, 407, 309, 311, 257, 3890, 11, 411, 11, 17995, 5893, 9984, 11, 597, 2516, 1045, 12869, 11, 597, 307, 264, 6162, 1315, 11, 370, 411, 3414, 420, 16174, 420, 2960, 11, 550, 257, 1329, 295, 17212, 293, 257, 1329, 295, 2227, 13], "temperature": 0.0, "avg_logprob": -0.2692876851783608, "compression_ratio": 1.3767123287671232, "no_speech_prob": 6.14380587649066e-06}, {"id": 322, "seek": 351700, "start": 3517.0, "end": 3531.0, "text": " And the functions that are that have this NS in their name, they also take a namespace, which is like a specification URL. I actually didn't get what that was.", "tokens": [400, 264, 6828, 300, 366, 300, 362, 341, 15943, 294, 641, 1315, 11, 436, 611, 747, 257, 5288, 17940, 11, 597, 307, 411, 257, 31256, 12905, 13, 286, 767, 994, 380, 483, 437, 300, 390, 13], "temperature": 0.0, "avg_logprob": -0.2614148029914269, "compression_ratio": 1.3288590604026846, "no_speech_prob": 2.058005065919133e-06}, {"id": 323, "seek": 351700, "start": 3531.0, "end": 3535.0, "text": " Some XML schema URL thing. Yeah, yeah.", "tokens": [2188, 43484, 34078, 12905, 551, 13, 865, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.2614148029914269, "compression_ratio": 1.3288590604026846, "no_speech_prob": 2.058005065919133e-06}, {"id": 324, "seek": 353500, "start": 3535.0, "end": 3550.0, "text": " Yeah. And there was a problem where these were not checked correctly. One of the arguments was not checked correctly. So what I noticed was a lot of these packages that were using these functions, they were taking,", "tokens": [865, 13, 400, 456, 390, 257, 1154, 689, 613, 645, 406, 10033, 8944, 13, 1485, 295, 264, 12869, 390, 406, 10033, 8944, 13, 407, 437, 286, 5694, 390, 257, 688, 295, 613, 17401, 300, 645, 1228, 613, 6828, 11, 436, 645, 1940, 11], "temperature": 0.0, "avg_logprob": -0.2682619297758062, "compression_ratio": 1.539568345323741, "no_speech_prob": 2.3182587028713897e-05}, {"id": 325, "seek": 355000, "start": 3550.0, "end": 3567.0, "text": " they were passing as arguments, things that were themselves taken as arguments. So the first argument that I needed to check for node NS was itself an argument to this function. So if I wanted to see whether a function was using the security issue,", "tokens": [436, 645, 8437, 382, 12869, 11, 721, 300, 645, 2969, 2726, 382, 12869, 13, 407, 264, 700, 6770, 300, 286, 2978, 281, 1520, 337, 9984, 15943, 390, 2564, 364, 6770, 281, 341, 2445, 13, 407, 498, 286, 1415, 281, 536, 1968, 257, 2445, 390, 1228, 264, 3825, 2734, 11], "temperature": 0.0, "avg_logprob": -0.2379368836025022, "compression_ratio": 1.6103896103896105, "no_speech_prob": 1.863088800746482e-05}, {"id": 326, "seek": 356700, "start": 3567.0, "end": 3583.0, "text": " then I needed to check which ones were using this function. But that was potentially in a different package. So what I did was I started working on this data extractor behind the scenes in a branch of the project on my computer.", "tokens": [550, 286, 2978, 281, 1520, 597, 2306, 645, 1228, 341, 2445, 13, 583, 300, 390, 7263, 294, 257, 819, 7372, 13, 407, 437, 286, 630, 390, 286, 1409, 1364, 322, 341, 1412, 8947, 284, 2261, 264, 8026, 294, 257, 9819, 295, 264, 1716, 322, 452, 3820, 13], "temperature": 0.0, "avg_logprob": -0.2265484379787071, "compression_ratio": 1.4339622641509433, "no_speech_prob": 1.670102574280463e-05}, {"id": 327, "seek": 358300, "start": 3583.0, "end": 3600.0, "text": " And I extracted the information of which functions are using these functions that are vulnerable and making a list of those. And then whenever I visited another package, I took all the vulnerable functions that they depend on.", "tokens": [400, 286, 34086, 264, 1589, 295, 597, 6828, 366, 1228, 613, 6828, 300, 366, 10955, 293, 1455, 257, 1329, 295, 729, 13, 400, 550, 5699, 286, 11220, 1071, 7372, 11, 286, 1890, 439, 264, 10955, 6828, 300, 436, 5672, 322, 13], "temperature": 0.0, "avg_logprob": -0.2299653795030382, "compression_ratio": 1.5694444444444444, "no_speech_prob": 4.539331348496489e-05}, {"id": 328, "seek": 360000, "start": 3600.0, "end": 3616.0, "text": " They have virtual DOM as a dependency or this other intermediate package that have these dependency issues. So these vulnerabilities and so on and so on. And the idea was, well, I'm just going to extract everything.", "tokens": [814, 362, 6374, 35727, 382, 257, 33621, 420, 341, 661, 19376, 7372, 300, 362, 613, 33621, 2663, 13, 407, 613, 37633, 293, 370, 322, 293, 370, 322, 13, 400, 264, 1558, 390, 11, 731, 11, 286, 478, 445, 516, 281, 8947, 1203, 13], "temperature": 0.0, "avg_logprob": -0.25924637977113113, "compression_ratio": 1.4052287581699345, "no_speech_prob": 2.5461955374339595e-05}, {"id": 329, "seek": 361600, "start": 3616.0, "end": 3633.0, "text": " And at some point, I'm going to be able to find out whether they are, one of them is misusing something. I never completed the research. Well, so far, I haven't been able to find any problematic use, at least.", "tokens": [400, 412, 512, 935, 11, 286, 478, 516, 281, 312, 1075, 281, 915, 484, 1968, 436, 366, 11, 472, 295, 552, 307, 3346, 7981, 746, 13, 286, 1128, 7365, 264, 2132, 13, 1042, 11, 370, 1400, 11, 286, 2378, 380, 668, 1075, 281, 915, 604, 19011, 764, 11, 412, 1935, 13], "temperature": 0.0, "avg_logprob": -0.20156484083695844, "compression_ratio": 1.412162162162162, "no_speech_prob": 0.00011409330909373239}, {"id": 330, "seek": 363300, "start": 3633.0, "end": 3647.0, "text": " So that's very positive. And now these issues are fixed anyway. So yeah, my idea was to make something that showed how many vulnerabilities there were in Elm and in its package ecosystem.", "tokens": [407, 300, 311, 588, 3353, 13, 400, 586, 613, 2663, 366, 6806, 4033, 13, 407, 1338, 11, 452, 1558, 390, 281, 652, 746, 300, 4712, 577, 867, 37633, 456, 645, 294, 2699, 76, 293, 294, 1080, 7372, 11311, 13], "temperature": 0.0, "avg_logprob": -0.2510927172674649, "compression_ratio": 1.4766839378238341, "no_speech_prob": 4.538841312751174e-05}, {"id": 331, "seek": 363300, "start": 3647.0, "end": 3651.0, "text": " And the highlight would have been, oh, there are zero issues.", "tokens": [400, 264, 5078, 576, 362, 668, 11, 1954, 11, 456, 366, 4018, 2663, 13], "temperature": 0.0, "avg_logprob": -0.2510927172674649, "compression_ratio": 1.4766839378238341, "no_speech_prob": 4.538841312751174e-05}, {"id": 332, "seek": 363300, "start": 3651.0, "end": 3654.0, "text": " Just make a website that says zero.", "tokens": [1449, 652, 257, 3144, 300, 1619, 4018, 13], "temperature": 0.0, "avg_logprob": -0.2510927172674649, "compression_ratio": 1.4766839378238341, "no_speech_prob": 4.538841312751174e-05}, {"id": 333, "seek": 365400, "start": 3654.0, "end": 3668.0, "text": " Yeah. And now, I don't know, like companies pay me to have a certification that says, hey, I'm using Elm and we are aware of all the security issues in the package ecosystem.", "tokens": [865, 13, 400, 586, 11, 286, 500, 380, 458, 11, 411, 3431, 1689, 385, 281, 362, 257, 21775, 300, 1619, 11, 4177, 11, 286, 478, 1228, 2699, 76, 293, 321, 366, 3650, 295, 439, 264, 3825, 2663, 294, 264, 7372, 11311, 13], "temperature": 0.0, "avg_logprob": -0.2278462942544516, "compression_ratio": 1.4771573604060915, "no_speech_prob": 0.00015829841140657663}, {"id": 334, "seek": 365400, "start": 3668.0, "end": 3676.0, "text": " Like basically, I was trying to do an audit of the ecosystem and trying to monetize that somehow, maybe.", "tokens": [1743, 1936, 11, 286, 390, 1382, 281, 360, 364, 17748, 295, 264, 11311, 293, 1382, 281, 15556, 1125, 300, 6063, 11, 1310, 13], "temperature": 0.0, "avg_logprob": -0.2278462942544516, "compression_ratio": 1.4771573604060915, "no_speech_prob": 0.00015829841140657663}, {"id": 335, "seek": 365400, "start": 3676.0, "end": 3677.0, "text": " Yeah, yeah.", "tokens": [865, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.2278462942544516, "compression_ratio": 1.4771573604060915, "no_speech_prob": 0.00015829841140657663}, {"id": 336, "seek": 367700, "start": 3677.0, "end": 3686.0, "text": " Turns out I lost interest in that. I don't know if it would be interesting financially. If your company thinks it would be interesting, let me know.", "tokens": [29524, 484, 286, 2731, 1179, 294, 300, 13, 286, 500, 380, 458, 498, 309, 576, 312, 1880, 20469, 13, 759, 428, 2237, 7309, 309, 576, 312, 1880, 11, 718, 385, 458, 13], "temperature": 0.0, "avg_logprob": -0.20665890562768077, "compression_ratio": 1.680672268907563, "no_speech_prob": 2.8849948648712598e-05}, {"id": 337, "seek": 367700, "start": 3686.0, "end": 3691.0, "text": " But otherwise, yeah, I prefer working on ElmReview directly, I guess.", "tokens": [583, 5911, 11, 1338, 11, 286, 4382, 1364, 322, 2699, 76, 8524, 1759, 3838, 11, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.20665890562768077, "compression_ratio": 1.680672268907563, "no_speech_prob": 2.8849948648712598e-05}, {"id": 338, "seek": 367700, "start": 3691.0, "end": 3692.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.20665890562768077, "compression_ratio": 1.680672268907563, "no_speech_prob": 2.8849948648712598e-05}, {"id": 339, "seek": 367700, "start": 3692.0, "end": 3703.0, "text": " So yeah, that was why I started making it. Like I needed to extract information from a package to give to other packages, to the review of other packages, and so on and so on.", "tokens": [407, 1338, 11, 300, 390, 983, 286, 1409, 1455, 309, 13, 1743, 286, 2978, 281, 8947, 1589, 490, 257, 7372, 281, 976, 281, 661, 17401, 11, 281, 264, 3131, 295, 661, 17401, 11, 293, 370, 322, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.20665890562768077, "compression_ratio": 1.680672268907563, "no_speech_prob": 2.8849948648712598e-05}, {"id": 340, "seek": 370300, "start": 3703.0, "end": 3718.0, "text": " That's very cool. Yeah, it does open up so many doors. Like the security vulnerability checking is like, I mean, there are some interesting projects in the JS ecosystem these days checking for security vulnerabilities.", "tokens": [663, 311, 588, 1627, 13, 865, 11, 309, 775, 1269, 493, 370, 867, 8077, 13, 1743, 264, 3825, 24210, 8568, 307, 411, 11, 286, 914, 11, 456, 366, 512, 1880, 4455, 294, 264, 33063, 11311, 613, 1708, 8568, 337, 3825, 37633, 13], "temperature": 0.0, "avg_logprob": -0.18657637178228142, "compression_ratio": 1.6043478260869566, "no_speech_prob": 5.390600927057676e-05}, {"id": 341, "seek": 370300, "start": 3718.0, "end": 3727.0, "text": " But it's just so much easier to get assurances around things like that with Elm and with ElmReview and ElmReview Extractors. It's a really cool space.", "tokens": [583, 309, 311, 445, 370, 709, 3571, 281, 483, 1256, 374, 2676, 926, 721, 411, 300, 365, 2699, 76, 293, 365, 2699, 76, 8524, 1759, 293, 2699, 76, 8524, 1759, 9881, 1897, 830, 13, 467, 311, 257, 534, 1627, 1901, 13], "temperature": 0.0, "avg_logprob": -0.18657637178228142, "compression_ratio": 1.6043478260869566, "no_speech_prob": 5.390600927057676e-05}, {"id": 342, "seek": 372700, "start": 3727.0, "end": 3740.0, "text": " And code quality, like, I mean, we don't really have much by way of code quality tools in the Elm community. We have ElmReview.", "tokens": [400, 3089, 3125, 11, 411, 11, 286, 914, 11, 321, 500, 380, 534, 362, 709, 538, 636, 295, 3089, 3125, 3873, 294, 264, 2699, 76, 1768, 13, 492, 362, 2699, 76, 8524, 1759, 13], "temperature": 0.0, "avg_logprob": -0.19587594270706177, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.00021994374401401728}, {"id": 343, "seek": 372700, "start": 3740.0, "end": 3756.0, "text": " Right. I mean, those are tools that help ensure code quality, but not code quality tools in the sense of like giving you a code quality report to try to, you know, I mean, of course, like unused functions and things like that are a code quality metric.", "tokens": [1779, 13, 286, 914, 11, 729, 366, 3873, 300, 854, 5586, 3089, 3125, 11, 457, 406, 3089, 3125, 3873, 294, 264, 2020, 295, 411, 2902, 291, 257, 3089, 3125, 2275, 281, 853, 281, 11, 291, 458, 11, 286, 914, 11, 295, 1164, 11, 411, 44383, 6828, 293, 721, 411, 300, 366, 257, 3089, 3125, 20678, 13], "temperature": 0.0, "avg_logprob": -0.19587594270706177, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.00021994374401401728}, {"id": 344, "seek": 375600, "start": 3756.0, "end": 3767.0, "text": " But it's sort of like stops being a code quality metric when the tool just fixes it for you. And then like, it's just a static analysis tool.", "tokens": [583, 309, 311, 1333, 295, 411, 10094, 885, 257, 3089, 3125, 20678, 562, 264, 2290, 445, 32539, 309, 337, 291, 13, 400, 550, 411, 11, 309, 311, 445, 257, 13437, 5215, 2290, 13], "temperature": 0.0, "avg_logprob": -0.2196051279703776, "compression_ratio": 1.5544554455445545, "no_speech_prob": 1.0952891898341477e-05}, {"id": 345, "seek": 375600, "start": 3767.0, "end": 3769.0, "text": " Yeah, the metric is always zero because it fixed everything.", "tokens": [865, 11, 264, 20678, 307, 1009, 4018, 570, 309, 6806, 1203, 13], "temperature": 0.0, "avg_logprob": -0.2196051279703776, "compression_ratio": 1.5544554455445545, "no_speech_prob": 1.0952891898341477e-05}, {"id": 346, "seek": 375600, "start": 3769.0, "end": 3778.0, "text": " Exactly. But that would be really cool to have like a suite of code quality tools to look at where to refactor.", "tokens": [7587, 13, 583, 300, 576, 312, 534, 1627, 281, 362, 411, 257, 14205, 295, 3089, 3125, 3873, 281, 574, 412, 689, 281, 1895, 15104, 13], "temperature": 0.0, "avg_logprob": -0.2196051279703776, "compression_ratio": 1.5544554455445545, "no_speech_prob": 1.0952891898341477e-05}, {"id": 347, "seek": 377800, "start": 3778.0, "end": 3788.0, "text": " Yeah. So I remember talking to the author of Elm Analyze, Mats. He was really liking the direction of ElmReview and he thought it was a great project. So that made me happy.", "tokens": [865, 13, 407, 286, 1604, 1417, 281, 264, 3793, 295, 2699, 76, 1107, 5222, 1381, 11, 27204, 13, 634, 390, 534, 16933, 264, 3513, 295, 2699, 76, 8524, 1759, 293, 415, 1194, 309, 390, 257, 869, 1716, 13, 407, 300, 1027, 385, 2055, 13], "temperature": 0.0, "avg_logprob": -0.19831258401103402, "compression_ratio": 1.5327102803738317, "no_speech_prob": 4.83195144624915e-05}, {"id": 348, "seek": 377800, "start": 3788.0, "end": 3800.0, "text": " And he was thinking, well, potentially, I could now make Elm Analyze use ElmReview under the hood and make things like dashboards or code quality metrics.", "tokens": [400, 415, 390, 1953, 11, 731, 11, 7263, 11, 286, 727, 586, 652, 2699, 76, 1107, 5222, 1381, 764, 2699, 76, 8524, 1759, 833, 264, 13376, 293, 652, 721, 411, 8240, 17228, 420, 3089, 3125, 16367, 13], "temperature": 0.0, "avg_logprob": -0.19831258401103402, "compression_ratio": 1.5327102803738317, "no_speech_prob": 4.83195144624915e-05}, {"id": 349, "seek": 380000, "start": 3800.0, "end": 3814.0, "text": " So exactly this idea. So yeah, I think it's possible. Yeah. What needs to be shown, what is interesting, that remains to be investigated.", "tokens": [407, 2293, 341, 1558, 13, 407, 1338, 11, 286, 519, 309, 311, 1944, 13, 865, 13, 708, 2203, 281, 312, 4898, 11, 437, 307, 1880, 11, 300, 7023, 281, 312, 30070, 13], "temperature": 0.0, "avg_logprob": -0.2511647277408176, "compression_ratio": 1.2454545454545454, "no_speech_prob": 1.5935687770252116e-05}, {"id": 350, "seek": 381400, "start": 3814.0, "end": 3832.0, "text": " Yeah, so many interesting things to explore here. One thing we would be remiss if we did not mention unit testing. There's really not too much to say on this point other than you can do it. You can write unit tests for your data extractors.", "tokens": [865, 11, 370, 867, 1880, 721, 281, 6839, 510, 13, 1485, 551, 321, 576, 312, 890, 891, 498, 321, 630, 406, 2152, 4985, 4997, 13, 821, 311, 534, 406, 886, 709, 281, 584, 322, 341, 935, 661, 813, 291, 393, 360, 309, 13, 509, 393, 2464, 4985, 6921, 337, 428, 1412, 8947, 830, 13], "temperature": 0.0, "avg_logprob": -0.1876019280532311, "compression_ratio": 1.5, "no_speech_prob": 5.142452209838666e-05}, {"id": 351, "seek": 383200, "start": 3832.0, "end": 3844.0, "text": " If you have tests, then ElmReview's testing framework will force you to explain how the data extract will look like.", "tokens": [759, 291, 362, 6921, 11, 550, 2699, 76, 8524, 1759, 311, 4997, 8388, 486, 3464, 291, 281, 2903, 577, 264, 1412, 8947, 486, 574, 411, 13], "temperature": 0.0, "avg_logprob": -0.18824203312397003, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.00010869032121263444}, {"id": 352, "seek": 383200, "start": 3844.0, "end": 3845.0, "text": " Really?", "tokens": [4083, 30], "temperature": 0.0, "avg_logprob": -0.18824203312397003, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.00010869032121263444}, {"id": 353, "seek": 383200, "start": 3845.0, "end": 3851.0, "text": " Yeah. Basically, ElmReview's testing framework is like, if there's anything that we can check, we will check it.", "tokens": [865, 13, 8537, 11, 2699, 76, 8524, 1759, 311, 4997, 8388, 307, 411, 11, 498, 456, 311, 1340, 300, 321, 393, 1520, 11, 321, 486, 1520, 309, 13], "temperature": 0.0, "avg_logprob": -0.18824203312397003, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.00010869032121263444}, {"id": 354, "seek": 385100, "start": 3851.0, "end": 3867.0, "text": " Whoa, I did not know this. I'm proud to say I did not know it because I have not encountered this situation before, because I really like writing tests for my ElmReview rules. But wow, that's cool.", "tokens": [7521, 11, 286, 630, 406, 458, 341, 13, 286, 478, 4570, 281, 584, 286, 630, 406, 458, 309, 570, 286, 362, 406, 20381, 341, 2590, 949, 11, 570, 286, 534, 411, 3579, 6921, 337, 452, 2699, 76, 8524, 1759, 4474, 13, 583, 6076, 11, 300, 311, 1627, 13], "temperature": 0.0, "avg_logprob": -0.2019779498760517, "compression_ratio": 1.3971631205673758, "no_speech_prob": 0.0003451943339314312}, {"id": 355, "seek": 386700, "start": 3867.0, "end": 3883.0, "text": " Yeah. I mean, if your rule provides a fix, then you will have to say how it's fixed. If you say, well, there's an error, it will say, well, what are the message and details and where is that error?", "tokens": [865, 13, 286, 914, 11, 498, 428, 4978, 6417, 257, 3191, 11, 550, 291, 486, 362, 281, 584, 577, 309, 311, 6806, 13, 759, 291, 584, 11, 731, 11, 456, 311, 364, 6713, 11, 309, 486, 584, 11, 731, 11, 437, 366, 264, 3636, 293, 4365, 293, 689, 307, 300, 6713, 30], "temperature": 0.0, "avg_logprob": -0.1754363945552281, "compression_ratio": 1.4485294117647058, "no_speech_prob": 4.1949606384150684e-05}, {"id": 356, "seek": 388300, "start": 3883.0, "end": 3901.0, "text": " Basically, everything that we can check, we check. I think sometimes it's annoying because you'd have to write a lot of things, especially for data extracts. Maybe it's a bit too much. I could imagine adding a feature that says, please don't force me to write a data extractor.", "tokens": [8537, 11, 1203, 300, 321, 393, 1520, 11, 321, 1520, 13, 286, 519, 2171, 309, 311, 11304, 570, 291, 1116, 362, 281, 2464, 257, 688, 295, 721, 11, 2318, 337, 1412, 8947, 82, 13, 2704, 309, 311, 257, 857, 886, 709, 13, 286, 727, 3811, 5127, 257, 4111, 300, 1619, 11, 1767, 500, 380, 3464, 385, 281, 2464, 257, 1412, 8947, 284, 13], "temperature": 0.0, "avg_logprob": -0.2091516629614011, "compression_ratio": 1.6088709677419355, "no_speech_prob": 0.00012922346650157124}, {"id": 357, "seek": 388300, "start": 3901.0, "end": 3910.0, "text": " But so far in general, the idea holds very well. I personally see it as a positive. It has worked for my rules, at least.", "tokens": [583, 370, 1400, 294, 2674, 11, 264, 1558, 9190, 588, 731, 13, 286, 5665, 536, 309, 382, 257, 3353, 13, 467, 575, 2732, 337, 452, 4474, 11, 412, 1935, 13], "temperature": 0.0, "avg_logprob": -0.2091516629614011, "compression_ratio": 1.6088709677419355, "no_speech_prob": 0.00012922346650157124}, {"id": 358, "seek": 391000, "start": 3910.0, "end": 3925.0, "text": " Yeah, you could potentially have something that allows you to assert on the data extractor or something. If you want to look at a subset of the values or something like that, I don't know. It's an interesting point.", "tokens": [865, 11, 291, 727, 7263, 362, 746, 300, 4045, 291, 281, 19810, 322, 264, 1412, 8947, 284, 420, 746, 13, 759, 291, 528, 281, 574, 412, 257, 25993, 295, 264, 4190, 420, 746, 411, 300, 11, 286, 500, 380, 458, 13, 467, 311, 364, 1880, 935, 13], "temperature": 0.0, "avg_logprob": -0.206509926739861, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.00011234762496314943}, {"id": 359, "seek": 392500, "start": 3925.0, "end": 3940.0, "text": " But yeah, currently what it does is you say, review.test.expectDataExtract, and then you give a JSON string that you expect it to return for your extractor.", "tokens": [583, 1338, 11, 4362, 437, 309, 775, 307, 291, 584, 11, 3131, 13, 31636, 13, 3121, 1043, 35, 3274, 36, 734, 1897, 11, 293, 550, 291, 976, 257, 31828, 6798, 300, 291, 2066, 309, 281, 2736, 337, 428, 8947, 284, 13], "temperature": 0.0, "avg_logprob": -0.2141549345375835, "compression_ratio": 1.4285714285714286, "no_speech_prob": 6.143957762105856e-06}, {"id": 360, "seek": 392500, "start": 3940.0, "end": 3948.0, "text": " I could imagine if you have very rich information, that could become tedious, but it's a great feature.", "tokens": [286, 727, 3811, 498, 291, 362, 588, 4593, 1589, 11, 300, 727, 1813, 38284, 11, 457, 309, 311, 257, 869, 4111, 13], "temperature": 0.0, "avg_logprob": -0.2141549345375835, "compression_ratio": 1.4285714285714286, "no_speech_prob": 6.143957762105856e-06}, {"id": 361, "seek": 394800, "start": 3948.0, "end": 3959.0, "text": " Yeah, in general, the test cases you use your rules on are pretty small, so I think it's manageable. But yeah, I can absolutely imagine it will be a bit too much.", "tokens": [865, 11, 294, 2674, 11, 264, 1500, 3331, 291, 764, 428, 4474, 322, 366, 1238, 1359, 11, 370, 286, 519, 309, 311, 38798, 13, 583, 1338, 11, 286, 393, 3122, 3811, 309, 486, 312, 257, 857, 886, 709, 13], "temperature": 0.0, "avg_logprob": -0.20116634079904266, "compression_ratio": 1.4204545454545454, "no_speech_prob": 1.1658785297186114e-05}, {"id": 362, "seek": 394800, "start": 3959.0, "end": 3966.0, "text": " So if you're hitting that and genuinely it's annoying, open an issue.", "tokens": [407, 498, 291, 434, 8850, 300, 293, 17839, 309, 311, 11304, 11, 1269, 364, 2734, 13], "temperature": 0.0, "avg_logprob": -0.20116634079904266, "compression_ratio": 1.4204545454545454, "no_speech_prob": 1.1658785297186114e-05}, {"id": 363, "seek": 394800, "start": 3966.0, "end": 3968.0, "text": " Very interesting.", "tokens": [4372, 1880, 13], "temperature": 0.0, "avg_logprob": -0.20116634079904266, "compression_ratio": 1.4204545454545454, "no_speech_prob": 1.1658785297186114e-05}, {"id": 364, "seek": 396800, "start": 3968.0, "end": 3980.0, "text": " So another use case, I can really see this being used, but I think it might also be, or this data extract idea, but I think it might be a bit too...", "tokens": [407, 1071, 764, 1389, 11, 286, 393, 534, 536, 341, 885, 1143, 11, 457, 286, 519, 309, 1062, 611, 312, 11, 420, 341, 1412, 8947, 1558, 11, 457, 286, 519, 309, 1062, 312, 257, 857, 886, 485], "temperature": 0.0, "avg_logprob": -0.25962210435133715, "compression_ratio": 1.5460122699386503, "no_speech_prob": 1.8336962966714054e-05}, {"id": 365, "seek": 396800, "start": 3980.0, "end": 3988.0, "text": " It will not work perfectly, but I would like to see an investigation in this, is for explaining things.", "tokens": [467, 486, 406, 589, 6239, 11, 457, 286, 576, 411, 281, 536, 364, 9627, 294, 341, 11, 307, 337, 13468, 721, 13], "temperature": 0.0, "avg_logprob": -0.25962210435133715, "compression_ratio": 1.5460122699386503, "no_speech_prob": 1.8336962966714054e-05}, {"id": 366, "seek": 398800, "start": 3988.0, "end": 4000.0, "text": " For instance, one of the things where people can get confused is when you have update functions, where you have one message that triggers a command,", "tokens": [1171, 5197, 11, 472, 295, 264, 721, 689, 561, 393, 483, 9019, 307, 562, 291, 362, 5623, 6828, 11, 689, 291, 362, 472, 3636, 300, 22827, 257, 5622, 11], "temperature": 0.0, "avg_logprob": -0.1725677982453377, "compression_ratio": 1.8202764976958525, "no_speech_prob": 6.806523742852733e-05}, {"id": 367, "seek": 398800, "start": 4000.0, "end": 4005.0, "text": " that triggers another message, which in turn triggers another command, and so on and so on.", "tokens": [300, 22827, 1071, 3636, 11, 597, 294, 1261, 22827, 1071, 5622, 11, 293, 370, 322, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.1725677982453377, "compression_ratio": 1.8202764976958525, "no_speech_prob": 6.806523742852733e-05}, {"id": 368, "seek": 398800, "start": 4005.0, "end": 4017.0, "text": " So for instance, if you need to process a payment, there's a lot of steps to that, and it can be hard to figure out in which order these messages come in.", "tokens": [407, 337, 5197, 11, 498, 291, 643, 281, 1399, 257, 10224, 11, 456, 311, 257, 688, 295, 4439, 281, 300, 11, 293, 309, 393, 312, 1152, 281, 2573, 484, 294, 597, 1668, 613, 7897, 808, 294, 13], "temperature": 0.0, "avg_logprob": -0.1725677982453377, "compression_ratio": 1.8202764976958525, "no_speech_prob": 6.806523742852733e-05}, {"id": 369, "seek": 401700, "start": 4017.0, "end": 4024.0, "text": " And I would love to see a diagram that shows in which order these things are applied.", "tokens": [400, 286, 576, 959, 281, 536, 257, 10686, 300, 3110, 294, 597, 1668, 613, 721, 366, 6456, 13], "temperature": 0.0, "avg_logprob": -0.22801824716421273, "compression_ratio": 1.4545454545454546, "no_speech_prob": 2.8855867640231736e-05}, {"id": 370, "seek": 401700, "start": 4024.0, "end": 4030.0, "text": " And I'm thinking that using static analysis, we could make this diagram.", "tokens": [400, 286, 478, 1953, 300, 1228, 13437, 5215, 11, 321, 727, 652, 341, 10686, 13], "temperature": 0.0, "avg_logprob": -0.22801824716421273, "compression_ratio": 1.4545454545454546, "no_speech_prob": 2.8855867640231736e-05}, {"id": 371, "seek": 401700, "start": 4030.0, "end": 4036.0, "text": " We're using ElmReview data extractors. You get all the information and you now make it a diagram.", "tokens": [492, 434, 1228, 2699, 76, 8524, 1759, 1412, 8947, 830, 13, 509, 483, 439, 264, 1589, 293, 291, 586, 652, 309, 257, 10686, 13], "temperature": 0.0, "avg_logprob": -0.22801824716421273, "compression_ratio": 1.4545454545454546, "no_speech_prob": 2.8855867640231736e-05}, {"id": 372, "seek": 403600, "start": 4036.0, "end": 4048.0, "text": " And I think you can do diagrams for a lot of things, like even, for instance, as I mentioned, the import modules before.", "tokens": [400, 286, 519, 291, 393, 360, 36709, 337, 257, 688, 295, 721, 11, 411, 754, 11, 337, 5197, 11, 382, 286, 2835, 11, 264, 974, 16679, 949, 13], "temperature": 0.0, "avg_logprob": -0.2076440957876352, "compression_ratio": 1.6358974358974359, "no_speech_prob": 1.1658479706966318e-05}, {"id": 373, "seek": 403600, "start": 4048.0, "end": 4055.0, "text": " Well, if you group them nicely, if you format them nicely, if you remove all the unnecessary details,", "tokens": [1042, 11, 498, 291, 1594, 552, 9594, 11, 498, 291, 7877, 552, 9594, 11, 498, 291, 4159, 439, 264, 19350, 4365, 11], "temperature": 0.0, "avg_logprob": -0.2076440957876352, "compression_ratio": 1.6358974358974359, "no_speech_prob": 1.1658479706966318e-05}, {"id": 374, "seek": 403600, "start": 4055.0, "end": 4061.0, "text": " this can now become an overview of your project that you can show to newcomers to your projects.", "tokens": [341, 393, 586, 1813, 364, 12492, 295, 428, 1716, 300, 291, 393, 855, 281, 40014, 433, 281, 428, 4455, 13], "temperature": 0.0, "avg_logprob": -0.2076440957876352, "compression_ratio": 1.6358974358974359, "no_speech_prob": 1.1658479706966318e-05}, {"id": 375, "seek": 406100, "start": 4061.0, "end": 4067.0, "text": " It can become documentation that you can force to always be up to date.", "tokens": [467, 393, 1813, 14333, 300, 291, 393, 3464, 281, 1009, 312, 493, 281, 4002, 13], "temperature": 0.0, "avg_logprob": -0.19401455908706508, "compression_ratio": 1.6144067796610169, "no_speech_prob": 7.367710350081325e-05}, {"id": 376, "seek": 406100, "start": 4067.0, "end": 4072.0, "text": " So this is something that I would like to see some exploration as well in.", "tokens": [407, 341, 307, 746, 300, 286, 576, 411, 281, 536, 512, 16197, 382, 731, 294, 13], "temperature": 0.0, "avg_logprob": -0.19401455908706508, "compression_ratio": 1.6144067796610169, "no_speech_prob": 7.367710350081325e-05}, {"id": 377, "seek": 406100, "start": 4072.0, "end": 4076.0, "text": " For the example, for the update, it's a lot more local, right?", "tokens": [1171, 264, 1365, 11, 337, 264, 5623, 11, 309, 311, 257, 688, 544, 2654, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.19401455908706508, "compression_ratio": 1.6144067796610169, "no_speech_prob": 7.367710350081325e-05}, {"id": 378, "seek": 406100, "start": 4076.0, "end": 4081.0, "text": " It's like, well, once you get information for this module, for this function,", "tokens": [467, 311, 411, 11, 731, 11, 1564, 291, 483, 1589, 337, 341, 10088, 11, 337, 341, 2445, 11], "temperature": 0.0, "avg_logprob": -0.19401455908706508, "compression_ratio": 1.6144067796610169, "no_speech_prob": 7.367710350081325e-05}, {"id": 379, "seek": 406100, "start": 4081.0, "end": 4087.0, "text": " maybe it could even be like explaining how the HTML will look like and how it interacts with,", "tokens": [1310, 309, 727, 754, 312, 411, 13468, 577, 264, 17995, 486, 574, 411, 293, 577, 309, 43582, 365, 11], "temperature": 0.0, "avg_logprob": -0.19401455908706508, "compression_ratio": 1.6144067796610169, "no_speech_prob": 7.367710350081325e-05}, {"id": 380, "seek": 408700, "start": 4087.0, "end": 4091.0, "text": " or which buttons, for instance, will trigger what messages. I don't know.", "tokens": [420, 597, 9905, 11, 337, 5197, 11, 486, 7875, 437, 7897, 13, 286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.20891880989074707, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.00010389350063633174}, {"id": 381, "seek": 408700, "start": 4091.0, "end": 4102.0, "text": " But the part where I'm like, this might not work very well is because you're probably going to have to compute that for your entire project,", "tokens": [583, 264, 644, 689, 286, 478, 411, 11, 341, 1062, 406, 589, 588, 731, 307, 570, 291, 434, 1391, 516, 281, 362, 281, 14722, 300, 337, 428, 2302, 1716, 11], "temperature": 0.0, "avg_logprob": -0.20891880989074707, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.00010389350063633174}, {"id": 382, "seek": 408700, "start": 4102.0, "end": 4107.0, "text": " which sounds like a lot when you're only interested in a specific part.", "tokens": [597, 3263, 411, 257, 688, 562, 291, 434, 787, 3102, 294, 257, 2685, 644, 13], "temperature": 0.0, "avg_logprob": -0.20891880989074707, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.00010389350063633174}, {"id": 383, "seek": 408700, "start": 4107.0, "end": 4114.0, "text": " You're only interested in the diagram for this one module or this one function.", "tokens": [509, 434, 787, 3102, 294, 264, 10686, 337, 341, 472, 10088, 420, 341, 472, 2445, 13], "temperature": 0.0, "avg_logprob": -0.20891880989074707, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.00010389350063633174}, {"id": 384, "seek": 411400, "start": 4114.0, "end": 4120.0, "text": " So maybe the data extract should take an argument.", "tokens": [407, 1310, 264, 1412, 8947, 820, 747, 364, 6770, 13], "temperature": 0.0, "avg_logprob": -0.28077233143341845, "compression_ratio": 1.45, "no_speech_prob": 1.8057507986668497e-05}, {"id": 385, "seek": 411400, "start": 4120.0, "end": 4121.0, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.28077233143341845, "compression_ratio": 1.45, "no_speech_prob": 1.8057507986668497e-05}, {"id": 386, "seek": 411400, "start": 4121.0, "end": 4131.0, "text": " Something like ElmCogen takes information in, which gets very tricky in terms of trying to cache the results,", "tokens": [6595, 411, 2699, 76, 34, 664, 268, 2516, 1589, 294, 11, 597, 2170, 588, 12414, 294, 2115, 295, 1382, 281, 19459, 264, 3542, 11], "temperature": 0.0, "avg_logprob": -0.28077233143341845, "compression_ratio": 1.45, "no_speech_prob": 1.8057507986668497e-05}, {"id": 387, "seek": 411400, "start": 4131.0, "end": 4135.0, "text": " but it could be doable in practice.", "tokens": [457, 309, 727, 312, 41183, 294, 3124, 13], "temperature": 0.0, "avg_logprob": -0.28077233143341845, "compression_ratio": 1.45, "no_speech_prob": 1.8057507986668497e-05}, {"id": 388, "seek": 411400, "start": 4135.0, "end": 4141.0, "text": " Like just if we don't care about ElmReview being slower, this could be done. Definitely.", "tokens": [1743, 445, 498, 321, 500, 380, 1127, 466, 2699, 76, 8524, 1759, 885, 14009, 11, 341, 727, 312, 1096, 13, 12151, 13], "temperature": 0.0, "avg_logprob": -0.28077233143341845, "compression_ratio": 1.45, "no_speech_prob": 1.8057507986668497e-05}, {"id": 389, "seek": 414100, "start": 4141.0, "end": 4144.0, "text": " So this is something I think could be pretty cool.", "tokens": [407, 341, 307, 746, 286, 519, 727, 312, 1238, 1627, 13], "temperature": 0.0, "avg_logprob": -0.20999039870042066, "compression_ratio": 1.5026737967914439, "no_speech_prob": 4.907388938590884e-05}, {"id": 390, "seek": 414100, "start": 4144.0, "end": 4155.0, "text": " I think Richard Feldman also talked about this for Rock, where they want people to be able to build tools for their packages.", "tokens": [286, 519, 9809, 42677, 1601, 611, 2825, 466, 341, 337, 6922, 11, 689, 436, 528, 561, 281, 312, 1075, 281, 1322, 3873, 337, 641, 17401, 13], "temperature": 0.0, "avg_logprob": -0.20999039870042066, "compression_ratio": 1.5026737967914439, "no_speech_prob": 4.907388938590884e-05}, {"id": 391, "seek": 414100, "start": 4155.0, "end": 4161.0, "text": " And then whenever you install a package, you also get like editor integrations that help explain things.", "tokens": [400, 550, 5699, 291, 3625, 257, 7372, 11, 291, 611, 483, 411, 9839, 3572, 763, 300, 854, 2903, 721, 13], "temperature": 0.0, "avg_logprob": -0.20999039870042066, "compression_ratio": 1.5026737967914439, "no_speech_prob": 4.907388938590884e-05}, {"id": 392, "seek": 416100, "start": 4161.0, "end": 4171.0, "text": " Like I don't remember if this was an example, a possible example, but you could imagine you're adding in Rock slash HTML package,", "tokens": [1743, 286, 500, 380, 1604, 498, 341, 390, 364, 1365, 11, 257, 1944, 1365, 11, 457, 291, 727, 3811, 291, 434, 5127, 294, 6922, 17330, 17995, 7372, 11], "temperature": 0.0, "avg_logprob": -0.2198535091472122, "compression_ratio": 1.6694214876033058, "no_speech_prob": 2.7533782485988922e-05}, {"id": 393, "seek": 416100, "start": 4171.0, "end": 4181.0, "text": " and now you can have a preview of the HTML in your editor, or you have a color package and you can have a color picker in your editor.", "tokens": [293, 586, 291, 393, 362, 257, 14281, 295, 264, 17995, 294, 428, 9839, 11, 420, 291, 362, 257, 2017, 7372, 293, 291, 393, 362, 257, 2017, 1888, 260, 294, 428, 9839, 13], "temperature": 0.0, "avg_logprob": -0.2198535091472122, "compression_ratio": 1.6694214876033058, "no_speech_prob": 2.7533782485988922e-05}, {"id": 394, "seek": 416100, "start": 4181.0, "end": 4183.0, "text": " I don't know. Things like that.", "tokens": [286, 500, 380, 458, 13, 9514, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.2198535091472122, "compression_ratio": 1.6694214876033058, "no_speech_prob": 2.7533782485988922e-05}, {"id": 395, "seek": 416100, "start": 4183.0, "end": 4190.0, "text": " And yeah, I think I could see the same thing with ElmReview, but like performance wise, this will not work.", "tokens": [400, 1338, 11, 286, 519, 286, 727, 536, 264, 912, 551, 365, 2699, 76, 8524, 1759, 11, 457, 411, 3389, 10829, 11, 341, 486, 406, 589, 13], "temperature": 0.0, "avg_logprob": -0.2198535091472122, "compression_ratio": 1.6694214876033058, "no_speech_prob": 2.7533782485988922e-05}, {"id": 396, "seek": 419000, "start": 4190.0, "end": 4195.0, "text": " And I know you've talked about like having language server like...", "tokens": [400, 286, 458, 291, 600, 2825, 466, 411, 1419, 2856, 7154, 411, 485], "temperature": 0.0, "avg_logprob": -0.21095783107883329, "compression_ratio": 1.57, "no_speech_prob": 1.6701022104825824e-05}, {"id": 397, "seek": 419000, "start": 4195.0, "end": 4197.0, "text": " Yes, yes.", "tokens": [1079, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.21095783107883329, "compression_ratio": 1.57, "no_speech_prob": 1.6701022104825824e-05}, {"id": 398, "seek": 419000, "start": 4197.0, "end": 4200.0, "text": " Intents or actions using ElmReview.", "tokens": [5681, 791, 420, 5909, 1228, 2699, 76, 8524, 1759, 13], "temperature": 0.0, "avg_logprob": -0.21095783107883329, "compression_ratio": 1.57, "no_speech_prob": 1.6701022104825824e-05}, {"id": 399, "seek": 419000, "start": 4200.0, "end": 4204.0, "text": " And yeah, it would be nice to go that way, I think.", "tokens": [400, 1338, 11, 309, 576, 312, 1481, 281, 352, 300, 636, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.21095783107883329, "compression_ratio": 1.57, "no_speech_prob": 1.6701022104825824e-05}, {"id": 400, "seek": 419000, "start": 4204.0, "end": 4207.0, "text": " But like maybe we should have an intervention like that.", "tokens": [583, 411, 1310, 321, 820, 362, 364, 13176, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.21095783107883329, "compression_ratio": 1.57, "no_speech_prob": 1.6701022104825824e-05}, {"id": 401, "seek": 419000, "start": 4207.0, "end": 4211.0, "text": " ElmReview is doing too much right now.", "tokens": [2699, 76, 8524, 1759, 307, 884, 886, 709, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.21095783107883329, "compression_ratio": 1.57, "no_speech_prob": 1.6701022104825824e-05}, {"id": 402, "seek": 419000, "start": 4211.0, "end": 4214.0, "text": " But these would be interesting explorations, I think.", "tokens": [583, 613, 576, 312, 1880, 24765, 763, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.21095783107883329, "compression_ratio": 1.57, "no_speech_prob": 1.6701022104825824e-05}, {"id": 403, "seek": 421400, "start": 4214.0, "end": 4222.0, "text": " Yeah, it does make... I mean, the extract functionality makes ElmReview feel more like a platform, which I think is a great thing.", "tokens": [865, 11, 309, 775, 652, 485, 286, 914, 11, 264, 8947, 14980, 1669, 2699, 76, 8524, 1759, 841, 544, 411, 257, 3663, 11, 597, 286, 519, 307, 257, 869, 551, 13], "temperature": 0.0, "avg_logprob": -0.18966018452363856, "compression_ratio": 1.5968379446640317, "no_speech_prob": 7.368160731857643e-05}, {"id": 404, "seek": 421400, "start": 4222.0, "end": 4231.0, "text": " My sort of AI experiment where I'm trying to build like a type solver that replaces certain debug.todos.", "tokens": [1222, 1333, 295, 7318, 5120, 689, 286, 478, 1382, 281, 1322, 411, 257, 2010, 1404, 331, 300, 46734, 1629, 24083, 13, 83, 378, 329, 13], "temperature": 0.0, "avg_logprob": -0.18966018452363856, "compression_ratio": 1.5968379446640317, "no_speech_prob": 7.368160731857643e-05}, {"id": 405, "seek": 421400, "start": 4231.0, "end": 4242.0, "text": " That's one of the things I'm doing is I'm actually like extracting the range of a debug.todo and then the relevant context around it of which things are in scope there.", "tokens": [663, 311, 472, 295, 264, 721, 286, 478, 884, 307, 286, 478, 767, 411, 49844, 264, 3613, 295, 257, 24083, 13, 83, 17423, 293, 550, 264, 7340, 4319, 926, 309, 295, 597, 721, 366, 294, 11923, 456, 13], "temperature": 0.0, "avg_logprob": -0.18966018452363856, "compression_ratio": 1.5968379446640317, "no_speech_prob": 7.368160731857643e-05}, {"id": 406, "seek": 424200, "start": 4242.0, "end": 4252.0, "text": " So that the type solver can go and do its thing and then pass that back to ElmReview and give it the range that it's solved for.", "tokens": [407, 300, 264, 2010, 1404, 331, 393, 352, 293, 360, 1080, 551, 293, 550, 1320, 300, 646, 281, 2699, 76, 8524, 1759, 293, 976, 309, 264, 3613, 300, 309, 311, 13041, 337, 13], "temperature": 0.0, "avg_logprob": -0.16027237818791315, "compression_ratio": 1.6317991631799162, "no_speech_prob": 2.931053859356325e-05}, {"id": 407, "seek": 424200, "start": 4252.0, "end": 4255.0, "text": " And that gives guardrails to the GPT prompt.", "tokens": [400, 300, 2709, 6290, 424, 4174, 281, 264, 26039, 51, 12391, 13], "temperature": 0.0, "avg_logprob": -0.16027237818791315, "compression_ratio": 1.6317991631799162, "no_speech_prob": 2.931053859356325e-05}, {"id": 408, "seek": 424200, "start": 4255.0, "end": 4259.0, "text": " So it's not just going and modifying your entire code base.", "tokens": [407, 309, 311, 406, 445, 516, 293, 42626, 428, 2302, 3089, 3096, 13], "temperature": 0.0, "avg_logprob": -0.16027237818791315, "compression_ratio": 1.6317991631799162, "no_speech_prob": 2.931053859356325e-05}, {"id": 409, "seek": 424200, "start": 4259.0, "end": 4264.0, "text": " It's only modifying the part you gave it permission to build an implementation for.", "tokens": [467, 311, 787, 42626, 264, 644, 291, 2729, 309, 11226, 281, 1322, 364, 11420, 337, 13], "temperature": 0.0, "avg_logprob": -0.16027237818791315, "compression_ratio": 1.6317991631799162, "no_speech_prob": 2.931053859356325e-05}, {"id": 410, "seek": 424200, "start": 4264.0, "end": 4268.0, "text": " And it ran the Elm compiler on it to make sure type checks and all that.", "tokens": [400, 309, 5872, 264, 2699, 76, 31958, 322, 309, 281, 652, 988, 2010, 13834, 293, 439, 300, 13], "temperature": 0.0, "avg_logprob": -0.16027237818791315, "compression_ratio": 1.6317991631799162, "no_speech_prob": 2.931053859356325e-05}, {"id": 411, "seek": 426800, "start": 4268.0, "end": 4280.0, "text": " But so it's actually going back and forth to ElmReview where it extracts from ElmReview, runs a script and then sends the results of that back to ElmReview to perform a replace rule.", "tokens": [583, 370, 309, 311, 767, 516, 646, 293, 5220, 281, 2699, 76, 8524, 1759, 689, 309, 8947, 82, 490, 2699, 76, 8524, 1759, 11, 6676, 257, 5755, 293, 550, 14790, 264, 3542, 295, 300, 646, 281, 2699, 76, 8524, 1759, 281, 2042, 257, 7406, 4978, 13], "temperature": 0.0, "avg_logprob": -0.20792558089546534, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.0783008292492013e-05}, {"id": 412, "seek": 426800, "start": 4280.0, "end": 4284.0, "text": " A fix. Pretty interesting possibilities there.", "tokens": [316, 3191, 13, 10693, 1880, 12178, 456, 13], "temperature": 0.0, "avg_logprob": -0.20792558089546534, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.0783008292492013e-05}, {"id": 413, "seek": 426800, "start": 4284.0, "end": 4291.0, "text": " Or we could just give the entire code base to an AI and then it would do the same thing that ElmReview would do.", "tokens": [1610, 321, 727, 445, 976, 264, 2302, 3089, 3096, 281, 364, 7318, 293, 550, 309, 576, 360, 264, 912, 551, 300, 2699, 76, 8524, 1759, 576, 360, 13], "temperature": 0.0, "avg_logprob": -0.20792558089546534, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.0783008292492013e-05}, {"id": 414, "seek": 426800, "start": 4291.0, "end": 4292.0, "text": " A lot easier.", "tokens": [316, 688, 3571, 13], "temperature": 0.0, "avg_logprob": -0.20792558089546534, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.0783008292492013e-05}, {"id": 415, "seek": 426800, "start": 4292.0, "end": 4297.0, "text": " That's true. Give it five years. We'll see where we are then.", "tokens": [663, 311, 2074, 13, 5303, 309, 1732, 924, 13, 492, 603, 536, 689, 321, 366, 550, 13], "temperature": 0.0, "avg_logprob": -0.20792558089546534, "compression_ratio": 1.6392156862745098, "no_speech_prob": 1.0783008292492013e-05}, {"id": 416, "seek": 429700, "start": 4297.0, "end": 4301.0, "text": " Oh, you pessimist.", "tokens": [876, 11, 291, 37399, 468, 13], "temperature": 0.0, "avg_logprob": -0.2563042921178481, "compression_ratio": 1.2892561983471074, "no_speech_prob": 0.00017389147251378745}, {"id": 417, "seek": 429700, "start": 4301.0, "end": 4312.0, "text": " I think there's a collaboration to be had between our traditional static analysis and our more modern artificial intelligence approaches.", "tokens": [286, 519, 456, 311, 257, 9363, 281, 312, 632, 1296, 527, 5164, 13437, 5215, 293, 527, 544, 4363, 11677, 7599, 11587, 13], "temperature": 0.0, "avg_logprob": -0.2563042921178481, "compression_ratio": 1.2892561983471074, "no_speech_prob": 0.00017389147251378745}, {"id": 418, "seek": 431200, "start": 4312.0, "end": 4328.0, "text": " I've mentioned this idea before of for a phantom builder extracting a diagram that shows you as a state machine, what are the possible states that this builder API can go through.", "tokens": [286, 600, 2835, 341, 1558, 949, 295, 337, 257, 903, 25796, 27377, 49844, 257, 10686, 300, 3110, 291, 382, 257, 1785, 3479, 11, 437, 366, 264, 1944, 4368, 300, 341, 27377, 9362, 393, 352, 807, 13], "temperature": 0.0, "avg_logprob": -0.29476716545190706, "compression_ratio": 1.5769230769230769, "no_speech_prob": 8.138694283843506e-06}, {"id": 419, "seek": 431200, "start": 4328.0, "end": 4334.0, "text": " Yeah, exactly. State machines are a perfect example. It's very easy to draw. There are tools for that.", "tokens": [865, 11, 2293, 13, 4533, 8379, 366, 257, 2176, 1365, 13, 467, 311, 588, 1858, 281, 2642, 13, 821, 366, 3873, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.29476716545190706, "compression_ratio": 1.5769230769230769, "no_speech_prob": 8.138694283843506e-06}, {"id": 420, "seek": 431200, "start": 4334.0, "end": 4341.0, "text": " So you just need to output to this good format. Like dots or mermaid I'm sure do that.", "tokens": [407, 291, 445, 643, 281, 5598, 281, 341, 665, 7877, 13, 1743, 15026, 420, 43146, 286, 478, 988, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.29476716545190706, "compression_ratio": 1.5769230769230769, "no_speech_prob": 8.138694283843506e-06}, {"id": 421, "seek": 434100, "start": 4341.0, "end": 4342.0, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.20415081121982673, "compression_ratio": 1.467032967032967, "no_speech_prob": 5.3059793572174385e-05}, {"id": 422, "seek": 434100, "start": 4342.0, "end": 4349.0, "text": " You just need to figure out what information you want a state diagram for and extract it and you're good to go.", "tokens": [509, 445, 643, 281, 2573, 484, 437, 1589, 291, 528, 257, 1785, 10686, 337, 293, 8947, 309, 293, 291, 434, 665, 281, 352, 13], "temperature": 0.0, "avg_logprob": -0.20415081121982673, "compression_ratio": 1.467032967032967, "no_speech_prob": 5.3059793572174385e-05}, {"id": 423, "seek": 434100, "start": 4349.0, "end": 4353.0, "text": " Yeah. Sky's the limit. I mean, there's so much cool stuff we could build.", "tokens": [865, 13, 9879, 311, 264, 4948, 13, 286, 914, 11, 456, 311, 370, 709, 1627, 1507, 321, 727, 1322, 13], "temperature": 0.0, "avg_logprob": -0.20415081121982673, "compression_ratio": 1.467032967032967, "no_speech_prob": 5.3059793572174385e-05}, {"id": 424, "seek": 434100, "start": 4353.0, "end": 4358.0, "text": " So, yeah, again, if you build some cool stuff, let us know. Tweet at us.", "tokens": [407, 11, 1338, 11, 797, 11, 498, 291, 1322, 512, 1627, 1507, 11, 718, 505, 458, 13, 314, 10354, 412, 505, 13], "temperature": 0.0, "avg_logprob": -0.20415081121982673, "compression_ratio": 1.467032967032967, "no_speech_prob": 5.3059793572174385e-05}, {"id": 425, "seek": 435800, "start": 4358.0, "end": 4371.0, "text": " Yeah. If you want to get started with this feature, we will link the article that I put on my blog, which is called Gaining Insight into your Codebase with Elm Review.", "tokens": [865, 13, 759, 291, 528, 281, 483, 1409, 365, 341, 4111, 11, 321, 486, 2113, 264, 7222, 300, 286, 829, 322, 452, 6968, 11, 597, 307, 1219, 460, 3686, 9442, 397, 666, 428, 383, 378, 68, 17429, 365, 2699, 76, 19954, 13], "temperature": 0.0, "avg_logprob": -0.29801307899364526, "compression_ratio": 1.5135135135135136, "no_speech_prob": 2.7528685677680187e-05}, {"id": 426, "seek": 435800, "start": 4371.0, "end": 4382.0, "text": " So read that and otherwise read the documentation for with data extractor in Elm Review's package documentation.", "tokens": [407, 1401, 300, 293, 5911, 1401, 264, 14333, 337, 365, 1412, 8947, 284, 294, 2699, 76, 19954, 311, 7372, 14333, 13], "temperature": 0.0, "avg_logprob": -0.29801307899364526, "compression_ratio": 1.5135135135135136, "no_speech_prob": 2.7528685677680187e-05}, {"id": 427, "seek": 438200, "start": 4382.0, "end": 4388.0, "text": " Yeah. And let us know what you come up with.", "tokens": [865, 13, 400, 718, 505, 458, 437, 291, 808, 493, 365, 13], "temperature": 0.0, "avg_logprob": -0.24816576639811197, "compression_ratio": 1.2820512820512822, "no_speech_prob": 2.1420684788608924e-05}, {"id": 428, "seek": 438200, "start": 4388.0, "end": 4393.0, "text": " Yeah. Great stuff. Well, thanks again for the great feature and Jeroen, until next time.", "tokens": [865, 13, 3769, 1507, 13, 1042, 11, 3231, 797, 337, 264, 869, 4111, 293, 508, 2032, 268, 11, 1826, 958, 565, 13], "temperature": 0.0, "avg_logprob": -0.24816576639811197, "compression_ratio": 1.2820512820512822, "no_speech_prob": 2.1420684788608924e-05}, {"id": 429, "seek": 439300, "start": 4393.0, "end": 4413.0, "text": " Until next time.", "tokens": [50364, 9088, 958, 565, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2344832420349121, "compression_ratio": 0.6666666666666666, "no_speech_prob": 0.0003584170190151781}], "language": "en"}